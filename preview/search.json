[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"index.html","id":"r-for-applied-epidemiology-and-public-health","chapter":"","heading":"R for applied epidemiology and public health","text":"handbook strives :Serve quick R code reference manualProvide task-centered examples addressing common epidemiological problemsAssist epidemiologists transitioning RBe accessible settings low internet-connectivity via [offline version][Download handbook data]Languages: Vietnamese (Tiếng Việt)Written epidemiologists, epidemiologists \nApplied Epi non-profit organisation grassroots movement frontline epis around world. write spare time offer resource community. encouragement feedback welcome:Visit website join contact listEmail contact@appliedepi.org tweet @epiRhandbookSubmit issues Github repositoryWe offer live R training instructors decades applied epidemiology experience - email us discuss.","code":""},{"path":"index.html","id":"how-to-use-this-handbook","chapter":"","heading":"How to use this handbook","text":"Browse pages Table Contents, use search boxClick “copy” icons copy codeYou can follow-along [example data][Download handbook data]See “Resources” section page materialOffline versionSee instructions [Download handbook data] page.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"","heading":"Acknowledgements","text":"handbook produced collaboration epidemiologists around world drawing upon experience organizations including local, state, provincial, national health agencies, World Health Organization (), Médecins Sans Frontières / Doctors without Borders (MSF), hospital systems, academic institutions.handbook approved product specific organization. Although strive accuracy, provide guarantee content book.","code":""},{"path":"index.html","id":"contributors","chapter":"","heading":"Contributors","text":"Editor: Neale BatraAuthors: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen LinReviewers supporters: Pat Keating, Amrish Baidjoe, Annick Lenglet, Margot Charette, Danielly Xavier, Marie-Amélie Degail Chabrat, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao MuiangaIllustrations: Calder Fong","code":""},{"path":"index.html","id":"funding-and-support","chapter":"","heading":"Funding and support","text":"handbook received supportive funding via COVID-19 emergency capacity-building grant TEPHINET, global network Field Epidemiology Training Programs (FETPs).Administrative support provided EPIET Alumni Network (EAN), special thanks Annika Wendland. EPIET European Programme Intervention Epidemiology Training.Special thanks Médecins Sans Frontières (MSF) Operational Centre Amsterdam (OCA) support development handbook.publication supported Cooperative Agreement number NU2GGH001873, funded Centers Disease Control Prevention TEPHINET, program Task Force Global Health. contents solely responsibility authors necessarily represent official views Centers Disease Control Prevention, Department Health Human Services, Task Force Global Health, Inc. TEPHINET.","code":""},{"path":"index.html","id":"inspiration","chapter":"","heading":"Inspiration","text":"multitude tutorials vignettes provided knowledge development handbook content credited within respective pages.generally, following sources provided inspiration handbook:“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify hosts website","code":""},{"path":"index.html","id":"terms-of-use-and-contribution","chapter":"","heading":"Terms of Use and Contribution","text":"","code":""},{"path":"index.html","id":"license","chapter":"","heading":"License","text":" Applied Epi Incorporated, 2021 work licensed Applied Epi Incorporated Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.Academic courses epidemiologist training programs welcome use handbook students, please send us email let us know. questions intended use, email epiRhandbook@gmail.com.","code":""},{"path":"index.html","id":"citation","chapter":"","heading":"Citation","text":"Batra, Neale, et al. Epidemiologist R Handbook. 2021. ","code":""},{"path":"index.html","id":"contribution","chapter":"","heading":"Contribution","text":"like make content contribution, please contact us first via Github issues email. implementing schedule updates creating contributor guide.Please note epiRhandbook project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-data-and-core-functions","chapter":"1 Cleaning data and core functions","heading":"1 Cleaning data and core functions","text":"page demonstrates common steps used process “cleaning” dataset, also explains use many essential R data management functions.demonstrate data cleaning, page begins importing raw case linelist dataset, proceeds step--step cleaning process. R code, manifests “pipe” chain, references “pipe” operator %>% passes dataset one operation next.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"core-functions","chapter":"1 Cleaning data and core functions","heading":"Core functions","text":"handbook emphasizes use functions tidyverse family R packages. essential R functions demonstrated page listed .Many functions belong dplyr R package, provides “verb” functions solve data manipulation challenges (name reference \"data frame-plier. dplyr part tidyverse family R packages (also includes ggplot2, tidyr, stringr, tibble, purrr, magrittr, forcats among others).want see functions compare Stata SAS commands, see page [Transition R].may encounter alternative data management framework data.table R package operators like := frequent use brackets [ ]. approach syntax briefly explained [Data Table] page.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"nomenclature","chapter":"1 Cleaning data and core functions","heading":"Nomenclature","text":"handbook, generally reference “columns” “rows” instead “variables” “observations”. explained primer “tidy data”, epidemiological statistical datasets consist structurally rows, columns, values.Variables contain values measure underlying attribute (like age group, outcome, date onset). Observations contain values measured unit (e.g. person, site, lab sample). aspects can difficult tangibly define.“tidy” datasets, column variable, row observation, cell single value. However datasets encounter fit mold - “wide” format dataset may variable split across several columns (see example [Pivoting data] page). Likewise, observations split across several rows.handbook managing transforming data, referring concrete data structures rows columns relevant abstract observations variables. Exceptions occur primarily pages data analysis, see references variables observations.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-pipeline","chapter":"1 Cleaning data and core functions","heading":"1.1 Cleaning pipeline","text":"page proceeds typical cleaning steps, adding sequentially cleaning pipe chain.epidemiological analysis data processing, cleaning steps often performed sequentially, linked together. R, often manifests cleaning “pipeline”, raw dataset passed “piped” one cleaning step another.chains utilize dplyr “verb” functions magrittr pipe operator %>%. pipe begins “raw” data (“linelist_raw.xlsx”) ends “clean” R data frame (linelist) can used, saved, exported, etc.cleaning pipeline order steps important. Cleaning steps might include:Importing dataColumn names cleaned changedDe-duplicationColumn creation transformation (e.g. re-coding standardising values)Rows filtered added","code":""},{"path":"cleaning-data-and-core-functions.html","id":"load-packages","chapter":"1 Cleaning data and core functions","heading":"1.2 Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  tidyverse   # data management and visualization\n)"},{"path":"cleaning-data-and-core-functions.html","id":"import-data","chapter":"1 Cleaning data and core functions","heading":"1.3 Import data","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"import","chapter":"1 Cleaning data and core functions","heading":"Import","text":"import “raw” case linelist Excel file using import() function package rio. rio package flexibly handles many types files (e.g. .xlsx, .csv, .tsv, .rds. See page [Import export] information tips unusual situations (e.g. skipping rows, setting missing values, importing Google sheets, etc).want follow along, click download “raw” linelist (.xlsx file).dataset large takes long time import, can useful import command separate pipe chain “raw” saved distinct file. also allows easy comparison original cleaned versions.import raw Excel file save data frame linelist_raw. assume file located working directory R project root, sub-folders specified file path.can view first 50 rows data frame . Note: base R function head(n) allow view just first n rows R console.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning-data-and-core-functions.html","id":"review","chapter":"1 Cleaning data and core functions","heading":"Review","text":"can use function skim() package skimr get overview entire dataframe (see page [Descriptive tables] info). Columns summarised class/type character, numeric. Note: “POSIXct” type raw date class (see [Working dates].\nTable 1.1: Data summary\nVariable type: characterVariable type: numericVariable type: POSIXct","code":"\nskimr::skim(linelist_raw)"},{"path":"cleaning-data-and-core-functions.html","id":"column-names","chapter":"1 Cleaning data and core functions","heading":"1.4 Column names","text":"R, column names “header” “top” value column. used refer columns code, serve default label figures.statistical software SAS STATA use “labels” co-exist longer printed versions shorter column names. R offer possibility adding column labels data, emphasized practice. make column names “printer-friendly” figures, one typically adjusts display within plotting commands create outputs (e.g. axis legend titles plot, column headers printed table - see scales section ggplot tips page [Tables presentation] pages). want assign column labels data, read online .R column names used often, must “clean” syntax. suggest following:Short namesNo spaces (replace underscores _ )unusual characters (&, #, <, >, …)Similar style nomenclature (e.g. date columns named like date_onset, date_report, date_death…)columns names linelist_raw printed using names() base R. can see initially:names contain spaces (e.g. infection date)Different naming patterns used dates (date onset vs. infection date)must merged header across two last columns .xlsx. know name two merged columns (“merged_header”) assigned R first column, second column assigned placeholder name “…28” (empty 28th column).NOTE: reference column name includes spaces, surround name back-ticks, example: linelist$` '\\x60infection date\\x60'`. note keyboard, back-tick (`) different single quotation mark (’).","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"      \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning-data-and-core-functions.html","id":"automatic-cleaning","chapter":"1 Cleaning data and core functions","heading":"Automatic cleaning","text":"function clean_names() package janitor standardizes column names makes unique following:Converts names consist underscores, numbers, lettersAccented characters transliterated ASCII (e.g. german o umlaut becomes “o”, spanish “enye” becomes “n”)Capitalization preference new column names can specified using case = argument (“snake” default, alternatives include “sentence”, “title”, “small_camel”…)can specify specific name replacements providing vector replace = argument (e.g. replace = c(onset = \"date_of_onset\"))online vignetteBelow, cleaning pipeline begins using clean_names() raw linelist.NOTE: last column name “…28” changed “x28”.","code":"\n# pipe the raw dataset through the function clean_names(), assign result as \"linelist\"  \nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new column names\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"      \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"manual-name-cleaning","chapter":"1 Cleaning data and core functions","heading":"Manual name cleaning","text":"Re-naming columns manually often necessary, even standardization step . , re-naming performed using rename() function dplyr package, part pipe chain. rename() uses style NEW = OLD - new column name given old column name., re-naming command added cleaning pipeline. Spaces added strategically align code easier reading.Now can see columns names changed:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"rename-by-column-position","chapter":"1 Cleaning data and core functions","heading":"Rename by column position","text":"can also rename column position, instead column name, example:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning-data-and-core-functions.html","id":"rename-via-select-and-summarise","chapter":"1 Cleaning data and core functions","heading":"Rename via select() and summarise()","text":"shortcut, can also rename columns within dplyr select() summarise() functions. select() used keep certain columns (covered later page). summarise() covered [Grouping data] [Descriptive tables] pages. functions also uses format new_name = old_name. example:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning-data-and-core-functions.html","id":"other-challenges","chapter":"1 Cleaning data and core functions","heading":"Other challenges","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"empty-excel-column-names","chapter":"1 Cleaning data and core functions","heading":"Empty Excel column names","text":"R dataset columns column names (headers). , import Excel dataset data column headers, R fill-headers names like “…1” “…2”. number represents column number (e.g. 4th column dataset header, R name “…4”).can clean names manually referencing position number (see example ), assigned name (linelist_raw$...1).","code":""},{"path":"cleaning-data-and-core-functions.html","id":"merged-excel-column-names-and-cells","chapter":"1 Cleaning data and core functions","heading":"Merged Excel column names and cells","text":"Merged cells Excel file common occurrence receiving data. explained [Transition R], merged cells can nice human reading data, “tidy data” cause many problems machine reading data. R accommodate merged cells.Remind people data entry human-readable data machine-readable data. Strive train users principles tidy data. possible, try change procedures data arrive tidy format without merged cells.variable must column.observation must row.value must cell.using rio’s import() function, value merged cell assigned first cell subsequent cells empty.One solution deal merged cells import data function readWorkbook() package openxlsx. Set argument fillMergedCells = TRUE. gives value merged cell cells within merge range.DANGER: column names merged readWorkbook(), end duplicate column names, need fix manually - R work well duplicate column names! can re-name referencing position (e.g. column 5), explained section manual column name cleaning.","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning-data-and-core-functions.html","id":"select-or-re-order-columns","chapter":"1 Cleaning data and core functions","heading":"1.5 Select or re-order columns","text":"Use select() dplyr select columns want retain, specify order data frame.CAUTION: examples , linelist data frame modified select() displayed, saved. demonstration purposes. modified column names printed piping data frame names().column names linelist point cleaning pipe chain:","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"keep-columns","chapter":"1 Cleaning data and core functions","heading":"Keep columns","text":"Select columns want remainPut names select() command, quotation marks. appear data frame order provide. Note include column exist, R return error (see use any_of() want error situation).","code":"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"fever\""},{"path":"cleaning-data-and-core-functions.html","id":"clean_tidyselect","chapter":"1 Cleaning data and core functions","heading":"“tidyselect” helper functions","text":"helper functions exist make easy specify columns keep, discard, transform. package tidyselect, included tidyverse underlies columns selected dplyr functions.example, want re-order columns, everything() useful function signify “columns yet mentioned”. command moves columns date_onset date_hospitalisation beginning (left) dataset, keeps columns afterward. Note everything() written empty parentheses:“tidyselect” helper functions also work within dplyr functions like select(), across(), summarise():everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEcontains() - columns containing character string\nexample: select(contains(\"time\"))\nexample: select(contains(\"time\"))starts_with() - matches specified prefix\nexample: select(starts_with(\"date_\"))\nexample: select(starts_with(\"date_\"))ends_with() - matches specified suffix\nexample: select(ends_with(\"_post\"))\nexample: select(ends_with(\"_post\"))matches() - apply regular expression (regex)\nexample: select(matches(\"[pt]al\"))\nexample: select(matches(\"[pt]al\"))num_range() - numerical range like x01, x02, x03any_of() - matches column exists returns error found\nexample: select(any_of(date_onset, date_death, cardiac_arrest))\nexample: select(any_of(date_onset, date_death, cardiac_arrest))addition, use normal operators c() list several columns, : consecutive columns, ! opposite, & , | .Use () specify logical criteria columns. providing function inside (), include function’s empty parentheses. command selects columns class Numeric.Use contains() select columns column name contains specified character string. ends_with() starts_with() provide nuance.function matches() works similarly contains() can provided regular expression (see page [Characters strings]), multiple strings separated bars within parentheses:CAUTION: column name specifically provide exist data, can return error stop code. Consider using any_of() cite columns may may exist, especially useful negative (remove) selections.one columns exists, error produced code continues without stopping cleaning chain.","code":"\n# move date_onset and date_hospitalisation to beginning\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"              \"generation\"           \"date_infection\"       \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\n# select columns that are class Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"      \"ct_blood\"   \"temp\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"             \"fever\"\nlinelist %>% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## [1] \"date_onset\""},{"path":"cleaning-data-and-core-functions.html","id":"remove-columns","chapter":"1 Cleaning data and core functions","heading":"Remove columns","text":"Indicate columns remove placing minus symbol “-” front column name (e.g. select(-outcome)), vector column names (). columns retained.can also remove column using base R syntax, defining NULL. example:","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove date_onset and all columns from fever to vomit\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n##  [7] \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"             \"source\"              \n## [13] \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n## [19] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\nlinelist$date_onset <- NULL   # deletes column with base R syntax "},{"path":"cleaning-data-and-core-functions.html","id":"standalone","chapter":"1 Cleaning data and core functions","heading":"Standalone","text":"select() can also used independent command (pipe chain). case, first argument original dataframe operated upon.","code":"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\""},{"path":"cleaning-data-and-core-functions.html","id":"add-to-the-pipe-chain","chapter":"1 Cleaning data and core functions","heading":"Add to the pipe chain","text":"linelist_raw, columns need: row_num, merged_header, x28. remove select() command cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning-data-and-core-functions.html","id":"deduplication","chapter":"1 Cleaning data and core functions","heading":"1.6 Deduplication","text":"See handbook page [De-duplication] extensive options de-duplicate data. simple row de-duplication example presented .package dplyr offers distinct() function. function examines every row reduce data frame unique rows. , removes rows 100% duplicates.evaluating duplicate rows, takes account range columns - default considers columns. shown de-duplication page, can adjust column range uniqueness rows evaluated regards certain columns.simple example, just add empty command distinct() pipe chain. ensures rows 100% duplicates rows (evaluated across columns).begin nrow(linelist) rows linelist.de-duplication nrow(linelist) rows. removed rows 100% duplicates rows., distinct() command added cleaning pipe chain:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning-data-and-core-functions.html","id":"column-creation-and-transformation","chapter":"1 Cleaning data and core functions","heading":"1.7 Column creation and transformation","text":"recommend using dplyr function mutate() add new column, modify existing one.example creating new column mutate(). syntax : mutate(new_column_name = value transformation)Stata, similar command generate, R’s mutate() can also used modify existing column.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"new-columns","chapter":"1 Cleaning data and core functions","heading":"New columns","text":"basic mutate() command create new column might look like . creates new column new_col value every row 10.can also reference values columns, perform calculations. , new column bmi created hold Body Mass Index (BMI) case - calculated using formula BMI = kg/m^2, using column ht_cm column wt_kg.creating multiple new columns, separate comma new line. examples new columns, including ones consist values columns combined using str_glue() stringr package (see page [Characters strings].Review new columns. demonstration purposes, new columns columns used create shown:TIP: variation mutate() function transmute(). function adds new column just like mutate(), also drops/removes columns mention within parentheses.","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nnew_col_demo <- linelist %>%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) %>% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # show only new columns, for demonstration purposes\n# HIDDEN FROM READER\n# removes new demo columns created above\n# linelist <- linelist %>% \n#   select(-contains(\"new_var\"))"},{"path":"cleaning-data-and-core-functions.html","id":"convert-column-class","chapter":"1 Cleaning data and core functions","heading":"Convert column class","text":"Columns containing values dates, numbers, logical values (TRUE/FALSE) behave expected correctly classified. difference “2” class character 2 class numeric!ways set column class import commands, often cumbersome. See [R Basics] section object classes learn converting class objects columns.First, let’s run checks important columns see correct class. also saw beginning ran skim().Currently, class age column character. perform quantitative analyses, need numbers recognized numeric!class date_onset column also character! perform analyses, dates must recognized dates!resolve , use ability mutate() re-define column transformation. define column , converted different class. basic example, converting ensuring column age class Numeric:similar way, can use .character() .logical(). convert class Factor, can use factor() base R as_factor() forcats. Read [Factors] page.must careful converting class Date. Several methods explained page [Working dates]. Typically, raw date values must format conversion work correctly (e.g “MM/DD/YYYY”, “DD MM YYYY”). converting class Date, check data confirm value converted correctly.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))"},{"path":"cleaning-data-and-core-functions.html","id":"grouped-data","chapter":"1 Cleaning data and core functions","heading":"Grouped data","text":"data frame already grouped (see page [Grouping data]), mutate() may behave differently data frame grouped. summarizing functions, like mean(), median(), max(), etc. calculate group, rows.Read using mutate () grouped dataframes tidyverse mutate documentation.","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning-data-and-core-functions.html","id":"clean_across","chapter":"1 Cleaning data and core functions","heading":"Transform multiple columns","text":"Often write concise code want apply transformation multiple columns . transformation can applied multiple columns using across() function package dplyr (also contained within tidyverse package). across() can used dplyr function, commonly used within select(), mutate(), filter(), summarise(). See applied summarise() page [Descriptive tables].Specify columns argument .cols = function(s) apply .fns =. additional arguments provide .fns function can included comma, still within across().","code":""},{"path":"cleaning-data-and-core-functions.html","id":"across-column-selection","chapter":"1 Cleaning data and core functions","heading":"across() column selection","text":"Specify columns argument .cols =. can name individually, use “tidyselect” helper functions. Specify function .fns =. Note using function mode demonstrated , function written without parentheses ( ).transformation .character() applied specific columns named within across().“tidyselect” helper functions available assist specifying columns. detailed section Selecting re-ordering columns, include: everything(), last_col(), (), starts_with(), ends_with(), contains(), matches(), num_range() any_of().example one change columns character class:Convert character columns name contains string “date” (note placement commas parentheses):, example mutating columns currently class POSIXct (raw datetime class shows timestamps) - words, function .POSIXct() evaluates TRUE. want apply function .Date() columns convert normal class Date.Note within across() also use function () .POSIXct evaluating either TRUE FALSE.Note .POSIXct() package lubridate. similar “” functions like .character(), .numeric(), .logical() base R","code":"\nlinelist <- linelist %>% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = everything(), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\nlinelist <- linelist %>% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))"},{"path":"cleaning-data-and-core-functions.html","id":"across-functions","chapter":"1 Cleaning data and core functions","heading":"across() functions","text":"can read documentation ?across details provide functions across(). summary points: several ways specify function(s) perform column can even define functions:can provide function name alone (e.g. mean .character)can provide function purrr-style (e.g. ~ mean(.x, na.rm = TRUE)) (see [page][Iteration, loops, lists])can specify multiple functions providing list (e.g. list(mean = mean, n_miss = ~ sum(.na(.x))).\nprovide multiple functions, multiple transformed columns returned per input column, unique names format col_fn. can adjust new columns named .names = argument using glue syntax (see page [Characters strings]) {.col} {.fn} shorthand input column function.\nprovide multiple functions, multiple transformed columns returned per input column, unique names format col_fn. can adjust new columns named .names = argument using glue syntax (see page [Characters strings]) {.col} {.fn} shorthand input column function.online resources using across(): creator Hadley Wickham’s thoughts/rationale","code":""},{"path":"cleaning-data-and-core-functions.html","id":"coalesce","chapter":"1 Cleaning data and core functions","heading":"coalesce()","text":"dplyr function finds first non-missing value position. “fills-” missing values first available value order specify.example outside context data frame: Let us say two vectors, one containing patient’s village detection another containing patient’s village residence. can use coalesce pick first non-missing value index:works provide data frame columns: row, function assign new column value first non-missing value columns provided (order provided).example “row-wise” operation. complicated row-wise calculations, see section Row-wise calculations.","code":"\nvillage_detection <- c(\"a\", \"b\", NA,  NA)\nvillage_residence <- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage <- coalesce(village_detection, village_residence)\nvillage    # print## [1] \"a\" \"b\" \"a\" \"d\"\nlinelist <- linelist %>% \n  mutate(village = coalesce(village_detection, village_residence))"},{"path":"cleaning-data-and-core-functions.html","id":"cumulative-math","chapter":"1 Cleaning data and core functions","heading":"Cumulative math","text":"want column reflect cumulative sum/mean/min/max etc assessed rows dataframe point, use following functions:cumsum() returns cumulative sum, shown :can used dataframe making new column. example, calculate cumulative number cases per day outbreak, consider code like :first 10 rows:See page [Epidemic curves] plot cumulative incidence epicurve.See also:cumsum(), cummean(), cummin(), cummax(), cumany(), cumall()","code":"\nsum(c(2,4,15,10))     # returns only one number## [1] 31\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step## [1]  2  6 21 31\ncumulative_case_counts <- linelist %>%  # begin with case linelist\n  count(date_onset) %>%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\nhead(cumulative_case_counts, 10)##    date_onset n cumulative_cases\n## 1  2012-04-15 1                1\n## 2  2012-05-05 1                2\n## 3  2012-05-08 1                3\n## 4  2012-05-31 1                4\n## 5  2012-06-02 1                5\n## 6  2012-06-07 1                6\n## 7  2012-06-14 1                7\n## 8  2012-06-21 1                8\n## 9  2012-06-24 1                9\n## 10 2012-06-25 1               10"},{"path":"cleaning-data-and-core-functions.html","id":"using-base-r","chapter":"1 Cleaning data and core functions","heading":"Using base R","text":"define new column (re-define column) using base R, write name data frame, connected $, new column (column modified). Use assignment operator <- define new value(s). Remember using base R must specify data frame name column name every time (e.g. dataframe$column). example creating bmi column using base R:","code":"linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain","chapter":"1 Cleaning data and core functions","heading":"Add to pipe chain","text":", new column added pipe chain classes converted.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) "},{"path":"cleaning-data-and-core-functions.html","id":"re-code-values","chapter":"1 Cleaning data and core functions","heading":"1.8 Re-code values","text":"scenarios need re-code (change) values:edit one specific value (e.g. one date incorrect year format)reconcile values spelled sameto create new column categorical valuesto create new column numeric categories (e.g. age categories)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"specific-values","chapter":"1 Cleaning data and core functions","heading":"Specific values","text":"change values manually can use recode() function within mutate() function.Imagine nonsensical date data (e.g. “2014-14-15”): fix date manually raw source data, , write change cleaning pipeline via mutate() recode(). latter transparent reproducible anyone else seeking understand repeat analysis.mutate() line can read : “mutate column date_onset equal column date_onset re-coded OLD VALUE changed NEW VALUE”. Note pattern (OLD = NEW) recode() opposite R patterns (new = old). R development community working revising .another example re-coding multiple values within one column.linelist values column “hospital” must cleaned. several different spellings many missing values.recode() command re-defines column “hospital” current column “hospital”, specified recode changes. Don’t forget commas !Now see spellings hospital column corrected consolidated:TIP: number spaces equals sign matter. Make code easier read aligning = rows. Also, consider adding hashed comment row clarify future readers side OLD side NEW. TIP: Sometimes blank character value exists dataset (recognized R’s value missing - NA). can reference value two quotation marks space inbetween (\"\").","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")  # print table of all unique values, including missing  ## \n##                      Central Hopital                     Central Hospital                           Hospital A                           Hospital B \n##                                   11                                  457                                  290                                  289 \n##                     Military Hopital                    Military Hospital                     Mitylira Hopital                    Mitylira Hospital \n##                                   32                                  798                                    1                                   79 \n##                                Other                         Port Hopital                        Port Hospital St. Mark's Maternity Hospital (SMMH) \n##                                  907                                   48                                 1756                                  417 \n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \n##                                   11                                 1512\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \n##                     Central Hospital                           Hospital A                           Hospital B                    Military Hospital \n##                                  468                                  290                                  289                                  910 \n##                                Other                        Port Hospital St. Mark's Maternity Hospital (SMMH)                                 <NA> \n##                                  907                                 1804                                  428                                 1512"},{"path":"cleaning-data-and-core-functions.html","id":"by-logic","chapter":"1 Cleaning data and core functions","heading":"By logic","text":"demonstrate re-code values column using logic conditions:Using replace(), ifelse() if_else() simple logicUsing case_when() complex logic","code":""},{"path":"cleaning-data-and-core-functions.html","id":"simple-logic","chapter":"1 Cleaning data and core functions","heading":"Simple logic","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"replace","chapter":"1 Cleaning data and core functions","heading":"replace()","text":"re-code simple logical criteria, can use replace() within mutate(). replace() function base R. Use logic condition specify rows change . general syntax :mutate(col_to_change = replace(col_to_change, criteria rows, new value)).One common situation use replace() changing just one value one row, using unique row identifier. , gender changed “Female” row column case_id “2195”.equivalent command using base R syntax indexing brackets [ ] . reads “Change value dataframe linelist‘s column gender (rows linelist’s column case_id value ’2195’) ‘Female’”.","code":"\n# Example: change gender of one specific observation to \"Female\" \nlinelist <- linelist %>% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning-data-and-core-functions.html","id":"ifelse-and-if_else","chapter":"1 Cleaning data and core functions","heading":"ifelse() and if_else()","text":"Another tool simple logic ifelse() partner if_else(). However, cases re-coding clear use case_when() (detailed ). “else” commands simplified versions else programming statement. general syntax :ifelse(condition, value return condition evaluates TRUE, value return condition evaluates FALSE), column source_known defined. value given row set “known” row’s value column source missing. value source missing, value source_known set “unknown”.if_else() special version dplyr handles dates. Note ‘true’ value date, ‘false’ value must also qualify date, hence using special value NA_real_ instead just NA.Avoid stringing together many ifelse commands… use case_when() instead! case_when() much easier read ’ll make fewer errors.Outside context data frame, want object used code switch value, consider using switch() base R.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n# Create a date of death column, which is NA if patient has not died.\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"clean_case_when","chapter":"1 Cleaning data and core functions","heading":"Complex logic","text":"Use dplyr’s case_when() re-coding many new groups, need use complex logic statements re-code values. function evaluates every row data frame, assess whether rows meets specified criteria, assigns correct new value.case_when() commands consist statements Right-Hand Side (RHS) Left-Hand Side (LHS) separated “tilde” ~. logic criteria left side pursuant values right side statement. Statements separated commas.example, utilize columns age age_unit create column age_years:row data evaluated, criteria applied/evaluated order case_when() statements written - top--bottom. top criteria evaluates TRUE given row, RHS value assigned, remaining criteria even tested row. Thus, best write specific criteria first, general last.Along lines, final statement, place TRUE left-side, capture row meet previous criteria. right-side statement assigned value like “check !” missing.DANGER: Vvalues right-side must class - either numeric, character, date, logical, etc. assign missing (NA), may need use special variations NA NA_character_, NA_real_ (numeric POSIX), .Date(NA). Read [Working dates].","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # if age is given in years\n            age_unit == \"months\" ~ age/12,    # if age is given in months\n            is.na(age_unit)      ~ age,       # if age unit is missing, assume years\n            TRUE                 ~ NA_real_)) # any other circumstance, assign missing"},{"path":"cleaning-data-and-core-functions.html","id":"missing-values","chapter":"1 Cleaning data and core functions","heading":"Missing values","text":"special functions handling missing values context data cleaning.See page [Missing data] detailed tips identifying handling missing values. example, .na() function logically tests missingness.replace_na()change missing values (NA) specific value, “Missing”, use dplyr function replace_na() within mutate(). Note used manner recode - name variable must repeated within replace_na().fct_explicit_na()function forcats package. forcats package handles columns class Factor. Factors R’s way handle ordered values c(\"First\", \"Second\", \"Third\") set order values (e.g. hospitals) appear tables plots. See page [Factors].data class Factor try convert NA “Missing” using replace_na(), get error: invalid factor level, NA generated. tried add “Missing” value, defined possible level factor, rejected.easiest way solve use forcats function fct_explicit_na() converts column class factor, converts NA values character “(Missing)”.slower alternative add factor level using fct_expand() convert missing values.na_if()convert specific value NA, use dplyr’s na_if(). command performs opposite operation replace_na(). example , values “Missing” column hospital converted NA.Note: na_if() used logic criteria (e.g. “values > 99”) - use replace() case_when() :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist %>% \n  mutate(hospital = fct_explicit_na(hospital))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\nlinelist <- linelist %>% \n  mutate(date_onset = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-dictionary","chapter":"1 Cleaning data and core functions","heading":"Cleaning dictionary","text":"Use R package linelist ’s function clean_variable_spelling() clean data frame cleaning dictionary. linelist package developed RECON - R Epidemics Consortium.Create cleaning dictionary 3 columns:\n“” column (incorrect value)\n“” column (correct value)\ncolumn specifying column changes applied (“.global” apply columns)\n“” column (incorrect value)“” column (correct value)column specifying column changes applied (“.global” apply columns)Note: .global dictionary entries overridden column-specific dictionary entries.Import dictionary file R. example can downloaded via instructions [Download handbook data] page.Pass raw linelist clean_variable_spelling(), specifying wordlists = cleaning dictionary data frame. spelling_vars = argument can used specify column dictionary refers columns (3rd default), can set NULL dictionary apply character factor columns. Note function can take long time run.Now scroll right see values changed - particularly gender (lowercase uppercase), symptoms columns transformed yes/1/0.Note column names cleaning dictionary must correspond names point cleaning script. See online reference linelist package details.","code":"\ncleaning_dict <- import(\"cleaning_dict.csv\")\nlinelist <- linelist %>% \n  linelist::clean_variable_spelling(\n    wordlists = cleaning_dict,\n    spelling_vars = \"col\",        # dict column containing column names, defaults to 3rd column in dict\n  )"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-1","chapter":"1 Cleaning data and core functions","heading":"Add to pipe chain","text":", new columns column transformations added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"num_cats","chapter":"1 Cleaning data and core functions","heading":"1.9 Numeric categories","text":"describe special approaches creating categories numerical columns. Common examples include age categories, groups lab values, etc. discuss:age_categories(), epikit packagecut(), base Rcase_when()quantile breaks quantile() ntile()","code":""},{"path":"cleaning-data-and-core-functions.html","id":"review-distribution","chapter":"1 Cleaning data and core functions","heading":"Review distribution","text":"example create age_cat column using age_years column.First, examine distribution data, make appropriate cut-points. See page [ggplot basics].CAUTION: Sometimes, numeric variables import class “character”. occurs non-numeric characters values, example entry “2 months” age, (depending R locale settings) comma used decimals place (e.g. “4,5” mean four one half years)..","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.04   23.00   84.00     107"},{"path":"cleaning-data-and-core-functions.html","id":"age_categories","chapter":"1 Cleaning data and core functions","heading":"age_categories()","text":"epikit package, can use age_categories() function easily categorize label numeric columns (note: function can applied non-age numeric variables ). bonum, output column automatically ordered factor.required inputs:numeric vector (column)breakers = argument - provide numeric vector break points new groupsFirst, simplest example:break values specify default lower bounds - , included “higher” group / groups “open” lower/left side. shown , can add 1 break value achieve groups open top/right.can adjust labels displayed separator =. default “-”can adjust top numbers handled, ceiling = arguemnt. set upper cut-set ceiling = TRUE. use, highest break value provided “ceiling” category “XX+” created. values highest break value (upper =, defined) categorized NA. example ceiling = TRUE, category XX+ values 70 (highest break value) assigned NA.Alternatively, instead breakers =, can provide lower =, upper =, =:lower = lowest number want considered - default 0upper = highest number want consideredby = number years groupsSee function’s Help page details (enter ?age_categories R console).","code":"\n# Simple example\n################\npacman::p_load(epikit)                    # load package\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(             # create new column\n      age_years,                            # numeric column to make groups from\n      breakers = c(0, 5, 10, 15, 20,        # break points\n                   30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \n##  1227  1223  1048   827  1216   597   251    78    27     7   107\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \n##  1469  1195  1040   770  1149   547   231    70    24     6   107\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \n##  1227  1223  1048   827  1216   597   251    78    28   113\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  <NA> \n##  2450  1875  1216   597   251    78    27     6     1     0     0   107"},{"path":"cleaning-data-and-core-functions.html","id":"cut","chapter":"1 Cleaning data and core functions","heading":"cut()","text":"cut() base R alternative age_categories(), think see age_categories() developed simplify process. notable differences age_categories() :need install/load another packageYou can specify whether groups open/closed right/leftYou must provide accurate labels yourselfIf want 0 included lowest group must specify thisThe basic syntax within cut() first provide numeric column cut (age_years), breaks argument, numeric vector c() break points. Using cut(), resulting column ordered factor.default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). opposite behavior age_categories() function. default labels use notation “(, B]”, means included B . Reverse behavior providing right = TRUE argument.Thus, default, “0” values excluded lowest group, categorized NA! “0” values infants coded age 0 careful! change , add argument include.lowest = TRUE “0” values included lowest group. automatically-generated label lowest category “[],B]”. Note include include.lowest = TRUE argument right = TRUE, extreme inclusion now apply highest break point value category, lowest.can provide vector customized labels using labels = argument. manually written, careful ensure accurate! Check work using cross-tabulation, described .example cut() applied age_years make new variable age_cat :Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 16-20).Re-labeling NA valuesYou may want assign NA values label “Missing”. new column class Factor (restricted values), simply mutate replace_na(), value rejected. Instead, use fct_explicit_na() forcats explained [Factors] page.Quickly make breaks labelsFor fast way make breaks label vectors, use something like . See [R basics] page references seq() rep().Read cut() Help page entering ?cut R console.","code":"\n# Create new variable, by cutting the numeric age variable\n# lower break is excluded but upper break is included in each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \n##     1469     1195     1040      770     1149      778       94        6      107\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                     Categories\n## Numeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\n##   0                    136      0       0       0       0       0       0        0    0\n##   0.0833333333333333     1      0       0       0       0       0       0        0    0\n##   0.25                   2      0       0       0       0       0       0        0    0\n##   0.333333333333333      6      0       0       0       0       0       0        0    0\n##   0.416666666666667      1      0       0       0       0       0       0        0    0\n##   0.5                    6      0       0       0       0       0       0        0    0\n##   0.583333333333333      3      0       0       0       0       0       0        0    0\n##   0.666666666666667      3      0       0       0       0       0       0        0    0\n##   0.75                   3      0       0       0       0       0       0        0    0\n##   0.833333333333333      1      0       0       0       0       0       0        0    0\n##   0.916666666666667      1      0       0       0       0       0       0        0    0\n##   1                    275      0       0       0       0       0       0        0    0\n##   1.5                    2      0       0       0       0       0       0        0    0\n##   2                    308      0       0       0       0       0       0        0    0\n##   3                    246      0       0       0       0       0       0        0    0\n##   4                    233      0       0       0       0       0       0        0    0\n##   5                    242      0       0       0       0       0       0        0    0\n##   6                      0    241       0       0       0       0       0        0    0\n##   7                      0    256       0       0       0       0       0        0    0\n##   8                      0    239       0       0       0       0       0        0    0\n##   9                      0    245       0       0       0       0       0        0    0\n##   10                     0    214       0       0       0       0       0        0    0\n##   11                     0      0     220       0       0       0       0        0    0\n##   12                     0      0     224       0       0       0       0        0    0\n##   13                     0      0     191       0       0       0       0        0    0\n##   14                     0      0     199       0       0       0       0        0    0\n##   15                     0      0     206       0       0       0       0        0    0\n##   16                     0      0       0     186       0       0       0        0    0\n##   17                     0      0       0     164       0       0       0        0    0\n##   18                     0      0       0     141       0       0       0        0    0\n##   19                     0      0       0     130       0       0       0        0    0\n##   20                     0      0       0     149       0       0       0        0    0\n##   21                     0      0       0       0     158       0       0        0    0\n##   22                     0      0       0       0     149       0       0        0    0\n##   23                     0      0       0       0     125       0       0        0    0\n##   24                     0      0       0       0     144       0       0        0    0\n##   25                     0      0       0       0     107       0       0        0    0\n##   26                     0      0       0       0     100       0       0        0    0\n##   27                     0      0       0       0     117       0       0        0    0\n##   28                     0      0       0       0      85       0       0        0    0\n##   29                     0      0       0       0      82       0       0        0    0\n##   30                     0      0       0       0      82       0       0        0    0\n##   31                     0      0       0       0       0      68       0        0    0\n##   32                     0      0       0       0       0      84       0        0    0\n##   33                     0      0       0       0       0      78       0        0    0\n##   34                     0      0       0       0       0      58       0        0    0\n##   35                     0      0       0       0       0      58       0        0    0\n##   36                     0      0       0       0       0      33       0        0    0\n##   37                     0      0       0       0       0      46       0        0    0\n##   38                     0      0       0       0       0      45       0        0    0\n##   39                     0      0       0       0       0      45       0        0    0\n##   40                     0      0       0       0       0      32       0        0    0\n##   41                     0      0       0       0       0      34       0        0    0\n##   42                     0      0       0       0       0      26       0        0    0\n##   43                     0      0       0       0       0      31       0        0    0\n##   44                     0      0       0       0       0      24       0        0    0\n##   45                     0      0       0       0       0      27       0        0    0\n##   46                     0      0       0       0       0      25       0        0    0\n##   47                     0      0       0       0       0      16       0        0    0\n##   48                     0      0       0       0       0      21       0        0    0\n##   49                     0      0       0       0       0      15       0        0    0\n##   50                     0      0       0       0       0      12       0        0    0\n##   51                     0      0       0       0       0       0      13        0    0\n##   52                     0      0       0       0       0       0       7        0    0\n##   53                     0      0       0       0       0       0       4        0    0\n##   54                     0      0       0       0       0       0       6        0    0\n##   55                     0      0       0       0       0       0       9        0    0\n##   56                     0      0       0       0       0       0       7        0    0\n##   57                     0      0       0       0       0       0       9        0    0\n##   58                     0      0       0       0       0       0       6        0    0\n##   59                     0      0       0       0       0       0       5        0    0\n##   60                     0      0       0       0       0       0       4        0    0\n##   61                     0      0       0       0       0       0       2        0    0\n##   62                     0      0       0       0       0       0       1        0    0\n##   63                     0      0       0       0       0       0       5        0    0\n##   64                     0      0       0       0       0       0       1        0    0\n##   65                     0      0       0       0       0       0       5        0    0\n##   66                     0      0       0       0       0       0       3        0    0\n##   67                     0      0       0       0       0       0       2        0    0\n##   68                     0      0       0       0       0       0       1        0    0\n##   69                     0      0       0       0       0       0       3        0    0\n##   70                     0      0       0       0       0       0       1        0    0\n##   72                     0      0       0       0       0       0       0        1    0\n##   73                     0      0       0       0       0       0       0        3    0\n##   76                     0      0       0       0       0       0       0        1    0\n##   84                     0      0       0       0       0       0       0        1    0\n##   <NA>                   0      0       0       0       0       0       0        0  107\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # make missing values explicit\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n  )    \n\n# table to view counts\ntable(linelist$age_cat, useNA = \"always\")## \n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69      70-100 Missing age        <NA> \n##        1227        1223        1048         827        1216         848         105           7         107           0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)"},{"path":"cleaning-data-and-core-functions.html","id":"quantile-breaks","chapter":"1 Cleaning data and core functions","heading":"Quantile breaks","text":"common understanding, “quantiles” “percentiles” typically refer value proportion values fall. example, 95th percentile ages linelist age 95% age fall.However common speech, “quartiles” “deciles” can also refer groups data equally divided 4, 10 groups (note one break point group).get quantile break points, can use quantile() stats package base R. provide numeric vector (e.g. column dataset) vector numeric probability values ranging 0 1.0. break points returned numeric vector. Explore details statistical methodologies entering ?quantile.input numeric vector missing values best set na.rm = TRUESet names = FALSE get un-named numeric vectorYou can use results quantile() break points age_categories() cut(). create new column deciles using cut() breaks defined using quantiles() age_years. , display results using tabyl() janitor can see percentages (see [Descriptive tables] page). Note exactly 10% group.","code":"\nquantile(linelist$age_years,               # specify numeric vector to work on\n  probs = c(0, .25, .50, .75, .90, .95),   # specify the percentiles you want\n  na.rm = TRUE)                            # ignore missing values ##  0% 25% 50% 75% 90% 95% \n##   0   6  13  23  33  41\nlinelist %>%                                # begin with linelist\n  mutate(deciles = cut(age_years,           # create new column decile as cut() on column age_years\n    breaks = quantile(                      # define cut breaks using quantile()\n      age_years,                               # operate on age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 to 1.0 by 0.1\n      na.rm = TRUE),                           # ignore missing values\n    include.lowest = TRUE)) %>%             # for cut() include age 0\n  janitor::tabyl(deciles)                   # pipe to table to display##  deciles   n    percent valid_percent\n##    [0,2] 748 0.11319613    0.11505922\n##    (2,5] 721 0.10911017    0.11090601\n##    (5,7] 497 0.07521186    0.07644978\n##   (7,10] 698 0.10562954    0.10736810\n##  (10,13] 635 0.09609564    0.09767728\n##  (13,17] 755 0.11425545    0.11613598\n##  (17,21] 578 0.08746973    0.08890940\n##  (21,26] 625 0.09458232    0.09613906\n##  (26,33] 596 0.09019370    0.09167820\n##  (33,84] 648 0.09806295    0.09967697\n##     <NA> 107 0.01619249            NA"},{"path":"cleaning-data-and-core-functions.html","id":"evenly-sized-groups","chapter":"1 Cleaning data and core functions","heading":"Evenly-sized groups","text":"Another tool make numeric groups dplyr function ntile(), attempts break data n evenly-sized groups - aware unlike quantile() value appear one group. Provide numeric vector number groups. values new column created just group “numbers” (e.g. 1 10), range values using cut().","code":"\n# make groups with ntile()\nntile_data <- linelist %>% \n  mutate(even_groups = ntile(age_years, 10))\n\n# make table of counts and proportions by group\nntile_table <- ntile_data %>% \n  janitor::tabyl(even_groups)\n  \n# attach min/max values to demonstrate ranges\nntile_ranges <- ntile_data %>% \n  group_by(even_groups) %>% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )## Warning in min(age_years, na.rm = T): no non-missing arguments to min; returning Inf## Warning in max(age_years, na.rm = T): no non-missing arguments to max; returning -Inf\n# combine and print - note that values are present in multiple groups\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")##  even_groups   n    percent valid_percent min  max\n##            1 651 0.09851695    0.10013844   0    2\n##            2 650 0.09836562    0.09998462   2    5\n##            3 650 0.09836562    0.09998462   5    7\n##            4 650 0.09836562    0.09998462   7   10\n##            5 650 0.09836562    0.09998462  10   13\n##            6 650 0.09836562    0.09998462  13   17\n##            7 650 0.09836562    0.09998462  17   21\n##            8 650 0.09836562    0.09998462  21   26\n##            9 650 0.09836562    0.09998462  26   33\n##           10 650 0.09836562    0.09998462  33   84\n##           NA 107 0.01619249            NA Inf -Inf"},{"path":"cleaning-data-and-core-functions.html","id":"case_when","chapter":"1 Cleaning data and core functions","heading":"case_when()","text":"possible use dplyr function case_when() create categories numeric column, easier use age_categories() epikit cut() create ordered factor automatically.using case_when(), please review proper use described earlier Re-code values section page. Also aware right-hand side values must class. Thus, want NA right-side either write “Missing” use special NA value NA_character_.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-2","chapter":"1 Cleaning data and core functions","heading":"Add to pipe chain","text":", code create two categorical age columns added cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning-data-and-core-functions.html","id":"add-rows","chapter":"1 Cleaning data and core functions","heading":"1.10 Add rows","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"one-by-one","chapter":"1 Cleaning data and core functions","heading":"One-by-one","text":"Adding rows one--one manually tedious can done add_row() dplyr. Remember column must contain values one class (either character, numeric, logical, etc.). adding row requires nuance maintain .Use ... specify placement row want add. .= 3 put new row current 3rd row. default behavior add row end. Columns specified left empty (NA).new row number may look strange (“…23”) row numbers pre-existing rows changed. using command twice, examine/test insertion carefully.class provide see error like :(inserting row date value, remember wrap date function .Date() like .Date(\"2020-10-10\")).","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)Error: Can't combine ..1$infection date <date> and ..2$infection date <character>."},{"path":"cleaning-data-and-core-functions.html","id":"bind-rows","chapter":"1 Cleaning data and core functions","heading":"Bind rows","text":"combine datasets together binding rows one dataframe bottom another data frame, can use bind_rows() dplyr. explained detail page [Joining data].","code":""},{"path":"cleaning-data-and-core-functions.html","id":"filter-rows","chapter":"1 Cleaning data and core functions","heading":"1.11 Filter rows","text":"typical cleaning step cleaned columns re-coded values filter data frame specific rows using dplyr verb filter().Within filter(), specify logic must TRUE row dataset kept. show filter rows based simple complex logical conditions.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"simple-filter","chapter":"1 Cleaning data and core functions","heading":"Simple filter","text":"simple example re-defines dataframe linelist , filtered rows meet logical condition. rows logical statement within parentheses evaluates TRUE kept.example, logical statement gender == \"f\", asking whether value column gender equal “f” (case sensitive).filter applied, number rows linelist nrow(linelist).filter applied, number rows linelist linelist %>% filter(gender == \"f\") %>% nrow().","code":"\nlinelist <- linelist %>% \n  filter(gender == \"f\")   # keep only rows where gender is equal to \"f\""},{"path":"cleaning-data-and-core-functions.html","id":"filter-out-missing-values","chapter":"1 Cleaning data and core functions","heading":"Filter out missing values","text":"fairly common want filter rows missing values. Resist urge write filter(!.na(column) & !.na(column)) instead use tidyr function custom-built purpose: drop_na(). run empty parentheses, removes rows missing values. Alternatively, can provide names specific columns evaluated missingness, use “tidyselect” helper functions described .See page [Missing data] many techniques analyse manage missingness data.","code":"\nlinelist %>% \n  drop_na(case_id, age_years)  # drop rows with missing values for case_id or age_years"},{"path":"cleaning-data-and-core-functions.html","id":"filter-by-row-number","chapter":"1 Cleaning data and core functions","heading":"Filter by row number","text":"data frame tibble, row usually “row number” (seen R Viewer) appears left first column. true column data, can used filter() statement.filter based “row number”, can use dplyr function row_number() open parentheses part logical filtering statement. Often use %% operator range numbers part logical statement, shown . see first N rows, can also use special dplyr function head().can also convert row numbers true column piping data frame tibble function rownames_to_column() (put anything parentheses).","code":"\n# View first 100 rows\nlinelist %>% head(100)     # or use tail() to see the n last rows\n\n# Show row 5 only\nlinelist %>% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)"},{"path":"cleaning-data-and-core-functions.html","id":"complex-filter","chapter":"1 Cleaning data and core functions","heading":"Complex filter","text":"complex logical statements can constructed using parentheses ( ), |, negate !, %%, & operators. example :Note: can use ! operator front logical criteria negate . example, !.na(column) evaluates true column value missing. Likewise !column %% c(\"\", \"b\", \"c\") evaluates true column value vector.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"examine-the-data","chapter":"1 Cleaning data and core functions","heading":"Examine the data","text":"simple one-line command create histogram onset dates. See second smaller outbreak 2012-2013 also included raw dataset. analyses, want remove entries earlier outbreak.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning-data-and-core-functions.html","id":"how-filters-handle-missing-numeric-and-date-values","chapter":"1 Cleaning data and core functions","heading":"How filters handle missing numeric and date values","text":"Can just filter date_onset rows June 2013? Caution! Applying code filter(date_onset > .Date(\"2013-06-01\"))) remove rows later epidemic missing date onset!DANGER: Filtering greater (>) less (<) date number can remove rows missing values (NA)! NA treated infinitely large small.(See page [Working dates] information working dates package lubridate)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"design-the-filter","chapter":"1 Cleaning data and core functions","heading":"Design the filter","text":"Examine cross-tabulation make sure exclude correct rows:criteria can filter remove first outbreak (2012 & 2013) dataset? see :first epidemic 2012 & 2013 occurred Hospital , Hospital B, also 10 cases Port Hospital.Hospitals & B cases second epidemic, Port Hospital .want exclude:nrow(linelist %>% filter(hospital %% c(\"Hospital \", \"Hospital B\") | date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013 either hospital , B, Port:\nExclude nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013\nExclude nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows Hospitals & B missing onset dates\nexclude nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows missing onset dates.\nExclude nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013Exclude nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows Hospitals & B missing onset datesDo exclude nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows missing onset dates.start linelist nrow(linelist)`. filter statement:re-make cross-tabulation, see Hospitals & B removed completely, 10 Port Hospital cases 2012 & 2013 removed, values - just wanted.Multiple statements can included within one filter command (separated commas), can always pipe separate filter() command clarity.Note: readers may notice easier just filter date_hospitalisation 100% complete missing values. true. date_onset used purposes demonstrating complex filter.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2012 2013 2014 2015 <NA>\n##   Central Hospital                        0    0  351   99   18\n##   Hospital A                            229   46    0    0   15\n##   Hospital B                            227   47    0    0   15\n##   Military Hospital                       0    0  676  200   34\n##   Missing                                 0    0 1117  318   77\n##   Other                                   0    0  684  177   46\n##   Port Hospital                           9    1 1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 6019\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2014 2015 <NA>\n##   Central Hospital                      351   99   18\n##   Military Hospital                     676  200   34\n##   Missing                              1117  318   77\n##   Other                                 684  177   46\n##   Port Hospital                        1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)  322   93   13\n##   <NA>                                    0    0    0"},{"path":"cleaning-data-and-core-functions.html","id":"standalone-1","chapter":"1 Cleaning data and core functions","heading":"Standalone","text":"Filtering can also done stand-alone command (part pipe chain). Like dplyr verbs, case first argument must dataset .can also use base R subset using square brackets reflect [rows, columns] want retain.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning-data-and-core-functions.html","id":"quickly-review-records","chapter":"1 Cleaning data and core functions","heading":"Quickly review records","text":"Often want quickly review records, columns. base R function View() print data frame viewing RStudio.View linelist RStudio:two examples viewing specific cells (specific rows, specific columns):dplyr functions filter() select():Within View(), pipe dataset filter() keep certain rows, select() keep certain columns. example, review onset hospitalization dates 3 specific cases:can achieve base R syntax, using brackets [ ] subset want see.","code":"\nView(linelist)\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-3","chapter":"1 Cleaning data and core functions","heading":"Add to pipe chain","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning-data-and-core-functions.html","id":"row-wise-calculations","chapter":"1 Cleaning data and core functions","heading":"1.12 Row-wise calculations","text":"want perform calculation within row, can use rowwise() dplyr. See online vignette row-wise calculations.\nexample, code applies rowwise() creates new column sums number specified symptom columns value “yes”, row linelist. columns specified within sum() name within vector c(). rowwise() essentially special kind group_by(), best use ungroup() done (page [Grouping data]).specify column evaluate, may want use “tidyselect” helper functions described select() section page. just make one adjustment (using within dplyr function like select() summarise()).Put column-specification criteria within dplyr function c_across(). c_across (documentation) designed work rowwise() specifically. example, following code:Applies rowwise() following operation (sum()) applied within row (summing entire columns)Creates new column num_NA_dates, defined row number columns (name containing “date”) .na() evaluated TRUE (missing data).ungroup() remove effects rowwise() subsequent stepsYou also provide functions, max() get latest recent date row:","code":"\nlinelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %>% \n  ungroup() %>% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display## # A tibble: 5,888 x 6\n##    fever chills cough aches vomit num_symptoms\n##    <chr> <chr>  <chr> <chr> <chr>        <int>\n##  1 no    no     yes   no    yes              2\n##  2 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  3 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  4 no    no     no    no    no               0\n##  5 no    no     yes   no    yes              2\n##  6 no    no     yes   no    yes              2\n##  7 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  8 no    no     yes   no    yes              2\n##  9 no    no     yes   no    yes              2\n## 10 no    no     yes   no    no               1\n## # ... with 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %>% \n  ungroup() %>% \n  select(num_NA_dates, contains(\"date\")) # for display## # A tibble: 5,888 x 5\n##    num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n##           <int> <date>         <date>     <date>               <date>      \n##  1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n##  2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n##  3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n##  4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n##  5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n## 10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n## # ... with 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %>% \n  ungroup() %>% \n  select(latest_date, contains(\"date\"))  # for display## # A tibble: 5,888 x 5\n##    latest_date date_infection date_onset date_hospitalisation date_outcome\n##    <date>      <date>         <date>     <date>               <date>      \n##  1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n##  2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n##  3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n##  4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n##  5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n## 10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n## # ... with 5,878 more rows"},{"path":"cleaning-data-and-core-functions.html","id":"arrange-and-sort","chapter":"1 Cleaning data and core functions","heading":"1.13 Arrange and sort","text":"Use dplyr function arrange() sort order rows column values.Simple list columns order sorted . Specify .by_group = TRUE want sorting first occur groupings applied data (see page [Grouping data]).default, column sorted “ascending” order (applies numeric also character columns). can sort variable “descending” order wrapping desc().Sorting data arrange() particularly useful making [Tables presentation], using slice() take “top” rows per group, setting factor level order order appearance.example, sort linelist rows hospital, date_onset descending order, use:","code":"\nlinelist %>% \n   arrange(hospital, desc(date_onset))"}]
