[
  {
    "objectID": "index.jp.html",
    "href": "index.jp.html",
    "title": "疫学のための R ハンドブック",
    "section": "",
    "text": "いらっしゃいませ",
    "crumbs": [
      "いらっしゃいませ"
    ]
  },
  {
    "objectID": "index.jp.html#疫学や公衆衛生に関わる業務のための-r",
    "href": "index.jp.html#疫学や公衆衛生に関わる業務のための-r",
    "title": "疫学のための R ハンドブック",
    "section": "疫学や公衆衛生に関わる業務のための R",
    "text": "疫学や公衆衛生に関わる業務のための R\n利用実績: 本ハンドブックは、世界中 45 万人に 100 万回以上 利用されています。\n目的: 疫学業務や研究で頻繁に直面する課題に対する対処法の実例を扱い、素早く使用できる R のリファレンスマニュアルとしてオンラインでもオフラインでも機能する\nR を始めたばかりですか？ アメリカ CDC、WHO、その他 75 以上の保健機関および世界中のフィールドエピトレーニングプログラムで使用されている 無料の自己学習型チュートリアル または、、ライブリモート型の intro course を試してください\n本書は他の言語でも利用できます: 英語 (English), ベトナム語 (Tiếng Việt), フランス語 (Français), スペイン語 (Español), 日本語, トルコ語 (Türkçe), ポルトガル語 (Português), ロシア (Русский)\n\n\n\n\n\n\n\n 疫学者や疫学実務者によって書かれた、疫学者や疫学実務者のためのハンドブック\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\nApplied Epi は、世界中の第一線で活躍する疫学者や疫学実務者による非営利団体であり、草の根運動です。私たちは、自分たちのもつリソースをコミュニティに提供するために、空き時間を使って執筆しています。皆様の励ましやご意見をお待ちしております。\n\n公式ウェブサイト（英語）は こちら\nメーリングリスト（英語）への登録は こちら\n\nメールでのお問い合わせ先（英語）： contact@appliedepi.org\nツイッター： @epiRhandbook（英語） @epiRhandbook_jp（日本語）\nLinkedIn（英語）は こちら\nGithub でのイシュー（Issue）の作成は、こちら （英語・日本語どちらでも可）\n\nまた、数十年にわたる疫学や疫学実務の経験を持つ講師によるリアルタイムの R トレーニングも提供しています（現在は英語のみ）。ご興味のある方は、メールでご相談ください。",
    "crumbs": [
      "いらっしゃいませ"
    ]
  },
  {
    "objectID": "index.jp.html#本書の使い方",
    "href": "index.jp.html#本書の使い方",
    "title": "疫学のための R ハンドブック",
    "section": "本書の使い方",
    "text": "本書の使い方\n\n左側にある目次を参照する、又は検索ボックスを使用します。\n\n各章にあるコードをコピーしたい場合は、「コピー（copy）」アイコンをクリックしてください。\n\n例題で使用されている サンプルデータ を使用すると、本書の内容をお手元の環境で実践しながら学ぶことができます。\n\nオフライン版の使い方\nハンドブックとデータのダウンロード の章をご覧ください。",
    "crumbs": [
      "いらっしゃいませ"
    ]
  },
  {
    "objectID": "index.jp.html#謝辞および注意事項",
    "href": "index.jp.html#謝辞および注意事項",
    "title": "疫学のための R ハンドブック",
    "section": "謝辞および注意事項",
    "text": "謝辞および注意事項\nこのハンドブックは、世界各地の疫学者や疫学実務者の協力により、地方、州、県、国の各保健機関、世界保健機関（World Health Organization; WHO）、国境なき医師団（MSF）、病院や学術機関などでの経験をもとに作成されています。\n本ハンドブックは、特定の団体から公認を得たものではありません。正確性を期していますが、本書の内容を保証するものではありません。\n\n作成者\n編集者: Neale Batra\n著者: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin\n査読者および支援者: Pat Keating, Amrish Baidjoe, Annick Lenglet, Margot Charette, Danielly Xavier, Marie-Amélie Degail Chabrat, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga\n日本語版翻訳者: 苅谷 瞳, 西田 典充, 齋藤 雄介, 馬場 美彦, 麸沢 美裕, 髙 勇羅, 藤井 亮輔, 浅野 裕太, 小山 佑奈, 山浦 礼子, 谷 拓朗, 川添 百合香, 中村 星斗, 西川 寛来, 長島 健悟, 茅野 大志, 伏見 淳, 平 友樹, 佐藤 俊太朗, 山口 征啓, 中根 優里, 堺 琴美, 石原 裕也\n図版制作者: Calder Fong\n\n\n\n\n\n\n資金支援\nこのハンドブックは、主にボランティアによってのべ数千時間をかけて作られました\nこのハンドブックは、実地疫学研修プログラム（Field Epidemiology Training Programs; FETPs）の世界的ネットワークである TEPHINET より、新型コロナウイルス感染症のための緊急助成金（COVID-19 emergency capacity-building grant）による支援を受けました。\n運営面では、EPIET 同窓生の会（EPIET Alumni Network; EAN）、とりわけ Annika Wendland から多大なる支援を受け、ここに謝意を示します。EPIET とは、介入疫学トレーニングのための欧州プログラム（European Programme for Intervention Epidemiology Training）の略称です。\n本ハンドブックの作成にあたり、国境なき医師団（MSF）アムステルダム運営センター（Operational Centre Amsterdam; OCA）からもご支援いただき、ここに謝意を表します。\n本書は、国際保健タスクフォース（The Task Force for Global Health）のプログラムである TEPHINET を通じて、米国疾病対策センター（Centers for Disease Control and Prevention; CDC）から資金提供を受けた協力契約番号 NU2GGH001873 により作成されました。本書の内容は著者の責任によるものであり、CDC、米国保健福祉省（Department of Health and Human Services）、The Task Force for Global Health, Inc.またはTEPHINET の公式見解を必ずしも示すものではありません。\n\n\nインスピレーション\n本書の内容を作成・開発するための知識の元になった多くのチュートリアルやドキュメントは、各章のページでクレジットされています。\n以下の資料が本書に多大なインスピレーションを与えてくれた主な参考資料は、以下の通りです。\nThe “R4Epis” project (MSF と RECON による共同プロジェクト)\nR Epidemics Consortium (RECON)\nR for Data Science book (R4DS)\nbookdown: Authoring Books and Technical Documents with R Markdown\nNetlify によってこのウェブサイトはホストされています。",
    "crumbs": [
      "いらっしゃいませ"
    ]
  },
  {
    "objectID": "index.jp.html#利用規約投稿規約",
    "href": "index.jp.html#利用規約投稿規約",
    "title": "疫学のための R ハンドブック",
    "section": "利用規約・投稿規約",
    "text": "利用規約・投稿規約\n\nライセンス\n Applied Epi Incorporated, 2021 本書は、 クリエイティブ・コモンズ 表示 - 非商用 - 継承 4.0 国際ライセンス（Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License）に基づき、Applied Epi Incorporated によってライセンスされています。\n授業や疫学者養成研修プログラムの提供者は、本ハンドブックの使用や翻案について、お気軽にお問い合わせください。(email contact@appliedepi.org).\n\n\n引用形式\nBatra, Neale, et al. The Epidemiologist R Handbook. 2021. \n\n\nコントリビューション\n本書の内容に貢献したい方は、まず Github のイシュー（Issues） またはメールにてご連絡ください。現在、本書の更新スケジュールやコントリビューターガイドを作成中です。\nなお、本プロジェクトは、コントリビューター行動規約（Contributor Code of Conduct）と共に公開されていることにご注意ください。本プロジェクトに貢献すると、その規約に従うことに同意したことになります。",
    "crumbs": [
      "いらっしゃいませ"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.jp.html",
    "href": "new_pages/editorial_style.jp.html",
    "title": "1  編集前記・技術注記",
    "section": "",
    "text": "1.1 アプローチとスタイル\n本書の潜在的な読者層は広いと考えています。R を初めて使う人はもちろん、より良い R の使い方やそのヒントを探している経験豊富な R ユーザーにもきっと役立ててもらえるはずです。そのため、本書は理解しやすく、簡潔である必要があり、R に慣れていない人でもコードを適用し、コードが何をしているのかをたどることができるよう、十分な説明を行うことを心がけました。\nその他のポイント",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>編集前記・技術注記</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.jp.html#アプローチとスタイル",
    "href": "new_pages/editorial_style.jp.html#アプローチとスタイル",
    "title": "1  編集前記・技術注記",
    "section": "",
    "text": "本書は、比較的簡単な事例を用いたコードの参考書であり、R やデータサイエンスの完全な教科書ではありません。\n本書は、応用疫学で R を使用するためのハンドブックであり、応用疫学の手法や科学に関するマニュアルではありません。\nそれぞれのタスクに最適な R のパッケージは頻繁に変わるため、このハンドブックでどのパッケージの使用を重視するかに関する議論を歓迎します。\n\n\nR パッケージ\n多くの選択肢\nR の学習で最も難しいことの 1 つは、特定のタスクに対してどの R パッケージを使うべきかを把握することです。あるタスクで悪戦苦闘しているうちに、「あれ、1 つのコマンドで全部やってくれる R パッケージがあるじゃないか！」と気づくことはよくあります。\nこのハンドブックでは、各タスクを完了するために少なくとも 2 つの方法を用いるようにしています。1 つは試行錯誤を重ねた方法（おそらくbase R か tidyverse パッケージ）、もう 1 つはその目的のためにカスタマイズされた特別な R パッケージを使用する方法です。パッケージがダウンロードできない、あるいはうまく動作しない場合に備えて、いくつかの選択肢を用意しておきたいと思います。\n使用するパッケージの選択にあたっては、一般的な利用者によってテストされ吟味されたもの、典型的な作業内で使用するパッケージの数が最小であるもの、安定しているもの（あまり頻繁に変更されない）、そしてシンプルかつ簡単にタスクを達成するパッケージと手法を優先的に選びました。\nこのハンドブックでは、一般的に tidyverse の R パッケージや関数を優先的に紹介します。tidyverse はデータサイエンスのために設計された複数の R パッケージを集めたものであり、含まれているパッケージは、基礎となる文法やデータ構造を共有しています。すべての tidyverse パッケージは、tidyverse パッケージを介してインストールまたは読み込むことが可能です。詳しくは tidyverse のウェブサイトをご覧ください。\nまた、本書の読者の中には、追加のパッケージをダウンロードするための信頼できるインターネット環境を利用できない方がいることを想定し、必要に応じて base R（R をインストールしたときに付属しているパッケージや関数）を用いた手法も紹介しています。\n関数とパッケージの明示的な関連付け\nR のチュートリアルで関数がコードで表示されても、それがどのパッケージのものかわからないとイライラすることがよくありますね！ 私たちはこのような状況を避けようとしています。\n本書では、説明する際にパッケージ名は太字で書き（例：dplyr）、関数は次のように書いています： mutate() 。また、関数がどのパッケージから来たものかを明示するために、文章内でパッケージを参照するか、dplyr::mutate() のようにコード内でパッケージを明示するようにしています。冗長に見えるかもしれませんが、あえてそのように書いています。\nパッケージや関数について詳しく知りたい方は、Rの基礎 の章をご覧ください。\n\n\nコードのスタイル\nこのハンドブックでは、以下の理由に基づき、頻繁に「改行」をいれて、コードを「縦長」に表示しています。\n\nコードの細かい点について、コードのすぐ隣で # を使って説明コメントを書くことができる\n一般的に、長い（縦長の）コードの方が読みやすい\n狭い画面でも読みやすい（横スクロールが必要ない）\nインデントにより、どの引数がどの関数に属しているかがわかりやすい\n\n以下に例を挙げます。\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;%  # 病院ごとのグループの列\n  slice_max(date, n = 1, with_ties = F) # 日付が同じ場合は最初の行を採用する\n\n本書のスタイルに従うと、上のコードは、次のように書きます。\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% # 病院ごとのグループの列\n  slice_max(\n    date,                # グループごとに日付の最大値を持つ行を保持する \n    n = 1,               # 最も上段の 1 列を保持する \n    with_ties = F)       # 日付が同じ場合は最初の行を採用する\n\nR コードは通常、改行やインデントの影響を受けません。コードを書く際は、カンマの後で改行すると、自動的なインデントが適用されます。\nまた、スペースをたくさん使っている理由は、その方が読みやすいからです（例えば、n=1 ではなく n = 1 ）。読み手に親切なコードを書きましょう！\n\n\n用語解説\nこのハンドブックでは、一般的に「変数（variables）」や「観測値（observations）」ではなく「列（columns）」や「行（rows）」といった用語を使用します。この 「tidy data（データの前処理）」 の入門書で説明されているように、ほとんどの疫学統計データセットは、行（rows）、列（columns）、値（values）の構造で構成されています。\n変数には、同じ基本属性（年齢層、転帰、発症日など）を測定した値が含まれます。観測値には、同じ単位（人、部位、実験試料など）で測定されたすべての値が含まれます。したがって、列や行と比較して、これらを具体的に定義することは困難であるでしょう。\n「整理された」データセットでは、各列が変数、各行が観測値、各セルが 1 つの値です。しかし、あなたが扱うデータセットの中には、この型に当てはまらないものもあります。例えば、「横長」形式のデータセットでは、変数が複数の列にまたがっていることがあります（データの縦横変換 の章で例をご覧ください）。同様に、観測値も複数の行にまたがって分割されていることもあります。\nこのハンドブックの大部分は、データの管理と変換に関するものなので、抽象的な観測値や変数よりも、行や列といったより具体的なデータ構造に言及する方が適切です。例外は主にデータ解析の章で生じ、そこでは変数や観測値への言及が多くなります。\n\n\n注釈\nここでは、このハンドブックで書かれている注釈の種類を紹介します。\n注釈：これは注釈です\nヒント：これはヒントです\n注意：これは注意事項です\n警告：これは警告です",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>編集前記・技術注記</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.jp.html#編集上の決定事項",
    "href": "new_pages/editorial_style.jp.html#編集上の決定事項",
    "title": "1  編集前記・技術注記",
    "section": "1.2 編集上の決定事項",
    "text": "1.2 編集上の決定事項\n以下では、パッケージや関数の選択に関して、編集上の重要な決定事項を記載しています。これらについて異なる意見がある場合や、新しいツールをご提供いただける場合は、こちらの Github ページに参加しメッセージをお送りください。\nパッケージ、関数、その他の編集上の決定事項の表\n\n\n\n\n\n\n\n\n\n項目\n候補パッケージ・関数\n推奨パッケージ・関数\n簡単な説明\n\n\n\n\n一般的なコーディング方法\ntidyverse, data.table, base\ntidyverse、data.table 関連の章で使用される。インターネットを持たない読者のための代替方法としては base を推奨\ntidyverse 読みやすいコードや一般性の高いコードの作成のために使用される（一番教えられているパッケージ\n\n\nパッケージの読み込み\nlibrary(),install.packages(), require(), pacman\npacman\nほとんどのパッケージのインストールと読み込みにおいて、コードの短縮と簡素化を実現する\n\n\nインポートとエクスポート\nrio, 他にも多数存在\nrio\n多くのファイルタイプに対応する手軽さ\n\n\n要約統計のためのグループ化\ndplyr group_by(), stats aggregate()\ndplyr group_by()\ntidyverse と同様に重要\n\n\n縦横変換\ntidyr (pivot 系関数), reshape2 (melt/cast), tidyr (spread/gather)\ntidyr (pivot 系関数)\nreshape2 は廃止され、tidyr は 1.0.0 版から pivot 系関数を使用\n\n\n列名のクリーニング\nlinelist, janitor\njanitor\nパッケージの集約を重視\n\n\n時間データの取り扱い\nlubridate, aweek, tsibble, zoo\nlubridate 一般的なものと、特定のケースに対応するものとがある\nlubridate の柔軟性、一貫性、パッケージ維持の見通し\n\n\nggplot ラベル\nlabs(), ggtitle()/ylab()/xlab()\nlabs()\nすべてのラベルを一箇所でシンプルに修正\n\n\n因子型への変換\nfactor(), forcats\nforcats\nさまざまな関数も同じコマンドで因子に変換\n\n\n流行曲線（エピカーブ）\nincidence, ggplot2, EpiCurve\nincidence2 を素早く、ggplot2 を詳細に\n信頼性\n\n\n結合処理\npaste(), paste0(), str_glue(), glue()\nstr_glue()\nstringr 内にあり paste 関数よりもシンプルな構文",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>編集前記・技術注記</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.jp.html#主な修正履歴",
    "href": "new_pages/editorial_style.jp.html#主な修正履歴",
    "title": "1  編集前記・技術注記",
    "section": "1.3 主な修正履歴",
    "text": "1.3 主な修正履歴\n\n\n\n日付\n主な変更点\n\n\n\n\n2021 年 5 月 10 日\n1.0.0 版の公開\n\n\n2022 年11 月 20 日\n1.0.1 版の公開\n\n\n\n更新情報 1.0.1 版は以下の変更が適用されています。\n\nR のバージョンを 4.2 に更新しました\nデータクリーニングと主要関数 : {linelist} パッケージから {matchmaker} パッケージへの変更、case_when() の例示コードから不溶な行を削除\n日付型データ : {linelist} パッケージの関数 guess_date() から {parsedate} パッケージの関数 parse_date() への変更\nデータの縦横変換 : pivot_wider() の id_cols= 引数の小変更\n標本調査データ分析 : plot_age_pyramid() から age_pyramid() への変更、サンキー図（沖積図）をプロットするコードの小変更\nヒートマップ : agg_weeks オブジェクト生成コードに ungroup() を追加\n動的な図の作成 : agg_weeks オブジェクト作成時に tidyr::expand() が意図通りに機能するために ungroup() を追加\n時系列分析とアウトブレイクの検出 : すべての trending::fit() と predict() 内のオブジェクトに対して data.frame() を追加\n複数回答データの分析 : case_when() から ifelse() への変更、データオブジェクト作成時に across() 引数を追加\n感染連鎖 : より新しいバージョンの {epicontacts} パッケージを利用するように変更",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>編集前記・技術注記</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.jp.html#バージョン情報-rrstudioパッケージ",
    "href": "new_pages/editorial_style.jp.html#バージョン情報-rrstudioパッケージ",
    "title": "1  編集前記・技術注記",
    "section": "1.4 バージョン情報 (R・RStudio・パッケージ)",
    "text": "1.4 バージョン情報 (R・RStudio・パッケージ)\nこのハンドブックで使用した R、RStudio、R パッケージのバージョンに関する情報を以下に示します。\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31 ucrt)\n os       Windows 11 x64 (build 22621)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       Europe/Stockholm\n date     2024-05-08\n pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.2   2023-12-11 [2] CRAN (R 4.3.2)\n digest        0.6.35  2024-03-11 [1] CRAN (R 4.3.3)\n evaluate      0.23    2023-11-01 [2] CRAN (R 4.3.2)\n fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.3.2)\n htmltools     0.5.8   2024-03-25 [1] CRAN (R 4.3.3)\n htmlwidgets   1.6.4   2023-12-06 [2] CRAN (R 4.3.2)\n jsonlite      1.8.8   2023-12-04 [2] CRAN (R 4.3.2)\n knitr         1.45    2023-10-30 [2] CRAN (R 4.3.2)\n rlang         1.1.3   2024-01-10 [2] CRAN (R 4.3.2)\n rmarkdown     2.26    2024-03-05 [1] CRAN (R 4.3.3)\n rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.3.2)\n sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.3.2)\n xfun          0.43    2024-03-25 [1] CRAN (R 4.3.3)\n\n [1] C:/Users/ngulu864/AppData/Local/R/win-library/4.3\n [2] C:/Program Files/R/R-4.3.2/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>編集前記・技術注記</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.jp.html",
    "href": "new_pages/data_used.jp.html",
    "title": "2  ハンドブックとデータのダウンロード",
    "section": "",
    "text": "2.1 オフライン版のダウンロード\nこのハンドブックのオフライン版を HTML ファイルとしてダウンロードすることで、インターネットに接続できない場合でも、Web ブラウザでファイルを閲覧することができます。オフラインでの利用を検討されている方は、以下の点にご注意ください。\nハンドブックをダウンロードする方法は2つあります。",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ハンドブックとデータのダウンロード</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.jp.html#オフライン版のダウンロード",
    "href": "new_pages/data_used.jp.html#オフライン版のダウンロード",
    "title": "2  ハンドブックとデータのダウンロード",
    "section": "",
    "text": "ファイルを開いた際、画像と目次の読み込みに 1 ～ 2 分かかる場合があります。\nオフラインのハンドブックは、1 ページが非常に長く、左側に目次があるなど、レイアウトが少し異なります。特定の用語を検索する際は、Ctrl + f （Cmd - f） を使用してください。\nインターネットに接続できなくなる前に、適切な R パッケージをインストールするため、推奨するパッケージ の章をご参照ください。\nすべてのサンプルデータを含む R パッケージ epirhandbook をインストールしてください（インストール方法は以下の通りです）。\n\n\n\nダウンロードリンクの利用\nこちらの リンク を右クリックし、「リンク先を別名で保存（Save link as）」を選択すると、素早くダウンロードすることができます。\nMac をお使いの場合は、Cmd を押しながらクリックしてください。モバイルの場合は、リンクを長押しし、「リンクを保存（Save link）」を選択すると、ハンドブックがお使いの端末にダウンロードされます。HTML コードが表示された場合は、上記の手順が正しく行われているか確認する、または次の方法をお試しください。\n\n\nR パッケージの利用\nEpirhandbook という R パッケージがあります。このパッケージには、Github リポジトリからハンドブックファイルをあなたのパソコンにダウンロードするための関数 download_book() が含まれています。\nまた、このパッケージには、すべてのサンプルデータをダウンロードするための関数 get_data() も含まれています。\n次のコードを実行し、Github repository appliedepi から R パッケージ epirhandbook パッケージをインストールします。このパッケージは CRAN にないので、Github からインストールする場合は特別な関数 p_install_gh() を使ってください。\n\n# 最新版の Epi R Handbook パッケージをインストールする\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nここで、今開いている R セッションで（これらのデータを）使用するために、パッケージを読み込みます。\n\n# 使用するパッケージを読み込む\npacman::p_load(epirhandbook)\n\n次に、epirhandbook パッケージに含まれている関数 download_book() （括弧内は空白）を実行して、ハンドブックをパソコンにダウンロードします。RStudio を使用している場合、保存場所を選択するウィンドウが表示されます。\n\n# オフラインハンドブックをパソコンにダウンロードする\ndownload_book()",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ハンドブックとデータのダウンロード</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.jp.html#サンプルデータのダウンロード",
    "href": "new_pages/data_used.jp.html#サンプルデータのダウンロード",
    "title": "2  ハンドブックとデータのダウンロード",
    "section": "2.2 サンプルデータのダウンロード",
    "text": "2.2 サンプルデータのダウンロード\nハンドブックの内容を「実際に体験しながら」学習したい場合、サンプルデータと出力結果をダウンロードすることができます。\n\nR パッケージの利用\n最も簡単にすべてのデータをダウンロードする方法は、前述した epirhandbook パッケージをインストールすることです。このパッケージには、すべてのサンプルデータをパソコンの任意のフォルダに保存する関数 get_data() が含まれています。\nepirhandbook パッケージをインストールするには、次のコードを実行してください。このパッケージは CRAN にないため、インストールする際には p_install_gh() という関数を使用し、このハンドブックの Github Organization（“appliedepi”）と epirhandbook パッケージを指定してください。\n\n# 最新版の Epi R Handbook パッケージをインストールする\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nダウンロード後、今開いている R セッションで、インストールしたパッケージを読み込みます。\n\n# 使用するパッケージを読み込む\npacman::p_load(epirhandbook)\n\n次に、epirhandbook パッケージに含まれている関数 get_data() を使って、サンプルデータをパソコンにダウンロードします。get_data(\"all\") を実行するとすべてのサンプルデータがダウンロードできます。特定のファイルのみをダウンロードしたい場合は、引用符の中でファイル名と拡張子を指定してください。\nデータはすでにパッケージと一緒にダウンロードされているため、あとはパソコンのフォルダに移動させるだけです。ポップアップウィンドウが表示されますので、保存先のフォルダを選択してください。約 30 のファイル（サンプルデータ、サンプルデータの出力結果を含む）ありますので、新規に「data」フォルダを作成することをおすすめします。\n\n# すべてのサンプルデータをパソコンのフォルダにダウンロードする\nget_data(\"all\")\n\n# ラインリストのサンプルデータのみをパソコンのフォルダにダウンロードする\nget_data(file = \"linelist_cleaned.rds\")\n\n\n# ある特定のファイルをパソコンのフォルダにダウンロードする\nget_data(\"linelist_cleaned.rds\")\n\nget_data() を使ってファイルをパソコンに保存した後、それを R にインポートする必要があります。詳細は、データのインポート・エクスポート の章をご参照ください。\nまた、ご希望の場合は、このハンドブックで使用したすべてのデータを、Github リポジトリの 「data」フォルダ で確認することができます。\n\n\n1 つずつダウンロードする\nこのオプションは、Github リポジトリからファイルごとにデータをダウンロードするもので、リンクまたはファイル固有の R コマンドのいずれかを使用します。ファイルの種類によっては、ダウンロードボタンでダウンロードできるものもあれば、R コマンドでダウンロードできるものもあります。\n\n症例ラインリスト\nこれは、outbreaks パッケージの練習用データセット ebola_sim から本ハンドブックチームによって拡張された架空のエボラ出血熱の発生状況のデータです。\n\n「加工前の」ラインリストのダウンロードはこちら（.xlsx）。「加工前の」症例ラインリストは、雑多なデータを含む Excel のスプレッドシートです。データクリーニングと主要関数 の章を学ぶ際にご利用ください。\n「前処理された」ラインリストのダウンロードはこちら（.rds）。このファイルは、このハンドブック内でラインリストを使用するすべての章で使用します。.rds ファイルは、列のデータ型を保持する R 特有のファイル形式です。これにより、R にデータをインポートした後、最小限のクリーニングを行うだけでよくなります。\n\nその他の関連ファイル\n\n Excel ファイル形式の「前処理された」ラインリストのダウンロードはこちら\nデータクリーニングの章の一部では、「クリーニングディクショナリ（cleaning dictionary）」（.csv ファイル）を使用しています。次のコマンドを実行すると、R に直接読み込むことができます。\n\n\npacman::p_load(rio) # rio パッケージのインストールと読み込み\n\n# Github から直接ファイルをインポートする\ncleaning_dict &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv\")\n\n\n\nマラリア症例数のデータ\nこれらのデータは、年齢層別、施設別、日別のマラリア症例数の架空のデータです。.rds ファイルは、列のデータ型を保持する R 特有のファイル形式です。これにより、R にデータをインポートした後、最小限のクリーニングを行うだけでよくなります。\n マラリア症例数データのダウンロードはこちら（.rds file） \n\n\nリッカート尺度のデータ\nこれは、人口ピラミッドとリッカート尺度 の章で使用する、リッカート尺度による架空の調査データです。次のコマンドを実行すると、R に直接読み込むことができます。\n\npacman::p_load(rio) # rio パッケージのインストールと読み込み\n\n# Github から直接ファイルをインポートする\nlikert_data &lt;- import(\"https://raw.githubusercontent.com/nsbatra/Epi_R_handbook/master/data/likert_data.csv\")\n\n\n\n柔軟なダッシュボード\n以下は、R Markdownで作るダッシュボード の章に関連するファイルへのリンクです。\n\nアウトブレイクダッシュボードの R Markdown をダウンロードするには、この リンク を右クリック（Mac の場合は Cmd を押しながらクリック）し、「リンク先を別名で保存（Save link as）」を選択してください。\nHTML ダッシュボードをダウンロードするには、この リンク を右クリック（Mac の場合は Cmd を押しながらクリック）し、「リンク先を別名で保存（Save link as）」を選択してください。\n\n\n\n接触者の追跡\n接触者の追跡 の章では、Go.Data のデータを例に、接触者追跡に関するデータ解析について紹介しました。この章で使用したデータは、次のリンクをクリックすると、.rds ファイルとしてダウンロードすることができます。\n感染者調査データのダウンロードはこちら（.rds file） \n接触者登録データのダウンロードはこちら（.rds file） \n接触者フォローアップのデータのダウンロードはこちら（.rds file） \n注釈：他のソフトウェア（KoBo、DHIS2 Tracker、CommCare など）の構造化された接触者の追跡データは、見た目が異なる場合があります。この章の代替サンプルデータやコンテンツをご提供いただける場合は こちら へご連絡ください。\nヒント：Go.Data を展開していて、API に接続したい場合は、データのインポート・エクスポートの章 (API セクション) と Go.Data Community of Practiceをご参照ください。\n\n\nGIS\nシェイプファイル（Shapefiles）には多くのサブファイルがあり、それぞれ異なるファイル拡張子を持っています。あるファイルの拡張子は「.shp」ですが、他のファイルは「.dbf」、「.prj」などの拡張子があります。\nGIS の基礎 の章には、Humanitarian Data Exchange ウェブサイトへのリンクがあり、zip ファイルとしてシェイプファイルを直接ダウンロードすることができます。\n例えば、医療施設ポイントデータは、こちら からダウンロードできます。「hotosm_sierra_leone_health_facilities_points_shp.zip」をダウンロードし、パソコンに保存したら、フォルダーを「解凍」してください。拡張子が異なる複数のファイル（例：「.shp」、「.prj」、「.shx」）が表示されますので、これらすべてのファイルをパソコンの同じフォルダ内に保存してください。そして、R にインポートするには、sf パッケージの st_read() に 「.shp」 ファイルのパスとファイル名を指定します（GIS の基礎 の章に記載されています）。\n先述したオプション 1 の方法に従って epirhandbook パッケージを利用してすべてのサンプルデータをダウンロードする場合、すべてのシェイプファイルが含まれます。\nまたは、R Handbook Github の「data」フォルダ（「gis」 サブフォルダを参照）からシェイプファイルをダウンロードすることも可能です。ただし、各サブファイルを個別にパソコンにダウンロードする必要があることに注意してください。Github で、各ファイルを個別にクリックし、「Download」ボタンをクリックしてダウンロードできます。下の図は、シェイプファイル「sle_adm3」が多くのファイルから構成されており、それぞれを Github からダウンロードする必要があることを示しています。\n\n\n\n\n\n\n\n\n\n\n\n系統樹\n系統樹 の章をご参照ください。299 の Shigella sonnei サンプルの全ゲノムシークエンスから構築した系統樹の Newick ファイルと対応するサンプルデータ（テキストファイルへ変換）です。ベルギーのサンプルとそのデータは、ECDC EUPHEM フェローのプロジェクトの一環として、サルモネラ菌と赤痢菌についてベルギー NRC から提供されたもので、原稿も掲載される予定です。国際的なデータは、公共データベース（ncbi）で公開されており、過去に発表されています。\n\n系統樹ファイル「Shigella_tree.txt」をダウンロードするには、この リンク を右クリック（Mac の場合は Cmd を押しながらクリック）し、「リンク先を別名で保存（Save link as）」を選択してください。\n各サンプルの追加情報を含む「sample_data_Shigella_tree.csv」をダウンロードするには、このリンクを右クリック（Mac の場合は Cmd を押しながらクリック）し、「リンク先を別名で保存（Save link as）」を選択してください。\n新しく作成されたサブセット・ツリーを見るには、このリンクを右クリック（Mac の場合は Cmd を押しながらクリック）し、「リンク先を別名で保存（Save link as）」を選択してください。.txt ファイルがあなたのパソコンにダウンロードされます。\n\nインストール後、系統樹の章で説明されているとおり、ape パッケージの read.tree() で .txt ファイルを取り込むことができます。\n\nape::read.tree(\"Shigella_tree.txt\")\n\n\n\n標準化\n標準化率 の章をご参照ください。次のコマンドで、インターネット上の Github リポジトリから直接 R セッションにデータを読み込むことができます。\n\n# rio パッケージのインストールと読み込み\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# A 国の人口統計データを Github から直接インポートする\nA_demo &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# A 国の死因を Github から直接インポートする\nA_deaths &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# B 国の人口統計データを Github から直接インポートする\nB_demo &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# B 国の死因を Github から直接インポートする\nB_deaths &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Reference Pop\n###############\n# B 国の人口統計データをGithubから直接インポートする\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\n\n\n時系列分析とアウトブレイクの検出\n時系列分析とアウトブレイクの検出 の章をご参照ください。surveillance パッケージに含まれている、2002 年から 2011 年までにドイツで報告されたカンピロバクター症例を使用しています（注：このデータセットは、学習のために 2011 年末から 3 ヶ月分のデータを削除し、元のデータから改編したものです）。\nドイツのカンピロバクターのデータのダウンロードはこちら（.xlsx）\nまた、時系列分析とアウトブレイクの検出の章では、ドイツの 2002 年から 2011 年の気候データ（気温：摂氏、降水量：ミリメートル）も使用します。これらのデータは ecmwfr パッケージを使用して EU Copernicus 衛星再解析データセットからダウンロードしたものです。時系列分析の章で説明されているように、これらのデータをすべてダウンロードし、stars::read_stars() でインポートする必要があります。\nドイツの 2002 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2003 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2004 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2005 年の天気予報のダウンロードはこちら（.nc file）ドイツの 2006 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2007 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2008 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2009 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2010 年の天気予報のダウンロードはこちら（.nc file）\nドイツの 2011 年の天気予報のダウンロードはこちら（.nc file）\n\n\n標本調査データ分析\n標本調査データ分析 の章では、MSF OCA 調査テンプレートをもとにした架空の死亡率調査データを使用しています。この架空のデータは、「R4Epis」プロジェクト の一環として作成されたものです。\n架空の調査データのダウンロードはこちら（.xlsx） \n架空の調査データのデータディクショナリはこちら（.xlsx）\n架空調査母集団データのダウンロードはこちら（.xlsx）\n\n\nShiny\nShiny で作るダッシュボード の章では、マラリアのデータを表示する簡単なアプリの作成方法を紹介しています。\nShiny アプリを作成する R ファイルのダウンロードは以下の通りです。\nShiny アプリの UI とサーバーのコードを含む app.R ファイルのダウンロードはこちら\nShiny アプリ用のマラリアデータを含む facility_count_data.rds ファイルのダウンロードはこちら。なお、here() のファイルパスが正しく動作するように、「data」フォルダ内に保存しなければならない場合があります。\n章内で説明されている、アプリを開く前に実行すべき global.R ファイルのダウンロードはこちら\nglobal.R がもととなっている plot_epicurve.R ファイルのダウンロードはこちら なお、here() のファイルパスが正しく動作するために、「funcs」フォルダ内に保存しなければならない場合があります。",
    "crumbs": [
      "本書について",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ハンドブックとデータのダウンロード</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html",
    "href": "new_pages/basics.jp.html",
    "title": "3  R の基礎",
    "section": "",
    "text": "3.1 なぜ R を使うのか？\nこちらの R プロジェクトのウェブサイト で述べられているように、R はプログラミング言語であり、統計的機械計算と視覚化のための環境を提供します。R は、汎用性や拡張性が非常に高く、また、コミュニティ手動の開発も行われています。\nR の費用\nR は無料で利用できます！ この点においては、自由かつオープンソースを志向する人々のコミュニティにおける、強固な倫理的矜持があります。\n再現性\nプログラミング言語を使用して行うデータ管理と分析は、（Excel や、カーソルを動かしてクリックしたり、手作業で管理するツールに比べて）、再現性を高めると共に、エラーの発見を容易にし、作業の負荷を軽減します。\nコミュニティ\nR には、大きなユーザーのコミュニティがあり、協同的です。現実世界の問題を扱う新しいパッケージやツール群が日々開発されており、ユーザーコミュニティで検証されています。コミュニティの 1 つの例として、R-Ladies は、R コミュニティでのジェンダーダイバーシティの推進をミッションとした世界的な組織です。また、大規模な R ユーザーコミュニティの 1 つでもあります。このコミュニティの支部はおそらくあなたの住んでいる場所の近くにもあるでしょう。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#キーワード",
    "href": "new_pages/basics.jp.html#キーワード",
    "title": "3  R の基礎",
    "section": "3.2 キーワード",
    "text": "3.2 キーワード\nRStudio：RStudio は、R をより使いやすくするグラフィカルインタフェース（Graphical User Interface; GUI）です。詳しくは、後述の RStudio のセクション を参照してください。\nオブジェクト：あなたが R に保存するすべて（データセット、変数、町の名前のリスト、合計人口や、グラフのようなアウトプットでさえも）は、名前が割り当てられかつ、以降のコマンドで参照可能な、オブジェクトです。詳しくは、後述の オブジェクトのセクション を参照してください。\n関数：関数とは、入力を受け入れて処理し、処理され変化した内容を出力して返すコードのことをいいます。詳しくは、後述の 関数のセクション を参照してください。\nパッケージ：R パッケージは、複数の関数をまとめて共用可能にしたものです。詳しくは、後述の パッケージのセクション を参照してください。\nスクリプト：スクリプトとは、R のコマンドが書かれたドキュメントファイルです。詳しくは、後述の スクリプトのセクション を参照してください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#learning",
    "href": "new_pages/basics.jp.html#learning",
    "title": "3  R の基礎",
    "section": "3.3 参考資料",
    "text": "3.3 参考資料\n\nRStudio に含まれているリソース\nヘルプドキュメント\nR パッケージや特定の関数のドキュメントについては、RStudio の “Help” タブをまず見つけてください。このタブは、Files、Plots、Packages タブを含むペインに含まれています（一般的には右下のペインにあります）。ショートカットとして、R コンソールに、クエスチョンマークに続けて、パッケージや特定の名前を入力しても関連するヘルプページを表示することができます。括弧（）は入力に含めないでください。\n例えば、?filter や、?diagrammeR というように入力します。\nインタラクティブチュートリアル\nR を学ぶ方法として、RStudio 内でインタラクティブに（コードを実際に書きながら）学ぶ方法がいくつかあります。\nまず、RStudio 自体が learnr パッケージを使ったチュートリアルペインを提供しています。このパッケージをインストールし、RStudio の右上に新たに現れる “Tutorilal” タブを開くだけで始められます。（この右上のペインは、Environment、History タブも含みます）。\nまた、swirl というパッケージは、R コンソールで体験的に学習できるコースを提供します。このパッケージをインストール後読み込み、そのあと、swirl() （空括弧をつけます）コマンドを R コンソール上で実行します。プロンプトがコンソール上に現れ、コンソール上での入力に反応します。あなたが選択したコースを通して、このプロンプトがガイドします。\n\n\nチートシート\nRStudio ウェブサイト 上には、多くの「チートシート（PDF ファイル）」があります。例えば、\n\nforcats パッケージと因子（ファクタ）型\nlubridate パッケージと日時型\nstringr パッケージと文字型\npurrr パッケージと反復操作\nデータのインポート\ndplyr パッケージとデータ変換\nR Markdown（PDF, Word, Powerpoint のような文書を作るために）\nShiny（インタラクティブなウェブアプリを作るために）\nggplot2 パッケージとデータ視覚化\n地図の作成（GIS）\nleaflet パッケージ（インタラクティブな地図の作成）\nR とともに使う Python（reticulate パッケージ）\n\nまた、こちら には Excel ユーザー のための R リソースもあります。\n\n\nTwitter\nR には活発なコミュニティがあり、役に立つヒントやショートカット、更新情報などを知ることができます。以下のアカウントをフォローしてください。\n\n本ハンドブックのアカウントをフォローしてくださいね！ @epiRhandbook\n\nR Function A Day @rfuntionaday には、驚くほどの情報量があります\nR for Data Science @rstats4ds\n\nRStudio @RStudio\n\nRStudio Tips @rstudiotips\n\nR-Bloggers @Rbloggers\n\nR-ladies @RLadiesGlobal\n\nHadley Wickham @hadleywickham\n\nそして、\n#epitwitter と #rstats のハッシュタグもチェックしてみてください！\n\n\n無料のオンラインリソース\n最も信頼できる書籍は、Garrett Grolemund と Hadley Wickham による R for Data Science です。\nR4Epis プロジェクトのウェブサイトは、「国境なき医師団（MSF）で緊急事態発生時に実施される一般的なアウトブレイク調査をサポートするために、標準化されたデータクリーニング、データ分析、およびレポート作成ツールを開発する」ことを目的にしています。ウェブサイトでは、R の基本的な資料、アウトブレイクと疫学調査に関する RMarkdown レポートのテンプレート、また、環境設定に役立つチュートリアルを閲覧することができます。\n\n\n英語以外の言語で書かれた資料\nMateriales de RStudio en Español\nIntroduction à R et au tidyverse (Francais)",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#インストール",
    "href": "new_pages/basics.jp.html#インストール",
    "title": "3  R の基礎",
    "section": "3.4 インストール",
    "text": "3.4 インストール\n\nR と RStudio\nR のインストール方法\nhttps://www.r-project.org/ のウェブサイトを開き、使用するコンピュータに応じて、R の最新バージョンをダウンロードしてください。\nRStudio のインストール方法\nhttps://rstudio.com/products/rstudio/download/ のウェブサイトを開き、使用するコンピュータに応じて、RStudio の最新バージョンをダウンロードしてください。\nアクセス許可\nR と RStudio は、読み取りと書き込みのアクセス許可があるディスクドライブにインストールする必要があることに注意してください。 そうしないと、R パッケージをインストールする際に影響を受けます（R パッケージのインストールは頻繁に必要になります）。 アクセス許可に関して問題が発生した場合は、アイコンを右クリックして「管理者として実行（Run as administrator）」を選択し、RStudio を開いてみてください。 その他の対処法は、ネットワークドライブで R を使用する場合 の章を参照してください。\nR と RStudio のアップデート方法\nR のバージョンは、起動時に R コンソールに出力されます。 または、sessionInfo() を実行しても確認できます。\nR のアップデートは、先述のウェブサイトにアクセスして、R を再インストールします。または、（Windows の場合は）installr パッケージを使用し、installr::updateR() を実行してもアップデートできます。 このコマンドを実行すると、最新バージョンの R がダウンロードされ、最新バージョンに対応してパッケージをアップデートするためのダイアログボックスが開きます。 詳細については、instrallr のドキュメント を参照してください。\nR をアップデートしても、古いバージョンの R がまだコンピュータ上に存在することに注意してください。 RStudio で “Tools” -&gt; “Global Options” をクリックし、R の古いバージョンを選択することで、R の古いバージョン（古い「インストール済み」のバージョン）を一時的に実行できます。 この操作は、最新バージョンの R で動作するようにアップデートされていないパッケージを使用する場合に役立ちます。\nRStudio をアップデートするには、上記のウェブサイトにアクセスして、RStudio を再ダウンロードします。 他の方法として、RStudio 内の “Help” -&gt; “Check for Updates” をクリックすることもありますが、この方法では最新のアップデートが表示されない場合があります。\nこのハンドブックの作成時に使用された R、RStudio、またはパッケージのバージョンを確認したい場合は、編集前記・技術注記 の章を参照してください。\n\n\nおそらくインストールが必要となるその他のソフトウェア\n\nTinyTeX (RMarkdown ドキュメント を PDF ファイルへ変換するため)\n\nPandoc (RMarkdown ドキュメントを変換するため)\n\nRTools (R パッケージの開発のため)\n\nphantomjs (感染連鎖図のような、動きのあるネットワークの静止画の保存のため)\n\n\nTinyTex\nTinyTex は カスタム化された LaTeX の 1 つです。R から PDF を作成したい場合に便利です。より詳しい情報は、https://yihui.org/tinytex/ をご覧ください。\nTinyTex を R コンソールでインストールするには、以下のコマンドを実行してください。\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# TinyTex をアンインストールする場合, tinytex::uninstall_tinytex() を実行する\n\n\n\nPandoc\nPandoc は、ドキュメント変換ツールであり、R とは切り離されたソフトウェアです。RStudio をインストールした際に同時にインストールされるので、個別にダウンロードする必要はありません。Rmarkdown ドキュメントを .pdf に変換したり、複雑な機能を追加してくれたりします。\n\n\nRTools\nRTools は、R のパッケージを開発するためのソフトウェアをまとめたものです。\n以下のウェブサイトからインストールしてください。\nhttps://cran.r-project.org/bin/windows/Rtools/\n\n\nphantomjs\nphantomjs は、ウェブページの「スクリーンショット」を取得するためによく使われるパッケージです。例えば、epicontacts パッケージで感染連鎖の図を作成する際、インタラクティブかつ動的な HTML ファイルが生成されます。静的な画像が必要な場合は、この作業を自動化するために webshot パッケージを使うと便利であり、このような自動化には、“phantomjs” という外部プログラムが必要です。phantomjs は webshot パッケージの webshot::install_phatomjs() を実行すると、インストールできます。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#rstudio",
    "href": "new_pages/basics.jp.html#rstudio",
    "title": "3  R の基礎",
    "section": "3.5 RStudio",
    "text": "3.5 RStudio\n\nRStudio オリエンテーション\nまず最初に、RStudio をたちあげます。 R とアイコンが非常に似ているので、R ではなく RStudio を開くことを確認してください。\nRStudio が動作するためには、R もインストールされている必要があります（先述のインストールのセクションを参照してください）。\nRStudio は、R を簡単に使用するためのインタフェース（GUI）です。R を車のエンジン、つまり重要な働きを行っている部分と例えるならば、RStudio は、車の車体（シートやアクセサリなど）、つまりあなたがエンジンを動かすために使うものと考えることができます！RStudio ユーザインタフェースのチートシートは こちら で参照いただけます。\nデフォルトでは、RStudio には 4 つの四角いペインがあります。\n\n\n\n\n\n\n\n\n\nヒントの: もし RStudio の左側に 1 つしかペインが表示されていない場合は、まだ R スクリプトを 1 つも開いていないからです。\nSource ペイン\nデフォルトでは左上に表示されるこのペインは、スクリプト の編集、実行、保存に使うスペースです。スクリプトは、実行コマンドを含んでいます。このペインには、データセット（データフレーム）を表示させることもできます。\nStata ユーザには、このペインは Do-file and Data Editor ウィンドウのように見えるでしょう。\nR Console ペイン\nRStudio でデフォルトで左下に表示される R コンソールは、R の「エンジン」に相当します。コマンドを実際に実行したり、グラフィックでない出力結果やエラー、または警告メッセージが表示されます。R コンソールに直接コマンドを入力し、実行することができますが、スクリプト上でコマンドを実行したときと違い、コンソールから実行したコマンドは保存されないことを覚えておいてください。\nStata に慣れている方にとっては、R コンソールは Command ウィンドウや Results ウィンドウに似ています。\nEnvironment ペイン\nデフォルトで右上に表示されるこのペインでは、現在のセッションにおける R 環境の オブジェクト の簡単な要約としてよく利用されます。オブジェクトは、インポート、変更、または生成されたデータセット、定義したパラメータ（例えば、分析の特定の疫学週）、または分析中に定義したベクトルまたはリスト（例えば、地域の名前）などが含まれます。データフレーム名の横にある矢印をクリックすると、データフレームに含まれている変数を確認できます。\nStata では、Variables Manager ウィンドウに最もよく似ています。\nこのペインには、過去に実行したコマンドを閲覧できる History タブもあります。もし learnr パッケージをインストール済みであれば、インタラクティブな R チュートリアルを行う “Tutorial” タブもこのペインにあります。また、外部接続のための “Connections” ペインと、Github インタフェースを選択した場合に “Git” タブもあります。\nPlots、Viewer、Packages と Help ペイン\n右下にあるペインはいくつかの重要なタブを含んでいます。地図などの図をプロットした際の出力結果は、Plot ペインに表示されます。インタラクティブ出力や、HTML 出力は Viewer ペインに表示されます。Help ペインはドキュメントやヘルプファイルを表示することができます。Files ペインは、ファイルを開いたり削除したりするために使われるブラウザです。Package ペインでは、R パッケージのインストール、アップデート、削除、読み込みと破棄（ロードとアンロード）が可能です。また、どのバージョンのパッケージがインストール済みかも確認することができます。R パッケージについてより詳しく知りたい方は、後述の パッケージセクション を参照してください。\nこのペインは、Stata の Plots Manager と Project Manager ウィンドウに相当する機能が含まれます。\n\n\nRStudio の設定\nTools ドロップダウンメニューにある Global Options を選択し、RStudio の設定や外観の変更します。外観や、背景の色などのデフォルトの設定を変更することができます。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n再起動\nR が固まって動かなくなった場合、Session メニューの “Restart R” をクリックすることで R を再起動することができます。RStudio を閉じたり開いたりする手間を省くことができ、この操作を実行した場合は、現在の R 環境のすべてが削除されます。\n\n\nキーボード ショートカット\n便利なキーボード ショートカットをいくつか以下に示します。Windows、Max、Linux のすべてのキーボード ショートカットを参照する場合は、RStudio ユーザインタフェースチートシート の 2 ページ目を参照してください。\n\n\n\n\n\n\n\n\nWindows/Linux\nMac\n動作\n\n\n\n\nEsc\nEsc\n現在実行中のコマンドを中断する（誤って未完成のコマンドを実行してしまった場合や、R コンソール内に “+” が見えている状態でエスケープできない場合に有用）\n\n\nCtrl+s\nCmd+s\nスクリプトを保存する\n\n\nTab\nTab\n自動補完する\n\n\nCtrl + Enter\nCmd + Enter\n現在の行または、選択したコードを実行する\n\n\nCtrl + Shift + C\nCmd + Shift + c\nハイライトされた行をコメント化する、またはコメントでない状態に戻す\n\n\nAlt + -\nOption + -\n&lt;- を挿入する\n\n\nCtrl + Shift + m\nCmd + Shift + m\n%&gt;% を挿入する\n\n\nCtrl + l\nCmd + l\nR コンソールの表示をクリアにする\n\n\nCtrl + Alt + b\nCmd + Option + b\n第一行から現在行まで実行する\n\n\nCtrl + Alt + t\nCmd + Option + t\n現在のコードセクションを実行する（R Markdown）\n\n\nCtrl + Alt + i\nCmd + Shift + r\nコードチャンクを挿入する（R Markdown 内へ）\n\n\nCtrl + Alt + c\nCmd + Option + c\n現在のコードチャンクを実行する（R Markdown）\n\n\nR コンソール内での 上下 矢印キー\n同左\n最近実行したコマンドを切り替える\n\n\nスクリプト内で Shift + 上下矢印キー\n同左\n複数行の選択\n\n\nCtrl + f\nCmd + f\n現在のスクリプト内の検索と置き換え\n\n\nCtrl + Shift + f\nCmd + Shift + f\nファイルをまたいだ検索（複数のスクリプトをまたいだ検索・置き換え）\n\n\nAlt + l\nCmd + Option + l\n選択したコードの折りたたみ\n\n\nShift + Alt + l\nCmd + Shift + Option+l\n選択したコードの展開\n\n\n\nヒント：RStudio の自動補完機能を使用したい場合は、入力時に Tab キーを押してください。スペルミスによるエラーを防ぐことができます。入力中に Tab キーを押すことで、これまでに入力した内容に基づき、入力する可能性のある関数とオブジェクトのドロップダウンメニューが表示されます。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#functions",
    "href": "new_pages/basics.jp.html#functions",
    "title": "3  R の基礎",
    "section": "3.6 関数",
    "text": "3.6 関数\n関数は R を使う上で核となるものです。関数は、タスクや操作を実行する方法が定義されたものです。R のインストールには多くの関数が含まれていますが、加えて個別にパッケージをダウンロードすると、さらに多くの関数が利用可能です（詳しくは、後述のパッケージ セクションで説明します）。また、ご自身でカスタム関数を定義することもできます。\n関数についてこの基礎的なセクションで説明することは、以下の項目です。\n\n関数とは何か、どのように機能するか\n関数の引数とは何か\n関数を理解するために使えるリソース\n\nこのハンドブックにおけるコードの書き方について：このハンドブックでは、関数は filter() のように括弧つきのスタイルで書かれています。後述の パッケージ のセクションで説明されているように、関数はパッケージに含まれており、パッケージとともにダウンロードされます。このハンドブックでは、パッケージの名前は dplyr のように太字で書かれています。サンプルコードでは、ときおり dplyr::filter() のように、関数名をパッケージ名と 2 つのコロン（::）でつなげている場合があります。この記法の目的は、後述の パッケージ のセクションで説明します。\n\n\n単純な関数\n関数とは、入力を受付け、入力に基づいて動作し、出力を生成する機械のようなものです。 出力が何であるかは関数に依存します。\n関数は通常、関数の括弧内に書かれた何らかのオブジェクトに対して動作します。 例えば、sqrt() は、数値の平方根を計算します。\n\nsqrt(49)\n\n[1] 7\n\n\n関数に渡されるオブジェクトには、データセットの列を指定することもできます（すべての種類のオブジェクトの詳細については、後述の オブジェクト セクションを参照してください）。R は複数のデータセットを格納できるため、オブジェクトを指定する際は、データセット名と列の両方を明記する必要があります。1 つの方法は、$ 表記を使用して、データセット名と列名をつなげることです（例えば、dataset$column）。以下の例では、lineliset データセット内の数値を含む列である age 列に summary() を適用し、age 列の要約統計量を算出し、出力しています。\n\n# `linelist` データセットの `age` 列の要約統計量を出力\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n\n注釈：関数の実行を裏から見ると、関数とは複雑なコードをユーザーが簡単に使えるように 1 つのコマンドにまとめたものです。\n\n\n\n複数の引数を取る関数\n関数は、たいてい引数と呼ばれる複数の入力を要求します。引数は関数の括弧内にあり、通常はコンマで区切られています。\n\n関数が正しく機能するために必須な引数もありますが、任意の引数もあります\n任意の引数は、デフォルトの値を持っています\n文字列、数値、ロジカル値（TRUE/FALSE）、更に他の型の入力を引数に取ることができます\n\n典型的な関数の例として、oven_bake() という架空の関数を考えます。入力オブジェクト（データセット、この例では「パンとなる生地（dough）」）を受け取り、追加の引数（minutes = と temperature =）で指定された操作を実行します。出力結果はコンソールに表示するか、代入演算子 &lt;- を使用してオブジェクトとして保存できます。\n\n\n\n\n\n\n\n\n\nより現実的な例として、以下の age_pyramid() コマンドでは、定義された年齢グループと、genger 列のような二値分類された列に基づいて、年齢ピラミッドをプロットします。関数には、括弧内にコンマで区切られた 3 つの引数が与えられます。それぞれの引数には、プロットするデータフレームとして linelist を、カウントする列として age_cat5 を、ピラミッドの色分けに使用する列として二値分類列である gender を指定します。\n\n# 年齢層別の人口ピラミッドを作成する\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n\n\n\n\n\n\n\n\n上で書いたコマンドは、以下のように、引数ごとに改行した長い書式で書くことができます。この書式は読みやすく、各部分を説明するための「コメント」を # を使って簡単に書くことができます。（コメントを多く残すことは良い習慣です！）以下のような長いコマンドを実行するには、コマンド全体をハイライトして “Run” をクリックするか、最初の行にカーソルを合わせて、 Ctrl キーと Enter キーを同時押すだけです。\n\n# 年齢層別の人口ピラミッドを作成する\nage_pyramid(\n  data = linelist,        # 症例ラインリストを使用\n  age_group = \"age_cat5\", # 年齢層の列を指定\n  split_by = \"gender\"     # ピラミッドの両翼に、性別列を使用\n  )\n\n\n\n\n\n\n\n\n引数が特定の順序で記述されている場合（関数のドキュメントで指定されている場合）は、引数の代入部分の前半（data = など）を書く必要はありません。以下のコードでは、データフレーム、age_group 変数、spilit_by 変数という引数の順序を関数が予測しているため、上で書いたコマンドとまったく同じピラミッドを作成します。\n\n# このコマンドは前述のピラミッドとまったく同じものを作成する\nage_pyramid(linelist, \"age_cat5\", \"gender\")\n\nより複雑な age_pyramid() コマンドには、以下のような任意の引数が含まれます。\n\nカウント数の代わりに割合を表示したい場合（デフォルトは、FALSE ですが、proportional = TRUE と設定します）\n両翼それぞれの色を指定したい場合（pal = は、“palette” の略で、2 つの色名のベクトル型として渡されます。c() 関数でベクトル型を作成する方法については、後述の オブジェクト のセクションを参照してください）\n\n注釈：引数名と値の両方の部分を指定した場合（例：proportional = TRUE）は、指定された引数の順序は問題になりません。\n\nage_pyramid(\n  linelist,                    # 症例ラインリストを使用\n  \"age_cat5\",                  # 年齢層別\n  \"gender\",                    # 性別で分類\n  proportional = TRUE,         # カウント数に代わり割合を表示\n  pal = c(\"orange\", \"purple\")  # 色の指定\n  )\n\n\n\n\n\n\n\n\n\n\n\n関数を作成する\nR は関数志向のプログラミング言語であるため、自分で関数を書くことができるようになっています。関数を作成すると以下のような利点があります。\n\nモジュール化（modular programming; コードを、独立した管理可能な部分に分離すること）を促進します\nエラーが発生しやすい、コピー＆ペーストの繰り返しを解消します\nコードに覚えやすい名前をつけられます\n\n関数の書き方については、関数の作成 の章で詳しく説明しています。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#packages",
    "href": "new_pages/basics.jp.html#packages",
    "title": "3  R の基礎",
    "section": "3.7 パッケージ",
    "text": "3.7 パッケージ\nパッケージには、関数が含まれています。\nR パッケージとは、あらかじめ定義された関数を含む、コードとドキュメントをまとめた共用可能なまとまりです。R コミュニティのユーザーは、特定の問題に対応したパッケージを常に開発しており、その特化して開発されたパッケージがあなたの業務に役立つ可能性があります！実際にR を使用する際には、何百ものパッケージをインストールして活用することになります。\nR のインストール時には、基本的な作業を実行する base パッケージ（以下、base R）と関数が含まれています。しかし、多くの R ユーザーが特殊な関数を作成しており、それらは R コミュニティによって検証され、あなたが使用するためにパッケージとしてダウンロードすることができます。このハンドブックでは、パッケージ名を太字で表記しています。R の使用にあたって難しく感じる点の 1 つは、ある作業を行うために選択できる関数またはパッケージが、多数あることです。\n\nインストールと読み込み\n関数は、インターネットを通じてコンピュータにダウンロード（「インストール」）できるパッケージに含まれています。パッケージがダウンロードされると、「ライブラリ」に保存されます。その後、パッケージを「読み込む」ことで、実行中の R セッションが閉じられるまで、読み込んだ関数にアクセスすることができます。\nR を個人用のライブラリ（図書館）と捉えてください。パッケージをダウンロードすると、新しい関数の本をライブラリに保存しますが、その本に含まれる関数を使用する際に、ライブラリから本を借りる（「読み込む」）必要があります。\n要約：R パッケージ内に含まれている利用可能な関数を使用するには、以下の 2 つの手順を実行する必要があります。\n\nパッケージは（1 回だけ）インストールされる必要があり、かつ\nパッケージは（各 R セッションにおいて）読み込まれる必要があります\n\n\n個人のライブラリ\n「ライブラリ」は、実際にはコンピュータ上のフォルダであり、インストールされている各パッケージのフォルダがそれぞれ含まれています。 R がコンピュータのどこにインストールされているかを調べ、“win-library” というフォルダを探してみてください。例：R\\win-library\\4.0 （4.0 は R のバージョンです。ダウンロードした R バージョンごとに異なるライブラリがあります）。\n.libPaths() を（空の括弧つきで）コンソールに入力し実行すると、ライブラリのファイルパスが出力されます。これは、ネットワークドライブで R を使用する場合 を使用するときに特に重要です。\n\n\nCRAN からのインストール\nほとんどの場合、R ユーザーは CRAN からパッケージをダウンロードします。CRAN（Comprehensive R Archive Network）は、R コミュニティのメンバーが R パッケージをオンラインで公開する場所です。\nCRAN からパッケージをダウンロードするときに、ウイルスとセキュリティについて懸念がある場合は、このトピックに関するこちらの こちらの記事 を参照してください。\n\n\nインストールと読み込みの方法\nこのハンドブックでは、packman パッケージ（“package manager” の省略）の使用を推奨しています。このパッケージには、必要に応じてパッケージをインストールし、かつ現在の R セッションで使用するためにパッケージを読み込む便利な関数である p_load() が含まれています。\np_load() の構文は非常にシンプルです。p_load() の括弧内に、コンマで区切られたパッケージ名を記載するだけです。例えば、以下のコマンドは、rio、tidyverse、here パッケージについて、まだインストールされていなければ、インストールを行い、使用するのために読み込みます。p_load() の利用は、他の人とスクリプトを共有する場合に特に便利で簡潔です。パッケージ名は大文字と小文字が区別されることに注意してください。\n\n# （必要であれば）インストールし、使用のために読み込む\npacman::p_load(rio, tidyverse, here)\n\nここでは、関数名（p_load()）の前に、パッケージ名（pacman）を明示的に記述し、これらを 2 つのコロンでつなぐ構文 pacman::p_load() を使用していることに注意してください。この書き方は、（すでにインストールされている場合に）pacman パッケージの読み込みにも便利です。\nbase R 内には、よく使用されているのを見かける、p_load() と同じような働きをする関数があります。パッケージをインストールするための base R の関数は、install.packages() 関数です。インストールするパッケージの名前は、括弧内で二重引用符で囲まれている必要があります。1 つのコマンドで複数のパッケージをインストールしたい場合は、c() でリスト化した文字ベクトルにして指定する必要があります。\n注釈：install.packages() は、パッケージを インストールしますが、現在のセッションで使用するための読み込みは行いません。\n\n# base R の関数で 1 つのパッケージをインストールする\ninstall.packages(\"tidyverse\")\n\n# base R の関数で複数のパッケージをインストールする\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n\nインストールは、コードを書く代わりにマニュアルでクリックして行うことも可能です。RStudio の “Packages” ペインに移動して、“Install” をクリックし、目的のパッケージ名を検索することで実行できます。\nインストールしたパッケージを使用するために読み込む base R パッケージの関数は、library() です。この関数は、一度に 1 つのパッケージしか読み込みできません（これが p_loard() を使用するもう 1 つの理由です）。パッケージ名は、二重引用符つきでも、なしでも指定できます。\n\n# base R パッケージの関数で複数のパッケージを読み込む\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n\nパッケージがインストールまたは読み込まれているかどうかを知りたい場合は、RStudio の Packages ペインで確認できます。パッケージがインストールされている場合は、バージョン番号とともに Packages ペインに表示されます。このボックスにチェックマークがついていた場合、現在のセッションで読み込まれています。\nGithub からのインストール\n場合によっては、CRAN からまだ入手できないパッケージをインストールしなければならないことがあります。あるいは、パッケージは CRAN で入手可能であるが、より安定し、また、（公開されている CRAN バージョンではまだ提供されていない）新機能を備えた開発バージョンのダウンロードが必要な場合もあります。このようなパッケージは、多くの場合、github.com のウェブサイトに無料で公開され、コード「リポジトリ」として公開されています。Github については、ハンドブックの Git と Github を使用したバージョン管理と共同作業 の章で詳しく説明しています。\nGithub から R パッケージをダウンロードする場合は、pacman パッケージの p_load_gh() を使用できます。p_load_gh() は、必要に応じてパッケージをGithub からインストールし、現在の R セッションで使用できるように読み込みます。他にも、remotes パッケージや devtools パッケージを使用しても Github からパッケージをインストールすできます。pacman パッケージに含まれるすべての関数をご覧になりたい方は こちらの公式ドキュメント を参照してください。\nGithub からパッケージをインストールする際は、より多くの情報が必要です。必要な情報は、以下の通りです。\n\nリポジトリ所有者の Github ID\nパッケージを含むリポジトリの名前\n（任意：特定の開発バージョンをダウンロードしたい場合）ダウンロードしたいブランチ（branch）の名前\n\n以下の例では、二重引用符で囲まれた部分のうち、スラッシュの前がリポジトリ所有者の Github ID であり、後がリポジトリの名前（パッケージ名）です。\n\n# Github リポジトリから epicontacts パッケージをインストールして読み込む\np_load_gh(\"reconhub/epicontacts\")\n\nメインブランチ（main branch）以外の ブランチからパッケージをインストールする場合は、リポジトリ名の後に続けて、“@” とブランチ名を追加します。\n\n# Github から \"timeline\" ブランチにある epicontacts パッケージをインストールする\np_load_gh(\"reconhub/epicontacts@timeline\")\n\n手元のコンピュータにあるバージョンと Github にあるバージョンが同じ場合は何も起こりません。p_load_current_gh() を使用する際に、update =TRUE と指定すると、パッケージを「強制的に」再インストールすることができます。packman パッケージについての詳細は、こちらのドキュメント を参照してください。\nZIP や TAR からのインストール\nURL からパッケージをインストールすることもできます。\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n\nまたは、zip ファイルをコンピュータに保存することでパッケージをダウンロードすることもできます。\n選択肢 1：remotes パッケージの install_local() を使う\n\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\n\n選択肢 2：base R パッケージの install.packages() を使用し、ZIP ファイルへのファイルパスを指定して type = \"source\" と repos = NULL を指定する\n\ninstall.packages(\"~/Downloads/dplyr-master.zip\", repos=NULL, type=\"source\")\n\n\n\n\nコードの書き方\nこのハンドブックでは、わかりやすくするために、次のように関数名の前に :: 記号を使用してパッケージの名前を記載することがあります：package_name::function_name()\n起動中の R セッションに使用したい関数のパッケージがすでに読み込まれている場合は、このような明示的な関数の呼び出しは必要なく、単に function_name() を書くだけで問題ありませんが、呼び出したい関数名が一般的な名前で、複数のパッケージに存在する可能性がある場合（例：plot()）には、パッケージ名を併記すると便利です。パッケージ名を併記すると、そのパッケージがまだ読み込まれていない場合には、そのパッケージを読み込みます。\n\n# rio パッケージの import() 関数を使用してデータセットをインポートする\nlinelist &lt;- rio::import(\"linelist.xlsx\", which = \"Sheet1\")\n\n\n\n関数のヘルプ\n関数について詳しく知りたい場合は、RStudio の右下にある Help タブで検索することができます。また、?thefunctionname（クエスチョンマークの後に関数名を入力する）のようにコマンドを実行すると、ヘルプページが Help ペインに表示されます。オンラインで関数に関する情報を検索することもできます。\n\n\nパッケージのアップデート\nパッケージは、再インストールすることでアップデートできます。また、RStudio の Packages ペインにある緑色の “Update” ボタンをクリックすると、新しいバージョンがインストール可能なパッケージを確認することもできます。パッケージのアップデートによって関数の動作が大きく変更された場合、古いコードを書き換える必要があることに注意してください。\n\n\nパッケージの削除\nパッケージの削除には、packman の p_delete() を使用するか、base R の remove.packages() を使用します。または、ライブラリを含むフォルダを見つけて手動でフォルダを削除します。\n\n\n依存関係\n多くの場合、パッケージは他のパッケージに依存して機能します。これを依存関係と呼びます。依存関係にあるパッケージのインストールに失敗した場合、そのパッケージに依存しているパッケージのインストールにも失敗することがあります。\np_depends() でパッケージの依存関係を確認し、p_depends_reverse() でどのパッケージがそれに依存しているかを確認できます。\n\n\nマスクされた関数\n2 つ以上のパッケージに同じ関数名が含まれていることは珍しくありません。例えば、dplyr パッケージには filter() がありますが、stats パッケージにも同じ名前の関数があります。同じ名前の関数を R セッションで読み込む場合、読み込まれる順番によって、デフォルトで呼び出される filter() がどちらのパッケージの関数であるかが決まります。デフォルトで呼び出される filter() コマンドは、後に読み込まれたパッケージの関数になります。\nRStudio の Environment ペインでは、順番を確認できます。“Global Environment” のドロップダウンメニューをクリックして、パッケージの読み込み順序を確認してください。このドロップダウンリストの下位にあるパッケージの関数は、ドロップダウンリストの上位に表示されるパッケージ内に含まれている同じ名前の関数をマスクします。パッケージを読み込む際、R はマスキングが発生しているかどうかをコンソール上で警告しますが、警告に気づかない場合が多く、よく見逃されます。\n\n\n\n\n\n\n\n\n\nマスキングを外す方法は以下の通りです。\n\nコマンド実行時にパッケージ名を指定します。例えば、dplyr::filter()\nパッケージが読み込まれる順序を変更して（例：p_load() 内）、新しい R セッションを開始します。\n\n\n\nデタッチやアンロード\nパッケージをデタッチする（アンロードする; 読み込んだパッケージを破棄する）には、以下のコマンドのように、正しいパッケージ名とコロンを 1 つだけ指定して detach() を使用します。なお、このコマンドを実行しても、マスキングが解決されない場合があります。\n\ndetach(package:パッケージ名, unload=TRUE)\n\n\n\n過去のバージョンをインストールする\n特定のパッケージの過去のバージョンをインストールしたい場合は、こちらのドキュメント を参照してください。\n\n\n推奨パッケージ\n日常の疫学業務に便利な推奨パッケージの一覧は、推奨するパッケージ の章をご覧ください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#scripts",
    "href": "new_pages/basics.jp.html#scripts",
    "title": "3  R の基礎",
    "section": "3.8 スクリプト",
    "text": "3.8 スクリプト\nスクリプトはプログラミングの基本的なパーツです。スクリプトは、コマンド（例えば、データセットの作成や更新、データ可視化の出力などを行う関数）を含むドキュメントです。スクリプトを保存し、後で実行することができます。スクリプトにコマンドを保存して実行するには、（R コンソールにコマンドを 1 つずつ入力することに比べて）多くの利点があります。\n\n可搬性：共同作業者にスクリプトを送ることで、共同で作業を行うことができます\n再現性：自分や共同作業者が「何を実行したか」を正確に知ることができます\nバージョン管理：自分や共同作業者が行った作業の変更履歴を追跡することができます\nコメントや注釈の付加：共同作業者に自分が何を行ったのかを説明することができます\n\n\nコメント付加\nスクリプト内で、R のコードに注釈（「コメント」）を付加することもできます。コメントは、自分自身や他の読み手に、コードが何を行っているかを説明するのに役立ちます。コメントを付加するには、ハッシュ記号（#）を入力し、その後にコメント内容を記述します。コメントは、R コードとは別の文字色で表示されます。\nハッシュ記号（#）の後に書かれたコードは実行されません。したがって、コードの前に # を置くと、コードを削除したくないが一時的にその行の実行をブロックする（「コードをコメント化する」）場合に便利な方法でもあります。複数行を選択して Ctrl + Shift + c（Mac では Cmd + Shift + c）を押すと、一度に複数行をコメント化したり、またはコードをコメントでない状態に戻すことができます。\n\n# コメントは 1 行にまとめることができる\n# データのインポート\nlinelist &lt;- import(\"linelist_raw.xlsx\") %&gt;%   # コード行の終わりにコメントを付加\n# filter(age &gt; 50)                          # コードのコメント化にも使用できる\n  count()\n\n\nコメントには、そのコードが何をしているかを残し、また、なぜそのコードを実行するかについても残しましょう\n合理的なサイズにコードを分割しましょう\nコードとともに、何をしているかをステップごとにテキストで説明しましょう（例えば、ステップを番号付きで明示しましょう）\n\n\n\nコーディングスタイル\n特にチームで作業する場合は、コーディングスタイルを意識することが必要です。私達は、tidyverse の スタイルガイド を提唱しています。このスタイルに準拠するのに役立つ、styler や lintr などのパッケージもあります。\nコードを他の人が読めるようにするために、いくつか非常に基本的なポイントを挙げます。\n* オブジェクトに名前をつける際に使用する文字や記号は、英語の小文字、数字、アンダースコア _ のみにする。（例：my_data）\n* 演算子の前後など、頻繁にスペースを挿入する。（例：n = 1 や age_new &lt;- age_old + 3）\n\n\nスクリプトの例\n以下は、短い R スクリプトの例です。コメントでコードを簡潔に説明すればするほど、共同作業者に喜ばれることを覚えておいてください。\n\n\n\n\n\n\n\n\n\n\n\n\nR arkdown\nR markdown スクリプトは、スクリプト自体が出力用のドキュメント（PDF、Word ファイル、HTML、Powerpoint ファイルなど）になる R スクリプトの一種です。このウェブサイトやハンドブックも R markdownスクリプトで作られています。\nR 初心者の方でも、R markdown を使うことができます！詳しく学びたい方は、本ハンドブックの R Markdown で作るレポート の章を参照してください。\n\n\n\nR notebooks\nR markdown と R notebook に違いはありませんが、ドキュメントの実行方法が若干異なります。詳しくは こちらのウェブサイト をご覧ください。\n\n\n\nShiny\nShiny アプリやウェブサイトは、app.R という 1 つの R スクリプトで構成されています。このファイルは以下の 3 つで構成されています。\n\nユーザインタフェース（ui）\nサーバ関数\nshinyApp 関数の呼び出し\n\n詳細は、このハンドブックの Shiny で作るダッシュボード の章を参照していただくか、こちらの Shiny チュートリアル をご覧ください。\napp.R は、昔は 2 つのファイル（ui.R と server.R）に分かれていました。\n\n\nコードの折りたたみ\nコードの一部を折りたたみ、スクリプトを読みやすくすることができます。\nコードを折りたたむには、# でテキストヘッダを書き始め、ヘッダを記述し、半角スペースをあけて、ダッシュ（-）、ハッシュ（#）、イコール（=）のいずれかの記号を少なくとも 4 つ続けて記述します。このように記述することで、スクリプトの左側にある行番号の隣の「すき間」に小さな下三角形が現れます。この下三角形をクリックすると、それ以降のコードが次のヘッダまで折りたたまれ、折りたたまれたことを示す左右矢印のアイコンが表示されます。\n折りたたまれたコードを展開するには、すき間の三角形をもう一度クリックするか、左右矢印アイコンをクリックします。また、この章の RStudio セクションで説明されているように、キーボードのショートカットもあります。\n記号 # を使用してヘッダを作成すると、スクリプトの左下部にある目次（以下の図を参照）もアクティブになり、スクリプト内で移動がしやすくなります。サブヘッダを作成するには、# シンボルを連続させます。見出し 1 の場合は #、見出し 2 の場合は、##、見出し 3 の場合は、### となります。\n以下は、サンプルスクリプトの 2 つのバージョンです。左側は、コメント付きのヘッダがついたオリジナルです。右側では、各ヘッダの後に 4 つのダッシュ（-）が記述されており、折りたたみ可能になっています。そのうちの 2 つが折り畳まれており、スクリプト左下部の目次に各セクションが表示されていることがわかります。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nその他、自動的に折りたたみの対象となるコード領域は、関数定義や、条件ブロック（if else 文）など、波括弧 { } で囲まれたコードです。コードの折りたたみについての詳細は、RStudio のウェブサイトサイト を参照してください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#作業ディレクトリ",
    "href": "new_pages/basics.jp.html#作業ディレクトリ",
    "title": "3  R の基礎",
    "section": "3.9 作業ディレクトリ",
    "text": "3.9 作業ディレクトリ\n作業ディレクトリとは、R が入出力に使用するルートフォルダの場所です。つまり、R がデフォルトでファイルを参照したり保存したりする場所です。 デフォルトでは、新しいファイルや出力はこの場所に保存され、インポートするファイル（データセットなど）もこの場所から検索されます。\n作業ディレクトリは、RStudio の Console ペインの上部に灰色のテキストで表示されます。getwd() を実行して現在の作業ディレクトリをコンソールに出力して表示することもできます（括弧内は空のままにします）。\n\n\n\n\n\n\n\n\n\n\n推奨される方法\n作業ディレクトリについて推奨する方法の詳細は、R プロジェクトの設定 の章を参照してください。 作業ディレクトリとファイルパスを管理するために、一般的で効率的かつ、トラブルのない方法は、以下の 3 つの要素を R プロジェクトの設定 の章で紹介する R プロジェクト指向のワークフローで組み合わせることです。\n\n1 つの R プロジェクトにすべてのファイルを集約します（R プロジェクトの設定 の章を参照してください）\nhere パッケージでファイルの場所を指定します（データのインポート・エクスポート の章を参照してください）\nrio パッケージでファイルのインポートとエクスポートを行います（データのインポート・エクスポート の章を参照してください）\n\n\n\n\nコマンドによる設定\n最近まで、R の学習者の多くは、スクリプトを setwd() コマンドで始めるよう教えられていましたが、代わりに R プロジェクトの設定 の章で紹介する R プロジェクト指向のワークフローの使用をおすすめします。あわせて、setwd() を使用しない理由が説明された こちらのドキュメント を参照してください。簡単に述べると、setwd() を使用した場合、行っている作業がお手元のコンピュータにのみ通用するものとなります。したがって、ファイルのインポートやエクスポートに使われるファイルパスは、他のコンピュータにとって「頼りにならない」ものになり、共同作業や、他のコンピュータでの作業を阻害します。他にもっとよいやり方があるのです！\n今述べたように、ほとんどの場合は setwd() を使用する方法はおすすめできませんが、使うことはできます。以下のように、目的のフォルダのファイルパスを二重引用符で囲んで、setwd() コマンドに渡すことができます。\n\nsetwd(\"C:/Documents/R Files/My analysis\")\n\n注意：setwd() で作業ディレクトリを設定することは、そのファイルパスがある 1 台のコンピュータに特有の場合、「頼りにならない」ものになりえます。代わりに、（here パッケージを使用して）R プロジェクトのルートディレクトリからの相対的なファイルパスを使用してください。\n\n\n\n手動での設定\n作業ディレクトリを手動で設定するには、（setwd() に相当する、マウスのクリックによる操作）メニューバーから Session をクリックし、ドロップダウンメニューから、“Set Working Directory” をポイントし、“Choose Directory” をクリックします。この操作で、特定の R セッション用の作業ディレクトリが設定されます。 注意：この方法を使用する場合、RStudio を開くたびに手動で設定する必要があります。\n\n\n\nR プロジェクト内で\nR プロジェクト内で実行している場合、作業ディレクトリのデフォルトは、“.rproj” ファイルを含む R プロジェクトのルートフォルダになります。これは、R プロジェクトファイル（拡張子が “.rproj” ）をクリックして、RStudio を開いた場合に適用されます。\n\n\n\nR markdown における作業ディレクトリ\nR markdown スクリプトでは、 R markdown ファイル（.Rmd）が保存されているフォルダが、デフォルトの作業ディレクトリとなります。R プロジェクトと here パッケージを使用している場合には、デフォルトは適用されず、R プロジェクトの設定 の章で説明されているように、作業ディレクトリは here() となります。\n単独ファイルの R markdown の作業ディレクトリを変更したい場合（R プロジェクトを使用せずに R markdown を使用している場合）、setwd() を使用すると、その特定のコードチャンクのみ適用されます。R markdown 内のすべてのコードチャンクに変更を加えるには、以下のように root.dir = パラメータを追加するするために設定用のチャンクを追加します。\n\nknitr::opts_knit$set(root.dir = 'desired/directorypath')\n\nこの方法より、R プロジェクト内で R markdown を使用し、here パッケージを使用する方が遥かに簡単です。\n\n\n\nファイルパスの設定\nおそらく多くの R 初心者が不満に感じることは（少なくとも Windows では）、データのインポート、エクスポートのためのファイルパスを打ち込むことです。ファイルパスを最適に入力する方法については、データのインポート・エクスポート の章で詳細を説明しますが、以下に重要なポイントをいくつか記載します。\n機能しないファイルパス\n以下に、「絶対パス」（もしくは、「フルアドレスパス」）のファイルパスのサンプルを記載しています。「絶対パス」で書かれたファイルパスは、他のコンピュータ上では機能しなくなります。例外の 1 つは、共有ドライブもしくは、ネットワークドライブを使用している場合です。\nC:/Users/Name/Document/Analytic Software/R/Projects/Analysis2019/data/March2019.csv  \nディレクトリの区切り記号\nファイルパスを入力する場合は、スラッシュの向きに注意してください。フォルダとファイル名の区切り（例：“data/provincial.csv”）には、スラッシュ（/）を使用してください。Windows でのデフォルトのファイルパスは、バックスラッシュ（\\\\）で表示されます。そのため、Windows ユーザーは各バックスラッシュ（\\\\）をスラッシュ（/）に変える必要があります。R プロジェクトの設定 の章で詳細を説明する here パッケージを使用する場合は、スラッシュ記号は問題になりません。\n相対パス\n通常、絶対パスの代わりに、「相対パス」でファイルパスを記述することをおすすめします。つまり、R プロジェクトのルートからの相対的なパスです。R プロジェクトの設定 の章で説明されているように、here パッケージを使うと相対パスを書くことができます。「相対パス」のファイルパスは以下のようになります。\n\n# R プロジェクトの data/linelist/clean サブフォルダから csv 形式のラインリストをインポートする\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))\n\nR プロジェクト内で相対パスを使用していても、R プロジェクト外でデータをインポートやエクスポートする際には、絶対パスを使用することができます。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#objects",
    "href": "new_pages/basics.jp.html#objects",
    "title": "3  R の基礎",
    "section": "3.10 オブジェクト",
    "text": "3.10 オブジェクト\nR は「オブジェクト指向 」言語であり、R で使用されるすべてのものはオブジェクトです。このセクションでは、以下の項目について説明します。\n\nオブジェクトの作り方（&lt;-）\nオブジェクトの型（例：データフレーム、ベクトルなど）\nオブジェクトの構成要素にアクセスする方法（例：データセット内の変数）\nオブジェクトのデータ型（例：数字型、ロジカル型、整数型、実数型、文字型、因子型）\n\n\n\nオブジェクト指向\nこのセクションは、R4Epis プロジェクトのウェブサイト を元に作成されました。データセット、変数、村の名前のリスト、総人口の数、さらにはグラフのような出力結果など、R に格納されるものはすべてオブジェクトであり、名前が割り当てられ、後のコマンドから参照可能です。\nオブジェクトは、値を割り当てられた時点で存在します（後述の割り当てのセクションを参照してください）。値が割り当てられると、オブジェクトは Environment ペインに表示されます（RStudio の右上にあります）。割り当てにより、オブジェクトの操作、変更、再定義が可能になります。\n\n\n\nオブジェクトを（&lt;-）で定義する\nR では、&lt;- 演算子によって値を割り当てることでオブジェクトを生成します。 割り当て用の演算子 &lt;- は「〜と定義する」と解釈できます。割り当てコマンドは、通常以下のように書きます。\nオブジェクト名 &lt;- 値 （もしくは、値を生成するプロセスや計算）\n例えば、現在の疫学週を表す値を、後のコードで参照するためにオブジェクトとして格納したいとします。以下の例では、current_week というオブジェクトに \"2018-w10\" という値が割り当てられ、定義されています（値は二重引用符で囲まれているため、文字型として定義されます）。current_week オブジェクトは、 RStudio の右上にある Environment ペインに表示され、以降のコマンドで参照できます。\n以下の R コマンドと出力結果を確認してください。\n\ncurrent_week &lt;- \"2018-W10\"   # 値を割り当てることで current_week オブジェクトを生成する\ncurrent_week                 # コンソールへ current_week オブジェクトの現在の値を出力する\n\n[1] \"2018-W10\"\n\n\n注釈：R コンソールでの [1] という出力は、これが出力の最初の項目であることを単に示しているだけということに注意してください。\n注意：オブジェクトの値を再定義するコマンドを実行することによって、オブジェクトに格納されている値は、上書きされます。 そのため、コマンドを実行する順序が非常に重要になります。\n以下のコマンドは、current_week の値を再定義します。\n\ncurrent_week &lt;- \"2018-W51\"   # current_week オブジェクトに新しい値を割り当てる\ncurrent_week                 # current_week の現在の値をコンソールへ出力する\n\n[1] \"2018-W51\"\n\n\n等号記号 =\nR コード中に等号記号を見かけることもあります。等号記号は以下の場面で使用されています。\n\n2 つのオブジェクトや値の間に置かれた二重等号 == は、論理的な問いかけを示しています。（例：左辺と右辺は等しいか？）\n関数の引数の値を定義するために、関数内で等号が使われている場合もあります（後述のセクションを参照してください）。（例：max(age, na.rm = TRUE)）\nオブジェクトを生成する際に、&lt;- の代わりに単独の等号 = を使うこともできますが、この方法は推奨されていません。こちらのドキュメント に、なぜ推奨されていないかの理由が記載されています。\n\nデータセット\nデータセット（通常は「データフレーム」）もオブジェクトであり、インポートされた際に名前を割り当てる必要があります。以下のコードでは、rio パッケージの import() でインポートされた CSV ファイルの値が linelist と名付けたオブジェクトに割り当てられ、定義されています。\n\n# インポートされた CSV ファイルの値が割り当てられ linelist が生成される\nlinelist &lt;- import(\"my_linelist.csv\")\n\nデータのインポート・エクスポート の章では、データセットのインポートとエクスポートについて更に詳しく説明しています。\n注意： 以下は、オブジェクトの名付けに関する注釈です\n\nオブジェクトの名前は、スペースを含んではいけません。スペースの代わりに、アンダースコア（ _ ）やピリオド（ . ）を使用してください。\nオブジェクトの名前は、大文字と小文字が区別されます（つまり、Dataset_A と dataset_A は別のオブジェクトです）。\nオブジェクトの名前は、英字で始めなければいけません（1, 2, 3 のような数値で始めることはできません）。\n\n出力\n表やプロットのような出力は、出力がオブジェクトとして格納される、または、格納されずに単純に（コンソールに）出力される良い例です。例えば、base R の table() を利用して作成した性別とアウトカムのクロス集計表は、（格納することなく）R コンソールに直接出力することもできます。\n\n# R コンソールのみに出力\ntable(linelist$gender, linelist$outcome)\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nまた、同じ集計表を名前付きオブジェクトとして保存することもできます。保存後に、コンソールに出力することもできます。\n\n# 保存する\ngen_out_table &lt;- table(linelist$gender, linelist$outcome)\n\n# 出力する\ngen_out_table\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\n列\nデータセット内の列も、オブジェクトであり、定義、上書き、生成などが可能です。\n新しい列を作成するために、base R の割り当て演算子（&lt;-）を使用することができます。以下の例では、bmi （Body Mass index）という名前の列を生成しています。そして、生成された bmi 列の各行には、wt_kg 列と ht_cm 列の値を使って計算された結果が値として割り当てられます。\n\n# base R パッケージの構文を利用して、新たに \"bmi\" 列を生成する\nlinelist$bmi &lt;- linelist$wt_kg / (linelist$ht_cm/100)^2\n\n列を生成し定義する方法は他にもあり、このハンドブックでは、上記とは別の方法に重点を置きます。それは、dplyr パッケージの mutate() とパイプ演算子（%&gt;%）を使用したパイプ処理で新しい列を生成することです。この方法で書かれたコードの方が読みやすく、また、データクリーニングと主要関数 の章で説明されているような利点があります。パイプ処理の詳細ついては、以降のパイプ処理セクションで詳しく説明しています。\n\n# dplyr 構文を用いて、新たに \"bmi\" 列を生成する\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\n\n\n\nオブジェクトの構造\nオブジェクトはひとかけらのデータ（例：my_number &lt;- 24）もしくは、構造化されたデータからなります。\n以下の画像は こちらのオンライン R チュートリアル から引用しました。いくつかの一般的なデータ構造とその名前を示しています。空間データは、この図には含まれておらず、GIS の基礎 の章で詳しく説明します。\n\n\n\n\n\n\n\n\n\n疫学領域（特に実地疫学; 訳注: 感染症の疫学調査などを行う領域）においては、とても高頻度でデータフレームやベクトルに出会うでしょう。\n\n\n\n\n\n\n\n\nデータ構造\n説明\n例\n\n\n\n\nVector\nベクトル：一連の単独オブジェクトを格納するもの。格納されている要素のデータ型はすべて同じ。（例：数字型や文字型）\nデータフレームにおいて「変数」（または列）はベクトルである。（例：age_years 列）\n\n\nData Frame\nデータフレーム：すべて同じ数の行を持つベクトル（例：列）を束ねたもの。\nlinelist はデータフレームである。\n\n\n\nなお、（データフレームに属さない）「独立した」ベクトルを作成する場合は、c() を使用して異なる複数の要素を結合する必要があります。例えば、図を作成する際に色付け用のベクトルを作成する場合は、以下のように書きます。\nvector_of_colors &lt;- c(\"blue\", \"red2\", \"orange\", \"grey\")\n\n\n\nオブジェクトのデータ型\nR に保存されているすべてのオブジェクトには、データ型があります。データ型は、R に対してオブジェクトの扱いを示します。取り得るデータ型は無数にありますが、通常は以下に示す範囲です。\n\n\n\nデータ型\n説明\n例\n\n\n\n\nCharacter\n文字型：「二重引用符に囲まれた」テキスト（単語や文章）をとる。文字型のオブジェクトに対しては、計算できない。\n“Character objects are in quotation marks”\n\n\nInteger\n整数型：整数のみ （小数は含まない）をとる。\n-5、14 や 2000\n\n\nNumeric\n数字型：小数を含む数値。二重引用符に囲まれていた場合は、 文字型として扱われる。\n23.1 や 14\n\n\nFactor\n因子型：特定の順序 あるいは、階層構造を持つベクトル\n順序付けられた値を持つ経済状態の変数\n\n\nDate\n日付型：あるデータが、日付であると R に示すと、そのデータは特別な方法で操作や表示ができる。日付型データ の章を参照。\n2018-04-12、15/3/1954 や Wed 4 Jan 1980\n\n\nLogical\nロジカル型：2 つの特別な値 TRUE もしくは FALSE をとる。（二重引用符付きの “TRUE” や “FALSE” ではないことに注意） | TRUE あるいは FALSE\n\n\n\ndata.frame\nデータフレーム型：R が典型的なデータセットを保存する方法。このデータ型は、同じ数の観測値（行）を持つデータのベクトル（列）をまとめたもの。\n例えば、linelist_raw と名付けられた AJS データセットには、68 個の変数と 300 個の観測値（行）が含まれる\n\n\ntibble\ntibble 型：この型は、データフレームの変化形の 1 つで、動作上の違いは、コンソールに整った形で出力されること。（最初の 10 行と、画面に収まる列のみを表示）\nいかなるデータフレーム、リスト、マトリックスは、as_tibble() で tibble 型に変換できる\n\n\nlist\nリスト型：ベクトルと似ているが、別のデータ型のオブジェクトを要素に含むことができる\nリスト型には、1 つの数値、データフレーム、ベクトル、リスト型そのものも格納できる\n\n\n\nclass() にオブジェクトの名前を渡すことで、オブジェクトのデータ型を確認できます。 注釈：データセット内の特定の列を参照するには、データセット名と列名を $ 記号で区切って記述します。\n\nclass(linelist)         # データフレーム型もしくは tibble 型であるべき\n\n[1] \"data.frame\"\n\nclass(linelist$age)     # 数字型であるべき\n\n[1] \"numeric\"\n\nclass(linelist$gender)  # 文字型であるべき\n\n[1] \"character\"\n\n\nときには、R によって列が自動的に別のデータ型に変換されることがありますが、これには注意が必要です！例えば、数値を含む列やベクトルに、文字列が挿入されると…列全体が文字型に変わります。\n\nnum_vector &lt;- c(1,2,3,4,5) # すべてが数値のベクトルを定義\nclass(num_vector)          # ベクトルのデータ型は 数字型\n\n[1] \"numeric\"\n\nnum_vector[3] &lt;- \"three\"   # 3 番目の要素を、文字型の文字列に変更\nclass(num_vector)          # ベクトルのデータ型は、文字型に変わってしまう\n\n[1] \"character\"\n\n\nよくある例としては、データフレームを操作して表を印刷するときに、合計の行を作り、同じセルにパーセンテージを数字として貼り付けようとすると（例：23 (40%)）、数字の列全体が 文字型に変換され、数学的な計算に使用できなくなります。場合によっては、オブジェクトや列を別のデータ型に変換する必要があります。\nよくある例としては、データフレームを操作して表を印刷するときに、合計の行を作り、同じセルにパーセンテージを数字として貼り付けようとすると（例、23 (40%)）、数字の列全体が 文字型に変換され、数学的な計算ができなくなります。場合によっては、オブジェクトや列を別のデータ型に変換する必要があります。\n\n\n\n関数\n動作\n\n\n\n\nas.character()\n文字型に変換する\n\n\nas.numeric()\n数字型に変換する\n\n\nas.integer()\n整数型に変換する\n\n\nas.Date()\n日付型に変換する。注釈：詳細は 日付型データ の章を参照。\n\n\nfactor()\n因子型に変換する。注釈：値の順序の再定義には、追加の引数が必要になる。\n\n\n\n同様に、base R にもオブジェクトのデータ型を調べる一連の関数があります。例：is.numeric(), is.character(), is.double(), is.factor(), is.integer()\nデータ型やデータ構造に関して更に学びたい方は、こちらのドキュメント をご覧ください。\n\n\n\n列および変数（$）\nデータフレーム内の列は、厳密には、「ベクトル」です（上記の表を参照）。ベクトルとは、すべてが同じデータ型（文字型、数字型、ロジカル型など）でなければならない一連の値です。\nベクトルは、データフレームとは独立して存在できます。例えば、モデルに説明変数として含めたい列名のベクトルなどがあります。「独立した」ベクトルを作成するには、以下のように c() を使います。\n\n# 文字型の値を持つ独立したベクトルを定義する\nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# 名前付きベクトルの値を出力する\nexplanatory_vars\n\n[1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\" \n\n\nデータフレーム内の列もベクトルであり、$ 記号を使用して、呼び出し、参照、抽出、生成などができます。 $ 記号は、データフレームの名前と列の名前をつなげるものです。このハンドブックでは、「変数」と言う代わりに「列」という言葉を使うようにしています。\n\n# age_years ベクトルの長さを取得する\nlength(linelist$age) # （age は linelist データフレーム中の列）\n\nデータフレームの名前の後に、$ 記号を入力すると、データフレーム内のすべての列がドロップダウンメニューで表示されます。矢印キーで列をスクロールし、Enter キーで列を選択することができます。この方法で入力すると、スペルミスが防げます！\n\n\n\n\n\n\n\n\n\n応用的なヒント：より複雑なオブジェクト（リストや、epicontacts オブジェクトなど）は、多数の階層を保持している場合があり、複数の $ 記号を使用することでアクセスできます。例：epicontacts$lineline$date_onset\n\n\n\n角括弧（[ ]）で要素を抽出する\nオブジェクトの一部を表示する必要がある際、角括弧 [ ] （またはブラケット記号）がよく使用されます。これは、「インデックス（indexing）」とも呼ばれます。データフレーム上で、$ 記号を使用して列にアクセスするのもインデックスの一種です。\n\nmy_vector &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")  # ベクトルを定義する\nmy_vector[5]                                  # 5 番目の要素を出力する\n\n[1] \"e\"\n\n\n角括弧は、summary() の出力のように、返された出力結果の特定の部分のみを表示したい場合にも使用できます。\n\n# summary をすべて出力\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n# summary の 2 番目の要素のみを、名前とともに出力（角括弧のペアを 1 つだけ使用）\nsummary(linelist$age)[2]\n\n1st Qu. \n      6 \n\n# 2 番目の要素のみを抽出し、要素の名前を含めずに出力（角括弧のペアを二重に使用）\nsummary(linelist$age)[[2]]\n\n[1] 6\n\n# 名前をもとに要素を抽出し、要素の名前を含めずに出力\nsummary(linelist$age)[[\"Median\"]]\n\n[1] 13\n\n\n角括弧はデータフレームでも使用でき、特定の行や列を表示します。以下のように、dataframe[rows, colums] という構文を使用します。\n\n# データセットから特定の行（2行目）のすべての列情報を表示（コンマを忘れずに！）\nlinelist[2,]\n\n# すべての行のある特定の一列の表示\nlinelist[, \"date_onset\"]\n\n# 2 行目の 5 列目から 10 列目の値を表示\nlinelist[2, 5:10] \n\n# 2 行目の 5 列目から 10 列目および 18 列目の値を表示\nlinelist[2, c(5:10, 18)] \n\n# 2 行目から 20 行目の特定の列を表示\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# 条件式に基づいて行と列を表示\n# *** 条件式にはデータフレームの名前が含まれてなければなりません！\nlinelist[linelist$age &gt; 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# View() を使用し、RStudio の Viewer ペインで出力結果を表示する（読みやすい表示）\n# *** View() は大文字 \"V\" であることに注意\nView(linelist[2:20, \"date_onset\"])\n\n# 新しいオブジェクトとして保存\nnew_table &lt;- linelist[2:20, c(\"date_onset\")] \n\nなお、上記の行や列のインデックスは、dplyr の構文（行に対しては filter()、列に対してはselect() ）を使用しても可能です。このような中核となる関数については、データクリーニングと主要関数 の章を参照してください。\n「行番号（row number）」に基づいて行の抽出（フィルタリング）を行うには、dplyr の row_number() を使用し、関数の括弧内は空ままで、filter() 関数内の論理的な条件式の一部に使用します。以下に示すように、多くの場合は、論理的な条件式の一部として、%in% 演算子を使用して数値の範囲を指定します。最初の N 行を表示したい場合は、dplyr の head() という特別な関数を用いることもできます。\n\n# 最初の 100 行を表示\nlinelist %&gt;% head(100)\n\n# 5 行目のみを表示\nlinelist %&gt;% filter(row_number() == 5)\n\n# 2 行目から 20 行目までを、特定の列のみ表示（列名に二重引用符は不要ということに注意）\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nリスト型のオブジェクトをインデックスする場合、単一のオブジェクトしか返さない場合でも、1 つのペアの角括弧を使用してインデックスした場合は常にリスト型が返されます。しかし、2 つのペアの角括弧を使用したインデックスは、単一の要素にアクセスでき、リスト型とは異なるデータ型も返すことができます。\n以下の例で示されるように、複数の角括弧のペアを続けて記述することも可能です。\nリストのインデックスをコショウ入れに例えた こちらのウェブサイト は、図を用いて面白く解説しており、参考になります。\n\n# 例示用のリストを定義\nmy_list &lt;- list(\n  # リストの最初の要素は、文字型のベクトル\n  hospitals = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n  # リストの 2 番目の要素は、複数の住所を含むデータフレーム\n  addresses   = data.frame(\n    street = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n    city   = c(\"Andover\", \"Hamilton\", \"El Paso\")\n    )\n  )\n\n上のコードで定義したリストをコンソールに表示すると、以下のようになります。以下の通りの 2 つの名前付きの要素があることがわかります。\n\nhospitals - 文字型のベクトル\naddresses - 住所のデータフレーム\n\n\nmy_list\n\n$hospitals\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n$addresses\n           street     city\n1 145 Medical Way  Andover\n2  1048 Brown Ave Hamilton\n3   999 El Camino  El Paso\n\n\nいくつかの方法を用いて、抽出してみましょう。\n\nmy_list[1] # \"list\" 型にある要素を返す（要素名はまだ表示される）\n\n$hospitals\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[1]] # （要素名のない）文字型のベクトルが返される\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[\"hospitals\"]] # リスト要素の名前でインデックスを行う\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[1]][3] # \"hospitals\" 文字型のベクトルの 3 番目の要素を返す\n\n[1] \"Santa Anna\"\n\nmy_list[[2]][1] # 住所データフレームの最初の列（\"street\"）を返す\n\n           street\n1 145 Medical Way\n2  1048 Brown Ave\n3   999 El Camino\n\n\n\n\n\nオブジェクトの削除\nrm() の引数に個別のオブジェクトの名前を渡すことで（二重引用符無しで）、R 環境から削除できます。\n\nrm(object_name)\n\nすべてのオブジェクトを削除する（作業ディレクトリを空にする）場合は、以下のコマンドを実行してください。\n\nrm(list = ls(all = TRUE))",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#パイプ演算子とオブジェクト",
    "href": "new_pages/basics.jp.html#パイプ演算子とオブジェクト",
    "title": "3  R の基礎",
    "section": "3.11 パイプ演算子とオブジェクト（%>%）",
    "text": "3.11 パイプ演算子とオブジェクト（%&gt;%）\nオブジェクトを使って作業を行う際に一般的な 2 つのアプローチは、以下の通りです。\n\nパイプ演算子および tidyverse：パイプ演算子を使用して関数から関数へオブジェクトを渡す方法です。つまり、オブジェクトそのものではなく、その動作に重点がおかれます。\n中間オブジェクトを定義する：オブジェクトを何度も再定義する方法です。つまり、オブジェクトそのものに重点が置かれます。\n\n\n\nパイプ処理\n簡潔に説明すると、パイプ演算子（%&gt;%）は、中間オブジェクトを 1 つの関数から次の関数へと渡します。\n会話する時に、「そして」と話をつなげるような役割を持ちます。多く関数は、パイプ演算子（%&gt;%）でつなげることができます。\n\nパイプ処理は、動作が実行されているオブジェクトではなく動作のつながりに重点を置きます。\nパイプ処理は、1 つのオブジェクトに対して、複数の動作を実行する必要がある場面で最適です。\nパイプ処理を行う演算子（%&gt;%）は、dplyr や tidyverse パッケージに同梱されている magrittr パッケージに含まれています。\nパイプ処理は、コードをより整えて読みやすく、かつより直感的に理解できるようにします。\n\nパイプ処理に関する詳細は、tidyverse の スタイルガイド を参照してください。\n以下に、比較のための架空の例として、「ケーキを焼く」動作を紹介します。まずは、パイプ処理の例です。\n\n# パイプ処理で、ケーキを焼く架空の例\n\ncake &lt;- flour %&gt;%       # ケーキを定義する。まず小麦粉を用意して…\n  add(eggs) %&gt;%   # 卵を追加して\n  add(oil) %&gt;%    # 油を追加して\n  add(water) %&gt;%  # 水を追加して\n  mix_together(         # 混ぜる\n    utensil = spoon,\n    minutes = 2) %&gt;%    \n  bake(degrees = 350,   # 焼成する\n       system = \"fahrenheit\",\n       minutes = 35) %&gt;%  \n  let_cool()            # 冷ます\n\nパイプ処理の活用について、他の資料をご覧になりたい方は、こちら をご覧ください。\nパイプ処理は、base R に含まれている関数ではありません。パイプ処理を使用するためには、magrittr パッケージがインストール、読み込まれている必要があります（基本的には、この操作は magritter パッケージを含む tidyverse や dplyr パッケージを読み込むときに行われます）。こちらの magrittr 公式ドキュメント でより詳しくパイプ処理について学ぶことができます。\n他の R コマンドと同様に、パイプ処理は、代入演算子（&lt;-）が含まれていない場合には出力結果を表示するためだけに使用でき、代入演算子（&lt;-）が含まれている場合には、オブジェクトの定義や再定義もできることに注意してください。以下の 2 つの例を参考にしてください。\n\n# オブジェクトを作成または上書きし、年齢カテゴリ別の集計カウントとして利用する（出力されない）\nlinelist_summary &lt;- linelist %&gt;% \n  count(age_cat)\n\n\n# 集計カウント表をコンソールへ出力する。保存はされない。\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\n%&lt;&gt;%\nこれは、magrittr パッケージの「代入パイプ演算子」であり、前方のオプジェクト（左側のオブジェクト）をパイプ演算子で関数に渡し、関数の実行後にまたオブジェクトを再定義します。この演算子は、一連のパイプ処理の最初に置く必要があり、短縮表記として使用できます。以下の 2 つのコマンドは同じ動作を行います。\n\nlinelist &lt;- linelist %&gt;%\n  filter(age &gt; 50)\n\nlinelist %&lt;&gt;% filter(age &gt; 50)\n\n\n\n\n中間オブジェクトの定義\n2 番目のアプローチは、オブジェクトやデータフレームを変更する以下の場合に適している可能性があります。\n\n複数のオブジェクトを操作する必要がある場合\n処理が意味を持ち、別のオブジェクト名にする必要がある中間処理がある場合\n\nリスク：\n\n各処理ごとに新しいオブジェクトを作成することは、多数のオブジェクトを作成することになります。後に、間違ったオブジェクトを使ったとしても気づかない可能性があります！\nすべてのオブジェクトに名前をつけると混乱する可能性があります\nエラーが発生しても簡単には発見できなくなる可能性があります\n\nそれぞれの中間オブジェクトに名前をつけるか、元のオブジェクトを上書きするか、あるいは、すべての関数を組み合わせるか、いずれの選択肢もリスクを伴います。\n以下は、前述の架空の「ケーキを焼く」動作の例です。今回は、中間オブジェクトを利用します。\n\n# 中間オブジェクトを使用する方法で、ケーキを焼く架空の例\nbatter_1 &lt;- left_join(flour, eggs)\nbatter_2 &lt;- left_join(batter_1, oil)\nbatter_3 &lt;- left_join(batter_2, water)\n\nbatter_4 &lt;- mix_together(object = batter_3, utensil = spoon, minutes = 2)\n\ncake &lt;- bake(batter_4, degrees = 350, system = \"fahrenheit\", minutes = 35)\n\ncake &lt;- let_cool(cake)\n\n次に、すべての動作を組み合わせる手法 ですが、この方法は非常に読みにくくなります。\n\n# 組み合わさった、あるいは、ネスト状になった多数の関数 - 判読困難\ncake &lt;- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = \"fahrenheit\", minutes = 35))",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#operators",
    "href": "new_pages/basics.jp.html#operators",
    "title": "3  R の基礎",
    "section": "3.12 重要な演算子と関数",
    "text": "3.12 重要な演算子と関数\nこのセクションでは、以下のような R の演算子について説明します。\n\n代入演算子\n関係演算子（～より少ない、～と等しい、など）\n論理演算子（and や or など）\n欠損値の扱い\n数学的演算子と関数（+/-、&gt;、sum()、median() など）\n%in% 演算子\n\n\n\n代入演算子\n&lt;-\nR の基本的な代入演算子は、&lt;- です。オブジェクト名 &lt;- 値 のように書きます。代入演算子は、= でも書き換え可能ですが、通常は &lt;- 演算子の使用を推奨しています。 また、可読性向上のために、代入演算子の前後にスペースを挿入することを推奨しています。\n&lt;&lt;-\n関数の作成 する時、または、ソーススクリプトでのインタラクティブな R の使用時に、&lt;&lt;- 代入演算子が必要になる可能性があります（base R パッケージに含まれています）。この演算子は、より高次の 親クラスの R 環境（訳注: 複数の環境の関係において上にくる環境）でオブジェクトを定義するために使用されます。こちらの オンラインドキュメント を参照してください。\n%&lt;&gt;%\nこれは、magrittr に含まれる、「代入パイプ演算子」です。この演算子は、前方のオブジェクトを演算子に渡し、そして、前方のオブジェクトを再定義します。パイプ処理の最初の演算子として使用しなければいけません。以下に示した 2 つの例のように、略式記法として機能します。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_months = age_years * 12)\n\n上のコマンドは、下のコマンドと同じ動作を行います。\n\nlinelist %&lt;&gt;% mutate(age_months = age_years * 12)\n\n%&lt;+%\nこの演算子は、ggtree パッケージを使用して、作成済みの系統樹へデータを追加する際に使用します。系統樹 の章もしくは、こちらの オンラインドキュメント を参照してください。\n\n\n\n関係演算子と論理演算子\n関係演算子は、値の比較に用いられ、データセットのサブセットを行う場合や、変数を定義する際によく使用されます。R でよく用いられる関係演算子は、以下の通りです。\n\n\n\n意味\n演算子\n例\n例のコマンドを実行した結果\n\n\n\n\n〜と等しい\n==\n\"A\" == \"a\"\nFALSE （R は大文字小文字を区別するため）注意：==（二重等号）は、代入演算子 &lt;- として働く =（等号）とは区別されます\n\n\n〜と等しくない\n!=\n2 != 0\nTRUE\n\n\n〜より大きい\n&gt;\n4 &gt; 2\nTRUE\n\n\n〜より小さい\n&lt;\n4 &lt; 2\nFALSE\n\n\n〜以上\n&gt;=\n6 &gt;= 4\nTRUE\n\n\n〜以下\n&lt;=\n6 &lt;= 4\nFALSE\n\n\n値が欠損している\nis.na()\nis.na(7)\nFALSE （欠損データの処理 の章を参照ください）\n\n\n値が欠損していない\n!is.na()\n!is.na(7)\nTRUE\n\n\n\nAND や OR などの論理演算子は、関係演算子とともによく用いられます。そして、より複雑な条件式を構築する際に使用されます。複雑な条件式では、複数の条件をグループに分けたり、処理順を明示するために括弧（ ）が必要な場合があります。\n\n\n\n\n\n\n\n意味\n演算子\n\n\n\n\nAND\n&\n\n\nOR\n|（バーティカルバー）\n\n\n括弧\n( ) 複数の条件をグループにまとめたり、演算の処理順を明示したりするために使用されます\n\n\n\n以下の例では、症例定義を作成するために、linelist 内の 2 つの変数を使用します。2 つの変数とは、テスト結果を保持する rdt_result 変数と、家庭内に他の症例があるかのフラグである other_cases_in_home 変数です。以下のコマンドでは、case_when() を使用して、症例定義のための新しい変数である case_def 変数を作成します。\n\nlinelist_cleaned &lt;- linelist %&gt;%\n  mutate(case_def = case_when(\n    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,\n    rdt_result == \"Positive\"                                 ~ \"Confirmed\",\n    rdt_result != \"Positive\" & other_cases_in_home == \"Yes\"  ~ \"Probable\",\n    TRUE                                                     ~ \"Suspected\"\n  ))\n\n\n\n\n\n\n\n\n上の例での条件\n新しい “case_def” 変数に割り当てられた値\n\n\n\n\nrdt_result 変数と other_cases_in_home 変数の値が欠損している\nNA（欠損）\n\n\nrdt_result 変数の値が、“Positive” である\n“Confirmed”\n\n\nrdt_result 変数の値が、“Positive” ではなく、かつ、other_cases_in_home 変数の値が “Yes” である\n“Probable”\n\n\n上記の条件のいずれか 1 つに合致しない\n“Suspected”\n\n\n\nR は大文字と小文字を区別するので、“Positive” と “positive” は異なる値として解釈することに注意してください！\n\n\n\n欠損値\nR では、欠損している値は特別な値 NA（「予約語」）で定義されています（二重引用符で囲まれた大文字の N と A ではありません）。もし別の方法で欠損値が表されたデータ（例：99、“Missing”、や ピリオドで表された欠損値）をインポートする場合、それらの値を NA に置き換えたくなるでしょう。置き換えの方法は、データのインポート・エクスポート の章を参照してください。\n値が NA であるかどうかを確認するには、is.na() という特別な関数を使用します。この関数は、 TRUE もしくは、FALSE を返します。\n\nrdt_result &lt;- c(\"Positive\", \"Suspected\", \"Positive\", NA)   # 2 例の陽性症例、1 例の疑い症例、1 例の不明症例\nis.na(rdt_result)  # rdt_result 変数の値が NA であるかを確認する\n\n[1] FALSE FALSE FALSE  TRUE\n\n\n欠損値や、無限（infinite）、NULL や不可能値については、欠損データの処理 の章を参照してください。データのインポート時に欠損値を変換する方法を学ぶには、データのインポート・エクスポート の章をご覧ください。\n\n\n\n数学と統計\nこのセクションに記載されているすべての演算子と関数は、base R パッケージを使用することで自動的に利用可能になります。\n\n算術演算子\n算術演算子は、加算や除算の際や、新しい列の追加の際などによく用いられます。以下は、R において共通に用いられる算術演算子です。演算子の前後に半角スペースを挿入するかどうかは、重要ではありません。\n\n\n\n目的\nR での例\n\n\n\n\n加算\n2 + 3\n\n\n減算\n2 - 3\n\n\n乗算\n2 * 3\n\n\n除算\n30 / 5\n\n\nべき乗\n2^3\n\n\n演算子の処理順\n( )\n\n\n\n\n\n算術演算子\n\n\n\n\n\n\n\n目的\n関数\n\n\n\n\n丸め（訳注: 四捨五入ではない）\nround(x, digits = n)\n\n\n丸め（訳注: 四捨五入）\njanitor::round_half_up(x, digits = n)\n\n\nceiling（切り上げ）\nceiling(x)\n\n\nfloor（切り捨て）\nfloor(x)\n\n\n絶対値\nabs(x)\n\n\n二乗根\nsqrt(x)\n\n\nべき乗\nexponent(x)\n\n\n自然対数\nlog(x)\n\n\nlog10（常用対数）\nlog10(x)\n\n\nlog2（二進対数）\nlog2(x)\n\n\n\n注釈：round() の digits = 引数は、小数点以下の桁数を指定します。signif() を使用すると、有効数字に丸めることができます。\n\n\n科学的数法\n科学的数法が使われるかどうかは、scipen オプションの値に依存します。\n?options のヘルプドキュメントより：scipen は、数値を固定記法または指数記法のいずれで出力するかを決定する際に適用されるペナルティ値です。正の値の場合は固定記法に、負の値の場合は科学的記法で出力されます。つまり、適用される数値が scipen 桁幅以上ではない場合に固定記法が優先されます。\nscipen オプションが少ない数値（例：0）に設定されている場合、常に「適用」されます。現在の R セッションで科学的数法を「適用しない」ようにしたい場合は、このオプションの値を非常に大きい値に設定します。例えば、以下のように設定します。\n\n# 科学的数法を適用しない\noptions(scipen=999)\n\n\n\n丸め\n要注意： round() 関数は、「銀行型丸め」（訳注: 最接近偶数への丸め）を行います。つまり、（端数が0.5の場合は）1 つ上の数が偶数である場合のみ、切り上げます。常に四捨五入したい場合は、junitor パッケージの round_half_up() を使用してください。詳しくは、こちらのドキュメントをご覧ください。\n\n# あなたの意図に適した丸めを実行してください\nround(c(2.5, 3.5))\n\n[1] 2 4\n\njanitor::round_half_up(c(2.5, 3.5))\n\n[1] 3 4\n\n\n\n\n統計関数\n注意： 以下の関数は、デフォルトの設定では、計算時に欠損値を含めます。欠損値は、na.rm = TRUE 引数を指定しない限り、出力時に NA が結果として出力されます。省略記法では、na.rm = T と記述されます。\n\n\n\n目的\n関数\n\n\n\n\nmean（平均値）\nmean(x, na.rm=T)\n\n\n中央値\nmedian(x, na.rm=T)\n\n\n標準偏差\nsd(x, na.rm=T)\n\n\n分位数*\nquantile(x, probs)\n\n\n総和\nsum(x, na.rm=T)\n\n\n最小値\nmin(x, na.rm=T)\n\n\n最大値\nmax(x, na.rm=T)\n\n\n数値の範囲\nrange(x, na.rm=T)\n\n\n要約統計量**\nsummary(x)\n\n\n\n注釈：\n\n*quantile()： x 変数は、分位数を計算する対象の数値ベクトルです。probs = 引数には、0 から 1.0 の範囲で確率に対応する数値ベクトルを指定できます。（例：c(0.5, 0.8, 0.05)）\n**summary()： この関数は、数値ベクトルの平均値、中央値、共通の分位数を含む統計的要約を出力します。\n\n要注意：上記の関数に数値ベクトルを渡す場合は、数値を c() 関数で囲んでいることを確認してください。\n\n# 生の数値を関数に渡す場合、c() 関数で囲む\nmean(1, 6, 12, 10, 5, 0)    # ！！！間違った表記！！！\n\n[1] 1\n\nmean(c(1, 6, 12, 10, 5, 0)) # 正しい表記\n\n[1] 5.666667\n\n\n\n\nその他に有用な関数\n\n\n\n\n\n\n\n\n目的\n関数\n例\n\n\n\n\n連続する数値を作成する\nseq(開始, 終了, 間隔)\nseq(1, 10, 2)\n\n\nx を n 回繰り返す\nrep(x, n 回)\nrep(1:3, 2) or rep(c(\"a\", \"b\", \"c\"), 3)\n\n\n数値ベクトルを区切る\ncut(x, n)\ncut(linelist$age, 5)\n\n\n無作為（ランダム）にサンプルを取得する\nsample(x, size)\nsample(linelist$id, size = 5, replace = TRUE)\n\n\n\n\n\n\n\n%in%\n値のマッチング（ベクトルやデータフレーム内に値があるかどうか）をすばやく評価するために非常に有用な演算子です。\n\nmy_vector &lt;- c(\"a\", \"b\", \"c\", \"d\")\n\n\n\"a\" %in% my_vector\n\n[1] TRUE\n\n\"h\" %in% my_vector\n\n[1] FALSE\n\n\nある値がベクトル内 %in% に無いかどうかを確かめるためには、論理式の直前に感嘆符（!）をつけます。\n\n# 論理式を否定する場合は、直前に感嘆符を置く\n!\"a\" %in% my_vector\n\n[1] FALSE\n\n!\"h\" %in% my_vector\n\n[1] TRUE\n\n\n%in% は、dplyr の case_when() を使用する際にとても便利です。前もってベクトルを定義しておくと、後ほどそれを参照できます。例えば、以下のように使用します。\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist &lt;- linelist %&gt;% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age &lt; 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\n\n注釈：stringr パッケージの str_detect() を使用して、文字列の一部を検出したい場合、c(\"1\", \"Yes\", \"yes\", \"y\") のような文字ベクトルは引数として渡せません。代わりに、正規表現で書かれた “1|Yes|yes|y” のように、OR バー演算子（|）で構成された文字列を与えなければなりません。例えば、str_detect(hospitalized, \"1|Yes|yes|y\") のように記述します。詳しくは、文字型・文字列型データ の章を参照してください。\n文字ベクトルを、以下のコマンドで名前付きの正規表現に変換可能です。\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative\n\n[1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\" \n\n# コンデンスを実行\naffirmative_str_search &lt;- paste0(affirmative, collapse = \"|\")  # base R を使用\naffirmative_str_search &lt;- str_c(affirmative, collapse = \"|\")   # stringr を使用\n\naffirmative_str_search\n\n[1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\"",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.jp.html#エラーと警告",
    "href": "new_pages/basics.jp.html#エラーと警告",
    "title": "3  R の基礎",
    "section": "3.13 エラーと警告",
    "text": "3.13 エラーと警告\nこのセクションでは以下について解説します。\n\nエラー（error）と警告（warning）の違い\nR コードを書く際の一般的な構文のヒント\nコードアシスト機能\n\nよくあるエラーと警告、そしてトラブルシューティングのヒントを知りたい方は、よくあるエラー の章をご覧ください。\n\n\nエラーと警告\nコマンドを実行すると、R コンソールが赤い文字で警告やエラーメッセージを表示するかもしれません。\n\n警告（warning） は、R はコマンドの実行を完了したが、追加のステップが必要もしくは、実行者が知るべき、通常にはない出力があることを意味します。\nエラー（error） は、R はコマンドの実行を完了できなかったことを意味します。\n\n解決のための手がかりを探す際には、以下を参考にしてください。\n\nエラーや警告メッセージは、通常、何行目で問題が発生しているかを教えてくれます。\nオブジェクトが、“is unknown” や、“not found” であると表示されているならば、オブジェクトの名前が間違っている（スペルミスなど）可能性や、library() でパッケージを読み込んでいない可能性、または、スクリプトに変更を加えたがスクリプトを再実行していない可能性が考えられます。\n\nそれでも解決できない場合は、エラーメッセージをいくつかのキーワードとともにコピーして Google で検索してください。すでに他の誰かが解決しているかもしれません！\n\n\n\n一般的な構文のヒント\nR でコマンドを記述する際にエラーや警告を発生させないために、知っておくとよい点を以下にいくつか挙げます。\n\n常に括弧を閉じる。ヒント：各コードチャンクで開き括弧 “(” と閉じ括弧 “)” の数を数える。\n列やオブジェクトの名前にはスペースを入れない。代わりにアンダースコア（ _ ）や、ピリオド（ . ）を使用する。\n関数の引数をコンマで区切ることを意識し、念頭に置く。\nR は大文字と小文字を区別するため、Variable_A と variable_A は区別される。\n\n\n\n\nコードアシスタント機能\nいかなるスクリプトでも（RMarkdown やそれ以外でも）、もしコードに誤りがあった場合は、スクリプトが誤りを解決する手がかりを提示してくれます。例えば、コンマが必要な箇所に入力を忘れた場合や、括弧を閉じ忘れた場合、RStudio は対象の行の右側に警告用のフラグを立てます。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R の基礎</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.jp.html",
    "href": "new_pages/transition_to_R.jp.html",
    "title": "4  Excel・Stata・SASとの比較",
    "section": "",
    "text": "4.1 Excel からの移行\nExcel から R への移行は、非常に達成しやすい目標です。気が遠くなるかもしれませんが、あなたならできます！\n確かに、Excel のスキルに長けていれば、VBA のようなスクリプトツールを使用して、Excel だけで非常に高度な操作を実行できます。Excel は世界中で使用されており、疫学者や疫学業務担当者にとって不可欠なツールです。しかし、R で補完することで、ワークフローを劇的に改善し、拡張することができます。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Excel・Stata・SASとの比較</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.jp.html#excel-からの移行",
    "href": "new_pages/transition_to_R.jp.html#excel-からの移行",
    "title": "4  Excel・Stata・SASとの比較",
    "section": "",
    "text": "メリット\nR を使用すると、時間の節約、より一貫性のある正確な分析、再現性、共有性、および迅速なエラーの修正という点で大きな利点があります。他の新しいソフトウェアと同じように、慣れ親しむために投資しなければならない時間の「学習曲線」があります。しかし、R を使うことで得られるメリットは非常に大きく、R によって新たな可能性が開かれるでしょう。\nExcel はよく知られたソフトウェアで、初心者でもカーソル操作で簡単に簡素な解析と視覚化を行うことができます。それに比べて、R の機能やインターフェースを快適に使えるようになるには数週間かかるかもしれません。しかし、近年、R は初心者にも使いやすいように進化しています。\n多くの Excel ワークフローはメモリと反復に依存しているため、エラーが発生する可能性が高くなります。さらに、一般的には、データのクリーニング履歴、解析方法、および使用されている方程式は表示されません。新しい仕事仲間が Excel ブックの動作とそのトラブルシューティング方法を習得するには、かなりの時間がかかります。R を使用すると、すべてのステップがスクリプトに明示的に書き込まれ、簡単に表示、編集、修正、および他のデータセットへの適用が可能になります。\nExcel から R への移行を始めるにあたり、いくつか重要な点で、基本的に考え方を変える必要があります。以下に詳しく説明していきます。\n\n\nデータの整理\n「人間だけが読める」乱雑なデータの代わりに、機械で可読なきちんとした「整然（tidy）」データを使用します。こちらの R の「整然」データに関するチュートリアル で説明されているように、「整然」データには主に以下の 3 つの要件があります。\n\n各変数がそれぞれ独自の列となっていること\n各観測値がそれぞれ独自の行となっていること\n各値がそれぞれ独自のセルとなっていること\n\nExcel ユーザーの方は、Excel の「表」 が担う、データを標準化して書式を予測しやすくする役割と同じように捉えてください。\n「整然」データの例としては、このハンドブックを通して使用されている症例リスト（linelist）が挙げられます。各変数はそれぞれ 1 列で表され、各観測値（症例）は独自の行を持ち、各値はそれぞれ 1 つのセルに収められています。以下に、症例リストの最初の 50 行を表示します。\n\n\n\n\n\n\n整然としないデータに遭遇する主な理由は、多くの Excel スプレッドシートが、機械やソフトウェアによる読みやすさではなく、人間にとっての読みやすさを優先するように設計されているためです。\nこの違いを理解しやすくするために、人間の可読性を機械の可読性より優先した整然としないデータの架空の例を以下に示します。\n例 1：\n\n\n\n\n\n\n\n\n\n問題点：上のスプレッドシートには、R が解読しにくい結合されたセルがあります。どの行を「ヘッダ」と見なすかが、明確ではありません。右側には色付けされた辞書があり、セルの値は色で表されますが、これも R は簡単に解釈できません（また、色覚多様性への配慮も欠けています！）。さらに、異なる情報が 1 つのセルにまとめられているのも問題です（複数の組織が1 つの領域で作業している、または「TBC」というステータスが「パートナー D」と同じセルにある）。\n例 2：\n\n\n\n\n\n\n\n\n\n問題点：上のスプレッドシートでは、データセット内に空の行と列が多数あります。これは、R でクリーニングする際に頭痛の種になります。さらに、GPS 座標は、1 つの施設につき、2 つの行に書かれています。その上、GPS 座標は 2 つの形式で書かれています！\n「整然」データセットは人間の目には読みにくいかもしれませんが、データのクリーニングと分析を簡単にしてくれます！整然データは、例えば「縦型」や「横型」（詳しくは、データの縦横変換 の章を参照ください）など、さまざまな形式で格納できますが、上記の原則は守られています。\n\n\n関数\nR の単語「関数」は新しいかもしれませんが、この概念は Excel にも数式として存在します。Excel の数式も、セミコロンと括弧の配置など、正確な構文で書かれている必要があります。R の関数を学ぶにあたって必要なのは、いくつかの新しい機能と、それらが R でどのように連携するかを学ぶことだけです。\n\n\nスクリプト\nR では、ボタンをクリックしてセルをドラッグする代わりに、すべての処理順と処理内容を「スクリプト」に書きます。Excel ユーザーは、スクリプトによって処理する「VBA マクロ」と同じように捉えるとわかりやすいでしょう。\nR のスクリプトは、段階的な手順で構成されています。これにより、第三者がスクリプトを読んだ際、あなたがどのような手順を実行したか簡単に確認でき、デバッグ（エラーや間違った計算の修正）にも役立ちます。R の基礎 の章で説明されている例をご覧ください。\nここでは、Rスクリプトの一例を紹介します。\n\n\n\n\n\n\n\n\n\n\n\nExcel から R への移行に関するリソース\n以下に、Excel から R へ移行する際に役立つ資料を紹介します。\n\nR と Excel の違い\n\nExcel ユーザー向け、RStudio を使用した R の使い方\n\n\n\nR と Excel の相互干渉\nR には、Excel ブックのインポートおよびデータの操作、Excel ファイルのエクスポートや保存、また Excel シートの操作に十何位対応する方法が複数あります。\nイタリック体や補足のためのテキストなど、見た目を美しくする Excel の書式設定の一部は、翻訳時に失われる可能性があります。ワークフローで、元の Excel フォーマットを保持したまま R と Excel の間でドキュメントをやり取りする必要がある場合は、openxlsx などのパッケージをお試しください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Excel・Stata・SASとの比較</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.jp.html#stata-からの移行",
    "href": "new_pages/transition_to_R.jp.html#stata-からの移行",
    "title": "4  Excel・Stata・SASとの比較",
    "section": "4.2 Stata からの移行",
    "text": "4.2 Stata からの移行\n\nStata から R へ\n多くの疫学者や疫学業務担当者は、最初に Stata の使い方を教わっており、R へ移行するのが難しく感じるかもしれません。しかし、もしあなたが Stata を快適に使用しているのであれば、R への移行はあなたが考えているよりも確実に行いやすいでしょう。Stata と R の間には、データの作成方法と変更方法、および分析機能の実装方法に関していくつか重要な違いがありますが、このような重要な違いを学習すると、あなたの Stata スキルを R で使用できるようになります。\n以下に Stata と R の主な違いをいくつか紹介します。\n一般的な注意事項\n\n\n\nSTATA\nR\n\n\n\n\n一度に表示および操作できるデータセットは 1 つのみ。\n複数のデータセットを同時に表示および操作できるため、多くの場合、コード内でデータセットを指定する必要がある。\n\n\n利用可能なオンラインコミュニティは、https://www.statalist.org/\n利用可能なオンラインコミュニティは、RStudio,、StackOverFlow、R-bloggers\n\n\nカーソル＆クリック機能をオプションで提供。\n最小限のカーソル＆クリック機能。\n\n\nhelp [command] コマンドでヘルプが利用できる。\n[function]? コマンドでヘルプが利用でき、ヘルプウィンドウで検索を行える。\n\n\nコードをコメント化する際には、* または /// または /*TEXT*/ を使用する。\n# を使用してコードをコメント化する。\n\n\nほとんどすべてのコマンドは Stata に組み込まれている。新しい関数やユーザーが作成した関数は、ssc install [package] を使用して ado ファイルとしてインストールできる。\nR は基本的な関数である base と一緒にインストールされるが、一般的な使用方法では、CRAN から他のパッケージをインストールする必要がある（R の基礎 の章を参照） 。\n\n\n分析用のコードは通常、do ファイルに書き込まれる。\n分析用のコードは、R Studioの source ペインで R スクリプトに書かれる。R Markdown に書く方法もあり。\n\n\n\n作業ディレクトリ\n\n\n\nSTATA\nR\n\n\n\n\n作業ディレクトリは絶対ファイルパスで表される。（例：“C:/usename/documents/projects/data/”）\n作業ディレクトリは、絶対ディレクトリにすることも、here パッケージを使用してプロジェクトのルートフォルダからの相対ディレクトリにすることもできる（データのインポート・エクスポート の章を参照）。\n\n\npwd で現在の作業ディレクトリを参照する。\ngetwd() または here()（here パッケージを使用している場合）で参照する。\n\n\ncd “フォルダの場所”で作業ディレクトリを設定する。\nsetwd(“フォルダの場所”)、または set_here(\"フォルダの場所\")（ here パッケージを使用する場合）で設定する。\n\n\n\nデータのインポートと表示\n\n\n\nSTATA\nR\n\n\n\n\nファイルタイプごとに専用のコマンドがある。\nほとんどの種類のファイルに対して、rio パッケージの import() を使用できる。特定の種類のファイルを扱う代替の関数もある（データのインポート・エクスポート の章を参照）。\n\n\ncsv ファイルの読み込みは、 import delimited “filename.csv” で行う。\nimport(\"filename.csv\") を使用。\n\n\nxslxファイルの読み込みは、 import excel “filename.xlsx” で行う。\nimport(\"filename.xlsx\") を使用。\n\n\nbrowse コマンドを使用して、新しいウィンドウでデータを閲覧できる。\nView(dataset) を使用して、RStudio の soruce ペインでデータセットを表示できる。R は複数のデータセットを同時に保持できるため、View() 関数の括弧内でデータセット名を指定する必要がある。また、関数名は大文字「V」で始まることに注意。\n\n\n変数名と基本情報を提供する summarize を使用してデータセットの概要を取得できる。\nsummary(dataset) を使用してデータセットの概要を取得できる。\n\n\n\n基本的なデータ操作\n\n\n\nSTATA\nR\n\n\n\n\nデータセット列は、多くの場合「変数」と呼ばれる。\nより一般的には 「列」 と呼ばれ、場合によっては 「ベクトル」 または 「変数」 と呼ばれます。\n\n\nデータセットを指定する必要がない。\n各コマンドで、データセットを指定する必要がある。例を確認したい場合は、データクリーニングと主要関数 の章を参照してください。\n\n\n新しい変数を作成する場合は、コマンド generate varname = を使用する。\n関数 mutate(varname = ) を使用して新しい変数を作成できる。dplyr 関数の詳細は、データクリーニングと主要関数 の章を参照してください。\n\n\n変数名を変更する場合は、rename old_name new_name を使用する。\nrename(new_name = old_name) 関数を使用して列の名前を変更できる。\n\n\n変数を削除する場合は、drop varname を使用する。\nselect() でマイナス記号と削除したい列名を括弧内に書き、変数を削除することができる。\n\n\n因子型の変数にラベルを付ける場合は、 label define などのコマンドを使用する。\n値をラベル付けしたい場合は、対象の列を因子型に変換し、レベルを指定する。詳しくは、因子（ファクタ）型データ の章をご参照ください。R では通常、Stata のように列名をラベル付けすることはしません。\n\n\n\n記述的分析\n\n\n\nSTATA\nR\n\n\n\n\n変数のカウントを表示したい場合は、tab varname を使用する。\ntable(dataset$colname) のように、 table() にデータセット名と列名を指定する。または、データのグループ化 の章で説明するように、 dplyr パッケージの count(varname) を使用する方法もある。\n\n\n2x2 テーブルのような 2 つの変数のクロス集計表の作成には、tab varname1 varname2 を使用する。\ntable(dataset$varname1, dataset$varname2 または count(varname1, varname2) を使用する。\n\n\n\n上の一覧表では、Stata コマンドを R に変換する概要を説明しましたが、すべてを網羅しているわけではありません。Stata ユーザーが R に移行する上で役立つ資料は他にもたくさんあり、以下にいくつか紹介します。\n\nhttps://dss.princeton.edu/training/RStata.pdf\n\nhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.html\n\nhttp://r4stats.com/books/r4stata/",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Excel・Stata・SASとの比較</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.jp.html#sas-からの移行",
    "href": "new_pages/transition_to_R.jp.html#sas-からの移行",
    "title": "4  Excel・Stata・SASとの比較",
    "section": "4.3 SAS からの移行",
    "text": "4.3 SAS からの移行\n\nSASから R への移行\nSAS は公衆衛生機関や学術研究分野で一般的に使用されています。新しい言語への移行は簡単ではありませんが、SAS と R の主要な違いを理解することは、すでに習得済みの言語を使用して新しい言語を操作するのに役立ちます。SAS と R の間のデータ管理および記述分析における主な違いについて、概要を以下に示します。\n一般的な注意事項\n\n\n\nSAS\nR\n\n\n\n\n利用可能なオンラインコミュニティは、SAS Customer Support\n利用可能なオンラインコミュニティは、RStudio,、StackOverFlow、R-bloggers\n\n\nhelp [command] コマンドでヘルプを利用できる。\n[function]? コマンドでヘルプが利用でき、ヘルプウィンドウで検索を行える。\n\n\n* TEXT ; または /* TEXT */ を使ってコードをコメント化できる。\n# を使用してコードをコメント化する。\n\n\nほとんどすべてのコマンドは SAS に組み込まれている。ユーザーは、SAS マクロ、 SAS/IML、 SAS Component Language (SCL)、および最近では、プロシージャ Proc Fcmp と Proc Proto を使用して新しい関数を作成できる。\nR は基本的な関数である base と一緒にインストールされるが、一般的な使用方法では、CRAN から他のパッケージをインストールする必要がある（R の基礎 の章を参照） 。\n\n\n分析は通常、Editor ウィンドウで SAS プログラムを書くことで実行される。\n分析用のコードは、R Studioの source ペインで R スクリプトに書かれる。R Markdown に書く方法もあり。\n\n\n\n作業ディレクトリ\n\n\n\nSAS\nR\n\n\n\n\n作業ディレクトリは、 %let rootdir=/root path; %include “&rootdir/subfoldername/filename” を使用してルートフォルダを定義することで、絶対的またはプロジェクトのルートフォルダからの相対的に指定することができる。\n作業ディレクトリは、絶対ディレクトリにすることも、here パッケージを使用してプロジェクトのルートフォルダからの相対ディレクトリにすることもできる（データのインポート・エクスポート の章を参照）。\n\n\n現在の作業ディレクトリは、%put %sysfunc(getoption(work)); で参照できる。\ngetwd() または here()（hereパッケージを使用している場合）で参照する。\n\n\n作業ディレクトリは、libname “フォルダ場所” で設定できる。\nsetwd(“フォルダの場所”)、または set_here(\"フォルダの場所\")（ here パッケージを使用する場合）で設定する。\n\n\n\nデータのインポートと表示\n\n\n\nSAS\nR\n\n\n\n\nProc Import プロシージャを使用するか、 Data Step Infile ステートメントを使用してインポートする。\nほとんどの種類のファイルに対して、rio パッケージの import() を使用できる。特定の種類のファイルを扱う代替の関数もある（データのインポート・エクスポート の章を参照）。\n\n\ncsv ファイルの読み込みは、 Proc Import datafile=”filename.csv” out=work.filename dbms=CSV; run; または Data Step Infile statement を使用することで行うことができる。\nimport(\"filename.csv\") を使用。\n\n\nxslx ファイルの読み込みは、 Proc Import datafile=”filename.xlsx” out=work.filename dbms=xlsx; run; または Data Step Infile statement を使用することで行うことができる。\nimport(\"filename.xlsx\") を使用。\n\n\nデータを閲覧する際は、Explorer ウィンドウを開いて、対象のライブラリとデータセットを選択し、新しいウィンドウで閲覧する。\nView(dataset) を使用して、RStudio の soruce ペインでデータセットを表示できる。R は複数のデータセットを同時に保持できるため、View() 関数の括弧内でデータセット名を指定する必要がある。また、関数名は大文字「V」で始まることに注意。\n\n\n\n基本的なデータ操作\n\n\n\nSAS\nR\n\n\n\n\nデータセット列は、多くの場合「変数」と呼ばれる。\nより一般的には 「列」 と呼ばれ、場合によっては 「ベクトル」 または 「変数」 と呼ばれます。\n\n\n新しい変数を作成する際には、特別な手順は必要なく、新しい変数名、等号、値の式の順に入力する。\n関数 mutate(varname = ) を使用して新しい変数を作成できる。dplyr 関数の詳細は、データクリーニングと主要関数 の章を参照してください。\n\n\n変数名を変更する場合は、rename *old_name=new_name* を使用する。\nrename(new_name = old_name) 関数を使用して列の名前を変更できる。\n\n\n変数を保持・選択する場合は、**keep**=varname を使用する。\nselect() の括弧内に保持したい変数名を書き、変数を選択することができる。\n\n\n変数を削除する場合は、**drop**=varname を使用する。\nselect() でマイナス記号と削除したい列名を括弧内に書き、変数を削除することができる。\n\n\n因子型の変数は、 Label ステートメントを使用して Data Step 内でラベル付けできる。\n値をラベル付けしたい場合は、対象の列を因子型に変換し、レベルを指定する。詳しくは、因子（ファクタ）型データ の章をご参照ください。R では通常、Stata のように列名をラベル付けすることはしません。\n\n\n観測値や行は、Data Step の Where または If ステートメントを使用して選択できる。選択条件が複数ある場合は、“and” コマンドで区切る。\nfilter() の括弧内に AND 演算子（&）またはコンマで区切られた複数の選択条件を指定し、観測値や行を選択できる。\n\n\nデータセットは、Data Step の Merge ステートメントを使用して結合できる。マージするデータセットは、最初に Proc Sort プロシージャを使用して並び替える必要がある。\ndplyr パッケージには、データセットをマージするための関数が複数ある。詳細は、データの結合 の章を参照ください。\n\n\n\n記述的分析\n\n\n\nSAS\nR\n\n\n\n\nデータセットの概要を確認するには、変数名と記述統計を表示する Proc Summary プロシージャを使用する。\nskimr パッケージの summary(dataset) または skim(dataset) を使用してデータセットの概要を取得できる。\n\n\n変数のカウントを表にするには、proc freq data=Dataset; Tables varname; Run; を使用する。\n記述統計表の作り方 の章を参照してください。base R の table() や janitor パッケージの tabyl() など複数の方法があります。Rは複数のデータセットを保持するため、関数を使用する際はデータセットと列名を指定する必要があることに注意してください。\n\n\n2x2 テーブルのような 2 つの変数のクロス集計表を作成するには、 proc freq data=Dataset; Tables rowvar*colvar; Run; を使用する。\n上と同様に、 table()、 tabyl() または 記述統計表の作り方 の章で説明されている方法を使用する。\n\n\n\n参考資料:\nR for SAS and SPSS Users (2011)\nSAS and R, Second Edition (2014)",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Excel・Stata・SASとの比較</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.jp.html#データの相互運用性",
    "href": "new_pages/transition_to_R.jp.html#データの相互運用性",
    "title": "4  Excel・Stata・SASとの比較",
    "section": "4.4 データの相互運用性",
    "text": "4.4 データの相互運用性\n\nR の rio パッケージで STATA .dta ファイル、SAS .xpt および .sas7bdat ファイル、 SPSS .por および .sav などのファイルをインポートまたはエクスポートする方法については、データのインポート・エクスポート の章をご覧ください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Excel・Stata・SASとの比較</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.jp.html",
    "href": "new_pages/packages_suggested.jp.html",
    "title": "5  推奨パッケージ",
    "section": "",
    "text": "5.1 CRAN のパッケージ\n##########################################\n# 疫学業務に役立つRパッケージの一覧      #\n##########################################\n\n# 本スクリプトは pacman R パッケージの p_load() を使用する。\n# p_load() は、まだインストールされていないパッケージをインストール・読み込み、すでにインストールされているパッケージは読み込みのみ行われる。\n\n\n# pacman パッケージがインストールされていることを確認する\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# CRAN から入手可能なパッケージ\n##############################\npacman::p_load(\n     \n     # Rを学ぶ\n     ############\n     learnr,   # R Studio チュートリアル画面でRをインタラクティブに学ぶ\n     swirl,    # Rコンソールでインタラクティブに学ぶ\n        \n     # プロジェクトとファイルの管理\n     #############################\n     here,     # Rのプロジェクトフォルダを基準とするファイルパス\n     rio,      # 様々なタイプのデータのインポート・エクスポート\n     openxlsx, # 複数のシートを有するExcelファイルのインポート・エクスポート \n     \n     # パッケージのインストールと管理\n     ################################\n     pacman,   # パッケージのインストール・読み込み\n     renv,     # グループで作業する際のパッケージのバージョン管理\n     remotes,  # githubからのインストール\n     \n     # 一般的なデータ管理\n     #########################\n     tidyverse,    # データを整理して表示するための多くのパッケージが含まれる\n          #dplyr,      # データ管理\n          #tidyr,      # データ管理\n          #ggplot2,    # データのグラフ化\n          #stringr,    # 文字列や文字の操作\n          #forcats,    # 因子を扱う \n          #lubridate,  # 日付を扱う\n          #purrr       # 反復処理とリストの操作\n     linelist,     # ラインリストの整理\n     naniar,       # 欠損値の評価\n     \n     # 統計  \n     ############\n     janitor,      # 表とデータの整理\n     gtsummary,    # 記述的および統計的表の作成\n     rstatix,      # 統計的検定と要約の実行\n     broom,        # 回帰結果の整理\n     lmtest,       # 尤度比検定\n     easystats,\n          # parameters, # 回帰結果整理のための代替パッケージ\n          # see,        # フォレストプロット作成のための代替パッケージ\n     \n     # 疫学モデリング\n     ###################\n     epicontacts,  # 伝播ネットワークの分析\n     EpiNow2,      # Rtの推定\n     EpiEstim,     # Rtの推定\n     projections,  # 発生率の予測\n     incidence2,   # 流行曲線（エピカーブ）の作成と発生データの処理\n     i2extras,     # incident2パッケージの追加関数\n     epitrix,      # 有用な疫学関数\n     distcrete,    # 離散遅延分布\n     \n     \n     # 図 - 一般\n     #################\n     #ggplot2,         # tidyverseパッケージに含まれる\n     cowplot,          # 図を組み合わせる  \n     # patchwork,      # 図を組み合わせる (代替パッケージ)     \n     RColorBrewer,     # カラースケール\n     ggnewscale,       # 配色レイヤーの追加\n\n     \n     # 図 - 特定のタイプ\n     ########################\n     DiagrammeR,       # DOT言語を使用した図\n     incidence2,       # 流行曲線（エピカーブ）\n     gghighlight,      # データの一部をハイライトする\n     ggrepel,          # ラベルの重なりを防ぐ\n     plotly,           # インタラクティブな図を作成する\n     gganimate,        # アニメーションを作成する\n\n     \n     # 地理情報システム(GIS)\n     ######\n     sf,               # SimpleFeature形式を使用して空間データを管理する\n     tmap,             # シンプルな地図の作成（動的・静的地図の両方で機能）\n     OpenStreetMap,    # ggplotマップにOSMベースマップを追加する\n     spdep,            # 空間統計 \n     \n     # 文書の作成\n     #################\n     rmarkdown,        # PDF、Word文書、パワーポイント、およびHTMLファイルの作成\n     reportfactory,    # Rマークダウンアウトプットの自動整理\n     officer,          # パワーポイント\n     \n     # ダッシュボード\n     ############\n     flexdashboard,    # Rマークダウンスクリプトをダッシュボードに変換する\n     shiny,            # インタラクティブなウェブアプリ\n     \n     # プレゼンテーション用の表の作成\n     #########################\n     knitr,            # RマークダウンレポートとHTML表の作成\n     flextable,        # HTML 表\n     #DT,              # HTML 表 (代替パッケージ)\n     #gt,              # HTML 表 (代替パッケージ)\n     #huxtable,        # HTML 表 (代替パッケージ) \n     \n     # 系統学\n     ###############\n     ggtree,           # 系統樹の作成とアノテーション\n     ape,              # 系統発生と進化の分析\n     treeio            # 系統発生ファイルの描画\n \n)",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>推奨パッケージ</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.jp.html#github-のパッケージ",
    "href": "new_pages/packages_suggested.jp.html#github-のパッケージ",
    "title": "5  推奨パッケージ",
    "section": "5.2 Github のパッケージ",
    "text": "5.2 Github のパッケージ\n以下は、2つのパッケージを Github リポジトリから直接インストールするためのコードです。\n\nepicontacts パッケージの開発バージョンには、時間軸 x に沿った伝播状況を表す図（伝播ツリー）を作成する関数が含まれています。\nepirhandbook パッケージには、このハンドブックで使用されているすべてのデータが含まれており、ハンドブックのオフラインバージョンをダウンロードするために使用できます。\n\n\n# Githubからダウンロードするパッケージ（CRANからはダウンロード不可）\n##########################################################\n\n# epicontacts の開発バージョン（時間軸xの伝播チェーン）\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# このハンドブックで使用されるデータが含まれるパッケージ \npacman::p_install_gh(\"appliedepi/epirhandbook\")",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>推奨パッケージ</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.jp.html",
    "href": "new_pages/r_projects.jp.html",
    "title": "6  R プロジェクト",
    "section": "",
    "text": "6.1 推奨する使用方法\nR の一般的、効率的、かつトラブルのない使い方は、以下の 3 つの要素を組み合わせることです。1 つの R プロジェクト内には、1 つの個別の作業プロジェクトがホストされています。各要素は、以下のセクションで説明します。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R プロジェクト</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.jp.html#推奨する使用方法",
    "href": "new_pages/r_projects.jp.html#推奨する使用方法",
    "title": "6  R プロジェクト",
    "section": "",
    "text": "R プロジェクト\n\nデータ、スクリプト、出力結果など作業に必要なものが格納されている作業環境\n\n\n相対パスを作成するための here パッケージ\n\nファイルパスは R プロジェクトのルートフォルダからの相対パスで記述します。詳しくは、データのインポート・エクスポート の章をご覧ください。\n\n\nデータをインポート・エクスポートするための rio パッケージ\n\nimport() および export() は、.csv、.xlsx、.png などの拡張子がついたあらゆる様式のファイルを扱います。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R プロジェクト</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.jp.html#r-プロジェクトの作成",
    "href": "new_pages/r_projects.jp.html#r-プロジェクトの作成",
    "title": "6  R プロジェクト",
    "section": "6.2 R プロジェクトの作成",
    "text": "6.2 R プロジェクトの作成\nR プロジェクトを作成するには、File メニューから、“New Project” を選択してください。次に、\n\nプロジェクト用に新しいフォルダを作成したい場合は、“New directory” を選択し、作成する場所を指定します。\n\n既存のフォルダ内にプロジェクトを作成したい場合は、“Existing directory” をクリックし、フォルダを指定します。\n\nGithubのリポジトリをクローンしたい場合は、3 つ目の選択肢である “Version Control” を選択し、そして “Git” を選択してください。詳しくは、Git と Github を使用したバージョン管理と共同作業 の章を参照してください。\n\n\n\n\n\n\n\n\n\n\nR プロジェクトは、.Rproj ファイルを含んだフォルダの形式で作成されます。.Rproj ファイルは、R プロジェクトへのショートカットであり、プロジェクトを開く主な方法となるでしょう。他の方法として、Fileメニューから “Open Project”を選択することでもプロジェクトを開くことができます。または、RStudio の右上端にある R プロジェクトのアイコンをクリックして表示される、利用可能な R プロジェクトのドロップダウンリストから操作してもプロジェクトを開くことができます。\nR プロジェクトを終了するには、新しいプロジェクトを開くか、プロジェクトを閉じます（File メニュー上の “Close Project” を選択する）。\n\nプロジェクトの切り替え\n別のプロジェクトに切り替えるには、RStudio の右上にある R プロジェクトのアイコンをクリックして表示されるドロップダウンメニューを使用します。“Close Project”（プロジェクトを閉じる）や “Open Project”（プロジェクトを開く）などのオプションが表示される他、最近のプロジェクトのリストも表示されます。\n\n\n\n\n\n\n\n\n\n\n\n初期設定\n一般的に、RStudio は毎回「まっさらな状態」、つまり前回のセッションからワークスペースを引き継いでいない状態で起動することがおすすめされています。これは、オブジェクトや結果がセッション間で引き継がれないことを意味します（スクリプトを実行することにより、オブジェクトや結果を再作成する必要があります）。ワークスペースを引き継がないようにすることで、より良いスクリプトを書くようになり、長期的にはエラーを回避することができるようになる、というメリットがあります。\n以下の順序に従って、RStudio を毎回「まっさらな状態」で起動するように設定してください。\n\nTools メニューから “Project Options” を選択します。\n\n“Project Options” を開いたら、“General” タブにある “Restore .RData into workspace at startup” を “No” に設定して RStudio が起動時にワークスペースに .RData を復元しないようにし、また、“Save workspace to .RData on exit” も “No” に設定して終了時にワークスペースを .RData に保存しないように設定します。\n\n\n\nプロジェクト内の整理\nプロジェクト内には、データ、スクリプト、図や出力結果などと名付けられたサブフォルダがあるのが一般的です。サブフォルダは、通常コンピュータに新しいフォルダを追加するのと同じ方法で追加することができます。あるいは、R コマンドによって新しいフォルダを作成する方法が知りたい方は、ディレクトリの操作 の章をご覧ください。\n\n\nバージョン管理\nスクリプトの名前に日付を入れたり（例：「transmission_analysis_2020-10-03.R」）、「アーカイブ（archive）」フォルダを作るなど、簡単な方法でよいので、バージョン管理システムの使用をおすすめします。また、各スクリプトの最初に、スクリプトの概要、タグ、作者、変更履歴をコメントしたヘッダーテキストを置くこともおすすめします。\nより複雑なバージョン管理の方法として、Github や同様のプラットフォームを使用したバージョン管理が挙げられます。詳細は、Git と Github を使用したバージョン管理と共同作業 の章を参照してください。\nまた、役立つヒントとして、“Edit” メニューにある “Find in Files”（ファイル内検索）ツールを使用すると、プロジェクトやフォルダ全体を横断的に検索することができます。複数のファイルにまたがる文字列の検索や置換も可能です。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R プロジェクト</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.jp.html#r-プロジェクトの使用例",
    "href": "new_pages/r_projects.jp.html#r-プロジェクトの使用例",
    "title": "6  R プロジェクト",
    "section": "6.3 R プロジェクトの使用例",
    "text": "6.3 R プロジェクトの使用例\n以下は、R project 内で here() を使用してデータのインポート、エクスポート、そして保存を行う例です。here パッケージについての詳細は、データのインポート・エクスポート の章をご覧ください。\nまず、R プロジェクトにある “data” と名付けられたフォルダから linelist_raw.xlsx ファイルをインポートする例を挙げます。\n\nlinelist &lt;- import(here(\"data\", \"linelist_raw.xlsx\"))\n\n次に、linelist と名付けられたオブジェクトを “my_linelist.rds” という名前の rds ファイルとして、R プロジェクトにある “data” フォルダ内の “clean” と名付けられたフォルダにエクスポートする例です。\n\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\n\nそして、一番最近出力した図を “epicurve_2021-02-15.png” という名前の png ファイルとして、R プロジェクトにある “outputs” フォルダ内の “epicurves” と名付けられたフォルダに保存する例です。\n\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R プロジェクト</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.jp.html#参考資料",
    "href": "new_pages/r_projects.jp.html#参考資料",
    "title": "6  R プロジェクト",
    "section": "6.4 参考資料",
    "text": "6.4 参考資料\nRStudio 公式ウェブサイト内の R プロジェクトの使用に関するページ をご覧ください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>R プロジェクト</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html",
    "href": "new_pages/importing.jp.html",
    "title": "7  データのインポート・エクスポート",
    "section": "",
    "text": "7.1 概要\nR に「データセット」をインポートする場合、一般的には、お手元の R 環境でフォルダディレクトリ内の特定のファイルパス・アドレスにあるファイル（Excel、CSV、TSV、RDS など）をインポートし、新しいデータフレームオブジェクトとして定義します。\nR では、他の統計プログラム（SAS、STATA、SPSS）で作成されたファイルを含め、多くの種類のファイルをインポート・エクスポートすることができます。また、リレーショナルデータベース（relational database）への接続も可能です。\nR には、以下のような R 独自のデータフォーマットもあります。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#概要",
    "href": "new_pages/importing.jp.html#概要",
    "title": "7  データのインポート・エクスポート",
    "section": "",
    "text": "RDS ファイル（.rds）は、データフレームなどの単一の R オブジェクトを保存します。RDS ファイルは、列のデータ型を維持するため、クリーニングされたデータを保存するのに適しています。詳しくは こちら をご覧ください。\n\nRData ファイル（.Rdata）は、複数のオブジェクトや、R のワークスペース全体を保存できます。詳しくは こちら をご覧ください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#rio-パッケージ",
    "href": "new_pages/importing.jp.html#rio-パッケージ",
    "title": "7  データのインポート・エクスポート",
    "section": "7.2 rio パッケージ",
    "text": "7.2 rio パッケージ\n本書では、rio パッケージの使用を推奨しています。“rio” は”R I/O”（Input/Output）の略語です。\nrio パッケージに含まれる関数 import() および export() は、様々な種類のファイル（例：.xlsx、.csv、.rds、.tsv）を扱うことができ、関数内でファイルパス（ “.csv” のような拡張子を含む）を指定すると、rio が拡張子を読み取り、指定された拡張子に最適なツールを使用してファイルをインポートまたはエクスポートします。\nrio を使わずに、他のパッケージの関数を使うこともできます。他のパッケージは、その使用がファイルの種類に特化しており、例えば、base R の read.csv()、openxlsx パッケージの read.xlsx()、 readr パッケージの write_csv() などが挙げられます。どのパッケージがどのファイル形式を扱えるかを覚えるのは大変ですが、rio パッケージの import() や export() はそのような暗記の必要が無く、扱いが簡単です。\nrio の関数 import() と export() は、ファイルの拡張子に基づき、与えられたファイルに適切なパッケージと関数を使用します。rio がバックグラウンドで使用するパッケージや関数については、この章の最後に掲載されている表ご覧ください。rio は、STATA、SAS、SPSSのファイルをはじめ、さまざまな種類のファイルをインポートすることができます。\nシェープファイル（shape file）のインポート・エクスポートには、GIS の基礎 の章で紹介する別のパッケージが必要です。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#here",
    "href": "new_pages/importing.jp.html#here",
    "title": "7  データのインポート・エクスポート",
    "section": "7.3 here パッケージ",
    "text": "7.3 here パッケージ\nhere パッケージの関数 here() を用いてファイルパスを作成することで、ファイルの場所と保存場所を R に簡単に指示することができます。\nhere パッケージは、 R プロジェクトと組み合わせて使用すると、 R プロジェクトのルートディレクトリ（トップレベルにあるフォルダ）に対する R プロジェクト内のファイルの場所を記述することができ、 R プロジェクトを複数の人やコンピュータで共有したり、アクセスしたりする場合に便利です。すべてのユーザーが共通の場所（ R プロジェクトのルート）からファイルパスを「開始」するようにすることで、異なるコンピュータ間のユニークなファイルパス（例: \"C:/Users/Laura/Documents...\" ）による煩雑さを避けることができます。\nR プロジェクトでの here() は以下のように機能します。\n\nhere パッケージが R プロジェクト内で最初に読み込まれると、「ベンチマーク」または「アンカー」として、 R プロジェクトのルートフォルダに”.here “という小さなファイルが配置されます。\n対象のスクリプトで、here() を使用してそのアンカーに基づいたファイルパスを作成し、R プロジェクトのサブフォルダ内のファイルを参照できるようにします\nファイルパスを作成するには、以下のように、ルートディレクトリ以降のフォルダ名を引用符で囲み、カンマで区切り、最後にファイル名とファイル拡張子を記述します\nhere() のファイルパスは、インポートとエクスポートの両方に使用できます\n\n例えば、以下では、関数 import() に、 here() で構築されたファイルパスが提供されています。\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\nコマンド here(\"data\", \"linelists\", \"ebola_linelist.xlsx\") は、実際にはユーザーのコンピュータに固有の完全なファイルパスをコンピュータに指示しています。\n\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\"\nhere() を用いた R コマンドは、 R プロジェクトにアクセスするすべてのコンピュータで正常に実行できるのが魅力です。\nヒント: “.here” ルートがどこに設定されているかわからない場合は、括弧内を空にして関数 here() を実行してください。\nこのリンク に here パッケージの詳細が記載されています。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#ファイルパス",
    "href": "new_pages/importing.jp.html#ファイルパス",
    "title": "7  データのインポート・エクスポート",
    "section": "7.4 ファイルパス",
    "text": "7.4 ファイルパス\nデータをインポートまたはエクスポートする際、ファイルパスを指定する必要があります。 次の 3 つの方法のいずれかを実行してください。\n\n推奨：here パッケージで「相対」ファイルパス（“relative” file path）を指定する\n「完全」・「絶対」ファイルパス（“full”/“absolute” file path）を指定する\n手動でファイルを選択する\n\n\n「相対」ファイルパス\nR では、「相対」ファイルパスは、R プロジェクトのルートを基準にしたファイルパスで構成されます。これにより、さまざまなコンピュータで機能する、より単純なファイルパスが可能になります（例えば、R プロジェクトが共有ドライブ上にある場合や、電子メールで送信される場合）。上記 のように、相対ファイルパスは here パッケージを用いて作成および使用されます。\n以下に、here() で作成された相対ファイルパスの例を示します。検索したい .xlsx ファイルがサブフォルダ “data” 、そしてその中のサブフォルダ “linelists” を含む R プロジェクト内にある場合のファイルパスです。\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\n\n\n「絶対」ファイルパス\n「絶対」または「完全な」ファイルパスを import() などの関数に指定できますが、ユーザーの特定のコンピュータに固有である故「壊れやすい」ため、推奨されていません。\n以下は、絶対ファイルパスの例です。Laura のコンピュータには、フォルダ “analysis” 、サブフォルダ “data”、そしてその中にサブフォルダ “linelists” があり、そこに対象の .xlsx ファイルがあります。\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")\n\n絶対ファイルパスについて、注意すべき点を以下で説明します。\n\nスクリプトを別のコンピュータで実行すると機能しないため、絶対ファイルパスの使用は避けてください。\n上記の例のように、スラッシュ（/）を使用してください（注: これは Windows ファイルパスのデフォルトとは異なります）\n\n二重スラッシュで始まるファイルパス（“//…”など）は、R によって認識されない可能性が高く、エラーが発生します。文字で始まる「名前付き」または「文字付き」のドライブ（“J:” や “C:” など）にファイルを移動することをおすすめします。この問題の詳細については、ディレクトリの操作 の章をご参照ください。\n\n絶対ファイルパスが適切な事例の 1 つは、すべてのユーザーが同じ絶対ファイルパスを持つ共有ドライブからファイルをインポートする場合です。\nヒント: すべての \\を / にすばやく変換するには、対象のコードを選択し、Ctrl + f（ Windows の場合）を使用し、「選択中」のオプションボックスをオンにしてから、置換機能を使用して変換します。\n\n\n\n手動でのファイル選択\n次のいずれかの方法でデータを手動でインポートできます。\n\nRStudio の Environment Pane にて、「データセットのインポート」（“Import Dataset”）をクリックし、データの種類を選択します。\nファイル（File） -&gt; データセットのインポート（Import Dataset） をクリックし、対象データの種類を選択します。\n\n手動でのファイル選択をコード化したい場合は、base R コマンドの file.choose() を（括弧内を空のまま）使用し、ユーザーがコンピュータからファイルを手動で選択できるポップアップウィンドウを表示します。以下に例を示します。\n\n\n# ファイルを手動で選択する\n# このコマンドを実行すると、ポップアップウィンドウが表示される\n# 選択したファイルパスがimport（）コマンドに提供される\n\nmy_data &lt;- import(file.choose())\n\nヒント：ポップアップウィンドウがすでに開いている RStudio ウィンドウの後ろに表示される場合があります。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#データのインポート",
    "href": "new_pages/importing.jp.html#データのインポート",
    "title": "7  データのインポート・エクスポート",
    "section": "7.5 データのインポート",
    "text": "7.5 データのインポート\nimport() を使用してデータセットをインポートするのは非常に簡単です。 ファイルパス（ファイル名とファイル拡張子を含む）を引用符で囲んで指定するだけです。 here() を使用してファイルパスを作成する場合は、先述のセクションで説明した手順に従ってください。 以下にいくつかの例を示します。\nまず、「作業ディレクトリ」または R プロジェクトのルートフォルダにある csv ファイルをインポートする例です。\n\nlinelist &lt;- import(\"linelist_cleaned.csv\")\n\n次に、R プロジェクトの “data” および “linelists” サブフォルダ（here() を使用して作成されたファイルパス）にある Excel ワークブックの最初のシートをインポートする例です。\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\n\n最後に、絶対ファイルパスを使用してデータフレーム（.rds ファイル）をインポートする例を紹介します。\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")\n\n\n特定の Excel シート\n特定のシートをインポートする場合は、シート名を which = 引数に指定します。 以下に例を示します。\n\nmy_data &lt;- import(\"my_excel_file.xlsx\", which = \"Sheetname\")\n\nhere() を使用して import() で相対パスを指定する場合でも、here() の閉じ括弧の後に which = 引数を追加することで、特定のシートを指定することができます。\n\n# デモ: 'here'パッケージで相対パスを使用し特定の Excel シートをインポートする\nlinelist_raw &lt;- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  \n\nデータフレームを R から特定の Excel シートにエクスポートし、 Excel ワークブックの残りの部分を変更しないようにするには、openxlsx などの代替パッケージを使用してインポート、編集、およびエクスポートする必要があります。詳細については、ディレクトリの操作 の章または こちらの github ページを参照してください。\nExcel ワークブックが .xlsb（バイナリ形式の Excel ワークブック）の場合、rio を使用してインポートできない場合があります。その場合は、ファイルを .xlsx として再保存するか、このような用途 のために作成された readxlsb などのパッケージの使用をおすすめします。\n\n\n\n欠損値\nまず、データセット内でどのような値が欠損しているかの定義を指定することが大切です。欠損データの処理 の章で説明されているように、R では欠損値は NA と表示されますが、インポートするデータセットでの欠損値は、99 や “Missing”、または単に空の文字スペース “” で表されている可能性があります。\nimport() に na = 引数を使用し、インポートするデータセットで欠損値とみなしたい値を引用符で囲んで指定します（数値の場合でも同様に指定します）。 以下に示すように、 c() を使用して括弧内に複数の値を書くと、複数の値を指定できます。\nインポートされたデータセットの値 “99” は欠落していると見なされ、Rで NA に変換されます。\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\n\nインポートされたデータセットの “Missing”、““（空のセル）、または” “（単一スペース）の値はすべて、Rで NA に変換されます。\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))\n\n\n\n\n行をスキップする\n.xlsx または .csv ファイル内の一部の行をインポートしたくない場合は、 rio の import() 内で引数 skip = を使用し、インポートをスキップする行数を指定します。\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\", skip = 1)  # ヘッダー行をインポートしない\n\n残念ながら、skip = には 1 行のみ指定可能であり、範囲を指定することはできません。（例えば、“2:10” はと指定することはできません）。上から連続していない特定の行のインポートをスキップするには、ファイルを複数回インポートし、dplyr パッケージの bind_rows() を使用することを検討してください。 以下に、2 行目のみをスキップする例を示します。\n\n\n2番目のヘッダー行を管理する\n以下に示すように、データセットの 2 番目の行が「データディクショナリ」（data dictionary）行である場合があります。この場合、すべての列が「文字型」としてインポートされる可能性があり、問題にを起こす場合があります。\n以下は、このようなデータセットの例です（最初の行がデータディクショナリとなっています）。\n\n\n\n\n\n\n\n2番目のヘッダー行の削除\n2 番目のヘッダー行を削除するには、データを2回インポートする必要があります。\n\n正しい列名を保存するためにデータをインポートします。\n\n最初の2行（ヘッダーと2行目）をスキップして、データを再度インポートします\n\n2 回目にインポートされたデータフレームに正しい名前を指定します\n\n正しい列名を指定するために使用される引数は、データファイルのタイプ（.csv、.tsv、.xlsx など ）によって異なります。これは、rio がファイルタイプごとに異なる関数を使用しているためです（上記の表を参照）。\nExcel ファイルの場合: (col_names =)\n\n# 1回目のインポートでは列名を保存する\nlinelist_raw_names &lt;- import(\"linelist_raw.xlsx\") %&gt;% names()  # 本来の列名を保存する\n\n# 2回目のインポートでは、2行目をスキップし、列名を引数col_names = に割り当てる\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n\nCSVファイルの場合: (col.names =)\n\n# 1回目のインポートでは列名を保存する\nlinelist_raw_names &lt;- import(\"linelist_raw.csv\") %&gt;% names() # 本来の列名を保存する\n\n# csvファイルの引数は 'col.names='であることに注意\nlinelist_raw &lt;- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n\nバックアップオプションとして - 列名を別のコマンドで変更する\n\n# base R の関数の colnames() 関数を使用してヘッダーを割り当てる・上書きする\ncolnames(linelist_raw) &lt;- linelist_raw_names\n\n\n\nデータディクショナリの作成\nおまけ：データディクショナリである 2 行目がある場合は、そこからデータディクショナリを簡単に作成できます。このヒントは、この 投稿 を基に作成されました。\n\ndict &lt;- linelist_2headers %&gt;%             # はじめに、1行目としてディクショナリを含むラインリスト\n  head(1) %&gt;%                             # 列名とディクショナリの一行目のみを保持する           \n  pivot_longer(cols = everything(),       # すべての列を長い形式に変更する\n               names_to = \"Column\",       # 新しい列名を割り当てる\n               values_to = \"Description\")\n\n\n\n\n\n\n\n\n\n2つのヘッダー行を組み合わせる\n元のデータセットにヘッダーが 2 行ある場合（特に、データの 2 行目がサブヘッダーである場合）、それらを 「結合」するか、2 番目のヘッダー行の値を最初のヘッダー行に追加することができます。\n以下のコマンドは、データフレームの列名を、最初の（本来の）ヘッダーとそのすぐ下（最初の行）の値の組み合わせとして（一緒に貼り付けて）定義します。\n\nnames(my_data) &lt;- paste(names(my_data), my_data[1, ], sep = \"_\")\n\n\n\n\n\nGoogle シート\ngooglesheet4 パッケージを使用して、スプレッドシートへのアクセスを認証することにより、オンラインの Google スプレッドシートからデータをインポートすることができます。\n\npacman::p_load(\"googlesheets4\")\n\n以下のように、練習用の Google シートをインポートして保存します。以下のコマンドは、 Google アカウントの認証の確認を求める場合があります。インターネットブラウザのプロンプトとポップアップに従い、Tidyverse API パッケージに、 Google ドライブでスプレッドシートを編集、作成、および削除する権限を付与します。\n以下のシートは「リンクを持っている人は誰でも閲覧可能」に設定されていますので、誰でもインポートすることができます。\n\nGsheets_demo &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\n\nこのシートは、上のURL の一部分であるシート ID のみを使用してインポートすることもできます。\n\nGsheets_demo &lt;- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")\n\nまた、別のパッケージである googledrive を使用しても、Google スプレッドシートを作成、編集、削除することができます。例えば、このパッケージの gs4_create() 関数や sheet_write() 関数などです。\nその他の参考資料: Google スプレッドシートのインポート 基礎\nより詳しいチュートリアル\ngooglesheets4 と tidyverse の間の相互作用",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#複数のファイルをインポートエクスポート分割結合する",
    "href": "new_pages/importing.jp.html#複数のファイルをインポートエクスポート分割結合する",
    "title": "7  データのインポート・エクスポート",
    "section": "7.6 複数のファイルをインポート、エクスポート、分割、結合する",
    "text": "7.6 複数のファイルをインポート、エクスポート、分割、結合する\n複数のファイルまたは複数の Excel ファイルをインポートして結合する例については、ループと反復処理・リストの操作 の章を参照してください。データフレームを分割し、それぞれのデータフレームを個別にエクスポートする方法や、それぞれのデータフレームを名前付きのワークシートとして含む一つの Excel ワークブックとしてエクスポートする方法の例も紹介しています。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#import_github",
    "href": "new_pages/importing.jp.html#import_github",
    "title": "7  データのインポート・エクスポート",
    "section": "7.7 Github からのインポート",
    "text": "7.7 Github からのインポート\nインポートするファイルの種類によって、Github から R にデータを直接インポートするのが非常に簡単な場合もあれば、いくつかの手順が必要な場合もあります。 以下に、いくつかの方法を示します。\n\nCSV ファイル\nR コマンドを使用して、.csv ファイルを Github から R に簡単に直接インポートすることができます。\n\nGithub リポジトリに移動し、目的のファイルを見つけてクリックします\n“Raw” ボタンをクリックします（以下に示すように、 “Raw” の csv データが表示されます）\nURL（ウェブアドレス）をコピーします\nimport() コマンド内で URL を引用符で囲みます\n\n\n\n\n\n\n\n\n\n\n\n\nXLSX ファイル\n一部のファイル（.xlsx、.rds、.nwk、.shp など）では、“Raw” データが表示できない場合があります\n\nGithubリポジトリに移動し、対象のファイルを見つけてクリックします\n以下に示すように、“Download” ボタンをクリックします\nファイルをコンピュータに保存し、 R にインポートします\n\n\n\n\n\n\n\n\n\n\n\n\nシェープファイル（Shape ファイル）\nシェープ（shape）ファイルには多くの従属ファイルがあり、それぞれファイルの拡張子が異なります。ファイル拡張子が “.shp” であるものもあれば、“.dbf”、“.prj” などのものもあります。Github からシェープファイルをダウンロードするには、各ファイルを個別にダウンロードし、すべてのファイルをコンピュータの同じフォルダに保存する必要があります。Github で、各ファイルを個別にクリックし、「ダウンロード」（“Download”）ボタンをクリックしてダウンロードします。\nコンピュータに保存後、GIS の基礎 の章で説明されているように、sf パッケージの st_read() を使用してシェープファイルをインポートできます。他の関連ファイルがコンピュータの同じフォルダ内にある場合に限り、“.shp” ファイルのファイルパスと名前を指定するだけで済みます。\n以下の例では、シェープファイル “sle_adm3” が多くのファイルで構成されていることがわかります。各ファイルを Github からダウンロードする必要があります。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#手動でのデータ入力",
    "href": "new_pages/importing.jp.html#手動でのデータ入力",
    "title": "7  データのインポート・エクスポート",
    "section": "7.8 手動でのデータ入力",
    "text": "7.8 手動でのデータ入力\n\n行ごとの入力\ntidyverse の tibble パッケージに含まれている tribble 関数を使用します（tribble のオンライン資料はこちら を参照ください）。\n列のヘッダーがチルダ（~）で始まることに注意してください。また、各列のデータ型（文字、数値など）は 1 つのみであることに注意してください。タブ、間隔、および新しい行を使用し、データ入力をより直感的で読みやすくすることができます。値の間のスペースの有無はどちらでも問題ありませんが、各行は改行して書かれています。以下に例を示します。\n\n# 行ごとに手動でデータセットを作成する\nmanual_entry_rows &lt;- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )\n\n新しいデータセットは以下のコマンドで表示できます。\n\n\n\n\n\n\n\n\n列ごとの入力\nデータフレームはベクトル（垂直列）で構成されているため、base R で手動でデータフレームを作成するアプローチでは、各列を定義してから結合します。通常、上のセクションで示したように、データは行で考えられるため、列ごとのデータ入力は、疫学では直感に反するかもしれません。\n\n# 各ベクトル（垂直列）を個別に定義し、それぞれに独自の名前を付ける\nPatientID &lt;- c(235, 452, 778, 111)\nTreatment &lt;- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     &lt;- c(1, 0, 1, 0)\n\n注意：すべてのベクトルは同じ長さ（同じ数の値）である必要があります。\n次に、関数 data.frame() を使用してベクトルを結合します。\n\n# ベクトル名を元に、列をデータフレームに結合する\nmanual_entry_cols &lt;- data.frame(PatientID, Treatment, Death)\n\n以下に、作成した新しいデータセットを表示します。\n\n\n\n\n\n\n\n\nクリップボードをインポート\n他の場所からデータをコピーしてクリップボードに保存した場合は、次の 2 つの方法のいずれかでインポートすることができます。\nclipr パッケージから、 read_clip_tbl() を使用してデータフレームとしてインポートする、又は単に read_clip() を使用して文字ベクトルとしてインポートすることができます。どちらの場合も、括弧は空のままにしておきます。\n\nlinelist &lt;- clipr::read_clip_tbl()  # 現在のクリップボードをデータフレームとしてインポートする\nlinelist &lt;- clipr::read_clip()      # 文字ベクトルとしてインポートする\n\nまた、clipr パッケージを使用し、データをクリップボードにエクスポートすることも簡単にできます。 エクスポートについては、後述のエクスポートに関するセクションを参照してください。\nクリップボードをインポートするもう 1 つの方法として、base R の read.table() で file = \"clipboard\") を指定し、データフレームとしてインポートすることもできます。\n\ndf_from_clipboard &lt;- read.table(\n  file = \"clipboard\",  # \"クリップボード\"に指定する\n  sep = \"t\",           # 区切り文字はタブ、またはコンマなどが指定可能\n  header=TRUE)         # ヘッダー行がある場合",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#最新のファイルをインポート",
    "href": "new_pages/importing.jp.html#最新のファイルをインポート",
    "title": "7  データのインポート・エクスポート",
    "section": "7.9 最新のファイルをインポート",
    "text": "7.9 最新のファイルをインポート\n手持ちのデータセットが毎日更新されることもあり、この場合、最新のファイルをインポートするようにコードを書きたいでしょう。 以下に、複数のファイルから最新のファイルをインポートする方法を 2 つ紹介します。\n\nファイル名の日付に基づいてファイルを選択する\n\nファイルメタデータ（最新の変更）に基づいてファイルを選択する\n\n\nファイル名の日付を用いて\nこの方法は、次の 3 つの前提条件を要します。\n\nファイル名の日付が信頼できるものであること\n\n日付は数値であり、一般的に同じ形式で表示されていること（例：年、月、日）\n\nファイル名に日付以外の番号が書かれていないこと\n\n各ステップについて説明し、最後にそれらを組み合わせて示します。\nまず、base R から dir() を使用して、対象のフォルダ内の各ファイルのファイル名だけを抽出します。dir() の詳細については、ディレクトリの操作 の章を参照してください。 この例では、対象のフォルダは、R プロジェクトにある “data” 内、そしてその中の “example” フォルダ内の “linelists” フォルダです。\n\nlinelist_filenames &lt;- dir(here(\"data\", \"example\", \"linelists\")) # フォルダからファイル名を取得\nlinelist_filenames                                              # 表示\n\n[1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n[3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n[5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n[7] \"case_linelist20201006.csv\"    \n\n\nこの名前ベクトルを取得したら、stringr パッケージの str_extract() で以下の正規表現を使用することにより、名前から日付を抽出できます。ファイル名に含まれているすべての数字（ダッシュやスラッシュなどの中央にある他の文字を含む）を抽出します。 stringr の詳細については、文字型・文字列型データ の章をご覧ください。\n\nlinelist_dates_raw &lt;- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # 数字とその間の文字を抽出\nlinelist_dates_raw  # 表示\n\n[1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"20201006\"  \n\n\n日付が一般的に同じ日付形式（例えば、年、月、日）で記述され、年が 4 桁であると仮定すると、lubridate の柔軟な変換関数（ymd()、dmy()、または mdy()）を使用して、それらを日付に変換できます。こういった関数の場合、ダッシュ、スペース、またはスラッシュは重要ではなく、番号の順序のみが重要です。 詳しくは、日付型データ の章をご覧ください。\n\nlinelist_dates_clean &lt;- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean\n\n[1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"2020-10-06\"\n\n\n次に、base R 関数 which.max() を使用し、最大日付値のインデックス位置（1 番目、2 番目、3 番目など）を取得することができます。以下の例では、最新のファイルは、6 番目のファイル “case_linelist_2020-10-08.xlsx” として正しく識別されています。\n\nindex_latest_file &lt;- which.max(linelist_dates_clean)\nindex_latest_file\n\n[1] 6\n\n\nこれらすべてのコマンドをまとめたコードは次のようになります。最後の行の . は、パイプラインのその時点でのオブジェクトを表すことに注意してください。この時点での値は単純に数字の 6 です。これは二重括弧で囲まれ、 dir() によって生成されたファイル名のベクトルの 6 番目の要素を抽出します。\n\n# パッケージを読み込む\npacman::p_load(\n  tidyverse,         # データ整理\n  stringr,           # 文字列/文字の操作\n  lubridate,         # 日付の処理\n  rio,               # データのインポート・エクスポート\n  here,              # 相対ファイルパス\n  fs)                # ディレクトリの相互作用\n\n# 最新ファイルのファイル名を抽出します\nlatest_file &lt;- dir(here(\"data\", \"example\", \"linelists\")) %&gt;%  # \"linelists\" サブフォルダからのファイル名          \n  str_extract(\"[0-9].*[0-9]\") %&gt;%                  # 日付（数字）を抽出\n  ymd() %&gt;%                                        # 数値を日付に変換（年-月-日形式を想定）\n  which.max() %&gt;%                                  # 最大日付のインデックスを取得（最新のファイル）\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # 最新のラインリストのファイル名を取得\n\nlatest_file  # 最新のファイルの名前を表示する\n\n[1] \"case_linelist_2020-10-08.xlsx\"\n\n\nこれで、上で抽出した名前をhere() で使用して、相対ファイルパスを完成させることができます。\n\nhere(\"data\", \"example\", \"linelists\", latest_file) \n\nそして、最新のファイルをインポートできます。\n\n# インポート\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # インポート \n\n\n\nファイル情報を用いて\nファイルの名前に日付が含まれていない場合（またはそれらの日付を信頼できない場合）は、ファイルのメタデータから最終変更日を抽出してみてください。fs パッケージの関数を使用し、最終変更時刻とファイルパスを含む各ファイルのメタデータ情報を調べることができます。\n以下のように、 fs の dir_info() に対象のフォルダを指定します。この場合、対象のフォルダは、フォルダ “data”、サブフォルダ “example”、およびそのサブフォルダ “linelists”の R プロジェクトにあります。結果は、ファイルごとに 1 行、 modification_time、path などの列を持つデータフレームとして返されます。ディレクトリの操作 の章では、視覚的な例を確認できます。\nこのファイルのデータフレームを modification_time 列で並べ替えてから、base Rの head() を使用し、最上位・最新の行（ファイル）のみを保持できます。次に、path 列に dplyr 関数 pull() を使用し、この最新ファイルのファイルパスを抽出します（この機能があるのは、dplyr 関数 pull() のみです）。最後に、抽出したファイルパスを import() 内で指定し、ファイルをインポートします。インポートされたファイルは latest_file として保存されます。\n\nlatest_file &lt;- dir_info(here(\"data\", \"example\", \"linelists\")) %&gt;%  # ディレクトリ内の全ファイルのファイル情報を収集\n  arrange(desc(modification_time)) %&gt;%      # 変更時間で並べ替え\n  head(1) %&gt;%                               # 一番上の（最新の）ファイルのみを保持する\n  pull(path) %&gt;%                            # ファイルパスのみを抽出\n  import()                                  # ファイルをインポート",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#import_api",
    "href": "new_pages/importing.jp.html#import_api",
    "title": "7  データのインポート・エクスポート",
    "section": "7.10 API",
    "text": "7.10 API\n「自動プログラミングインターフェース」（Automated Programming Interface; API）を使用して、ウェブサイトからデータを直接インポートできます。API は、あるソフトウェアアプリケーションが別のソフトウェアアプリケーションと対話できるようにする一連のルールです。クライアントである貴方が「リクエスト」（“request”）を送信し、要求したコンテンツを含む「レスポンス」（“response”）を受信します。R の httr パッケージおよび jsonlite パッケージにより、このプロセスを容易に行うことができます。\nAPI 対応の各ウェブサイトには、知っておくべき独自のドキュメントと詳細があります。一部のサイトは公開されており、誰でもアクセス可能です。ユーザー ID や経歴を備えたプラットフォームなど、その他のデータにアクセスするには認証が必要です。\n言うまでもなく、API を介してデータをインポートするにはインターネットに接続する必要があります。以下において、API を使用してデータをインポートする例を簡単に説明し、その他の関連資料を紹介します。\n注意：API が必要ない別のウェブサイトに同じデータが投稿されている可能性があり、その場合は API を使用しない方がデータ取得が容易である可能性があります。例えば、Github からのインポート に関するセクションで説明したように、import() にサイトの URL を指定するだけでアクセスできる場合があります。\n\nHTTP リクエスト\nAPI のやり取りは、HTTP リクエストを介して行われるのが最も一般的です。HTTP はハイパーテキスト転送プロトコル（Hypertext Transfer Protocol）であり、クライアントとサーバー間のリクエスト（要求）・レスポンス（応答）の基本的な形式です。入力と出力のフォーマットは、API のタイプによって異なる場合がありますが、プロセスは同じです。ユーザーからの「リクエスト」（多くの場合、HTTP リクエスト）にはクエリ（query）が含まれ、その後に「レスポンス」が続き、レスポンスには、リクエスト及び場合によってはリクエストされた内容についてのステータス情報が含まれます。\nHTTP リクエストのいくつかの構成要素は次のとおりです。\n\nAPI エンドポイントの URL\n「メソッド」（“Method”）または “Verb”\nヘッダー\n本文\n\nHTTP リクエストの「メソッド」は、実行したいアクションを指定します。最も一般的な HTTP メソッドの 2 つは GET と POST ですが、その他にも PUT、DELETE、PATCH などがあります。R にデータをインポートする場合、 GET を使用することが多いです。\nリクエストを送信した後、コンピュータは、送信したリクエストと同様の形式で「レスポンス」を受け取ります。レスポンスには、URL、HTTP ステータス（ステータス200が必要です！）、ファイルタイプ、サイズ、目的のコンテンツなどが含まれます。次のステップとして、受け取ったレスポンスを解析して、R 環境内で実行可能なデータフレームに変換する必要があります。\n\n\nパッケージ\nhttr パッケージは、R で HTTP リクエストを処理するのに適しています。ウェブ APIの予備知識はほとんど必要なく、ソフトウェア開発用語にあまり詳しくない方でも利用することができます。また、HTTP レスポンスが .json の場合、jsonlite パッケージを使用してレスポンスを解析することができます。\n\n# パッケージを読み込む\npacman::p_load(httr, jsonlite, tidyverse)\n\n\n\n公開されているデータ\n以下は、Trafford Data Lab のチュートリアルから借用した HTTP リクエストの例です。このサイトには、他にも学習用の資料や API の演習がいくつかあります。\n事例：イギリスの Trafford 市にあるファーストフードの店舗リストをインポートしたい。このデータは、イギリスの食品衛生評価データを提供する Food Standards Agency の API からアクセスすることができる。\n今回のリクエストのパラメータは以下の通りです。\n\nHTTP 動詞：GET\nAPI エンドポイント URL：http://api.ratings.food.gov.uk/Establishments\n選択したパラメーター：name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityId\nヘッダー：“x-api-version”, 2\nデータフォーマット：JSON, XML\nドキュメンテーション：http://api.ratings.food.gov.uk/help\n\n使用する R コードは次のようになります。\n\n# リクエストの準備\npath &lt;- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest &lt;- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# サーバーエラーがないか確認（\"200\"が望ましい）\nrequest$status_code\n\n# リクエストを送信し、レスポンスを解析して、データフレームに変換\nresponse &lt;- content(request, as = \"text\", encoding = \"UTF-8\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%\n  pluck(\"establishments\") %&gt;%\n  as_tibble()\n\nこれで、ファーストフード施設ごとに 1 行を含む response データフレームを取得できました。\n\n\n認証が必要なデータ\n一部のAPIには認証が必要です。自分が誰であるかを証明することで、制限されたデータにアクセスできます。このようなデータをインポートするには、まず、POST メソッドを使用して、ユーザー名、パスワード、またはコードを提供する必要があります。POST メソッドを使用することで、その後の GET メソッドのリクエストで使用できるアクセストークン（access token）を取得できます。\n以下に、アウトブレイク調査ツールである Go.Data からデータをクエリする例を示します。Go.Data は、データ収集に使用される Web フロントエンドとスマートフォンアプリケーション間のすべての交信に API を使用しています。Go.Data は世界中で使用されています。アウトブレイクデータは機密性が高く、自分が担当するアウトブレイクに関するデータにしかアクセスできないようになっているため、認証が必要です。\n以下の R コードでは、httr と jsonlite パッケージを使用してGo.Data APIに接続し、あるアウトブレイクの接触者フォローアップに関するデータをインポートします。\n\n# 認可のための認証情報を設定\nurl &lt;- \"https://godatasampleURL.int/\"           # 有効な Go.Data URL の例\nusername &lt;- \"username\"                          # 有効な Go.Data ユーザー名 \npassword &lt;- \"password\"                          # 有効な Go,Data パスワード\noutbreak_id &lt;- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # 有効な Go.Data アウトブレイク ID\n\n# アクセストークンを取得する\nurl_request &lt;- paste0(url,\"api/oauth/token?access_token=123\") # ベース URL リクエストを定義する\n\n# リクエストの準備\nresponse &lt;- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # 上で保存したユーザー名とパスワードを使用して認証する                               \n    password = password),                                       \n    encode = \"json\")\n\n# リクエストの実行と応答の解析\ncontent &lt;-\n  content(response, as = \"text\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%          # ネストした JSON をフラット化する\n  glimpse()\n\n# 応答から得られたアクセストークンを保存する\naccess_token &lt;- content$access_token    # アクセストークンを保存して、以下の後続の API 呼び出しを許可します\n\n# アウトブレイクの連絡先をインポートする\n# アクセストークンを使用する \nresponse_contacts &lt;- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # GET リクエスト\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts &lt;- content(response_contacts, as = \"text\")         # テキスト JSON に変換\n\ncontacts &lt;- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # JSON をフラット化して tibble として保存\n\n注意：認証が必要な API から大量のデータをインポートする場合、タイムアウトになる場合があります。 これを回避するには、各 API GET リクエストの前にアクセストークンを再度取得し、クエリでフィルターまたは制限を使用してみてください。\nヒント： jsonlite パッケージの fromJSON() では、最初の実行では完全にネストが解除されないため、tibble にリストアイテムが残っている可能性があります。.json がどの程度ネストされているかに応じて、特定の変数のネストをさらに解除する必要があります。詳細は、flatten()などの jsonlite パッケージの説明をご覧ください。\n詳細は、LoopBack Explorer のドキュメント、API に関する Go.Data Github レポジトリ のページ、または 接触者の追跡 の章をご覧ください。\nhttr パッケージの詳細は こちら をご覧ください。\nこのセクションは、こちらのチュートリアルとこちらのチュートリアル を参照して作成されました。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#エクスポート",
    "href": "new_pages/importing.jp.html#エクスポート",
    "title": "7  データのインポート・エクスポート",
    "section": "7.11 エクスポート",
    "text": "7.11 エクスポート\n\nrio パッケージを使って\nrio パッケージを使用すると、import() と同様の方法で export() を使用できます。まず、保存する R オブジェクトの名前（linelist など）を指定し、保存するファイルの名前、およびそのファイルの拡張子を含むファイルパスを引用符で囲みます。例を以下に示します。\n以下のコードを実行すると、データフレーム linelist が Excel ワークブックとして作業ディレクトリ（R プロジェクトのルートフォルダ）に保存されます。\n\nexport(linelist, \"my_linelist.xlsx\") # 作業ディレクトリに保存する\n\n拡張子を変更すると、同じデータフレームを csv ファイルとして保存できます。 例えば、 here() で作成されたファイルパスを使用してもデータを保存することができます。\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))\n\n\n\nクリップボードにエクスポート\n（Excel、Google スプレッドシートなどの別のソフトウェアに貼り付けるためなど）データフレームをコンピュータの「クリップボード」にエクスポートしたい場合は、clipr パッケージの write_clip() を使用できます。\n\n# ラインリストデータフレームをシステムのクリップボードにエクスポートする\nclipr::write_clip(linelist)",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#import_rds",
    "href": "new_pages/importing.jp.html#import_rds",
    "title": "7  データのインポート・エクスポート",
    "section": "7.12 RDS ファイル",
    "text": "7.12 RDS ファイル\n.csv、.xlsx などに加えて、R データフレームを .rds ファイルとしてエクスポート・保存することもできます。.rds は R に固有のファイル形式であり、エクスポートされたデータを R で再度操作することがわかっている場合に非常に便利です。\n.rds では列のデータ型がそのまま保存されるため、インポート時に再度整理する必要はありません（Excel や CSV ファイルでは、これは頭痛の種になります！）。また、.rds は他のファイル形式と比較してファイルサイズが小さいので、大きいデータセットのエクスポートやインポートに便利です。\n例えば、R を使用している疫学チームに所属していて、マッピングのために GIS チームにファイルを送る必要がある場合、.rds ファイルを使用すると、すべての列のデータ型が保持されているため、受け取ったチームの負担が少なくなります。\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#import_rdata",
    "href": "new_pages/importing.jp.html#import_rdata",
    "title": "7  データのインポート・エクスポート",
    "section": "7.13 Rdata ファイルとリスト",
    "text": "7.13 Rdata ファイルとリスト\n.Rdata ファイルには、複数の R オブジェクト（複数のデータフレーム、モデリングの結果、リストなど）を保存でき、特定のプロジェクトで多くのデータをまとめたり共有する場合に非常に便利です。\n以下の例では、複数の R オブジェクトがエクスポートされたファイル “my_objects.Rdata” 内に保存されています。\n\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\n\n注意：リストをインポートする場合は、rio パッケージの import_list() を使用し、元のデータ構造と完全に同じ内容をインポートしてください。\n\nrio::import_list(\"my_list.Rdata\")",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#プロットの保存",
    "href": "new_pages/importing.jp.html#プロットの保存",
    "title": "7  データのインポート・エクスポート",
    "section": "7.14 プロットの保存",
    "text": "7.14 プロットの保存\nggplot() などによって作成されたプロットを保存する方法については、ggplot の基礎 の章で詳しく説明されています。\n簡単に説明すると、プロットを表示した後、 ggsave(\"my_plot_filepath_and_name.png\") を実行します。引数 plot = には、保存されたプロットオブジェクトを指定する必要がありますが、最も最近表示されたプロットを保存したい場合は、ファイル拡張子付きのファイルパスのみを指定することも可能です。加えて、width =、height =、units =、そして dpi = を設定することもできます。\n感染連鎖ツリーなど、関連性を表した図を保存する方法については、感染連鎖の図式化 の章をご覧ください。",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.jp.html#参考資料",
    "href": "new_pages/importing.jp.html#参考資料",
    "title": "7  データのインポート・エクスポート",
    "section": "7.15 参考資料",
    "text": "7.15 参考資料\nR データインポート・エクスポートマニュアル\nR for Data Science のデータインポートについての章\nggsave() に関するドキュメント\n以下は、こちら rio パッケージに関するウェブサイトから抜粋した表です。扱うデータの種類ごとに、予想されるファイル拡張子、データのインポートまたはエクスポートに rio で使用されるパッケージ、この機能がデフォルトでインストールされたバージョンの rio に含まれているかどうかが表示されています。\n\n\n\n\n\n\n\n\n\n\nフォーマット\n一般的な拡張子\nインポート用パッケージ\nエクスポート用パッケージ\nデフォルトでインストールされているかの有無\n\n\n\n\nカンマ区切りデータ\n.csv\ndata.tablefread()\ndata.table\n有\n\n\nパイプ区切りデータ\n.psv\ndata.tablefread()\ndata.table\n有\n\n\nタブ区切りデータ\n.tsv\ndata.tablefread()\ndata.table\n有\n\n\nSAS\n.sas7bdat\nhaven\nhaven\n有\n\n\nSPSS\n.sav\nhaven\nhaven\n有\n\n\nStata\n.dta\nhaven\nhaven\n有\n\n\nSAS\nXPORT\n.xpt\nhaven\n有\n\n\nSPSSポータブル\n.por\nhaven\n\n有\n\n\nExcel\n.xls\nreadxl\n\n有\n\n\nExcel\n.xlsx\nreadxl\nopenxlsx\n有\n\n\nRシンタックス\n.R\nbase\nbase\n有\n\n\n保存されたRオブジェクト\n.RData,.rda\nbase\nbase\n有\n\n\nシリアル化されたRオブジェクト\n.rds\nbase\nbase\n有\n\n\nEpiinfo\n.rec\nforeign\n\n有\n\n\nMinitab\n.mtp\nforeign\n\n有\n\n\nSystat\n.syd\nforeign\n\n有\n\n\n“XBASE”\nデータベースファイル\n.dbf\nforeign\n有\n\n\nWekaAttribute-Relationファイル形式\n.arff\nforeign\nforeign\n有\n\n\nデータ交換フォーマット\n.dif\nutils\n\n有\n\n\nFortran データ\n認識された拡張子はありません\nutils\n\n有\n\n\n固定幅フォーマットデータ\n.fwf\nutils\nutils\n有\n\n\ngzip コンマ区切りデータ\n.csv.gz\nutils\nutils\n有\n\n\nCSVY (CSV+YAMLメタデータヘッダー)\n.csvy\ncsvy\ncsvy\n無\n\n\nEViews\n.wf1\nhexView\n\n無\n\n\nFeatherR/Python交換フォーマット\n.feather\nfeather\nfeather\n無\n\n\nFastStorage\n.fst\nfst\nfst\n無\n\n\nJSON\n.json\njsonlite\njsonlite\n無\n\n\nMatlab\n.mat\nrmatio\nrmatio\n無\n\n\nOpenDocument スプレッドシート\n.ods\nreadODS\nreadODS\n無\n\n\nHTML テーブル\n.html\nxml2\nxml2\n無\n\n\nShallow XMLドキュメント\n.xml\nxml2\nxml2\n無\n\n\nYAML\n.yml\nyaml\nyaml\n無\n\n\nクリップボード\ntsv\nclipr\nclipr\n無",
    "crumbs": [
      "基本編",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>データのインポート・エクスポート</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html",
    "href": "new_pages/cleaning.jp.html",
    "title": "8  データクリーニングと主要関数",
    "section": "",
    "text": "主要関数\nこのハンドブックでは、R パッケージの一つである tidyverse 系関数を主に使用します。以下の表は、本章で使用する基本の R パッケージおよびパッケージに含まれる関数の一覧です。\n関数の多くは、データ操作に関する課題を解決するための「動詞」関数を提供する R パッケージ dplyr に属しています（dplyr という名前は”data frame-plier” にちなんでいます）。dplyr パッケージは、ggplot2、tidyr、stringr、tibble、purrr、magrittr、forcats などのパッケージを含む R パッケージである tidyverse ファミリーの一部です。\nこれらの関数を Stata や SAS のコマンドと比較したい場合は、Excel・Stata・SASとの比較 の章を参照にしてください。\nまた、R パッケージの data.table では、:= のような演算子や角括弧 [ ] が頻繁に使用されており、別の形式のデータ管理フレームワークを目にすることがあるかもしれません。この手法と構文については、データテーブル の章で簡単に説明しています。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#パイプラインによるデータクリーニング",
    "href": "new_pages/cleaning.jp.html#パイプラインによるデータクリーニング",
    "title": "8  データクリーニングと主要関数",
    "section": "8.1 パイプラインによるデータクリーニング",
    "text": "8.1 パイプラインによるデータクリーニング\nこの章では、代表的なデータクリーニングの手順を実行し、パイプに処理を順次追加しながら進めていきます。\n疫学的な分析やデータ処理では、クリーニングを行う際、複数の手順が連続して実行されることが多く、手順どうしが互いに関連していることがよくあります。Rでは多くの場合、このように連続した手順はクリーニングを行う一貫したパイプラインとして作成され、データが処理されます。作成されたパイプラインでは、未加工のデータセットが 1 つのデータ処理のステップから別のデータ処理のステップに渡されます。\nこのような連続処理には、dplyr パッケージの「動詞」関数と magrittr パッケージのパイプ演算子 %&gt;% が使用されます。パイプ処理は、始めに未加工データ（“linelist_raw.xlsx”）を扱い、最終的に、使用や保存、エクスポートなどが行えるクリーニングされた R データフレーム（linelist）を作成することを目標としています。\nパイプラインのデータ処理は、各手順の順番が重要です。クリーニングの手順には以下のようなものがあります。\n\nデータをインポートする\n\n列名を修正、または変更する\n\n重複したデータを排除する\n\n列を作成し、変換する（例：値の再定義または標準化）\n\n行を抽出、または追加する",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#パッケージの読み込み",
    "href": "new_pages/cleaning.jp.html#パッケージの読み込み",
    "title": "8  データクリーニングと主要関数",
    "section": "8.2 パッケージの読み込み",
    "text": "8.2 パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R パッケージに関する詳細は、R の基礎 の章をご覧ください。\n\npacman::p_load(\n  rio,        # データを読み込むためのパッケージ  \n  here,       # 相対ファイルパスを設定するためのパッケージ  \n  janitor,    # データ前処理と表の作成のためのパッケージ  \n  lubridate,  # 日付操作のためのパッケージ  \n  matchmaker, # データ辞書に基づいたデータ前処理のためのパッケージ\n  epikit,     # age_categories()を含むパッケージ  \n  tidyverse   # データ管理と可視化のためのパッケージ  \n  )",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#データのインポート",
    "href": "new_pages/cleaning.jp.html#データのインポート",
    "title": "8  データクリーニングと主要関数",
    "section": "8.3 データのインポート",
    "text": "8.3 データのインポート\n\nデータをインポートする\nここでは、rio パッケージの import() を使って、未加工の症例リスト（Excel ファイル）をインポートします。rio パッケージは、様々な形式のファイル（.xlsx、.csv、.tsv、.rds など）に対応できます。rio パッケージの詳細や、通常とは異なる状況（行のスキップ、欠損値の設定、Googleシートのインポートなど）での対処法を知りたい方は、インポートとエクスポート の章をご覧ください。\nお手元の環境でこの章の内容を実行したい方は、こちら から「未加工の」ラインリストをダウンロードしてください（.xlsx ファイルとしてダウンロードされます）。\nデータサイズが大きいためにインポートに時間がかかる場合は、インポートするためのコードを、インポート後のデータ前処理を行うパイプラインとは別の場所に書き、未加工データを元データとしてオブジェクトに保存しておくと便利です。コードを分けて書くことで、未加工のデータと前処理済みのデータの比較が容易になります。\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\")\n\nデータフレームの最初の 50 行を確認してみましょう。\n注釈：base R に含まれている関数 head(n) を使うと、R コンソールに最初の n 行が表示されます。\n\n\n\n\n\n\n\n\nインポートしたデータを確認する\nskimr パッケージの skim() を使うと、データフレーム全体の概要を把握することができます（詳しくは、記述統計表の作り方 を参照ください）。列は、文字値や数値などのデータ型別にまとめられています。\n注釈：“POSIXct” は未加工の日付データ型の一つです（詳細は、日付型データ の章をご覧ください）。\n\nskimr::skim(linelist_raw)\n\n\n\n\nData summary\n\n\nName\nlinelist_raw\n\n\nNumber of rows\n6611\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n17\n\n\nnumeric\n8\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n137\n0.98\n6\n6\n0\n5888\n0\n\n\ndate onset\n293\n0.96\n10\n10\n0\n580\n0\n\n\noutcome\n1500\n0.77\n5\n7\n0\n2\n0\n\n\ngender\n324\n0.95\n1\n1\n0\n2\n0\n\n\nhospital\n1512\n0.77\n5\n36\n0\n13\n0\n\n\ninfector\n2323\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2323\n0.65\n5\n7\n0\n2\n0\n\n\nage\n107\n0.98\n1\n2\n0\n75\n0\n\n\nage_unit\n7\n1.00\n5\n6\n0\n2\n0\n\n\nfever\n258\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n258\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n258\n0.96\n2\n3\n0\n2\n0\n\n\naches\n258\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n258\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n844\n0.87\n5\n5\n0\n1091\n0\n\n\nmerged_header\n0\n1.00\n1\n1\n0\n1\n0\n\n\n…28\n0\n1.00\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n7\n1.00\n16.60\n5.71\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nlon\n7\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n7\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nrow_num\n0\n1.00\n3240.91\n1857.83\n1.00\n1647.50\n3241.00\n4836.50\n6481.00\n\n\nwt_kg\n7\n1.00\n52.69\n18.59\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n7\n1.00\n125.25\n49.57\n4.00\n91.00\n130.00\n159.00\n295.00\n\n\nct_blood\n7\n1.00\n21.26\n1.67\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n158\n0.98\n38.60\n0.95\n35.20\n38.30\n38.80\n39.20\n40.80\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ninfection date\n2322\n0.65\n2012-04-09\n2015-04-27\n2014-10-04\n538\n\n\nhosp date\n7\n1.00\n2012-04-20\n2015-04-30\n2014-10-15\n570\n\n\ndate_of_outcome\n1068\n0.84\n2012-05-14\n2015-06-04\n2014-10-26\n575",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#列名",
    "href": "new_pages/cleaning.jp.html#列名",
    "title": "8  データクリーニングと主要関数",
    "section": "8.4 列名",
    "text": "8.4 列名\nRでは、データセットの「ヘッダー」または各列の「一番上」の値が列名になります。列名は、コード内で列を参照するために使用されるほか、図を作成する際はデフォルトのラベルとして使用されます。\nSAS や STATA など他の統計ソフトでは、短い列名を具体的に説明する「ラベル」が列名と共に使用されることが多いですが、R ではほとんど使用されません（R でもデータに列ラベルを追加することは可能です）。列名を図の表示に合わせて変更したい場合は、通常、図をプロットするコードの中で調整します（例えば、図の軸や凡例のタイトル、表示される表のヘッダーなどを調整したい場合です。詳細は、ggplot のヒントの章の 31.2 スケールと見やすい表の作り方 の章を参照してください）。データに列ラベルを付けたい場合は、こちら と こちら のページをご覧ください。\nR の列名はデータ分析やデータ管理において非常に頻繁に使用されるため、「きれいに」整えられている必要があります。列名を設定する際の一般的なルールとして、以下のように提案します。\n\n短い名前にする\nスペースを使わない（スペースが必要な場合は、アンダースコア _ に置き換えてください）\n&、#、&lt; &gt; などの特殊な文字を使用しない\n各列似たようなスタイルの用語を使用する（例：異なる種類の日付データを含む列が複数ある場合に、date_onset、date_report、date_death とするなど）\n\n以下に、base R の names() を使用して linelist_raw の列名を表示しました。表示された列名には、次のような特徴がみられます。\n\nスペースを含む名前がある（例：infection date）\n日付データを含む列が複数あるが、各列異なるルールで名付けられている (例：date onset と infection date）\n最後の 2 列の名前（“merged_header” と “…28”）を見ると、ダウンロードされた元の .xlsx ファイルの最後の 2 列には、マージされたヘッダーがあったことがわかります。2 つの列がマージされてできた列が R によって分割され、マージされてできた列の名前（“merged_header”）は元々の最初の列に割り当てられ、元々の 2 番目の列にはセルを保持するために一時的に “…28” が割り当てられています（マージされる前は空欄の列であり、28番目の列であるため）。\n\n\nnames(linelist_raw)\n\n [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\"          \n\n\n注釈：スペースを含む列名を参照するには、その名前をバックティック（`）で囲みます。例えば、linelist$` '\\x60infection date\\x60'` というように使用します。キーボードでは、バックティック（`）とシングルクォーテーションマーク（’）が異なることに注意してください。\n\n自動クリーニング\njanitor パッケージの clean_names() は、以下のように列名を標準化し、ユニークにします。\n\nすべての列名をアンダースコア（_）、数字、文字のみで構成されるように変換します。\n\nアクセント記号付きの文字は ASCII に音訳されます（例：ドイツ語のウムラウト記号付きの o は単に “o” に変換され、スペイン語の “enye”は “n”に変換されます）。\n\n変換後の列名の大文字と小文字の区別は、case = 引数を使って指定できます（デフォルトは “snake” になっていますが、他に “sentence”、“title”、“small_camel” などがあります）。\n\nreplace = 引数にベクトルを与えることで、特定の名前の置き換えを指定することができます（例：replace = c(onset = \"date_of_onset\"))\nclean_names() に関する公式ドキュメントは、こちらをご覧ください。\n\nでは、前処理のパイプラインを作成していきます。まず初めに、以下では、未加工のラインリストに対して clean_names() を使用し、列名を整えていきます。\n\n# 未加工のデータセットをclean_names()にパイプし、出力結果をlinelistとして保存する\nlinelist &lt;- linelist_raw %&gt;% \n  janitor::clean_names()\n\n# 新しく作成された linelist の列名を確認する\nnames(linelist)\n\n [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\"            \n\n\n注釈：最終列の列名 “…28” が “x28” に変化したことに注目してください。\n\n\n手動による列名のクリーニング\n上で行った自動クリーニングによる列名の標準化の後に、列名を個別に、一つずつ変更することが必要な場合があります。 rename() は NEW = OLD というスタイルを採用しており、新しい列名を既存の列名の前に書く必要があります。\n以下では、上で作成した自動クリーニングのパイプラインに名前を個別に変更するコマンドを追加しています。コードを読みやすくするため、戦略的にスペースを追加しています。\n\n# パイプチェーン処理 (未加工データから始まり、クリーニングステップを経由してパイプで処理される)\n##################################################################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # 列名の標準化\n    janitor::clean_names() %&gt;% \n    \n    # 列名を個別に変更\n           # 新しい列名            # 既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)\n\nこれで、列名が変更されていることがわかります。\n\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\n\n列の位置による名前の変更\n列名ではなく、列の位置によって列の名前を変更することもできます。\n\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)\n\n\nselect() および summarise() による列名の変更\nショートカットとして、dplyr パッケージの select() や summarise() でも列の名前を変更することができます。select() は特定の列だけを残すために使用します（本章で後述します）。summarise() については、データのグループ化 の章や、記述統計表の作り方 の章で説明します。これらの関数も rename() と同様に、new_name = old_name というフォーマットを使用します。以下はその例です。\n\nlinelist_raw %&gt;% \n  select(#新しい列名             # 既存の列名\n         date_infection       = `infection date`,\n         date_hospitalisation = `hosp date`) #列名を変更し、変更した列だけを残す\n\n\n\n\nその他の課題\n\n空白の Excel 列名\nR は、列名（ヘッダー）のないデータセット列を処理することはできません。したがって、データはあるがヘッダーがない Excel データセットをインポートした場合、R は “…1” や “…2” といった名前でヘッダーを埋めます。数字は列番号を表します（例：データセットの 4 列目にヘッダーがない場合、R はその列を “…4” と命名します）。\nR によって付与された名前は、ポジション番号（上記の例を参照）または割り当てられた名前（linelist_raw$...1）を参照することで、手動でクリーニングすることができます。\n\n\nExcel の列名とセルの結合\nExcel ファイル内のマージされたセルは、データを受け取る際によく問題になります。Excel・Stata・SASとの比較 の章で説明したように、マージされたセルは、人間がデータを読むときには便利ですが、 コンピュータにとっては「整頓されたデータ」ではないため、 データを読み込む際に多くの問題が発生します。R はマージされたセルに対応できないからです。\n人間が読めるデータとコンピュータが読めるデータは別物であることを、データ入力をする担当者に伝えてください。また、整頓されたデータの原則 をユーザーに教えるよう努めてください。可能であれば、セルが結合されていない整頓されたフォーマットでデータが手元に届くように、データ入力や収集の手順を変更しましょう。\n\n各変数はそれぞれ個別の列でなければなりません。\n\n各観測値は、それぞれ個別の行である必要があります。\n\nそれぞれの値は、それぞれ別のセルに入力されていなければなりません。\n\nrio パッケージの import() を使用した場合、マージされたセルの値は最初のセルに割り当てられ、それ以降のセルは空になります。\n結合されたセルを処理するための一つの解決策は、openxlsx パッケージの readWorkbook() を使用してデータをインポートすることです。引数 fillMergedCells = TRUE を設定すると、マージされたセルの値を、マージ範囲内のすべてのセルに入れることができます。\n\nlinelist_raw &lt;- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)\n\n警告：readWorkbook() で列名をマージすると、列名が重複してしまうので、手動で修正する必要があります。R は列名が重複するとうまく動作しません！重複した列名がある場合は、手動による列名のクリーニングのセクションで説明したように、列の位置（例えば 5 列目）を参照し、列名を再設定することができます。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#列の選択と並び替え",
    "href": "new_pages/cleaning.jp.html#列の選択と並び替え",
    "title": "8  データクリーニングと主要関数",
    "section": "8.5 列の選択と並び替え",
    "text": "8.5 列の選択と並び替え\ndplyr パッケージの select() を使って、残したい列を選択し、データフレーム内における列の順番を指定します。\n注意：以下の例では、linelist データフレームを select() で変更して表示していますが、これは例としてデータを示すためであり、変更されたデータは保存はされていないことに注意してください。変更された列名は、データフレームを names() にパイプすることで表示されます。\nまず、現時点での linelist データフレームのすべての列名を以下に表示します。\n\nnames(linelist)\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\n列の保持\n残しておきたい列のみを選択する\nselect() の中で、列の名前を引用符（” “）を使わずに指定します。指定された列は、指定された順序でデータフレームに表示されます。存在しない列を指定した場合、R がエラーを返すことに注意してください（このような場合にエラーを出さないようにするには、後述の any_of() の使い方を参照してください）。\n\n# ラインリストのデータセットはselect()に渡され、name()で列名を表示する\nlinelist %&gt;% \n  select(case_id, date_onset, date_hospitalisation, fever) %&gt;% \n  names()  # 列名を表示する\n\n[1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n[4] \"fever\"               \n\n\n\n\n“tidyselect” ヘルパー関数\ntidyverse パッケージに含まれる tidyselect パッケージのヘルパー関数は、列の保持や除外、または変換する列を簡単に指定するための関数であり、dplyr 系関数で列を選択する方法の基礎となっています。\n例えば、列の順番を変更したい場合、everything() は「記載されていない他のすべての列」を意味する便利な関数です。以下のコードは、date_onset と date_hospitalisation の列をデータセットの最初（左）に移動させますが、それ以外の列はすべてそのままにします。everything() の括弧内は空であることに注意してください。\n\n# date_onset と date_hospitalisation を先頭に移動させる\nlinelist %&gt;% \n  select(date_onset, date_hospitalisation, everything()) %&gt;% \n  names()\n\n [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n以下に、select()、across()、summary() などの dplyr 系関数内で使える他の “tidyselect” ヘルパー関数を紹介します。\n\neverything()：指定されていない他のすべての列を指定します。\n\nlast_col()：最後の列を指定します。\n\nwhere()：すべての列に関数を適用し、TRUEとなるものを選択します。\n\ncontains()：ある文字列を含む列を指定します。\n\n\n例）select(contains(\"time\"))\n\n\nstarts_with()：指定された接頭語を指定します。\n\n例）select(starts_with(\"date_\"))\n\n\nends_with()：指定された接尾語を指定します。\n\n\n例）select(ends_with(\"_post\"))\n\n\nmatches()：正規表現（regex）を適用し、列を指定します。\n\n\n例）select(matches(\"[pt]al\"))\n\n\nnum_range()：x01、x02、x03 のような数値の範囲を指定します。\n\nany_of()：関数内で使用した場合、指定する列が存在する場合は、その関数が適用され、存在しない場合は適用されず、エラーを表示しません。\n\n\n例）select(any_of(date_onset, date_death, cardiac_arrest))\n\n\n\nさらに、複数の列を列挙する場合には c()、連続した列には :、反対の列には !、AND には &、OR には | などの通常の演算子が使用できます。\n列の論理的な条件を指定したい場合は、where() を使用します。where() の中に関数を入れる場合は、関数の後に空の括弧をつけないでください。以下のコードは、 数字型データの列をすべて選択します。\n\n# 数字型データの列を選択する\nlinelist %&gt;% \n  select(where(is.numeric)) %&gt;% \n  names()\n\n[1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"     \n[6] \"ht_cm\"      \"ct_blood\"   \"temp\"      \n\n\nある特定の文字列が含まれている列のみを選択したい場合は、contains() を使用します。 また、ends_with() や starts_with() を使用すると、より詳細に列を指定することができます。\n\n# 特定の文字を含む列を選択する\nlinelist %&gt;% \n  select(contains(\"date\")) %&gt;% \n  names()\n\n[1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n[4] \"date_outcome\"        \n\n\nさらに、contains() と同様の動作をする matches() は、 OR バー（|）で区切られた複数の文字列などの正規表現を括弧内で指定することができます（正規表現の詳細については、文字型・文字列型データ の章を参照ください）。\n\n# 複数の文字列に当てはまる列を検索する\nlinelist %&gt;% \n  select(matches(\"onset|hosp|fev\")) %&gt;%   # \"|\" は OR を意味する\n  names()\n\n[1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n[4] \"fever\"               \n\n\n注意：指定した列名がデータセットに存在しない場合、エラーが返されてコードの処理が停止することがあります。存在するかどうかわからない列を指定したい場合は、any_of() を使用することをおすすめします。any_of() は、列の除外など、否定的な列の選択をする場合においてと特に有用です。\n以下のコードでは、指定されている列のうち 1 つだけがデータセットに存在しますが、エラーは発生せず、コードは処理を停止することなく実行されます。\n\nlinelist %&gt;% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %&gt;% \n  names()\n\n[1] \"date_onset\"\n\n\n\n\n列の除外\nデータセットから除外したい列がある場合は、列名の前にマイナス記号（-）を付ける（例：select(-outcome)）、または以下のように列名のベクトルの前にマイナス記号（-）を付けて指定すると、除外できます。指定された以外の列はすべて残ります。\n\nlinelist %&gt;% \n  select(-c(date_onset, fever:vomit)) %&gt;%\n     # date_onsetと、feverからvomitまでのすべての列を削除する\n  names()\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n [7] \"gender\"               \"hospital\"             \"lon\"                 \n[10] \"lat\"                  \"infector\"             \"source\"              \n[13] \"age\"                  \"age_unit\"             \"row_num\"             \n[16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n[19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[22] \"x28\"                 \n\n\nR の基本的な構文を使用し、除外したい列を NULL と定義して削除することもできます。例えば、以下のようになります。\n\nlinelist$date_onset &lt;- NULL   # Rの基本的な構文で列を削除する\n\n\n\n独立型\nselect() は、パイプ内で使用するだけでなく、独立したコマンドとして使用することもできます。この場合、最初の引数には前処理したい元のデータフレームを指定します。\n\n# IDと年齢に関連した列を持つ新しいラインリストを作成する\nlinelist_age &lt;- select(linelist, case_id, contains(\"age\"))\n\n# 列名を表示する\nnames(linelist_age)\n\n[1] \"case_id\"  \"age\"      \"age_unit\"\n\n\n\nパイプラインに追加\nlinelist_raw データセットには、row_num、merged_header、x28 という必要のない列があります。以下に、前処理パイプラインの select() コマンドで削除する例を示します。\n\n# パイプライン処理 (未加工データから始まり、クリーニングステップを経由してパイプで処理される)\n##################################################################################\n\n\n# パイプラインを開始する\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n\n     # 列名の標準化\n    janitor::clean_names() %&gt;% \n    \n\n     # 列名を個別に変更\n           #新しい列名            #既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # ここまでは、すでに説明したクリーニング手順\n    #####################################################\n\n   # 列の除外\n    select(-c(row_num, merged_header, x28))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#重複行の削除",
    "href": "new_pages/cleaning.jp.html#重複行の削除",
    "title": "8  データクリーニングと主要関数",
    "section": "8.6 重複行の削除",
    "text": "8.6 重複行の削除\n重複したデータを削除する方法の詳細については、このハンドブックの 重複データの排除 の章を参照してください。本章では、重複した行の削除について、非常に簡単な例のみを紹介します。\ndplyr パッケージの distinct() は、データフレーム内のすべての行をチェックし、重複していない行のみを残します。つまり、完全に重複している行をデータフレームから削除します。\n重複する行をチェックする際には、列の範囲を指定できますが、デフォルトではデータフレーム内のすべての列が対象となります。重複データの排除 の章にあるように、対象となる列の範囲を調整して特定の列に関してのみ、重複した行があるかをチェックすることもできます。\n以下は、空のコマンド distinct() をパイプチェーンに追加するだけのシンプルな例です。これにより、他の行と完全に同一である行がない（重複している行がない）ことが保証されます（データフレーム内のすべての列がチェックされます）。\n現時点の linelist データフレームには、全部で nrow(linelist) 行が含まれています。\n\nlinelist &lt;- linelist %&gt;% \n  distinct()\n\n上のコードを実行して重複削除すると、データフレームの行数は nrow(linelist) になります。他の行と完全に同一である行が削除されました。\n以下では、パイプラインに distinct() コマンドを追加しています。\n\n# パイプチェーン処理 (未加工データから始まり、クリーニングステップを経由してパイプで処理される)\n##################################################################################\n\n# パイプラインを開始する\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n\n     # 列名の標準化\n    janitor::clean_names() %&gt;% \n    \n     # 列名を個別に変更\n           # 新しい列名            # 既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # 列の除去\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # ここまでは、すでに説明したクリーニング手順\n    #####################################################\n    \n    # 重複の除去\n    distinct()",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#列の作成と変換",
    "href": "new_pages/cleaning.jp.html#列の作成と変換",
    "title": "8  データクリーニングと主要関数",
    "section": "8.7 列の作成と変換",
    "text": "8.7 列の作成と変換\n新しい列の追加や、既存の列の修正が必要な場合には、dplyr 系関数の mutate() を使用することをおすすめします。\n以下に、mutate() を使用して新しい列を作成する例を紹介します。次のような構文を使用します：mutate(new_column_name = value or transformation)\nStata の generate コマンドに似ていますが、R の mutate() は既存の列を修正する場合にも使用できます。\n\n新しい列の作成\n以下は、mutate() を使用して新しい列を作成する最も基本的なコマンドです。ここでは、すべての行の値が 10 である新しい列 new_col を作成します。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(new_col = 10)\n\nまた、他の列の値を参照して、計算を行うこともできます。以下では、bmi という新しい列が作成され、各症例（各行）の Body Mass Index（BMI）を格納しています。これは、既存の列である ht_cm と wt_kg を使用して、BMI = kg/m^2 の式で計算されたものです。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\n新しい列を複数作成する場合は、それぞれをコンマで区切って改行します。以下は、stringr パッケージの str_glue() を使って他列の値を組み合わせた列を作成するなど、複数の新しい列を作成する場合の例です（str_glue() についての詳細は、文字型・文字列型データ の章を参照ください）。\n\nnew_col_demo &lt;- linelist %&gt;%                       \n  mutate(\n    new_var_dup    = case_id,             # 新しい列＝既存の列のコピーを作成する\n    new_var_static = 7,                   # 新しい列＝全ての値が同じ\n    new_var_static = new_var_static + 5,  # 列を上書きしたり、他の変数を使って計算したりすることができる\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") \n    # 新しい列 = 他の列の値を貼り付ける\n    ) %&gt;% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        \n# デモ用に新しい列のみを表示\n\n以下では、新しい列を確認するために、新しい列とそれを作成するために使用された列のみが表示されています。\n\n\n\n\n\n\nヒント：mutate() の変化形として、transmute() という関数があります。この関数は、mutate() と同じように新しい列を追加しますが、括弧の中に書かれていないすべての列を削除または除外します。\n\n# HIDDEN FROM READER（ウェブ版には表示されない）\n# 上で新しく作成されたデモ用の列を除外する\n\n# linelist &lt;- linelist %&gt;% \n#   select(-contains(\"new_var\"))\n\n\n\n列のデータ型の変換\n日付、数字、理論値（TRUE/FALSE）を含む列は、正しく分類された場合のみ期待通りの動きをします。例えば、文字型の “2” と数字型の 2 は異なることに注意してください。\nデータをインポートするコードの中に列のデータ型を指定する方法もありますが、扱いにくい場合が多いです。オブジェクトや列のデータ型を変換する方法については、R の基礎 の章の 3.10 オブジェクトのデータ型のセクションを参照してください。\n本章では、まず、重要な列について、正しいデータ型であるかどうかのチェックを行ってみましょう。これは本章の最初に skim() を実行したときに確認しました。\nでは、具体的に見ていきましょう。現在、age 列のデータ型は 文字列型（character）ですが、定量的な分析を行うためには、age 列の数字が数値として認識される必要があります。\n\nclass(linelist$age)\n\n[1] \"character\"\n\n\n以下で、date_onset 列のデータ型も確認してみると、文字列型であることがわかります。分析を行うためは、date_onset 列の日付が日付として認識される必要があります。\n\nclass(linelist$date_onset)\n\n[1] \"character\"\n\n\nこのようなデータ型の相違を解決するために、mutate() の機能を使用し、変換で列を再定義していきます。列の定義は変更しませんが、データ型を変更します。以下では、基本的な例として、age 列を数字型（numeric）に変換します。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age = as.numeric(age))\n\n同様に、as.character() や as.logical() を使用することもできます。因子型（factor）に変換したい場合は、base R の factor() や forcats パッケージの as_factor() を使いましょう。詳しくは、因子（ファクタ）型データ の章をご覧ください。\n日付型（date）への変換には注意が必要です。日付型データ の章でいくつか方法を紹介しますが、通常、日付型への変換を正しく行うためには、日付データがすべて同じ形式である必要があります（例：“MM/DD/YYYY”、または “DD MM YYYY”）。データを日付型に変換した後にチェックして、各値が正しく変換されたことを確認してください。\n\n\nグループ化されたデータ\nデータフレームがすでにグループ化されている場合（グループ化の詳細は、データのグループ化 の章を参照ください）は、mutate() の動作がグループ化されていない場合と異なるかもしれません。データフレームがすでにグループ化されている場合、mean()、median()、max() などの要約関数は、すべての行ではなくグループごとに計算されます。\n\n# 全行の平均値で正規化された年齢\nlinelist %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# 年齢を病院グループの平均値で正規化\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\nグループ化されたデータフレームでの mutate () の使用については、こちらの tidyverse mutate に関するドキュメント で詳しく説明されています。必要な方はご覧ください。\n\n\n複数列の一斉変換\nコードを簡潔にするために、同じ変換を行うコマンドを複数の列に適用したい場合があります。dplyr パッケージ（ tidyverse パッケージにも含まれています）の across() を使用すると、データの変換を行うコマンドを一度に複数の列に適用することができます。 across() はすべての dplyr 系関数で使用することができますが、一般的には select()、mutate()、filter()、summarise() 内でよく使用されます。across() を summarise() 内でどのように使用するかについて知りたい方は、記述統計表の作り方 の章をご覧ください。\nacross() では、.cols = 引数には列を指定し、.fns = 引数には適用する関数を指定します。.fns に与える追加の引数は、コンマの後に含めることができます。\n\nacross() を使用して列を選択する\n.cols = 引数に列を指定します。 個別に列名を指定することもできますし、“tidyselect” ヘルパー関数を使用することもできます。関数を .fns = 引数に指定します。以下に示すように、関数機能を使用すると、関数はその括弧（ ）なしで記述することに注意してください。\n以下の例では、as.character() を使用した文字型への変換が、 across() で指定された特定の列に適用されます。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n\n列を指定する際には、“tidyselect” ヘルパー関数を使用すると便利です。“tidyselect” ヘルパー関数には、everything()、last_col()、where()、starts_with()、ends_with()、contains()、matches()、num_range()、any_of() などがあり、本章上部の列の選択と並び替えのセクションで詳述されています。\nまず、データフレーム内のすべての列を文字列型（character）に変換する例を以下に示します。\n\n# すべての列を文字列型に変換する\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = everything(), .fns = as.character))\n\n他の例として、例えば列名に “date”という文字列が含まれている列を文字列型に変換したい場合のコマンドを以下に紹介します（コンマと括弧の配置に注意してください）。\n\n# date という文字が列名に含まれている列を文字列型に変換する\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\n\nまた、別の例として、現在 POSIXct 型（未加工の日付時分秒を示すデータ型）の列を日付型（date）に変換する例を示します。まず、is.POSIXct() の評価値が TRUE である列を where() で検索し、次に、これらの列に as.Date() を適用して、通常の 日付型（date）に変換します。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))\n\n\nacross() 内で where() を使用し、is.POSIXct() で各列が TRUE または FALSE か評価できるようにしていることに注意してください。\nis.POSIXct()は lubridate パッケージの関数であることに注意してください。is.character()、is.numeric()、is.logical() などの他の類似した “is” 系関数は base R の関数です。\n\n\n\nacross()\nacross() に関数を与える方法の詳細については、?across をコンソールで実行して表示されるドキュメントをお読みください。要約すると、対象の列に対して実行する関数を指定する方法はいくつかあり、独自の関数を指定することもできます。\n\n関数名のみを指定することができます（例：mean または as.character）。\n関数を purrr スタイルで使用することができます（例：~ mean(.x, na.rm = TRUE)) （詳細は、ループと反復処理・リストの操作 の章を参照してください）。\nリストを使用することで、複数の関数を指定することができます（例：list(mean = mean, n_miss = ~ sum(is.na(.x)))）。\n\n複数の関数を指定した場合は、入力された列ごとに複数の変換後の列が返され、col_fn という形式で一意の名前が付けられます。返された列の名前を調整したい場合は、.names = 引数で glue パッケージの構文を使用してください（glue パッケージに関する詳細は、文字型・文字列型データ の章を参照ください）。{.col} と {.fn} は入力された列と関数の省略形です。\n\n\n\n\n\ncoalesce()\ncoalesce() は、dplyr パッケージに含まれており、指定された値のうち、欠損値ではない最初の値を見つける関数です。この関数は、指定された順序で、取得された欠損値ではない最初の値で欠損値を埋めます。\nここでは、データフレーム以外の例を示します。2 つのベクトルがあるとします。1 つは患者の発見された村、もう 1 つは患者の居住地の村です。coalesce() を使用し、各ベクトルの欠損値ではない最初の値を見つけることができます。\n\nvillage_detection &lt;- c(\"a\", \"b\", NA,  NA)\nvillage_residence &lt;- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage &lt;- coalesce(village_detection, village_residence)\nvillage    # 結果を表示する\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\ncoalesce() は、データフレームの列を対象とした場合にも同じように動作します。この関数は、指定した列の中で欠損地ではない最初の値を、新しい列の値として各行ごとに割り当てます。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(village = coalesce(village_detection, village_residence))\n\nこれは、データフレームの行ごとに処理をしていく「行処理（row-wise 演算）」の一例です。より複雑な行処理については、本章下部の 8.12 行単位の計算 のセクションをご覧ください。\n\n\n累積計算\nデータフレームの行を計算し、その時点までの累積和、平均、最小、最大などを列に反映させたい場合は、以下の関数を使用します。\ncumsum() は、以下のように、累積和を返します。\n\nsum(c(2,4,15,10))     # 1つの数字のみを返す\n\n[1] 31\n\ncumsum(c(2,4,15,10))  # 各ステップでの累積和を返す\n\n[1]  2  6 21 31\n\n\nこれは、データフレームで新しい列を作るときに使用できます。例えば、アウトブレイクにおける一日あたりの累積症例数を知りたい場合は、次のようなコードを使って計算できます。\n\ncumulative_case_counts &lt;- linelist %&gt;%  # 症例ラインリスト \n  count(date_onset) %&gt;%                 # 一日当たりの行数をカウント   \n  mutate(cumulative_cases = cumsum(n))  # 累積和の新しい列\n\n以下に、最初の 10 行を表示します。\n\nhead(cumulative_case_counts, 10)\n\n   date_onset n cumulative_cases\n1  2012-04-15 1                1\n2  2012-05-05 1                2\n3  2012-05-08 1                3\n4  2012-05-31 1                4\n5  2012-06-02 1                5\n6  2012-06-07 1                6\n7  2012-06-14 1                7\n8  2012-06-21 1                8\n9  2012-06-24 1                9\n10 2012-06-25 1               10\n\n\n流行曲線（エピカーブ）で累積罹患率をプロットする方法については、流行曲線（エピカーブ） の章をご覧ください。\n関連項目：cumsum()、cummean()、cummin()、cummax()、cumany()、cumall()\n\n\nR の基本パッケージ base を使用する\nbase R を使って新しい列を定義する（または列を再定義する）こともできます。その場合は、新しい列（または修正する列）にデータフレームの名前を $ でつないで書き、代入演算子 &lt;- を使って新しい値を定義します。base R を使用する際には、毎回、列名の前にデータフレーム名を指定しなければならないことを覚えておいてください（例：dataframe$column）。ここでは、base R を使用して 新しく bmi という列を作成する例を示します。\n\nlinelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)\n\n\n\nパイプラインへの追加\n以下では、パイプラインに新しい列を追加し、いくつかの列のデータ型を変換しています。\n\n# パイプライン処理 (未加工データから始まり、クリーニングステップを経由してパイプで処理される)\n##################################################################################\n\n\n# パイプラインの開始\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n  # 列名の標準化\n    janitor::clean_names() %&gt;% \n    \n     # 列名を個別に変更\n           # 新しい列名           #既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n\n    # 列の除去\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # 重複行の削除\n    distinct() %&gt;% \n  \n    # ここまでは、すでに説明したクリーニング手順\n    ###################################################\n    # 新しい列の追加\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;% \n  \n    # 列のデータ型を変換\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#値の再定義",
    "href": "new_pages/cleaning.jp.html#値の再定義",
    "title": "8  データクリーニングと主要関数",
    "section": "8.8 値の再定義",
    "text": "8.8 値の再定義\n以下のような場合には、値を再定義（変更）する必要があります。\n\n特定の値を編集する場合（例：日付の年号や書式が間違っている場合など）。\n同じ綴りでない値を調整する場合。\nカテゴリ値の新しい列を作成する場合。\n数値カテゴリの新しい列を作成する（例：年齢カテゴリ）。\n\n\n特定の値\n値を手動で変更するためには、mutate() 内で recode() を使用します。\n例えば、データの中に意味のない日付（例：“2014-14-15”）があるとします。未加工の元データ上でマニュアルで日付を修正することもできますし、mutate() と recode() を使用して前処理パイプラインに日付を修正するコマンドを書き込むこともできます。後者の方がより透明性と再現性が高く、行われた分析を理解しようとする第三者や同じように分析しようとする人にとって、分析を再現しやすくなります。\n\n# 間違っている値の修正                    # 既存の値     # 新しい値\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\n\n上の例の mutate() の行は、「date_onset 列内の間違っている値を新しい値に変換し、date_onset 列に再定義する」と読むことができます。recode() のパターン（既存の値 = 新しい値）は、ほとんどの R の関数のパターン（新しい値 = 既存の値）とは逆であることに注意してください。R の開発コミュニティでは、この相違の統一化に取り組んでいます。\n以下に、別の例として、1 つの列において複数の値を再定義する例を紹介します。\nlinelist の hospital 列には、いくつか綴り（つづり）が間違った値があることに加え、多くの欠損値があるため、hospital 列の値をクリーニングする必要があります。\n\ntable(linelist$hospital, useNA = \"always\")  \n\n\n                     Central Hopital                     Central Hospital \n                                  11                                  457 \n                          Hospital A                           Hospital B \n                                 290                                  289 \n                    Military Hopital                    Military Hospital \n                                  32                                  798 \n                    Mitylira Hopital                    Mitylira Hospital \n                                   1                                   79 \n                               Other                         Port Hopital \n                                 907                                   48 \n                       Port Hospital St. Mark's Maternity Hospital (SMMH) \n                                1756                                  417 \n  St. Marks Maternity Hopital (SMMH)                                 &lt;NA&gt; \n                                  11                                 1512 \n\n # 欠損値を含むすべての一意の値のテーブルを表示する\n\n以下の recode() コマンドでは、指定した複数の値を書き換え、hospital 列を再定義しています。既存の値から新しい値に書き換えるそれぞれのコードの後にコンマを忘れないようにしてください。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital,\n                     # 参照:     既存の値 = 新しい値\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\n\n上のコードを実行すると、 hospital 列内で間違った綴りの値が修正され、正しい綴りの値のグループに統合されていることがわかります。\n\ntable(linelist$hospital, useNA = \"always\")\n\n\n                    Central Hospital                           Hospital A \n                                 468                                  290 \n                          Hospital B                    Military Hospital \n                                 289                                  910 \n                               Other                        Port Hospital \n                                 907                                 1804 \nSt. Mark's Maternity Hospital (SMMH)                                 &lt;NA&gt; \n                                 428                                 1512 \n\n\nヒント：等号（=）の前後には、スペースをいくつか入れても問題ありません。コードを読みやすくするために、すべての行またはほとんどの行で等号（=）の場所を揃えることをおすすめします。また、ハッシュタグでコメント行を追加し、どちらが古い値でどちらが新しい値なのかを、第三者に明確にわかるようにすることも大事なポイントです。\nヒント：データセットの中には、空白文字の値が存在することがあります（これは、R の欠損値である NA として認識されません）。このような値を参照するためには、2 つの引用符をスペースを空けずに（““）使用します。\n\n\n論理条件\n以下では、論理条件を使用して列の値を再定義する方法を説明します。\n\n単純な論理条件：replace()、ifelse()、if_else() を使う\n複雑な論理条件：case_when() を使う\n\n\n\n単純な論理条件\n\nreplace()\nreplace() は base R の関数で、論理条件を使って変更する行を指定します。一般的な構文は以下の通りです。\nmutate(col_to_change = replace(col_to_change, criteria for rows, new value))\nreplace() を使用する一般的な状況としては、一意の行識別子（症例ごとの ID 番号など）を使用して、1 つの行の 1 つの値だけを変更する場合です。下の例では、case_id が「2195」である行の性別を “Female”に変更しています。\n\n# 例：ある特定の観測データの性別を \"Female\" に変更する\nlinelist &lt;- linelist %&gt;% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\n\nR の基本的な構文と角括弧 [ ] を使った同等のコマンドは、以下の通りです。linelist データフレームの gender 列の値を（linelist の case_id 列の値が「2195」である行について）“Female” に変更する、と読めます。\n\nlinelist$gender[linelist$case_id == \"2195\"] &lt;- \"Female\"\n\n\n\nifelse() と if_else()\n簡潔な論理条件のためのツールとして、ifelse() とそのパートナーである if_else() があります。しかし、ほとんどの場合、再定義のためにはcase_when()（以下に詳述）を使ったほうがわかりやすいでしょう。これらの “if else” コマンドは、if とelse のプログラミング文を簡略化したものです。一般的な構文は以下の通りです。\nifelse(condition, value to return if condition evaluates to TRUE, value to return if condition evaluates to FALSE)\n下の例では、source_known という列が新しく定義されています。既存の列 source の値が欠損していなければ、source_known 列の値は “known” に設定され、source 列の値が欠落している場合は、 “unknown” に設定されます。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n\nif_else() は、日付を扱う dplyr の特別バージョンです。真（TRUE）の値が日付の場合、「偽（FALSE）」の値も日付でなければならないことに注意してください。そのため、単に NA ではなく NA_real_ という特別な値を使用しています。\n\n#  患者が死亡していない場合はNAとなる死亡日の列を作成する\nlinelist &lt;- linelist %&gt;% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))\n\nifelseコマンドをたくさん並べるのは避けましょう…代わりにcase_when()を使ってください！case_when() の方がずっと読みやすく、エラーも少なくなります。\n\n\n\n\n\n\n\n\n\nデータフレーム以外で、コード内で使用するオブジェクトの値を切り替えたい場合は、base R のswitch() の使用を検討してください。\n\n\n\n複雑な論理条件\nある変数を複数のグループに分ける場合や、複雑な論理条件文を使って値を再定義する必要がある場合は、dplyr の case_when() を使用します。この関数は、データフレーム内のすべての行を計算し、その行が指定された基準を満たしているかどうかを評価して、正しい値を新しく割り当てます。\ncase_when() コマンドは、右側（Right-Hand Side: RHS）左側（Left-Hand Side: LHS）をチルダ ~ で区切ったコードで構成されています。各コードの左側には論理条件が、右側には準拠値が記述されて、コンマで区切られています。\n例えば、ここでは age と age_unit の列を利用して age_years の列を作成しています。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_years = case_when(\n       age_unit == \"years\"  ~ age,       # 年齢が年単位の場合\n       age_unit == \"months\" ~ age/12,    # 年齢が月単位の場合、値を 12 で割る\n       is.na(age_unit)      ~ age))      # 年齢の単位が見つからない場合は、年を仮定\n                                         # その他の状況では、欠損値 NA とする\n\nデータの各行が評価されるとき、case_when() 内に書かれたコードの順に、上から下へと適用・評価されます。ある行で論理式が TRUE と評価された場合、その行の評価式の右側（RHS）の値がオブジェクトに割り当てられ、残りの論理式は同じ行では評価されません。したがって、もっとも明確な範囲の論理式（狭い範囲の論理式）を最初に記述して、もっとも一般的な範囲の論理式（広い範囲の論理式）を最後に書くのがよいでしょう。いずれの論理式の右側 (RHS) にも当てはまらなかった場合は、オブジェクトに NA が割り当てられます。\nときには、最後の行にそれ以前の行で記述しなかったすべての場合に値を割り当てる論理式を記述する必要があるかもしれません。この場合の論理式は、左辺 (LHS) に TRUE と記述すると実現できます。この記述方法は、この行より前の行の論理式のいずれも当てはまらない場合に対応します。左辺に TRUE と書いた論理式の右辺 (RHS) には、“check me!” や “missing” のような文字列型を指定できます。\n以下は、case_when() の別例です。確定症例と疑義症例を定義する論理式に従い、症例各行の分類を示す新しい列を作成する例です。\n\nlinelist &lt;- linelist %&gt;% \n     mutate(case_status = case_when(\n\n          # 患者が血液検査を受けて、結果が陽性だった場合、\n          # 該当行の case_status 列に \"Confirmed\"（確定症例）を代入する\n          ct_blood &lt; 20                   ~ \"Confirmed\",\n\n          # 患者の血液検査が陽性ではなく、かつ\n          # \"source\"（疫学的関係あり）であり、かつ、発熱している (fever) 場合\n          # 該当行の case_status 列に \"Suspect\"（疑義症例）を代入する\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n\n          # 上記の論理式に該当しない患者の場合\n          # \"To investigate\"（要調査）を代入する\n          TRUE                            ~ \"To investigate\"))\n\n警告：右側の値はすべて同じデータ型でなければなりません。欠損値（NA）を割り当てるには、NA_character_、NA_real_（数値や POSIX の場合）、as.Date(NA)など、データ型によって異なる NA を使用する必要があるかもしれません。詳しくは、日付型データの章の日付の操作 のセクションをご覧ください。\n\n\n欠損値\n以下は、データクリーニングの観点から欠損値を処理するための特別な関数です。\n論理的に欠損値をテストする is.na() などの関数について知りたい場合など、欠損値の識別と処理に関して詳しく学びたい方は、欠損データの処理 の章を参照してください。\nreplace_na()\n欠損値（NA）を “Missing” などの特定の値に変更する場合は、dplyr パッケージに含まれる replace_na() をmutate() 内で使用します。これは、上記の recode と同じように使用されることに注意してください 。対象となる変数の名前は、replace_na() 内で再度明記される必要があります。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\n\nfct_explicit_na()\nfct_explicit_na() は、forcats パッケージに含まれている関数です。forcats パッケージは、因子（ファクタ）型の列を扱います。因子型は、c(\"First\", \"Second\", \"Third\") のような順序付きの値を扱うための R の方法であり、表やプロットに表示される値（病院など）の順序を設定します。詳細は、因子（ファクタ）型データ の章を参照してください。\nデータが因子型で、replace_na() を使って NA を “Missing” に変換しようとすると、以下のようなエラーが表示されます。\ninvalid factor level, NA generated.\n“Missing” を因子型がとれるレベルとして定義せずに追加しようとしたため、エラーとなります。\nこの問題を解決する最も簡単な方法は、forcats パッケージの fct_explicit_na() を使用することです。この関数は、列を因子型に変換し、NA 値を文字型の “(Missing)” に変換します。\n\nlinelist %&gt;% \n  mutate(hospital = fct_explicit_na(hospital))\n\nもう一つ、さらに手間がかかる方法ですが、fct_expand() を用いて因子型を追加し、その後、欠損値を変換しても同じ結果を得ることができます。\nna_if()\n特定の値を NA に変換するには、dplyr の na_if() を使います。以下のコマンドは replace_na() とは逆の操作を行います。以下の例では、列 hospital の “Missing” の値はすべて NA に変換されます。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n\n注意： na_if() は論理的条件（例：“all values &gt; 99”）には使用できません。このような論理的条件には、replace() または case_when() を使用してください。\n\n# 40度以上の温度をNAに変換する \nlinelist &lt;- linelist %&gt;% \n  mutate(temp = replace(temp, temp &gt; 40, NA))\n\n# 2000年1月1日以前の発症日を欠損に変換する\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = replace(date_onset, date_onset &gt; as.Date(\"2000-01-01\"), NA))\n\n\n\nクリーニングディクショナリ（Cleaning dictionary）\nR の matchemaker パッケージに含まれる関数 match_df() を使用し、データフレームをクリーニングディクショナリを用いて前処理します。\n\nまず、クリーニングディクショナリを作成します。クリーニングディクショナリは、以下の 3 つの列で構成される必要があります。\n\n\nfrom 列（不正な値）\nto 列（正しい値）\n変更を適用する列を指定する列（すべての列に変更を適用する場合は、“.global” と記入する）\n\n注意：.globalのディクショナリ項目は、列固有のディクショナリ項目によって上書きされます。\n\n\n\n\n\n\n\n\n\n\n本章では、ハンドブックとデータのダウンロード の章にあるクリーニングディクショナリを例として使用しますので、上のリンクからダウンロードし、インポートしてください。\n\n\ncleaning_dict &lt;- import(\"cleaning_dict.csv\")\n\n\n未加工のラインリストを match_df() に渡し、distionary = 引数にインポートしたクリーニングディクショナリデータフレームを指定します。引数 from = には「置き換え前」の値を含むディクショナリの列名を指定します。引数 by = には対応する「置き換え後」の値を含む列名を指定し、データフレームの 3 列目には置き換えする列名を列挙します。すべての列に対して置き換えを実行する場合は、by = 列に .global を指定します。4 列目 order は、変更後の値の並び順を指定します。\n\n詳しくは ?match_df を実行すると表示されるパッケージドキュメントを参照してください。この関数は、サイズの大きなデータセットでは、実行時間が長いことに注意してください。\n\nlinelist &lt;- linelist %&gt;%     # match_df() にデータセットを渡す\n     matchmaker::match_df(\n          dictionary = cleaning_dict,  # ディクショナリデータフレームのオブジェクト名を指定\n          from = \"from\",               # 置き換える値を格納した列を指定（デフォルトでは、1 列目）\n          to = \"to\",                   # 置き換え後の値を格納した列を指定（デフォルトでは 2 列目）\n          by = \"col\"                   # 置き換え対象の列名を列挙した列を指定（デフォルトでは 3 列目）\n  )\n\n以下の表を右側にスクロールすると、上のコマンドを実行後に値がどのように変化したかがわかります。特に、性別の変化（小文字から大文字に変換された）や、すべての症状の列が yes/no の 2 択から 1/0 の 2 択に変化したことに注目してください。\n\n\n\n\n\n\nクリーニングディクショナリの col 列に記入される列名は、クリーニングする時点での列名と同一でなければならないことに注意してください。詳細については、こちら の linelist パッケージのドキュメントを参照してください。\n\nパイプチェーンへの追加\n以下では、いくつかの新しい列と列変換がパイプチェーンに追加されています。\n\n#クリーニングパイプチェーン (未加工データから始まり、クリーニングステップ経由してパイプで処理される)\n##################################################################################\n\n# パイプチェーンの処理開始\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n \n     # 列名の構文の標準化\n    janitor::clean_names() %&gt;% \n\n     # 手動で列名を変更\n           # 新しい列名             # 既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # 列の除去\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # 重複除去\n    distinct() %&gt;% \n  \n    # 列を追加\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # 列のデータ型を変換\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n  \n    # 列の追加: 入院の遅れ\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # ここまでは、すでに説明したクリーニング手順\n   ###################################################\n\n    # 病院の列の値をクリーニングする\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # age_years 列を新しく作成する (age 列と age_unit 列を使用する)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#num_cats",
    "href": "new_pages/cleaning.jp.html#num_cats",
    "title": "8  データクリーニングと主要関数",
    "section": "8.9 数値カテゴリ",
    "text": "8.9 数値カテゴリ\nここでは、数値データをカテゴリ化する方法を説明します。一般的な例としては、年齢のカテゴリー化や、検査結果のグループ化などがあります。ここでは、以下について説明します。\n\nage_categories() ( epikit パッケージより)\ncut()（base Rより）\ncase_when()\nquantile() と ntile() を使った分位数による分割\n\n\n分布を確認する\n例として、age_years 列を使用して新たに age_cat 列を作成していきます。\n\n# linelistのage列のデータ型をチェックする\nclass(linelist$age_years)\n\n[1] \"numeric\"\n\n\nまずデータの分布を確認し、適切な分割点（カットポイント）を作ります。詳しくは ggplot の基礎 の章をご覧ください。\n\n# 分布を確認する\nhist(linelist$age_years)\n\n\n\n\n\n\n\n\n\nsummary(linelist$age_years, na.rm=T)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.04   23.00   84.00     107 \n\n\n注意：数字型のデータが文字列型としてインポートされることがあります。これは、値の一部に数字以外の文字が含まれている場合に発生します。例えば、年齢を「2ヶ月」と入力した場合や、（R のロケール設定にもよりますが）小数点の代わりにコンマが使用されている場合などです（例：“4,5” が 4 年半の意味で使われている場合）。\n\n\n\nage_categories()\nepikit パッケージの age_categories() を使用すると、数値列の分類やラベル付けを簡単に行うことができます（注：この関数は、年齢以外の数値変数にも適用できます）。結果として出力される列は、自動的に順序付けられたカテゴリーとなります。\n入力する必要がある項目は、以下の通りです。\n\n数値のベクトル（列）\nbreakers = 引数：新しいグループの分割点の数値ベクトルを指定する。\n\nまず、簡単な例を示します。\n\n# 簡単な例\n################\npacman::p_load(epikit)                     #パッケージの読み込み\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(             # 新しい列の作成\n      age_years,                           # 分割点によってグループ化する数値列\n      breakers = c(0, 5, 10, 15, 20,       # 分割点\n                   30, 40, 50, 60, 70)))\n\n# テーブルを表示\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    27     7   107 \n\n\n指定した分割点によるグループ分けは、デフォルトでは下限の値から始まります。つまり、下限の値は「上位」のグループに含まれ、グループが下または左に「開いている」状態になります。下図のように、各分割点に1を加えることで、上または右で開いたグループにすることができます。\n\n# 同じカテゴリーの上端を含める\n############################################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# テーブルを表示\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  &lt;NA&gt; \n 1469  1195  1040   770  1149   547   231    70    24     6   107 \n\n\nseparator = を使用すると、ラベルの表示方法を調整できます。 デフォルトは “-” です。\nまた、ceiling = を使用し、分割点として指定された数値のうち最大の値の扱い方を調整できます。ceiling = TRUE と設定すると、指定された分割点の最大値が「上限（ceiling）」となり、最大値を超えるカテゴリ “XX+” は作成されません。分割点の最大値（または upper = 引数が使用されている場合は、その値）を超える値は、NA に分類されます。以下は、ceiling = TRUE の例で、XX+ のカテゴリは作成されず、70（分割点の最大値）を超える値は NA として割り当てられます。\n\n# 上限をTRUEに設定した場合\n##########################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 が上限となり、70 以上の値は NA となる\n\n# テーブルを表示\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    28   113 \n\n\nまた、breakers = の代わりに、lower＝、upper＝、by＝ のすべてを指定することもできます。\n\nlower = 下限となる値（デフォルトは 0）\nupper = 上限となる値\nby = グループ内の年の数\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# テーブルの表示\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  &lt;NA&gt; \n 2450  1875  1216   597   251    78    27     6     1     0     0   107 \n\n\n詳細は、age_categories() のヘルプページをご覧ください（R コンソールで ?age_categories と入力してください）。\n\n\n\ncut()\ncut() は age_categories() に代わる base R の関数ですが、age_categories() と比較すると複雑です。以下の説明を読むと、この処理を簡単にするために age_categories() が開発されたことがわかると思います。age_categories() との注目すべき違いは、以下のとおりです。\n\n別のパッケージをインストール・ロードする必要がない。\nグループが右か左に開いているか閉じているかを指定できる。\n正確なラベルを自分で用意する必要がある。\n一番下のグループに “0” を入れたい場合は、その旨を明記する必要がある。\n\ncut() の基本的な構文は、まず分割したい数値列（age_years）を指定し、次に breaks 引数に分割点の数値ベクトル c() を指定します。cut() を使用すると、結果として出力される列は順序付けられたカテゴリとなります。\nデフォルトでは、右または上側が「オープン」で包括的（左または下側が「クローズ」で排他的）になるように分類されます。これは、age_categories() 関数とは逆の動作です。デフォルトのラベルでは “(A, B]” という表記が使われており、これは「Aは含まれないがBは含まれる」という意味です。right = TRUE に設定することで、この動作を逆にすることができます。\nデフォルトでは、“0” の値は一番下のグループから除外され、NA に分類されることに注意してください。乳幼児が 0 歳としてコードされているデータもあるので、注意が必要です。これを変更するには、引数 include.latest = TRUE を追加して、“0” の値が一番下のグループに含まれるようにします。この場合、自動的に作成される一番下のカテゴリのラベルは “[A],B]” となります。なお、include.latest = TRUE を指定し、かつ right = TRUE を指定した場合、含まれるのは最小値ではなく最大値の分割点とカテゴリーに適用されることに注意してください。\nlabels = 引数を使って、カスタマイズされたラベルのベクトルを指定することができます。手作業で指定する必要があるため、間違えのないように十分注意してください。後述するように、クロス集計を用いて作業を確認してください。\nage_years に cut() を使用して、新しい変数 age_cat を作成した例を以下に示します。\n\n# 年齢変数を分割してカテゴリ化した変数を新しく作る\n# 下限の分割点は除外されるが、上限の分割点は各カテゴリに含まれる\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         \n      ))              # 一番下のグループに0を入れる\n\n# グループごとの観測値の数を集計する\ntable(linelist$age_cat, useNA = \"always\")\n\n\n   [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100] \n    1469     1195     1040      770     1149      778       94        6 \n    &lt;NA&gt; \n     107 \n\n\n分割した結果を確認してください！！！数値列とカテゴリ列をクロス集計して、各年齢値が正しいカテゴリに割り当てられていることを検証します。特に、境界値の割り当てを確認してください（例：隣接するカテゴリが 10-15 と 16-20 の場合、15 の値がどこに割り当てられているか）。\n\n# 数値列とカテゴリ列のクロス集計\ntable(\"Numeric Values\" = linelist$age_years,   # 分かりやすくするために、表の中に名前を入れる\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # NA値の検証を忘れずに\n\n                    Categories\nNumeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70]\n  0                    136      0       0       0       0       0       0\n  0.0833333333333333     1      0       0       0       0       0       0\n  0.25                   2      0       0       0       0       0       0\n  0.333333333333333      6      0       0       0       0       0       0\n  0.416666666666667      1      0       0       0       0       0       0\n  0.5                    6      0       0       0       0       0       0\n  0.583333333333333      3      0       0       0       0       0       0\n  0.666666666666667      3      0       0       0       0       0       0\n  0.75                   3      0       0       0       0       0       0\n  0.833333333333333      1      0       0       0       0       0       0\n  0.916666666666667      1      0       0       0       0       0       0\n  1                    275      0       0       0       0       0       0\n  1.5                    2      0       0       0       0       0       0\n  2                    308      0       0       0       0       0       0\n  3                    246      0       0       0       0       0       0\n  4                    233      0       0       0       0       0       0\n  5                    242      0       0       0       0       0       0\n  6                      0    241       0       0       0       0       0\n  7                      0    256       0       0       0       0       0\n  8                      0    239       0       0       0       0       0\n  9                      0    245       0       0       0       0       0\n  10                     0    214       0       0       0       0       0\n  11                     0      0     220       0       0       0       0\n  12                     0      0     224       0       0       0       0\n  13                     0      0     191       0       0       0       0\n  14                     0      0     199       0       0       0       0\n  15                     0      0     206       0       0       0       0\n  16                     0      0       0     186       0       0       0\n  17                     0      0       0     164       0       0       0\n  18                     0      0       0     141       0       0       0\n  19                     0      0       0     130       0       0       0\n  20                     0      0       0     149       0       0       0\n  21                     0      0       0       0     158       0       0\n  22                     0      0       0       0     149       0       0\n  23                     0      0       0       0     125       0       0\n  24                     0      0       0       0     144       0       0\n  25                     0      0       0       0     107       0       0\n  26                     0      0       0       0     100       0       0\n  27                     0      0       0       0     117       0       0\n  28                     0      0       0       0      85       0       0\n  29                     0      0       0       0      82       0       0\n  30                     0      0       0       0      82       0       0\n  31                     0      0       0       0       0      68       0\n  32                     0      0       0       0       0      84       0\n  33                     0      0       0       0       0      78       0\n  34                     0      0       0       0       0      58       0\n  35                     0      0       0       0       0      58       0\n  36                     0      0       0       0       0      33       0\n  37                     0      0       0       0       0      46       0\n  38                     0      0       0       0       0      45       0\n  39                     0      0       0       0       0      45       0\n  40                     0      0       0       0       0      32       0\n  41                     0      0       0       0       0      34       0\n  42                     0      0       0       0       0      26       0\n  43                     0      0       0       0       0      31       0\n  44                     0      0       0       0       0      24       0\n  45                     0      0       0       0       0      27       0\n  46                     0      0       0       0       0      25       0\n  47                     0      0       0       0       0      16       0\n  48                     0      0       0       0       0      21       0\n  49                     0      0       0       0       0      15       0\n  50                     0      0       0       0       0      12       0\n  51                     0      0       0       0       0       0      13\n  52                     0      0       0       0       0       0       7\n  53                     0      0       0       0       0       0       4\n  54                     0      0       0       0       0       0       6\n  55                     0      0       0       0       0       0       9\n  56                     0      0       0       0       0       0       7\n  57                     0      0       0       0       0       0       9\n  58                     0      0       0       0       0       0       6\n  59                     0      0       0       0       0       0       5\n  60                     0      0       0       0       0       0       4\n  61                     0      0       0       0       0       0       2\n  62                     0      0       0       0       0       0       1\n  63                     0      0       0       0       0       0       5\n  64                     0      0       0       0       0       0       1\n  65                     0      0       0       0       0       0       5\n  66                     0      0       0       0       0       0       3\n  67                     0      0       0       0       0       0       2\n  68                     0      0       0       0       0       0       1\n  69                     0      0       0       0       0       0       3\n  70                     0      0       0       0       0       0       1\n  72                     0      0       0       0       0       0       0\n  73                     0      0       0       0       0       0       0\n  76                     0      0       0       0       0       0       0\n  84                     0      0       0       0       0       0       0\n  &lt;NA&gt;                   0      0       0       0       0       0       0\n                    Categories\nNumeric Values       (70,100] &lt;NA&gt;\n  0                         0    0\n  0.0833333333333333        0    0\n  0.25                      0    0\n  0.333333333333333         0    0\n  0.416666666666667         0    0\n  0.5                       0    0\n  0.583333333333333         0    0\n  0.666666666666667         0    0\n  0.75                      0    0\n  0.833333333333333         0    0\n  0.916666666666667         0    0\n  1                         0    0\n  1.5                       0    0\n  2                         0    0\n  3                         0    0\n  4                         0    0\n  5                         0    0\n  6                         0    0\n  7                         0    0\n  8                         0    0\n  9                         0    0\n  10                        0    0\n  11                        0    0\n  12                        0    0\n  13                        0    0\n  14                        0    0\n  15                        0    0\n  16                        0    0\n  17                        0    0\n  18                        0    0\n  19                        0    0\n  20                        0    0\n  21                        0    0\n  22                        0    0\n  23                        0    0\n  24                        0    0\n  25                        0    0\n  26                        0    0\n  27                        0    0\n  28                        0    0\n  29                        0    0\n  30                        0    0\n  31                        0    0\n  32                        0    0\n  33                        0    0\n  34                        0    0\n  35                        0    0\n  36                        0    0\n  37                        0    0\n  38                        0    0\n  39                        0    0\n  40                        0    0\n  41                        0    0\n  42                        0    0\n  43                        0    0\n  44                        0    0\n  45                        0    0\n  46                        0    0\n  47                        0    0\n  48                        0    0\n  49                        0    0\n  50                        0    0\n  51                        0    0\n  52                        0    0\n  53                        0    0\n  54                        0    0\n  55                        0    0\n  56                        0    0\n  57                        0    0\n  58                        0    0\n  59                        0    0\n  60                        0    0\n  61                        0    0\n  62                        0    0\n  63                        0    0\n  64                        0    0\n  65                        0    0\n  66                        0    0\n  67                        0    0\n  68                        0    0\n  69                        0    0\n  70                        0    0\n  72                        1    0\n  73                        3    0\n  76                        1    0\n  84                        1    0\n  &lt;NA&gt;                      0  107\n\n\nNA値の再ラベル付け\nNA 値に “Missing” などのラベルを付けたい場合があります。新しく作成した列は因子型（制限付き型）であるため、この値は拒否されるので、単純に replace_na() で変換させることはできません。代わりに、因子（ファクタ）型データ の章で説明されているように、forcats パッケージの fct_explicit_na() を使用してください。\n\nlinelist &lt;- linelist %&gt;% \n  \n   # cut()すると、因子型のage_catが自動的に作成される \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # 欠損値を明示する\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  \n  )    # ラベルを指定することができる\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat = fct_explicit_na(age_cat, na_level = \"Missing age\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n# 各カテゴリに含まれる数値の数を表で表示する\ntable(linelist$age_cat, useNA = \"always\")\n\n\n        0-4         5-9       10-14       15-19       20-29       30-49 \n       1227        1223        1048         827        1216         848 \n      50-69      70-100 Missing age        &lt;NA&gt; \n        105           7         107           0 \n\n\n切れ目やラベルを素早く作る\nベクトルの改行やラベルを素早く作成するには、以下のような方法があります。seq() や rep() については、R の基礎 の章を参照してください。\n\n# 0から90までのブレークポイントを5で割る\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# デフォルトのcut()の設定を前提に、上記のカテゴリのラベルを作成する\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# 両方のベクトルが同じ長さであることを確認する\nlength(age_seq) == length(age_labels)\n\ncut() の詳細については、Rコンソールで ?cut と入力し、表示されるヘルプページを参照してください。\n\n\n四分位数による分割\n一般的な理解では、「クォンタイル（quantile）」または「パーセンタイル（percentile）」は、通常、下になる値の割合を指します。例えば、linelist の年齢の 95 パーセンタイルは、年齢の 95 %が該当する年齢になります。\nしかし、一般的には、「四分位数」や「十分位数」は、データのグループを 4 つまたは 10 のグループに均等に分けたものを指すことがあります（グループよりも分割点が 1 つ多いことに注意してください）。\n四分位数を取得するには、base R に含まれている stats の quantile() を使用します。データセットの列などの数値ベクトルと、0 から 1.0 までの確率の数値ベクトルを指定します。分割点は、数値ベクトルとして返されます。?quantile を入力すると、統計的手法の詳細を調べることができます。\n入力された数値ベクトルに欠損値がある場合は、na.rm = TRUE を設定することをお勧めします。\nnames = FALSE を設定すると、名前のない数値ベクトルが得られます。\n\nquantile(linelist$age_years,             # 演算する数値ベクトルを指定\n  probs = c(0, .25, .50, .75, .90, .95),  # 欲しいパーセンタイルを指定\n  na.rm = TRUE)                          # 欠損値を無視する\n\n 0% 25% 50% 75% 90% 95% \n  0   6  13  23  33  41 \n\n\nquantile() の結果は、age_categories() や cut() の分割点として使用できます。以下では、cut() を使って新しい列 deciles を作成し、age_years に対して quantiles() を使って区切りを定義しています。janitor の tabyl() を使って結果を表示し、各グループのパーセンテージを見ることができます（詳細は、記述統計表の作り方 の章を参照ください）。各グループ、正確に 10 %ではないことに注意してください。\n\nlinelist %&gt;%                              #linelistから開始。\n  mutate(deciles = cut(age_years,        # 新しい列を作る。 age_years列をcut()でdecileに格納。\n    breaks = quantile(                   # quantile()を使ってカットオフを定義する。\n      age_years,                         # age_yearsの操作。\n      probs = seq(0, 1, by = 0.1),       # 0.0から1.0へ0.1倍。\n      na.rm = TRUE),                    # 欠損値を無視する\n    include.lowest = TRUE)) %&gt;%          # cut()でage 0を含む。\n  janitor::tabyl(deciles)                # 表示するテーブルへのパイプ。\n\n deciles   n    percent valid_percent\n   [0,2] 748 0.11319613    0.11505922\n   (2,5] 721 0.10911017    0.11090601\n   (5,7] 497 0.07521186    0.07644978\n  (7,10] 698 0.10562954    0.10736810\n (10,13] 635 0.09609564    0.09767728\n (13,17] 755 0.11425545    0.11613598\n (17,21] 578 0.08746973    0.08890940\n (21,26] 625 0.09458232    0.09613906\n (26,33] 596 0.09019370    0.09167820\n (33,84] 648 0.09806295    0.09967697\n    &lt;NA&gt; 107 0.01619249            NA\n\n\n\n\n均等な大きさのグループ\n数値グループを作成するもう 1 つの方法として、dplyr の関数 ntile() で、データを n 個の均等な大きさのグループに分割する方法があります。quantile() と異なり、同じ値が複数のグループに入ることがあることに注意してください。この方法では、数値ベクトルを指定し、そして分割するグループの数を指定することが必要ですが、作成される新しい列の値は、グループの「番号」（例：1 から 10）だけで、cut() を使ったときのように値の範囲そのものではありません。\n\n# ntile()でグループを作る\nntile_data &lt;- linelist %&gt;% \n  mutate(even_groups = ntile(age_years, 10))\n\n# グループ別の数と割合の表を作る\nntile_table &lt;- ntile_data %&gt;% \n  janitor::tabyl(even_groups)\n  \n# 範囲を示すために最小値と最大値を添付する\nntile_ranges &lt;- ntile_data %&gt;% \n  group_by(even_groups) %&gt;% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `min = min(age_years, na.rm = T)`.\nℹ In group 11: `even_groups = NA`.\nCaused by warning in `min()`:\n! no non-missing arguments to min; returning Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# 結合して表示する（値が複数のグループに存在することに注意）\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")\n\n even_groups   n    percent valid_percent min  max\n           1 651 0.09851695    0.10013844   0    2\n           2 650 0.09836562    0.09998462   2    5\n           3 650 0.09836562    0.09998462   5    7\n           4 650 0.09836562    0.09998462   7   10\n           5 650 0.09836562    0.09998462  10   13\n           6 650 0.09836562    0.09998462  13   17\n           7 650 0.09836562    0.09998462  17   21\n           8 650 0.09836562    0.09998462  21   26\n           9 650 0.09836562    0.09998462  26   33\n          10 650 0.09836562    0.09998462  33   84\n          NA 107 0.01619249            NA Inf -Inf\n\n\n\n\n\ncase_when()\ndplyr の関数 case_when() を使って数値列からカテゴリを作成することは可能ですが、epikit のage_categories() や cut() を使った方が、自動的に順序付けられた要素を作成してくれるので、より簡単です。\ncase_when() を使用する場合は、この章の「値の再定義」のセクションで説明した方法を確認してください。また、右辺にくるすべての値は同じデータ型でなければならないことに注意してください。したがって、右辺の値を NA にしたい場合は、“Missing”と書くか、特別な NA 値である NA_character_ を使用する必要があります。\n\n\nパイプチェーンへの追加\n以下では、カテゴリ化された 2 つの年齢列を作成するコードを、前処理パイプラインに追加しています。\n\n# パイプチェーン処理 (未加工データから始まり、クリーニングステップを経由してパイプで処理される)\n##################################################################################\n\n\n# パイプチェーンのクリーニング開始\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    #列名の構文の標準化\n    janitor::clean_names() %&gt;% \n\n     \n     # 手動で列名を変更\n           # 新しい列名             # 既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n     # 列を削除\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n     # 重複除去\n    distinct() %&gt;% \n\n     # 列の追加\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n     # 列のデータ型を変換\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n     # 列の追加:入院の遅延\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n     # 病院の列の値をクリーニングする\n    mutate(hospital = recode(hospital,\n                         　　　# 既存の値 = 新しい値\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n     # age_years列の作成（age 列と age_unit 列を使用する）\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;%\n\n     # ここまでは、すでに説明したクリーニング手順\n    ###################################################   \n    mutate(\n         # 年齢別カテゴリ：カスタマイズする\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # 年齢カテゴリ：0～85歳までの5段階\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#行の追加",
    "href": "new_pages/cleaning.jp.html#行の追加",
    "title": "8  データクリーニングと主要関数",
    "section": "8.10 行の追加",
    "text": "8.10 行の追加\n\n一行ずつ追加する\n手作業で一行ずつ追加するのは面倒ですが、dplyr の add_row() を使えば可能です。各列は 1 つのデータ型（因子型、数字型、ロジカル型など）の値のみを含む必要があることを覚えておいてください。そのため、行の追加にはこれを維持するための微妙な調整が必要です。\n\nlinelist &lt;- linelist %&gt;% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)\n\n.before と .after. を使って、追加したい行の位置を指定します。.before = 3 は、新しい行を現在の 3 行目の前に配置します。デフォルトでは、新しい行は最後に追加されます。指定されていない列は空欄（NA）になります。\n新しい行番号は奇妙に見えるかもしれません（“…23”）。既存の行の行番号は変更されているため、このコマンドを 2 回使用する場合は、慎重に検討・テストしてください。\n指定したデータ型が実際のデータ型と異なる場合は、以下のようなエラーが表示されます。\nError: Can't combine ..1$infection date &lt;date&gt; and ..2$infection date &lt;character&gt;.\n（日付の値を持つ行を挿入する際には、as.Date(\"2020-10-10\") のように as.Date() という関数で日付を囲うことを忘れないでください）。\n\n\n複数行を結合する\nあるデータフレームの行を別のデータフレームの下部に結合してデータセットを結合するには、dplyr の bind_rows() を使用します。これについては、データの結合 の章で詳しく説明しています。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#行の抽出フィルタリング",
    "href": "new_pages/cleaning.jp.html#行の抽出フィルタリング",
    "title": "8  データクリーニングと主要関数",
    "section": "8.11 行の抽出（フィルタリング）",
    "text": "8.11 行の抽出（フィルタリング）\n列を整理し、値を再定義した後の典型的なクリーニングステップは、dplyr の filter() を使ってデータフレームの特定の行を抽出（フィルタリング）することです。\nfilter() では、データセット内の特定の行を抜き出すために、TRUE でなければならない論理を指定します。以下では、単純な論理条件と複雑な論理条件に基づいて行を抽出する方法を示します。\n\n\n単純なフィルタリング\n以下の単純な例では、論理的な条件を満たすように行を抽出した上で、linelist データフレームを再定義します。括弧内の論理条件が評価され、 TRUE となる行のみが残ります。\nこの例では、論理条件は gender == \"f\" で、列 gender の値が \"f\" に等しいかどうかを問いています（大文字と小文字は区別されます）。\nフィルタを適用する前の linelist の行数は nrow(linelist) です。\n\nlinelist &lt;- linelist %&gt;% \n  filter(gender == \"f\")   # 性別が \"f\" である行だけを残す\n\nフィルタを適用した後の linelist の行数は linelist %&gt;% filter(gender == \"f\") %&gt;% nrow() となります。\n\n\n欠損値のフィルタリング\n欠損値のある行をフィルタリングしたいことはよくあります。filter(!is.na(column) & !is.na(column)) と書きたい気持ちを抑えて、代わりにこのためにカスタマイズされた tidyr の関数である drop_na() を使いましょう。空の括弧をつけて実行すると、欠損値のある行を削除します。あるいは、欠落があるか評価したい特定の列の名前を指定したり、上述の “tidyselect”ヘルパー関数を使用することもできます。\n\nlinelist %&gt;% \n  drop_na(case_id, age_years)  \n# case_idやage_yearsの値が欠損している行を削除する。\n\nデータの欠落の分析や管理の詳細ついては、欠損データの処理 の章をご覧ください。\n\n\n行番号によるフィルタリング\nデータフレームや Tibble では、各行には通常「行番号（row number）」があり、R Viewer で見ると最初の列の左側に表示されます。これは、それ自体はデータの列ではありませんが、filter() を使用する際に参照することができます。\n「行番号」に基づいてフィルタリングしたい場合は、フィルタリングの論理条件のとして、dplyr の関数 row_number() を空括弧付きで使用します。多くの場合、以下のように、論理条件文の一部として、%in% 演算子を使用して数値の範囲を指定します。最初の N 行を表示するには、特別な dplyr 関数 head() を使用することもできます。\n\n# 最初の100行を表示する\nlinelist %&gt;% head(100)     \n# またはtail()を使って最後のn行を見る\n\n# 5列目のみ表示する\nlinelist %&gt;% filter(row_number() == 5)\n\n# 2行目から20行目までと、3つの特定の列を見る\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nまた、データフレームを tibble 関数 rownames_to_column() にパイプすることで、行番号を列として変換することができます（括弧の中には何も入れないでください）。\n\n\n\n複雑なフィルタリング\n括弧 （）、OR ｜、ネゲート ！、％in％、AND ＆ の各演算子を使って、より複雑な論理条件を作ることができます。その例を以下に示します。\n注： 論理的条件の前に ! 演算子を使うと、その後の論理的条件が否定されます。例えば、！is.na(column) は、列の値が欠損していない場合に真（TRUE）と評価されます。同様に、！column %in% c(\"a\", \"b\", \"c\") は、列の値がベクトルに含まれていない場合に真（TRUE）と評価されます。\n\nデータを調べる\n以下は、発症日のヒストグラムを作成するためのシンプルなコマンドです。この未加工データセットには、二つのアウトブレイクが含まれていることはわかります（2012～2013 年に発生した小規模なアウトブレイクと 2014～2015 年に発生した大規模なアウトブレイク）。今回の分析では、最初の小規模なアウトブレイクをラインリストから削除していきます。\n\nhist(linelist$date_onset, breaks = 50)\n\n\n\n\n\n\n\n\n\n\n数値や日付の欠損をフィルターで処理する方法\ndate_onset 列で 2013 年 6 月以降の行を抽出することはできるでしょうか。これには、注意が必要です。filter(date_onset &gt; as.Date(\"2013-06-01\"))) というコードを適用すると、発症日が欠落している後期流行の行がすべて削除されてしまいます！\n警告：日付や数値の「大（&gt;）」または「小（&lt;）」にフィルタリングすると、欠損値（NA）のある行が削除されてしまいます。これは、NA が無限に大きい、または小さいものとして扱われるためです。\n(日付データと lubridate パッケージを使用した処理については、日付データの章の 日付の操作のセクションを参照してください。）\n\n\nフィルターを作成する\nクロス集計を行い、正しい行だけを除外していることを確認して下さい。\n\ntable(Hospital  = linelist$hospital,                     #病院名\n      YearOnset = lubridate::year(linelist$date_onset),  #発症した年\n      useNA     = \"always\")                              #欠損値の表示\n\n                                      YearOnset\nHospital                               2012 2013 2014 2015 &lt;NA&gt;\n  Central Hospital                        0    0  351   99   18\n  Hospital A                            229   46    0    0   15\n  Hospital B                            227   47    0    0   15\n  Military Hospital                       0    0  676  200   34\n  Missing                                 0    0 1117  318   77\n  Other                                   0    0  684  177   46\n  Port Hospital                           9    1 1372  347   75\n  St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n  &lt;NA&gt;                                    0    0    0    0    0\n\n\nデータセットから最初のアウトブレイク（2012～2013 年に発生したアウトブレイク）を除外するために、他にどのような基準でフィルタリングできるでしょうか。次のことがわかりました。\n\n2012 年と 2013 年に発生した最初のアウトブレイクは、A 病院（Hospital A）と B 病院（Hospital B）で発生し、ポート病院（Port Hospital）でも10件の症例が確認されました。\n2 回目のアウトブレイク（2014～2015 年に発生したアウトブレイク）では、A 病院（Hospital A）と B 病院（Hospital B）には症例は確認されませんでしたが、ポート病院（Port Hospital）には症例が確認されました。\n\n除外したい項目：\n\nA 病院（Hospital A）、 B 病院（Hospital B）、ポート病院（Port Hospital）のいずれかで 2012 年と 2013 年に発症した nrow(linelist %&gt;% filter(hospital %in% c(\"Hospital A\", \"Hospital B\") | date_onset &lt; as.Date(\"2013-06-01\"))) の行。\n\n2012 年および 2013 年に発症した nrow(linelist %&gt;% filter(date_onset &lt; as.Date(\"2013-06-01\")) の行を除外する。\nnrow(linelist %&gt;% filter(hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) 発症日が欠落している A 病院および B 病院の行を除外する。\nnrow(linelist %&gt;% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset)) 発症日が見つからない他の行は除外しない。\n\n\n6608 のラインリストから始めます。以下がフィルタリングのコードです。\n\nlinelist &lt;- linelist %&gt;% \n # 発症日が2013年6月1日以降の行、または発症日が不明でA病院またはB病院以外の病院であった行を残す\n  filter(date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)\n\n[1] 6019\n\n\n再度クロス集計を行うと、A 病院と B 病院が完全に取り除かれ、2012 年と 2013 年のポート病院で発生した 10 件が取り除かれ、その他の値はすべて同じになっていることがわかります。\n\ntable(Hospital  = linelist$hospital,                     # 病院名\n      YearOnset = lubridate::year(linelist$date_onset),  # 発症した年\n      useNA     = \"always\")                              # 欠損値の表示\n\n                                      YearOnset\nHospital                               2014 2015 &lt;NA&gt;\n  Central Hospital                      351   99   18\n  Military Hospital                     676  200   34\n  Missing                              1117  318   77\n  Other                                 684  177   46\n  Port Hospital                        1372  347   75\n  St. Mark's Maternity Hospital (SMMH)  322   93   13\n  &lt;NA&gt;                                    0    0    0\n\n\n複数のステートメントを 1 つの filter() コマンドの中に含めることができます（カンマで区切ってください）。または、分かりやすくするために、常に別の filter() コマンドにパイプすることもできます。\n注：date_hospitalisation には欠損値がないことから、読者の中には date_hospitalisation でフィルタリングする方が簡単だと思われる方もいるかもしれません。これは事実です。ここでは、複雑なフィルタを理解するために date_onset を使用しました。\n\n\n\n独立型\nフィルタリングは、（パイプチェーンの一部ではなく）独立したコマンドとしても実行できます。他の dplyr 系の関数と同様に、この場合、一番最初の引数はデータセットそのものでなければなりません。\n\n# dataframe &lt;- filter(dataframe, condition(s) for rows to keep)\n\nlinelist &lt;- filter(linelist, !is.na(case_id))\n\nbase Rを使う場合、保持したい [行、列] を、角括弧 [] を使ってサブセット（フィルタリング）することもできます。\n\n# dataframe &lt;- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist &lt;- linelist[!is.na(case_id), ]\n\n\n\nデータを素早く確認\n数少ない行や列のデータを素早く確認したいことがよくあります。base R の View() を使用すると、RStudio データフレームが表示されます。\n以下のコマンドを実行すると、RStudio でラインリストが表示されます。\n\nView(linelist)\n\n特定のセル（特定の行、特定の列）を表示する 2 つの例を紹介します。\ndplyrの関数 filter() と select() を使用する\nView() の中で、データセットを filter() にパイプして特定の行を残し、select() にパイプして特定の列を残します。例えば、特定の 3 つの症例の発症日と入院日を確認する場合です。\n\nView(linelist %&gt;%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %&gt;%\n       select(date_onset, date_hospitalisation))\n\nbase R でも [ ] を使用してサブセットすると、同じことができます。\n\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\n\n\nパイプチェーンに追加\n\n# パイプチェーン処理 (未加工データから始まり、クリーニングステップを経由してパイプで処理される)\n##################################################################################\n\n\n# パイプチェーンのクリーニング開始\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    #列名構文の標準化\n    janitor::clean_names() %&gt;% \n    \n    # 手動で列名を変更\n           #新しい列名            # 既存の列名\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # 列の除去\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # 重複除去\n    distinct() %&gt;% \n\n    # 列を追加する\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # 列のデータ型を変換\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # 列の追加: 入院までの時間\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # 病院列の値を整える\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # age_years 列を作成する (age列とage_unit列から)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;%\n  \n    mutate(\n          # 年齢別カテゴリ：カスタマイズする\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # 年齢カテゴリ：0～85歳までの5段階\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))%&gt;% \n    \n      # ここまでは、すでに説明したクリーニング手順\n    ###################################################\n    filter(\n         # case_idが欠落していない行のみを残す\n          !is.na(case_id),  \n          \n           # 2回目のアウトブレイクだけを残すようにフィルタリングする\n          date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#行単位の計算",
    "href": "new_pages/cleaning.jp.html#行単位の計算",
    "title": "8  データクリーニングと主要関数",
    "section": "8.12 行単位の計算",
    "text": "8.12 行単位の計算\n行内で計算を行いたい場合は、dplyr の rowwise() を利用することができます。例えば、以下のコードでは rowwise() を使用し、ラインリストの各行について、値が “yes” である指定された症状の列の数を合計する新しい列を作成しています。rowwise() は本質的には特殊な group_by() であるため、終わったら ungroup() を使うのがベストです（詳細は、データのグループ化 の章を参照ください）。\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %&gt;% \n  ungroup() %&gt;% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # 表示のため\n\n# A tibble: 5,888 × 6\n   fever chills cough aches vomit num_symptoms\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;\n 1 no    no     yes   no    yes              2\n 2 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 3 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 4 no    no     no    no    no               0\n 5 no    no     yes   no    yes              2\n 6 no    no     yes   no    yes              2\n 7 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 8 no    no     yes   no    yes              2\n 9 no    no     yes   no    yes              2\n10 no    no     yes   no    no               1\n# ℹ 5,878 more rows\n\n\n評価する列を指定する際に、この章の select() セクションで説明されている “tidyselect” ヘルパー関数を使用したいと思うかもしれません。その場合は、1 つだけ調整が必要です（ select() や summarise() のような dplyr 関数内で使用していないため）。\n列指定の基準を dplyr の c_across() の中に入れます。これは、c_across（ドキュメントはこちら）が、特に rowwise() と連動するように設計されているからです。例えば、次のようなコードです。\n\nrowwise() を適用して、各行の中で以下の演算（sum()）が適用されます（列全体の合計ではありません）。\n新しい列 num_NA_dates を作成します。これは、各行について、is.na() が TRUE と評価された列 （列名に “date” を含むもの） の数として定義されます（これらはデータが欠損しています）。\nungroup() により、後続のステップで rowwise() の影響を取り除きます。\n\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %&gt;% \n  ungroup() %&gt;% \n  select(num_NA_dates, contains(\"date\")) # for display\n\n# A tibble: 5,888 × 5\n   num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n          &lt;int&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n 2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n 3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n 4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n 5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n\n\nまた、max() のような他の関数を使用し、各行の最新または直近の日付を取得することもできます。\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %&gt;% \n  ungroup() %&gt;% \n  select(latest_date, contains(\"date\"))  # for display\n\n# A tibble: 5,888 × 5\n   latest_date date_infection date_onset date_hospitalisation date_outcome\n   &lt;date&gt;      &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n 2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n 3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n 4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n 5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.jp.html#並び替えアレンジとソート",
    "href": "new_pages/cleaning.jp.html#並び替えアレンジとソート",
    "title": "8  データクリーニングと主要関数",
    "section": "8.13 並び替え（アレンジとソート）",
    "text": "8.13 並び替え（アレンジとソート）\ndplyr の arrange()を使用し、列の値で行を並べ替えたり、順番に並べたりします。\n単純に、並び替えたい順に列を列挙します。データに適用されたグループ化を最初並べ替えたい場合は、.by_group = TRUE と指定します（データのグループ化 の章を参照）。\nデフォルトでは、列は「昇順」で並び替えされます（これは、数字や文字の列にも適用されます）。変数を desc() で囲むと、「降順」で並び替えできます。\narrange() によるデータの並び替えは、プレゼンテーション用のテーブルを作成するとき や、slice() を使ってグループごとに「上位」の行を抽出するとき、あるいは因子レベルの順序を出現順に設定するときなどに特に便利です。\n例えば、linelist デーフレームの行を病院別（hospital 列）に並び替え、次に出現日（date_onset 列）の降順で並び替える場合は、次のようになります。\n\nlinelist %&gt;% \n   arrange(hospital, desc(date_onset))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>データクリーニングと主要関数</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html",
    "href": "new_pages/dates.jp.html",
    "title": "9  日付型データ",
    "section": "",
    "text": "9.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#準備",
    "href": "new_pages/dates.jp.html#準備",
    "title": "9  日付型データ",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについては、R の基礎 の章を参照してください。\n\n# パッケージがインストールされているか確認し、必要に応じてパッケージをインストールし、ロードする\n\npacman::p_load(\n  lubridate,  # 日付の扱いと変換のための一般的なパッケージ  \n  parsedate,  # 厄介な日付を「推測」する関数を持つ\n  aweek,      # 日付を週に、週を日付に変換する別のオプション\n  zoo,        # 日付と時間に関する追加の関数\n  here,       # ファイル管理\n  tidyverse,  # データマネジメントと可視化  \n  rio)        # データのインポートとエクスポート\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、ハンドブックとデータのダウンロード の章を参照してください。ここではデータのファイルが作業ディレクトリにあると仮定し、ファイルパスにはサブフォルダを指定しません。\n\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#現在の日付",
    "href": "new_pages/dates.jp.html#現在の日付",
    "title": "9  日付型データ",
    "section": "9.2 現在の日付",
    "text": "9.2 現在の日付\nコンピュータの「システム」における現在の日付や日時を取得するには、base R を使って次のように行います。\n\n# システムの日付を取得（日付型:DATE）\nSys.Date()\n\n[1] \"2024-05-08\"\n\n# システム時刻の取得（日時型:DATETIME）\nSys.time()\n\n[1] \"2024-05-08 11:58:21 CEST\"\n\n\nlubridate パッケージでは、それぞれを today() と now() で返すことができます。 date() は現在の日付と時刻を、曜日と月名とともに返します。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#日付型dateに変換",
    "href": "new_pages/dates.jp.html#日付型dateに変換",
    "title": "9  日付型データ",
    "section": "9.3 日付型（Date）に変換",
    "text": "9.3 日付型（Date）に変換\nデータセットを R にインポートすると、日付列の値が「1989/12/30」、「05/06/2014」、「13 Jan 2020」のようになることがあります。このような場合、R はこれらの値を文字として扱っている可能性が高いです。これらの値が日付であること、そしてその日付のフォーマット（どの部分が日で、どこが月で、どこが年であるかなど）を R に伝える必要があります。\nR に伝えることで、このような値を日付型（Date）に変換します。日付型（Date）に変更された日付は、システム内部では数値（「起点日」の 1970 年 1 月 1 日からの日数）として保存されています。日付を数値として扱うことはあまりありませんが、これにより日付を連続変数として扱い、日付間の距離を計算するなどの特殊な操作が可能になります。\nデフォルトでは、日付型（Date）の値は YYYY-MM-DD で表示されます。このセクションでは、日付の値の表示方式を変更する方法について説明します。\n以下では、列を文字型（character）から日付型（Date）型に変換する 2 つのアプローチを紹介します。\nヒント： class(linelist$date_onset) のように、base R の class() で現在のデータ型を確認することができます。\n\nbase R\nas.Date() （“D” が大文字であることに注意）は、オブジェクトや列を日付型（Date）に変換する標準的な base R の関数です。\nas.Date() を使用する際には、以下が必要です。\n\n文字型（character）としてインポートされた日付データの現在の形式を指定します。または、日付を数値として扱う場合は、元の日付の形式を指定します（9.4 Excel における日付 のセクションを参照）。\n\n文字型（character）の日付データに使用する場合、すべての日付値は同じフォーマットでなければなりません（そうでない場合は、parsedate パッケージの parse_date() をお試しください）。\n\nまず、base R の class() で列のデータ型を確認してください。データ型がわからない場合や表示されたデータ型が見慣れない場合（例えば “POSIXct”と表示される場合など）は、まず as.character() で文字型（character）に変換し、その後に日付型（Date）に変換するのが最も簡単です。\n次に、as.Date() 内で、format = 引数を使って、文字型（character）の日付データの現在のフォーマット、つまり、どの文字が月、日、年を表すのか、どのように分けられているのかを R に伝えます。現在のフォーマットがすでに R の標準的な日付フォーマット（“YYYY-MM-DD” または “YYYY/MM/DD”）である場合は、format = 引数は必要ありません。\nformat = には、以下の特殊な “strptime” の略語を使用して、現在の日付フォーマットを表す文字列を（引用符で囲んで）指定します。例えば、“24/04/1968” のように、現時点での日付データが ’“DD/MM/YYYY” のフォーマットである文字型（character）である場合、format = \"%d/%m/%Y\" を使用して値を日付型（Date）に変換します。フォーマットを引用符で囲む必要があることに注意してください。また、スラッシュやダッシュも忘れずにつけてくださいね！\n\n# Date 型に変換\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))\n\n以下のリストは、strptime のほぼすべての略語を含んでいます。ここにない略語をご覧になりたい方は、?strptime を実行すると、すべての略語を含むリストを見ることができます。\n%d = 月の日にち（5、17、28 など）\n%j = 年の日にち（ユリウス通日 001-366）\n%a = 曜日の省略形（Mon、Tue、Wed など）\n%A = 完全な曜日表示（Monday、Tuesday など）\n%w = 曜日番号（0-6、日曜日が 0）\n%u = 曜日番号（1-7、月曜日が 1）\n%W = 週の番号（00-53、月曜日が週の始まり）\n%U = 週の番号（01-53、日曜日が週の始まり）\n%m = 月の番号（例：01、02、03、04）\n%b = 月の省略形（Jan、Feb など）\n%B = 完全な月表示（January、February など）\n%y = 2桁の年（例：89）\n%Y = 4桁の年（例：1989）\n%h = 時間（24 時間表示）\n%m = 分\n%s = 秒\n%z = GMT（グリニッジ標準時）からの差\n%Z = タイムゾーン（文字型）\nヒント：as.Date() の format = 引数は、R にコマンド実行後の日付のフォーマットを伝えるためではなく、コマンド実行前の日付を識別するために指定します。\nヒント：format = の引数には、対象の日付に使われているセパレータ（例えば、/ や - 、またはスペース）を含めることを忘れないでください。\n日付が日付型（Date）に変換されると、YYYY-MM-DD というデフォルトの標準フォーマットで表示されます。\n\n\nlubridate\n文字型のオブジェクトを日付に変換するには、lubridate パッケージを使用すると簡単です。lubridate パッケージは base R よりもシンプルで一貫性があり、日付と時刻を扱うために開発されたtidyverse のパッケージです。lubridate は日付と時刻の最も標準的な手法とされ、常に推奨されます。\nlubridate パッケージは、文字型オブジェクトを日付に変換するためのヘルパー関数をいくつか提供しています。このヘルパー関数は、as.Date() でフォーマットを指定ことに比べ、直観的かつ柔軟に文字型オブジェクトを変換することができます。ヘルパー関数は、柔軟な日付フォーマットに対応し、さまざまなセパレータを使用できることに加え、日付フォーマットの略語に由来した日付の同義語（例えば、January を意味する “01” や “Jan”）を使用することもできます。\n\n# lubridate をインストールし、読み込む\npacman::p_load(lubridate)\n\nymd() は、対象となる日付の値を年、月、日の順に柔軟に変換します。\n\n# 「年月日」のフォーマットで日付を読み込み\nymd(\"2020-10-11\")\n\n[1] \"2020-10-11\"\n\nymd(\"20201011\")\n\n[1] \"2020-10-11\"\n\n\nmdy() は、対象となる日付の値を月、日、年の順に柔軟に変換します。\n\n# 「月日年」のフォーマットで日付を読み込み\nmdy(\"10/11/2020\")\n\n[1] \"2020-10-11\"\n\nmdy(\"Oct 11 20\")\n\n[1] \"2020-10-11\"\n\n\ndmy() は、対象となる日付の値を日、月、年の順に柔軟に変換します。\n\n# 「日月年」のフォーマットで日付を読み込み\ndmy(\"11 10 2020\")\n\n[1] \"2020-10-11\"\n\ndmy(\"11 October 2020\")\n\n[1] \"2020-10-11\"\n\n\n\n\n\n\nパイプ（%&gt;%）を使って文字型（character）の列から日付型（Date）の列への変換を lubridate で行うと、以下のようになります。\n\nlinelist &lt;- linelist %&gt;%\n  mutate(date_onset = lubridate::dmy(date_onset))\n\nコマンド実行後、class() を実行して列のデータ型を確認します。\n\n# 列のデータ型を確認\nclass(linelist$date_onset)  \n\n日付が日付型（Date）に変換されると、YYYY-MM-DD というデフォルトの標準フォーマットで表示されます。\n上記の関数は、年が 4 桁のときに最も期待通りに機能します。2 桁の年は、lubridate が世紀として推測するため、予想外の結果になることがあります。\n2 桁の年を（すべて同じ世紀の 4 桁の年に変換するには、文字型（character）に変換した後、 stringr パッケージの str_glue() を用いて、既存の数字と接頭辞（prefix）を組み合わせ（文字型・文字列型データ の章を参照）、その後日付型（Date）に変換します。\n\ntwo_digit_years &lt;- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")\n\n2015\n2015\n2016\n2017\n\n\n\n\n列の結合\n複数の数字型（numeric）の列を一つの日付型（Date）の列にまとめるには、lubridate 関数の make_date() と make_datetime() を利用します。例えば、データフレーム linelist に 数値列 onset_day, onset_month, onset_year がある場合、以下のようなコマンドを実行してください。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#excel-における日付",
    "href": "new_pages/dates.jp.html#excel-における日付",
    "title": "9  日付型データ",
    "section": "9.4 Excel における日付",
    "text": "9.4 Excel における日付\n多くのソフトウェアでは、内部では日付を数字として保存します。R は 1970 年 1 月 1 日を起点として日付を格納します。したがって、as.numeric(as.Date(\"1970-01-01)) を実行すると 0 となります。\nMicrosoft Excel では、お使いの OS に応じて、Windows の場合は 1899年12月30日、Mac の場合は 1904 年 1 月 1 日を起点として日付が保存されます。詳しくは Microsoft の公式ドキュメント をご覧ください。\nこのように、Excel では日付が数値として保存されているため、Excel ファイルを R でインポートすると、日付が文字ではなく数値としてインポートされることがよくあります。Excel からインポートしたデータセットで、日付が “41369” のような数字や文字として表示されている場合は as.Date() （または lubridate の as_date()）を使って変換しますが、先述のようにフォーマットを指定する代わりに、Excel の日付の起点日を引数 origin = に指定します。\nこれは、Excel の日付が文字型（character）として R に保存されている場合には機能しないため、日付が数字型（numeric）であることを必ず確認してください。\n注釈：起点日は、R の標準の日付形式（YYYY-MM-DD）で入力してください。\n\n# Excel の数字の日付を変換する際、Excel の「起点日」を入力する例\ndata_cleaned &lt;- data %&gt;% \n  mutate(date_onset = as.numeric(date_onset)) %&gt;%   # 数字型であることを確認\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # Excelの起点日で日付に変換",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#厄介な日付",
    "href": "new_pages/dates.jp.html#厄介な日付",
    "title": "9  日付型データ",
    "section": "9.5 厄介な日付",
    "text": "9.5 厄介な日付\nparsedate パッケージの parse_date() は、複数の異なる形式の日付を含む「厄介な」日付列を読み込んで、その日付を標準的な形式に変換してくれます。parse_date() については、こちら でさらに詳しく学ぶことができます。\n例えば parse_date は、文字の日付”03 Jan 2018”, “07/03/1982”, “08/20/85”のベクトルを、“2018-01-03”, “1982-03-07”, “1985-08-20”のように、一律で日付（Date）型に変換します。\n\nparsedate::parse_date(c(\"03 January 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))\n\n[1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n\n\n\n# dater_onset 列に parse_date() を使用した例\nlinelist &lt;- linelist %&gt;%      \n    mutate(date_onset = parse_date(date_onset))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#日時型datetimeに変換",
    "href": "new_pages/dates.jp.html#日時型datetimeに変換",
    "title": "9  日付型データ",
    "section": "9.6 日時型（datetime）に変換",
    "text": "9.6 日時型（datetime）に変換\n先に述べたように、R では日付と時間の両方の情報を含む、日時型（datetime）もサポートしています。日付型（Date）と同様に、文字型（character）オブジェクトから日時型（datetime）オブジェクトに変換する必要があります。\n\n日付と時刻の変換\n標準的な日時型（datetime）は、最初に日付があり、その後に時間要素が続く形式です（ 01 Jan 2020, 16:30 など）。日付と同様に、このフォーマットには様々な方法があり、また、提供できる精度（時、分、秒）のレベルも様々です。\nこれらの文字列を日時型（datetime）に変換するための lubridate ヘルパー関数も存在します。これらの関数は、日付ヘルパー関数を拡張したもので、末尾に _h（時のみを指定）、_hm（時と分を指定）、_hms（時、分、秒を指定）を付けます（例: dmy_hms()）。以下のように使用します。\n時間のみの日時データを日時型（datetime）に変換する\n\nymd_h(\"2020-01-01 16hrs\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\nymd_h(\"2020-01-01 4PM\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\n\n時と分を含む日時データを日時型（datetime）に変換する\n\ndmy_hm(\"01 January 2020 16:20\")\n\n[1] \"2020-01-01 16:20:00 UTC\"\n\n\n時、分、秒を含む日時データを日時型（datetime）に変換する\n\nmdy_hms(\"01 January 2020, 16:20:40\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nタイムゾーンを指定することもできますが、有効ではありません。タイムゾーンについては、この章の後半、「9.11 日付・タイムゾーンの変換」のセクションを参照してください。\n\nmdy_hms(\"01 January 2020, 16:20:40 PST\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nデータフレームを扱う場合は、stringr パッケージの str_glue() と lubridate パッケージの関数を用いて、日付の列と時間の列を組み合わせて日時型（datetime）の列を作成できます。stringr の詳細については、文字型・文字列型データ の章を参照してください。\n以下では、linelist データフレームを例として使用します。linelist データフレームには、 “hours : minutes” という時間と分がコロン（:）で区切られているフォーマットの列があり、これを日時型（datetime）に変換していきます。\n\nまず、“hours : minutes” 列の欠損値を列の中央値で埋め、「きれいな」入院時刻の列（time_admission_clean）を作成します。これは lubridate が欠損値を処理できないためです。time_admission_clean 列を date_hospitalisation 列に結合し、 最後に ymd_hm() 関数を使って日時型（datetime）に変換します。\n\n\n# パッケージ\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission 列は hours:minutes というフォーマット\nlinelist &lt;- linelist %&gt;%\n  \n  # 入院時刻が欠損している場合は、中央値の入院時刻を割り当てる\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # 時刻が欠損している場合、\n      median(time_admission),        # 中央値を割り当て、\n      time_admission                 # 欠損していない場合はそのままにする\n  ) %&gt;%\n  \n    # str_glue() を使用して、日付と時刻の列を結合し、1つの文字型の列を作成\n    # ymd_hm() を使って日時型に変換\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %&gt;% \n      ymd_hm()\n  )\n\n\n\n時間のみの変換\n“hours : minutes” というように、対象となる日付データが文字型（character）で時間（時、分）しか含まれていない場合は、base R の strptime() を使って時間として変換・操作することができます。例えば、2 つの時間の差を求めるには、\n\n# 直接、文字で時間を入力\ntime1 &lt;- \"13:45\" \ntime2 &lt;- \"15:20\"\n\n# 日時型（datetime）に変換した時刻\ntime1_clean &lt;- strptime(time1, format = \"%H:%M\")\ntime2_clean &lt;- strptime(time2, format = \"%H:%M\")\n\n# 差分はデフォルトでは \"difftime\" クラスだが、ここでは数値に変換\nas.numeric(time2_clean - time1_clean)   # 時間単位（ hour ）での差分\n\n[1] 1.583333\n\n\nただし、日付の値が指定されていない場合は、今日の日付として変換されます。文字型の日付列と文字型の時刻列を組み合わせるには、上のセクションの stringr の使用方法を参照してください。strptime() について詳しくはこちらをご覧ください。\n一桁の数字を二桁に変換するには（例えば、時間や分を先頭のゼロで”埋めて” 2 桁にするなど）、文字型・文字列型データの章の「文字列を伸長する」のセクションをご覧ください。\n\n\n時間の抽出\nlubridate の hour(), minute(), second() で時刻の要素を抽出できます。\nここでは、時刻を抽出して一日の区分で分類する例を示します。 time_admission という入院時刻を表す列 は、“HH:MM” というフォーマットの文字型（character）です。まず、上述した strptime() を使って文字を日時型（datetime）に変換します。次に hour() で時間を抽出すると、0 ～ 24 の数値が返されます。最後に、case_when() を用いて time_period という列を作成し、入院時刻に基づいて午前（Morning）、午後（Afternoon）、夕方（Evening）、夜（Night）の 4 つに分類します。\n\nlinelist &lt;- linelist %&gt;%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %&gt;%\n  mutate(time_period = case_when(\n    hour_admit &gt; 06 & hour_admit &lt; 12 ~ \"Morning\",\n    hour_admit &gt;= 12 & hour_admit &lt; 17 ~ \"Afternoon\",\n    hour_admit &gt;= 17 & hour_admit &lt; 21 ~ \"Evening\",\n    hour_admit &gt;=21 | hour_admit &lt;= 6 ~ \"Night\"))\n\ncase_when() については、データのクリーニングと主要関数 の章をご覧ください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#日付の操作",
    "href": "new_pages/dates.jp.html#日付の操作",
    "title": "9  日付型データ",
    "section": "9.7 日付の操作",
    "text": "9.7 日付の操作\nlubridate は他にも様々な機能があります。例えば、日付や日時から一部を抽出、日付の演算、日付の間隔を計算などです。\nまず、例に用いる日付を定義します。\n\n# 日時型（Date）のオブジェクトを作成\nexample_date &lt;- ymd(\"2020-03-01\")\n\n\n日付成分の抽出\n月、日、曜日などの共通する部分を抽出します。\n\nmonth(example_date)  # 月番号\n\n[1] 3\n\nday(example_date)    # 日にち\n\n[1] 1\n\nwday(example_date)   # 曜日番号（1-7）\n\n[1] 1\n\n\nまた、日時型（datetime）のオブジェクトや列から時刻を抽出できます。これは、入院時刻の分布を見たい場合に便利です。\n\nexample_datetime &lt;- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # 時の抽出\nminute(example_datetime)   # 分の抽出\nsecond(example_datetime)   # 秒の抽出\n\n週を抽出するにはいくつかオプションがあります。以下の「疫学週」のセクションを参照してください。\n特定の表記で日付を表示したい場合（「Jan 2020」や「Thursday 20 March」、「Week 20, 1977」など）は、次の「日付の表示」のセクションで説明するように、より柔軟に対応することができます。\n\n\n日付の計算\n日数や週数を足すには、lubridate の関数を使用します。\n\n# 日付に3日分足す\nexample_date + days(3)\n\n[1] \"2020-03-04\"\n\n# 日付に7週分足し、2日分引く\nexample_date + weeks(7) - days(2)\n\n[1] \"2020-04-17\"\n\n\n\n\n日付の間隔\n日付の間隔は、以下の方法で計算できます。\n\n両方の日付が日付型（Date）であることを確認する\n\n引き算で日付の差 “difftime” を返す\n\n必要に応じて、結果を数字型（numeric）に変換する\n\n以下では、2 つの日付の間隔を計算しています。日付型（Date）の値に減算記号（マイナス）を使用して、間隔を求められます。ただし、返される値のデータ型は “difftime” であり、数値に変換する必要があります。\n\n# example_dateから2020年2月20日までの間隔を求める \noutput &lt;- example_date - ymd(\"2020-02-20\")\noutput    # 出力\n\nTime difference of 10 days\n\nclass(output)\n\n[1] \"difftime\"\n\n\n“difftime” に対して追加の操作を行うには、as.numeric() で数字型（numeric）に変換します。\nパイプ（%&gt;%）によって、これらを一連の流れで操作できます。\n\npacman::p_load(lubridate, tidyverse)   # パッケージを読み込む\n\nlinelist &lt;- linelist %&gt;%\n  \n  # dmy フォーマットを指定して、発症日を文字から日付オブジェクトに変換\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %&gt;%\n  \n  # 3 月に発症していないケースをすべて除外\n  filter(month(date_onset) == 3) %&gt;%\n    \n  # 発症から入院までの日数の差を求める\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n\nデータフレームでは、上記の日付のいずれかが欠損していると操作が失敗し、数値ではなく NA が表示されます。この列を計算に使用する場合は、以下のように必ず na.rm = 引数を TRUE に設定してください。\n\n# データが欠損していない症例について、発症から入院までの日数の中央値を算出\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#日付の表示",
    "href": "new_pages/dates.jp.html#日付の表示",
    "title": "9  日付型データ",
    "section": "9.8 日付の表示",
    "text": "9.8 日付の表示\n日付を正しいデータ型にした後、「2018-01-05」ではなく「Monday 05 January」など、データそのものとは異なる表示にしたいことがあります。また表示されている日付の要素でグループ化し、表示を調整することもあります（例：年と月でグループ化）。\n\nformat()\n日付の表示を調整するには、base R に含まれている関数である format() を使用します。この関数を使用する際は、“%” で始まる strptime 略語（ as.Date() で使用されるのと同じ構文）を用いて、希望の出力フォーマットを文字列（引用符で囲まれたもの）で指定します。以下は、一般的な略語の例です。\n注意：format() を使用すると、値が文字型（character）に変換されます。そのため、データ分析や処理が終わった後に使用するか、または、表示のみに使用されます。 strptime のすべての略語の一覧は、?strptime を実行してご覧ください。\n%d = 月の日にち（5、17、28 など）\n%j = 年の日にち（ユリウス通日 001-366）\n%a = 曜日の省略形（Mon、Tue、Wed など）\n%A = 完全な曜日表示（Monday、Tuesday など）\n%w = 曜日番号（0-6、日曜日が 0）\n%u = 曜日番号（1-7、月曜日が 1）\n%W = 週の番号（00-53、月曜日が週の始まり）\n%U = 週の番号（01-53、日曜日が週の始まり）\n%m = 月の番号（例：01、02、03、04）\n%b = 月の省略形（Jan、Feb など）\n%B = 完全な月表示（January、February など）\n%y = 2桁の年（例：89）\n%Y = 4桁の年（例：1989）\n%h = 時間（24 時間表示）\n%m = 分\n%s = 秒\n%z = GMT（グリニッジ標準時）からの差\n%Z = タイムゾーン（文字型）\n以下は、今日の日付のフォーマットの例です。\n\n# フォーマットした今日の日付\nformat(Sys.Date(), format = \"%d %B %Y\")\n\n[1] \"08 May 2024\"\n\n# 日付と時間を簡単に取得する（デフォルトのフォーマット）\ndate()\n\n[1] \"Wed May  8 11:58:22 2024\"\n\n# str_glue() を使って、フォーマットした日付、時刻、タイムゾーンを組み合わせる\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")\n\nWednesday, May 08 2024, +0000  UTC, 11:58:22\n\n# フォーマットを使用して週を表示\nformat(Sys.Date(), \"%Y Week %W\")\n\n[1] \"2024 Week 19\"\n\n\nなお、str_glue() を使用する場合は、二重引用符（\"\"）の中では一重引用符（' '）を使用することに注意してください。\n\n\n年月\n日付型（Date）の列を月と年に変換するには、 zoo パッケージの as.yearmon() を使うことをおすすめします。これは、日付を適切な順序で yearmon 型に変換する関数です。もし format(column, \"%Y %B\") を使用した場合、文字型（character）に変換され、値がアルファベット順に並んでしまいます。\n以下では、as.yearmon() 関数を使って、date_onset 列から yearmonth 列を新たに作成しています。デフォルト（正しい）の順序で得られた結果を以下のテーブルに示します。\n\n# 新しい列の作成 \ntest_zoo &lt;- linelist %&gt;% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# テーブルの出力\ntable(test_zoo$yearmon)\n\n\nApr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 \n       7       64      100      226      528     1070     1112      763 \nDec 2014 Jan 2015 Feb 2015 Mar 2015 Apr 2015 \n     562      431      306      277      186 \n\n\n一方、format() を使うと、希望の表示形式にはなりますが、正しい順序にはなりません。\n\n# 新しい列の作成\ntest_format &lt;- linelist %&gt;% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# テーブルの出力\ntable(test_format$yearmon)\n\n\nApr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 \n       7      186      528      562      306      431      226      100 \nMar 2015 May 2014 Nov 2014 Oct 2014 Sep 2014 \n     277       64      763     1112     1070 \n\n\n注意： ggplot() を用いる際、日付の表示のみを調整したい場合は、scale_x_date() の date_labels = 引数に strptime フォーマットを使用するだけで十分な場合があります。この場合 \"%b %Y\" または \"%Y %b\" を使用できます。詳しくは、ggplot のヒント の章をご覧ください。\nzoo には as.yearqtr() という関数もあります。また、ggplot() を用いる際には scale_x_yearmon() を使用できます。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#dates_epi_wks",
    "href": "new_pages/dates.jp.html#dates_epi_wks",
    "title": "9  日付型データ",
    "section": "9.9 疫学週",
    "text": "9.9 疫学週\n\nlubridate\n日付ごとにデータをグループ化する例は、データのグループ化 の章をご覧ください。以下では、週ごとにデータをグループ化する際の注意点について簡単に説明します。\n一般的には、 lubridate パッケージに含まれている関数である floor_date() に引数 unit = \"week\" を指定して使用することをおすすめします。これは、引数 week_start = で定義される週の「開始日」に日付を丸めるものです。デフォルトの週の開始日は 1（月曜日）ですが、週の任意の日を開始日として指定することができます（例：日曜日は 7）。floor_date() は汎用性があり、unit = を “second”, “minute”, “hour”, “day”, “month”, “year”に設定することで、他の時間単位への切り捨てに使用することができます。\n返される値は、日付型（Date）の週の開始日です。日付型（Date）はデータをプロットする際に便利で、ggplot() に認識されやすく、正しい順序で表示されます。\nプロットの中で週ごとに日付を調整して表示するだけなら、この章の「日付の表示」のセクションを参照してください。例えば、エピカーブをプロットする際に、必要な strptime の “%” を指定することで、希望の日付表示をフォーマットすることができます。例えば、“%Y-%W” または “%Y-%U” を使用すると、年と週の番号が返されます（それぞれ月曜または日曜の週の開始日を指定）。\n\n\n週ごとのカウント\ncount(), group_by(), summarise()によるデータのグループ化については、データのグループ化 の章で詳しく説明しています。以下に簡単な例を示します。\n\nmutate() で新しく “week” という列を作成し、floor_date() で unit = \"week\" を使用する。\n\n週ごとの行数（症例数）を count() で取得し、日付が欠損しているケースを除外する。\n\ntidyr の complete() を使用し、行や症例がないものも含めて、すべての週がデータに現れるようにする。デフォルトでは、「新しい」行のカウント値は NA だが、 fill = 引数で 0 にすることができる。 fill = 引数では、名前付きリストを指定する（以下、n はカウント列の名前）。\n\n\n# 毎週の症例数を集計したデータセットの作成\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%             # 発症日が欠損のケースを削除\n  mutate(weekly_cases = floor_date(   # 発症週の新しい列を作成\n    date_onset,\n    unit = \"week\")) %&gt;%            \n  count(weekly_cases) %&gt;%           # 週ごとにグループ化し、グループごとの行数をカウント（「n」という列を作成）\n  tidyr::complete(                  # 症例が報告されていない週も含めて、すべての週が存在するようにする\n    weekly_cases = seq.Date(          # \"weekly_cases\" という列を完全なシーケンスとして再定義\n      from = min(weekly_cases),       # 最小の日付から\n      to = max(weekly_cases),         # 最大の日付まで\n      by = \"week\"),                   # 週ごとに\n    fill = list(n = 0))             # n という列の NA を 0 で埋める\n\n以下に、上のコマンドを実行して出力されたデータフレームの最初の行を示します。\n\n\n\n\n\n\n\n\n疫学週 の代替案\nなお、lubridate には week()、 epiweek()、isoweek() という関数があり、それぞれ開始日などが微妙に異なります。しかし、一般的には floor_date() があれば十分です。これらの関数の詳細については、コンソールに ?week と入力するか、こちら をご覧ください。\n疫学週を設定するために、aweek パッケージの使用を検討してみてください。このパッケージについては、RECON のウェブサイトで詳しく説明されています。このパッケージには、date2week() と week2date() という関数があり、week_start = \"Monday\" で週の開始日を設定することができます。このパッケージを使用すると、最も簡単に “week” フォーマット（例： “2020-W12”）で日付を出力することができます。もう一つの aweek の利点は、date2week() を日付列に適用すると、返される列（週形式）が自動的に因子型（factor）になり、対象期間内のすべての週のレベルが含まれることです（これにより、上述の complete() の余分なステップを回避できます）。ただし、aweek には、日付を月や年などの週以外の時間単位に丸める機能はありません。\n時系列の代わりに、“week” フォーマット（“2020 W12”）を表示するのにも適しているのが、パッケージ tsibble の yearweek() です。これは 時系列分析とアウトブレイクの検出 の章で紹介しています。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#日付タイムゾーンの変換",
    "href": "new_pages/dates.jp.html#日付タイムゾーンの変換",
    "title": "9  日付型データ",
    "section": "9.10 日付・タイムゾーンの変換",
    "text": "9.10 日付・タイムゾーンの変換\n様々なタイムゾーンでデータが記録された場合、そのデータを一つのタイムゾーンで標準化することが重要になります。これには未だ解決されていない課題があり、多くの場合、データのタイムゾーン要素を手作業でコード化しなければなりません。\nR では、日時型（datetime）オブジェクトはタイムゾーン要素を含んでいます。デフォルトでは、すべての日時型（datetime）オブジェクトには、コンピュータのローカルタイムゾーンが適用されます。これは、サマータイムによりタイムゾーンが変更されることが多いため、通常は名前付きのタイムゾーンではなく場所に固有のものです。日付の列が表すイベントは特定の時間に起因するものではないため、時間単位でのタイムシフトを合理的に説明することはできませんので、日付の時間要素がなければタイムゾーンを正確に補正することはできません。\nlubridate には日時型（datetime）オブジェクトのタイムゾーンを別のタイムゾーンに変更するためのヘルパー関数がいくつかあります。tz データベースのタイムゾーンを日時型（datetime）オブジェクトに適用することで、タイムゾーンの設定が行えます。データを使用している場所が以下の一覧にない場合は、近隣の大都市のタイムゾーンが利用可能です。\nhttps://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n\n# 現在の時刻を列に割り当て\ntime_now &lt;- Sys.time()\ntime_now\n\n[1] \"2024-05-08 11:58:23 CEST\"\n\n# with_tz()を使用して、時刻を変更しながら、新しいタイムゾーンをカラムに割り当て\ntime_london_real &lt;- with_tz(time_now, \"Europe/London\")\n\n# force_tz()を使って、時刻を維持したまま、新しいタイムゾーンをカラムに割り当て\ntime_london_local &lt;- force_tz(time_now, \"Europe/London\")\n\n\n# このコードを実行したコンピュータがロンドン時間に設定されていない場合は\n# 時間の差が発生する\n# (コンピュータのタイムゾーンとロンドンのタイムゾーンとの差の時間数)\ntime_london_real - time_london_local\n\nTime difference of -1 hours\n\n\nこの作業は抽象的に見えるかもしれません。複数のタイムゾーンにまたがったデータを扱わなければ、このような作業は不要でしょう。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#前後の値の計算",
    "href": "new_pages/dates.jp.html#前後の値の計算",
    "title": "9  日付型データ",
    "section": "9.11 前後の値の計算",
    "text": "9.11 前後の値の計算\nlead() と lag() は dplyr パッケージの関数で、ベクトル（通常は数値や日付のベクトル）の中から前の値（遅れた値）や後の値（先行する値）を見つけるのに役立ちます。これは、時間単位での変化や差を計算するときに便利です。\n例えば、現在の週と前の週の症例数の差を計算したいとします。元のデータは、以下のように週ごとのカウントになっています。\n\n\n\n\n\n\nlag() や lead() を使用する際には、データフレーム内の行の順序が非常に重要です。日付や数字が昇順か降順かに注意してください。\nまず、前週（lagged）の値を含む新しい列を作成します。\n\nn = で前後のユニット数（非負の整数）を指定する。\n\n存在しない行（前の値がない最初の行など）に置かれる値を定義するには、default = を使用する。デフォルトは NA 。\n\n参照する列が順序付けられていない場合は、order_by = TRUE を使用する。\n\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\n\n\n\n\n\n\n\n次に、2 つの症例の列の差分となる新しい列を作成します。\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)\n\n\n\n\n\n\n\nlead() と lag() については、こちら をご覧いただくか、コンソールで ?lag と入力してください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.jp.html#参考資料",
    "href": "new_pages/dates.jp.html#参考資料",
    "title": "9  日付型データ",
    "section": "9.12 参考資料",
    "text": "9.12 参考資料\nlubridate tidyverse page\nlubridate RStudio cheatsheet\nR for Data Science page on dates and times\nOnline tutorial\nDate formats",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>日付型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html",
    "href": "new_pages/characters_strings.jp.html",
    "title": "10  文字型・文字列型データ",
    "section": "",
    "text": "10.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#準備",
    "href": "new_pages/characters_strings.jp.html#準備",
    "title": "10  文字型・文字列型データ",
    "section": "",
    "text": "パッケージの読み込み\nstringr およびその他の tidyverse パッケージをインストールまたは読み込みます。\n\n# パッケージのインストール・読み込み\npacman::p_load(\n  stringr,    # 文字列を扱うための多くの関数\n  tidyverse,  # データ操作のための追加の関数\n  tools)      # タイトルケースに変更するための関数\n\n\n\nデータの読み込み\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、こちら をクリックして「前処理された」ラインリスト（linelist）をダウンロードしてください（.rds 形式で取得できます）。 データは rio パッケージの import() を利用してインポートしましょう（import() は、.xlsx、.csv、.rdsなど、様々な形式のファイルを扱うことができます）。インポートの詳細については、データのインポート・エクスポート の章を参照してください。\n\n# 症例ラインリストの読み込み \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nインポートしたラインリストの最初の 50 行を以下に表示します。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#結合分割配列",
    "href": "new_pages/characters_strings.jp.html#結合分割配列",
    "title": "10  文字型・文字列型データ",
    "section": "10.2 結合、分割、配列",
    "text": "10.2 結合、分割、配列\nこのセクションでは以下の項目について説明します。\n\nstr_c()、str_glue()、unite() を使った文字列の結合\n\nstr_order() を使った文字列の並べ替え\n\nstr_split() と separate() 文字列の分割\n\n\n\n文字列の結合\n複数の文字列を 1 つの文字列に結合する場合は、stringr の str_c を使うことをおすすめします。結合するそれぞれの文字列を、コンマで区切って指定します。\n\nstr_c(\"String1\", \"String2\", \"String3\")\n\n[1] \"String1String2String3\"\n\n\n引数 sep = は、与えられた各引数の間に指定した文字値を挿入します（例：コンマ、スペース、改行 \"\\n\"）。\n\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")\n\n[1] \"String1, String2, String3\"\n\n\n引数 collapse = は str_c() に複数の値をベクトルで入力する場合に使用します。これは、コード実行後に出力されるベクトルの要素を区切るために使用され、出力されるベクトルが 1 つの長い文字列のみを要素として持つようにします。\n以下の例では、2 つのベクトルを 1 つにまとめています（姓と名）。また、似たような例として、管轄区域とその症例数があります。姓名を使用する例では、\n\n姓と名の間に sep = で指定した値が表示されます\n\n各姓名の間に collapse = で指定した値が表示されます\n\n\nfirst_names &lt;- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  &lt;- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep には入力された文字列（ここでは姓と名）を繋ぐ際間に挿入される文字（列）を指定\n# collapse には繋がれた文字列同士（ここでは各姓名）の間に挿入される文字（列）を指定\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")\n\n[1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n\n\n注釈：出力結果をどのように表示したいかによって、正しく表示されるようにstr_c() を使用したコード全体を cat() で囲む必要があります。例えば、以下のように、結合された文字列を改行して表示したい場合などです。\n\n# 改行を正しく表示するためにフレーズ全体をcat()で囲む\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))\n\nabdul hussein;\nfahruk akinleye;\njanice okeke\n\n\n\n\n\n動的文字列\nstr_glue() を使うと、文字列に動的な R コードを加えることができます。以下のように、動的なプロットキャプション（見出しや説明文など）を作成する際に非常に便利な関数です。\n\nすべての内容を二重引用符で囲んでください。str_glue(\"\")\n\n動的なコードやあらかじめ定義された値への参照は、二重引用符の中の波括弧 {} に入力します。1つの str_glue() コマンド中に複数の波括弧を入れることができます。\n文字として引用符 ’’ を表示したい場合は、二重引用符の中に一重引用符を使用します（例：日付の書式を指定する場合など。以下の例を参照ください）。\n\nヒント：\\n で改行することができます。\n\nヒント：format() で日付の表示を調整し、Sys.Date() で現在の日付を表示することができます。\n\n以下に、動的なプロットキャプションの簡単な例を示します。\n\nstr_glue(\"Data include {nrow(linelist)} cases and are current to {format(Sys.Date(), '%d %b %Y')}.\")\n\nData include 5888 cases and are current to 08 May 2024.\n\n\nもう一つの方法は、以下のように波括弧内に仮置きの変数を挿入し、str_glue() の最後にそれらを定義する方法です。これにより、表示したいプロットキャプションが長い場合でも、コードが読みやすくなります。\n\nstr_glue(\"Linelist as of {current_date}.\\nLast case hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %&gt;% filter(is.na(date_onset)))\n         )\n\nLinelist as of 08 May 2024.\nLast case hospitalized on 30 Apr 2015.\n256 cases are missing date of onset and not shown\n\n\nデータフレームからの抜き出し\nデータフレームからデータを取り出して、文字列としてまとめておくと便利な場合があります。以下にデータフレームの例を示します。これを使って、管轄区域、新規および総症例数についての要約文を作成します。\n\n# 症例データフレームの作成\ncase_table &lt;- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\n\n\n\n\n\n\n\nstr_glue_data() を使用して、データフレームの各行から取り出した情報を文字列にまとめることができます。\n\ncase_table %&gt;% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")\n\nZone 1: 3 (40 total cases)\nZone 2: 0 (4 total cases)\nZone 3: 7 (25 total cases)\nZone 4: 0 (10 total cases)\nZone 5: 15 (103 total cases)\n\n\n異なる行の文字列を結合する\n複数の行の値を結合して 1 つの行にまとめる場合など、データフレームの値を列に沿って結合したい場合は、重複データの排除 の章内の ロールアップした値 のセクションを参照してください。\nデータフレームを 1 行の文字列にまとめる\nstr_c() でデータフレーム名と列名を指定し、sep = と collapse = の引数を与えることで、データフレーム内の情報を 1 行に表示させることができます。\n\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")\n\n[1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\nさらにもう一度 str_c() で先に書いた str_c() を包むことで、文の先頭に文字列 “New Cases:” を追加することができます（“New Cases:” が元の str_c() 内にあった場合、複数回表示されます）。\n\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))\n\n[1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\n\n\n列の結合\nデータフレーム中の複数の列を文字列にまとめるには、tidyr パッケージの unite() を用います。これは separate() の逆の操作にあたります。\nまず新しく統合される列の名前を指定します。次に結合したい列の名前を指定します。\n\nデフォルトではアンダースコア _ によって各列の値が結合されますが、これは sep = によって変更できます。\n\nremove = は入力に用いた列をデータフレームから削除します（デフォルトでは TRUE）。\nna.rm = は結合時に欠損値を除外します（デフォルトでは FALSE）。\n\n以下に、例として小さいなデータフレームを作成して説明します。\n\ndf &lt;- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # 患者 1\n                \"chills, aches, pains\",        # 患者 2 \n                \"fever\",                       # 患者 3\n                \"vomiting, diarrhoea\",         # 患者 4\n                \"bleeding from gums, fever\",   # 患者 5\n                \"rapid pulse, headache\"),      # 患者 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\n\n\ndf_split &lt;- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")\n\nWarning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\n\n\n以下に、作成したデータフレームを表示します。\n\n\n\n\n\n\n以下のコマンドで、症状が入力された 3 つの列を統一します。\n\ndf_split %&gt;% \n  unite(\n    col = \"all_symptoms\",         # 新しく作られる列の名前\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # 結合する列\n    sep = \", \",                   # 区切りに使われる結合子\n    remove = TRUE,                # TRUEの場合、結合元の列をデータフレームから削除する\n    na.rm = TRUE                  # TRUEの場合、欠損値を無視して結合する\n  )\n\n  case_ID                all_symptoms outcome\n1       1     jaundice, fever, chills Recover\n2       2        chills, aches, pains   Death\n3       3                       fever   Death\n4       4         vomiting, diarrhoea Recover\n5       5 bleeding, from, gums, fever Recover\n6       6      rapid, pulse, headache Recover\n\n\n\n\n\n分割\nパターンに基づいて文字列を分割するには、str_split() を使います。文字（列）を評価し、新たに分割された値からなる文字ベクトルの list を返します。\n以下の簡単な例では、1 つの文字列を 3 つに分割しています。デフォルトでは、最初に与えられた文字列ごとに 1 つの要素（文字ベクトル）を持つ list を返します。simplify = TRUE の場合は、文字行列を返します。\nこの例では、1 つの文字列が与えられ、コマンドを実行すると、1 つの要素を持つリスト （つまり 3 つの値を持つ文字ベクトル）が出力されます。\n\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n\n出力が保存されていれば、角括弧 [ ] を使って任意の値（n 番目の値）にアクセスし、抽出できます。特定の値を抽出するには、次のような構文を使用できます。the_returned_object[[1]][2]\nこの例では、最初に評価された文字列から 2 番目の値（“fever”）を抽出します。要素の抽出の詳細については、R の基礎 の章をご覧ください。\n\npt1_symptoms &lt;- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # リスト内の1つ目（かつここでは唯一）の要素内にある2つ目の値を返す\n\n[1] \" fever\"\n\n\nstr_split() で複数の文字列を指定した場合、出力されるリストには複数の要素が含まれます。\n\nsymptoms &lt;- c(\"jaundice, fever, chills\",     # 患者 1\n              \"chills, aches, pains\",        # 患者 2 \n              \"fever\",                       # 患者 3\n              \"vomiting, diarrhoea\",         # 患者 4\n              \"bleeding from gums, fever\",   # 患者 5\n              \"rapid pulse, headache\")       # 患者 6\n\nstr_split(symptoms, \",\")                     # 各患者の症状を分割する\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n[[2]]\n[1] \"chills\" \" aches\" \" pains\"\n\n[[3]]\n[1] \"fever\"\n\n[[4]]\n[1] \"vomiting\"   \" diarrhoea\"\n\n[[5]]\n[1] \"bleeding from gums\" \" fever\"            \n\n[[6]]\n[1] \"rapid pulse\" \" headache\"  \n\n\n出力結果を後にデータフレームの列にしたい場合、次のように simplify = TRUE を設定し、文字行列を出力すると便利です。\n\nstr_split(symptoms, \",\", simplify = TRUE)\n\n     [,1]                 [,2]         [,3]     \n[1,] \"jaundice\"           \" fever\"     \" chills\"\n[2,] \"chills\"             \" aches\"     \" pains\" \n[3,] \"fever\"              \"\"           \"\"       \n[4,] \"vomiting\"           \" diarrhoea\" \"\"       \n[5,] \"bleeding from gums\" \" fever\"     \"\"       \n[6,] \"rapid pulse\"        \" headache\"  \"\"       \n\n\nまた n = を使って、分割する数を調整することもできます。例えば、以下の例は分割数を 2 に制限するもので、それ以上のコンマは 2 番目の値の中に残ります。\n\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)\n\n     [,1]                 [,2]            \n[1,] \"jaundice\"           \" fever, chills\"\n[2,] \"chills\"             \" aches, pains\" \n[3,] \"fever\"              \"\"              \n[4,] \"vomiting\"           \" diarrhoea\"    \n[5,] \"bleeding from gums\" \" fever\"        \n[6,] \"rapid pulse\"        \" headache\"     \n\n\n注釈：str_split_fixed() を使用しても同じ結果が出力されますが、その場合は simplify 引数を与えず、代わりに列数（n）を指定しなければなりません。\n\nstr_split_fixed(symptoms, \",\", n = 2)\n\n\n\n列の分割\nデータフレームの列を分割する場合は、dplyr パッケージの separate() が最適です。この関数は、文字列を要素に持つ 1 つの列を複数の列に分割することができます。\n例えば、先述の列の結合のセクションで作成した簡単なデータフレーム df を見てみましょう。このデータフレームには case_ID の列、多くの症状をまとめた文字列からなる列、そして予後を示す列が含まれています。ここでは、複数の症状が含まれている symptoms 列を症状ごとの列に分割し、各列が単一の症状を表すようにすることを目的とします。\n\n\n\n\n\n\nデータを separate() で処理する場合、まず分離する列を指定します。次に、以下のように新しい列名を含むベクトル c() を into = 引数に指定します。\n\nsep = 分割する位置を、文字または数字で指定します。\nremove = デフォルトではFALSE。入力された列を削除します。\n\nconvert = デフォルトではFALSE。文字列 “NA”を NA に変換します。\nextra = 分離によって作成された値の数が、指定された新規列の名前よりも多い場合の動作を制御します。\n\nextra = \"warn\" は、警告を表示し、過剰な値は削除されます（デフォルト）。\nextra = \"drop\" は、警告を表示せずに余分な値を削除します。\nextra = \"merge\" は、into = で指定された新しい列の数だけ分割します。- この設定では全ての入力データが保存されます。\n\n\nextra = \"merge\" を使用した例を以下に示します（ここではデータは失われません）。2 つの新しい列が定義され、3 つ目の症状は 2 つ目の列に入ります。\n\n# 3つ目の症状は2つ目の新しい列に組み込まれる\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1          sym_2 outcome\n1       1           jaundice  fever, chills Recover\n2       2             chills   aches, pains   Death\n3       3              fever           &lt;NA&gt;   Death\n4       4           vomiting      diarrhoea Recover\n5       5 bleeding from gums          fever Recover\n6       6        rapid pulse       headache Recover\n\n\nデフォルトの extra = \"drop\" に設定した場合、以下のように警告が表示されます。\n\n# 3番目の症状は失われる\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")\n\nWarning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].\n\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1      sym_2 outcome\n1       1           jaundice      fever Recover\n2       2             chills      aches   Death\n3       3              fever       &lt;NA&gt;   Death\n4       4           vomiting  diarrhoea Recover\n5       5 bleeding from gums      fever Recover\n6       6        rapid pulse   headache Recover\n\n\n注意：into = に入力された値の数（新規列の名前）が不足していると、データが切り捨てられる可能性があります。\n\n\n\nアルファベット順に並べる\n複数の文字列をアルファベット順に並べることができます。str_order() を使用すると、順序が返され、str_sort() はその順序に並べ替えた文字列を返します。\n\n# 文字列の定義\nhealth_zones &lt;- c(\"Alba\", \"Takota\", \"Delta\")\n\n# アルファベット順を返す\nstr_order(health_zones)\n\n[1] 1 3 2\n\n# アルファベット順に並び替える\nstr_sort(health_zones)\n\n[1] \"Alba\"   \"Delta\"  \"Takota\"\n\n\n英語以外の他のアルファベットを使用したい場合は、引数 locale = を追加します。R コンソールで stringi::stri_locale_list() と入力すると、指定可能なアルファベットの一覧を表示することができます。\n\n\n\nR の基本関数\nR の base パッケージに含まれている関数である paste() や paste0() は、与えられたベクトルのすべての要素を文字に変換した後、結合して 1 つの文字列を返すためによく使われます。これらの関数は str_c() と似ていますが、使用される構文はより複雑で、括弧の中では各部分がコンマで区切られています。括弧内の各部分は、引用符で囲まれた文字テキストまたはすでに定義されたコードオブジェクト（引用符なし）です。例えば、以下のようになります。\n\nn_beds &lt;- 10\nn_masks &lt;- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")\n\n[1] \"Regional hospital needs 10 beds and 20 masks.\"\n\n\nsep = と collapse = の引数を指定できます。paste() は、paste0() で sep = \" \"（半角スペース）を使用した場合と同じです。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#整理と標準化",
    "href": "new_pages/characters_strings.jp.html#整理と標準化",
    "title": "10  文字型・文字列型データ",
    "section": "10.3 整理と標準化",
    "text": "10.3 整理と標準化\n\n\n大文字小文字の変更\n管轄区域の名称など、大文字小文字を変更しなければならない場合がよくあります。その場合は、以下のように stringr に含まれる str_to_upper()、str_to_lower()、str_to_title() を使用すると便利です。\n\nstr_to_upper(\"California\")\n\n[1] \"CALIFORNIA\"\n\nstr_to_lower(\"California\")\n\n[1] \"california\"\n\n\nbase R の toupper()、tolower() を使用しても同じ処理をすることができます。\n語頭を大文字にする\n各単語の語頭を大文字にしたい場合は、str_to_title() を使います。\n\nstr_to_title(\"go to the US state of california \")\n\n[1] \"Go To The Us State Of California \"\n\n\ntools パッケージの toTitleCase() を使うことで、より厳密に（“to”、“the”、“of” のような単語は大文字化されずに）語頭を大文字にすることができます。\n\ntools::toTitleCase(\"This is the US state of california\")\n\n[1] \"This is the US State of California\"\n\n\nまた、str_to_sentence() を使うと、文字列の最初の文字の語頭のみを大文字にすることができます。\n\nstr_to_sentence(\"the patient must be transported\")\n\n[1] \"The patient must be transported\"\n\n\n\n\n文字列を伸長する\nstr_pad() を用いると、文字列に特定の文字を足すことで、指定した長さまで文字列を伸ばすことができますデフォルトではスペース（空白）が追加されますが、pad = によってピリオドなど他の文字を指定することも可能です。\n\n# 異なる長さのICDコード\nICD_codes &lt;- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# 最低7文字になるよう右側に空白を足したICDコード\nstr_pad(ICD_codes, 7, \"right\")\n\n[1] \"R10.13 \" \"R10.819\" \"R17    \"\n\n# 空白の代わりにピリオドで文字列を伸長\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")\n\n[1] \"R10.13.\" \"R10.819\" \"R17....\"\n\n\n例えば、pad = \"0\" により先頭に 0 を足すことで、時間や分のように数字で構成される文字列の長さが少なくとも 2 になるように処理することができます。\n\n# 先頭に0を足して2桁にする（例：時間・分の表示）\nstr_pad(\"4\", 2, pad = \"0\") \n\n[1] \"04\"\n\n# \"hours\"という名前の数字列を作る場合\n# hours &lt;- str_pad(hours, 2, pad = \"0\")\n\n\n\n文字列を短縮する\nstr_trunc() で文字列の長さの最大値を設定できます。与えられた文字列の長さが指定した最大値を超える場合、その文字列は短縮され、省略記号（…）が挿入されます。このとき、省略記号は文字数にカウントされることに注意してください。使用される省略記号は ellipsis = で指定することができます。また side = によって、省略記号がどこに挿入されるか（“left”、 “right”、 “center”）を指定することができます。\n\noriginal &lt;- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")\n\n[1] \"Symp...ing\"\n\n\n\n\n長さの標準化\n文字列の長さの最大値を str_trunc() で指定し、さらに str_pad() を用いて短い文字列をその長さまで伸長することができます。以下の例では、最大値を 6 に設定し（1 つの文字列が短縮されます）、次に設定された最大値 6 に満たない文字列がその長さまで伸長されます。\n\n# 異なる長さのICDコード\nICD_codes   &lt;- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# 最大の長さが6になるよう文字列を短縮\nICD_codes_2 &lt;- str_trunc(ICD_codes, 6)\nICD_codes_2\n\n[1] \"R10.13\" \"R10...\" \"R17\"   \n\n# 最小の長さが6になるよう文字列を伸長\nICD_codes_3 &lt;- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3\n\n[1] \"R10.13\" \"R10...\" \"R17   \"\n\n\n\n\n先頭・末尾の空白を削除する\nstr_trim() を用いて文字列の端にある空白、改行（\\n）、タブ （\\t）を削除できます。\"right\"、\"left\"、または \"both\" を指定することにより、どちらの端から削除するかを選択することができます（例：str_trim(x, \"right\")）。\n\n# 右端に余分な空白を持つID\nIDs &lt;- c(\"provA_1852  \", # 2つの余分な空白あり\n         \"provA_2345\",   # 余分な空白なし\n         \"provA_9460 \")  # 1つの余分な空白あり\n\n# 右端から空白を削除\nstr_trim(IDs)\n\n[1] \"provA_1852\" \"provA_2345\" \"provA_9460\"\n\n\n\n\n繰り返される空白の削除\nstr_squish() を用いて文字列の内部に連続して現れる空白を削除できます。例えば、2 つ続きになっている空白を 1 つの空白に変更できます。str_trim() と同様、文字列の端にある空白、改行、タブを削除することもできます。\n\n# 元の文字列は内部に余分な空白を含む\nstr_squish(\"  Pt requires   IV saline\\n\")\n\n[1] \"Pt requires IV saline\"\n\n\nR コンソールに ?str_trim、?str_pad と入力すると、詳細を確認できます。\n\n\n指定の文字数で文章を改行する\nstr_wrap() を用いることで、長い文章を指定した文字数で改行し整理することができます。任意の文字数を指定すれば、アルゴリズムにより以下のように文章中に改行（\\n）が挿入されます。\n\npt_course &lt;- \"Symptom onset 1/4/2020 vomiting chills fever. Pt saw traditional healer in home village on 2/4/2020. On 5/4/2020 pt symptoms worsened and was admitted to Lumta clinic. Sample was taken and pt was transported to regional hospital on 6/4/2020. Pt died at regional hospital on 7/4/2020.\"\n\nstr_wrap(pt_course, 40)\n\n[1] \"Symptom onset 1/4/2020 vomiting chills\\nfever. Pt saw traditional healer in\\nhome village on 2/4/2020. On 5/4/2020\\npt symptoms worsened and was admitted\\nto Lumta clinic. Sample was taken and pt\\nwas transported to regional hospital on\\n6/4/2020. Pt died at regional hospital\\non 7/4/2020.\"\n\n\nbase の cat() に上記のコマンドを入力することで、改行された文章を表示することができます。\n\ncat(str_wrap(pt_course, 40))\n\nSymptom onset 1/4/2020 vomiting chills\nfever. Pt saw traditional healer in\nhome village on 2/4/2020. On 5/4/2020\npt symptoms worsened and was admitted\nto Lumta clinic. Sample was taken and pt\nwas transported to regional hospital on\n6/4/2020. Pt died at regional hospital\non 7/4/2020.",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#位置による操作",
    "href": "new_pages/characters_strings.jp.html#位置による操作",
    "title": "10  文字型・文字列型データ",
    "section": "10.4 位置による操作",
    "text": "10.4 位置による操作\n\n位置を指定して文字を抽出する\nstr_sub() は文字列の一部を返します。この関数は次の 3 つの引数を取ります。\n\n文字ベクトル\n開始位置\n終了位置\n\n位置を定義する際にいくつかの注意点があります：\n\n位置番号が正のとき、位置は文字列の左端からカウントされます。\n位置番号が負のとき、位置は文字列の右端からカウントされます。\n開始・終了位置は選択範囲に含まれます。\n文字列の長さを超えて選択された範囲は無視されます。\n\n以下に文字列 “pneumonia” を用いた例を示します：\n\n# 左から3文字目を開始および終了位置に設定\nstr_sub(\"pneumonia\", 3, 3)\n\n[1] \"e\"\n\n# 位置0は存在しません\nstr_sub(\"pneumonia\", 0, 0)\n\n[1] \"\"\n\n# 左から6文字目を開始位置、右から1文字目を終了位置に設定\nstr_sub(\"pneumonia\", 6, -1)\n\n[1] \"onia\"\n\n# 右から5文字目を開始位置、右から2文字目を終了位置に設定\nstr_sub(\"pneumonia\", -5, -2)\n\n[1] \"moni\"\n\n# 左から4文字目を開始位置、文字列の長さを超えた位置を終了位置に設定\nstr_sub(\"pneumonia\", 4, 15)\n\n[1] \"umonia\"\n\n\n\n\n位置を指定して単語を抽出する\nn 番目の単語を抽出したい場合は、stringr パッケージの word() を用います。文字列、開始位置、終了位置を引数に取ります。\n初期設定では空白で区切られた部分が単語と認識されます。区切りは sep = で変更でき、例えば sep = \"_\" と指定すると下線で区切られた部分が単語と認識されます。\n\n# 評価したい文字列\nchief_complaints &lt;- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# 1から3番目の単語を抽出\nword(chief_complaints, start = 1, end = 3, sep = \" \")\n\n[1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\" \n\n\n\n\n位置を指定して文字を入れ替える\nstr_sub() と代入演算子（&lt;-）を組み合わせて文字列の一部を変更できます。\n\nword &lt;- \"pneumonia\"\n\n# 3番目と4番目の文字をXに変更する\nstr_sub(word, 3, 4) &lt;- \"XX\"\n\n# 結果を表示\nword\n\n[1] \"pnXXmonia\"\n\n\nデータフレームの列など、複数の文字列に対して用いる場合の例を示します。以下の例では、コマンド実行後に “HIV” の文字列が長くなることに注意してください。\n\nwords &lt;- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# 3番目と4番目の文字をXに変更する\nstr_sub(words, 3, 4) &lt;- \"XX\"\n\nwords\n\n[1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\"        \n\n\n\n\n長さを評価する\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nbase R の nchar() でも同様の操作が可能です。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#パターン",
    "href": "new_pages/characters_strings.jp.html#パターン",
    "title": "10  文字型・文字列型データ",
    "section": "10.5 パターン",
    "text": "10.5 パターン\nstringr に含まれる関数の多くは、与えられた文字列から特定のパターンを見つけ、その位置を特定したり、抽出・入れ替えなどの操作を行うことができます。\n\n\nパターンを見つける\n以下の例のように str_detect() を使うことで、文字列中に特定のパターンが存在するか否かを判別することができます。初めに検索する文字列を与え（string =）、さらに探したいパターンを入力します（pattern =）。 初期設定では大文字小文字が区別されることに注意してください！\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")\n\n[1] TRUE\n\n\n引数 negate = を TRUE に設定することで、パターンが存在「しない」かどうかを判定できます。\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)\n\n[1] FALSE\n\n\n大文字小文字を無視したい場合は、パターンを regex() で包み、regex() 中に ignore_case = TRUE（もしくは短く T）と指定します。\n\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))\n\n[1] TRUE\n\n\nstr_detect() で検索する文字列が文字ベクトルやデータフレームの列である場合は、各要素ごとに TRUE または FALSE が返されます。\n\n# 職業のベクトル・列\noccupations &lt;- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# 各文字列中に\"teach\"が含まれるかを判別する - TRUE/FALSE が出力される\nstr_detect(occupations, \"teach\")\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nTRUE がいくつあるかを数えたい場合は、出力された値を sum() に入力します。\n\nsum(str_detect(occupations, \"teach\"))\n\n[1] 1\n\n\n複数のパターンを探したい場合は、以下のように各パターンを OR 記号（|）で区切り、pattern = で指定します。\n\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))\n\n[1] 3\n\n\nより多くのパターンを同時に探したいときは、 str_c() と sep = | を組み合わせた出力を文字オブジェクトとして先に定義することで、コードをより簡潔にすることができます。以下の例では、医療従事者の職業リストをパターンとして検索します。\n\n# 検索するパターン\noccupation_med_frontline &lt;- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline\n\n[1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\n\n\n以下の例では、先に定義した職業リストの中に含まれる医療職（occupation_med_frontline）の数を返します。\n\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))\n\n[1] 2\n\n\n文字列検索のための基本 R 関数\nbase R の grepl() は str_detect() と同様、パターンの有無を判定しロジカルベクトルを返します。基本構文は grepl(pattern, strings_to_search, ignore.case = FALSE, ...) です。grepl() を使用する利点の 1 つとして、regex() を使わずに ignore.case = を指定するだけで大文字小文字を区別するかを変更することができます。\n同様に、base R の sub() と gsub() は str_replace() に近い働きをします。 基本構文は gsub(pattern, replacement, strings_to_search, ignore.case = FALSE) です。sub() は一致したパターンのうち最初に現れるものだけを、gsub() は一致したパターンの全てを入れ替えます。\n\nコンマをピリオドに入れ替える\n以下に gsub() を用いてコンマをピリオドに入れ替える例を示します。これは米国や英国以外で収集されたデータを扱う際に役に立つかもしれません。\n内部の gsub() は lengths 内のピリオドを除いて ““（空白無し）に入れ替えます。ピリオド”.” をパターンとして指定する際は、その前に 2 つバックスラッシュを置くことで「エスケープ」する必要があります。これは正規表現において “.” が “全ての文字” を意味するためです。 ここで出力された結果（ピリオドは削除されカンマのみを含む）は外側の gsub() に渡され、コンマがピリオドに置き換わります。\n\nlengths &lt;- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # コンマを見つける\n                replacement = \".\",            # ピリオドに入れ替える\n                x = gsub(\"\\\\.\", \"\", lengths)  # ピリオド（エスケープして指定）を削除する\n                )\n           )                                  # 出力を数字ベクトルに変更\n\n\n\n\n全て入れ替える\nstr_replace_all() は「検索と置換」ツールとして使用できます。検索する文字列、パターン、置き換える値をそれぞれ string =、pattern =、replacement = で指定します。 以下の例では、全ての “dead” を “deceased” に入れ替えます。大文字小文字が区別されることに注意してください。\n\noutcome &lt;- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")\n\n[1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\"\n\n\n注釈：\n\n指定したパターンを NA で置き換えるには str_replace_na() を用います。\nstr_replace() は与えられた各文字列中に現れる最初のパターンだけを入れ替えます。\n\n\n\n\nパターンの有無による条件分岐\ncase_when() との組み合わせ\nstr_detect() は dplyr パッケージの case_when() と組み合わせて用いられることが多いです。例として、occupations がラインリスト内の列であるとします。以下の mutate() は case_when() による条件分岐に従って新しい列 is_educator を作ります。case_when() についての詳細は、データクリーニングと主要関数 の章を参照してください。\n\ndf &lt;- df %&gt;% \n  mutate(is_educator = case_when(\n    # occupation内でパターン検索（大文字小文字は区別しない）\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # その他全て\n    TRUE                                               ~ \"Not an educator\"))\n\nnegate = F を用いて除外したいパターンを指定できることも覚えておきましょう。\n\ndf &lt;- df %&gt;% \n  # 新しい列is_educatorの値を条件分岐により決定する\n  mutate(is_educator = case_when(\n    \n    # \"Educator\"の値を取るためには2つの基準を満たす必要がある：\n    # 指定されたパターンを持ち、かつ除外されたパターンを持たない\n\n    # 指定されたパターンを持つ\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &\n    \n    # 指定されたパターンを持たない\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # 上記の条件を満たさない全ての行\n    TRUE                                            ~ \"Not an educator\"))\n\n\n\n\nパターンの位置を特定する\n指定したパターンが与えられた文字列中に最初に現れる位置を特定するためには、str_locate() を用います。パターンの最初と最後の文字の位置を返します。\n\nstr_locate(\"I wish\", \"sh\")\n\n     start end\n[1,]     5   6\n\n\nその他の str 関数と同様、str_locate() にも “_all” バージョンが存在します（str_locate_all()）。与えられた各文字列中に現れるパターンの全ての位置を list 形式で返します。\n\nphrases &lt;- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # *最初に*現れるパターンの位置\n\n     start end\n[1,]     6   6\n[2,]     3   3\n[3,]     1   1\n[4,]     4   4\n\nstr_locate_all(phrases, \"h\" ) # *全ての*パターンの位置\n\n[[1]]\n     start end\n[1,]     6   6\n\n[[2]]\n     start end\n[1,]     3   3\n\n[[3]]\n     start end\n[1,]     1   1\n[2,]     4   4\n\n[[4]]\n     start end\n[1,]     4   4\n\n\n\n\n\n一致したパターンを抽出する\nstr_extract_all() はマッチしたパターンそのものを返します。これは “OR（|）” を用いて複数のパターンを検索したときに特に有用です。例えば、職業の文字列リスト（前のセクションを参照）内で “teach”、“prof”、“tutor” のいずれかのパターンに合致する単語を探したいとします。\nstr_extract_all() 与えられた文字列内の一致するパターン全ての list を返します。以下の例では、出力されたリストのうち 3 つ目の要素において 2 つのパターンが一致していることに注目してください。\n\nstr_extract_all(occupations, \"teach|prof|tutor\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\n[1] \"prof\"\n\n[[3]]\n[1] \"teach\" \"tutor\"\n\n[[4]]\n[1] \"tutor\"\n\n[[5]]\ncharacter(0)\n\n[[6]]\ncharacter(0)\n\n[[7]]\ncharacter(0)\n\n[[8]]\ncharacter(0)\n\n[[9]]\ncharacter(0)\n\n[[10]]\ncharacter(0)\n\n\n一方、str_extract() は最初に一致したパターンのみを返します。従って、出力結果は与えられた各文字列に対して 1 つのパターンが文字ベクトルで返されます。 一致するパターンがない場合は NA が返されます。この NA は str_extract を na.exclude() で包むことで消去することもできます。以下の例では、3 つ目の文字列の 2 つ目の一致パターンが表示されないことに注意してください。\n\nstr_extract(occupations, \"teach|prof|tutor\")\n\n [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA     \n[10] NA     \n\n\n\n\n\nサブセットと数え上げ\nここでは str_subset() と str_count() を扱います。\nstr_subset() は一致したパターンだけでなく、そのパターンを含む文字列全体を返します：\n\nstr_subset(occupations, \"teach|prof|tutor\")\n\n[1] \"university professor\"           \"primary school teacher & tutor\"\n[3] \"tutor\"                         \n\n\nstr_count() は検索した文字列中に指定したパターンが現れる合計回数をベクトルで返します。\n\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))\n\n [1] 0 1 2 1 0 0 0 0 0 0\n\n\n\n\n\n正規表現グループ\n作成中",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#特殊文字",
    "href": "new_pages/characters_strings.jp.html#特殊文字",
    "title": "10  文字型・文字列型データ",
    "section": "10.6 特殊文字",
    "text": "10.6 特殊文字\nバックスラッシュ \\ によるエスケープ\nバックスラッシュ \\ はその直後に現れる文字の意味を「エスケープ」するために使われます。例えば、二重引用符の中で使用されている引用符の前にバックスラッシュを置くと（\\\"）、その引用符が二重引用符の中で表示されます。その際、中で挟まれる引用符はそれを囲む引用符とは干渉しません。\n注釈：バックスラッシュを文字として表示したい場合は、その前にもう 1 つのバックスラッシュを置いて、エスケープ記号としての役割を回避する必要があります。つまり、\\\\ と書くことでバックスラッシュを1 つ表示できます。\n特殊文字の例\n\n\n\n特殊文字\n意味\n\n\n\n\n\"\\\\\"\nバックスラッシュ\n\n\n\"\\n\"\n改行\n\n\n\"\\\"\"\n二重引用符中での二重引用符の表示\n\n\n'\\''\n一重引用符中での一重引用符の表示\n\n\n\"\\`\"\nバッククオート\n\n\n\"\\r\"\nキャリッジリターン\n\n\n\"\\t\"\nタブ\n\n\n\"\\v\"\nバーティカルタブ\n\n\n\"\\b\"\nバックスペース\n\n\n\n?\"'\" コマンドを R コンソールで実行すると、特殊文字の一覧が表示できます（RStudio ではヘルプ画面に表示されます）。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#正規表現-regex",
    "href": "new_pages/characters_strings.jp.html#正規表現-regex",
    "title": "10  文字型・文字列型データ",
    "section": "10.7 正規表現 (regex)",
    "text": "10.7 正規表現 (regex)",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#正規表現と特殊文字",
    "href": "new_pages/characters_strings.jp.html#正規表現と特殊文字",
    "title": "10  文字型・文字列型データ",
    "section": "10.8 正規表現と特殊文字",
    "text": "10.8 正規表現と特殊文字\n正規表現（または regex）とは、文字列パターンを記述するために用いられる言語規則のことです。馴染みがない人にとっては、まるで他の星の言葉のように映るかもしれません。ここでは、その正規表現に対するハードルを少し下げることを目標にします。\nこのセクションで扱う内容の多くは こちらのチュートリアル と こちらのチートシート を参考に作成されました。ここでは、このハンドブックがインターネットへのアクセスが無く他のチュートリアルを見れない方からも利用されうることを念頭に、これらの参考文献から内容を選んで参考にしています。\n正規表現は決まった構造を持たない文章（例えば、診療録、主訴、既往歴やデータフレーム中の文字列など）から特定のパターンを抜き出すためによく使われます。\n正規表現を構築するために使われる基本ツールは以下の 4 つです。\n\n文字セット\nメタ文字\n数量詞\nグループ\n\n文字セット\n文字セットは角括弧 [ ] を用いて文字のリストを表現します。角括弧中に含まれる文字のいずれかが対象の文字列中に含まれる場合、一致パターンとして扱われます。例えば、母音のいずれかを検索したい場合 “[aeiou]” と表現できます。以下によく使われる文字セットを示します。\n\n\n\n文字セット\n検索される文字\n\n\n\n\n\"[A-Z]\"\n全ての大文字アルファベット\n\n\n\"[a-z]\"\n全ての小文字アルファベット\n\n\n\"[0-9]\"\n全ての数字\n\n\n[:alnum:]\n全てのアルファベットおよび数字\n\n\n[:digit:]\n全ての数字\n\n\n[:alpha:]\n全ての大文字および小文字アルファベット\n\n\n[:upper:]\n全ての大文字アルファベット\n\n\n[:lower:]\n全ての小文字アルファベット\n\n\n\n複数の文字セットを 1 つの角括弧中に（空白なしで！）組み合わせることができます。例えば \"[A-Za-z]\" は全ての大文字および小文字アルファベットを、\"[t-z0-5]\" は t から z までの小文字アルファベットと 0 から 5 までの数字を表します。\nメタ文字\nメタ文字は文字セットの省略表記です。以下にいくつかの重要な例を示します：\n\n\n\nメタ文字\n検索される文字\n\n\n\n\n\"\\\\s\"\n1 つの空白\n\n\n\"\\\\w\"\n全てのアルファベットおよび数字（A-Z、a-z、または 0-9）\n\n\n\"\\\\d\"\n全ての数字（0-9）\n\n\n\n数量詞\n多くの場合、検索したいパターンは 2 つ以上の文字を含みます。数量詞により一致を探す文字や数字の長さを規定できます。\n数量詞は数を指定したいパターンの後に波括弧 { } を置き、その中に数字を書くことで定義されます。 例えば、\n\n\"A{2}\" は大文字 A 2 つを示します。\n\n\"A{2,4}\" は 2 から 4 つの大文字 A を示します（波括弧中に空白は置かれません！）。\n\n\"A{2,}\" は 2 つ以上の大文字 A を示します。\n\"A+\" は 1 つ以上の大文字 A を示します（他の文字が現れるまで、連続した A は全てグループに含まれます）。\nアスタリスク * を前におくと 0 個以上のという意味が付加されます（そのパターンが存在するか不確かなときに有用です）。\n\n+ シンボルを使うと、他の文字が出てくるまでの連続した同一の文字が全て一致するパターンとして扱われます。例えば、\"[A-Za-z]+\" という表現は全ての単語（アルファベットのみでできた文字列）に対応します。\n\n# 数量詞をテストするための文字列\ntest &lt;- \"A-AA-AAA-AAAA\"\n\n数量詞 {2} を用いた場合、2 つ続きの A のみがマッチとして扱われます。AAAA からは 2 つのマッチが返されます。\n\nstr_extract_all(test, \"A{2}\")\n\n[[1]]\n[1] \"AA\" \"AA\" \"AA\" \"AA\"\n\n\n数量詞 {2,4} を用いた場合、2 つから 4 つ続きの A がマッチとして扱われます。\n\nstr_extract_all(test, \"A{2,4}\")\n\n[[1]]\n[1] \"AA\"   \"AAA\"  \"AAAA\"\n\n\n数量詞 + を用いた場合、1 つ以上の連続した A がマッチとして扱われます：\n\nstr_extract_all(test, \"A+\")\n\n[[1]]\n[1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\n\n\n相対的位置\nここで紹介する構文を用いることで、探したいパターンの直前または直後に来る文字ないしはパターンを指定することができます。例えば、「ピリオドが直後に来る 2 つ続きの数字」というパターンを表現したいときは (?&lt;=\\.)\\s(?=[A-Z])\n\nstr_extract_all(test, \"\")\n\n[[1]]\n [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\n\n\n\n\n\n位置構文\nマッチするパターン\n\n\n\n\n\"(?&lt;=b)a\"\n“b” が直前に来る “a”\n\n\n\"(?&lt;!b)a\"\n“b” が直前に来ない “a”\n\n\n\"a(?=b)\"\n“b” が直後に来る “a”\n\n\n\"a(?!b)\"\n“b” が直後に来ない “a”\n\n\n\nグループ\n正規表現の中でグループを用いることで、パターン検索をより整理された形で行うことができます。\n正規表現の例\nここでは、以下の文章から正規表現を用いて有用な情報を抽出する例を示します。\n\npt_note &lt;- \"Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute.\"\n\n以下の正規表現は、全ての単語（連続したアルファベットのみからなるまとまり）を抽出します。\n\nstr_extract_all(pt_note, \"[A-Za-z]+\")\n\n[[1]]\n [1] \"Patient\"     \"arrived\"     \"at\"          \"Broward\"     \"Hospital\"   \n [6] \"emergency\"   \"ward\"        \"at\"          \"on\"          \"Patient\"    \n[11] \"presented\"   \"with\"        \"radiating\"   \"abdominal\"   \"pain\"       \n[16] \"from\"        \"LR\"          \"quadrant\"    \"Patient\"     \"skin\"       \n[21] \"was\"         \"pale\"        \"cool\"        \"and\"         \"clammy\"     \n[26] \"Patient\"     \"temperature\" \"was\"         \"degrees\"     \"farinheit\"  \n[31] \"Patient\"     \"pulse\"       \"rate\"        \"was\"         \"bpm\"        \n[36] \"and\"         \"thready\"     \"Respiratory\" \"rate\"        \"was\"        \n[41] \"per\"         \"minute\"     \n\n\n正規表現 \"[0-9]{1,2}\" は 1 つのみもしくは 2 つ続きの数字にマッチします。\"\\\\d{1,2}\" もしくは \"[:digit:]{1,2}\" と書くこともできます。\n\nstr_extract_all(pt_note, \"[0-9]{1,2}\")\n\n[[1]]\n [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\"\n\n\n\n\n\n\nこちらのチートシート の 2 ページ目に、有用な正規表現のリストやヒントがありますので、参照してください。\nこちらのチュートリアル も参考にしてください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.jp.html#参考資料",
    "href": "new_pages/characters_strings.jp.html#参考資料",
    "title": "10  文字型・文字列型データ",
    "section": "10.9 参考資料",
    "text": "10.9 参考資料\nstringr に含まれる関数の詳細は こちら を参照してください。\nstringr に関する簡単な説明は こちら から読むことができます。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>文字型・文字列型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html",
    "href": "new_pages/factors.jp.html",
    "title": "11  因子（ファクタ）型データ",
    "section": "",
    "text": "11.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#準備",
    "href": "new_pages/factors.jp.html#準備",
    "title": "11  因子（ファクタ）型データ",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについては、R の基礎 の章を参照してください。\n\npacman::p_load(\n  rio,           # インポート・エクスポート\n  here,          # ファイルパス\n  lubridate,     # 日付\n  forcats,       # 因子型データ\n  aweek,         # 自動的な因子レベルを持つエピウィークの作成\n  janitor,       # 表\n  tidyverse      # データ管理・可視化\n  )\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、こちらをクリックして「前処理された」ラインリスト（linelist）をダウンロードしてください（.rds 形式で取得できます）。 データは rio パッケージの import() を利用してインポートしましょう（import() は、.xlsx、.csv、.rdsなど、様々な形式のファイルを扱うことができます）。インポートの詳細については、データのインポート・エクスポート の章を参照してください。\n\n# データセットをインポートする\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n\n\n新しいカテゴリ変数\nこのセクションでは、一般的によく行われる新しいカテゴリ変数の作成を例に説明します。\n数字型の列を因子型に変換した場合、その列の数値計算はできなくなることに注意してください。\n\n列の作成\n既存の days_onset_hosp （症状発現から入院までの日数）列を用いて、各行を複数カテゴリのいずれかに分類し、新しく delay_cat 列を作成します。dplyr の case_when() を使い、左側には各行に適用する論理基準を書き、右側には新しい列 delay_cat の値として返される値を書きます。case_when() については、データクリーニングと主要関数 の章で詳しく説明しています。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = case_when(\n    # 基準                                   # 基準が TRUE の場合 delay_cat に指定される値\n    days_onset_hosp &lt; 2                        ~ \"&lt;2 days\",\n    days_onset_hosp &gt;= 2 & days_onset_hosp &lt; 5 ~ \"2-5 days\",\n    days_onset_hosp &gt;= 5                       ~ \"&gt;5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  \n\n\n\n初期値の順序\ncase_when() で作成されたように、新しい列 delay_cat は文字型であり、まだ因子型ではありません。したがって、度数分布表では、デフォルトの英数字の順序で値が表示されます（直感的ではなく、あまり意味のない順序です）。\n\ntable(linelist$delay_cat, useNA = \"always\")\n\n\n &lt;2 days  &gt;5 days 2-5 days     &lt;NA&gt; \n    2990      602     2040      256 \n\n\n同様に、棒グラフを作成する場合も、この順序で x 軸の値が表示されます（R で最も一般的なデータ視覚化のパッケージである ggplot2 の詳細については、ggplot の基礎 の章を参照ください）。\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#因子型への変換",
    "href": "new_pages/factors.jp.html#因子型への変換",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.2 因子型への変換",
    "text": "11.2 因子型への変換\n文字型や数字型の列を因子型に変換するには、forcats パッケージに含まれている関数のいずれかを使用します（関数については 以下 で詳しく説明します）。このパッケージを使用するとデータを因子型に変換でき、任意の因子レベルの順序を指定することができます。例えば、 fct_relevel() を使用すると、レベルの順序を手動で指定できます。一方、as_factor() は単にデータを因子型に変換するのみで、レベルの設定などの機能はありません。\nbase R の関数である factor() は、列を因子型に変換し、levels = 引数に指定した文字ベクトルにより、因子レベルの順序を手動で指定することができます。\n以下では、mutate() と fct_relevel() を使用して、列 delay_cat を文字型から因子型に変換します。列 delay_cat は、上記の 準備 セクションで作成されされたものです。\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat))\n\nここで、この列の一意の「値」（重複のない形で取り出された値）は、因子の「レベル」と見なされます。レベルには順序があり、これは base R の levels() で確認するか、同じく base R の table() または janitor の tabyl() でカウントテーブル（列内の値の個数を集計した表）として表示することもできます。デフォルトでは、レベルの順序は先の例と同様に英数字になります。 NA は因子レベルではないことに注意してください。\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"&gt;5 days\"  \"2-5 days\"\n\n\nfct_relevel() を使ってレベルの順序を手動で指定することもできます。以下のように、レベルの値を二重引用符で囲み、コンマで区切って順番に記載します。記載する綴り（つづり）は列内の値と正確に一致する必要があることに注意してください。データに存在しないレベルを作成する場合は、代わりに fct_expand() を使用してください。fct_expand() の詳細は、以下のセクション をご覧ください。\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))\n\n上のコマンドを実行すると、指定したように、意味のある順序でレベルが並べられることが確認できます。\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nこれで、プロットの順序もより直感的に理解できるようになりました。\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#レベルの追加または削除",
    "href": "new_pages/factors.jp.html#レベルの追加または削除",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.3 レベルの追加または削除",
    "text": "11.3 レベルの追加または削除\n\nレベルの追加\n因子にレベルを追加する必要がある場合、 fct_expand() で実行することができます。列名の後に新しいレベル（コンマで区切る）を入力するだけです。値を表にすると、新しく作成されたレベルが確認でき、新しいレベルに含まれる値の個数（カウント）がゼロであることがわかります。base R の table() や、janitor の tabyl() で表を作成できます。\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %&gt;% \n  tabyl(delay_cat)   # 表の表示\n\n                      delay_cat    n    percent valid_percent\n                        &lt;2 days 2990 0.50781250     0.5308949\n                       2-5 days 2040 0.34646739     0.3622159\n                        &gt;5 days  602 0.10224185     0.1068892\n       Not admitted to hospital    0 0.00000000     0.0000000\n Transfer to other jurisdiction    0 0.00000000     0.0000000\n                           &lt;NA&gt;  256 0.04347826            NA\n\n\n注：forcats 関数は、欠損値（NA）を簡単にレベルとして追加するための特別な関数です。詳しくは、以下の 欠損値 に関するセクションを参照してください。\n\n\nレベルの削除\nfct_drop() を使用すると、「使用されていない」レベル（カウントがゼロのレベル）がレベルのセットから削除されます。上の例で追加したレベル（“Not addmitted to hospital”）はレベルとして存在しますが、実際にその値を持つ行はありません。したがって、因子型の列に fct_drop() を適用すると、このような使用されていないレベルは削除されます。\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_drop(delay_cat)) %&gt;% \n  tabyl(delay_cat)\n\n delay_cat    n    percent valid_percent\n   &lt;2 days 2990 0.50781250     0.5308949\n  2-5 days 2040 0.34646739     0.3622159\n   &gt;5 days  602 0.10224185     0.1068892\n      &lt;NA&gt;  256 0.04347826            NA",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#fct_adjust",
    "href": "new_pages/factors.jp.html#fct_adjust",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.4 レベルの順序の調整",
    "text": "11.4 レベルの順序の調整\nforcats パッケージには、因子型のレベルの順序を簡単に調整する便利な関数があります（列が因子型として定義された後に使用してください）。\nforcats パッケージに含まれる関数は、次の 2 つの状況で因子型の列に適用できます。\n\n通常通り、データフレームの列に対して適用する（変更内容がその後のデータ利用に適用されるようにする）\n\nプロット内で適用し、変更内容がプロット内でのみ適用されるようにする\n\n\n手動で調整\nfct_relevel() は、因子レベルを手動で順序付けるために使用されます。因子型ではない列で使用された場合、その列は最初に因子型に変換されます。\nまず、括弧の中に対象の因子型の列名を記入し、次に以下のどちらかを記入します。\n\nすべてのレベルを希望する順序で文字ベクトル c() で記入する、または\n\n1 つのレベルを記入し、after = 引数で希望の配置を指定する\n\n以下に、すでに因子型である delay_cat 列に含まれる因子のレベルを希望する順序で再定義する例を示します。\n\n# レベルの順序を再定義する\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\")))\n\n1 つのレベルのみを調整する場合は、それを fct_relevel() にて単独で指定し、after = 引数に番号を指定し、既存の順序のどこに配置するかを指定します。例えば、以下のコマンドでは、“&lt;2 days” を 2 番目の位置に移動させます。\n\n# レベルの順序を再定義する\nlinelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", after = 1)) %&gt;% \n  tabyl(delay_cat)\n\n\n\nプロット内で調整\nforcats コマンドを使用して、データフレーム内、またはプロット内でのみレベルの順序を調整することが可能です。設定できます。ggplot() のコマンド内で列名を「指定する」コマンドを使用することにより、レベルの順序の反転や調整などをプロット内でのみ適用させることができます。\n以下に、 ggplot() で 2 つのプロットを作成します（プロットの作成についての詳細は、ggplot の基礎 の章を参照ください）。最初の例では、 delay_cat の列がプロットの x 軸にプロットされ、linelist データセットにあるデフォルトの順序でレベルが表示されます。二つ目の例では、fct_relevel() の内で delay_cat の列を指定してプロット内で順序を変更しています。\n\n# 英数字のデフォルトの順序（ggplot 内での調整なし）\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# ggplot 内で調整された因子レベルの順序\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n注釈：二つ目の例では、デフォルトの x 軸のタイトルが非常に複雑になっていることに注意してください。軸のタイトルは、ggplot2 の labs() 引数で変更することができます。\n\n\n反転\nレベルの順番を逆にしたい場合は、因子を fct_rev() で囲むだけです。\nプロットの凡例のみを反転し、実際の因子レベルは反転させたくない場合は、guides() を使用して反転できます（詳しくは、ggplot の基礎 の章を参照ください）。\n\n\n頻度による順序付け\n列内の値の頻度で並べ替える場合は、fct_infreq() を使用します。欠損値（NA）は、“Missing” などの名付けられたレベルに変換されない限り、自動的に最後に含まれます（欠損値の変換については、本章の このセクション を参照ください）。fct_infreq() を使用したコマンドをさらに fct_rev() で囲むと、順序を反転することができ、頻度が少ない方から表示されます。\n以下に示すように、この関数は ggplot() 内で使用できます。\n\n# 頻度順に並べる\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# 頻度順を反転させる\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n出現順序による順序付け\nfct_inorder() を使用すると、データ内で最初の行からの出現順と一致するようにレベルの順序を設定することができます。fct_inorder() は、arrange() を用いてデータフレーム内のデータを並び替え、その並び替えられた順序を因子の順序とする場合に有効です。\n\n\n別の列の要約統計による順序付け\nfct_reorder() を使用して、列のレベルを他の列の要約統計量で並べ替えることができます。視覚的にも、プロット上でバーやポイントが安定して上昇または下降するような美しいプロットになります。\n以下の例では、x 軸は delay_cat、y 軸は数値列 ct_blood（サイクル閾値）です。ボックスプロットでは、 delay_cat グループごとの CT 値の分布を示しています。グループの CT値 中央値で昇順にボックスプロットを並べ替えます。\n以下の最初の例では、デフォルトの順序である英数字での順序が使用され、ボックスプロットが乱雑に表示されており、特定の順序で表示されていないことがわかります。二つ目の例では、fct_reorder()を使用して delay_cat 列（x 軸にプロットされている）が 1 番目に指定され、次に ct_blood 列が2番目の引数として指定され、最後に “median” が3番目の引数として指定されています（“max”、“mean”、“min” などが使用可能）。二つ目のコマンド実行後、delay_cat のレベルの順序は、各 delay_cat グループの CT 値の中央値によって昇順で並び替えられましたことがわかります（右側のプロット）。NA （欠損値）は名付けられたレベルに変換されない限り、最後に表示されることに注意してください。\n\n# 元の因子レベル順で並べられた箱ひげ図\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by original alpha-numeric levels\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# CT 値の中央値順に並べられた箱ひげ図\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nこの例では、グループ化やそれに伴う計算は、すべて ggplot コマンドの内部で行われているため、ggplot() 呼び出しの前にグループ化する必要がないことに注意してください。\n\n\n「終了」値による順序付け\nグループ化された折れ線グラフには、fct_reorder2() を使用してください。fct_reorder2() は、折れ線グラフの「最後」の値によって因子の順序を並び替えます（凡例も同様に並び替えられます）。 つまり、「最大の x 値に対応する y 値」によって因子の順序が変更され、並べ替えられます。\n例えば、時間の経過に伴う病院ごとの症例数を示す線がある場合、 aes() の color = 引数にfct_reorder2() を適用し、凡例に現れる病院の順序が折れ線グラフの終端の順序と一致するようにすることができます。 詳しくは、こちら のドキュメントをご覧ください。\n\nepidemic_data &lt;- linelist %&gt;%         # linelistデータセットを使用する   \n    filter(date_onset &lt; as.Date(\"2014-09-21\")) %&gt;%    # 見やすくするためのカットオフを指定\n    count(                                            # 週ごとおよび病院ごとの症例数を取得する\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # プロットの作成を開始\n  geom_line(                                        # 折れ線グラフを作る\n    aes(\n      x = epiweek,                                  # x-軸 エピウィーク\n      y = n,                                        # y-軸は1週間あたりの症例数\n      color = fct_reorder2(hospital, epiweek, n)))+ # 病院ごとにグループ化および色付けされたデータ、グラフ終端の高さによる因子順\n  labs(title = \"Factor levels (and legend display) by line height at end of plot\",\n       color = \"Hospital\")                          # 凡例のタイトルを変更する",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#fct_missing",
    "href": "new_pages/factors.jp.html#fct_missing",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.5 欠損値",
    "text": "11.5 欠損値\n因子型の列に欠損値（NA）がある場合は、fct_explicit_na() を使用して “Missing” などの名前付きのレベルに簡単に変換できます。NA 値は、デフォルトで因子のレベルオーダーの最後に “(Missing)” に変換されます。引数 na_level = でレベル名を調整することができます。\n以下では、fct_explicit_na() を delay_cat 列に使用し、NA を “Missing delay”に変換した表を tabyl() で表示しています。\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %&gt;% \n  tabyl(delay_cat)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing\n  delay\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\n     delay_cat    n    percent\n      2-5 days 2040 0.34646739\n       &lt;2 days 2990 0.50781250\n       &gt;5 days  602 0.10224185\n Missing delay  256 0.04347826",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#レベルを結合する",
    "href": "new_pages/factors.jp.html#レベルを結合する",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.6 レベルを結合する",
    "text": "11.6 レベルを結合する\n\n手動で\nfct_recode() を使い、レベルの表示を手動で調整することができます。これは、dplyr パッケージの recode()（データクリーニングと主要関数 の章を参照）に似ていますが、fct_recode() を使用すると新たな因子レベルを作成できます。因子型の列に recode() を使用する場合、新しく因子として作成された値は、あらかじめ許容レベルとして設定されていない限り、拒否されます。\nfct_recode() は、複数のレベルに同じレベルを新たに割り当てることで、複数のレベルを一つのレベルに「結合」することもできます。複数のレベルを一つに結合する際は、元のデータが失われないように注意してください。元のデータを保持するために、既存の列を上書きするのではなく、新しい列を作成して結合の処理を行うことをおすすめします。\nfct_recode() の構文は recode() とは異なります。recode() は OLD = NEW の形式で因子の名前を書きますが、fct_recode() は NEW = OLD で因子名を書きます。\ndelay_cat 列の現在のレベルは次のとおりです。\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\n以下では、構文 fct_recode(column, \"new\" = \"old\", \"new\" = \"old\", \"new\" = \"old\") を使用して新しいレベルを作成します。\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"&lt;2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 2 days 2990 0.50781250     0.5308949\n      2 to 5 days 2040 0.34646739     0.3622159\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\n次に、fct_recode() を使用して、複数のレベルを一つのレベルに結合します。新しいレベル “Less than 5 days” が作成された時にエラーが発生しないことに注意してください。\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"&lt;2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 5 days 5030 0.85427989     0.8931108\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\n\n\n「その他」として縮小\nfct_other() を使用して、因子レベルを「その他（“Other”）」と名付けられたレベルに手動で割り当てることができます。以下では、“Port Hospital” と “Central Hospital” を除く、hospital 列のすべての病院が「その他（“Other”）」にまとめられています。keep = または drop = のいずれかを使用してベクトルで指定できます。other_level = で「その他（“Other”）」レベルの表示を変更できます。\n\nlinelist %&gt;%    \n  mutate(hospital = fct_other(                      # レベルの\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # これらを別々にキープする\n    other_level = \"Other Hospital\")) %&gt;%            # 他のすべては \"Other Hospital\" として \n  tabyl(hospital)                                   # 表を表示\n\n         hospital    n    percent\n Central Hospital  454 0.07710598\n    Port Hospital 1762 0.29925272\n   Other Hospital 3672 0.62364130\n\n\n\n\n頻度が少ないレベルを結合する\nfct_lump() を用いて、最も頻度の低い因子レベルを自動的に結合することができます。\n多数の頻度が低いレベルを「その他（“Other”）」レベルに「ひとまとめ」にするには、以下のいずれかを行います。\n\nn = に独立して保持したいグループの数を指定します。頻度の高い順に n 番目までレベルが保持され、それ以外のレベルは「その他（“Other”）」として一つに結合されます。\n\nprop = に維持したいレベル以上の閾値頻度の割合を指定します。それ以外のレベルは「その他（“Other”）」として一つに結合されます。\n\nother_level = で「その他（“Other”）」レベルの表示を変更できます。 以下では、最も頻度の高い 2 つの病院を除くすべての病院が “Other Hospital” に統合されています。\n\nlinelist %&gt;%    \n  mutate(hospital = fct_lump(                      # レベルの調整\n    hospital,\n    n = 2,                                          # 上位2位のレベルをキープ\n    other_level = \"Other Hospital\")) %&gt;%            # 他は \"Other Hospital\"\n  tabyl(hospital)                                   # 表を表示\n\n       hospital    n   percent\n        Missing 1469 0.2494905\n  Port Hospital 1762 0.2992527\n Other Hospital 2657 0.4512568\n\n\n, warn ## Show all levels\n因子型を使用する利点の一つは、データセットに実際に存在する値に関係なく、プロットの凡例や表の表示形式を標準化することです。\n例えば、多くの図表を作成する場合（複数の管轄区域に対応するためなど）、データの完成度や構成が異なっていても、凡例や表が同じように表示されるようにしたいものです。\n\n\nプロット内で\nggplot() の図では、該当するscale_xxxx() に drop = FALSE の引数を追加するだけです。データ中に存在するかどうかにかかわらず、すべての因子レベルが表示されます。因子型の列のレベルが fill = を使用して表示されている場合、scale_fill_discrete() で drop = FALSE を指定すると、以下のようになります。因子レベルが x = （x 軸に対して） color = または size = で表示されている場合は、それに応じて scale_color_discrete() または scale_size_discrete() で指定します。\n以下の例は、病院ごとの年齢カテゴリの積み上げ棒グラフです。scale_fill_discrete(drop = FALSE) を追加すると、データに存在しない場合でも、すべての年齢グループが凡例に表示されるようになります。\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+            # すべての年齢層を凡例に表示する\n  labs(\n    title = \"All age groups will appear in legend, even if not present in data\")\n\n\n\n\n\n\n\n\n\n\n表で\njanitor の tabyl() や base R の table() では、使用されていない因子レベルを含むすべてのレベルが表示されます。\ndplyr の count() や summarise() を使って表を作成する場合は、引数 .drop = FALSE を追加し、使われていない因子レベルも含めてすべてのレベルのカウントを含めるようにします。\n詳細については、記述統計表の作り方 の章、scale_discrete について説明した こちら のページ、または count() について説明した こちら のページを参照してください。また、接触者の追跡 の章では他の例を紹介しています。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#疫学週",
    "href": "new_pages/factors.jp.html#疫学週",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.7 疫学週",
    "text": "11.7 疫学週\n疫学週作成方法については、データのグループ化 の章で詳しく説明していますので、そちらをご覧ください。また、日付型データ の章では、疫学週の作成方法と書式を紹介していますので、あわせてご覧ください。\n\nプロット内での疫学週\n疫学週を作成してプロットに表示することが目的である場合は、データのグループ化 の章で説明されているように、lubridate パッケージの floor_date() を使用して簡単に行うことができます。その際作成される値は、YYYY-MM-DD 形式の日付型になります。floor_date() で作成された列をプロットで使用する場合は、日付が正しく順序付けられているため、因子レベルの調整や因子型への変換を気にする必要はありません。以下に表示されている、発症日の ggplot() ヒストグラムを参照してください。\nfloor_date() で作成された列をプロットする際は、scale_x_date() を使用して x 軸上の日付の表示形式を調整できます。詳細については、流行曲線（エピカーブ） の章を参照してください。\nscale_x_date() の date_labels = 引数に表示したい形式を、“strptime” 形式で指定ください。日付型データ の章で詳しく説明されていますが、“strptime” 形式では “%” 記号を使用します。また、“％Y” を使用して 4 桁の年を表し、“％W” または “％U” を使用して週番号（それぞれ月曜日または日曜日の週）を表します。\n\nlinelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %&gt;%  # 週の列を作成\n  ggplot()+                                                  # ggplotを開始\n  geom_histogram(mapping = aes(x = epiweek_date))+           # 発症日のヒストグラム\n  scale_x_date(date_labels = \"%Y-W%W\")                       # 日付の表示をYYYY-WWwに調整\n\n\n\n\n\n\n\n\n\n\nデータ内のエピウィーク\nただし、表示形式の変更の目的がプロットではない場合は、次の 2 つの方法のいずれかを使うことができます。\n\n表示形式を細かく調整するには、データフレーム内で lubridate で作成された疫学週の列（YYYY-MM-DD）を希望の表示形式（YYYY-WWw）に変換した後、因子型データに変換します。\n\nまず、base R の format() を使用して、日付表示を YYYY-MM-DD から YYYY-Www 形式に変換します（詳しくは、日付型データ の章を参照ください）。表示形式の変換時に、データ型は文字型に変換されます。次に、factor() を使用して文字型から因子型に変換します。\n\nlinelist &lt;- linelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # 疫学週を作成する（YYYY-MM-DD）\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # （YYYY-WWw）表示に変換\n         epiweek_formatted = factor(epiweek_formatted))       # 因子に変換\n\n# レベルの表示\nlevels(linelist$epiweek_formatted)\n\n [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\"\n [7] \"2014-W19\" \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\"\n[13] \"2014-W25\" \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\"\n[19] \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\" \"2014-W35\" \"2014-W36\"\n[25] \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\" \"2014-W41\" \"2014-W42\"\n[31] \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\" \"2014-W48\"\n[37] \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\"\n[43] \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\"\n[49] \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\"\n[55] \"2015-W15\" \"2015-W16\"\n\n\n警告：“Www-YYYY” や “%W-%Y” など、年より先に週を配置すると、デフォルトの英数字レベルの順序がおかしくなります（例えば、01-2015 は 35-2014 より前になる）。その場合は、順序を手動で調整する必要があり、非常に面倒な作業が必要になります。\n\nデフォルトの表示を高速化するには、aweek パッケージに含まれる date2week() を使用します。week_start = に任意の曜日を指定し、factor = TRUE に設定すると、アウトプットされる列は順序付けられた因子型になります。また、その週に症例がない場合でも、期間内の考えられるすべての週が因子レベルとして含まれます。\n\n\ndf &lt;- linelist %&gt;% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)\n\naweek パッケージの詳細は、日付型データ の章を参照してください。また、date2week() と逆の働きをする week2date() についても触れられています。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.jp.html#参考資料",
    "href": "new_pages/factors.jp.html#参考資料",
    "title": "11  因子（ファクタ）型データ",
    "section": "11.8 参考資料",
    "text": "11.8 参考資料\nR for Data Science の 因子型のページ\naweek パッケージに関する ドキュメント",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>因子（ファクタ）型データ</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.jp.html",
    "href": "new_pages/pivoting.jp.html",
    "title": "12  データの縦横変換",
    "section": "",
    "text": "12.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの縦横変換</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.jp.html#準備",
    "href": "new_pages/pivoting.jp.html#準備",
    "title": "12  データの縦横変換",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについて詳しくは R の基礎 の章をご参照ください。\n\npacman::p_load(\n  rio,          # ファイルをインポートする\n  here,         # ファイルの場所を指定する\n  kableExtra,   # Build and manipulate complex tables\n  tidyverse)    # データ管理と ggplot2 を使用したデータ可視化のパッケージ\n\n\n\nデータのインポート\n\n\nマラリアの症例数のデータ\nこの章では、日ごとのマラリアの症例数について、施設別、年齢層別の架空のデータセットを使用します。お手元の環境でこの章の内容を実行したい方は、ここをクリックしてダウンロードしてください（rds ファイル）。rio パッケージの import() を使用してデータをインポートします（rio パッケージは .xlsx, .csv, .rds など様々な種類のファイルを取り扱うことができます。詳細は、データのインポート・エクスポート の章をご覧ください）。\n\n# データをインポートする\ncount_data &lt;- import(\"malaria_facility_count_data.rds\")\n\n最初の 50 行を以下に表示します。\n\n\n\n\n\n\n\n\n12.1.1 症例データのラインリスト\nこの章の後半では、エボラ出血熱の流行をシミュレーションした症例データセットも使用します。お手元の環境で同じ内容を実行したい方は、ここをクリックして「前処理された」ラインリストをダウンロードしてください（.rds 形式で取得できます）。rio パッケージの import() を使用してデータをインポートします（rio パッケージは .xlsx, .csv, .rds など様々な種類のファイルを取り扱うことができます。詳細は、データのインポート・エクスポート の章をご覧ください）。\n\n# データセットをインポートする\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの縦横変換</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.jp.html#横長から縦長へ",
    "href": "new_pages/pivoting.jp.html#横長から縦長へ",
    "title": "12  データの縦横変換",
    "section": "12.2 横長から縦長へ",
    "text": "12.2 横長から縦長へ\n\n\n\n\n\n\n\n\n\n\n\n12.2.1 「横長」形式\nデータは「横長」形式で入力・保存されることがよくあります。つまり、研究対象者の特性や回答が 1 つの行に保存されるのです。この形式は表示する上では便利かもしれませんが、一部の分析には適していません。\n先述の準備のセクションでインポートした count_data のデータセットを例にとってみましょう。各行が「施設利用日」を表していることがわかります。実際の症例数（1 番右の列）は「横長」形式で格納されており、ある施設利用日のすべての年齢層の情報が 1 行に格納されています。\n\n\n\n\n\n\nこのデータセットのそれぞれの観測値は、 2020-05-16 から 2020-08-12 までのある日付の、 65 施設のうちの 1 施設におけるマラリアの症例数を指しています。これらの施設は、1 つの Province （North）と 4 つのDistrict（Spring、Bolo、Dingo、Barnard）に位置しています。このデータセットでは、マラリアの 総症例数と、3 つの年齢層（4 歳未満、5 ～ 14 歳、15 歳以上）におけるマラリアの症例数が含まれています。\nこのような「横長」のデータは、列見出しが実際には「変数」を表しておらず、仮想的な「年齢層」の値を表しているため、「整然データ」の基準に従っているとは言えません。\nこの形式は、情報を表で表示したり、症例報告書からデータを入力（Excel など）する際に便利です。しかし、解析段階においては、通常、これらのデータは「整然データ」基準に沿った「縦長」形式に変換した方が扱いやすいです。特に R パッケージの ggplot2 は、データが 「縦長」形式である場合に最適に機能します。\nマラリアの総症例数を時系列で視覚化することは、現在のデータ形式でも難しくありません。\n\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)\n\n\n\n\n\n\n\n\nしかし、この総症例数に対する各年齢層の相対的な寄与を表示したいとしたらどうでしょうか。この場合、関心のある変数（年齢層）が単一の列としてデータセットに含まれていることを確認する必要があります。関心のある変数が単一の列であれば、ggplot2 で図の「見栄え」を調整する aes() 引数で指定することができます。\n\n\n\npivot_longer()\ntidyr の関数 pivot_longer() は、データを「長く」します。tidyr は、R パッケージの tidyverse の一部です。\npivot_longer() は、変換する列の範囲（= cols に指定）を受け取ります。したがって、データセットの一部だけを操作することが可能です。ここでは、症例数の列だけをピボットしたいので、この関数は、マラリアのデータに適しています。\nこの処理では、2 つの「新しい」列が作成されます。1 つはカテゴリ（以前の列名）で、もう 1 つは対応する値（例：症例数）で構成されます。これらの新しい列の名前は、初期値のままでも構いませんが、names_to = や values_to = を用いて独自の名前を指定することもできます。\nそれでは、pivot_longer() を実際に使ってみましょう。\n\n\n12.2.2 標準的な縦横変換\ntidyr の pivot_longer() を使用し、「横長」データを 「縦長」 形式に変換していきます。具体的には、マラリアの症例数のデータを表す 4 つの数値列を、年齢層を保持する列と対応する値を保持する列の 2 つの新しい列に変換します。\n\ndf_long &lt;- count_data %&gt;% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n\n新しく作成されたデータフレーム（df_long）は行数が増え（12,152 vs 3,038）、縦に長くなっていることに注目してください。元のデータセットの各行が、df_long では 4 行に別れ、df_long の長さは元のデータセットの 4 倍の長さになっています。4 行に別れた行はそれぞれ、年齢層（4 歳未満、5 ～ 14 歳、15 歳以上、総数）ごとのマラリアの症例数を表しています。\n新しいデータセットは、長くなっただけでなく、列の数が 10 から 8 に減っています。元のデータセットでは 4 つの列（malaria_ で始まる列）に格納されていたデータが、新しいデータセットでは 2 つの列に格納されているためです。\nこれらの 4 つの列の列名はすべて malaria_ で始まるので、便利な “tidyselect” 関数である starts_with() を使用しても同じ結果を得ることができます（これらのヘルパー関数についての詳細は、データクリーニングと主要関数 の章をご参照ください）。\n\n# tidyselectのヘルパー関数で列を指定する\ncount_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid name    value\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    11\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    12\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    23\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    46\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    11\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    10\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…     5\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    26\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     8\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     5\n# ℹ 12,142 more rows\n\n\n位置による指定\n\n# 位置で列を指定する\ncount_data %&gt;% \n  pivot_longer(\n    cols = 6:9\n  )\n\n列名の範囲による指定\n\n# 連続する列の範囲を指定する\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\n\nこの 2 つの新しい列には name と value という初期値の列名が与えられていますが、names_to と values_to という引数を使うことで、これらを上書きして、より意味のある列名を付けることができます。そうしておくと、その列に何の変数が格納されているかを思い出すのに便利です。ここでは、age_group と counts という列名をつけてみましょう。\n\ndf_long &lt;- \n  count_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid age_group    \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;        \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot  \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot  \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n# ℹ 12,142 more rows\n# ℹ 1 more variable: counts &lt;int&gt;\n\n\nこの新しいデータセットを ggplot2 に渡して、新しい列 count を Y 軸に、もう一つの新しい列 age_group を fill = 引数（列の色）に指定することができます。以下のコードを実行すると、マラリアの症例数を年齢層ごとに積み上げた棒グラフが作成されます。\n\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nこの新しいプロットと先ほど作ったプロットを比較してみてください。問題点に気づきましたか？\n調査データを扱うときによくある問題に遭遇しました。malaria_tot 列からの総症例数も含まれているため、プロットの各棒の大きさは、実際の大きさの 2 倍になっています。\nこの問題はいくつかの方法で対処することができます。一つの方法としては、ggplot() に渡す前に、データセットから総症例数を単純に抽出することです。\n\ndf_long %&gt;% \n  filter(age_group != \"malaria_tot\") %&gt;% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nまた、もう一つの方法として、pivot_longer() を実行する際にこの変数（malaria_tot 列）を除くことで、別の変数としてデータセットに保持することも可能です。新しい行を埋めるために、この変数の値がどのように「拡張」されるかを見てみましょう。\n\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # 総症例数の列は含まない\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\n# A tibble: 9,114 × 9\n   location_name data_date  submitted_date Province District malaria_tot newid\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4\n# ℹ 9,104 more rows\n# ℹ 2 more variables: age_group &lt;chr&gt;, counts &lt;int&gt;\n\n\n\n\n12.2.3 複数のデータ型を含むデータのピボット\n上記の例は、「縦長変換する」列がすべて同じデータ型（文字型、数字型、ロジカル型など）である場合にうまく機能します。\nしかし、疫学者や疫学業務担当者が扱う仕事の領域では、非専門家によって作成され、独特で標準的ではない論理に従ったデータを扱う場合が多くあります。Hadley Wickham は、Tidy Data の原則に関する彼の重要な論文で（Tolstoy の一文を参照して）次のように指摘しています。「整然データセットは家族のように、どれも似ているが、乱雑なデータセットは乱雑のあり方がそれぞれ異なっている。」\n特によくある問題は、異なるデータ型のデータを含む列をピボットする必要があることです。このピボットでは、これらの異なるデータ型を 1 つの列に格納することになりますが、これは好ましい状況ではありません。このような混乱を回避するためには様々なアプローチがありますが、pivot_longer() を使用して、自分でこのような状況を作らないようにするための重要なステップがあります。\n3 つの項目 A 、B、C のそれぞれについて、異なる時点で時系列による観測が行われた状況を考えてみましょう。例えば、個人（エボラ出血熱患者の接触者を 21 日間毎日追跡する）や、遠隔地の村の保健所がまだ機能しているかどうか年に 1 回確認することなどが挙げられます。接触者追跡の例を使ってみましょう。データが以下のように保存されているとします。\n\n\n\n\n\n\n見ての通り、少し複雑なデータになっています。各行には 1 つの項目に関する情報が格納されていますが、時間が進むにつれて時系列がどんどん右に流れています。さらに、列のデータ型は日付型と文字型が交互になっています。\n筆者が遭遇した特にひどい例は、コレラの調査データで、4 年間毎日 8 列の新しい観測値が追加されたものでした。筆者のノートパソコンでは、このデータが保存されている Excel ファイルを開くだけで 10 分以上かかりました！\nこのデータを扱うには、データフレームを縦長形式に変換する必要がありますが、各項目の観測ごとに、日付型の列（date 列）と文字型の列（character 列; status を表す列）の分離を維持する必要があります。そうしないと、1 つの列の中に変数の種類が混在してしまう可能性があるからです（データ管理や整然データにおいて、一番「やってはいけないこと」です）。\n\ndf %&gt;% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\")\n  )\n\n# A tibble: 18 × 3\n   id    observation value     \n   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;     \n 1 A     obs1_date   2021-04-23\n 2 A     obs1_status Healthy   \n 3 A     obs2_date   2021-04-24\n 4 A     obs2_status Healthy   \n 5 A     obs3_date   2021-04-25\n 6 A     obs3_status Unwell    \n 7 B     obs1_date   2021-04-23\n 8 B     obs1_status Healthy   \n 9 B     obs2_date   2021-04-24\n10 B     obs2_status Healthy   \n11 B     obs3_date   2021-04-25\n12 B     obs3_status Healthy   \n13 C     obs1_date   2021-04-23\n14 C     obs1_status Missing   \n15 C     obs2_date   2021-04-24\n16 C     obs2_status Healthy   \n17 C     obs3_date   2021-04-25\n18 C     obs3_status Healthy   \n\n\n上記では、ピボットによって日付列と文字列が 1 つの列の value に統合されています。R は列全体を文字型に変換することで対応し、日付の機能は失われています。\nこのような事態を防ぐには、元の列名の構文構造を利用します。このデータセットでは、観測番号、アンダースコア、そして “status” または “date” のいずれかを用いた共通の命名構造があります。この構文を利用して、ピボットした後にこれら 2 つのデータ型を別々の列に保持することが可能です。\nこの操作を行う手順は、以下の通りです。\n\nnames_to = 引数に文字ベクトルを指定し、2 番目の項目に (\".value\") を指定する。この特別な用語は、ピボットした列がその列名に含まれる文字に基づいて分割されることを示します。\nまた、names_sep = の引数には、「分割」する文字を指定する必要があります。ここでは、アンダースコア “_” です。\n\nこのように、新しい列の命名と分割は、既存の列名のアンダースコア “_” を中心に行われる。\n\ndf_long &lt;- \n  df %&gt;% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  \n1 A     obs1        2021-04-23 Healthy\n2 A     obs2        2021-04-24 Healthy\n3 A     obs3        2021-04-25 Unwell \n4 B     obs1        2021-04-23 Healthy\n5 B     obs2        2021-04-24 Healthy\n6 B     obs3        2021-04-25 Healthy\n7 C     obs1        2021-04-23 Missing\n8 C     obs2        2021-04-24 Healthy\n9 C     obs3        2021-04-25 Healthy\n\n\n仕上げに\ndate 列は現在文字型であることに注意してください。日付型データ の章で説明した mutate() と as_date() 関数を使用すると、適切な日付型に簡単に変換できます。\nまた、stringr パッケージの str_remove_all() を使用し、“obs” を削除して数値形式に変換することで、 observation 列も数字型（numeric）に変換できます（詳しくは、文字型データ の章をご参照ください）。\n\ndf_long &lt;- \n  df_long %&gt;% \n  mutate(\n    date = date %&gt;% lubridate::as_date(),\n    observation = \n      observation %&gt;% \n      str_remove_all(\"obs\") %&gt;% \n      as.numeric()\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;  \n1 A               1 2021-04-23 Healthy\n2 A               2 2021-04-24 Healthy\n3 A               3 2021-04-25 Unwell \n4 B               1 2021-04-23 Healthy\n5 B               2 2021-04-24 Healthy\n6 B               3 2021-04-25 Healthy\n7 C               1 2021-04-23 Missing\n8 C               2 2021-04-24 Healthy\n9 C               3 2021-04-25 Healthy\n\n\nそして、この形式のデータを用いることにより、例えば、記述的なヒートマップをプロットするなどの作業を始めることができます。\n\nggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\" = \"red\", \n        \"Missing\" = \"orange\")\n  )",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの縦横変換</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.jp.html#縦長から横長へ",
    "href": "new_pages/pivoting.jp.html#縦長から横長へ",
    "title": "12  データの縦横変換",
    "section": "12.3 縦長から横長へ",
    "text": "12.3 縦長から横長へ\n\n\n\n\n\n\n\n\n\n場合によっては、データセットを横長形式に変換したいことがあります。このような場合は、pivot_wider() 関数を使用します。\n典型的な使用例としては、分析結果を読み手にとって理解しやすい形式（見やすい表の作り方 の章を参照）に変換する場合です。つまり、1 つの主題に関する情報が複数の行にまたがっているデータセットを、その情報が 1 つの行に格納される形式に変換することが必要な場合です。\n\nデータ\nこの章では、1 つの症例が1 行に含まれる症例ラインリスト（準備 のセクションを参照）を使用することにします。\n以下に、最初の 50 行を示します。\n\n\n\n\n\n\n例えば、性別で年齢層ごとの個体数を知りたいとします。\n\ndf_wide &lt;- \n  linelist %&gt;% \n  count(age_cat, gender)\n\ndf_wide\n\n   age_cat gender   n\n1      0-4      f 640\n2      0-4      m 416\n3      0-4   &lt;NA&gt;  39\n4      5-9      f 641\n5      5-9      m 412\n6      5-9   &lt;NA&gt;  42\n7    10-14      f 518\n8    10-14      m 383\n9    10-14   &lt;NA&gt;  40\n10   15-19      f 359\n11   15-19      m 364\n12   15-19   &lt;NA&gt;  20\n13   20-29      f 468\n14   20-29      m 575\n15   20-29   &lt;NA&gt;  30\n16   30-49      f 179\n17   30-49      m 557\n18   30-49   &lt;NA&gt;  18\n19   50-69      f   2\n20   50-69      m  91\n21   50-69   &lt;NA&gt;   2\n22     70+      m   5\n23     70+   &lt;NA&gt;   1\n24    &lt;NA&gt;   &lt;NA&gt;  86\n\n\nこれは縦長のデータセットで、ggplot2 での視覚化には最適ですが、表での表示には適していません。\n\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))\n\n\n\n\n\n\n\n\n\n\npivot_wider()\nそのため、pivot_wider() を使用し、データを報告書に表として載せるのに適した形式に変換していきます。\n引数 names_from は、新しい列名を生成するための列を指定し、引数 values_from は、セルに入力する値を取得するための列を指定します。id_cols = はオプションですが、ピボット化されるべきでない列名のベクトルを提供することができ、これによって各行を識別することができます。\n\ntable_wide &lt;- \n  df_wide %&gt;% \n  pivot_wider(\n    id_cols = age_cat,\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide\n\n# A tibble: 9 × 4\n  age_cat     f     m  `NA`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 0-4       640   416    39\n2 5-9       641   412    42\n3 10-14     518   383    40\n4 15-19     359   364    20\n5 20-29     468   575    30\n6 30-49     179   557    18\n7 50-69       2    91     2\n8 70+        NA     5     1\n9 &lt;NA&gt;       NA    NA    86\n\n\nこの表は、より読みやすいので、報告書に掲載するのに適しています。さらに、flextable や knitr などのパッケージを使うと、よりきれいな表に編集することができます。編集する方法は、見やすい表の作り方 の章で詳しく説明されています。\n\ntable_wide %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% # 行と列の合計を表示する\n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 10, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nage_cat\nf\nm\nNA\nTotal\n\n\n\n\n0-4\n640\n416\n39\n1095\n\n\n5-9\n641\n412\n42\n1095\n\n\n10-14\n518\n383\n40\n941\n\n\n15-19\n359\n364\n20\n743\n\n\n20-29\n468\n575\n30\n1073\n\n\n30-49\n179\n557\n18\n754\n\n\n50-69\n2\n91\n2\n95\n\n\n70+\nNA\n5\n1\n6\n\n\nNA\nNA\nNA\n86\n86\n\n\nTotal\n2807\n2803\n278\n5888",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの縦横変換</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.jp.html#欠損値の穴埋め",
    "href": "new_pages/pivoting.jp.html#欠損値の穴埋め",
    "title": "12  データの縦横変換",
    "section": "12.4 欠損値の穴埋め",
    "text": "12.4 欠損値の穴埋め\npivot の後、そしてより一般的には bind の後、いくつかのセルに空白ができてしまい、それを埋めたいと思うことがあります。 \n\nデータ\n例えば、2 つのデータセットがあり、それぞれ測定番号、施設名、その時点の症例数の観測値があるとします。しかし、2 番目のデータセットには、最初のデータセットには含まれていない変数 Year が含まれています。\n\ndf1 &lt;- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 \n\n# A tibble: 9 × 3\n  Measurement Facility Cases\n        &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1           1 Hosp 1      66\n2           2 Hosp 1      26\n3           3 Hosp 1       8\n4           1 Hosp 2      71\n5           2 Hosp 2      62\n6           3 Hosp 2      70\n7           1 Hosp 3      47\n8           2 Hosp 3      70\n9           3 Hosp 3      38\n\ndf2 &lt;- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2\n\n# A tibble: 3 × 4\n   Year Measurement Facility Cases\n  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1  2000           1 Hosp 4      82\n2  2001           2 Hosp 4      87\n3  2002           3 Hosp 4      46\n\n\nbind_rows() でこの 2 つのデータセットを結合すると、最初のデータセットに作成された Year 変数は、NA で埋められます。\n\ndf_combined &lt;- \n  bind_rows(df1, df2) %&gt;% \n  arrange(Measurement, Facility)\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66    NA\n 2           1 Hosp 2      71    NA\n 3           1 Hosp 3      47    NA\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26    NA\n 6           2 Hosp 2      62    NA\n 7           2 Hosp 3      70    NA\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8    NA\n10           3 Hosp 2      70    NA\n11           3 Hosp 3      38    NA\n12           3 Hosp 4      46  2002\n\n\n\n\n\nfill()\nYear は特に時間的な傾向を調べるのに有効な変数であるため、NA を埋めたいとしましょう。この場合、fill() を使用し、埋める列と方向（この場合は上 “up”）を指定することで、空白のセルを埋めることができます。\n\ndf_combined %&gt;% \n  fill(Year, .direction = \"up\")\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66  2000\n 2           1 Hosp 2      71  2000\n 3           1 Hosp 3      47  2000\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26  2001\n 6           2 Hosp 2      62  2001\n 7           2 Hosp 3      70  2001\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8  2002\n10           3 Hosp 2      70  2002\n11           3 Hosp 3      38  2002\n12           3 Hosp 4      46  2002\n\n\nあるいは、下方向に埋めるため、データを並べ替えることもできます。\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  arrange(Measurement, desc(Facility))\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47    NA\n 3           1 Hosp 2      71    NA\n 4           1 Hosp 1      66    NA\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70    NA\n 7           2 Hosp 2      62    NA\n 8           2 Hosp 1      26    NA\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38    NA\n11           3 Hosp 2      70    NA\n12           3 Hosp 1       8    NA\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  fill(Year, .direction = \"down\")\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47  2000\n 3           1 Hosp 2      71  2000\n 4           1 Hosp 1      66  2000\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70  2001\n 7           2 Hosp 2      62  2001\n 8           2 Hosp 1      26  2001\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38  2002\n11           3 Hosp 2      70  2002\n12           3 Hosp 1       8  2002\n\n\nこれで、図を作成するのに便利なデータセットができました。\n\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\n\n\n\n\n\n\n\n\nしかし、報告書に表として掲載するには向いていないデータセットですので、この縦長形式で整頓されていないデータフレームを、横長形式で整頓されたデータフレームに変換する練習をしてみましょう。\n\ndf_combined %&gt;% \n  pivot_wider(\n    id_cols = c(Measurement, Facility),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  arrange(Facility) %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% \n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 5, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\nTotal\n\n\n\n\n1\nHosp 1\n66\nNA\nNA\n66\n\n\n2\nHosp 1\nNA\n26\nNA\n26\n\n\n3\nHosp 1\nNA\nNA\n8\n8\n\n\n1\nHosp 2\n71\nNA\nNA\n71\n\n\n2\nHosp 2\nNA\n62\nNA\n62\n\n\n3\nHosp 2\nNA\nNA\n70\n70\n\n\n1\nHosp 3\n47\nNA\nNA\n47\n\n\n2\nHosp 3\nNA\n70\nNA\n70\n\n\n3\nHosp 3\nNA\nNA\n38\n38\n\n\n1\nHosp 4\n82\nNA\nNA\n82\n\n\n2\nHosp 4\nNA\n87\nNA\n87\n\n\n3\nHosp 4\nNA\nNA\n46\n46\n\n\nTotal\n-\n266\n245\n162\n673\n\n\n\n\n\n\n\n\nこの場合、変数 Measurement を追加すると表の作成に支障が出るため、Facility 、Year 、Cases の 3 つの変数のみを含めるように指定する必要があります。\n\ndf_combined %&gt;% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  knitr::kable()\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\n\n\n\n\n1\nHosp 4\n82\nNA\nNA\n\n\n1\nHosp 3\n47\nNA\nNA\n\n\n1\nHosp 2\n71\nNA\nNA\n\n\n1\nHosp 1\n66\nNA\nNA\n\n\n2\nHosp 4\nNA\n87\nNA\n\n\n2\nHosp 3\nNA\n70\nNA\n\n\n2\nHosp 2\nNA\n62\nNA\n\n\n2\nHosp 1\nNA\n26\nNA\n\n\n3\nHosp 4\nNA\nNA\n46\n\n\n3\nHosp 3\nNA\nNA\n38\n\n\n3\nHosp 2\nNA\nNA\n70\n\n\n3\nHosp 1\nNA\nNA\n8",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの縦横変換</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.jp.html#参考資料",
    "href": "new_pages/pivoting.jp.html#参考資料",
    "title": "12  データの縦横変換",
    "section": "12.5 参考資料",
    "text": "12.5 参考資料\n便利な チュートリアル はこちら",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>データの縦横変換</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html",
    "href": "new_pages/grouping.jp.html",
    "title": "13  データのグループ化",
    "section": "",
    "text": "13.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#準備",
    "href": "new_pages/grouping.jp.html#準備",
    "title": "13  データのグループ化",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R パッケージの詳細については、 R の基礎 の章を参照してください。\n\npacman::p_load(\n  rio,       # データの読み込み\n  here,      # ファイルをみつける\n  tidyverse, # データのクリーニング、処理、プロット (dplyr を含む)\n  janitor)   # 列と行の合計を追加する\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、こちら をクリックして「前処理された」ラインリスト（linelist）をダウンロードしてください（.rds 形式で取得できます）。 データは rio パッケージの import() を利用してインポートしましょう。データをインポートする様々な方法については、データのインポート・エクスポート の章を参照してください。\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n以下に、linelist の最初の 50 行を表示します。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化",
    "href": "new_pages/grouping.jp.html#グループ化",
    "title": "13  データのグループ化",
    "section": "13.2 グループ化",
    "text": "13.2 グループ化\ndplyr の group_by() は、指定された列の値によって、行をグループ化する関数です。複数の列が指定されている場合は、列の値の組み合わせによって、行がグループ化されます。それぞれの一意の値（または値の組み合わせ）でグループが構成されます。データセットがグループ化された後は、データセットの変更や計算は各グループ内で実行されます。\nたとえば、次のコマンドは linelist を outcome 列の値で行をグループ化し、出力結果を新しいデータフレーム ll_by_outcome として保存します。グループ化する列は group_by() の括弧内に書きます。\n\nll_by_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\ngroup_by() を実行した後も、データセットには目に見える変化がないことに注意してください。 「グループ化された」データフレームに mutate()、 summarise()、 arrange() などの別の dplyr 関数を適用するまで、目に見える変化はありません。\nただし、データフレームを print() で出力すると、グループ化を「見る」ことができます。出力されたデータフレームを確認すると、それが tibble 型のオブジェクト に変換されていることがわかります。また、グループ化に使用された列名ならびにグループの数がヘッダー行のすぐ上に表示されています。\n\n# 表示して、適用されたグループ化を確認\nll_by_outcome\n\n# A tibble: 5,888 × 30\n# Groups:   outcome [3]\n   case_id generation date_infection date_onset date_hospitalisation\n   &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;              \n 1 5fe599           4 2014-05-08     2014-05-13 2014-05-15          \n 2 8689b7           4 NA             2014-05-13 2014-05-14          \n 3 11f8ea           2 NA             2014-05-16 2014-05-18          \n 4 b8812a           3 2014-05-04     2014-05-18 2014-05-20          \n 5 893f25           3 2014-05-18     2014-05-21 2014-05-22          \n 6 be99c8           3 2014-05-03     2014-05-22 2014-05-23          \n 7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29          \n 8 369449           4 2014-05-28     2014-06-02 2014-06-03          \n 9 f393b4           4 NA             2014-06-05 2014-06-06          \n10 1389ca           4 NA             2014-06-05 2014-06-07          \n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_outcome &lt;date&gt;, outcome &lt;chr&gt;, gender &lt;chr&gt;,\n#   age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;,\n#   hospital &lt;chr&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;,\n#   wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;,\n#   cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;,\n#   bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n一意のグループ\n複数の列を使用してデータをグループ化する場合、グループ化に使用された列の値の一意の組み合わせによって各グループが作成されます。\n作成された各グループと各グループに含まれる行数を確認する場合は、グループ化されたデータを tally() に渡します。各グループに含まれる行数を表示せずに一意のグループだけを表示したい場合は、group_keys() に渡します。\n下の例では、グループ化に使用された列 outcome の結果には、「Death」、「Recover」、NA の 3 つの一意の値があります。2582 行の deaths, 1983 行の recover, 1323 行の NA（outcome の記録なし）があることがわかります。\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally()\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\n複数の列でグループ化することもできます。下の例では、データフレームが outcome 列と gender 列の組み合わせごとにグループ化され、集計されています。 outcome 列と gender 列の一意の組み合わせが、いずれかの列の欠損値も含めて、独自のグループとして作成されていることに注意してください。\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally()\n\n# A tibble: 9 × 3\n# Groups:   outcome [3]\n  outcome gender     n\n  &lt;chr&gt;   &lt;chr&gt;  &lt;int&gt;\n1 Death   f       1227\n2 Death   m       1228\n3 Death   &lt;NA&gt;     127\n4 Recover f        953\n5 Recover m        950\n6 Recover &lt;NA&gt;      80\n7 &lt;NA&gt;    f        627\n8 &lt;NA&gt;    m        625\n9 &lt;NA&gt;    &lt;NA&gt;      71\n\n\n\n\n新しい列\nグループ化に使用する列を、group_by() のコード内で新しく作成することもできます。これは、 group_by() を実行する前に mutate() を呼び出すのと同じです。このスタイルは簡素な集計作業には便利ですが、コードをわかりやすくするために mutate() で先に新しい列を作成してから、group_by() にパイプすることをおすすめします。\n\n#  group_by() コマンド内で作成されたバイナリ変数（列）によってグループ化する\nlinelist %&gt;% \n  group_by(\n    age_class = ifelse(age &gt;= 18, \"adult\", \"child\")) %&gt;% \n  tally(sort = T)\n\n# A tibble: 3 × 2\n  age_class     n\n  &lt;chr&gt;     &lt;int&gt;\n1 child      3618\n2 adult      2184\n3 &lt;NA&gt;         86\n\n\n\n\nグループ化した列の追加・削除\nデフォルトでは、すでにグループ化されているデータに対して group_by() を実行すると、古いグループが削除され、新しく作成されたグループが適用されます。すでに作成されたグループに新しいグループを追加したい場合は、引数に .add = TRUE を含めてください。\n\n# outcome毎にグループ化\nby_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\n# さらに性別によるグループ化を追加\nby_outcome_gender &lt;- by_outcome %&gt;% \n  group_by(gender, .add = TRUE)\n\nすべてのグループの保持\n因子型（factor）の列でデータをグループ化すると、現時点でデータに存在していない因子（factor）のレベルが存在する可能性があります。このような列でグループ化すると、デフォルトでは、存在しないレベルは削除され、グループとして含まれません。すべてのレベルが（データに存在しない場合でも）グループとして表示されるように変更したい場合は、group_by() コマンドで .drop = FALSE と設定します。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化の解除",
    "href": "new_pages/grouping.jp.html#グループ化の解除",
    "title": "13  データのグループ化",
    "section": "グループ化の解除",
    "text": "グループ化の解除\nグループ化されたデータは ungroup() でグループ化が解除されるまで、グループ化されたままになります。グループ化を解除せずに計算を行うと、期待通りの結果にならない可能性があります！\n以下は、すべてのグループを解除する例です。\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nungroup() 内に列名を書くと、特定の列のみのグループ化を解除することもできます。\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup(gender) # gender によるグループ化を解除し、outcome によるグループ化は残す\n\n注： count() は、カウントを行った後にデータのグループ化を自動的に解除します。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#group_summarise",
    "href": "new_pages/grouping.jp.html#group_summarise",
    "title": "13  データのグループ化",
    "section": "13.3 グループ化したデータの要約",
    "text": "13.3 グループ化したデータの要約\nsummarise() を使用して要約統計量の表を作成する方法の詳細については、記述統計表の作り方 の章の dplyr セクションを参照してください。ここでは、summarise() をグループ化されたデータに適用したときに、summarise() の動作がどのように変化するかについて簡単に説明します。\ndplyr パッケージに含まれている summarise() （または summarize()）は、データフレームを受け取り、あなたが定義した要約統計量を含む、新しい要約データフレームに変換します。グループ化されていないデータフレームでは、サマリー統計量はデータフレーム内のすべての行から計算されます。summarise() がグループ化されたデータに適用されると、各グループの要約統計量が生成されます。\n以下に示すように、通常、summarise() の構文は、新しく作成される要約列の名前、等号（=）、そしてデータに適用する統計関数（例えば min()、 max()、 median()、 sd() など）を指定します。統計関数の中に、操作する列と関連する引数を書きます（例：na.rm = TRUE）。 sum() を使用して、指定する論理条件を満たす行の数を数えることもできます（== を使用します）。\n以下は、グループ化されていないデータセットに適用された summarise() の例です。データセット全体から計算された結果が返されます。\n\n# グループ化されていないラインリストの要約統計量\nlinelist %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))\n\n  n_cases mean_age max_age min_age n_males\n1    5888 16.01831      84       0    2803\n\n\n対照的に、以下はグループ化されたデータに適用される同じ summarise() を使用したコマンドです。統計は outcome グループごとに計算されます。グループ化された列が新しいデータフレームにどのように引き継がれるかに注意してください。\n\n# グループ化されてたラインリストの要約統計量\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))\n\n# A tibble: 3 × 6\n  outcome n_cases mean_age max_age min_age n_males\n  &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;\n1 Death      2582     15.9      76       0    1228\n2 Recover    1983     16.1      84       0     950\n3 &lt;NA&gt;       1323     16.2      69       0     625\n\n\nヒント： summarise 関数は、イギリス英語とアメリカ英語のどちらの綴りで書いても機能します。summarise() と summarize()は同じ関数を呼び出します。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化したデータの集計",
    "href": "new_pages/grouping.jp.html#グループ化したデータの集計",
    "title": "13  データのグループ化",
    "section": "13.4 グループ化したデータの集計",
    "text": "13.4 グループ化したデータの集計\ncount() と tally() は同じような処理を行いますが、異なる関数です。count() と tally() の違いに関する詳細は、こちら をご覧ください。\n\ntally()\ntally() は summarise(n = n()) の省略形であり、データをグループ化しません。グループ化された集計を行うには、 group_by() コマンドの後に書く必要があります。 sort = TRUE を追加すると、最大のグループが一番上に表示されます。\n\nlinelist %&gt;% \n  tally()\n\n     n\n1 5888\n\n\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally(sort = TRUE)\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\n\n\ncount()\n対照的に count() は以下を行います。\n\n指定された列に group_by() を適用する\n\nsummarise() を適用し、各グループに含まれている行数である n 列を返す\n\nungroup() を適用する\n\n\nlinelist %&gt;% \n  count(outcome)\n\n  outcome    n\n1   Death 2582\n2 Recover 1983\n3    &lt;NA&gt; 1323\n\n\ngroup_by() と同様に、count() コマンド内で新しい列を作成できます。\n\nlinelist %&gt;% \n  count(age_class = ifelse(age &gt;= 18, \"adult\", \"child\"), sort = T)\n\n  age_class    n\n1     child 3618\n2     adult 2184\n3      &lt;NA&gt;   86\n\n\ncount() は「ロールアップ」機能を使用して複数回呼び出すことができます。例えば、病院の数を性別ごとに計算したい場合は、次のように行います。わかりやすくするために、（name  = を使って）最後の列の名前がデフォルトの「n」から変更されていることに注意してください。\n\nlinelist %&gt;% \n  # 一意なoutcome - genderグループをカウントします\n  count(gender, hospital) %&gt;% \n  # 性別ごとに行を集計し（3）、性別ごとに病院の数を数えます（6）\n  count(gender, name = \"hospitals per gender\" ) \n\n  gender hospitals per gender\n1      f                    6\n2      m                    6\n3   &lt;NA&gt;                    6\n\n\n\n\n総数を追加する\ncount() と summarise() とは対照的に、add_count() を使用すると、データフレーム内の他のすべての列を保持しつつ、グループごとの行数を含む新しい列 n を追加できます。\n各グループに含まれる行数が新しい列 n に出力され、それぞれグループの各行に表示されます。出力結果を確認するため、この新しい列 n 列を追加した後、見やすくなるように列を並べ替えます。他の例については、本章後半の グループ化したデータを変換する のセクションを参照してください。\n\nlinelist %&gt;% \n  as_tibble() %&gt;%                   # 出力が綺麗になるようにtibbleに変換\n  add_count(hospital) %&gt;%           # 病院ごとのカウント列n を追加\n  select(hospital, n, everything()) # デモ目的に列を並び替え\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\n合計を追加する\ntally() か count() を使用した後、合計行または列の合計を簡単に追加するには、記述統計表の作り方 の章の janitor セクションを参照してください。janitor パッケージは、adorn_totals() や adorn_percentages() のような、合計を追加してパーセンテージを表示する関数を提供します。以下は簡単な例です。\n\nlinelist %&gt;%                                  # 症例のラインリスト\n  tabyl(age_cat, gender) %&gt;%                  # 2 つの列の数をクロス集計\n  adorn_totals(where = \"row\") %&gt;%             # 合計行を追加\n  adorn_percentages(denominator = \"col\") %&gt;%  # 列の分母を使用して比率に変換\n  adorn_pct_formatting() %&gt;%                  # 比率をパーセントに変換\n  adorn_ns(position = \"front\") %&gt;%            # 「数（パーセント）」と表示\n  adorn_title(                                # タイトルを調整\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\nより複雑な合計行、たとえば合計以外の要約統計量を含む行を新しく追加したい場合は、 記述統計表の作り方の章のこちらのセクション をご覧ください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#日付によるグループ化",
    "href": "new_pages/grouping.jp.html#日付によるグループ化",
    "title": "13  データのグループ化",
    "section": "13.5 日付によるグループ化",
    "text": "13.5 日付によるグループ化\nデータを日付でグループ化する場合は、対象の日付単位（たとえば「日」、「疫学週」、「月」など）の列が必要です。（なければ作成する必要があります）。この列は 日付型データ の章の 疫学週のセクション で説明されているように、lubridate の floor_date() を使用して作成することもできます。 この列を作成後、dplyr の count() を使用し、これらの一意の日付で行をグループ化し、カウントすることができます。\n日付の処理に共通して、よく必要となる追加手順は、データに存在しない日付を追加して埋めることです。そのような場合は、tidyr の complete() を使用すると、集計された日付系列の、範囲内のすべての日付単位に関して、日付が完全にそろいます。この手順がないと、症例が報告されていない 週はデータに表示されないかもしれません！\ncomplete() 内で、日付列を最小から最大までの一連の日付 seq.Date()として再定義することで、日付列の値が拡張・展開されます。デフォルトでは、新しく「展開された」行の症例数のカウント値は NA になります。NA ではなく 0 と表示したい場合は、complete() の引数 fill = にカウント値の列名をリスト形式で指定します（新しく作成された症例数のカウント列の名前が n であれば fill = list(n = 0) と書きます）。詳細については ?complete を、使用例をご覧になりたい方は、日付型データの章の 日付の操作のセクション を参照してください。\n\nラインリストの症例を日でグループ化\nこちらは complete() を使用せずに、症例を日数でグループ化する例です。以下の例では、最初の行で症例のない日をスキップすることに注意してください。\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%        # date_onset の値がないものを削除する\n  count(date_onset)              # 一意な日付ごとの行数をカウントする\n\n\n\n\n\n\n\n下の例では complete() コマンドを追加して、範囲内のすべての日が確実に表示されるようにしました。\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%                 # date_onset 列の値がないものを削除する\n  count(date_onset) %&gt;%                   # 一意な日付ごとの行数をカウントする\n  complete(                               # 症例がない日もすべて表示する\n    date_onset = seq.Date(                # 列を日付シーケンスとして再定義する\n      from = min(date_onset, na.rm=T), \n      to = max(date_onset, na.rm=T),\n      by = \"day\"),\n    fill = list(n = 0))  # 新しく行を追加して列 n に（デフォルトの NAの代わりに）0 を表示する\n\n\n\n\n\n\n\n\n\nラインリストの症例を週でグループ化\n同じ原則でデータを週でもグループ化することができます。最初に「症例が発症した週」という新しい列を floor_date() の unit = \"week\" を使って作成します。 次に前述のように count() を使って週毎の症例数を集計します。最後に complete() で症例がない週もすべて表示されるようにします。\n\n# 週毎の症例数のデータセットを作る\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%                 # date_onset 列の値がないものを削除します\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %&gt;%  # 発症した週という新しい列\n  count(week) %&gt;%                         # データを週毎にグループ化し、グループごとに行をカウントします。\n  complete(                               # ケースがない場合でも、すべての日が表示されるようにします\n    week = seq.Date(                      # 列を日付シーケンスとして再定義します\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))                   # 新しく行を追加して列 n に（デフォルトの NA の代わりに）0 を表示します\n\nデータフレームの最初の 50 行を以下に表示します。\n\n\n\n\n\n\n\n\nラインリストの症例を月でグループ化\n症例を月毎に集約するには、lubridate パッケージの floor_date() を使用しますが、引数は unit = \"months\" です。 これにより、各日付はその月の 1 日に切り捨て・切り上げられます。出力結果は、Date 型になります。 complete() でも by = \"months\" と指定することに注意してください。\n\n# 月毎の症例数のデータセットを作る\nmonthly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %&gt;%  # 新しい列、発症月の 1 日\n  count(month) %&gt;%                          # 月ごとの症例数をカウント\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # 症例が報告されていない月も含めてすべての月を組み込む\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))\n\n\n\n\n\n\n\n\n\n日毎の集計数を週毎に\n日毎の集計を週毎に集約するには、上記のように floor_date() を使用します。ただし、 count() の代わりに group_by() と summarize() を使用します。週あたりの行数をカウントするだけでなく、日毎の症例数を sum() する必要があるためです。\n\n\n日毎の集計を月毎に\n日毎の集計を月毎に集約するには、上記のように floor_date() と unit = \"month\" を使用します。ただし、 count() の代わりに group_by() と summarize() を使用します。月毎の行数をカウントするだけでなく、日毎の症例数を sum() する必要があるためです。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化したデータの並び替え",
    "href": "new_pages/grouping.jp.html#グループ化したデータの並び替え",
    "title": "13  データのグループ化",
    "section": "13.6 グループ化したデータの並び替え",
    "text": "13.6 グループ化したデータの並び替え\ndplyr の arrange() を使用してデータフレーム内の行を並べ替えると、引数に .by_group = TRUE を設定しない限り、データがグループ化されたときに同じように動作します。この場合、行はまずグループ化に適用された列、次に arrange() に指定した列の順番で並び替えられます。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化したデータのフィルタリング",
    "href": "new_pages/grouping.jp.html#グループ化したデータのフィルタリング",
    "title": "13  データのグループ化",
    "section": "13.7 グループ化したデータのフィルタリング",
    "text": "13.7 グループ化したデータのフィルタリング\n\nfilter()\nデータフレームを評価する関数（ max(), min(), mean() など）と組み合わせて filter() を適用すると、これらの関数が各グループに適用されます。たとえば、フィルタリングによって患者が年齢の中央値を超えている行のみを保持する場合、グループごとにフィルタリングが適用され、各グループの年齢の中央値を超える行が保持されます。\n\n\nグループごとにスライスする\nデータ内の位置に基づいて行をフィルタリングする dplyr の slice() も、グループごとに適用できます。期待通りにデータを「スライス」するためためには、各グループ内のデータを並べ替えることを忘れないでください。\n例えば、各病院で一番最近入院した 5 つの症例を取得したい場合は、次のように行います。\n\nhospital 列でラインリストをグループ化する\n\n各病院グループ内で date_hospitalisation 列を最新の日付から古い日付へ降順で並べ替える\n\nスライスして各病院から最初の 5 行を抽出する\n\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  arrange(hospital, date_hospitalisation) %&gt;%\n  slice_head(n = 5) %&gt;% \n  arrange(hospital) %&gt;%                            # 表示用\n  select(case_id, hospital, date_hospitalisation)  # 表示用\n\n# A tibble: 30 × 3\n# Groups:   hospital [6]\n   case_id hospital          date_hospitalisation\n   &lt;chr&gt;   &lt;chr&gt;             &lt;date&gt;              \n 1 20b688  Central Hospital  2014-05-06          \n 2 d58402  Central Hospital  2014-05-10          \n 3 b8f2fd  Central Hospital  2014-05-13          \n 4 acf422  Central Hospital  2014-05-28          \n 5 275cc7  Central Hospital  2014-05-28          \n 6 d1fafd  Military Hospital 2014-04-17          \n 7 974bc1  Military Hospital 2014-05-13          \n 8 6a9004  Military Hospital 2014-05-13          \n 9 09e386  Military Hospital 2014-05-14          \n10 865581  Military Hospital 2014-05-15          \n# ℹ 20 more rows\n\n\nslice_head() - 上から n 行を選択する\nslice_tail() - 最後から n 行を選択する\nslice_sample() - n 行をランダムに選択する\nslice_min() - order_by = 列で最も高い値を持つ n 行を選択する（with_ties = TRUE を使用すると同点を保持する）\nslice_max() - order_by = 列で最も低い値を持つ n 行を選択する（with_ties = TRUE を使用すると同点を保持する）\nslice() の他の例と詳細をご覧になりたい方は、重複データの排除 を参照ください。\n\n\nグループの大きさでフィルタリングする\nadd_count() は、元のデータに列 n を追加し、括弧内で指定した行のグループごとの行数を計算する関数です。\n以下の例では、add_count() が hospital 列に適用され、新しい列 n の各行の値は、その行の病院の総症例数となります。n 列の値がどのように繰り返されるているかに注意してください。以下の例の列名 n は、 add_count() 内の name = を使用して変更できます。結果をわかりやすく表示するため、 select() を使用して列を並べ替えています。\n\nlinelist %&gt;% \n  as_tibble() %&gt;% \n  add_count(hospital) %&gt;%          # 「この行と同じ病院に入院した行数」を追加する\n  select(hospital, n, everything())\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\nこうすれば「小さな」病院、たとえば 500 人未満の患者が入院した病院、に入院した症例列を簡単にフィルタリングできるようになります。\n\nlinelist %&gt;% \n  add_count(hospital) %&gt;% \n  filter(n &lt; 500)",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化したデータを変換する",
    "href": "new_pages/grouping.jp.html#グループ化したデータを変換する",
    "title": "13  データのグループ化",
    "section": "13.8 グループ化したデータを変換する",
    "text": "13.8 グループ化したデータを変換する\nすべての列と（要約ではない）行を保持したまま、グループ統計を含む新しい列を追加するには summarise() ではなく、 group_by() の後に mutate() を使用します。\nこれは、他のすべての列を残したまま、グループ統計を算出するときに便利です。例えば、ある行の値をその行を含むグループの値と比較する計算などです。\n以下の例では、ある症例（行）の入院までに所要した日数（入院の遅れ）と、病院全体の入院までに所要した日数の平均値との差を計算します。 手順は次のとおりです。\n\nデータを病院ごとにグループ化する\n\ndays_onset_hosp 列を使って、病院全体の遅れの平均を含む新しい列を作成する\n\n2 つの列の差を計算する\n\n結果をわかりやすく表示するために、表示する列のみを select() で選択しています。\n\nlinelist %&gt;% \n  # 病院ごとのグループデータ（ラインリストへの変更はまだ保存されていない）\n  group_by(hospital) %&gt;% \n  \n  # 新しい列\n  mutate(\n    # 病院ごとの入院までの平均日数（小数点第1位を四捨五入）\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # 各行の遅延と病院の平均遅延の差（小数点以下第1位を四捨五入）\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %&gt;%\n  \n  # 特定の行のみを選択 - 表示の目的で\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)\n\n# A tibble: 5,888 × 5\n# Groups:   hospital [6]\n   case_id hospital              days_onset_hosp group_delay_admit diff_to_group\n   &lt;chr&gt;   &lt;chr&gt;                           &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 5fe599  Other                               2               2             0  \n 2 8689b7  Missing                             1               2.1          -1.1\n 3 11f8ea  St. Mark's Maternity…               2               2.1          -0.1\n 4 b8812a  Port Hospital                       2               2.1          -0.1\n 5 893f25  Military Hospital                   1               2.1          -1.1\n 6 be99c8  Port Hospital                       1               2.1          -1.1\n 7 07e3e8  Missing                             2               2.1          -0.1\n 8 369449  Missing                             1               2.1          -1.1\n 9 f393b4  Missing                             1               2.1          -1.1\n10 1389ca  Missing                             2               2.1          -0.1\n# ℹ 5,878 more rows",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#グループ化したデータの選択",
    "href": "new_pages/grouping.jp.html#グループ化したデータの選択",
    "title": "13  データのグループ化",
    "section": "13.9 グループ化したデータの選択",
    "text": "13.9 グループ化したデータの選択\nselect() はグループ化されたデータに対して機能しますが、グループ化した列は常に（ select() で指定されていない場合でも）含まれます。グループ化した列を含みたくない場合は、最初に ungroup() を使用してください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.jp.html#参考資料",
    "href": "new_pages/grouping.jp.html#参考資料",
    "title": "13  データのグループ化",
    "section": "13.10 参考資料",
    "text": "13.10 参考資料\n詳細については、以下の資料をご参照ください。\n\nグループ化されたデータには、いかなる要約機能でも適用することができます。 RStudio data transformation cheat sheet を参照ください。\nThe Data Carpentry が作成した dplyr のページ\ntidyverse 公式ドキュメントの group_by() と grouping のページ\nData manipulation に関するページ\nSummarize with conditions in dplyr",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データのグループ化</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.jp.html",
    "href": "new_pages/joining_matching.jp.html",
    "title": "14  データの結合",
    "section": "",
    "text": "14.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの結合</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.jp.html#準備",
    "href": "new_pages/joining_matching.jp.html#準備",
    "title": "14  データの結合",
    "section": "",
    "text": "パッケージを読み込む\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R パッケージの詳細については、R の基礎 の章を参照してください。\n\npacman::p_load(\n  rio,            # ファイルのインポートとエクスポート\n  here,           # ファイルを探す \n  tidyverse,      # データ管理と可視化\n  RecordLinkage,  # 確率的マッチング\n  fastLink        # 確率的マッチング\n)\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、こちら をクリックして「前処理された」ラインリスト（linelist）をダウンロードしてください（.rds 形式で取得できます）。 データは rio パッケージの import() を利用してインポートしましょう（import() は、.xlsx、.csv、.rdsなど、様々な形式のファイルを扱うことができます）。インポートの詳細については、データのインポート・エクスポート の章を参照してください。\n\n# 症例ラインリストをインポートする \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nラインリストの最初の 50 行を以下に表示します。\n\n\n\n\n\n\n\n\n\nサンプルデータセット\n以下の「データの結合」セクションでは、次のデータセットを使用します。\n\ncase_id、date_onset、hospital の列で最初の 10 行のみを含む、linelist データセットの小型版。\n\n各病院の詳細な情報を含む、 hosp_info という名前の別のデータフレーム。\n\n「確率的マッチング」のセクションでは、2 種類の小さなデータセットを使用しますが、データセットを作成するためのコードはセクション内に記載されています。\n\n小型版の症例ラインリスト\n以下は小型版の症例のラインリストで、case_id、date_onset、hospital の列の最初の10行のみが含まれています。\n\nlinelist_mini &lt;- linelist %&gt;%                 # 元のラインリストから始める\n  select(case_id, date_onset, hospital) %&gt;%   # 列を選択\n  head(10)                                    # 最初の10行のみを取得します\n\n\n\n\n\n\n\n\n\n病院情報データフレーム\n以下は、7 つの病院に関する追加情報（患者数、利用可能な医療レベル）を含むまったく別のデータフレームを作成するためのコードです。 なお、“Military Hospital” という名前の病院は 2 つあり、住民10000人を収容する一次病院と、住民 50280人を収容する二次病院の 2 つです。\n\n# 病院情報データフレームを作成する\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)\n\nこのデータフレームに含まれる病院は、以下の通りです。\n\n\n\n\n\n\n\n\n\n\nデータの前処理\n従来の結合（非確率的マッチング）では大文字と小文字が区別され、2 つのデータフレームを結合する際は、対象の文字が完全に一致する必要があります。以下では、linelist_mini データセットと hosp_info データセットの前処理を行いながら、結合する前に行わなければならない前処理（クリーニング）手順のいくつかについて説明します。\n違いを特定する\nデータフレームの hosp_name 列の値は、linelist_mini データフレームの hospital 列の値と一致する必要があります。\n以下に、linelist_mini データフレームの値を、base R の unique() で表示します。\n\nunique(linelist_mini$hospital)\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n\n\n次に、hosp_info データフレームの値は以下の通りです。\n\nunique(hosp_info$hosp_name)\n\n[1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"      \n[5] \"ignace\"           \"sisters\"         \n\n\nいくつかの病院は両方のデータフレームに存在しますが、スペルが異なっていることがわかります。\n値を揃える\nまず、hosp_info データフレームの値をクリーニングして整えます。データクリーニングと主要関数 の章で説明したように、dplyr の case_when() を使用し、論理的な基準で値を再コード化することができます。両方のデータフレームに存在する 4 つの病院については、linelist_mini の値と一致するように値を変更します。 他の病院は、値を変更せずそのままにします（TRUE ~ hosp_name）。\n注意: 通常、クリーニングを行う場合は新しい列を作成して行うべきですが（例: hosp_name_clean）、今回の例では簡単にするため、新しく列を作成せずに古い列を修正します。\n\nhosp_info &lt;- hosp_info %&gt;% \n  mutate(\n    hosp_name = case_when(\n      # 基準                             # 新しい値\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\n\n両方のデータフレームに存在する病院名が揃えられました。linelist_mini にはないが hosp_info にはある病院が 2 つありますが、これらは後に結合するステップで扱います。\n\nunique(hosp_info$hosp_name)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Port Hospital\"                       \n[4] \"St. Mark's Maternity Hospital (SMMH)\"\n[5] \"ignace\"                              \n[6] \"sisters\"                             \n\n\nデータフレームを結合する前に、列名をすべて小文字または大文字に変換すると、結合作業がより簡単になります。列のすべての値を大文字または小文字に変換する必要がある場合は、文字型・文字列型データ の章で言及したように、mutate() を使用して、さらに stringr の以下のいずれかの関数に変換したい列を適用します。\nstr_to_upper()\nstr_to_upper()\nstr_to_title()",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの結合</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.jp.html#dplyr-による結合",
    "href": "new_pages/joining_matching.jp.html#dplyr-による結合",
    "title": "14  データの結合",
    "section": "14.2 dplyr による結合",
    "text": "14.2 dplyr による結合\ndplyr パッケージには、データを結合する様々な関数があります。dplyr は tidyverse パッケージに含まれます。以下に、データを結合する関数について、簡単な使用例とともに説明します。\n有益な GIF を提供してくれた &lt;https://github.com/gadenbuie&gt; に感謝申し上げます。\n\n\n一般的な構文\n結合のコマンドは、単一のコマンドとして実行して 2 つのデータフレームを新しいオブジェクトに結合することも、あるいは、パイプチェーン（%&gt;%）内で使用して、データクリーニングまたは変換の際に1つのデータフレームを別のデータフレームにマージ（併合）することもできます。\n以下の例では、left_join() を単一コマンドとして使用し、新たに joined_data と名付けるデータフレームを作成します。 結合に使用されるデータはデータフレーム 1 と 2（df1 と df2 ）です。 前者のデータフレームがベースラインデータフレーム（基礎となるデータフレーム）であり、後者のデータフレームは前者のデータフレームに結合されています。\n3 番目の引数 y = では、2 つのデータフレームの行を揃えるために使用される各データフレームの列を指定します。 これらの列の名前が異なる場合は、以下に示すよう に c() ベクトル内に指定してください。以下の例では、df1 データフレームの ID 列と df2 データフレームの identifier 列で共通している値に基づいて行が照合されます。\n\n# 列 \"ID\"（最初のデータフレーム）と列 \"identifier\"（2番目のデータフレーム）の間の共通の値に基づいて結合する\njoined_data &lt;- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\n\nby で指定する列名が両方のデータフレームでまったく同じ名前である場合、その名前を引用符で囲んで指定できます。\n\n# 両方のデータフレームの列 \"ID\" の共通値に基づく結合\njoined_data &lt;- left_join(df1, df2, by = \"ID\")\n\n複数の列にわたる共通の値に基づいてデータフレームを結合する場合は、これらのフィールドを c() ベクトル内で指定します。 この例では、各データフレームの 3 つの列の値が正確に一致している場合に行が結合されます。\n\n# 同じ名、姓、年齢に基づいて結合する\njoined_data &lt;- left_join(df1, df2, by = c(\"name\" = \"firstname\", \"surname\" = \"lastname\", \"Age\" = \"age\"))\n\nコマンドは、パイプライン内で実行することもでき、その場合はパイプされるデータフレームが変更されます。\n以下の例では、df1 がパイプを通過し、df2 がパイプに結合されるため、df1 が変更され、再定義されます。\n\ndf1 &lt;- df1 %&gt;%\n  filter(date_onset &lt; as.Date(\"2020-03-05\")) %&gt;% # その他のクリーニング \n  left_join(df2, by = c(\"ID\" = \"identifier\"))    # df2 を df1 に結合\n\n注意: 結合では、大文字と小文字が区別されます。したがって、結合する前にすべての値を小文字または大文字に変換しておくと便利です。変換方法の詳細は、文字型・文字列型データの章を参照ください。\n\n\n\n左結合（left join）と右結合（right join）\n左結合または右結合は、データフレームに情報を追加するためによく使用されます。つまり、新しい情報は、ベースラインデータフレーム（基礎となるデータフレーム）にすでに存在する行にのみ追加されます。 これらは疫学的研究において、あるデータセットから別のデータセットに情報を追加するために使われる一般的な結合です。\n左結合または右結合を行う際は、コマンド内におけるデータフレームの順序が重要となります*。\n\n左結合では、最初に書かれているデータフレームがベースラインです。\n\n右結合では、2 番目に書かれているデータフレームがベースラインです。\n\nベースラインデータフレームでは、結合後もすべての行が保持されます。二次データフレーム（ベースラインではないデータフレーム）の行は、識別子として指定された列の値がベースラインデータフレームの識別子供と一致する場合にのみ、ベースラインデータフレームに結合されます。加えて、\n\n一致しない二次データフレームの行は削除されます\n二次データフレームの 1 行がベースラインデータフレームの複数の行と一致する場合（多対一）、ベースラインデータフレームの各行にその一致した二次データフレームの行が追加されます\nベースラインフレームの 1 行が二次データフレームの複数の行と一致する場合（一対多）、一致したすべての組み合わせが返されます。つまり、返されたデータフレームに新しい行が追加される可能性があります\n\n左結合と右結合のアニメーション例（画像提供元）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n例\n以下は、 hosp_info （二次データフレーム、ここを参照）を left_join() でlinelist_mini （ベースラインデータフレーム、ここを参照）に左結合し、結果を出力したものです。元の linelist_mini の行数は 10 でした。以下に表示された左結合後の linelist_mini を、次の点に注意して確認してください。\n\nlinelist_mini の右側に 2 つの新しい列、 catchment_pop と level が追加されました\n\nベースラインデータフレーム linelist_mini の元の行はすべて保持されています\n\nlinelist_mini 内に元からあった “Military Hospital” の一行は、二次データフレーム内の 2 行と一致したため複製され、両方の組み合わせが出力されました\n\n二次データフレームの結合識別子列（hosp_name）は、ベースラインデータフレームの識別子列（hospital）と重複しているため、削除されました\n\nベースラインデータフレームの行が二次データフレームのどの行とも一致しなかった場合（ここでは、 hospital 列の値が “Other” または “Missing” の場合）、NA（空白）が二次データフレームから追加された列に入力されます（ここでは、catchment_pop 列と level 列）\n\n元のデータフレーム（“sisters” および “ignace” 病院）と一致しない二次データフレームの行は結合されませんでした\n\n\nlinelist_mini %&gt;% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in left_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n右結合を使用するべきか、または左結合を使用するべきか？\n上の質問に答えるために、「どちらのデータフレームの行がすべて保持されるべきか？」と自分自身に聞いてみてください。左結合では、コマンドで指定された最初のデータフレーム行がすべて保持されますが、右結合では、2 番目のデータフレームの行がすべて保持されます。\n以下の 2 つのコマンドは、先述の例と同じくlinelist_mini をベースラインデータフレームとし、hosp_info を linelist_mini に結合するコマンドです。コマンド実行後の出力結果は同じですが、結合方法が異なります（1 つ目は左結合、2 つ目は右結合がを使用している）。hosp_info を右から結合させるか（左結合）、左から結合するか（右結合）によって、列の順序が異なっています。それに伴い、行の順番もずれる可能性がありますが、select() による列の並べ替えや arrange() による行の並べ替えで対処することができます。\n\n# 以下の2つのコマンドの出力結果は同じだが、行と列の順序が異なる\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n1 つ目は、左結合で hosp_info を linelist_mini に結合した結果です（新しい列は右側から結合されます）。\n\n\nWarning in left_join(linelist_mini, hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n2 つ目は、右結合で hosp_info を linelist_mini に結合した結果です（新しい列は左側から結合されます）。\n\n\nWarning in right_join(hosp_info, linelist_mini, by = c(hosp_name = \"hospital\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 4 of `x` matches multiple rows in `y`.\nℹ Row 5 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n左結合か右結合のどちらを使用するのかを決める際は、結合に使用するデータが既存のパイプライン（%&gt;%）内にあるかも確認してください。 パイプライン内のデータセットがベースラインである場合は、左結合を使用してデータを追加するのがよいでしょう。\n\n\n\n\n完全結合（full join）\n完全結合は、両方のデータフレーム内のすべての行が結合される結合であり、結合の中で最も包括的なものです。\n一方のデータフレームにあるがもう一方のデータフレームにない行（一致が見つからなかった行）も出力結果のデータフレームに含まれるため、出力結果のデータフレームはその分長くなります。結合の際に生じたギャップは、欠損値（NA）で埋められます。 結合の際には、列や行の数に注意を払い、大文字小文字の区別や文字などを入念にチェックしてください。\nベースラインデータフレームは、コマンドで最初に指定されるデータフレームです。データフレームの順序を調整しても結合結果として返される行は変わりませんが、結果の列の順序、行の順序、および保持される識別子の列が変更されます。\n\n\n\n\n\n\n\n\n\n完全結合のアニメーション例（画像提供元）\n例\n以下は、 hosp_info （7 行のデータフレーム、ここに表示）を full_join() で linelist_mini（10 行のデータフレーム、ここに表示）に完全結合した出力結果です。 次の点に注意してください。\n\nベースラインデータフレーム（linelist_mini）のすべての行が保持されます\n\nベースラインデータフレームと一致しない二次データフレームの行も保持され（“ignace” と “sisters” 病院）、対応するベースラインデータフレームの列 case_id と onset の値は欠損値（NA）で埋められています\n\n同様に、ベースラインデータフレームの行のうち、二次データフレームと一致しない行も保持され（“Other” と “Missing”）、二次データフレームから結合された列である catchment_pop と level が欠損値（NA）で埋められます\n\n一対多または多対一の場合（例えば “Military Hospital”の行）、すべての組み合わせが出力されます（最終的なデータフレームが長くなります）\n\n結合に使用された識別子の列は、ベースラインデータフレームの識別子列（hospital）のみが保持されます\n\n\nlinelist_mini %&gt;% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in full_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\n内部結合（inner join）\n内部結合は、両方のデータフレームで一致する行のみが結合され、データ結合の中で最も制限の多い結合です。そのため、結合後のベースラインデータフレームの行数が減少する可能性があります。どのデータフレームを「ベースライン」とするか（関数内で最初に指定されるデータフレーム）を調整しても、結合結果として返される行は変わりませんが、列の順番、行の順番、どの識別子列が保持されるかには影響します。\n\n\n\n\n\n\n\n\n\n内部結合のアニメーション例（画像提供元）\n例\n以下は、full_join() を使用して linelist_mini（ベースラインデータフレーム）とhosp_info （二次データフレーム）を完全結合した出力結果です。\n\n二次データフレームの行と一致しないベースラインデータフレームの行は結合されません（ hospital 列が”Missing” または “Other” である行）\n\n同様に、ベースラインデータフレームの行と一致しなかった二次データフレームの行も結合されません（ hosp_name 列が “sisters”または “ignace” の行）\n\n結合に使用された識別子の列は、ベースラインデータフレームの識別子列（hospital）のみが保持されます\n\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\n準結合（semi join）\n準結合は、別のデータセットを使用して行や列を追加するのではなく、フィルタリングを実行する「フィルタリング結合」です。\n準結合では、二次データフレームの行と一致するベースラインデータフレームの行すべてが保持されます (ただし、二次データフレームから新しい列は追加されず、また、複数の一致があった行も複製されません）。「フィルタリング」結合について詳しく知りたい方は、こちら をご覧ください。\n\n\n\n\n\n\n\n\n\n準結合のアニメーション例 (画像提供元)\n以下のコマンドでは、hosp_info をベースラインデータフレーム、linelist_mini を二次データフレームとしています。linelist_mini データフレームにある病院名（ hospital 列）に一致する hosp_info データフレームの病院（hosp_name 列）が出力結果として返されます。\n\nhosp_info %&gt;% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n                             hosp_name catchment_pop     level\n1                    Military Hospital         40500 Secondary\n2                    Military Hospital         10000   Primary\n3                        Port Hospital         50280 Secondary\n4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary\n\n\n\n\n\nアンチ結合（anti join）\nアンチ結合では、ベースラインデータフレームのうち、二次データフレームと一致しない行が出力される、もう 1 つの「フィルタリング結合」です。\nフィルタリング結合について詳しく知りたい方は、こちら をご覧ください。\nアンチ結合は一般的に、二つのデータフレームのうち一方のデータフレームに存在しないデータを見つけ出したり、結合したデータに一致するはずのデータが含まれているかを確認したり、または左結合など他の結合後に除外されたデータを詳しく見る際に用いられます。\nright_join() および left_join() と同様に、最初に指定されるベースラインデータフレームが重要です。結合後は、二次データフレームの行と一致しないベースラインデータフレームの行のみが出力結果として返されます。下の GIF では、二次データフレームの紫の行 4 がベースラインデータフレームのどの行にも一致せず、出力されていないことに注意してください。\n\n\n\n\n\n\n\n\n\nアンチ結合のアニメーション例 (画像提供元)\n\n簡単な anti_join() の例\n簡単な例として、hosp_info データフレームにある病院のうち、linelist_mini データフレームには含まれていない病院を検索してみましょう。ベースラインデータフレームとして、hosp_info を最初に指定します。結合後は、linelist_mini データフレームにない病院が返されます。\n\nhosp_info %&gt;% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n\n\n\n\n\n\n\n\n複雑な anti_join() の例\n別の例として、linelist_mini データフレームと hosp_info データフレームで inner_join() を実行したとします。linelist_mini データフレームには、hosp_info データフレームにはない病院の症例があり、そのような症例は結合の際に除かれるため、結合後の linelist_mini データフレームは元のデータフレームよりも短くなります。\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n内部結合で除外された linelist_mini データフレームの症例を確認するために、実行された内部結合と同じように linelist_mini をベースラインデータフレームとしてアンチ結合を実行します。\n\nlinelist_mini %&gt;% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\n\n\n\n\n逆に、hosp_info をベースラインデータフレームとして使用してアンチ結合を実行すると、内部結合で除外された hosp_info データフレームの病院を確認することができます。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの結合</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.jp.html#確率的マッチング",
    "href": "new_pages/joining_matching.jp.html#確率的マッチング",
    "title": "14  データの結合",
    "section": "14.3 確率的マッチング",
    "text": "14.3 確率的マッチング\nデータセット間で共通する識別子がない場合は、確率的なマッチングアルゴリズムを使用することを検討してください。これは、データ間の類似性（例えば、Jaro-Winkler 文字列距離や数値距離）に基づいて 2 つのデータセット間でマッチングを見つけるものです。以下は、fastLink パッケージを使用した簡単な例です。\nパッケージを読み込む\n\npacman::p_load(\n  tidyverse,      # データ整理と可視化\n  fastLink        # データ結合\n  )\n\n確率的マッチングを解説するために使用する 2 つの小さなサンプルデータセット（cases と test_results）を次に示します。\n以下は、サンプルデータセットを作成するためのコードです。\n\n# データセットを作成する\n\ncases &lt;- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults &lt;- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )\n\ncases データセットには、検査結果を待っている患者の記録が 9 件ある。\n\n\n\n\n\n\ntest_results データセットには 14 件の記録があり、result という列があります。この列は、確率的マッチングを行う際に cases データセットに追加したい列です。\n\n\n\n\n\n\n\n確率的マッチング\nfastLink パッケージの fastLink() を使用して、マッチングアルゴリズムを適用します。以下に、fastLink() の基本的な情報を記載します。 コンソールに ?fastLink と入力すると、さらに詳細を読むことができます。\n\n引数 dfA = および dfB = に比較する 2 つのデータフレームを指定します\n\n引数 varnames = で、マッチングに使用するすべての列名を指定します。ここで指定されるすべての列は dfA と dfB の両方に含まれている必要があります。\n\n引数 stringdist.match = で、varnames にある列のうち、文字列の「距離（“distance”）」を評価する列を指定する。\n\n引数 numeric.match = で、varnames にある列の中から、数値の距離「距離（“distance”）」を評価する列を指定する。\n\n欠損値は無視されます\n\nデフォルトでは、Winkler の線形割り当て（Winkler’s linear assignment solution）による重複排除が行われ、一方のデータフレームの各行が、最大でもう一方のデータフレームの 1 行しかマッチングされません。評価済みのマッチをすべて表示したい場合は、 dedupe.matches = FALSE と設定してください。\n\nヒント: lubridate パッケージの day()、 month()、 year() を用いて、ひとつの日付列を 3 つの別々の数値列に分割することができます。\nマッチングの閾値のデフォルトは 0.94（threshold.match = ）ですが、この値は調整可能です。閾値を高くすると偽陰性（マッチするはずの行がマッチしない）が増える可能性があり、同様に閾値を低くすると偽陽性が増えうることを考慮して、閾値を設定してください。\n以下では、名前と地区の列については文字列の距離で、年、月、誕生日については数値の距離でマッチングを行います。マッチングの閾値は 95% に設定されています。\n\nfl_output &lt;- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nDeduping the estimated matches.\nGetting the match patterns for each estimated match.\n\n\nマッチを確認する\nfastLink() で確率的マッチングを行った結果を fl_output として定義しました。 このオブジェクトは list であり、内部にはマッチングの結果の詳細を含むデータフレームが複数含まれています。中でも、matches と名付けられたデータフレームには、cases と results データセット間のマッチング結果が含まれており、fl_output$matches というコマンドでアクセスすることができます。以下では、後でアクセスしやすいように my_matches という名前で matches データフレームを保存します。\nmy_matches を表示すると、2 つの列ベクトルが含まれていることがわかります。cases（ “inds.a”）と results（ “inds.b”）の行番号・インデックスのペア（「行名（“rownames”）」とも呼ばれています）がベストマッチを表します。データフレームの行番号が欠落している場合、指定されたマッチングの閾値で対応する値がもう一方のデータフレームになかったことを意味します。\n\n# マッチングを表示\nmy_matches &lt;- fl_output$matches\nmy_matches\n\n  inds.a inds.b\n1      1      1\n2      2      2\n3      3      3\n4      4      4\n5      8      8\n6      7      9\n7      6     10\n8      5     12\n\n\n以下の点に注意してください。\n\n名前のスペルや生年月日が若干異なるにもかかわらず、マッチングが成立した。\n\n“Tony B. Smith” が “Anthony B Smith” とマッチした\n\n“Maria Rodriguez” が “Marialisa Rodrigues” とマッチした\n\n“Betty Chase” が “Elizabeth Chase” とマッチした\n\n“Olivier Laurent De Bordeaux” が “Oliver Laurent De Bordow” とマッチした（生年月日の欠落は無視する）\n\n\ncases データセット 9 行目（“Blessing Adebayo” の行）は、results データセットにマッチする行がなかったため、 my_matches には存在していません。\n\n確率的マッチングに基づく結合\nこれらのマッチング結果を使用して results データセットを cases データセットに結合するための戦略は、次のとおりです。\n\nleft_join() を使用して、my_matches を cases に結合します（cases の行名を my_matches の “inds.a” に一致させます）\n\n次に、もう一度 left_join() を使用し、今度は results を cases に結合します（ 前のステップで cases に新しく結合された “inds.b” を results の行名に一致させます）\n\n結合を行う前に、まず 3 つのデータフレームをクリーニングする必要があります。\n\ndfA と dfB の行番号（「行名（“rowname”）」）を列に変換する必要があります。\n\nmy_matches に含まれる 2 列は文字型データに変換し、文字型の行名に結合できるようにします。\n\n\n# 結合前のデータのクリーニング\n#############################\n\n# casesの行番号（rowname）を列に変換する \ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\n# test_results の 行番号（rownames） を列に変換する\nresults_clean &lt;- results %&gt;% rownames_to_column()  \n\n#  データセットの全ての列を文字列に変換し、行番号で結合できるようにする\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n\n\n# matches_clean を dfA に結合、その後 dfB も結合\n###################################\n# 列 \"inds.b\" を dfA に追加する\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# dfB 由来の列を追加する \ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\n上のコードを実行すると、結果として出力されるデータフレーム complete には、cases と results の両方のデータセットに含まれるすべての列が含まれます。多くの場合、列名が重複してしまうため、“.x” や “.y” といった添え字が出力結果のデータフレームの列名に付加されます。\n\n\n\n\n\n\nあるいは、 cases データセットに results データセットの特定の列のみを追加したい場合は、結合を行う前に results データセットの列を選別しましょう。select() を使用して results データセットで結合後も残したい列のみを選択し（この例では、rowname 列と results 列）、選択された列のみを cases データセットに結合することができます。\n\ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\nresults_clean &lt;- results %&gt;%\n  rownames_to_column() %&gt;% \n  select(rowname, result)    # 特定の列のみを選択する\n\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n# 結合\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\n\n\n\n\n\n\nどちらかのデータセットをマッチした行だけにサブセットしたい場合は、以下のコードを使用してください。\n\ncases_matched &lt;- cases[my_matches$inds.a,]  # results の行と一致した cases の行\nresults_matched &lt;- results[my_matches$inds.b,]  # cases の行と一致した results の行\n\nまたは、一致しなかった行のみを表示することもできます。\n\ncases_not_matched &lt;- cases[!rownames(cases) %in% my_matches$inds.a,]  # results の行と一致しなかった cases の行\nresults_not_matched &lt;- results[!rownames(results) %in% my_matches$inds.b,]  # cases の行と一致しなかった results の行\n\n\n\n確率的な重複排除\n確率的マッチングは、データの重複排除にも使用できます。その他の重複排除の方法については、重複排除の章を参照してください。\nここでは、 cases データセットに重複した行を 2 行追加した新しいデータセットである cases_dup データセットを例として使用します。“Tony Smith” と重複する行として “Anthony Smith” の行が追加され、“Marialisa Rodrigues” と重複する行として “Maria Rodriguez” の行が追加されました。\n\n\n\n\n\n\n先述のセクションと同じように fastLink() を実行し、出力結果を cases_dup データフレームと比較します。dfA = 引数と dfB = 引数に指定されたデータフレームが同一である場合、この関数は重複を解消することを目的として動作します。先述のセクションと違って、stringdist.match = や numeric.match = は設定しないことに注意してください。\n\n## 同じデータセットにfastLinkを実行する\ndedupe_output &lt;- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\ndfA and dfB are identical, assuming deduplication of a single data set.\nSetting return.all to FALSE.\n\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nCalculating the posterior for each pair of matched observations.\nGetting the match patterns for each estimated match.\n\n\ngetMatches() で重複の可能性がある行を確認することができます。重複確認を行いたいデータフレームを dfA = と dfB = の両方に指定し、前述の fastLink() の出力結果を fl.out = に指定します。fl.out に指定されるオブジェクトは fastLink.dedupe 型、すなわち fastLink() の出力結果でなければなりません。\n\n## getMatches() を実行\ncases_dedupe &lt;- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\n\n一番右の列は重複する ID （duplicate ID）を表しており、最後の 2 行は上から 2 行目と 3 行目と重複している可能性が高いことが分かります。\n\n\n\n\n\n\n重複していると思われる行の行番号を確認したい場合は、 dedupe.ids 列の ID ごとの行数をカウントし、複数の行がある ID だけを残すようにフィルタリングします。この場合、2 行目と 3 行目が残ります。\n\ncases_dedupe %&gt;% \n  count(dedupe.ids) %&gt;% \n  filter(n &gt; 1)\n\n  dedupe.ids n\n1          2 2\n2          3 2\n\n\n重複している可能性がある行全体を確認したい場合は、以下のコマンドに行番号を入れます。\n\n# 2行目とその重複候補をすべて表示する\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   \n\n   gender   first middle  last   yr mon day district dedupe.ids\n2       M Anthony     B. Smith 1970   9  19    River          2\n10      M    Tony     B. Smith 1970   9  19    River          2",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの結合</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.jp.html#データの結合と整列",
    "href": "new_pages/joining_matching.jp.html#データの結合と整列",
    "title": "14  データの結合",
    "section": "14.4 データの結合と整列",
    "text": "14.4 データの結合と整列\n2 つのデータフレームを結合するもう一つの方法は、それらを 「バインドする（“bind”）」ことです。これは、行や列を「追加する（“append” や “add”）」ことだと捉えることもできます。\n他にも、このセクションでは、データフレームの行の順番を別のデータフレームの順番に「揃える（“align”）」方法についても説明します。このトピックについては、以下の「列をバインドする」のセクションで後述します。\n\n行をバインドする\nデータフレームの行を別のデータフレームの下部にバインドするには、dplyr の bind_rows() を使用します。非常に包括的な方法であり、いずれかのデータフレームに存在するすべての列が結合されます。 以下のことに注意してください。\n\nbase R の row.bind() とは異なり、dplyr の bind_rows() では、バインドするデータフレームの列の順序が同じである必要はありません。列名が同じである限り、データは正しくバインドされます。\n\n.id = 引数に文字型の列を指定すると、各行がどのデータフレームからのものであるかを識別するのに役立つ新しい列が生成されます。\n\n同じような構造を持つデータフレームを複数含む list で bind_rows() を使用すると、それら複数のデータフレームを 1 つのデータフレームに結合できます。ループと反復処理・リストの操作 の章で紹介している purrr を使用して複数のラインリストをインポートする例を参照してください。\n\n行によるバインドの一般的な例として、dplyr の summarise() で作成された要約統計表に「合計（“totals”）」を表す行を結合する例が挙げられます。以下では、「合計」行を含む病院ごとの症例数と CT 値の中央値の表を作成します。\nsummarise() は、病院ごとにグループ化されたデータに対して使用され、病院ごとの要約データフレームが出力されますが、「合計」行は自動的に生成されません。そのため、データを再度要約して「合計」行を作成します。その際に使用されるデータは、病院ごとにグループ化されていないため、1 行だけのデータフレームが新たに生成されます。これらのデータフレームを結合し、最終的な表を作成していきます。記述統計表の作り方 の章および 見やすい表の作り方 の章では他の例を紹介していますので、詳しく知りたい方はご参照ください。\n\n# コアテーブルの作成\n###################\nhosp_summary &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;%                        # 病院別のグループデータ\n  summarise(                                    # 目的の指標の新しい要約列を作成する\n    cases = n(),                                  # 病院ごとの行数-結果グループ\n    ct_value_med = median(ct_blood, na.rm=T))     # グループあたりのCT値の中央値\n\n作成された hosp_summary データフレームは次のとおりです。\n\n\n\n\n\n\n「合計」行を含む（病院ごとにグループ化されていない）データフレームを作成します。このデータフレームに含まれる行は 1 行のみです。\n\n# totals を作成\n###############\ntotals &lt;- linelist %&gt;% \n  summarise(\n    cases = n(),                               # データセット全体の行数    \n    ct_value_med = median(ct_blood, na.rm=T))  # データセット全体のCT中央値\n\n以下に作成した totals データフレームを表示します。列が 2 つしかないことに注意してください。これらの列は hosp_summary にもありますが、 hosp_summary には totals にない列が 1 つあることに注意してください（hospital 列）。\n\n\n\n\n\n\nこれで、bind_rows() を使用して行をバインドできます。\n\n# データフレームをバインドする\ncombined &lt;- bind_rows(hosp_summary, totals)\n\n以下に、出力結果を表示します。 最後の行を確認し、hosp_summary になかった列（hospital 列）の欠損値（NA）がどのように埋められているかを確認してください。見やすい表の作り方 の章で説明するように、 replace_na() を使用すると、空欄のセル（hospital 列の最後のセル）に「合計」と入力することができます。\n\n\n\n\n\n\n\n\n列をバインドする\n先述のセクションで使用した bind_rows() と同様の dplyr 系関数である bind_cols() を使用すると、2 つのデータフレームを縦向きに組み合わせる（列をバインドする）ことができます。列をバインドする際は、先述の各種結合（join）と異なり、各行が位置をもとにマッチングされることに注意してください。例えば、各データフレームの 12 行目が整列される、といった具合です。\nここでは、例としていくつかの要約統計表をバインドします。また、match() を使用して、データフレームの行の順序を別のデータフレームの順序と一致するように並び替える方法も説明します。\nこの例では、 linelist データフレームを基に、症例数と死亡数を病院ごとに含む要約統計表を作成し、 case_info データフレームとして定義します。\n\n# 要約統計表を作成する\ncase_info &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\n\n\n\n\n\n\n\n次に、別の情報を含むデータフレームを新たに作成します。ここでは、疫学調査された接触者（exposed contacts）の割合と「フォローアップ」された接触者の割合を病院ごとに含むデータフレーム contact_fu を作成します。\n\ncontact_fu &lt;- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)\n\n\n\n\n\n\n\nどちらのデータフレームにも同じ病院が含まれていますが、データフレームごとに病院の順序が異なることに注意してください。病院名の順序をそろえる最も簡単な方法は、病院の列で left_join() を使用することですが、もう一つステップを追加することにより bind_cols() を使用することもできます。\n\nmatch() を使用して順序を揃える\n今回の例では、それぞれのデータフレームにおいて行の順序が異なるため、このまま bind_cols() コマンドを実行すると、データの不一致が生じます。正しく列をバインドするためには、base R の match() を使用し、データフレームの行の順序をもう一つのデータフレームの行の順序で並び替えます。 この方法では、どちらのデータフレームにも重複する値がないことを前提としています。\nmatch() を使用する場合の構文は、match(TARGET ORDER VECTOR, DATA FRAME COLUMN TO CHANGE) です。この構文では、最初の引数には目的の順序（単一のベクトル、またはこの例ではデータフレームの列）を指定し、2 番目の引数には並べ替えたいデータフレームの列を指定します。match() を実行すると、正しい位置の順序を表す数値のベクトルが出力されます。match() に関する詳細は、?match をコンソールで実行して確認してください。\n\nmatch(case_info$hospital, contact_fu$hospital)\n\n[1] 4 2 3 6 5 1\n\n\n出力される数値ベクトルをサブセットブラケット [ ] 内のコンマの前に指定して、データフレームを並べ替えることができま。base R のサブセットブラケット [ ] の使い方は、R の基礎 の章で詳しく説明されていますので、必要な方はご参照ください。以下のコマンドでは、match() によって出力される数値ベクトルで並び替えられた行のデータフレームを新しく作成し、新しいデータフレームとして定義しします。\n\ncontact_fu_aligned &lt;- contact_fu[match(case_info$hospital, contact_fu$hospital),]\n\n\n\n\n\n\n\nこれで、正しい行の順序（互いに一致する行の順序）でデータフレームの列を結合できます。 一部の列が重複しているため、結合前に rename() でクリーニングする必要があることに注意してください。bind_rows() や bind_cols() についての詳細は、こちら をご覧ください。\n\nbind_cols(case_info, contact_fu)\n\nNew names:\n• `hospital` -&gt; `hospital...1`\n• `hospital` -&gt; `hospital...4`\n\n\n# A tibble: 6 × 6\n  hospital...1                     cases deaths hospital...4 investigated per_fu\n  &lt;chr&gt;                            &lt;int&gt;  &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt; \n1 Central Hospital                   454    193 St. Mark's … 80%          60%   \n2 Military Hospital                  896    399 Military Ho… 82%          25%   \n3 Missing                           1469    611 Missing      &lt;NA&gt;         &lt;NA&gt;  \n4 Other                              885    395 Central Hos… 78%          20%   \n5 Port Hospital                     1762    785 Port Hospit… 64%          75%   \n6 St. Mark's Maternity Hospital (…   422    199 Other        55%          80%   \n\n\nbase R にも bind_cols() と同様の働きをする cbind() という関数があります。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの結合</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.jp.html#参考資料",
    "href": "new_pages/joining_matching.jp.html#参考資料",
    "title": "14  データの結合",
    "section": "14.5 参考資料",
    "text": "14.5 参考資料\nJoin に関する Tidyverse のページ\n相関性データに関する R for Data Science のページ\ndplyr bind に関する Tidyverse のページ\nfastLink パッケージの コード例（Github）\nfastLink についての論文\nRecordLinkage package についての論文",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データの結合</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html",
    "href": "new_pages/deduplication.jp.html",
    "title": "15  重複データの排除",
    "section": "",
    "text": "15.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html#準備",
    "href": "new_pages/deduplication.jp.html#準備",
    "title": "15  重複データの排除",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについては、R の基礎 の章を参照してください。\n\npacman::p_load(\n  tidyverse,   # 重複排除、グループ化、スライスの関数\n  janitor,     # 重複部分の確認をする関数\n  stringr)     # 文字列検索で、値の「ロールアップ」に使用\n\n\n\nデータのインポート\nここでは、以下の R コードで作成された、新型コロナウイルス感染症（COVID-19）に関する電話調査の記録のデータセット obs を例として使用します。\nデータセットには、接触者と感染者の調査内容が記録されており、recordID（コンピュータで生成された番号）、personID、name、date（調査が行われた日）、time（調査が行われた時間）、purpose（調査の目的、調査の回答者が接触者か感染者のどちらであるか）、symptoms_ever（調査対象者が、症状があったことを一度でも報告したかどうか）といった列が含まれています。\n以下は、obs データセットを作成するコードです。\n\nobs &lt;- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %&gt;% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))\n\n\n\n作成したデータセットを以下に表示します\n上部のフィルターボックスを使って、電話調査に回答した人の各記録を確認することができます。\n\n\n\n\n\n\nデータを確認する際、次の点に注意してください。\n\n最初の 2 行は完全に同じ記録（100% 重複）で、recordID も重複している（コンピュータの不具合により重複した記録が作成されたと考えられる）\n\n2 番目の 2 行は、recordID を除くすべての列で重複している\n\n何人かの被調査者（調査回答者）は、調査を複数回受けている（接触者として調査を受けたこともあれば、感染者として調査を受けたこともある）\n\n被調査者は、電話調査を受けた際に「今まで症状があったかどうか」を尋ねられるが、情報の一部が欠損している（symptoms_ever 列）\n\n以下に、janitor の tabyl() を使って、被調査者の名前と調査の目的（被調査者が接触者か感染者のどちらであるか）を簡単に集計しました。\n\nobs %&gt;% \n  tabyl(name, purpose)\n\n    name case contact\n    adam    1       2\n  amrish    1       3\n   brian    1       2\n  mariah    1       2\n natalie    1       0\n  nikhil    0       2\n  raquel    0       2\n   smita    0       1",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html#重複排除",
    "href": "new_pages/deduplication.jp.html#重複排除",
    "title": "15  重複データの排除",
    "section": "15.2 重複排除",
    "text": "15.2 重複排除\nここでは、データフレーム内の重複する行を確認し、削除する方法を説明します。また、ベクトル内の重複する要素を処理する方法も紹介します。\n\n\n重複する行を調べる\n重複している行を素早く確認するには、 janitor パッケージの get_dupes() を使います。デフォルトでは、この関数が返す行は、すべての列の値が重複している行（100% 重複の行）です。\nobs データフレームの最初の 2 行では、本来一意であるべき recordID 列を含むすべての列が同じ値となっており、この 2 列は 100% 重複 しています。以下のコマンドを実行して出力されたデータフレームには、新しい列 dupe_count が右側に自動的に追加され、重複した値の組み合わせを持つ行の数が表示されます。\n\n# すべての列で 100％ 重複\nobs %&gt;% \n  janitor::get_dupes()\n\n\n\n\n\n\n\n元のデータセット と比較してみてください。\nしかし、recordID を無視して考えると、元データの 3 行目と 4 行目の行も重複していることになります。つまり、3 行目と 4 行目は recordID を除くすべての列に同じ値が記録されています。このような行を確認したい場合は、 get_dupes() の中でマイナス記号 - を使って無視する列を指定します。\n\n# recordID 列を除くすべての列で値が重複している\nobs %&gt;% \n  janitor::get_dupes(-recordID)         # 除きたい列が複数ある場合は c() で囲む\n\n\n\n\n\n\n\n重複として考慮する列を明示的に指定することもできます。以下では、name と purpose という列のみに同じ値を持つ行が返されます。name 列に “amrish” という値をもつ行の dupe_count が 3 になっていることに注目してください。これは、“amrish” という人物が「接触者（“contact”）」として 3 回電話調査を受けたことを示しています。\n右にスクロールすると、データフレームに含まれるすべての列を確認できます。\n\n# name と purpose の列の値が重複する行のみ\nobs %&gt;% \n  janitor::get_dupes(name, purpose)\n\n\n\n\n\n\n\n元のデータセット と比較してみてください。\nget_dupes() に関する詳細は、?get_dupes をご覧ください。また、こちら のドキュメントもご参照ください。\n\n\n\n一意の行のみを保持する\nデータフレームの一意の行のみ（重複しない行のみ）を保持するには、dplyr の distinct() を使います（データクリーニングと主要関数 の章でさらに詳しく説明しています）。重複している行のうち、最初の行のみが保持され、それ以外の行は削除されます。デフォルトでは、「最初」とは最も上位の rownumber （行の順序、上から下へ番号が振られている）を意味します。その結果、一意の行だけが残ります。\n以下の例では、recordID という列を除いて distinct() を実行して、2 つの重複した行を削除しています。上の表の最初の行（name 列の値が “adam” の行）は 100% 重複しており、削除されます（訳注：最初の行ではなく、2 番目の行が削除される、の誤り。deuplicate() は重複する行のうち、最初の行が保持されそれ以外の重複行が削除される）。また、3 行目（“amrish” の行）は、recordID を除くすべての列で 4 行目と重複しており、削除されます（訳注：削除されるのは 4 行目）。その結果、obs データセットの n （調査記録の数）は 19 ではなく、17 になります。\n右にスクロールすると、データフレームに含まれるすべての列を確認できます。\n\n# 既存のパイプラインに加える（データクリーニング）\nobs %&gt;% \n  distinct(across(-recordID), # データフレームを一意の行だけにする（重複している最初の行は残す）\n           .keep_all = TRUE) \n\n# パイプを使わない場合は、以下のように第一引数にデータセットの名前を入れる \n# distinct(obs)\n\n\n\n\n\n\n\n注意： グループ化されたデータに distinct() を使う場合は、各グループごとに適用されます。\n特定の列に基づいて重複排除する\n重複排除の基準となる列を指定することもできます。これにより、指定した列の値のみ重複している行に重複排除が適用されます。また .keep_all = TRUE を設定しない限り、指定されていないすべての列が削除されます。\n以下のコマンドでは、name 列と purpose 列の値が同じ行にのみ重複排除が適用されます。したがって、name 列 が “brian” である行は 3 行から 2 行になります。残された 2 行は、“brain” が最初に「接触者（“contact”）」として受けた調査記録と、彼が「感染者（“case”）」として受けた唯一の調査記録です。調査の目的別に（接触者か感染者であるか）“brian” が受けた最後の調査記録（複数ある記録のうち、最も新しい記録）を保持したい場合は、本章の「グループ内のスライス」のセクションを参照してください。\n右にスクロールすると、データフレームに含まれるすべての列を確認できます。\n\n# 既存のパイプラインに加える（データクリーニング）\nobs %&gt;% \n  distinct(name, purpose, .keep_all = TRUE) %&gt;%  # name と purpose 列によって重複を排除して一意の行にし、すべての列を保持する\n  arrange(name)                                  # 見やすさのために並び替える\n\n\n\n\n\n\n\n元のデータセット と比較してみてください。\n\n\n\nベクトル内の要素の重複排除\nbase R に含まれている関数の duplicated() は、ベクトル（列）を評価して、同じ長さのロジカルベクトル（TRUE または FALSE）を返します。重複する値のうち、最初の値が現れたときは FALSE（重複していない）を返し、それ以降に値が現れたときは TRUE （重複している）を返します。NA も他の値と同じように重複しているか判断されることに注意してください。\n\nx &lt;- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)\n\n [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\n重複した要素だけを返したい場合は、角括弧 [ ] を使って、以下のように元のベクトルをから重複した要素のみを抜き出すことができます。\n\nx[duplicated(x)]\n\n[1]  1 NA  4  4  1  2\n\n\n一意の要素だけを返すには、base Rの unique() を使います。NA を出力から取り除くには、unique() の中に na.omit() を入れます。\n\nunique(x)           # 代わりに x[!duplicated(x)] を使うこともできる\n\n[1]  1  2 NA  4  5\n\nunique(na.omit(x))  # NAを除外する\n\n[1] 1 2 4 5\n\n\n\n\n\nbase R を使う\n重複する行を返す\nbase R では、データフレーム df の中でどの行が 100% 重複しているかを、duplicated(df) というコマンドで確認できます（行のロジカルベクトルを返します）。\nしたがって、基本のサブセット [ ] コマンドをデータフレームに使用して、df[duplicated(df),] で重複した行を表示して確認することもできます（すべての列を見るという意味のコンマを忘れないでください！）。\n一意の行を返す\n上述を参照してください。一意の行を表示して確認したい場合は、duplicated() の前に論理否定演算子 ! を加え、以下のように書きます。\ndf[!duplicated(df),]\n特定の列の値だけが重複している行を返す\nduplicated() の括弧内で df をサブセットし（重複判定の対象となる範囲を定義し）、duplicated() が df の特定の列のみを考慮するようにします。\n重複判定の対象となる列を指定するには、コンマの後に列番号または列名を入力してください（これらはすべて duplicated() 関数の中で行ってください）。\nduplicated() の後には、必ずコンマ , を外側に置くようにしてください。\n例えば、2 列目から 5 列目の値のみ重複の評価をする場合は、df[!duplicated(df[, 2:5]),]\nまた、name と purpose の列の値のみ重複の評価をする場合は、df[!duplicated(df[, c(\"name\", \"purpose\")]),] のように書きます。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html#スライシング抽出",
    "href": "new_pages/deduplication.jp.html#スライシング抽出",
    "title": "15  重複データの排除",
    "section": "15.3 スライシング（抽出）",
    "text": "15.3 スライシング（抽出）\nデータフレームの「スライス」とは、行番号・位置によってデータにフィルタリングを適用し、指定した行を抽出することです。これは、グループごとに複数の行があり（例えば、一人の被調査者（“person”）に複数の調査記録があるなど）、そのうちの 1 つまたはいくつかだけを残したい場合に特に便利です。\n基本的な slice() 関数は、数値を受け取り、その数値で表された位置にある行を返します。指定された数値が正の値であれば、その値のみが返されます。負の値で指定された行は返されません。複数のすうを指定する場合は、数値はすべて正またはすべて負でなければなりません。\n\nobs %&gt;% slice(4)  # 4番目の行を返す\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n\n\nobs %&gt;% slice(c(2,4))  # 2番目と4番目の行を返す\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        1        1   adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n#obs %&gt;% slice(c(2:4))  # 2～4番目の行を返す\n\n元のデータセット と比較してみてください。\nslice() には、他にいくつかの応用的な関数があり、以下で紹介します。 このような関数を使用する際は、対象となる列を指定し、返す行の数を n = に書く必要があります。\n\nslice_min() と slice_max() は、指定した列の最小値や最大値を持つ行のみを保持します。これは、順序付き因子の “min”と “max”を返すのにも使えます。\n\nslice_head() と slice_tail() は、最初または最後の行のみを保持します。\n\nslice_sample() は、行をランダムに抽出します。\n\n\nobs %&gt;% slice_max(encounter, n = 1)  # 調査番号（encounter）で最大値を持つ行を返す\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n2       13        3 mariah 2020-01-06 08:32         3 contact            No\n3       16        5  brian 2020-01-07 07:59         3    case            No\n\n\n保持する行の数または割合を指定するには、引数 n = または prop = を使用します。この関数をパイプの中で使用しない場合は、第一引数にデータセットの名前を指定してください（例：slice(data, n = 2)）。詳細は ?slice を参照してください。\n他にも以下の引数が使用できます。\n.order_by = - slice_min() や slice_max() の中でスライスする前に順序付ける列を指定するのに使用されます。\nwith_ties = - デフォルトは TRUE で、関数の条件に該当する行が複数あった場合（「タイ（“ties”）」と呼ばれる状況）、そのすべての行が保持されます。\n.preserve = - デフォルトは FALSE です。TRUE の場合、スライス後にグループの構造が再計算されます。\nweight_by = - オプションで、重み付けのための数値列を指定します（数字が大きいほどサンプリングされる可能性が高い）。 また、サンプリングが復元・非復元で行われるかを示す replace = もあります。\nヒント： slice_max() や slice_min() を使用する際には、必ず n = を指定し記述してください（例：2 だけでなく、n = 2）。n = を指定せずか関数を実行すると、Error:…is not empty. というエラーが発生することがあります。\n注意：top_n()という関数を目にすることがあるかもしれませんが、これは各 slice 関数に取って代わられました。\n\n\nグループごとのスライス\nslice_*() をグループ化されたデータフレームに適用すると、スライス操作が各グループに対して個別に実行されるので、非常に便利です。group_by() と slice() という関数を併用してデータをグループ化し、各グループから行をスライス（抽出）します。\nこれは、被調査者（人）ごとに複数の記録（行）があり、そのうちの 1 つの記録（行）だけを残したい場合の重複排除に便利です。まず、グループ化に使用したい列を group_by() に指定し、次に異なる列でスライス関数を使用します。\n以下の例では、被調査者ごとに最新の調査記録のみを保持するために、name 列で行をグループ化し、date 列に n = 1 で slice_max() を使用します。slice_max() のような関数を日付に適用するには、適用される日付の列は日付型（Date）にあらかじめ変換されていなければならないことに注意してください。\nデフォルトでは、関数の条件に該当する行が複数あった場合（この例では最新の日付が複数ある場合）はすべての行が保持されるため、一部の被調査者（“adam” など）には複数の行が表示されてしまいます。これを避けるために、with_ties = FALSE とします。これにより、1 人につき 1 つの行のみが返されます。\n注意： arrange()を使用する場合は、.by_group = TRUE を指定すると、各グループごとにデータが並び替えられます。\n警告：with_ties = FALSE の 場合、条件に該当する複数行の最初の行が保持されます。わかりづらいかもしれませんが、例えば、Mariah（name 列が “mariah” である行）の場合には最新の日付 （1 月 6 日）で 2 つの調査記録があり、最初の調査記録（データフレームを上から見て一番最初に現れる記録）が保持されています。同じ日の後の方の記録を保持したい場合は、次の例（「タイ」を壊す）をご覧ください。\n\nobs %&gt;% \n  group_by(name) %&gt;%       # 行を name 列でグループ化\n  slice_max(date,          # グループごとに最大の日付の値を持つ行を保持 \n            n = 1,         # 最上位の行のみを残す \n            with_ties = F) # 同じ日付が複数ある場合、最初の列を残す\n\n\n\n\n\n\n\n上の例では、Amrish の記録（name 列が “amrish” である行）では 1 月 5 日の行だけ、また Brian の記録（name 列が “brian” である行）では 1 月 7 日の行だけが保持されています。元のデータセット と比較してみてください。\n「タイ」を壊す\n複数のスライス文を実行することで、「タイ（“ties”）を壊す」ことができます。上述の例では、最新の日付（date）に複数の調査記録がある場合、最新の時間（time）の調査記録が保持されます（文字型の時間を並べ替えるために、lubridate::hm() で time 型に変換しました）。\n以下のコマンドを実行すると、Mariah （name 列が “mariah” である行）の 1 月 6 日の行は、時間が07:25 の 2 回目の調査記録ではなく、08:32 の 3 回目の調査記録が残されたことに注意してください。\n\n# 「タイを壊す」ため、複数のスライスを使用する例\nobs %&gt;%\n  group_by(name) %&gt;%\n  \n  # まず、最新の日付でスライスする\n  slice_max(date, n = 1, with_ties = TRUE) %&gt;% \n  \n  # 次に、複数行が該当する場合は最新の時刻の行を選択する（タイは認められない）\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)\n\n\n\n\n\n\n\n上の例では、調査番号（encounter 列）の値でスライスすることも可能ですが、例として date 列と time 列でスライスしています。\nヒント：slice_max() や slice_min() を文字型（character）の列に使用する場合は、まずその列を順序付けられた因子型（factor）に変換する必要があります！\n元のデータセット と比較してみてください。\n\n\n\nすべてを残すが、目印をつける\nすべての記録を残しつつ、一部の記録だけを分析対象として目印をつけたい場合は、一意の recordID と 調査番号（encounter）を利用した 2 段階のアプローチを検討します。\n\n元のデータフレームから分析に必要な行だけをスライス（抽出）し、別のデータフレームとして保存する。\n\n元のデータフレームの一意の識別子（ここでは recordID）がステップ 1. で作成したデータフレームに存在するかどうか判定した列を、元のデータフレームに case_when() で新たに作成する。\n\n\n# 1. 分析のために保持する行をデータフレームとして定義する\nobs_keep &lt;- obs %&gt;%\n  group_by(name) %&gt;%\n  slice_max(encounter, n = 1, with_ties = FALSE) # 各被調査者の最新の調査番号（ encounter）のみを残す\n\n\n# 2. 元のデータフレームに目印をつける\nobs_marked &lt;- obs %&gt;%\n\n  # 新しい dup_record 列の作成\n  mutate(dup_record = case_when(\n    \n    # レコードが obs_keep のデータフレームにある場合\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # それ以外は、分析のために「無視（\"Ignore\"）」とマークする\n    TRUE                            ~ \"Ignore\"))\n\n# 出力\nobs_marked\n\n   recordID personID    name       date  time encounter purpose symptoms_ever\n1         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n3         2        2  amrish 2020-01-02 14:20         1 contact            No\n4         3        2  amrish 2020-01-02 14:20         1 contact            No\n5         4        3  mariah 2020-01-05 12:00         1    case            No\n6         5        2  amrish 2020-01-05 16:10         3    case           Yes\n7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes\n8         7        5   brian 2020-01-05 15:20         1 contact            No\n9         8        6   smita 2020-01-05 14:20         1 contact           Yes\n10        9        7  raquel 2020-01-05 12:30         1 contact          &lt;NA&gt;\n11       10        2  amrish 2020-01-02 10:24         2 contact           Yes\n12       11        1    adam 2020-01-05 09:40         2    case            No\n13       12        3  mariah 2020-01-06 07:25         2 contact            No\n14       13        3  mariah 2020-01-06 08:32         3 contact            No\n15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes\n16       15        5   brian 2020-01-06 15:31         2 contact           Yes\n17       16        5   brian 2020-01-07 07:59         3    case            No\n18       17        7  raquel 2020-01-07 11:13         2 contact            No\n19       18        8 natalie 2020-01-07 17:12         1    case            No\n     dup_record\n1        Ignore\n2        Ignore\n3        Ignore\n4        Ignore\n5        Ignore\n6  For analysis\n7        Ignore\n8        Ignore\n9  For analysis\n10       Ignore\n11       Ignore\n12 For analysis\n13       Ignore\n14 For analysis\n15 For analysis\n16       Ignore\n17 For analysis\n18 For analysis\n19 For analysis\n\n\n\n\n\n\n\n\n元のデータセット と比較してみてください。\n\n\n\n行の完全性の計算\n行の完全性（非欠損性）の指標を含む列を作成します。このような列は、重複排除やスライスの際に、どの行を他の行よりも優先させるかを決定する際に役立ちます。\n以下の例では、完全性を測定したい「キー（“key”）」となる列の列名を、ベクトルに保存します。\nそして、mutate() で key_completeness という新しい列を作成します。新しく作成された各行の値は、計算された割合として定義されます。各行、「キー（“key”）」とした列のうち欠落していない列の数を、「キー（“key”）」とした列の数で割ったものです。\nこれには base R の rowSums() が使われています。また、. も使われています。パイプの中で使用された . は、その時点でのデータフレームを参照します（この場合は角括弧 [ ] で囲んでサブセットされたデータ範囲）。\n右にスクロールすると、データフレームに含まれるすべての列を確認できます。\n\n# 「キー（\"key\"）」とする列をベクトルとして作成する\n# 結果を \"key_cols\" として指定された列のうち、値が欠損していない割合として表示する\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %&gt;% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) \n\n\n\n\n\n\n\n元のデータセットをご覧ください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html#str_rollup",
    "href": "new_pages/deduplication.jp.html#str_rollup",
    "title": "15  重複データの排除",
    "section": "15.4 ロールアップした値",
    "text": "15.4 ロールアップした値\nこのセクションでは、以下の項目について説明します。\n\n複数の行の値を 1 つの行に「ロールアップする（“roll-up”）」（まとめる）方法\n\n値をロールアップした後、各セルの値を上書き・優先させる方法\n\nこのタブでは、本章の「準備」セクションで作成したサンプルデータセットを使用します。\n\n\nロールアップした値を一列に並べる\n以下のコマンドでは、group_by() と summarise() を使って行を被調査者ごとにグループ化し、グループ化された行の中の一意な値を 1 つの行にすべて貼り付けています。このようにして、被調査者 1 人につき 1 つの要約行を作成できます。ここでは、要約行を作成する際のいくつかの注意点があります。\n\n新しく作成された列すべてに接尾辞を追加することができます（この例では “_roll”）。\n\nセルごとに一意の値だけを表示したい場合は、na.omit() を unique() で囲みます。\n\nna.omit() は NA 値を削除しますが、残したい場合は paste0(.x) を削除します。\n\n\n# 値を「personID」ごとに1行にロールアップ（まとめる）\ncases_rolled &lt;- obs %&gt;% \n  \n  # personID でグループ化\n  group_by(personID) %&gt;% \n  \n  # 各グループ内で行を並べ替え（例：日付順）\n  arrange(date, .by_group = TRUE) %&gt;% \n  \n  # グループ化された行のすべての値を、各列に \"; \" で区切って貼り付ける\n  summarise(\n    across(everything(),                           # すべての列に適用\n           ~paste0(na.omit(.x), collapse = \"; \"))) # 欠損値でない値を結合する関数\n\n結果として、グループ（personID）ごとに 1 つの行が作成され、日付で並べ替えられた値が貼り合わされます。右にスクロールすると、データフレームに含まれるすべての列を確認できます。\n\n\n\n\n\n\n元のデータセット と比較してみてください。\n次に、以下では、一意の値のみを表示します。\n\n# バリエーション - 一意の値のみを表示 \ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                                   # すべての列に適用\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # 欠損値でない値を結合する関数\n\n\n\n\n\n\n\nそして、各列に接尾辞を追加します。\nこの例では「_roll」と追加し、ロールアップされた（まとめられた）ことを表します。\n\n# バリエーション - 列名に接尾辞を追加 \ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # 列名に「_roll」を付加\n\n\n\n\n\n\n\n\n\n\n値と階層の上書き\nある列のロールアップされた値（まとめられた値）をすべて評価して、特定の値（例えば、「最も重要な値（“best”）」や「最大値｛“maximum”）」など）だけを残したい場合は、その列で mutate() を使用し、 stringr パッケージの str_detect() で文字列パターンを順に探し、セルの内容を上書きするように case_when() を使用します。\n\n# クリーンなケース\n#############\ncases_clean &lt;- cases_rolled %&gt;% \n    \n    # クリーンな Yes-No-Unknown 列: 文字列に存在する \"highest\" の値（最も重要な値）でテキストを置き換える\n    mutate(across(c(contains(\"symptoms_ever\")),                     # 指定された列を操作（Y/N/U）\n             list(mod = ~case_when(                                 # 新しい列に接尾辞 \"_mod\" を追加し、case_when() を実装\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # \"Yes\"が検出された場合、セルの値が \"Yes\" に変換される\n               str_detect(.x, \"No\")        ~ \"No\",                  # \"No \"が検出された場合、セルの値が \"No\" に変換される\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # \"Unknown\" が検出された場合、セルの値が \"Unknown\" に変換される\n               TRUE                        ~ as.character(.x)))),   # それ以外の場合はそのままの値とする\n      .keep = \"unused\")                                             # 古い列は削除し、_mod 列のみを残す\n\nこれで、symptoms_ever という列に、その人が症状に対して「Yes」と答えたことがある場合、「Yes」だけが表示されるようになりました。\n\n\n\n\n\n\n元のデータセット と比較してみてください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html#確率的重複排除",
    "href": "new_pages/deduplication.jp.html#確率的重複排除",
    "title": "15  重複データの排除",
    "section": "15.5 確率的重複排除",
    "text": "15.5 確率的重複排除\n名前、年齢、性別、生年月日などの複数の列にわたる類似性（文字列の「距離（どのくらい類似しているか）」など）に基づいて、重複している「可能性が高い」ものを特定したい場合があります。このような場合は、確率的マッチングアルゴリズム（probabilistic matching algorithm）を適用することが可能です。\n重複している可能性が高いものを特定する方法についての説明は、データの結合 の章を参照してください。「確率的マッチング」のセクションでは、確率的マッチングアルゴリズムを適用して、データフレームをそれ自体と比較し、確率的な重複排除を行う例を紹介しています。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.jp.html#参考資料",
    "href": "new_pages/deduplication.jp.html#参考資料",
    "title": "15  重複データの排除",
    "section": "15.6 参考資料",
    "text": "15.6 参考資料\n本章に掲載されている内容の多くは、以下の資料やウェブサイトを参考に作成されました。\ndatanovia\ndplyr tidyverse reference\ncran janitor vignette",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>重複データの排除</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.jp.html",
    "href": "new_pages/iteration.jp.html",
    "title": "16  ループと反復処理・リストの操作",
    "section": "",
    "text": "16.1 準備",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ループと反復処理・リストの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.jp.html#準備",
    "href": "new_pages/iteration.jp.html#準備",
    "title": "16  ループと反復処理・リストの操作",
    "section": "",
    "text": "パッケージを読み込む\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n     rio,         # インポート・エクスポートのためのパッケージ\n     here,        # ファイルの場所の指定のためのパッケージ\n     purrr,       # 反復処理のためのパッケージ\n     grates,      # scales in ggplot\n     tidyverse    # データ管理と視覚化のためのパッケージ\n)\n\n\n\nデータをインポートする\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストをインポートする\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nラインリストの始めの 50 行は、以下の通りです。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ループと反復処理・リストの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.jp.html#for-ループ",
    "href": "new_pages/iteration.jp.html#for-ループ",
    "title": "16  ループと反復処理・リストの操作",
    "section": "16.2 for ループ",
    "text": "16.2 for ループ\n\nR における for ループ\nfor ループは R ではあまり一般的ではありませんが、他のプログラミング言語では頻繁に使用されています。初心者の方にとって、for ループは反復処理ごとに何が起こっているのかを正確に把握しやすく、コードの確認やデバッグがしやすいため、反復処理の学習や練習に役立ちます。\nfor ループを扱うこのセクションを飛ばして、purrr パッケージでマッピングした関数を使用し反復処理を行う方法を紹介する 16.3 purrr とリスト に移動しても構いません。\n\n\n中心となる要素\nfor ループは以下の 3 つの主要な部分から成り立っています。\n\n繰り返し実行するアイテムのシーケンス\nシーケンス内の各アイテムに対して実行されるオペレーション\n結果を格納するコンテナ （必須ではなく、必要な場合のみ作成する）\n\n以下に示しているように、基本的な構文は for (アイテム in シーケンス) {アイテムを用いたオペレーションの指示}です。括弧と波括弧の違いに注意してください。結果は、コンソールに出力したり、コンテナに格納したりすることができます。\n簡単な for ループの例を以下に示します。\n\nfor (num in c(1,2,3,4,5)) {  # シーケンスの定義（1 から 5 の数）と \"{\" によるループの開始\n  print(num + 2)             # オペレーション（それぞれのシーケンス内の数に 2 を足して表示してください）\n}                            # \"}\" によるループの終了                            \n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n\n                             # この例では、結果をコンテナに格納していない\n\n\n\nシーケンス\nこれは、for ループにおいて “for” で示されている部分です。オペレーションはシーケンス内の各アイテムに対して（“for” each item）実行されます。シーケンスには、一連の値（管轄区名、疾患名、列名、リスト要素など）や、一連の連続した数値（1, 2, 3, 4, 5 など）を指定することができます。以下で説明するように、それぞれに実用性があります。\nシーケンス文の基本構造は、アイテム in ベクトルです．\n\n「アイテム」の部分には任意の文字や単語を書くことができます（例：“i”, “num”, “hosp”, “district” など）。この「アイテム」の値は、ループを繰り返すたびにベクトル内の各値に、指定された順番で変化していきます。\nベクトルには、文字列や列名、あるいは数字列などを用いることが出来ます。ループを繰り返すたびに変化していく値であり、これらの値は、「アイテム」を用いたオペレーションの指示により、「for ループ」 の中で使用されます。\n\n例：文字列のシーケンス\nこの例では、あらかじめ病院名の文字ベクトルを定義し、その各値に対してループを実行します。\n\n# 病院名のベクトルを作成する\nhospital_names &lt;- unique(linelist$hospital)\nhospital_names # 作成したベクトルを表示する\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n[6] \"Central Hospital\"                    \n\n\nここでは、hospital_names の値を、hosp という単語を使って示しています。一番最初に実行されるループでは、hosp の値は hospital_names[[1]] 、2 回目のループでは hospital_names[[2]] となります。\n\n# 文字列シーケンスに対する 'for ループ'\n\nfor (hosp in hospital_names){       # シーケンス\n  \n       # オペレーションがここに来る\n  }\n\n例：列名のシーケンス\nこれは、上記の文字列のシーケンスの変形で、既存の R オブジェクトの名前（例えば、データフレームの列名など）を抽出してベクトルとしたシーケンスです。便利なことに、for ループのオペレーションコードでは、列名を用いて元のデータフレームを指定する（サブセットする）ことが出来ます。\n下の例では、linelist データフレームの names()（列名）がシーケンスです。「アイテム」の名前は col で、ループが繰り返すに従い、その表す値が各列名に変化します。\n例として、for ループの中に、シーケンスの値ごとに実行されるオペレーションを加えます。この例では、シーケンスの値（列名）を使って、linelist の列名を一つずつ指定して（サブセットして）います。オペレーションコードでは、R の基礎 の章で説明したように、二重角括弧 [[ ]] を使用してサブセットします。そして、ループにより指定された列は is.na()、次に sum() に渡され、列内の欠損値の数を算出します。結果として、コンソールに欠損値の数が各列ごとに表示されます。\n列名を用いてインデックスする場合の注意点：列自体を指定したいときには、 単に “col” と書いてはいけません！ col は、単に列の名前を表しています。列内の値全体を指定するには、linelist[[col]] と書いて列名を linelist のインデックスとして使用する必要があります。\n\nfor (col in names(linelist)){        # linelist内の各列に対するループ：列名は \"col\" で表されている\n  \n  # オペレーションコードの例：各列の欠損地の数を表示する \n  print(sum(is.na(linelist[[col]])))  # \"col\"の値は反復処理の繰り返しごとに変化し、linelist は \"col\" のその時々の値によってインデックスされる\n     \n}\n\n[1] 0\n[1] 0\n[1] 2087\n[1] 256\n[1] 0\n[1] 936\n[1] 1323\n[1] 278\n[1] 86\n[1] 0\n[1] 86\n[1] 86\n[1] 86\n[1] 0\n[1] 0\n[1] 0\n[1] 2088\n[1] 2088\n[1] 0\n[1] 0\n[1] 0\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 149\n[1] 765\n[1] 0\n[1] 256\n\n\n例：数字のシーケンス\n次は、連続した数字の列をシーケンスとして用いる例を説明します。「アイテム」の値は文字値（“Central Hospital” や “date_onset” など）ではなく数字となり、データフレームをループする際に便利です。for ループ内で「アイテム」の番号を使うことで、データフレームを行番号でインデックスすることができます。\n例えば、データフレーム内のすべての行をループして、ある情報を抽出したい場合、「アイテム」は行番号になります。この場合、「アイテム」は i と書かれることが多いです。\nfor ループの処理を言葉で説明すると、「1 からデータフレームの行の総数までの数からなるシーケンス内のすべてのアイテムに対して、X を行う」となります。一番最初に実行されるループでは、「アイテム」i の値は 1 です。2 回目のループでは、i は 2 になります。\nこのシーケンスをコードにすると、次のようになります：for (i in 1:nrow(linelist)) {#オペレーションのコード}。i は「アイテム」を表し、1:nrow(linelist) は、1 から linelist の総行数までの連続した数字からなるシーケンスを表しています。\n\nfor (i in 1:nrow(linelist)) {  # データフレームに対して使用\n  # オペレーションのコードがここに来る\n}  \n\nシーケンスを数字にしたいが、（データフレームではなく）ベクトルを用いる場合は、 seq_along() を使うことで、ベクトルの各要素に対する添字のシーケンスを得ることが出来ます。例えば、for (i in seq_along(hospital_names) {#オペレーションのコード} とします。\n以下のコードによって添字を得ることができ、その添字がループの i の値になります。\n\nseq_along(hospital_names)  # 名前のついているベクトルに対して使用\n\n[1] 1 2 3 4 5 6\n\n\nシーケンスに添字を使うと、ループの出力結果を格納するコンテナのインデックスとして、i 番号を簡単に使用できるという利点があります。詳しくは、次のオペレーションのセクションで例を示して説明します。\n\n\nオペレーション\nオペレーションは、for ループの中の波括弧 { } の中に記述されているコードのことです。オペレーションコードは、シーケンス内の各「アイテム」ごとに実行される必要があります。したがって、「アイテム」によって変化するコードの各部分が、実際に変化するように正しくコードされているか注意する必要があります。例えば、インデックスには [[ ]] を使うことを忘れないでください。\n以下の例では、linelist データフレームの各行に対して反復処理を実行します。各行の gender と age の値を結合し、文字ベクトルのコンテナである cases_demographics に格納する作業を行います。また、[[i]] を使ってインデックスすることで、ループの出力結果を「コンテナ」のベクトルの正しい位置に保存しているところもポイントです。\n\n# 結果を格納するコンテナを作成する：文字ベクトル\ncases_demographics &lt;- vector(mode = \"character\", length = nrow(linelist))\n\n# for ループ\nfor (i in 1:nrow(linelist)){\n  \n  # オペレーション\n  # 角括弧をインデックスに用いることで、linelist の i 行の値を取り出す\n  row_gender  &lt;- linelist$gender[[i]]\n  row_age     &lt;- linelist$age_years[[i]]    # インデックスを忘れずに！\n     \n  # genderとageを結合し、コンテナのベクトル内のインデックスされた場所に格納する\n  cases_demographics[[i]] &lt;- str_c(row_gender, row_age, sep = \",\") \n\n}  # ループの終了\n\n\n# 最初の 10 行を表示する\nhead(cases_demographics, 10)\n\n [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\"\n\n\n\n\nコンテナ\nfor ループの結果はコンソールに表示したり、RStudio プロットペインに出力したりすることができます。また、後で使用するためにループの実行結果を「コンテナ」に保存しておきたい場合もあります。出力を保存するコンテナとして、ベクトル、データフレーム、あるいはリストなどを使用することが出来ます。\n出力結果を保存するコンテナは、for ループを開始する前に、データが何も入っていない空のベクトル、データフレーム、またはリストを作成するのが最も効率的です。空のコンテナは、ベクトルやリストの場合は vector() で、データフレームの場合は matrix() や data.frame() を使用して作成することができます。\n空のベクトルを作成する\nvector() を使用し、ループの出力結果を挿入するオブジェクトの想定されるデータ型を mode = で指定します（数値データを格納する “double”、“character”、または “logical”のいずれかを指定）。また、事前に length = を指定する必要があります。これは、for ループのシーケンスの長さになります。\n例えば、各病院の入院までの時間の中央値を格納したいとします。その場合、“double” を使用し、予想される出力数（ここではデータセット内の病院の数）を length として設定します。\n\ndelays &lt;- vector(\n  mode = \"double\",                            # 数値データを格納する\n  length = length(unique(linelist$hospital))) # データセット内の病院の数\n\n空のデータフレームを作成する\n下のコードのように、行と列の数を指定することで、空のデータフレームを作ることができます。\n\ndelays &lt;- data.frame(matrix(ncol = 2, nrow = 3))\n\n空のリストを作成する\nfor ループで作成した図（プロット）をリストに格納したい場合は、空のリストを作成します。リストとベクトルは似ていますが、リストは複数の異なるデータ型の R オブジェクトを格納することが出来ます。リストの中のアイテムは、数値、データフレーム、ベクトル、を取ることができることのほか、別のリストを取ることもできます。\n空のリストを作成する際には、ベクトルを作成した時と同じように vector() を使用しますが、mode = \"list\" とする必要があります。長さは好きなように指定してください。\n\nplots &lt;- vector(mode = \"list\", length = 16)\n\n\n\nコンテナを使用せず結果を表示する\nなお、for ループ内で出力結果を表示する場合は、print() で指示する必要があります。\n以下の例では、シーケンスは文字ベクトルであり、これを使用して病院ごとにラインリストをサブセットしています。結果はコンテナには保存されず、print() によってコンソールに出力されています。\n\nfor (hosp in hospital_names){ \n     hospital_cases &lt;- linelist %&gt;% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}\n\n[1] 885\n[1] 1469\n[1] 422\n[1] 1762\n[1] 896\n[1] 454\n\n\n\n\nfor ループの動作確認を行う\n意図したようにループが動作するか確認するために、i &lt;- 10 や hosp &lt;- \"Central Hospital\" など、「アイテム」を一時的に代入するコマンドを実行します。これをループの外で行い、その後、オペレーションコードのみ（波括弧内のコード）を実行し、期待通りの結果が得られるかを確認します。\n\n\nプロットをループする\n前述した 3 つの要素（コンテナ、シーケンス、オペレーション）をすべて使用し、各病院の流行曲線（エピカーブ）を作成してみましょう（流行曲線についての詳細は、流行曲線（エピカーブ） の章をご覧ください）。\nまず、incidence2 パッケージを使用し、すべての症例を性別ごとに色分けした流行曲線を作成します。\n\n# 'incidence' のオブジェクトを作成する\noutbreak &lt;- incidence2::incidence(   \n     x = linelist,                   # データフレームを指定する（linelist全体）\n     date_index = \"date_onset\",      # 日付の列\n     interval = \"week\",              # 週ごとに集計\n     groups = \"gender\")              # 性別によるグルーピング\n     #na_as_group = TRUE)            # 性別の欠損値は欠損のグループ（NA）として扱う\n\n# 流行曲線をプロットする\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # Fill colour of bars by gender\n       color = \"black\"      # Contour colour of bars\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n\n\n\n\n\n\n\n\n次に、各病院ごとに個別のプロットを作成するためには、この流行曲線のコードを for ループの中に入れる必要があります。\nfor ループを作成する最初のステップとして、病院名の入ったベクトル hospital_names を保存します。作成するfor ループは、病院の名前ごとに、各病院一度だけ実行されます：for (hosp in hospital_names)。hosp の値は、for ループが繰り返されるたびに、ベクトル内のそれぞれの病院名を表し、ループ内で使用されます。\nループ内では、通常通り R のコードを書くことができますが、「アイテム」（この場合は hosp）の値が変化することに注意してください。このループ内では、\n\n列 hospital が hosp の値と同じになるように、linelist に filter() を適用しています。\nincidence オブジェクトは、フィルタリングされたラインリストに対して作成されています。\nプロットには、各病院ごとに hosp を用いたタイトルが自動生成されます。\n病院ごとに作成された各プロットは、一時的に保存され、そして表示されます。\nループは次の繰り返しを実行し、hospital_names 内の次の病院に対して同じオペレーションが繰り返されます。\n\n\n# 病院名が格納されたベクトルを作成する\nhospital_names &lt;- unique(linelist$hospital)\n\n# hospital_names 内のそれぞれの病院名（\"hosp\"）ごとに、流行曲線を作成し表示する\nfor (hosp in hospital_names) {\n     \n     # 反復処理ごとにその時々の病院に対して incidence オブジェクトを作成する\n     outbreak_hosp &lt;- incidence2::incidence(\n          x = linelist %&gt;% filter(hospital == hosp),   # 現在反復処理が行われている病院名によって linelist をフィルタリングする\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\"#,\n          #na_as_group = TRUE\n     )\n     \n     # プロットを作成し保存する\n     # タイトルは現在反復処理が行われている病院名に合わせて自動生成される\n     plot_hosp &lt;- ggplot(outbreak_hosp, # incidence object name\n                         aes(x = date_index, #axes\n                             y = count, \n                             fill = gender), # fill colour by gender\n                         color = \"black\"      # colour of bar contour\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #title\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # With older versions of R, remove the # before na_as_group and use this plot command instead.\n    # plot_hosp &lt;- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     # 現在反復処理が行われている病院のプロットを表示する\n     print(plot_hosp)\n     \n} # hospital_names 内の全ての病院名に対してオペレーションが行われた後、for ループを終了する \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nループの進捗状況を確認する\n反復回数の多いループは、実行終了までに何分、何時間もかかることがあるため、進捗状況を R のコンソールに表示すると便利です。以下の if 文をループのオペレーションの中に配置することで、100 番目の数字ごとに結果を表示することができます。コード内で用いる際には、i が自分の作成したループ内の「アイテム」となるように適宜変更してください。\n\n# 進捗を 100 回の反復処理のたびに示すループ\nfor (i in seq_len(nrow(linelist))){\n\n  # print progress\n  if(i %% 100==0){    # 演算子 %% は剰余を示す\n    print(i)\n\n}",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ループと反復処理・リストの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.jp.html#iter_purrr",
    "href": "new_pages/iteration.jp.html#iter_purrr",
    "title": "16  ループと反復処理・リストの操作",
    "section": "16.3 purrr とリスト",
    "text": "16.3 purrr とリスト\n反復処理のもう一つの方法として、purrr パッケージを使用する方法があります。purrr パッケージは tidyverse パッケージに含まれている反復処理を行うパッケージです。\n同じタスクを何度も実行する必要がある場合、汎用性の高い方法を習得していると非常に便利です。この方法は、複数の管轄区域のプロットを作成する際や、多くのファイルをインポートして結合する際などに多くの場面で用いることができます。\npurrr パッケージには他にもいくつか利点があり、パイプ %&gt;% と一緒に使用できること、通常の for ループよりもエラー処理に優れていること、そして構文が非常にすっきりとしてシンプルであること、などが挙げられます。もし for ループを使っているのであれば、purrr パッケージを使うことでより明確で簡潔にコードを書くことができるでしょう。\nコードを書く際は、purrr パッケージが関数型のプログラミングツールであることを念頭に置いて進める必要があり、繰り返し適用されるオペレーションは、関数内に示す必要があります。関数を書く方法について詳細を知りたい方は、関数の作成 の章をご覧ください。\nまた、purrr パッケージに含まれる関数は、多くの場合リストとベクトルに対して働くので、リストやベクトルの各要素に関数を適用すると考えてください！\n\nパッケージを読み込む\npurrr パッケージは tidyverse パッケージの一部なので、別々にパッケージをインストールする・読み込む必要はありません。\n\npacman::p_load(\n     rio,            # インポート・エクスポート\n     here,           # ファイルパス\n     tidyverse,      # データの管理と視覚化\n     writexl,        # 複数のシートを含むExcelファイルを作成\n     readxl          # 複数のシートを含むExcelファイルをインポート\n)\n\n\n\nmap()\npurrr パッケージの中核となる関数の一つが map() です。map()は、与えられたリストやベクトルの各インプット要素に関数を「マッピング（mapping）」する（適用する）関数です。\n基本的な構文は map(.x = シーケンス, .f = 関数, その他の引数) です。もう少し詳しく説明すると、\n\n.x = は、.f 関数が繰り返し適用されるインプットであり、例えば、管轄区名のベクトル、データフレームの列、またはデータフレームのリストです。\n.f = は、入力 .x の各要素に対して適用される関数です。これは、すでに存在する print() のような関数でも、自分で定義したカスタム関数でも構いません。関数は、チルダ（~）の後に書かれることが多いです（詳細は後述します）。\n\n構文を作成する際は、以下の点についてご注意ください。\n\n関数がそれ以上引数を指定する必要がない場合は、括弧やチルダを使わずに書くことができます（例：.f = mean）。全ての反復処理において同じ値になる引数がある場合、map() の中、かつ .f = の外で指定します（例：map(.x = my_list, .f = mean, na.rm = T) の na.rm = T）。\n.x（または単に.）は、反復処理の .x 値の代用値として、.f = 関数の中で使用することができます。\n関数をより細かく設定するには、チルダ構文（~）を使用してください。関数を、括弧を用いて通常通り書いてください（例: map(.x = my_list, .f = ~mean(., na.rm = T))）。特に、引数の値が反復処理ごとに変化する場合や、値が .x 自体である場合には、この構文を使用してください（以下の例を参照ください）。\n\nmap() を用いた際の出力はリストになります。リストはベクトルに似ていますが、構成要素が異なります。リストには、多くのデータフレーム、多くのベクトル、多くの単一の値、あるいは多くのリストが含まれる可能性があります。以下に説明するように、他のタイプの出力を生成する map() の代替関数があります（例えば、データフレームを生成する map_dfr()、文字ベクトルを生成する map_chr()、数字ベクトルを生成する map_dbl() など）。\n\n例：エクセルシートをインポートし、結合する\n疫学業務担当者の一般的なタスクを用いて説明します。例えば、症例データの入った Excel ファイルをインポートしたいが、ファイルには異なる名前シートが複数含まれており、その複数のシートに分かれて症例データが保存されている場合です。どうすれば複数のシートを効率的にインポートして 1 つのデータフレームにまとめることができるでしょうか？\n以下のような Excel ファイルが送られてきたとします。病院ごとにシートが分かれており、各シートにはそれぞれの病院の症例が含まれています。\n\n\n\n\n\n\n\n\n\nここでは、map() を使った方法を紹介します。\n\nimport() を、各エクセルシートごとに実行するように map() する。\nインポートされた複数のデータフレームを bind_rows() を使用して結合し、一つのデータフレームにまとめる。\n一つにまとめる際、元の Excel シートの名前を新しい列に保存する。最終的なデータフレームで、各行の症例が、元々はどの Excel シートに保存されていたのか（どの病院で報告されたのか）をわかるようにする。\n\nまず、シート名を抽出してオブジェクトに格納する必要があります。readxl パッケージの excel_sheets() にエクセルファイルのパスを渡し、シート名を抽出します。抽出されたシート名は、sheet_names という文字ベクトルに格納されます。\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\n各シートの名前は、以下の通りです。\n\nsheet_names\n\n[1] \"Central Hospital\"              \"Military Hospital\"            \n[3] \"Missing\"                       \"Other\"                        \n[5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\n\n\nこれでシート名を格納したベクトルができたので、map() を用いて import() に 1 つずつ病院の名前を渡すことができます。この例では、sheet_names が .x であり、import() が .f となります。\nインポートとエクスポート の章で説明したように、Excel ファイルで import() を使用する場合、引数 which = を用いてインポートするシートを指定することができます。map() の .f 関数に import() を使用し、 import() 内で which = .x と指定すると、反復処理を繰り返すたびに、ベクトル sheet_names の表す値が変化します。反復処理の最初の 1 回目では “Central Hospital” 、2 回目には “Military Hospital” となります。\n注意点としては、map() を使用しているので、各 Excel シートのデータは、別々のデータフレームとしてリスト内に保存されることです。各リスト要素（リスト内に保存される各データフレーム）に適切な名前を付けるために、sheet_names を map() に渡す前に、purrr パッケージの set_names() に渡しています。\n反復処理で作成されるリストは combined という名前で保存されます。\n\ncombined &lt;- sheet_names %&gt;% \n  purrr::set_names() %&gt;% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\n\n反復処理後に出力されたリストを確認すると、各 Excel シートのデータが名前付きリストに保存されていることがわかります。ここまで順調ですが、まだ完成形ではありません。\n\n\n\n\n\n\n\n\n\n最後に、dplyr パッケージの bind_rows() を使用します。これは、互いに似たような構造をもつ複数のデータフレームが含まれたリストを受け取り、それらを 1 つのデータフレームに結合する関数です。リスト要素の名前（この例では、病院名）から新しい列を作成するために、引数 .id = を使用して新しい列に必要な名前を指定します。\n以下が一連のコマンドの流れです。\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # シート名を抽出する\n \ncombined &lt;- sheet_names %&gt;%                                     # シート名から開始\n  purrr::set_names() %&gt;%                                        # 名前を指定\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %&gt;%  # 反復処理を行い、インポートし、リストに保存する\n  bind_rows(.id = \"origin_sheet\") # データフレームのリストを結合し、新しい列に元データのシート名を保存する  \n\nこれで元のシート名が保存された列を含むデータフレームができました！\n\n\n\n\n\n\n\n\n\nmap() には様々なバリエーションがあります。例えば、map_dfr() はリストではなく、データフレームを返します。そのため、上記のタスクに使用する場合、bind_rows() を使用して行を結合する必要はありません。しかし、各症例がどのシート（病院）のものかは把握できません。\nmap() には他にも、map_chr() や map_dbl() があり、次の 2 つの理由から非常に便利な関数だと言えます。第一に、反復処理の出力を（リストではなく）ベクトルに自動的に変換してくれます。第二に、データがどのような形式で返ってくるかを指定することが出来ます。map_chr() では文字ベクトル、map_dbl() では数値ベクトルとしてデータが戻ってきます。詳細は、本章で後詳します！\nまた、 map_at() と map_if() も反復処理を行う際に非常に便利な関数です。map_at() を使用する場合はインデックス・名前のベクトルを、map_if() を使用する場合は論理条件（logical test）を適用するだけで、リストのどの要素を反復処理するかを指定することができます。\n例えば、前述の各病院の症例データについて、1 枚目のシートをインポートしたくない場合を考えてみましょう。この場合、map() の代わりに map_at() を使用し、.at = の引数に c(-1) を指定します。これは、インプット .x の最初の要素を使用しないことを意味します。また、.at = に正の数のベクトルや名前を指定して、使用する要素を指定することもできます。\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined &lt;- sheet_names %&gt;% \n     purrr::set_names() %&gt;% \n     # 1枚目のシートは除く\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))\n\n1 枚目のシート名が出力リストの要素として表示されますが、これは単なる文字名（データフレームではない）になっています。行を結合する前には、この要素を削除する必要があります。リストの要素を削除したり変更したりする方法については、本章で後述します。\n\n\n\nデータセットを分割しエクスポートする\n以下では、一つのデータセットを複数のデータセットに分割し、分割されたデータセットを map() の反復処理を使用してそれぞれ別々の Excel シートまたは CSV ファイルとしてエクスポートする方法を例示します。\n\nデータを分割する\n例えば、複数の病院から報告された症例を含んだデータフレーム linelist があり、報告元の病院ごとに個別のラインリストを作成し、それぞれを個別の CSV ファイルとしてエクスポートしたい場合、次のような手順で行います。\ndplyr パッケージの group_split() を使用して、データフレーム linelist を hospital 列内の値で分割します。これにより、病院別のデータフレームからなるリストが出力されます。\n\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital)\n\nView(linelist_split) を実行すると、このリストは 6 つのデータフレーム（“tibbles”）からなり、それぞれのデータフレームが各病院で報告された症例を含んでいることがわかります。\n\n\n\n\n\n\n\n\n\nただし、リスト内のデータフレームには、デフォルトでは名前が付いていないことに注意してください！次のステップでは、それぞれのデータフレームに名前を付け、CSV ファイルでエクスポートする際にはその名前を使うようにしていきます。\n名前を抽出する方法として、dplyr パッケージの pull() を使用し、リストの各データフレームから hospital 列を抽出する方法があります。次に、エラーが起こらないように念のため、抽出された値を文字に変換し、unique() を使用してデータフレームの名前（ここでは、病院名）を抽出します。そして、これらのすべてのステップを map() によって各データフレームに適用します。\n\nnames(linelist_split) &lt;- linelist_split %&gt;%   # リスト化されたデータフレームの名前を指定する \n     # それぞれのデータフレームに以下の関数を適用することで、名前を抽出する \n     map(.f = ~pull(.x, hospital)) %&gt;%        # hospital 列を取り出す\n     map(.f = ~as.character(.x)) %&gt;%          # 取り出した値を、念のため、文字に変換する\n     map(.f = ~unique(.x))                    # 病院名を抽出する\n\nこれで、リストの各要素に名前を付けることができました。付けられた名前は、 names(linelist_split) を実行すると確認できます。\n\n\n\n\n\n\n\n\n\n\nnames(linelist_split)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Missing\"                             \n[4] \"Other\"                               \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\n\n2 つ以上の列を用いた group_split()\n例えば、病院と性別の組み合わせでラインリストを分割するなど、複数の列（変数）によってラインリストを分割したい場合は、リストの要素に名前を付ける方法が異なります。この場合は、まず、dplyr パッケージの group_keys() を使用し、病院と性別の組み合わせすべてに対して「グループキー」を作成します（グループキーは、データフレームとして作成されます）。そして、二列に渡って作成されたグループキーを、以下のように unite() を使用して一つの値に結合し、結合した組み合わせ名を linelist_split に割り当てます。\n\n# ラインリストを病院と性別のすべての組み合わせによって分割する\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital, gender)\n\n# グループキーをデータフレームとして抽出する\ngroupings &lt;- linelist %&gt;% \n     group_by(hospital, gender) %&gt;%       \n     group_keys()\n\ngroupings      # グループキーを表示する \n\n# A tibble: 18 × 2\n   hospital                             gender\n   &lt;chr&gt;                                &lt;chr&gt; \n 1 Central Hospital                     f     \n 2 Central Hospital                     m     \n 3 Central Hospital                     &lt;NA&gt;  \n 4 Military Hospital                    f     \n 5 Military Hospital                    m     \n 6 Military Hospital                    &lt;NA&gt;  \n 7 Missing                              f     \n 8 Missing                              m     \n 9 Missing                              &lt;NA&gt;  \n10 Other                                f     \n11 Other                                m     \n12 Other                                &lt;NA&gt;  \n13 Port Hospital                        f     \n14 Port Hospital                        m     \n15 Port Hospital                        &lt;NA&gt;  \n16 St. Mark's Maternity Hospital (SMMH) f     \n17 St. Mark's Maternity Hospital (SMMH) m     \n18 St. Mark's Maternity Hospital (SMMH) &lt;NA&gt;  \n\n\n以下のコードでは、それぞれの組み合わせをダッシュで結合し、それを linelist_split のリスト要素の名前に割り当てます。まず、NA を “Missing” に置き換え、次に、dplyr パッケージの unite() を使って列の値をダッシュで結合します。そして、無名のベクトルに変換し、linelist_split のリスト要素の名前として使えるようにします。\n\n# 一つの名前の値に結合する \nnames(linelist_split) &lt;- groupings %&gt;% \n     mutate(across(everything(), replace_na, \"Missing\")) %&gt;%  # 全ての列において NA を \"Missing\" に置き換える\n     unite(\"combined\", sep = \"-\") %&gt;%                         # 全ての列の値を一つに結合する\n     setNames(NULL) %&gt;% \n     as_vector() %&gt;% \n     as.list()\n\n\n\n\nExcel シートとして出力する\nwritexl パッケージの write_xlsx() に各リスト要素に名前が付いた linelist_split を渡すことで、シートごとに 1 つの病院のラインリストを含んだ Excel ファイルとして出力することができます。write_xlsx() は、複数のシートからなる Excel ファイルをエクスポートする機能があり、リスト要素の名前が各シートの名前として自動的に適用されます。\n\nlinelist_split %&gt;% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))\n\nExcel ファイルを開くと、症例がデータが病院ごとに複数のシートに分割されて保存されているのが確認できます。\n\n\n\n\n\n\n\n\n\n\n\nCSVファイルとして出力する\n少し複雑になりますが、それぞれの病院個別のラインリストを、CSV ファイルとして出力することもできます。ファイルの名前をそれぞれの病院の名前として出力します。\n今回も map() を使用します。前述したように、リスト要素の名前（病院名）が含まれたベクトルを map() に渡し、linelist_split リスト内の要素（データフレーム）に rio パッケージの export() を繰り返し適用します（export() についての詳細は、インポートとエクスポート の章をご覧ください）。また、リスト要素の名前は、エクスポートする各 CSV ファイルのファイル名として使用します。以下に、CSV ファイルとして出力する方法を示します。\n\nまず、病院の名前が含まれた文字値ベクターを .x として map() に与えます\n.f 関数を export() とし、エクスポートするデータフレームとエクスポート先となるファイルパスを指定します\n入力された .x（病院名）は .f の中において、linelist_split リスト内のインデックスとなります。反復処理が繰り返すたびに一つのデータフレームが export() に渡されます。\n例えば、“Military Hospital” の症例データに対して map() が適用されている時は、linelist_split[[.x]] は実際には linelist_split[[\"Military Hospital\"]] となり、 linelist_split の 2 番目のリスト要素（“Military Hospital” の全章例を含むデータフレーム）が返されます。\nexport() で指定するファイルパスには、 str_glue() を使用して各病院名を適用します（str_glue() に関する詳細は、文字型・文字列型データ の章を参照ください）。\n\nファイルパスの起点、および “data” フォルダを特定するために here() を用います（str_glue() 内で使用されている二重引用符に影響がないように、一重引用符を使用していることに注意してください）。\n\nexport() で指定するファイルパス内には、here() を使用した後に / と .x を記載し、各病院名がファイル名になるようにします\n最後に、export() によって CSV ファイルが作成されるように拡張子 “.csv” を記します\n\n\nnames(linelist_split) %&gt;%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))\n\nこれで、それぞれのファイルが R プロジェクト “Epi_R_handbook” の “data” フォルダ内に保存されました！\n\n\n\n\n\n\n\n\n\n\n\n\nカスタム関数\nmap() に渡す関数を自分で作成したい場合はどうするのでしょうか。\n例えば、それぞれの病院ごとに、その病院の全症例を含む流行曲線を作成したいとします。これを purrr パッケージを用いて行うには、.f 関数を ggplot() にし、+ を使用して通常通り拡張することができます。map() は常にリストを出力するため、作成されたプロットもリストとして保存されます。リストに保存されたプロットは、 ggpubr パッケージの ggarrange() を使用して抽出し、プロットすることができます（ggpubr パッケージの公式ドキュメントは、こちら をご覧ください）。\n\n# リストから要素をプロットするためのパッケージを読み込む\npacman::p_load(ggpubr)\n\n# 6つの病院の 「名前」のベクトルに対してマッピングする（すでに作成済）\n# ggplot 関数を用いる\n# 出力は6つの ggplots を含むリストとなる\n\nhospital_names &lt;- unique(linelist$hospital)\n\nmy_plots &lt;- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %&gt;% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# リストとして保存されている ggplots を表示する\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\n上で紹介した map() コードが複雑すぎる場合、ggplot() を用いて作成したコードを自分で定義するカスタム関数として使用しても、同様の結果を得ることができます。例えば、その関数を make_epicurve()) と名付け、map() 内で使用することができます。その場合、.x は反復処理の繰り返しごとにそれぞれの病院名となり、make_epicurve() 内では hosp_name として使用されます。関数を作成する手順について詳しく知りたい方は、関数の作成 の章を参照してください。\n\n# 関数を作成する\nmake_epicurve &lt;- function(hosp_name){\n  \n  ggplot(data = linelist %&gt;% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n\n\n# 作成した関数をマッピングする\nmy_plots &lt;- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# リストとして保存されている ggplots を表示する\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\n複数列に対して関数をマッピングする\nその他に頻繁に用いられる例としては、複数の列に対して同じ関数をマッピングする場合、が挙げられます。以下では、linelist データフレーム内の数値列に対して t.test() を map() し、性別で数値を比較していきます。\n簡単な統計的検定 の章で学んだことを思い出してください。t.test() は、 t.test(文字列 ~ バイナリ変数の列) のような数式形式のインプットを扱うことができることを学びましたね。この例では、以下のことを行います。\n\n比較したい数値列を、linelist から選びます。これらは、map() に対してのインプット .x になります\nt.test() は、.f 関数として、選択されたそれぞれの数値列に対して適用されます\nt.test() のカッコ内は、\n\n最初の チルダ（~ ）は .f に先行し、.x に対して map() が反復処理を行うことを意味します\n.x は反復処理の繰り返しの際に t.test() に適用される列を表します\n2つ目のチルダ（~）は、上で説明した通り、t 検定の数式の一部です\nt.test() は、チルダ（~）の右側にバイナリ変数の列をあてます。ここでは linelist$gender というベクトルをあてています（select() に gender を含まないように注意してください）\n\nmap() はリストを返すので、反復処理の終了後、t 検定の結果を示すリストが出力され、一つのリスト要素がそれぞれの数値列の結果を表します。\n\n\n# 結果はリストとして保存される\nt.test_results &lt;- linelist %&gt;% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %&gt;%  # マッピングしたい数字列だけを選択する\n  map(.f = ~t.test(.x ~ linelist$gender))        # t.test() は、数字値 ~ カテゴリ値で表される数式と用いる\n\nRStudio では、t.test_results は以下のように表示されます。重要なポイントとして、\n\n一番上に全てのリストを束ねる t.test_results と名づけられたリストがあるのが確認できます。これは、5 つの要素からなり、それぞれの要素は linelist から選択され gender での t 検定に用いられた変数名と同じく age, wt_km, ht_cm, ct_blood, temp と名付けられています。\n\n5 つの要素それぞれはリストであり、p.value や conf.int といった要素を含んでいます。これらの要素のうち、p.value などは単一の値である一方、estimate などは 2 つ以上の要素（mean in group f と mean in group m）を含んでいます。\n\n\n\n\n\n\n\n\n\n\n注釈：データフレーム内の特定の列にのみ関数を適用したい場合、データクリーニングと主要関数 の章で説明したように、mutate() と across() を使用すると簡単にできます。以下に、“age” の列にだけ as.character() を適用させる例を示します。括弧とコンマの位置に注意してください。\n\n# 列名に \"age\" を含む列を文字変数に変換する\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  \n\n\n\nリストから抽出する\nmap() はアウトプットをリストとして出力するので、purrr パッケージに含まれる関数を用いてリストからデータを抽出する方法について少し説明します。前のセクションで作成した t.test_results リストを例として使用します。t.test_results リストは、5 つのリストからなるリストです。5 つのリストには、linelist データフレームのいくつかの変数とバイナリ変数である gender との間の t 検定の結果がそれぞれ保存されています。リスト構造の図は前のセクションをご覧ください。\n\n要素の名前を抽出する\nリスト内の要素の名前を抽出するには、base R の names() を使うと簡単にできます。今回は、names() を t.test_results に適用することでそれぞれのサブリスト名（t 検定に用いられた変数の名前）を抽出します。\n\nnames(t.test_results)\n\n[1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\"    \n\n\n\n\n名前または位置によって要素を特定する\nR の基礎 の章で説明したように、 [[ ]] を用いると、リストの要素を名前、または位置で抽出することができます。以下では、二重括弧を t.tests_results リストに用いてインデックスし、age に対する t 検定の結果（リストの最初の要素）を表示しています。\n\nt.test_results[[1]] # 位置で最初の要素を特定\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\nt.test_results[[1]][\"p.value\"] # 最初の要素内の \"p.value\" という名前の要素を返す  \n\n$p.value\n[1] 2.350374e-96\n\n\nさらに、より簡単で柔軟性の高い方法として、purrr パッケージの map() と pluck() を使用し、同様の結果を抽出する方法を以下で説明していきます。\n\n\npluck()\npluck() はリスト内の要素を名前もしくは位置で抽出することができます。例えば、年齢に対する t 検定の結果を抽出するには pluck() を以下のように使用します。\n\nt.test_results %&gt;% \n  pluck(\"age\")        # 代わりに pluck(1) とすることもできる\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\n\nさらに下の階層を抽出するには、コンマを使います。以下の例では、t.test_results というリスト内の age というリストの要素である “p.value” を抽出しています。文字ではなく、数字を代わりに用いることもできます。\n\nt.test_results %&gt;% \n  pluck(\"age\", \"p.value\")\n\n[1] 2.350374e-96\n\n\nまた、リスト内のすべての最上階層から、より下の階層にある要素を抽出するには、map() を用いて pluck() をそれぞれの最上階層の要素に適用させるとできます。例えば、以下のコードでは t.test_results リストに含まれるすべてのサブリストから “p.value” という要素を抽出しています。この場合、t.test_results は反復処理対象となる .x であり、pluck() は反復される関数である .f であり、“p-value” はその関数に対して適用されています。\n\nt.test_results %&gt;%\n  map(pluck, \"p.value\")   # リストに含まれるすべての p 値を返す\n\n$age\n[1] 2.350374e-96\n\n$wt_kg\n[1] 2.664367e-182\n\n$ht_cm\n[1] 3.515713e-144\n\n$ct_blood\n[1] 0.4473498\n\n$temp\n[1] 0.5735923\n\n\n他の方法として、map() で要素の名前を引用符をつけて示し、それを抽出する方法があります。map() を利用する場合はアウトプットがリストで出力されますが、map_chr() を用いる場合は名前付きの文字ベクトルとして出力され、map_dbl() を用いる場合は名前付きの数字ベクトルとして出力されます。\n\nt.test_results %&gt;% \n  map_dbl(\"p.value\")   # すべての p 値を名前付きの数値ベクトルとして返す\n\n          age         wt_kg         ht_cm      ct_blood          temp \n 2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01 \n\n\npluck() の詳細は、purrr パッケージの 公式ドキュメント をご覧ください。chuck() という関数もあり、chuck() は要素が存在しなければ NULL ではなくエラーを返します。\n\n\n\nリストをデータフレームに変換する\nこれは少し複雑な内容のため、より網羅的に学びたい方は、本章の最後に記載されている参考資料を参照してください。ここでは、前のセクションでリストとして出力された t 検定の結果（t.test_results）をデータフレームに変換する方法を説明します。p 値の列と 2 つのグループ（男性と女性）それぞれの平均値の列を含むデータフレームを作成していきます。\n方法と使用する関数を示します：\n\ntibble （データフレームのようなもの）を作成するため、tibble() を使います\n\nt.test_results 全体が tibble の最初の列として保存されないように、tibble() を波括弧でくくります\n\ntibble() 内では、それぞれの列が明示的に作成されるので、mutate() で列を作成する方法に似ています。\n\n以下のコードでは、. は t.test_results を表しています\n列名を t 検定で用いた変数名（それぞれのリスト要素の名前）にしたい場合は、前述したように names() を使用します\n列名を p 値にしたい場合は、前述したように map_dbl() を用いて p.value の要素を抽出し、数字ベクトルに変換します\n\n\n\nt.test_results %&gt;% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }\n\n# A tibble: 5 × 2\n  variables         p\n  &lt;chr&gt;         &lt;dbl&gt;\n1 age       2.35e- 96\n2 wt_kg     2.66e-182\n3 ht_cm     3.52e-144\n4 ct_blood  4.47e-  1\n5 temp      5.74e-  1\n\n\n今回は、さらにそれぞれのグループ（男性と女性）の平均値の列を追加していきます。\nこの場合、estimate という要素を抽出したいのですが、問題はその中に 2 つの要素 （mean in group f と mean in group m）が含まれていることです。そのため、map_chr() や map_dbl() を用いてベクターに変換することはできません。その代わり、tibble() 内で map() を用いることで tibble 内にリスト要素の列を作成することができます！\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}\n\n# A tibble: 5 × 3\n  variables         p means       \n  &lt;chr&gt;         &lt;dbl&gt; &lt;named list&gt;\n1 age       2.35e- 96 &lt;dbl [2]&gt;   \n2 wt_kg     2.66e-182 &lt;dbl [2]&gt;   \n3 ht_cm     3.52e-144 &lt;dbl [2]&gt;   \n4 ct_blood  4.47e-  1 &lt;dbl [2]&gt;   \n5 temp      5.74e-  1 &lt;dbl [2]&gt;   \n\n\nリスト要素の列が一度できると、このような「入れ子構造内のリスト要素の列」を「外に取り出す（“rectangle” または “un-nest”）」のに役立つ tidyr パッケージの関数がいくつかあります（tidyr パッケージは tidyverse パッケージに含まれている）。詳しくは、このページ を参照するか、vignette(\"rectangle\") を実行してください。簡単に述べると、\n\nunnest_wider()：リスト要素の列のそれぞれの要素を、列として外に出します\nunnest_longer()：リスト要素の列のそれぞれの要素を、行として外に出します\nhoist()：unnest_wider() と似ていますが、どの要素を入れ子構造の外に出すか指定する必要があります\n\n以下では、unnest_wider() に t.test_results という tibble を渡し、tibble 内の入れ子になっているリスト要素である means 列を指定しています。その結果、means はもともとそれぞれの means のセル内の値であった要素からなる 2 つの列に変換されました。\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %&gt;% \n  unnest_wider(means)\n\n# A tibble: 5 × 4\n  variables         p `mean in group f` `mean in group m`\n  &lt;chr&gt;         &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 age       2.35e- 96              12.7              19.6\n2 wt_kg     2.66e-182              45.8              59.6\n3 ht_cm     3.52e-144             109.              142. \n4 ct_blood  4.47e-  1              21.2              21.2\n5 temp      5.74e-  1              38.6              38.6\n\n\n\n\nリストを捨てる・保持する・コンパクトにする\npurrr パッケージの関数はリストを扱うことが多いため、リストを変換するのに用いられる purrr パッケージの関数をいくつか簡単に説明します。purrr パッケージに含まれる関数について、より詳しい内容を知りたい方は、本章の最後に記載されている参考資料をご覧ください。\n\nlist_modify() にはいくつか用途がありますが、例えばリストの要素を取り除く、といった場合に使用されます\n\nkeep() は、引数 .p = で指定された要素、もしくは .p = に与えられた関数が TRUE となる要素を保持（キープ）します\n\ndiscard() は、引数 .p = で指定された要素、もしくは .p = に与えられた関数が TRUE となる要素を取り除きます\n\ncompact() は、全ての空の要素を取り除きます\n\nそれでは、map() を使用して複数のファイルをインポートし結合した 例：エクセルシートをインポートし、結合する で作成したリストである combined（6 つのデータフレームを含むリスト）を用いて例を示します。\nリスト内の要素を要素名の名前で取り除きたい場合は、list_modify() で取り除きたい要素名を NULL に指定することで取り除くことができます。\n\ncombined %&gt;% \n  list_modify(\"Central Hospital\" = NULL)   # リスト要素を名前で取り除く\n\nまた、何かの基準を指定して要素を取り除くこともできます。その場合は、「述語」方程式（TRUE か FALSE を判定する方程式）を .p = に渡します。チルダ（~）を関数の前に用い、リスト要素を表す .x を用います。keep() を使用し、TRUE と判定されたリスト要素を保持します。逆に、TRUE と判定されたリスト要素を取り除きたい場合は、discard() を使用してください。以下に例を示します。\n\n# 500行以上を含むリスト要素のみを保持する\ncombined %&gt;% \n  keep(.p = ~nrow(.x) &gt; 500)  \n\nもう一つの例として、データフレームではない要素を取り除くコードを以下に紹介します。\n\n# データフレームではないリスト要素を取り除く\ncombined %&gt;% \n  discard(.p = ~class(.x) != \"data.frame\")\n\nまた、述語方程式にそれぞれのリスト内の要素や列を含めることもできます。以下の例では、ct_blood 列の平均値が 25 よりも大きいリスト要素を取り除いています。\n\n# ct_blood 列の平均値が 25 以上のリスト要素を取り除く\ncombined %&gt;% \n  discard(.p = ~mean(.x$ct_blood) &gt; 25)  \n\nすべての空の列を取り除きたい場合は、以下のコードを実行してください。\n\n# 全ての空の列を取り除く\ncombined %&gt;% \n  compact()\n\n\n\npmap()\nこのセクションは、作成中です。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ループと反復処理・リストの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.jp.html#apply-関数",
    "href": "new_pages/iteration.jp.html#apply-関数",
    "title": "16  ループと反復処理・リストの操作",
    "section": "16.4 Apply 関数",
    "text": "16.4 Apply 関数\npurrr パッケージの代わりに、base R に含まれている種々の “apply” 系の関数を使用して反復処理を行うこともできます。詳しくは、こちら をご覧ください。",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ループと反復処理・リストの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.jp.html#参考資料",
    "href": "new_pages/iteration.jp.html#参考資料",
    "title": "16  ループと反復処理・リストの操作",
    "section": "16.5 参考資料",
    "text": "16.5 参考資料\nData Carpentry の for loops に関するページ\nThe R for Data Science の iteration に関するページ\nExcel ファイルのインポート・エクスポートについて\njennybc による purrr の チュートリアル\nRebecca Barter による purrr の チュートリアル\nmap, pmap, and imap についての purrr の チュートリアル\npurrr のチートシート\npurrr の役立つヒント\nkeep と discard 関数について",
    "crumbs": [
      "データマネジメント",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ループと反復処理・リストの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html",
    "href": "new_pages/tables_descriptive.jp.html",
    "title": "17  記述統計表の作り方",
    "section": "",
    "text": "17.1 準備",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#準備",
    "href": "new_pages/tables_descriptive.jp.html#準備",
    "title": "17  記述統計表の作り方",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについては R の基礎の章を参照してください。\n\npacman::p_load(\n  rio,          # ファイルインポート\n  here,         # ファイルロケータ\n  skimr,        # データの概要を把握\n  tidyverse,    # データ管理とggplot2描画\n  gtsummary,    # 要約統計量と検定\n  rstatix,      # 要約統計量と統計的検定\n  janitor,      # 表に合計値とパーセンテージを追加\n  scales,       # 割合をパーセンテージに簡単に変換\n  flextable     # 表をきれいな画像に変換\n  )\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストをインポート\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nlinelist の最初の 50 行を以下に表示します。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#データを閲覧する",
    "href": "new_pages/tables_descriptive.jp.html#データを閲覧する",
    "title": "17  記述統計表の作り方",
    "section": "17.2 データを閲覧する",
    "text": "17.2 データを閲覧する\n\nskimr パッケージ\nskimrパッケージを使用すると、データセット内の各変数の概要を、詳細かつ見た目にわかりやすいで把握することができます。 skimr の詳細については、 github ページをご覧ください。\n以下では、関数 skim() を linelist データフレーム全体に適用しています。データフレームの概要とすべての列の概要が（データ型別に）生成されます。\n\n## データセット内の各変数の情報を取得\nskim(linelist)\n\n\n\n\nData summary\n\n\nName\nlinelist\n\n\nNumber of rows\n5888\n\n\nNumber of columns\n30\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n4\n\n\nfactor\n2\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n0\n1.00\n6\n6\n0\n5888\n0\n\n\noutcome\n1323\n0.78\n5\n7\n0\n2\n0\n\n\ngender\n278\n0.95\n1\n1\n0\n2\n0\n\n\nage_unit\n0\n1.00\n5\n6\n0\n2\n0\n\n\nhospital\n0\n1.00\n5\n36\n0\n6\n0\n\n\ninfector\n2088\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2088\n0.65\n5\n7\n0\n2\n0\n\n\nfever\n249\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n249\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n249\n0.96\n2\n3\n0\n2\n0\n\n\naches\n249\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n249\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n765\n0.87\n5\n5\n0\n1072\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_infection\n2087\n0.65\n2014-03-19\n2015-04-27\n2014-10-11\n359\n\n\ndate_onset\n256\n0.96\n2014-04-07\n2015-04-30\n2014-10-23\n367\n\n\ndate_hospitalisation\n0\n1.00\n2014-04-17\n2015-04-30\n2014-10-23\n363\n\n\ndate_outcome\n936\n0.84\n2014-04-19\n2015-06-04\n2014-11-01\n371\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nage_cat\n86\n0.99\nFALSE\n8\n0-4: 1095, 5-9: 1095, 20-: 1073, 10-: 941\n\n\nage_cat5\n86\n0.99\nFALSE\n17\n0-4: 1095, 5-9: 1095, 10-: 941, 15-: 743\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n0\n1.00\n16.56\n5.79\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nage\n86\n0.99\n16.07\n12.62\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nage_years\n86\n0.99\n16.02\n12.64\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nlon\n0\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n0\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nwt_kg\n0\n1.00\n52.64\n18.58\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n0\n1.00\n124.96\n49.52\n4.00\n91.00\n129.00\n159.00\n295.00\n\n\nct_blood\n0\n1.00\n21.21\n1.69\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n149\n0.97\n38.56\n0.98\n35.20\n38.20\n38.80\n39.20\n40.80\n\n\nbmi\n0\n1.00\n46.89\n55.39\n-1200.00\n24.56\n32.12\n50.01\n1250.00\n\n\ndays_onset_hosp\n256\n0.96\n2.06\n2.26\n0.00\n1.00\n1.00\n3.00\n22.00\n\n\n\n\n\nデータセット全体の情報を得るために、ベース R にある summary() を使用することもできますが、この出力は skimr を使用した場合よりも読みづらくなる可能性があります。そのため、ページスペースを倹約するため下記の結果は表示していません。\n\n## データセットの各列の情報を取得 \nsummary(linelist)\n\n\n\n要約統計量\nベース R を使い、数値列の要約統計量を得ることができます。以下のように summary() を使用すると、数値列の有用な要約統計量の殆どを得ることができます。データフレーム名を以下のように指定しなければならないことにも注意してください。\n\nsummary(linelist$age_years)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.02   23.00   84.00      86 \n\n\nインデックスブラケット [ ]で特定の一部分にアクセスして保存することができます。:\n\nsummary(linelist$age_years)[[2]]            # 2番目の要素のみを取得\n\n[1] 6\n\n# 同様に、要素名による指定も可能\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \n\nmax()、 min()、 median()、mean()、 quantile()、 sd()、および range() などの ベース の関数を使って、個々の統計量を得ることができます。統計量の全リストは R の基礎 章を参照してください。.\n注意: R ではデータに欠測値が含まれている場合、そのことを知らせるために NA を表示します。欠測値を無視したい場合は、統計量の関数を指定する際に引数 na.rm = TRUE を指定します。.\nrstatix gtsummaryの get_summary_stats() を使用すると データフレーム形式 で要約統計量を取得できます。これは、それ以降の演算を行ったり、数値をプロットするのに役立ちます。rstatix パッケージとその関数の詳細については、 簡単な統計的検定 章を参照してください。\n\nlinelist %&gt;% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # 計算をする行\n    type = \"common\")                    # 利用する要約統計量を指定\n\n# A tibble: 5 × 10\n  variable     n   min   max median   iqr  mean     sd    se    ci\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#tbl_janitor",
    "href": "new_pages/tables_descriptive.jp.html#tbl_janitor",
    "title": "17  記述統計表の作り方",
    "section": "17.3 janitor パッケージ",
    "text": "17.3 janitor パッケージ\njanitor パッケージには集計表やクロス集計表を作成するために tabyl() があり、ヘルパー関数を利用して「加工」したり、変更したりすることでパーセンテージ、割合、カウント数などを表示などを行えます。\n以下では linelist データフレームを janitor パッケージの関数にパイプ演算子で渡し、結果を表示しています。必要に応じて、代入演算子 &lt;-を使って結果のテーブルを保存することもできます。\n\ntabyl のシンプルな使い方\nデフォルトでは、特定の行に対して tabyl() を使用すると、ユニークな値、カウント数、および行ごとの「パーセンテージ」（実際には割合）が生成されます。割合は桁数が多く表示されるかもしれません。後述する adorn_rounding() を使うことで小数部分の桁数を調整できます。\n\nlinelist %&gt;% tabyl(age_cat)\n\n age_cat    n     percent valid_percent\n     0-4 1095 0.185971467   0.188728025\n     5-9 1095 0.185971467   0.188728025\n   10-14  941 0.159816576   0.162185453\n   15-19  743 0.126188859   0.128059290\n   20-29 1073 0.182235054   0.184936229\n   30-49  754 0.128057065   0.129955188\n   50-69   95 0.016134511   0.016373664\n     70+    6 0.001019022   0.001034126\n    &lt;NA&gt;   86 0.014605978            NA\n\n\n上図のように、欠測値がある場合は行に &lt;NA&gt;と記載されて表示されます。show_na = FALSEと指定すると、表示されなくなります。 欠測値がない場合は、この行が表示されることはありません。欠測値がある場合、割合は、すべての列（分母に NA 数を含む）と「実際の数」（分母に NA 数を含まない）に対しての両方で表示されます。\n列が因子型で、データに特定のレベルしか存在しない場合でも、すべてのレベルが表に表示されます。この機能をオフにするには、 show_missing_levels = FALSE と指定します。詳細は 因子（ファクタ）型データ 章を参照してください。\n\n\nクロス集計表\nクロス集計表のカウント数は tabyl() 内で 1 つ以上の列を追加することで実現できます現在はカウント数のみが表示されていますが、割合やパーセントは以下の手順で追加できます。\n\nlinelist %&gt;% tabyl(age_cat, gender)\n\n age_cat   f   m NA_\n     0-4 640 416  39\n     5-9 641 412  42\n   10-14 518 383  40\n   15-19 359 364  20\n   20-29 468 575  30\n   30-49 179 557  18\n   50-69   2  91   2\n     70+   0   5   1\n    &lt;NA&gt;   0   0  86\n\n\n\n\ntabyl を 「加工する」\njanitor パッケージの adorn() 関数を使用して、合計値を加算したり、割合やパーセントに変換したり、その他の方法で表示を調整します。多くの場合、これらの関数のいくつかに tabyl をパイプ演算子で渡します。\n\n\n\n\n\n\n\n関数\n説明\n\n\n\n\nadorn_totals()\n合計値を追加 （where = “row”、“col”、または “both”）。name = を “Total” と指定。\n\n\nadorn_percentages()\ndenominator =を “row”、“col”、または “all” と指定してカウント数を割合に変換する。\n\n\nadorn_pct_formatting()\n割合をパーセントに変換。 digits =で小数点桁数を指定する。“%” 記号を削除する場合は affix_sign = FALSEと指定する。\n\n\nadorn_rounding()\n割合を丸めるには、 digits = で小数点桁数を指定する。パーセントを丸めるにはadorn_pct_formatting() を用い、digits =で小数点桁数を指定する。\n\n\nadorn_ns()\n割合あるいはパーセントの表にカウント数を追加する。パーセントの後にカウント数を括弧内に表示する場合は position = “rear” （後ろの意味）、カウント数の後にパーセントを括弧内に表示する場合はposition = “front”（前の意味）とそれぞれ位置を指定する。\n\n\nadorn_title()\n引数 row_name = および/または col_name =で文字列を追加する。\n\n\n\n上記の関数を利用する場合には、その順序を意識してください。以下に例を示します。\nデフォルトの割合の代わりにパーセントを使用したシンプルな一元表（one-way table）です。\n\nlinelist %&gt;%               # 症例ラインリスト\n  tabyl(age_cat) %&gt;%       # 年齢カテゴリごとにカウント数と割合の表を作成\n  adorn_pct_formatting()   # 割合をパーセントに変換\n\n age_cat    n percent valid_percent\n     0-4 1095   18.6%         18.9%\n     5-9 1095   18.6%         18.9%\n   10-14  941   16.0%         16.2%\n   15-19  743   12.6%         12.8%\n   20-29 1073   18.2%         18.5%\n   30-49  754   12.8%         13.0%\n   50-69   95    1.6%          1.6%\n     70+    6    0.1%          0.1%\n    &lt;NA&gt;   86    1.5%             -\n\n\n行合計と行パーセントのクロス集計表です。\n\nlinelist %&gt;%                                  \n  tabyl(age_cat, gender) %&gt;%                  # 年齢と性別のカウント数\n  adorn_totals(where = \"row\") %&gt;%             # 行合計を追加\n  adorn_percentages(denominator = \"row\") %&gt;%  # カウント数を割合に変換\n  adorn_pct_formatting(digits = 1)            # 割合をパーセントに変換\n\n age_cat     f     m    NA_\n     0-4 58.4% 38.0%   3.6%\n     5-9 58.5% 37.6%   3.8%\n   10-14 55.0% 40.7%   4.3%\n   15-19 48.3% 49.0%   2.7%\n   20-29 43.6% 53.6%   2.8%\n   30-49 23.7% 73.9%   2.4%\n   50-69  2.1% 95.8%   2.1%\n     70+  0.0% 83.3%  16.7%\n    &lt;NA&gt;  0.0%  0.0% 100.0%\n   Total 47.7% 47.6%   4.7%\n\n\nカウント数とパーセントの両方が表示されるように調整したクロス集計表です。\n\nlinelist %&gt;%                                  # 症例ラインリスト\n  tabyl(age_cat, gender) %&gt;%                  # カウント数についてのクロス集計\n  adorn_totals(where = \"row\") %&gt;%             # 行合計を追加\n  adorn_percentages(denominator = \"col\") %&gt;%  # 割合に変換\n  adorn_pct_formatting() %&gt;%                  # パーセントに変換\n  adorn_ns(position = \"front\") %&gt;%            # \"count (percent)\"となるように表示を変更\n  adorn_title(                                # タイトルを調整\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\n\n\ntabyl の出力\nデフォルトでは、tabyl は R のコンソールに生データを出力します。\nほかに、tabyl を flextable などのパッケージに渡して、RStudio ビューアで「きれいな」画像として出力し、.png、.jpeg、.html などの形式でエクスポートすることもできます。 これについては 見やすい表の作り方 章で説明しています。この方法で出力して adorn_titles() を使用する場合は、 placement = \"combined\" を指定する必要があることに注意してください。\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% # 画像として出力するためにこれは必要\n  flextable::flextable() %&gt;%    # きれいな画像に変換\n  flextable::autofit()          # 1行ごとにフォーマット\n\nAge Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1,095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1,095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%)941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%)743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1,073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%)754 (12.8%)50-692  (0.1%)91  (3.2%)2  (0.7%)95  (1.6%)70+0  (0.0%)5  (0.2%)1  (0.4%)6  (0.1%)0  (0.0%)0  (0.0%)86 (30.9%)86  (1.5%)\n\n\n\n\n他の表での使用\njanitor パッケージの adorn_*() は、 dplyr パッケージの summarise() や count()、 base R の table() で作成した表など、他の表でも使用できます。必要な janitor パッケージの関数を表をパイプ関数に渡すだけです。例えば、以下のようになります。\n\nlinelist %&gt;% \n  count(hospital) %&gt;%   # dplyrパッケージの関数\n  adorn_totals()        # janitorパッケージの関数\n\n                             hospital    n\n                     Central Hospital  454\n                    Military Hospital  896\n                              Missing 1469\n                                Other  885\n                        Port Hospital 1762\n St. Mark's Maternity Hospital (SMMH)  422\n                                Total 5888\n\n\n\n\ntabyl の保存\nflextableのようなパッケージを使って表を「きれいな」画像に変換すると、そのパッケージの関数、例えば save_as_html(), save_as_word(), save_as_ppt(), およびsave_as_image() を使って表を保存できます (詳しくは 見やすい表の作り方 の章で説明します)。以下では、表を Word 文書として保存し、さらに手作業で編集できるようにします。\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% \n  flextable::flextable() %&gt;%                     # 画像に変換\n  flextable::autofit() %&gt;%                       # 1行のみであることを確認\n  flextable::save_as_docx(path = \"tabyl.docx\")   # ファイルパスでWordドキュメントとして保存\n\n\n\n\n\n\n\n\n\n\n\n\n統計量\nstatsパッケージの chisq.test() や fisher.test() のように、以下のように tabyls に統計的検定を用いることができます。欠測値は許容されないため、show_na = FALSE で tabyl から除外されることに注意してください。\n\nage_by_outcome &lt;- linelist %&gt;% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)\n\n\n    Pearson's Chi-squared test\n\ndata:  age_by_outcome\nX-squared = 6.4931, df = 7, p-value = 0.4835\n\n\n統計に関する詳しいコードやヒントは 簡単な統計的検定 の章をご覧ください。\n\n\nその他のヒント\n\n上記の計算から欠測値を除外するには、引数 na.rm = TRUE を指定します。\ntabyl() で作成されていない表に adorn_*() ヘルパー関数を用いる場合、 adorn_percentage(,,,c(cases,deaths)) のように、特定の列を指定することができます（4 番目の指定していなかった引数にそれらを指定します）。この構文は単純ではありません。代わりに summarise() の使用を検討してください。\n詳しくは janitor ページ and this tabyl ヴィネットをご一読ください.",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#dplyr-パッケージ",
    "href": "new_pages/tables_descriptive.jp.html#dplyr-パッケージ",
    "title": "17  記述統計表の作り方",
    "section": "17.4 dplyr パッケージ",
    "text": "17.4 dplyr パッケージ\ndplyr パッケージは、 tidyverse パッケージの一部であり、とても一般的なデータ管理ツールです。summarise() や count() といった dplyr パッケージの関数による表作成は、要約統計量の計算、グループ ごとの要約、 または ggplot() への表出力をする際に便利な方法です。\nsummarise() は、新しい要約データフレーム を作成します。データが グループ化されていない 場合は、データフレーム全体に対して指定された要約統計量を 1 行のデータフレームとして作成します。データがグループ化されている場合は、新しいデータフレームはグループごとに 1 行が作成されます（ データのグループ化 の章を参照）。\nsummarise() の括弧の中に、それぞれの新しい要約列の名前、等号、適用する統計関数を記入します。\nヒント: summarise 関数は、UK と US の両方のスペルで動作します（summarise() および summarize()）。\n\nカウント数の取得\nsummarise() 内で適用する最もシンプルな関数は n() です。括弧を空にすると、行数がカウントされます。\n\nlinelist %&gt;%                 # linelistで開始\n  summarise(n_rows = n())    # n_rows列の新しい要約データフレームを取得\n\n  n_rows\n1   5888\n\n\nあらかじめデータをグループ化しておくと、さらに面白いことができます。\n\nlinelist %&gt;% \n  group_by(age_cat) %&gt;%     # age_cat列のユニークな値でデータをグループ化\n  summarise(n_rows = n())   # *グループごと* に行数を返す\n\n# A tibble: 9 × 2\n  age_cat n_rows\n  &lt;fct&gt;    &lt;int&gt;\n1 0-4       1095\n2 5-9       1095\n3 10-14      941\n4 15-19      743\n5 20-29     1073\n6 30-49      754\n7 50-69       95\n8 70+          6\n9 &lt;NA&gt;        86\n\n\n上記のコマンドは、代わりに count() を使うと短縮できます。count() は次のような処理を行います。:\n\n与えられた列によってデータをグループ化する\nそれらを n() でまとめる（ n列を作る）\nデータのグループ化解除\n\n\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\nname =に指定すると、カウントする列の名前をデフォルトの n から別の名前に変更できます。\n2 つ以上のグループ化された列のカウント数を集計する場合も、カウント数を n 列に入れた「縦」形式で返されます。「縦」および「横」データ形式については、 データの縦横変換 の章を参照してください。\n\nlinelist %&gt;% \n  count(age_cat, outcome)\n\n   age_cat outcome   n\n1      0-4   Death 471\n2      0-4 Recover 364\n3      0-4    &lt;NA&gt; 260\n4      5-9   Death 476\n5      5-9 Recover 391\n6      5-9    &lt;NA&gt; 228\n7    10-14   Death 438\n8    10-14 Recover 303\n9    10-14    &lt;NA&gt; 200\n10   15-19   Death 323\n11   15-19 Recover 251\n12   15-19    &lt;NA&gt; 169\n13   20-29   Death 477\n14   20-29 Recover 367\n15   20-29    &lt;NA&gt; 229\n16   30-49   Death 329\n17   30-49 Recover 238\n18   30-49    &lt;NA&gt; 187\n19   50-69   Death  33\n20   50-69 Recover  38\n21   50-69    &lt;NA&gt;  24\n22     70+   Death   3\n23     70+ Recover   3\n24    &lt;NA&gt;   Death  32\n25    &lt;NA&gt; Recover  28\n26    &lt;NA&gt;    &lt;NA&gt;  26\n\n\n\n\nすべてのレベルを表示\n因子 型の列を表にする場合、 summarise() または count() コマンドに .drop = FALSE を追加して指定することで、データ内の値を持つレベルだけでなく、すべて のレベルが表示されるようにすることができます。\nこの手法は、表やグラフを標準化するのに有効です。例えば、複数のサブグループのために数値を作成している場合や、ルーチンレポートのために数値を繰り返し作成している場合などです。これらの状況のいずれにおいても、データ内の値の存在は変動する可能性がありますが、一定に保たれるレベルを定義できます。\n詳しくは 因子（ファクタ）型データ の章をご覧ください。\n\n\n割合\n割合を追加するには、表を mutate() にパイプ演算子に渡して新しい列を作成します。新しい列は、カウントする列（デフォルトではn ）をカウントする列の sum() で割ったものとして定義します（割合が計算されます）。\nこの場合、 mutate() 中のsum() コマンドは、割合の分母として使用しているために、列全体の n を合計していることに注意してください。データのグループ化 の章で説明したように、**もし* グループ化された データの中で sum() が使われた場合（例えば mutate() の直後に group_by() コマンドが使われた場合）は、グループごとの合計が得られます。先に述べたように、 count() は グループ化を解除する と結果は変わります。つまり、その場合は、すべての列に対する割合が計算されます。\nパーセント（%）を表示させるには、scales パッケージの percent() で割合（注：(n / sum (n)のこと）を囲むことで簡単に行えます（文字列型へ変換することに注意してください）。\n\nage_summary &lt;- linelist %&gt;% \n  count(age_cat) %&gt;%                     # 性別によるグループ化とカウント（\"n\"列を生成）\n  mutate(                                # 列のパーセントの作成 - 分母に注意\n    percent = scales::percent(n / sum(n))) \n\n# 出力\nage_summary\n\n  age_cat    n percent\n1     0-4 1095  18.60%\n2     5-9 1095  18.60%\n3   10-14  941  15.98%\n4   15-19  743  12.62%\n5   20-29 1073  18.22%\n6   30-49  754  12.81%\n7   50-69   95   1.61%\n8     70+    6   0.10%\n9    &lt;NA&gt;   86   1.46%\n\n\n以下は、グループ内の割合を計算する方法です。異なるレベルのデータのグループ化を適用したり削除したりを順番に行っていきます。まず、データは group_by() で outcome を指定することでグループ化されます。次に、count() を適用します。この関数は、データをage_cat でさらにグループ化し、各結果と outcome-age-cat の組み合わせのカウント数を取得します。重要なことは、count() は処理を終えると同時に、age_cat によるグループ化を解除するので、残ったデータのグループ化は元の結果によるグループ化のみになるということです。つまり、割合を計算する最後のステップ（分母 sum(n)）では outcomeによってグループ化されたままということになります。\n\nage_by_outcome &lt;- linelist %&gt;%                  # linelistから開始\n  group_by(outcome) %&gt;%                         # 転帰でグループ化\n  count(age_cat) %&gt;%                            # age_catでグループ化してカウント後、age_catのグループ化を解除\n  mutate(percent = scales::percent(n / sum(n))) # パーセントの算出 - 分母が結果グループごとであることに注意\n\n\n\n\n\n\n\n\n\nプロット\n上記のような「縦」の表出力を ggplot() で表示するのは、比較的簡単です。データは当然 「縦」持ち形式であり、ggplot() はそれを受け入れることができます。ggplot の基礎 と ggplot のヒント の章でさらに例をご覧ください。\n\nlinelist %&gt;%                      # linelistから開始\n  count(age_cat, outcome) %&gt;%     # グループ化して2列で集計\n  ggplot()+                       # ggplotに新しいデータフレームを渡す\n    geom_col(                     # 棒グラフの作成\n      mapping = aes(   \n        x = outcome,              # X軸にoutcomeをマッピング\n        fill = age_cat,           # fill に age_catをマッピング（age_catで色分け）\n        y = n))                   # カウント列\"n\"を高さにマッピング\n\n\n\n\n\n\n\n\n\n\n要約統計量\ndplyr パッケージの summarise() の大きな利点は、 median()、mean()、max()、min()、sd()（標準偏差）、パーセンタイルなどのより高度な要約統計量を取得できることです。また、 sum() を使って、特定の論理的条件を満たす行の数を取得することもできます。上記のように、データフレームセット全体、またはグループごとにこうした出力を行うことができます。\n構文は同じで、 summarise() の括弧の中に、新しい各要約列の名前、等号、適用する統計関数を指定します。統計関数の中では、操作する列と関連する引数を指定します（例：殆ど数学関数では na.rm = TRUE ）。\nまた、sum() を使って、論理的な基準を満たす行の数を取得することができます。() 内の式が TRUE と評価された場合にカウントされます。例えば、以下のようになります:\n\nsum(age_years &lt; 18, na.rm=T)\n\nsum(gender == \"male\", na.rm=T)\n\nsum(response %in% c(\"Likely\", \"Very Likely\"))\n\n以下では、linelist データを症状発現から入院までの遅延日数（ days_onset_hosp 列）を病院別にまとめています。\n\nsummary_table &lt;- linelist %&gt;%                                        # linelist から開始し、新規オブジェクトとして保存\n  group_by(hospital) %&gt;%                                             # すべての計算を病院ごとにまとめる\n  summarise(                                                         # 以下の列の要約を取得\n    cases       = n(),                                                # グループごとの行数\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # 最大の遅延日数\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # 平均の遅延日数（丸める）\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # 遅延日数の標準偏差（丸める）\n    delay_3     = sum(days_onset_hosp &gt;= 3, na.rm = T),               # 3日以上の遅延日数の行数\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # 3日以上の遅延日数の行数列をパーセントに変換 \n  )\n\nsummary_table  # 出力\n\n# A tibble: 6 × 7\n  hospital               cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n  &lt;chr&gt;                  &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;      \n1 Central Hospital         454        12        1.9      1.9     108 24%        \n2 Military Hospital        896        15        2.1      2.4     253 28%        \n3 Missing                 1469        22        2.1      2.3     399 27%        \n4 Other                    885        18        2        2.2     234 26%        \n5 Port Hospital           1762        16        2.1      2.2     470 27%        \n6 St. Mark's Maternity …   422        18        2.1      2.3     116 27%        \n\n\nヒント:\n\nsum() をロジカル型と共に利用することで、特定の条件 (==)を満たす行を「数える」ことができます。\nsum()のような数学関数では、 na.rm = TRUE を使用することに注意してください。そうしない場合、欠測値がある場合に NA が返されます。\nscales パッケージの関数 percent() を使って、簡単にパーセントに変換することができます。\n\n小数点以下1桁を表示するには accuracy = 0.1、また 2桁を表示するには accuracy = 0.01と、それぞれ指定します。\n\nbase R の round() を使用して小数点以下を指定します。\nこれらの統計量をデータセット全体で計算するには、 group_by() を使用せずに summarise() を使用します。\n後で計算するための列（分母など）を作成し、最終的に select() でデータフレームから削除することもできます。\n\n\n\n条件付き統計量\n特定の条件を満たす行の最大値など、条件付き統計量 を取得したい場合がありますこれは、括弧 [ ]で列をサブセットすることで実現できます。以下 の例では、発熱があると分類された患者と発熱がないと分類された患者の最高体温を取得します。ただし、(下記に示すように) group_by() コマンドや pivot_wider() に別の列を追加する方が適切な場合もあるので注意してください。\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )\n\n# A tibble: 6 × 3\n  hospital                             max_temp_fvr max_temp_no\n  &lt;chr&gt;                                       &lt;dbl&gt;       &lt;dbl&gt;\n1 Central Hospital                             40.4        38  \n2 Military Hospital                            40.5        38  \n3 Missing                                      40.6        38  \n4 Other                                        40.8        37.9\n5 Port Hospital                                40.6        38  \n6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9\n\n\n\n\nのりづけ (Glueing)\nstringr の関数 str_glue() は、複数の列の値を 1 つの新しい列にまとめるのに便利です。この文脈では、一般的に summarise() コマンドの 後 に使用します。\n文字型・文字列型データ の章では、 unite() や paste0() など、列を結合するためのさまざまなオプションについて説明しています。この使用例では、 unite() よりも柔軟性があり、paste0() よりもシンプルな構文である str_glue() を提唱します。\n以下では、上で作成した summary_table データフレームを delay_mean 列とdelay_sd 列が組み合わされるように変更し、新しい列に括弧の整形を追加し、それぞれの古い列を削除しています。\nそして、表の見栄えをよりよくするために、 janitor パッケージの adorn_totals() を使って合計行を追加します（これは数字以外の列を無視します）。最後に、 dplyr パッケージの select() を使用して、列の並び替え、より適切な列名に名前を変更します。\nこれで、 flextable パッケージに渡して、表を word、.png、.jpeg、.html、Powerpoint、RMarkdown などに印刷することができるようになりました！( 見やすい表の作り方 の章を参照）。\n\nsummary_table %&gt;% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %&gt;%  # 他の値を組み合わせてフォーマット\n  select(-c(delay_mean, delay_sd)) %&gt;%                       # 古い2列を削除   \n  adorn_totals(where = \"row\") %&gt;%                            # 合計列を追加\n  select(                                                    # 列の順番と名称を指定\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )\n\n                        Hospital Name Cases Max delay Mean (sd) Delay 3+ days\n                     Central Hospital   454        12 1.9 (1.9)           108\n                    Military Hospital   896        15 2.1 (2.4)           253\n                              Missing  1469        22 2.1 (2.3)           399\n                                Other   885        18   2 (2.2)           234\n                        Port Hospital  1762        16 2.1 (2.2)           470\n St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116\n                                Total  5888       101         -          1580\n % delay 3+ days\n             24%\n             28%\n             27%\n             26%\n             27%\n             27%\n               -\n\n\n\nパーセンタイル\ndplyr パッケージの パーセンタイルと分位数は特筆に値します。分布を取得するには、デフォルトで quantile() を使用するか、 probs =で必要な値を指定します。\n\n# 年齢のデフォルトパーセンタイル値の取得 (0%, 25%, 50%, 75%, 100%)\nlinelist %&gt;% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               0\n2               6\n3              13\n4              23\n5              84\n\n# 手動で指定した年齢のパーセンタイル値を取得 (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               1\n2              13\n3              23\n4              48\n\n\nグループごとに数量を取得したい場合、 group_by() に単純に別の列を追加すると、長くてあまり役に立たない出力になる可能性があります。そこで、代わりに「必要な分位数レベルごとに列を作成する 方法を試してみてください。\n\n# 手動で指定した年齢のパーセンタイル値を取得 (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )\n\n# A tibble: 6 × 5\n  hospital                               p05   p50   p75   p98\n  &lt;chr&gt;                                &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Central Hospital                         1    12    21  48  \n2 Military Hospital                        1    13    24  45  \n3 Missing                                  1    13    23  48.2\n4 Other                                    1    13    23  50  \n5 Port Hospital                            1    14    24  49  \n6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\n\n\ndplyr パッケージの summarise() は確かにより細かい制御が可能ですが、必要なすべての要約統計量は rstatix パッケージの get_summary_stat() で生成できることに気づくかもしれません。グループ化されたデータに適用した場合、 0%、25%、50%、75%、100% の値を取得します。グループ化されていないデータに適用する場合は、probs = c(.05, .5, .75, .98)でパーセンタイルを指定できます。\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 6 × 8\n  hospital                         variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;chr&gt;                            &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Central Hospital                 age        445     0     6    12    21     58\n2 Military Hospital                age        884     0     6    14    24     72\n3 Missing                          age       1441     0     6    13    23     76\n4 Other                            age        873     0     6    13    23     69\n5 Port Hospital                    age       1739     0     6    14    24     68\n6 St. Mark's Maternity Hospital (… age        420     0     7    12    22     84\n\n\n\nlinelist %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 1 × 7\n  variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 age       5802     0     6    13    23     84\n\n\n\n\n\n集計されたデータをまとめる\n集計されたデータから始めた場合、 n() を使用すると、集計されたカウントの合計ではなく、行 数を取得します。合計を取得するには、データのカウント列に対して sum() を使用します。\n例えば、下記の件数データフレーム linelist_agg を使用しているとしましょう。 これは、結果と性別ごとのケース数を「縦」持ち形式で表示しています。\n以下では、結果および性別ごとの linelist 症例数のデータフレームの例を作成しています（わかりやすくするために欠測値は削除しています）。\n\nlinelist_agg &lt;- linelist %&gt;% \n  drop_na(gender, outcome) %&gt;% \n  count(outcome, gender)\n\nlinelist_agg\n\n  outcome gender    n\n1   Death      f 1227\n2   Death      m 1228\n3 Recover      f  953\n4 Recover      m  950\n\n\nグループ別に（ n列の）カウントを合計するには、 summarise() を使用しますが、新しい列をsum(n, na.rm=T)と設定します。合計処理に条件付きの要素を追加するには、カウント列にサブセットブラケット [ ] 構文を使用します。\n\nlinelist_agg %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))\n\n# A tibble: 2 × 4\n  outcome total_cases male_cases female_cases\n  &lt;chr&gt;         &lt;int&gt;      &lt;int&gt;        &lt;int&gt;\n1 Death          2455       1228         1227\n2 Recover        1903        950          953\n\n\n\n\nacross() 複数の列\n複数列に渡ってsummarise() を使用するには across() を使用します。こうすることで同じ統計量を多くの列で計算したい場合に便利になります。summarise() の中にacross() を置き、以下のように指定します。:\n\n.cols = 列名のベクトル c() または “tidyselect” ヘルパー関数(下記参照)\n.fns = 実行する関数（括弧なし） - list() 内に複数を指定できます。\n\n以下では、mean() を複数の数値列に適用しています。列のベクトルは .cols =に明示的に命名され、ひとつの関数 mean は .fns =に（括弧なしで）指定されます。関数の追加の引数（例：na.rm=TRUE）は .fns == の後にコンマで区切って指定されます。\nacross() を使用する際には、括弧やカンマの順序を正しく設定するのが難しい場合がありますacross() の中には、列、関数、そして関数に必要な追加の引数を含める必要があることを覚えておいてください。\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # 列\n                   .fns = mean,                               # 関数\n                   na.rm=T))                                  # その他の引数\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `outcome = \"Death\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 3 × 5\n  outcome age_years  temp wt_kg ht_cm\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Death        15.9  38.6  52.6  125.\n2 Recover      16.1  38.6  52.5  125.\n3 &lt;NA&gt;         16.2  38.6  53.0  125.\n\n\n複数の関数を一度に実行できます。以下では、関数 mean と sd がlist() 内の .fns = に提供されています。新しい列名に付加される文字名（例：“mean” や “sd”）を指定することができます。\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # 列\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # 複数の関数\n                   na.rm=T))                                 # 追加の引数\n\n# A tibble: 3 × 9\n  outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 Death             15.9         12.3      38.6   0.962       52.6     18.4\n2 Recover           16.1         13.0      38.6   0.997       52.5     18.6\n3 &lt;NA&gt;              16.2         12.8      38.6   0.976       53.0     18.9\n# ℹ 2 more variables: ht_cm_mean &lt;dbl&gt;, ht_cm_sd &lt;dbl&gt;\n\n\nここでは、列を選択するために .cols = に提供できるそれらの “tidyselect” ヘルパー関数です。:\n\neverything() - 記載されていない他のすべての列\nlast_col() - 最後の列\nwhere() - すべての列に関数を適用し、TRUE となるものを選択する\nstarts_with() - 指定された接頭辞にマッチします。例: starts_with(\"date\")\nends_with() - 指定された接尾辞にマッチします。例: ends_with(\"_end\")\ncontains() - 文字列を含む列を指定します。例: contains(\"time\")\nmatches() - 正規表現 （regex） を適用します。 例: contains(\"[pt]al\")\nnum_range() -\nany_of() - 列に名前がある場合にマッチします。名前が存在しない可能性がある場合に便利です。例: any_of(date_onset, date_death, cardiac_arrest)\n\n例えば、すべての数値列の平均値を返すには、 where() を使い、as.numeric() という関数を（括弧を付けずに）指定します。これらはすべて across() コマンドの中で行われます。\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(\n    .cols = where(is.numeric),  # データフレーム内のすべての数値行\n    .fns = mean,\n    na.rm=T))\n\n# A tibble: 3 × 12\n  outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6\n2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6\n3 &lt;NA&gt;          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6\n# ℹ 2 more variables: bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\n横への変換\n表を「横」持ち形式にしたい場合は、 tidyr の pivot_wider() を使って変換できます。rename() で列名を変更する必要があるでしょう。詳細については データの縦横変換 章を参照してください。\n以下の例では 割合のセクションから「縦」持ち表 age_by_outcome から始めます。わかりやすいように、もう一度作成して出力しましょう。:\n\nage_by_outcome &lt;- linelist %&gt;%                  # linelistから開始\n  group_by(outcome) %&gt;%                         # 転帰でグループ化 \n  count(age_cat) %&gt;%                            # age_catでグループ化してカウント後、age_catのグループ化を解除\n  mutate(percent = scales::percent(n / sum(n))) # パーセントを計算 - 分母が転帰グループ別であることに注意\n\n\n\n\n\n\n\nより広い範囲をピボット（縦横変換）するために、既存の列 age_cat の 値 から新しい列を作成します (names_from = age_catと設定します)。また、新しいテーブルの値は既存の列 nから取得するように指定し、 values_from = nとします。ピボットコマンドで言及されていない列（outcome）は、左端にそのまま残ります。\n\nage_by_outcome %&gt;% \n  select(-percent) %&gt;%   # 簡潔にするためにカウントのみを保持\n  pivot_wider(names_from = age_cat, values_from = n)  \n\n# A tibble: 3 × 10\n# Groups:   outcome [3]\n  outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Death     471   476     438     323     477     329      33     3    32\n2 Recover   364   391     303     251     367     238      38     3    28\n3 &lt;NA&gt;      260   228     200     169     229     187      24    NA    26\n\n\n\n\n行を合計する\nsummarise() がグループ化されたデータを処理するとき、自動的に「合計」の統計値を生成するわけではありません。以下では、合計行を追加するための 2 つの方法を紹介します。:\n\njanitor パッケージの adorn_totals()\n合計できる数や割合、パーセントだけで構成されている表の場合は、前のセクションで説明したように、janitor パッケージの adorn_totals() を使って 合計 値を追加できます。この関数は数値列の合計しかできないことに注意してください。他の合計要約統計量を計算したい場合は、 dplyr パッケージを使った次の方法を参照してください。\n以下では、 linelist を男女別に分類し、結果が判明している症例数、死亡者数、回復者数を記載した表にまとめています。この表を adorn_totals() にパイプ演算子で渡すと、各列の合計を反映した合計行が下部に追加されます。さらに adorn_*() でコードにあるように表示を調整しています。\n\nlinelist %&gt;% \n  group_by(gender) %&gt;%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # グループ内で結果の欠測がない行数\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # グループ内でoutocomeが\"Death\"の行数\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # グループ内でoutocomeが\"Recovered\"の行数\n  ) %&gt;% \n  adorn_totals() %&gt;%                                # 合計行を加工 (各数値列の合計)\n  adorn_percentages(\"col\") %&gt;%                      # 列で割合を取得\n  adorn_pct_formatting() %&gt;%                        # 割合をパーセントに変換\n  adorn_ns(position = \"front\")                      # %とカウントを表示（カウントを先に）\n\n gender  known_outcome        n_death      n_recover\n      f 2,180  (47.8%) 1,227  (47.5%)   953  (48.1%)\n      m 2,178  (47.7%) 1,228  (47.6%)   950  (47.9%)\n   &lt;NA&gt;   207   (4.5%)   127   (4.9%)    80   (4.0%)\n  Total 4,565 (100.0%) 2,582 (100.0%) 1,983 (100.0%)\n\n\n\n\n“total” のデータに対してsummarise() を行い、次に bind_rows() を行う\nmedian() や mean() などの要約統計量を含む表の場合、上記の adorn_totals() の方法では 十分では ありません。代わりに、データセット全体の要約統計を得るには、別の summarise() コマンドで計算し、その結果を元のグループ化された要約表にバインドする必要があります。データの結合 の章で説明したように、 dplyr パッケージの bind_rows() を使って結合を行うことができます。以下はその例です。:\ngroup_by() と summarise() を使って、次のように 病院ごと の結果の要約表を作ることができます。:\n\nby_hospital &lt;- linelist %&gt;% \n  filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%  # 転帰や病院が欠測している症例（case）を削除\n  group_by(hospital, outcome) %&gt;%                      # データをグループ化\n  summarise(                                           # 関心のある指標の新しい要約列を作成\n    N = n(),                                            # 病院-転帰グループごとの行数      \n    ct_value = median(ct_blood, na.rm=T))               # グループごとのCT値の中央値\n  \nby_hospital # テーブルを出力\n\n# A tibble: 10 × 4\n# Groups:   hospital [5]\n   hospital                             outcome     N ct_value\n   &lt;chr&gt;                                &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n 1 Central Hospital                     Death     193       22\n 2 Central Hospital                     Recover   165       22\n 3 Military Hospital                    Death     399       21\n 4 Military Hospital                    Recover   309       22\n 5 Other                                Death     395       22\n 6 Other                                Recover   290       21\n 7 Port Hospital                        Death     785       22\n 8 Port Hospital                        Recover   579       21\n 9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\n\n\n合計を得るには、同じ summarise() コマンドを実行しますが、下記のように、データを hospital ではなく outcome でグループ化します。:\n\ntotals &lt;- linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # 病院をなくして転帰のみでグループ化    \n      summarise(\n        N = n(),                                       # 転帰ごとのみの統計量     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # 表を出力\n\n# A tibble: 2 × 3\n  outcome     N ct_value\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n1 Death    1971       22\n2 Recover  1469       22\n\n\nこの 2 つのデータフレームを結合することができます。 by_hospital は 4 列で、 totals は 3 列であることに注意してください。bind_rows() を使用すると、列は名前ごとに結合され、余分なスペースは NA と表示されます（例えば、新しい 2 つの totals 行の hospital 列の値）。行を結合した後、 replace_na() を使用してこれらの空欄を “Total” に変換します（ データクリーニングと主要関数 章を参照）。\n\ntable_long &lt;- bind_rows(by_hospital, totals) %&gt;% \n  mutate(hospital = replace_na(hospital, \"Total\"))\n\n以下は、新しい表の下部に “Total” の行がある状態です。\n\n\n\n\n\n\n「縦」持ち形式のこの表があなたの望むものかもしれません。 オプション として、この表を ピボット で 横 持ちにして読みやすくするができます。上記の 横変換セクションや、データの縦横変換 の章を参照してください。また、列を追加して、きれいに並べることもできます。このコードを以下に示します。\n\ntable_long %&gt;% \n  \n  # 横変換とフォーマット\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # 縦から横へ変換\n    values_from = c(ct_value, N),                       # ct_valueとN(カウント)列から新規の値\n    names_from = outcome) %&gt;%                           # 転帰を新しい列名に\n  mutate(                                              # 新規列を追加\n    N_Known = N_Death + N_Recover,                               # 既知の症例数数\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # 死亡症例のパーセント（小数点1桁）\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # 回復症例のパーセント（小数点1桁）\n  select(                                              # 列の並べ替え\n    hospital, N_Known,                                   # 最初の列\n    N_Recover, Pct_Recover, ct_value_Recover,            # 回復症例の列\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # 死亡症例の列\n  arrange(N_Known)                                  # 行を最小から最大まで並べる（合計行は最下部）\n\n# A tibble: 6 × 8\n# Groups:   hospital [6]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n6 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;\n\n\nそして、続いてこの表を画像としてきれいに出力することができます。以下は、 flextableでの出力例です。今説明した例を「きれいな」表に仕上げる方法については 見やすい表の作り方 の章で詳しく説明しています。\n\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#tbl_gt",
    "href": "new_pages/tables_descriptive.jp.html#tbl_gt",
    "title": "17  記述統計表の作り方",
    "section": "17.5 gtsummary パッケージ",
    "text": "17.5 gtsummary パッケージ\n要約統計量をきれいな出版原稿レベルの図版として出力したい場合、gtsummary パッケージとそこに含まれる関数 tbl_summary() を使用できます。最初はコードが複雑に見えるかもしれませんが、とてもきれいな出力で、RStudio ビューアパネルに HTML イメージとして表示されます。 ここのビニエットをご一読ください。\nまた、統計的検定の結果 gtsummary テーブルに追加することもできます。この処理については、簡単な統計的検定 章の gtsummary セクションで説明しています。\ntbl_summary() を紹介するにあたり、まず最も基本的な動作を示します。これだけでも、大きく美しい表が生成されます。次に、表をより適した形に調整、修正する方法の詳細を解説します。\n\n要約表\ntbl_summary() のデフォルトの動作は非常に素晴らしく、指定された列を受け取り、ひとつのコマンドで要約表を作成します。この関数は、列のデータ型に応じた統計値を表示します。数値列では中央値と四分位範囲（IQR）、カテゴリ列ではカウント（％）を表示します。欠測値は “Unknown” に変換されます。統計量を説明するための脚注が下部に追加され，合計 N が上部に表示されます。\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;%  # 興味のある列のみを残す\n  tbl_summary()                                                  # デフォルト\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n13 (6, 23)\n\n\n    Unknown\n86\n\n\ngender\n\n\n\n\n    f\n2,807 (50%)\n\n\n    m\n2,803 (50%)\n\n\n    Unknown\n278\n\n\noutcome\n\n\n\n\n    Death\n2,582 (57%)\n\n\n    Recover\n1,983 (43%)\n\n\n    Unknown\n1,323\n\n\nfever\n4,549 (81%)\n\n\n    Unknown\n249\n\n\ntemp\n38.80 (38.20, 39.20)\n\n\n    Unknown\n149\n\n\nhospital\n\n\n\n\n    Central Hospital\n454 (7.7%)\n\n\n    Military Hospital\n896 (15%)\n\n\n    Missing\n1,469 (25%)\n\n\n    Other\n885 (15%)\n\n\n    Port Hospital\n1,762 (30%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n422 (7.2%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\n調整\nそれでは、この機能の仕組みと調整方法について説明します。主要な論点を以下に詳述します。:\nby = 列で層別することで（例えば、結果で）、二元表を作成することができます。\nstatistic = 表示する統計量とその表示方法を方程式で指定します。方程式は、チルダ ~ で区切られた2つの部分からなります。右側は希望する統計表示を引用符で囲み、左側にその表示を適用する列を指定します。\n\n式の右側は、 stringr の str_glue() の構文（ 文字型・文字列型データを参照）を使い、希望する表示文字列を引用符で囲み、統計量そのものを波括弧で囲みます “n”（カウント数）、“N”（分母）、“mean”、“median”、“sd”、“max”、“min”、 “p##” のようなパーセンタイル値、または “p” として全体に対するパーセントなどの統計量を含めることができます。詳細は ?tbl_summary を参照してください。\n式の左辺では、列を名前で指定したり（age または c(age, gender) など）、 all_continuous()、all_categorical()、contains()、starts_with() などのヘルパーを使用したりすることができます。\n\nstatistic = の方程式の簡単な例として、age_years 列の平均値のみを表示する場合は以下のようになります。:\n\nlinelist %&gt;% \n  select(age_years) %&gt;%         # 興味のある列だけを残す\n  tbl_summary(                  # 要約表を作成\n    statistic = age_years ~ \"{mean}\") # 平均年齢を出力\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n16\n\n\n    Unknown\n86\n\n\n\n1 Mean\n\n\n\n\n\n\n\n\n\nもう少し複雑な式であれば、 「({min}, {max})」のように、最大値と最小値を括弧で囲み、カンマで区切ったものがあります。:\n\nlinelist %&gt;% \n  select(age_years) %&gt;%                       # 興味のある列だけを残す \n  tbl_summary(                                # 要約表を作成\n    statistic = age_years ~ \"({min}, {max})\") # 年齢の最小値と最大値を出力\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n(0, 84)\n\n\n    Unknown\n86\n\n\n\n1 (Range)\n\n\n\n\n\n\n\n\n\nまた、別々の列や列の種類に応じて構文を変えることもできます。以下の複雑な例では、 statistc = に指定された値は、すべての連続列に対しては平均値と括弧内の標準偏差を表示し、すべてのカテゴリ列に対しては n、分母、パーセントを表示することを示す リスト となっています。\ndigits = 桁数や丸め方を調整します。オプションとして、連続した列のみを対象とするように指定することもできます（以下のように）。\nlabel = 列名の表示方法を調整します。列名と必要なラベルをチルダで区切って入力してください。デフォルトではカ列名が表示されます。\nmissing_text = 欠測値の表示方法を調整します。デフォルトは “Unknown” です。\ntype = 統計量を何段階で表示するかを調整するために使用します。構文は statistic = と似ていますが、左に列、右に値を持つ方程式を指定します。よくある 2 つのシナリオを紹介します。:\n\ntype = all_categorical() ~ \"categorical\" 強制的に二分法のカラム（例： feveryes/no）を使用して、“yes” の行だけではなく、すべてのレベルを表示します。\ntype = all_continuous() ~ \"continuous2\" 後のセクションで示すように、変数ごとに複数行の統計量を可能にします。\n\n以下の例では、これらの各引数を使用して元の要約表を修正しています。:\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;% # 興味のある列だけを残す\n  tbl_summary(     \n    by = outcome,                                               # 転帰ごとにテーブル全体を層別化\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # 連続列に対して統計量を算出してフォーマット\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # カテゴリ列に対して統計量を算出してフォーマット\n    digits = all_continuous() ~ 1,                              # 連続列に対して丸めの指定\n    type   = all_categorical() ~ \"categorical\",                 # 強制的に全カテゴリ水準を表示\n    label  = list(                                              # 列名のラベルを表示\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # 欠測値の表示方法\n  )\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\n\n\n\n\nAge (years)\n15.9 (12.3)\n16.1 (13.0)\n\n\n    Missing\n32\n28\n\n\nGender\n\n\n\n\n\n\n    f\n1,227 / 2,455 (50%)\n953 / 1,903 (50%)\n\n\n    m\n1,228 / 2,455 (50%)\n950 / 1,903 (50%)\n\n\n    Missing\n127\n80\n\n\nfever\n\n\n\n\n\n\n    no\n458 / 2,460 (19%)\n361 / 1,904 (19%)\n\n\n    yes\n2,002 / 2,460 (81%)\n1,543 / 1,904 (81%)\n\n\n    Missing\n122\n79\n\n\nTemperature\n38.6 (1.0)\n38.6 (1.0)\n\n\n    Missing\n60\n55\n\n\nHospital\n\n\n\n\n\n\n    Central Hospital\n193 / 2,582 (7.5%)\n165 / 1,983 (8.3%)\n\n\n    Military Hospital\n399 / 2,582 (15%)\n309 / 1,983 (16%)\n\n\n    Missing\n611 / 2,582 (24%)\n514 / 1,983 (26%)\n\n\n    Other\n395 / 2,582 (15%)\n290 / 1,983 (15%)\n\n\n    Port Hospital\n785 / 2,582 (30%)\n579 / 1,983 (29%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n199 / 2,582 (7.7%)\n126 / 1,983 (6.4%)\n\n\n\n1 Mean (SD); n / N (%)\n\n\n\n\n\n\n\n\n\n\n\n連続変数の統計量を複数行表示\n連続変数の統計量を複数行で表示したい場合は、type = を “continuous2” に設定することで可能です。どの統計量を表示するかを選択することで、先に示したすべての要素を 1 つの表にまとめることができます。 これを行うには、タイプを “continuous2” と入力して、表を返してほしいことを関数に伝える必要があります。欠測値の数は “Unknown” と表示されます。\n\nlinelist %&gt;% \n  select(age_years, temp) %&gt;%                      # 興味のある列のみを残す\n  tbl_summary(                                     # 要約表を作成する\n    type = all_continuous() ~ \"continuous2\",       # 複数の統計量を出力したいことを指示 \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # 行1には平均値とSD\n      \"{median} ({p25}, {p75})\",                   # 行2には中央値とIQR\n      \"{min}, {max}\")                              # 行3には最小値と最大値\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,888\n\n\n\n\nage_years\n\n\n\n\n    Mean (SD)\n16 (13)\n\n\n    Median (IQR)\n13 (6, 23)\n\n\n    Range\n0, 84\n\n\n    Unknown\n86\n\n\ntemp\n\n\n\n\n    Mean (SD)\n38.56 (0.98)\n\n\n    Median (IQR)\n38.80 (38.20, 39.20)\n\n\n    Range\n35.20, 40.80\n\n\n    Unknown\n149\n\n\n\n\n\n\n\n\np 値の追加、色や見出しの調整など、これらの表を修正する方法は他にもたくさんあります。これらの多くはドキュメントに記載されており（コンソールで ?tbl_summary と入力してください）、いくつかは 簡単な統計的検定のセクションに記載されています。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#base-r",
    "href": "new_pages/tables_descriptive.jp.html#base-r",
    "title": "17  記述統計表の作り方",
    "section": "17.6 base R",
    "text": "17.6 base R\n関数 table() を使って、列の集計やクロス集計を行うことができます。上記のオプションとは異なり、以下のように、列名を参照するたびにデータフレームを指定する必要があります。\n注意: 引数 useNA = \"always\" （“no” または “ifany” に設定することも可能）を含めない限り、NA （欠測値）値は集計 されません。\nヒント: magrittr の %$% を使用すれば、 ベース 関数でデータフレームの呼び出しを繰り返しする必要がなくなります。例えば、以下のように記述できます。 linelist %$% table(outcome, useNA = \"always\")\n\ntable(linelist$outcome, useNA = \"always\")\n\n\n  Death Recover    &lt;NA&gt; \n   2582    1983    1323 \n\n\n複数の列をカンマで区切って順番に並べることで、クロス集計が可能です。 オプションとして、Outcome = linelist$outcomeのように各列に「名前」を付けることもできます。\n\nage_by_outcome &lt;- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # 表をオブジェクトとして保存\nage_by_outcome   # 表を出力\n\n       \n        Death Recover &lt;NA&gt;\n  0-4     471     364  260\n  5-9     476     391  228\n  10-14   438     303  200\n  15-19   323     251  169\n  20-29   477     367  229\n  30-49   329     238  187\n  50-69    33      38   24\n  70+       3       3    0\n  &lt;NA&gt;     32      28   26\n\n\n\n割合\n割合を取得するには、上記の表を関数 prop.table() に渡します。引数 margins = を使用して、行に対しての割合の場合は “1”、列に対しての場合は “2”、または表全体に対しての場合は “3” のいずれかを指定します。 わかりやすくするために、この表を base R の round() にパイプで渡し、2 桁の数字を指定します。\n\n# 上で定義した表の割合を、行ごとに、丸めて取得\nprop.table(age_by_outcome, 1) %&gt;% round(2)\n\n       \n        Death Recover &lt;NA&gt;\n  0-4    0.43    0.33 0.24\n  5-9    0.43    0.36 0.21\n  10-14  0.47    0.32 0.21\n  15-19  0.43    0.34 0.23\n  20-29  0.44    0.34 0.21\n  30-49  0.44    0.32 0.25\n  50-69  0.35    0.40 0.25\n  70+    0.50    0.50 0.00\n  &lt;NA&gt;   0.37    0.33 0.30\n\n\n\n\n合計\n行と列の合計を加えるには、テーブルを addmargins() に渡します。これは、数と割合の両方で機能します。\n\naddmargins(age_by_outcome)\n\n       \n        Death Recover &lt;NA&gt;  Sum\n  0-4     471     364  260 1095\n  5-9     476     391  228 1095\n  10-14   438     303  200  941\n  15-19   323     251  169  743\n  20-29   477     367  229 1073\n  30-49   329     238  187  754\n  50-69    33      38   24   95\n  70+       3       3    0    6\n  &lt;NA&gt;     32      28   26   86\n  Sum    2582    1983 1323 5888\n\n\n\n\nデータフレームに変換\ntable() オブジェクトを直接データフレームに変換することは、簡単ではありません。以下にひとつの方法を示します。:\n\nuseNA = \"always\" を 使用せず にテーブルを作成します。代わりに forcats の fct_explicit_na() で NA 値を “(Missing)” に変換します。\naddmargins() にパイプ演算子で渡して合計値を追加します（オプション）\nbase R の as.data.frame.matrix() にパイプ演算子で渡します。\n表を tibble 関数の rownames_to_column() にパイプ演算子で渡し、最初の行の名前を指定します。\n必要に応じて、出力、表示、またはエクスポートします。この例では、 見やすい表の作り方 の章で説明したように、flextable パッケージの flextable() を使用します。 こうすると、RStudio の viewer ペインにきれいな HTML イメージとして出力することができます。\n\n\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %&gt;% \n  addmargins() %&gt;% \n  as.data.frame.matrix() %&gt;% \n  tibble::rownames_to_column(var = \"Age Category\") %&gt;% \n  flextable::flextable()\n\nAge CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.jp.html#参考資料",
    "href": "new_pages/tables_descriptive.jp.html#参考資料",
    "title": "17  記述統計表の作り方",
    "section": "17.7 参考資料",
    "text": "17.7 参考資料\nこの章に掲載されている情報の多くは、これらのリソースやオンライン上のヴィネットを参考にしています。:\ngtsummary\ndplyr",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>記述統計表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.jp.html",
    "href": "new_pages/stat_tests.jp.html",
    "title": "18  基本的な統計的検定",
    "section": "",
    "text": "18.1 準備",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>基本的な統計的検定</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.jp.html#準備",
    "href": "new_pages/stat_tests.jp.html#準備",
    "title": "18  基本的な統計的検定",
    "section": "",
    "text": "パッケージを読み込む\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R basics の章をご覧ください。\n\npacman::p_load(\n  rio,          # ファイルをインポートする\n  here,         # ファイルの位置決める\n  skimr,        # データの概要を把握する\n  tidyverse,    # データ管理 + ggplot2 グラフィックス \n  gtsummary,    # 要約統計と検定をする\n  rstatix,      # 統計を行う\n  corrr,        # 数値変数の相関分析を行う\n  janitor,      # 表に合計値とパーセンテージを加える\n  flextable     # 表をHTMLに変換する\n  )\n\n\n\n18.1.1 データをインポートする\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# linelist のインポートをする\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nlinelist の最初の50行が下のように表示されます。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>基本的な統計的検定</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.jp.html#base-r",
    "href": "new_pages/stat_tests.jp.html#base-r",
    "title": "18  基本的な統計的検定",
    "section": "18.2 base R",
    "text": "18.2 base R\nbase R の関数を使って、統計的検定を行うことができます。コマンドは比較的簡単で、結果は R のコンソールに表示されるので簡単に見ることができます。しかし、出力は、通常、リストですので、結果を次の操作で使用したい場合は、操作が難しくなります。\n\n18.2.1 T 検定\n「スチューデントの t 検定」とも呼ばれるｔ検定は、通常、2つのグループ間で何らかの数値変数の平均値に有意差があるかどうかを判定するために使用されます。ここでは、列が同じデータフレーム内にあるかどうかに応じて、この検定を行うための構文を示します。\n構文1：これは、数値列とカテゴリー列が同じデータフレームにある場合の構文です。数式の左側に数値列を、右側にカテゴリー列を用意します。データセットを data =で指定します。オプションとして、paired = TRUE、conf.level = (初期設定は0.95)、alternative = (“two.sided”、 “less”、 “greater” のいずれか)を設定します。詳細を知りたい場合は ?t.test と入力してください。\n\n##ｔ検定を使用してアウトカムグループごとに平均年齢を比較する\nt.test(age_years ~ gender, data = linelist)\n\n\n    Welch Two Sample t-test\n\ndata:  age_years by gender\nt = -21.344, df = 4902.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.571920 -6.297975\nsample estimates:\nmean in group f mean in group m \n       12.60207        19.53701 \n\n\n構文2：この代替構文を使って、2つの別々の数値ベクトルを比較することができます。たとえば、2 つの列が異なるデータセットにある場合です。\n\nt.test(df1$age_years, df2$age_years)\n\nまた，t 検定は，標本平均がある特定の値と有意に異なるかどうかを判定するためにも使用できます。ここでは、既知/仮説の母平均を mu =として、1標本の t 検定を行います。\n\nt.test(linelist$age_years, mu = 45)\n\n\n\n18.2.2 Shapiro-Wilk 検定\nShapiro-Wilk 検定は，標本が正規分布の母集団から得られたものであるかどうかを判定するために使用できます（t 検定など，他の多くの検定や分析の仮定）．ただし，これは3件から5000件まで観察サンプルにしか使用できません。より大きなサンプルでは，分位数-分位数 プロットを使用することが有用かもしれません。\n\nshapiro.test(linelist$age_years)\n\n\n\n18.2.3 Wilcoxon の順位和検定\nWilcoxon の順位和検定（Mann–Whitney の U 検定とも呼ばれる）は、2つの数値サンプルの母集団が正規分布していない場合や、不均等な分散を持つ場合に、そのサンプルが同じ分布から来ているかどうかを判断するためによく使用されます。\n\n## Wilcoxon の検定を使用してアウトカムグループごとに年齢の分布を比較する\nwilcox.test(age_years ~ outcome, data = linelist)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age_years by outcome\nW = 2501868, p-value = 0.8308\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n18.2.4 Kruskal-Wallis 検定\nKruskal-Wallis 検定は、Wilcoxon の順位和検定を拡張したもので、2つ以上のサンプルの分布の違いを検定するのに使用できます。2つのサンプルしか使用しない場合は、Wilcoxon の順位和検定と同じ結果が得られます。\n\n##  Kruskal-Wallis 検定を使用して、アウトカムグループごとに年齢の分布を比較する\nkruskal.test(age_years ~ outcome, linelist)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  age_years by outcome\nKruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308\n\n\n\n\n18.2.5 カイ二乗検定\nPearson のカイ二乗検定は、カテゴリー変数のグループ間の有意差を検定する際に使用されます。\n\n## 各グループにおける割合をカイ二乗検定で比較する\nchisq.test(linelist$gender, linelist$outcome)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  linelist$gender and linelist$outcome\nX-squared = 0.0011841, df = 1, p-value = 0.9725\n\n\n\n\n18.2.6 rstatix パッケージ\nrstatix パッケージは、「パイプ・フレンドリー」なフレームワークで統計的検定を実行し、結果を取得する機能を提供します。結果は自動的にデータフレームに格納されるので、結果に対して後続の操作を行うことができます。また、関数に渡されるデータをグループ化して、グループごとに統計を実行することも容易です。\n\n\n要約統計\nget_summary_stats() は、要約統計を素早く表示する方法です。データセットをこの関数に繋げて、分析したい列を指定するだけです。列が指定されていない場合は、すべての列の統計量が計算されます。\nデフォルトでは、数、最大値、最小値、平均、25パーセンタイル値、75パーセンタイル値、四分位範囲、中央絶対偏差 (mad)、平均、標準偏差、標準誤差、平均値の信頼区間という全ての種類の要約統計量が表示されます。\n\nlinelist %&gt;%\n  rstatix::get_summary_stats(age, temp)\n\n# A tibble: 2 × 13\n  variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166\n2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\ntype = に以下の値のいずれかを指定することで、返す要約統計量の一部を指定することができます。full”、“common”、“robust”、“five_number”、“mean_sd”、“mean_se”、“mean_ci”、“median_iqr”、“median_mad”、“quantile”、“mean”、“median”、“min”、“max”\nグループ化されたデータにも使用でき、グループ化された変数ごとに行として返される。\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  rstatix::get_summary_stats(age, temp, type = \"common\")\n\n# A tibble: 12 × 11\n   hospital     variable     n   min   max median   iqr  mean     sd    se    ci\n   &lt;chr&gt;        &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Central Hos… age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n 2 Central Hos… temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n 3 Military Ho… age        884   0    72     14    18    16.1 12.4   0.417 0.818\n 4 Military Ho… temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n 5 Missing      age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n 6 Missing      temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n 7 Other        age        873   0    69     13    17    16.0 12.5   0.422 0.828\n 8 Other        temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n 9 Port Hospit… age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n10 Port Hospit… temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n11 St. Mark's … age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n12 St. Mark's … temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095\n\n\nまた、rstatix を使って統計的な検定を行うこともできます。\n\n\nT 検定\n数式の構文を使って、数値とカテゴリーの列を指定します。\n\nlinelist %&gt;% \n  t_test(age_years ~ gender)\n\n# A tibble: 1 × 10\n  .y.   group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_… f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****        \n\n\nまた、~ 1 を使用し、 mu = を指定すると、1標本の T 検定を行うことができます。これは、グループごとに行うこともできます。\n\nlinelist %&gt;% \n  t_test(age_years ~ 1, mu = 30)\n\n# A tibble: 1 × 7\n  .y.       group1 group2         n statistic    df     p\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age_years 1      null model  5802     -84.2  5801     0\n\n\n該当する場合は、以下のようにグループごとに統計的検定を行うことができます。\n\nlinelist %&gt;% \n  group_by(gender) %&gt;% \n  t_test(age_years ~ 1, mu = 18)\n\n# A tibble: 3 × 8\n  gender .y.       group1 group2         n statistic    df         p\n* &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n3 &lt;NA&gt;   age_years 1      null model   192     -3.80   191 1.96e-  4\n\n\n\n\nShapiro-Wilk 検定\n前述の通り、サンプルサイズは3～5000の間でなければなりません。\n\nlinelist %&gt;% \n  head(500) %&gt;%      # 例として、linelist での最初の500行の症例\n  shapiro_test(age_years)\n\n# A tibble: 1 × 3\n  variable  statistic        p\n  &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 age_years     0.917 6.67e-16\n\n\n\n\nWilcoxon の順位和検定\nMann–Whitney の U 検定としても知られています。\n\nlinelist %&gt;% \n  wilcox_test(age_years ~ gender)\n\n# A tibble: 1 × 9\n  .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****        \n\n\n\n\nKruskal-Wallis 検定\n\nlinelist %&gt;% \n  kruskal_test(age_years ~ outcome)\n\n# A tibble: 1 × 6\n  .y.           n statistic    df     p method        \n* &lt;chr&gt;     &lt;int&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis\n\n\n\n\n18.2.7 カイ二乗検定\nカイ二乗検定の関数は表をもとに実施しますので、まずクロス集計を作成します。クロス集計を作成する方法はたくさんありますが（記述表を参照）、ここでは janitor パッケージの tabyl() を使用し、chisq_test() に渡す前に値ラベルの左端の列を削除します。\n\nlinelist %&gt;% \n  tabyl(gender, outcome) %&gt;% \n  select(-1) %&gt;% \n  chisq_test()\n\n# A tibble: 1 × 6\n      n statistic     p    df method          p.signif\n* &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;   \n1  5888      3.53 0.473     4 Chi-square test ns      \n\n\nrstatix パッケージの関数では、さらに多くの関数や統計検定を実行できます。rstatix パッケージのドキュメントをオンラインで見るには、ここをクリックするか、?rstatix を入力してください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>基本的な統計的検定</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.jp.html#stats_gt",
    "href": "new_pages/stat_tests.jp.html#stats_gt",
    "title": "18  基本的な統計的検定",
    "section": "18.3 gtsummary パッケージ",
    "text": "18.3 gtsummary パッケージ\n本パッケージで作成したきれいな表に統計的な検定の結果を追加したい場合は、gtsummary パッケージを使用してください（「記述表」章の gtsummary セクションで説明しています）。\ntbl_summary() で比較の統計的検定を行うには、テーブルに add_p() を追加し、使用する検定を指定します。add_q() を使用して、多重検定で補正された p 値を得ることができる。詳細は ?tbl_summary を実行してください。\n\n18.3.1 カイ二乗検定\n2つのグループにおけるカテゴリー変数の割合を比較します。カテゴリー変数に適用された場合の add_p() へのデフォルトの統計的検定は、連続性補正を用いた独立性のカイ二乗検定ですが、予想される算出数が5以下の場合は、フィッシャーの正確検定が用いられます。\n\nlinelist %&gt;% \n  select(gender, outcome) %&gt;%    # 興味のある変数を投入\n  tbl_summary(by = outcome) %&gt;%  # 要約表の作成とグループ化をする変数を指定\n  add_p()                        # 実行する検定の指定\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\ngender\n\n\n\n\n&gt;0.9\n\n\n    f\n1,227 (50%)\n953 (50%)\n\n\n\n\n    m\n1,228 (50%)\n950 (50%)\n\n\n\n\n    Unknown\n127\n80\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\n18.3.2 T 検定\n2つのグループにおける連続変数の平均値の差を比較します。例えば、患者の転帰ごとに平均年齢を比較します。\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%             # 興味のある変数を投入\n  tbl_summary(                               # 要約表を作成\n    statistic = age_years ~ \"{mean} ({sd})\", # 表示したい要約統計量を指定\n    by = outcome) %&gt;%                        # グループ化する変数を指定\n  add_p(age_years ~ \"t.test\")                # 実行する検定を指定\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n16 (12)\n16 (13)\n0.6\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n\n\n\n\n\n\n\n\n\nWilcoxon の順位和検定\n2つのグループにおける連続変数の分布を比較します。デフォルトでは、2つのグループを比較する際に Wilcoxon の順位和検定と中央値（四分位範囲）を使用します。しかし、非正規分布のデータや複数のグループを比較する場合は、Kruskal-Wallis 検定を使用することがより適切です。\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # 興味ある変数を投入\n  tbl_summary(                                         # 要約表を作成\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # 表示したい統計量を指定(これは初期値なので取り除くことができる)\n    by = outcome) %&gt;%                                  # グループ化する変数を指定\n  add_p(age_years ~ \"wilcox.test\")                     # 実行する検定を指定（これはデフォルトなので括弧内は取り除くことが可能）\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\n\n\n\nKruskal-Wallis 検定\nデータが正規分布しているかどうかに関わらず、2つ以上のグループにおける連続変数の分布を比較します。\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # 興味ある変数を投入\n  tbl_summary(                                         # 要約表を作成\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # 表示したい統計量を指定(これは初期値なので取り除くことができる)\n    by = outcome) %&gt;%                                  # グループ化する変数を指定\n  add_p(age_years ~ \"kruskal.test\")                    # 実行する検定を指定\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Kruskal-Wallis rank sum test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18.3.3 相関\n数値変数間の相関は、tidyverse corrr パッケージを使用して実施することができます。Pearson、Kendall tau、Spearman rho を使って相関を計算することができます。このパッケージは表を作成し、値を自動的に記入する機能も備えています。\n\ncorrelation_tab &lt;- linelist %&gt;% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %&gt;%   # 興味ある変数を投入\n  correlate()      # 相関係数表を作成 (初期設定ではPearsonを使用)\n\ncorrelation_tab    # 表示す\n\n# A tibble: 6 × 7\n  term            generation      age ct_blood days_onset_hosp    wt_kg    ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 generation        NA       -2.22e-2  0.179         -0.288    -0.0302  -0.00942\n2 age               -0.0222  NA        0.00849       -0.000635  0.833    0.877  \n3 ct_blood           0.179    8.49e-3 NA             -0.600    -0.00636  0.0181 \n4 days_onset_hosp   -0.288   -6.35e-4 -0.600         NA         0.0153  -0.00953\n5 wt_kg             -0.0302   8.33e-1 -0.00636        0.0153   NA        0.884  \n6 ht_cm             -0.00942  8.77e-1  0.0181        -0.00953   0.884   NA      \n\n## 重複する項目を削除 (上記の表がミラーリングされている) \ncorrelation_tab &lt;- correlation_tab %&gt;% \n  shave()\n\n## 相関係数表を表示\ncorrelation_tab\n\n# A tibble: 6 × 7\n  term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 generation        NA       NA        NA              NA       NA        NA\n2 age               -0.0222  NA        NA              NA       NA        NA\n3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n\n## 相関をプロット\nrplot(correlation_tab)\n\n\n\n\n\n\n\n\n\n\n\n18.3.4 参考資料\nこの章における多くの情報はオンラインでのこれらのリソースより採用しています。\ngtsummary dplyr corrr sthda correlation",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>基本的な統計的検定</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html",
    "href": "new_pages/regression.jp.html",
    "title": "19  単変量と多変量回帰",
    "section": "",
    "text": "19.1 準備",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html#準備",
    "href": "new_pages/regression.jp.html#準備",
    "title": "19  単変量と多変量回帰",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基本 の章をご覧ください。\n\npacman::p_load(\n  rio,          # ファイルのインポート\n  here,         # ファイルパスの指定\n  tidyverse,    # データ管理と ggplot2 での可視化\n  stringr,      # テキストの編集 \n  purrr,        # tidy な方法でのオブジェクトの反復\n  gtsummary,    # 統計量や検定の要約 \n  broom,        # 回帰の結果を整然化\n  lmtest,       # 尤度比検定\n  parameters,   # 回帰の結果を整然化するための代替手段\n  see           # フォレストプロットを可視化するための代替手段\n  )\n\n\n\nデータの読み込み\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストのインポート\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nラインリストの始めの 50 行は次のように表示されます。\n\n\n\n\n\n\n\n\nデータの前処理\n\n説明変数を保存\n説明変数の列名を文字ベクトルとして保存します。この文字ベクトルは後で使用します。\n\n## 関心のある変数を定義\nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n\n\n1 と 0 に変換\n以下では、説明変数の列（はい・いいえ（“yes”/“no”）、男性・女性（“m”/“f”）と死亡・生存（“dead”/“alive”））をロジスティック回帰モデルの解析がうまくいく形（1 / 0）へ変換します。これを効率的に行うために、dplyr パッケージの across() を使って、複数の列を一度に変換します。それぞれの列に適用する関数は case_when() （この関数も dplyr パッケージ）です。この関数は、特定の変数に対して 1 と 0 に変換するロジックを適用する。across() と case_when() についてはデータクリーニングと主要関数の章を参照してください。\n注釈: 下記コード中の「.」は、ある時点で across() 処理されている列を表します。\n\n## 2 値変数（yes/no などが格納されている変数）を 0/1 に変換\nlinelist &lt;- linelist %&gt;%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## 各列と「アウトカム」に対する処理であることを指定\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## 男性、はい、死亡を 1 に変換\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0,           ## 女性、いいえ、回復を 0 に変換\n      TRUE                            ~ NA_real_)    ## それ以外は欠測値に変換\n    )\n  )\n\n\n\n欠測値のある行を削除\n欠測値を含む行を削除するために、tidyr パッケージの関数の drop_na() が使用できます。しかし、この処理を行いたいのは、対象となる列の値に欠測がある時だけです。\nまず行わなければいけないことは、先に作成した explanatory_vars ベクトルに列 age が含まれるか確認することです（前述の case_when() 操作は 2 値変数のみに対応しているため、age はエラーになります）。次に、linelist を drop_na() に渡して、outcome 列や explanatory_vars のいずれかで値が欠測している行を削除します。\nコードを実行する前に、linelist オブジェクトの行数は nrow(linelist) で確認できます。\n\n## age_category を説明変数に追加 \nexplanatory_vars &lt;- c(explanatory_vars, \"age_cat\")\n\n## 対象となる変数の情報が欠測している行を削除\nlinelist &lt;- linelist %&gt;% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))\n\nlinelist オブジェクトに残っている行数は nrow(linelist) で確認できます。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html#単変量",
    "href": "new_pages/regression.jp.html#単変量",
    "title": "19  単変量と多変量回帰",
    "section": "19.2 単変量",
    "text": "19.2 単変量\n記述統計表の作り方の章と同様に、事例によって使用する R パッケージが決まります。ここでは単変量解析を行うための 2 つのオプションを紹介します。\n\nbase R で利用可能な関数を使用して、結果をすぐにコンソールに表示します。また、broom パッケージを使用して、出力を整然化します。\nモデルに対して gtsummary パッケージを使用して、出版原稿レベルの出力を得ます。\n\n\n\nbase R\n\n線形回帰\nbase R 関数の lm() は線形回帰を実行し、連続尺度の応答と説明変数との関連を、線形の関係があるという仮定のもとで評価します。\n式を応答と説明変数の列名をチルダ（~）で分けた formula として与え、利用するデータを data = で指定しましょう。後で利用するために、実行結果のモデルを R オブジェクトとして定義しておきます。\n\nlm_results &lt;- lm(ht_cm ~ age, data = linelist)\n\nそうすると、 summary() をモデルの結果に対して実行することができ、回帰係数（推定値）、P 値、残差などの統計指標を確認することができます。\n\nsummary(lm_results)\n\n\nCall:\nlm(formula = ht_cm ~ age, data = linelist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-128.579  -15.854    1.177   15.887  175.483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  69.9051     0.5979   116.9   &lt;2e-16 ***\nage           3.4354     0.0293   117.2   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.75 on 4165 degrees of freedom\nMultiple R-squared:  0.7675,    Adjusted R-squared:  0.7674 \nF-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: &lt; 2.2e-16\n\n\nsummary() の代わりに、broom パッケージの tidy() を使って、結果を表にまとめることもできます。結果より、年齢が 1 歳上がるごとに身長が 3.5 cm ずつ高くなり、これは統計的にも有意であることがわかりました。\n\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    69.9     0.598       117.       0\n2 age             3.44    0.0293      117.       0\n\n\nこの回帰の結果を ggplot パッケージを使って表すこともできます。これを行うためには、まず broom パッケージの argument() を使って、観測データ点とモデルに当てはめた直線を 1 つのデータフレームに取り込みます。\n\n## 回帰した点と観測データを 1 つのデータフレームにまとめる\npoints &lt;- augment(lm_results)\n\n## 年齢を x 軸としてプロット\nggplot(points, aes(x = age)) + \n  ## 身長を追加\n  geom_point(aes(y = ht_cm)) + \n  ## 得られた回帰直線を追加\n  geom_line(aes(y = .fitted), colour = \"red\")\n\n\n\n\n\n\n\n\ngeom_smooth() を使って、ggplot パッケージに単純な線形回帰の直線を追加することも可能です。\n\n## データをプロット\n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## 観測データを表示\n  geom_point() + \n  ## 回帰直線を追加\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nより詳細なチュートリアルは、この章の最後にある参考資料を参照してください。\n\n\nロジスティック回帰\nstats パッケージ（base R の一部）の glm() は、一般化線形モデル（GLM: Generalized Linear Models）のあてはめに使われます。\nglm() は単変量および多変量のロジスティック回帰に使われます（例えば、オッズ比が得られる）。核となる部分は次の通りです。\n\n# glm() の引数\nglm(formula, family, data, weights, subset, ...)\n\n\nformula = モデルは、アウトカムを左に説明変数をチルダの右に配置した式として glm() に設定されます。\nfamily = この引数は実行するモデルのタイプを決めます。ロジスティック回帰の場合は family = \"binomial\" を、ポアソン回帰の場合は family = \"poisson\" を使います。他の例は下の表に示します。\ndata = 使用するデータフレームを設定します。\n\n必要であれば、family = familytype(link = \"linkfunction\")) 構文を使ってリンク関数を設定します。他の分布族や、weights = や subset = などのオプション引数については、ヘルプドキュメントで詳しく説明されています（?glm）。\n\n\n\n\n\n\n\n分布族\nリンク関数のデフォルト\n\n\n\n\n\"binomial\"\n(link = \"logit| |“gaussian”|(link = “identity”)| |“Gamma”|(link = “inverse”)| |“inverse.gaussian”|(link = “1/mu^2”)| |“poisson”|(link = “log”)| |“quasi”|(link = “identity”, variance = “constant”)| |“quasibinomial”|(link = “logit”)| |“quasipoisson”|(link = “log”)`\n\n\n\nglm() を実行する際には、結果を名前付きの R オブジェクトとして保存するのが一般的です。そうすることで、以下のように summary() を使って結果をコンソールに表示させたり、結果に対して他の操作（例：指数変換）を行ったりすることができます。\n負の二項回帰を実行する必要がある場合は、MASS パッケージを使用します。glm.nb() は glm() と同じ構文を使います。様々な回帰を段階的に知りたい場合は、UCLA stats のページを見てください。\n\n\n単変量の glm()\nこの例では、異なる年齢カテゴリと死亡というアウトカム（準備セクションで死亡を 1 と変換しました）との関連を評価しています。以下は、age_cat によるアウトカムの単変量モデルです。モデルの出力を model として保存し、summary() でコンソールに出力します。出力される推定値は対数オッズ比であり、ベースラインレベルは age_cat の 1 番目の因子水準（レベル）（“0 - 4”）です。\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   0.233738   0.072805   3.210  0.00133 **\nage_cat5-9   -0.062898   0.101733  -0.618  0.53640   \nage_cat10-14  0.138204   0.107186   1.289  0.19726   \nage_cat15-19 -0.005565   0.113343  -0.049  0.96084   \nage_cat20-29  0.027511   0.102133   0.269  0.78765   \nage_cat30-49  0.063764   0.113771   0.560  0.57517   \nage_cat50-69 -0.387889   0.259240  -1.496  0.13459   \nage_cat70+   -0.639203   0.915770  -0.698  0.48518   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n与えた変数のベースラインレベルを変更するには、列のデータ型が因子であることを確認し、fct_relevel() で希望するレベルを最初の位置に移動させます（因子（ファクタ）型データの章を参照してください）。例えば、下の例では、列 age_cat に対して、“20-29” をベースラインとして設定してから、修正したデータフレームを glm() に渡しています。\n\nlinelist %&gt;% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %&gt;% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %&gt;% \n  summary()\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.26125    0.07163   3.647 0.000265 ***\nage_cat0-4   -0.02751    0.10213  -0.269 0.787652    \nage_cat5-9   -0.09041    0.10090  -0.896 0.370220    \nage_cat10-14  0.11069    0.10639   1.040 0.298133    \nage_cat15-19 -0.03308    0.11259  -0.294 0.768934    \nage_cat30-49  0.03625    0.11302   0.321 0.748390    \nage_cat50-69 -0.41540    0.25891  -1.604 0.108625    \nage_cat70+   -0.66671    0.91568  -0.728 0.466546    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n結果の表示\nほとんどの用途では、上記の出力にいくつかの修正を加える必要があります。broom パッケージの tidy() は、モデルの結果を見やすくするために便利です。\nここでは、モデルの出力とカウントの表を組み合わせる方法を紹介します。\n\n指数変換された対数オッズ比の推定値と信頼区間を得るために、モデルを tidy() に渡し、 exponentiate = TRUE と conf.int = TRUE を設定します。\n\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %&gt;% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%        # 指数変換し信頼区間を算出\n  mutate(across(where(is.numeric), round, digits = 2))  # 全ての数値列を四捨五入\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, digits = 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n以下の表は、整然化された model の出力です:\n\n\n\n\n\n\n\nこれらのモデルの結果とカウントの表を組み合わせます。下記では、janitor パッケージの tabyl() を使ってクロス集計表を作成します。これは記述統計表の作り方の章で説明しています。\n\n\ncounts_table &lt;- linelist %&gt;% \n  janitor::tabyl(age_cat, outcome)\n\n\n\n\n\n\n\n\n\n\n\nこの counts_table データフレームは、次のように見えます:\n\n\n\n\n\n\nこれで bind_cols()（dplyr パッケージ）を使って counts_table と結果 model を水平方向に結合することができます。bind_cols() では、2 つのデータフレームの行数が完全に一致していなければならないことを注意してください。このコードでは、一連の引き渡し過程の中で結合しているので、渡されたオブジェクト counts_table を表す . を使って、そのオブジェクトと model を結合しています。最後に、select() を使って必要な列とその順番を選択し、base R の round() で小数点以下 2 桁に指定した四捨五入を全ての数値列に適用しています。\n\ncombined &lt;- counts_table %&gt;%           # カウントの集計表から始める\n  bind_cols(., model) %&gt;%              # 回帰の出力と結合\n  select(term, 2:3, estimate,          # 変数を選択し、列の並べ直し\n         conf.low, conf.high, p.value) %&gt;% \n  mutate(across(where(is.numeric), round, digits = 2)) ## 小数点以下 2 桁に四捨五入\n\n結合されたデータフレームの外観は以下の通りです。これは flextable パッケージの関数を使って画像として綺麗に印刷されます。見やすい表の作り方では、flextable パッケージを使ったこのような表のカスタマイズ方法を説明していますが、knitr や GT などの他のさまざまなパッケージを使うこともできます。\n\ncombined &lt;- combined %&gt;% \n  flextable::qflextable()\n\n\n\n複数の単変量モデルの反復方法\n以下では、glm() と tidy() を使った方法を紹介します。よりシンプルな方法については、gtsummary パッケージのセクションを参照してください。\nいくつかの曝露変数のモデルを立て、単変量のオッズ比（つまり、変数同士で調整しない）を生成するためには、下記のアプローチが使えます。まず、stringr パッケージの str_c() を使って単変量のモデル式を作成します（文字型・文字列型データを参照）。次に、それぞれのモデル式に対して glm() の回帰を実行し、それぞれの glm() の結果を tidy() に渡します。最後に tidyr パッケージの bind_rows() を使って全てのモデルの出力を縦に結合します。このアプローチでは、purrr パッケージの map() を使って反復処理を行います。このツールのより詳しい情報はループと反復処理・リストの操作を参照してください。\n\n説明変数の列名のベクトルを作成します。このベクトルはこの章の準備セクションで explanatory_vars としてすでに作っています。\nstr_c() を使って複数の文字列としてのモデル式を作成します。ここでは左に outcome、右に explanatory_vars から得られる列名を指定します。ピリオド . が explanatory_vars の列名に置き換わります。\n\n\nexplanatory_vars %&gt;% str_c(\"outcome ~ \", .)\n\n[1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\" \n[4] \"outcome ~ cough\"   \"outcome ~ aches\"   \"outcome ~ vomit\"  \n[7] \"outcome ~ age_cat\"\n\n\n\nこの文字列としてのモデル式を map() に渡して、各入力に適用する関数として ~glm() に設定します。glm() の中では、as.formula(.x) を回帰式として設定します。ここで、 .x は上のステップで定義した文字列としての式で置き換えられます。map() は各文字列の式を反復し、それぞれの回帰を実行します。\nこの最初の map() の出力は 2 番目の map() コマンドに渡されることにより、回帰の出力に対して tidy() が適用されます。\n最後に、2 番目の map() の出力（整然化されたデータフレームのリスト）が bind_rows() で縦に結合され、全ての単変量の結果が単一のデータフレームになります。\n\n\nmodels &lt;- explanatory_vars %&gt;%       # 関心のある変数から始める\n  str_c(\"outcome ~ \", .) %&gt;%         # 各変数を式にする（\"アウトカム ~ 関心のある変数\"）\n  \n  # 各単変量の式を反復\n  map(                               \n    .f = ~glm(                       # 式を一つ一つ glm() に渡す\n      formula = as.formula(.x),      # glm() の中で、文字列としての式は .x である\n      family = \"binomial\",           # glm のタイプ（ロジスティック）を指定\n      data = linelist)) %&gt;%          # データセット\n  \n  # 上記から得られた glm 回帰の出力を整然化\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # 指数変換 \n      conf.int = TRUE)) %&gt;%          # 信頼区間を算出\n  \n  # 回帰の出力のリストを一つのデータフレームとして結合\n  bind_rows() %&gt;% \n  \n  # 全ての数値列を四捨五入\n  mutate(across(where(is.numeric), round, digits = 2))\n\n今回は、複数の単変量回帰の結果を結合しているため、models の最終的なオブジェクトが長くなっています。クリックすると model の全ての行が表示されます。\n\n\n\n\n\n\n先に示したように、各説明変数の linelist から集計表を作成し、models に結合して、見栄えの良い表を作ることができます。まず、変数定義からはじめて、map() を使って、その変数を反復処理させます。この反復処理には、dplyr パッケージの関数を使って集計表を作成するユーザー定義関数を用います。そして、その結果を組み合わせ、models の結果と結合します。\n\n## それぞれの説明変数に対して処理\nuniv_tab_base &lt;- explanatory_vars %&gt;% \n  map(.f = \n    ~{linelist %&gt;%                ## linelist から始める\n        group_by(outcome) %&gt;%     ## アウトカムごとにデータをグループ化\n        count(.data[[.x]]) %&gt;%    ## 関心のある変数に対して集計\n        pivot_wider(              ## 横長形式に変換（クロス集計表として）\n          names_from = outcome,\n          values_from = n) %&gt;% \n        drop_na(.data[[.x]]) %&gt;%         ## 欠測行を削除\n        rename(\"variable\" = .x) %&gt;%      ## 関心のある列の変数名を \"variable\" に変更\n        mutate(variable = as.character(variable))} ## 文字列に変換しないと、2 値でない（カテゴリカル）変数が因子として出てきてしまい結合できない\n      ) %&gt;% \n  \n  ## 集計結果のリストを 1 つのデータフレームとして結合\n  bind_rows() %&gt;% \n  \n  ## 回帰の結果と結合\n  bind_cols(., models) %&gt;% \n  \n  ## 関心のある列のみ抽出\n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %&gt;% \n  \n  ## 四捨五入する小数点位置を指定\n  mutate(across(where(is.numeric), round, digits = 2))\n\n以下は、上で作成したデータフレームです。この表を綺麗な HTML 出力に変換する方法（例えば、flextable パッケージの使用）については、見やすい表の作り方の章を参照してください。\n\n\n\n\n\n\n\n\n\n\ngtsummary パッケージ\n以下では、gtsummary パッケージの tbl_uvregression() の使い方を紹介します。記述統計表の作り方の章に示したように、gtsummary パッケージの関数は統計解析を行い、かつプロフェッショナルな外観の出力を作成するのに良い仕事をします。この関数は単変量の回帰分析の結果の表を作成します。\nlinelist から必要な列（説明変数とアウトカム変数）のみ選択し、それを tbl_uvregression() に渡します。これにより、準備のセクションで explanatory_vars として定義したそれぞれの列（gender、fever、chills、cough、aches、vomit と age_cat）に対して単変量回帰を行います。\nこの関数に対して、method = として glm （引用符はいらない）を、y = にアウトカム列を、ロジスティック回帰を行いたい場合は method.args = に family = binomial を指定し、さらに結果を指数変換するように指示しています。\n出力は HTML で、カウントが含まれます。\n\nuniv_tab &lt;- linelist %&gt;% \n  dplyr::select(explanatory_vars, outcome) %&gt;% ## 関心のある変数を選択\n\n  tbl_uvregression(                         ## 単変量解析の表を生成\n    method = glm,                           ## 実行したい回帰（一般化線形モデル）を定義\n    y = outcome,                            ## アウトカム変数を定義\n    method.args = list(family = binomial),  ## 実行したい glm のタイプを定義（ここではロジスティック）\n    exponentiate = TRUE                     ## 対数オッズ比ではなくオッズ比を得るために指数変換を指定\n  )\n\n## 単変量の結果の表を出力\nuniv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nこの表の出力は、テキストラベルを調整したり、P 値によって行を太字にしたりするなど、さまざまな変更を加えることができます。チュートリアルはこちらやオンラインサイトを参照してください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html#層別",
    "href": "new_pages/regression.jp.html#層別",
    "title": "19  単変量と多変量回帰",
    "section": "19.3 層別",
    "text": "19.3 層別\ngtsummary パッケージを使った層別解析は現在も継続して開発しています。この章は追って更新します。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html#多変量",
    "href": "new_pages/regression.jp.html#多変量",
    "title": "19  単変量と多変量回帰",
    "section": "19.4 多変量",
    "text": "19.4 多変量\n多変量回帰分析をするために、またしても 2 つのアプローチを提案します。\n\nglm() と tidy()\ngtsummary パッケージ\n\nこれらのワークフローはそれぞれ似ていて、最後のステップで最終的に表にまとめるところだけが違います。\n\n多変量回帰分析の実施\nここでは、glm() を使います。（単変量解析と違って）プラス記号（ + ）で説明変数を区切ることで、式の右辺に変数を追加していきます。\n全ての説明変数を使ってモデルを実行するには、次のようにします:\n\nmv_reg &lt;- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)\n\n\nCall:\nglm(formula = outcome ~ gender + fever + chills + cough + aches + \n    vomit + age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   0.069054   0.131726   0.524    0.600\ngender        0.002448   0.065133   0.038    0.970\nfever         0.004309   0.080522   0.054    0.957\nchills        0.034112   0.078924   0.432    0.666\ncough         0.138584   0.089909   1.541    0.123\naches        -0.070705   0.104078  -0.679    0.497\nvomit         0.086098   0.062618   1.375    0.169\nage_cat5-9   -0.063562   0.101851  -0.624    0.533\nage_cat10-14  0.136372   0.107275   1.271    0.204\nage_cat15-19 -0.011074   0.113640  -0.097    0.922\nage_cat20-29  0.026552   0.102780   0.258    0.796\nage_cat30-49  0.059569   0.116402   0.512    0.609\nage_cat50-69 -0.388964   0.262384  -1.482    0.138\nage_cat70+   -0.647443   0.917375  -0.706    0.480\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5700.2  on 4153  degrees of freedom\nAIC: 5728.2\n\nNumber of Fisher Scoring iterations: 4\n\n\n2 つの変数とそれらの交互作用項は、+ の代わりにアスタリスク（ * ）で変数を区切ることでモデルに含めることができます。また交互作用項のみを指定する場合は、コロン（ : ）で区切ります。例えば次の通りです。\n\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n\nオプションとして、下記コードを使うことで、あらかじめ定義された列名のベクトルと str_c() を使って上記コードを再生成することもできます。これは、説明変数の名前が変更される場合や、全てを再入力したくない場合に便利です。\n\n## 全ての関心のある変数に対して回帰を実行\nmv_reg &lt;- explanatory_vars %&gt;%  ## 説明変数の列名ベクトルから始める\n  str_c(collapse = \"+\") %&gt;%     ## 全ての関心のある説明変数名をプラス記号で区切って結合\n  str_c(\"outcome ~ \", .) %&gt;%    ## アウトカムと上記文字列を結合し、モデル式の形にする\n  glm(family = \"binomial\",      ## glm のタイプをロジスティックとして定義\n      data = linelist)          ## データセットを定義\n\n\nモデルの構築\n任意の説明変数を含む様々なモデルを保存しながら、段階的にモデルを構築することができます。また以下に示すように、lmtest パッケージの lrtest() を使ってこれらのモデルを尤度比検定で比較することができます:\n注釈: base の anova(model1, model2, test = \"Chisq\") を使っても同じ結果を得ることができます。\n\nmodel1 &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 &lt;- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)\n\nLikelihood ratio test\n\nModel 1: outcome ~ age_cat\nModel 2: outcome ~ age_cat + gender\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)\n1   8 -2852.6                    \n2   9 -2852.6  1 2e-04     0.9883\n\n\n他の方法は、各モデルのオブジェクトを受け取り、stats パッケージの step() を適用することです。この関数では、モデルを構築する際に使用したい変数選択の方向を指定します。\n\n## AIC に基づいた変数増加法によりモデルを選択\n## \"backward\" や \"both\" を指定することで変数選択の方法を調整できる\nfinal_mv_reg &lt;- mv_reg %&gt;%\n  step(direction = \"forward\", trace = FALSE)\n\nまた数値の表示をわかりやすくするために、指数表記をオフにすることもできます:\n\noptions(scipen=999)\n\n単変量解析のセクションで説明したように、モデルの出力を tidy() に渡して、対数オッズ比と信頼区間を指数変換します。最後に、全ての数値列を小数点以下 2 桁に四捨五入します。スクロールして全ての行を確認してください。\n\nmv_tab_base &lt;- final_mv_reg %&gt;% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%  ## 推定値の整然化されたデータフレームを得る\n  mutate(across(where(is.numeric), round, digits = 2))          ## 四捨五入\n\n結果として得られたデータフレームは以下のようになります:\n\n\n\n\n\n\n\n\n\n\n単変量と多変量の解析結果の結合\n\ngtsummary パッケージを使った結合\ngtsummary パッケージは tbl_regression() を提供しており、回帰の結果（この場合は glm()）を受け取り、美しくまとめた表を作成します。\n\n## 最終的な回帰モデルの結果の表を表示\nmv_tab &lt;- tbl_regression(final_mv_reg, exponentiate = TRUE)\n\n表を確認しましょう。\n\nmv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n1.15\n0.96, 1.37\n0.12\n\n\naches\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n\n\n\n\n\n\n\n\n    0-4\n—\n—\n\n\n\n\n    5-9\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nまた、gtsummary パッケージで作成したいくつかの異なる表を tbl_merge() で結合することができます。ここでは、多変量回帰分析の結果を、上で作成したgtsummary パッケージの単変量の結果と結合させています。\n\n## 単変量結果を結合 \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # 結合\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # ヘッダー名を設定\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nUnivariate\nMultivariable\n\n\nN\nOR1\n95% CI1\np-value\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n1.15\n0.96, 1.37\n0.12\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\ndplyr を使った結合\nglm() / tidy() の単変量と多変量の出力を結合する別の方法として、dplyr パッケージの結合関数があります。\n\n先に示した単変量の結果（カウントを含む univ_tab_base）と、整然化された多変量の結果 mv_tab_base を結合します。\nselect() を使って、必要な列だけを残し、その順序を指定し、名前を変更します。\n実数型である全ての列に対して round() を適用して、小数点以下 2 桁に四捨五入します。\n\n\n## 単変量と多変量の表を結合\nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %&gt;% \n  ## 列を選択し、名前を変更\n  select( # 新しい名前 = 古い名前\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %&gt;% \n  mutate(across(where(is.double), round, 2))   \n\n# A tibble: 20 × 11\n   characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval\n   &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          909  1168    1.28        1.18         1.4       0   \n 2 gender               916  1174    1           0.88         1.13      0.97\n 3 (Intercept)          340   436    1.28        1.11         1.48      0   \n 4 fever               1485  1906    1           0.85         1.17      0.99\n 5 (Intercept)         1472  1877    1.28        1.19         1.37      0   \n 6 chills               353   465    1.03        0.89         1.21      0.68\n 7 (Intercept)          272   309    1.14        0.97         1.34      0.13\n 8 cough               1553  2033    1.15        0.97         1.37      0.11\n 9 (Intercept)         1636  2114    1.29        1.21         1.38      0   \n10 aches                189   228    0.93        0.76         1.14      0.51\n11 (Intercept)          931  1144    1.23        1.13         1.34      0   \n12 vomit                894  1198    1.09        0.96         1.23      0.17\n13 (Intercept)          338   427    1.26        1.1          1.46      0   \n14 age_cat5-9           365   433    0.94        0.77         1.15      0.54\n15 age_cat10-14         273   396    1.15        0.93         1.42      0.2 \n16 age_cat15-19         238   299    0.99        0.8          1.24      0.96\n17 age_cat20-29         345   448    1.03        0.84         1.26      0.79\n18 age_cat30-49         228   307    1.07        0.85         1.33      0.58\n19 age_cat50-69          35    30    0.68        0.41         1.13      0.13\n20 age_cat70+             3     2    0.53        0.07         3.2       0.49\n# ℹ 4 more variables: mv_or &lt;dbl&gt;, mvv_ci_low &lt;dbl&gt;, mv_ci_high &lt;dbl&gt;,\n#   mv_pval &lt;dbl&gt;",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html#フォレストプロット",
    "href": "new_pages/regression.jp.html#フォレストプロット",
    "title": "19  単変量と多変量回帰",
    "section": "19.5 フォレストプロット",
    "text": "19.5 フォレストプロット\nこのセクションでは、回帰の結果を図示する方法を示します。ggplot2 パッケージを使って自分自身でプロットを作成する方法と、easystats と呼ばれるメタパッケージ（多くのパッケージを含むパッケージ）を使う方法があります。\nggplot2 パッケージに慣れていない方は、ggplot の基礎の章をご参照ください。\n\n\nggplot2 パッケージ\nggplot() を使って、多変量回帰の結果の要素をプロットすることで、フォレストプロットを構築できます。下の “geoms” を使ってプロットのレイヤーを追加していきます:\n\ngeom_point() を使った推定値の図示\ngeom_errorbar() を使った信頼区間の図示\ngeom_vline() を使った OR = 1 を表す垂直線の図示\n\nプロットする前に、forcats パッケージの fct_relevel() を使って、y 軸上の変数 / レベルの順序を設定すると良いでしょう。（設定しないと）ggplot() は、年齢カテゴリに対して英数字順に表示するといった期待通りの結果を返さないかもしれません。詳しくは因子（ファクタ）型データを参照してください。\n\n## 多変量の結果から切片項を削除\nmv_tab_base %&gt;% \n  \n  # y 軸上に示される変数 / レベルの順序を指定\n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %&gt;%\n  \n  # \"intercept\" の行をプロットから削除\n  filter(term != \"(Intercept)\") %&gt;% \n  \n  ## y 軸に変数を x 軸に推定値（OR）をプロット\n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## 点推定値をポイントとして図示\n  geom_point() + \n  \n  ## 信頼区間をエラーバーとして追加\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## OR = 1 を示す参照をダッシュ線で示す\n  geom_vline(xintercept = 1, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\neasystats パッケージ\nggplot2 パッケージが提供する細かいレベルの制御をしたくない場合は、代わりに easystats パッケージの組み合わせを使用することができます。\nparameters パッケージの model_parameters() は broom パッケージの tidy() と同じ処理を行います。see パッケージは、これらの出力を受け取り ggplot() オブジェクトとしてデフォルトのフォレストプロットを作成します。\n\npacman::p_load(easystats)\n\n## 多変量の結果から切片項を削除\nfinal_mv_reg %&gt;% \n  model_parameters(exponentiate = TRUE) %&gt;% \n  plot()",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.jp.html#参考資料",
    "href": "new_pages/regression.jp.html#参考資料",
    "title": "19  単変量と多変量回帰",
    "section": "19.6 参考資料",
    "text": "19.6 参考資料\nこの章の内容は、これらの資料やオンラインの動作例を参考にしています。\nLinear regression in R\ngtsummary\nUCLA stats page\nsthda stepwise regression",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>単変量と多変量回帰</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html",
    "href": "new_pages/missing_data.jp.html",
    "title": "20  データの欠損",
    "section": "",
    "text": "20.1 準備",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#準備",
    "href": "new_pages/missing_data.jp.html#準備",
    "title": "20  データの欠損",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R basics の章をご覧ください。\n\npacman::p_load(\n  rio,           # インポート／エクスポート\n  tidyverse,     # データの管理と視覚化\n  naniar,        # 欠損の評価と視覚化\n  mice           # 欠損値の補完\n)\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストをインポートする\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n最初の 50 行を以下に示します。\n\n\n\n\n\n\n\n\nインポート時における欠損の変換\nデータをインポートする際に、欠損、と分類されるべき値については少し注意が必要です。例えば、99、999、“Missing”、空欄（““）、または 空のスペースを含むセル（” “） などです。インポートのコマンドと一緒にこれらの値を NA （R において欠損値を示す）に変換することが出来ます。 使用するコマンドがファイルのタイプによって異なるので、詳細については データの欠損 のインポートのセクションを参考にしてください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#r-における欠損値",
    "href": "new_pages/missing_data.jp.html#r-における欠損値",
    "title": "20  データの欠損",
    "section": "20.2 R における欠損値",
    "text": "20.2 R における欠損値\n以下では、R における欠損の表示や評価の仕方、また、それに関連するいくつかの値や関数について見ていきたいと思います。\n\nNA\nR においては、欠損値は予約語（特別な値）として指定された NA で表示されます。これは引用符なしで用いることに注意が必要です。“NA” とは異なり、これは通常の文字と同じ扱いとなります（ビートルズの Hey Jude の歌詞と同じです）。\nデータ内では “99”、“Missing”、または “Unknown” というように欠損が表されていることもあります。また、空の文字値 ““（空欄のように見える）や、スペース” ” で表されていることもあります。これらについては、インポート時に NA に変換する もしくはデータを na_if() を用いてクリーニングする必要があります。\nデータクリーニングにおいて、逆に全ての NA を “Missing” に変換したり、replace_na() を用いたり、因子型の場合には fct_explicit_na() を用いたりして処理することもできます。\n\n\nいろいろな NA\n多くの場合は、NA が欠損値を示し、それで全てがうまくいきます。しかし、オブジェクトのデータ型（文字値、数値、など）によって異なる NA を用いる必要が出てくる場合があります。あまり頻繁に起こることではないですが、注意が必要です。\n多いのは、dplyr パッケージの case_when() を用いて新しい列を作成する場合などです。 データクリーニングと主要関数 の章で述べたように、この関数はデータフレーム内の全ての行に対して、ある基準（コードの右辺に書かれている条件）に合致するかどうかを評価し、新しい値（コードの左辺に書かれている値）を作成します。右辺に書かれている値は、全て同じデータ型でないといけません。\n\nlinelist &lt;- linelist %&gt;% \n  \n  # \"age\" 列から新しく \"age_years\" 列を作成する\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,       # age が年であれば、そのままの値を返す\n    age_unit == \"months\" ~ age/12,    # age が月であれば、12 で割る\n    is.na(age_unit)      ~ age,       # age のユニットが欠損であれば、years とする\n    TRUE                 ~ NA_real_)) # 他のすべての場合には欠損とする\n\n右辺に NA を持ってきたい場合は、以下に示している特殊な NA のうちのどれかを用いる必要があります。他の右辺の値が文字型の場合は “Missing” か、NA_character_ を使用する必要があります。他の右辺が日付型や数字型の場合は NA_real_ を用いります。条件式であった場合 NA を用いることが出来ます。\n\nNA - 条件式 TRUE/FALSE において用いる\nNA_character_ - 文字値に用いる\nNA_real_ - 日付型、数字値に用いる\n\n繰り返しになりますが、新しい行を case_when() を用いて作成しようとしない限りは、こうした例に出会うことはありません。より詳細について知りたい方は、R documentation on NA を参考にしてください。\n\n\nNULL\n他に R で用いられる値に、NULL があります。これは、条件が正でも誤でもないことを示しています。すなわち、値が定義されない関数などを適用した際に返されます。一般的には、関数を書いたり、ある特定の条件において NULL を返すことを指示する shiny app を書いたりする場合を除いて、NULL を値として指定することはありません。\nNullかどうかは is.null() を用いて評価することができ、as.null() を用いて変換することができます。\nNULL と NA の違いについては、ブログのポスト を見てください。\n\n\nNaN\nNaN は値としてとることが不可能なものを表す特別な値です。例えば、0 を 0 で割れ、と R に指示したような場合です。is.nan() を用いて評価することが出来、また、補足関数としてis.infinite() や is.finite() が存在します。\n\n\nInf\nInf は無限大を表します。例えば、ある値を0で割った場合などです。\nこれらの欠損値がどのように影響するかを簡単な例で示しましょう。例えば、z &lt;- c(1, 22, NA, Inf, NaN, 5) で作成される z というベクターまたはコラムがあるとします。\n一番大きな値を見つけるために max() をこのコラムに適用することを考えます。na.rm = TRUE を用いることで、計算から NA を除くことが出来ます。しかし、Inf や NaN は残り、結果として Inf が返されます。これは、[ ] と is.finite() を用いて有限な値のみを含むサブセットを作成して計算することで解決することができます： max(z[is.finite(z)]) 。\n\nz &lt;- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # NA が返される\nmax(z, na.rm=T)                  # Inf が返される\nmax(z[is.finite(z)])             # 22 が返される\n\n\n\n例\n\n\n\n\n\n\n\nR コマンド\n出力\n\n\n\n\n5 / 0\nInf\n\n\n0 / 0\nNaN\n\n\n5 / NA\nNA\n\n\n5 / Inf |0NA - 5|NAInf / 5|Infclass(NA)| \"logical\"class(NaN)| \"numeric\"class(Inf)| \"numeric\"class(NULL)`\n“NULL”\n\n\n\n“NAs introduced by coercion” はよくある警告メッセージです。数値のベクターに文字値を挿入しようとするなどの不正な操作を行った場合に起こります。\n\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))\n\nWarning: NAs introduced by coercion\n\n\n[1] 10 20 NA 40\n\n\nNULL はベクターにおいては無視されます。\n\nmy_vector &lt;- c(25, NA, 10, NULL)  # define\nmy_vector                         # print\n\n[1] 25 NA 10\n\n\nある一つの値の分散を求めようとすると NA が返されます。\n\nvar(22)\n\n[1] NA",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#便利な関数",
    "href": "new_pages/missing_data.jp.html#便利な関数",
    "title": "20  データの欠損",
    "section": "20.3 便利な関数",
    "text": "20.3 便利な関数\n以下では、R の base R の関数で、欠損値を評価したり扱ったりする際に便利なものを示します。\n\nis.na() と !is.na()\nis.na() は欠損値を特定する場合、または欠損でない値を特定する場合（! を一緒に用いります）に使います。どちらも理論値（TRUE or FALSE）が返されます。 返されたベクトルに sum() を適用、例えば sum(is.na(linelist$date_outcome)) とすることで、TRUE の数を計算することが出来ます。\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n\n!is.na(my_vector)\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\nsum(is.na(my_vector))\n\n[1] 2\n\n\n\n\nna.omit()\nこの関数をデータフレームに対して適用することで、一つでも欠損値を含む行を除くことが出来ます。これもまた、base R に含まれます。 ベクトルに対して適用すると、NA を除くことが出来ます。例えば：\n\nna.omit(my_vector)\n\n[1]  1  4 56  5 22\nattr(,\"na.action\")\n[1] 4 6\nattr(,\"class\")\n[1] \"omit\"\n\n\n\n\ndrop_na()\nデータクリーニング の際に便利な tidyr パッケージの関数です。括弧内を空にして走らせると、欠損値を一つでも含む行を除くことが出来ます。括弧内で列の名前を指定することで、その列内の値が欠損している行を除くことが出来ます。列の指定には “tidyselect” を用いることもできます。\n\nlinelist %&gt;% \n  drop_na(case_id, date_onset, age) # これらの列の値を欠損している行を除く\n\n\n\nna.rm = TRUE\nmax()、min()、sum() または、mean() などの計算を行う関数を用いるときに NA が一つでも存在すると、NA が返されます。このデフォルトの挙動は意図的なもので、データの中に欠損がある場合の注意喚起となります。\n計算から欠損値を除くことで、この警告を回避することが出来ます。そのためには、na.rm = TRUE （“na.rm” 引数 は “remove NA” の意）を一緒に用いります。\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     \n\n[1] NA\n\nmean(my_vector, na.rm = TRUE)\n\n[1] 17.6",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#データフレーム内の欠損を評価する",
    "href": "new_pages/missing_data.jp.html#データフレーム内の欠損を評価する",
    "title": "20  データの欠損",
    "section": "20.4 データフレーム内の欠損を評価する",
    "text": "20.4 データフレーム内の欠損を評価する\nデータフレーム linelist 内の欠損を評価し、視覚化するのには naniar パッケージが便利です。\n\n# パッケージをインストールするもしくは読み込む\npacman::p_load(naniar)\n\n\n欠損の数を定量化する\n全ての欠損の値の割合を示すには pct_miss() を、数を示すには n_miss() を用いります。\n\n# すべてのデータフレーム内の欠損値の割合\npct_miss(linelist)\n\n[1] 6.688745\n\n\n以下の 2 つの関数は、それぞれ、欠損値を含む行の割合、または欠損が一つもない行の割合を返してくれます。NA は欠損を意味しますが、\"\" や \" \" は欠損としてはカウントされないことに注意してください。\n\n# 欠損値を含む行の割合を示す\npct_miss_case(linelist)   # 数を示すには n_miss() を用いる\n\n[1] 69.12364\n\n\n\n# コンプリートケース（欠損のない行）の割合を示す  \npct_complete_case(linelist) # 数を示すには n_complete() を用いる\n\n[1] 30.87636\n\n\n\n\n欠損状況を視覚化する\ngg_miss_var() を用いることで、それぞれの列における欠損値の数（もしくは割合）を示すことが出来ます。\n\nプロットをグループごとに見たい場合は、facet = で列の名前（引用符にいれない）を指定することが出来ます\nデフォルトでは、割合ではなく数が表示されます。割合にしたい場合は show_pct = TRUE で指定します\n通常の ggplot() 通り、軸やタイトルのラベルを追加したい場合は + labs(...) を用いて行うことが出来ます\n\n\ngg_miss_var(linelist, show_pct = TRUE)\n\n\n\n\n\n\n\n\n以下では、データが %&gt;% を用いて関数に渡されています。facet = を用いても、データを分けることが出来ます。\n\nlinelist %&gt;% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n\n\n\n\n\n\n\n\nどの値が欠損しているかを示すために、vis_miss() を用いてデータフレームをヒートマップで表すことが出来ます。また 特定の列をデータフレームから select() して関数にその列だけを渡すこともできます。\n\n# データフレーム全体に対して欠損のヒートプロットを示す  \nvis_miss(linelist)\n\n\n\n\n\n\n\n\n\n\n欠損状況の関係性を探り、可視化する\n存在しないものをどうやって視覚化すればよいのでしょうか？デフォルトでは、ggplot() を使うと、欠損値を除いてプロットを作成してしまいます。\nnaniar パッケージの geom_miss_point() を用いれば解決します。2 つの列から散布図を作成するときに、ある一方の変数は存在し、片方の変数は欠損である場合には、欠損値をその列の最小値よりもさらに 10% 小さな値に変換し、違う色で散布図上に示してくれます。\n以下に示している散布図では、赤いドットはある一方の変数は存在しているが片方の変数が欠損している場合を示しています。これによって欠損していない値に対する欠損している値の分布を視覚的に確認することが出来ます。\n\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\n\n\n\n\n\n\n\n\n別の列によって層別化したあとに欠損を評価したい場合は、gg_miss_fct() を使います。これは、因子型（または日付）の列の値ごとにデータフレームの欠損の割合をヒートマップで示してくれます。\n\ngg_miss_fct(linelist, age_cat5)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat5 = (function (x) ...`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\nℹ The deprecated feature was likely used in the naniar package.\n  Please report the issue at &lt;https://github.com/njtierney/naniar/issues&gt;.\n\n\n\n\n\n\n\n\n\nこの関数を日付ごとにデータフレームを示すのに用いると、欠損が時系列を追うごとにどのように変化しているかを示すことも出来ます。\n\ngg_miss_fct(linelist, date_onset)\n\nWarning: Removed 29 rows containing missing values or values outside the scale range\n(`geom_tile()`).\n\n\n\n\n\n\n\n\n\n\n\n「付随する」列\nある一方の列の欠損を、もう片方の列の値ごとに示す別の方法として、naniar パッケージの作成する「付随する列」を用いるものがあります。bind_shadow() を用いると、全ての列に対して NA または not NA の 2 値変数を作成し、“_NA” を末尾に付けた新しい列として元のデータセットに結合してくれます。すなわち、データセットの列は 2 倍になります。\n\nshadowed_linelist &lt;- linelist %&gt;% \n  bind_shadow()\n\nnames(shadowed_linelist)\n\n [1] \"case_id\"                 \"generation\"             \n [3] \"date_infection\"          \"date_onset\"             \n [5] \"date_hospitalisation\"    \"date_outcome\"           \n [7] \"outcome\"                 \"gender\"                 \n [9] \"age\"                     \"age_unit\"               \n[11] \"age_years\"               \"age_cat\"                \n[13] \"age_cat5\"                \"hospital\"               \n[15] \"lon\"                     \"lat\"                    \n[17] \"infector\"                \"source\"                 \n[19] \"wt_kg\"                   \"ht_cm\"                  \n[21] \"ct_blood\"                \"fever\"                  \n[23] \"chills\"                  \"cough\"                  \n[25] \"aches\"                   \"vomit\"                  \n[27] \"temp\"                    \"time_admission\"         \n[29] \"bmi\"                     \"days_onset_hosp\"        \n[31] \"case_id_NA\"              \"generation_NA\"          \n[33] \"date_infection_NA\"       \"date_onset_NA\"          \n[35] \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n[37] \"outcome_NA\"              \"gender_NA\"              \n[39] \"age_NA\"                  \"age_unit_NA\"            \n[41] \"age_years_NA\"            \"age_cat_NA\"             \n[43] \"age_cat5_NA\"             \"hospital_NA\"            \n[45] \"lon_NA\"                  \"lat_NA\"                 \n[47] \"infector_NA\"             \"source_NA\"              \n[49] \"wt_kg_NA\"                \"ht_cm_NA\"               \n[51] \"ct_blood_NA\"             \"fever_NA\"               \n[53] \"chills_NA\"               \"cough_NA\"               \n[55] \"aches_NA\"                \"vomit_NA\"               \n[57] \"temp_NA\"                 \"time_admission_NA\"      \n[59] \"bmi_NA\"                  \"days_onset_hosp_NA\"     \n\n\nこれらの「付随する列」は、他のどの列に対してでも、欠損している値の割合をプロットするのに使えます。\n例えば、以下のプロットでは、date_hospitalisation 列の値ごとに、days_onset_hosp 列（発症してから入院までの日数）における欠損の割合を示しています。x 軸の列の密度をプロットしており、興味のある付随する列によって層別化（color =）していることに注意してください。x 軸が数値もしくは日付の列である場合、このプロットはうまく実行されます。\n\nggplot(data = shadowed_linelist,          # 付随する列を含むデータフレーム\n  mapping = aes(x = date_hospitalisation, # 数値もしくは日付の列\n                colour = age_years_NA)) + # 興味のある付随する列\n  geom_density()                          # 密度曲線をプロットする\n\n\n\n\n\n\n\n\n以下に示すように、統計量のサマリを層別化して示すのにも「付随する列」を使用することが出来ます。\n\nlinelist %&gt;%\n  bind_shadow() %&gt;%                # 「付随する列」を作成する\n  group_by(date_outcome_NA) %&gt;%    # 層別化に用いる「付随する列」を指定する\n  summarise(across(\n    .cols = age_years,             # 統計量を示したい変数を指定する\n    .fns = list(\"mean\" = mean,     # 興味のある統計量を指定する\n                \"sd\" = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # 統計量の計算に用いるその他のコマンド\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `date_outcome_NA = !NA`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 2 × 6\n  date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min\n  &lt;fct&gt;                    &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 !NA                       16.0         12.6          158.             0\n2 NA                        16.2         12.9          167.             0\n# ℹ 1 more variable: age_years_max &lt;dbl&gt;\n\n\n以下に、列の欠損値の割合を時系列ごとに示す他の方法を示します。naniar パッケージは使用しません。週ごとの観測値の欠損の割合を示しています。\n\nデータを、興味のある単位時間（日、週、など）でまとめ、NA（そしてその他興味のある値）を含む観測値の割合を計算します\nggplot() を用いて、欠損の割合を折れ線グラフとしてプロットします\n\n以下では、ラインリストを用いて、まず週ごとの値を新しい列として加え、値が欠損している週ごとの記録の割合を計算しています（7 日間での割合を計算したい場合は、以下のスクリプトとは少し異なります）。\n\noutcome_missing &lt;- linelist %&gt;%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %&gt;%   # 新しく week の列を作成する\n  group_by(week) %&gt;%                                             # 行を、week ごとにグルーピングする\n  summarise(                                                     # それぞれの値を week ごとにまとめる\n    n_obs = n(),                                                  # 観測数\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),        # 欠損を含む観測数\n    outcome_p_miss  = outcome_missing / n_obs,                    # 欠損を含む観測の割合\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),           # 死亡例の観測数\n    outcome_p_dead  = outcome_dead / n_obs) %&gt;%                   # 死亡例の観測の割合\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %&gt;%         # ggplot のために week を除くすべての列をロング形式にピボットする\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # 割合を示す値だけを残す\n\nこのデータを用いて、週ごとに欠損の割合を折れ線で示します。ggplot2 パッケージについてあまり詳しくない場合は、ggplotの基礎 の章を参考にしてください。\n\nggplot(data = outcome_missing)+\n    geom_line(\n      mapping = aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#欠損値を含むデータを使う",
    "href": "new_pages/missing_data.jp.html#欠損値を含むデータを使う",
    "title": "20  データの欠損",
    "section": "20.5 欠損値を含むデータを使う",
    "text": "20.5 欠損値を含むデータを使う\n\n欠損値を含む行を取り除く\n欠損値を含む行を除く簡単な方法は、dplyr パッケージの drop_na() を用いる方法です。\n元の linelist には nrow(linelist) 行含まれています。欠損値を含む行を除いた後の行数は以下になります。\n\nlinelist %&gt;% \n  drop_na() %&gt;%     # あらゆる欠損値を含む列を除く\n  nrow()\n\n[1] 1818\n\n\nまた、ある特定の列内の欠損値を含む行を除くこともできます。\n\nlinelist %&gt;% \n  drop_na(date_onset) %&gt;% # date_onset 行に欠損を含む列を除く\n  nrow()\n\n[1] 5632\n\n\n順番に行を表示することも出来ますし、 “tidyselect” helper functions を使うこともできます。\n\nlinelist %&gt;% \n  drop_na(contains(\"date\")) %&gt;% # \"date\" を含む行に欠損を含む列を除く \n  nrow()\n\n[1] 3029\n\n\n\n\n\nggplot() での NA の扱い方\nたいていの場合、プロットから除かれた値の数はキャプションとして報告するのが賢明です。以下に例を示します。\nggplot() においては、labs() を追加し、その中で caption = としてキャプションを追加することが出来ます。キャプションの中で stringr パッケージの str_glue() を使うことで、文中に直接値を張り付けることが出来るので、データそれぞれの値を用いることが出来ます。\n\n\\n は、行替えに用いることが出来ます。\nもし、複数の列がプロットに表示されない値を含む場合（例えば、年齢あるいは性別がプロットに反映されている場合）、表示されていない数を正確に計算するためにはそれらの列で絞り込みを行う必要があります。\n\n\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  \n\nggplot() コマンドを使用する前に、文字をオブジェクトとして保存し、str_glue() 内ではそのオブジェクト名を指定するだけの方が簡単な場合もあります。\n\n\n\n因子型におけるNA\n興味のある列が因子型である場合、NA を文字値にするには forcats パッケージの fct_explicit_na() を用いる必要があります。詳細については[因子（ファクタ）型データ] (#factors)の章を参考にしてください。デフォルトでは、新しい値は “(Missing)” として扱われますが、na_level = のコマンドによって変更することが出来ます。\n\npacman::p_load(forcats)   # パッケージの読み込み\n\nlinelist &lt;- linelist %&gt;% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)\n\n[1] \"f\"       \"m\"       \"Missing\"",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#欠損値の補完",
    "href": "new_pages/missing_data.jp.html#欠損値の補完",
    "title": "20  データの欠損",
    "section": "20.6 欠損値の補完",
    "text": "20.6 欠損値の補完\n単純に全ての欠損値を除いたデータセットを解析するのではなく、「ギャップを埋めて」、欠損値を補完してからデータを解析する方が良い場合もあります。単純にすべての欠損値を除くと、いろいろ問題があることがあります。例えば：\n\n欠損値を含む観測値や大量の欠損値を含む変数を全て除くと、ある種の解析を行うパワーが減る可能性があります。例えば、先に示したように、linelist データにおいては、全ての変数のうち欠損値をまったく含まない観測は限られた割合しかありません。データセットの大部分を取り除いてしまうと、大量の情報を失ってしまうことになります！さらに、たいていの変数はそれなりの量の欠損値を含んでいます。そのため、ほとんどの分析において欠損値がたくさん含まれる変数を除去することはあまり適切ではありません。\n欠損がなぜ生じているのかによっては、単に欠損を含まないデータのみで解析することは、解析結果にバイアスが生じたり、ミスリーディングな結果となることがあります。例えば、ある患者さんが熱や咳などの重要な症状の有無に関するデータを欠損しているとします。たとえば、明らかにそこまで重症でない患者さんについては熱や咳などの症状について記録をしていない可能性もあります。その場合は、単に欠損を含む観測値を除くと、データセット内の最も健康な人々を除くことになり、非常に結果にバイアスを生じることになります。\n\nどのくらい欠損しているか、ということに加えて、なぜ欠損が生じてるのかを考えることが重要です。そうすることで、欠損データを補完することがどのくらい重要なのか、そしてどの方法で補完することが一番良いのかについて判断を下しやすくなるでしょう。\n\n欠損データの種類\n欠損データには一般的に、以下に挙げる 3 つの種類があります；\n\nMissing Completely at Random (MCAR) これは、データが欠損する確率と、他のデータ内との変数との間に関係性がないことを意味します。すべてのケースで、欠損する確率がおなじこととなります。これは珍しい状況です。しかし、もしデータが MCAR であると信じる確固とした理由があるのであれば、欠損していないデータだけを補間を行わずに分析することは、結果にバイアスを生じさせません（とはいえ、パワーはいくらか失われます）。[TODO: consider discussing statistical tests for MCAR]\nMissing at Random (MAR) この名前は少しミスリーディングで、というのも、MAR は、生じている欠損のパターンを他の変数の情報から規則的に予測できるタイプの欠損データのことだからです。例えば、全てのケースにおいて、熱のデータを欠損しているのは、実は寒気と痛みのある人は熱があると推測されたために熱を測らなかったためだとします。そうだとすると、寒気と痛みのあった観測値においては、発熱もまた生じていると容易に予測することが出来、欠損値を補完するためにこの情報を使用することが出来ます。実際には、これはもう少しスペクトラム的な話で、悪寒と痛みの両方を訴えており発熱のデータを欠損している患者は発熱もしている可能性が高いが、必ずしもそうというわけではない、ということです。しかし、完全に予測できるわけではなくとも、予測可能ではあります。欠損データの種類としては、最も多いタイプのものです。\nMissing not at Random (MNAR) Not Missing at Random (NMAR) と呼ばれることもあります。このタイプは、欠損データの割合が系統的でなく、他の情報を用いて予測可能でもなく、また、ランダムに欠損が生じているわけでもないタイプの欠損のデータのことです。すなわち、データは何らかの明らかになっていない原因により欠損しているか、あるいは情報を持っていない何らかの規則に基づいて欠損しているといえます。例えば、年齢のデータが欠損しているのは、非常に高齢の患者は自分の年齢を知らないか、自分の年齢を開示したくなかったからだとします。この場合、年齢の欠損は、年齢データ自身に関連しており（すなわちランダムに生じているわけではない）、従って他の情報に基づいて欠損を予測することはできません。MNAR は複雑で、対処法としては、欠損を補完しようとするよりも、もっとデータを集めること、そしてなぜ欠損が生じているのかについての情報を収集することが良いでしょう。\n\nまとめると、MCAR データを補完することは比較的容易ですが、一方、MNAR データを補完することは不可能ではないにしても非常にチャレンジングです。多くのデータの補完のメソッドは、MAR を仮定しています。\n\n\n便利なパッケージ\nMmisc、missForest（ランダムフォレストによる欠損値の補完）、そして mice（連鎖方程式による多重代入法）などのパッケージは、欠損値の補完に便利です。このセクションでは、いろいろなテクニックを学ぶことの出来る mice パッケージについてのみ解説します。mice の開発者によるオンラインブックには、より詳細が示されています（https://stefvanbuuren.name/fimd/）。\nmice パッケージを読み込みます；\n\npacman::p_load(mice)\n\n\n\n平均値代入法\n例えば、非常に単純な解析をしている、あるいは MCAR を仮定する強い理由がある時には、数値の欠損を単にその変数の平均値で代入することが出来る場合があります。例えば、我々のデータセット内の気温の欠損値は MCAR であるか単に平年値である、と仮定できる可能性があります。気温の欠損値をデータセットの値の平均値で補完した新しい変数を作成するコードを示します。しかし、多くの場合では単に平均値を補完するとバイアスを生じる可能性があるので、十分注意が必要です。\n\nlinelist &lt;- linelist %&gt;%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\n\n同じような方法で、因子型の欠損値をある特定の値で補完することもできます。例えば、転帰について（“Death” または “Recover”）の情報が欠損している観測値はすべて死亡データであるとします（このデータセットについては、これは本当は正しくないのですが）。\n\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))\n\n\n\n回帰代入法\nいくらかアドバンスな方法として、何らかの統計モデルを用いて欠損値がどんな値らしいのかを推測し、それで補完する方法があります。ここでは、体温についての情報は欠損しているけれど年齢と発熱についての情報は存在する観測値に対して、年齢（年）と発熱を予測因子とした簡単な線形回帰モデルを用いて値を予測する方法を示しています。実際には、このような単純なモデルではなく、より正確なモデルを使用した方が良いでしょう。\n\nsimple_temperature_model_fit &lt;- lm(temp ~ fever + age_years, data = linelist)\n\n#単純な体温モデルを用いて、体温の欠損値を予測する\npredictions_for_missing_temps &lt;- predict(simple_temperature_model_fit,\n                                        newdata = linelist %&gt;% filter(is.na(temp))) \n\nもしくは、体温の欠損値に対して同様にモデルを作成する方法として mice パッケージを用いる方法もあります。\n\nmodel_dataset &lt;- linelist %&gt;%\n  select(temp, fever, age_years)  \n\ntemp_imputed &lt;- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)\n\nWarning: Number of logged events: 1\n\ntemp_imputed_values &lt;- temp_imputed$imp$temp\n\nこれは、欠損値を予測値で補完する、という意味で missForest パッケージなどのよりアドバンスな方法と同じタイプの方法だと言えます。missForest の場合は、線形回帰ではなくランダムフォレストを用いて予測モデルを作成します。他のタイプのモデルを使用することもできます。この方法は、MCARの場合はうまくいきますが、MAR あるいは MNAR の方がデータをうまく説明する、と思っている場合には注意が必要です。補完の質は、予測モデルがどのくらい正確か、ということにも拠りますが、正確なモデルであっても補完されたデータのばらつきが少し過小となる場合もあります。\n\n\nLOCF と BOCF\nLast observation carried forward (LOCF) と baseline observation carried forward (BOCF) は、時系列および縦断データの補完方法です。考え方としては、欠損の生じている観測値よりも前に観測されたデータで欠損値を補完しようというものです。連続で値が欠損している場合は、最後に観測された値で補完します。\nLOCF および BOCF のどちらも tidyr パッケージの fill() を用いて実装することが出来ます（HMISC、zoo、そして data.table などのパッケージを用いても行うことが出来ます）。fill() をどのように使うのか示すために、2000 年と 2001 年において四半期ごとの罹患数を含む単純な時系列データを作成します。しかし、Q1 以降の半期に関するデータは欠損しているので、補完する必要があります。データの縦横変換 の章においても、fill() の使用方法が示されています。\n\n#単純なデータセットを作成する\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n#year の欠損値を補完する\ndisease %&gt;% fill(year)\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nfill() を使用する前に、データが正しくソートされているかどうかを確認してください。fill() はデフォルトで「下向きに」補完しますが、 .direction パラメタを用いることで違う方向に補完することもできます。例えば、似たようなデータですが、今度は年の終わり（Q4）のみ記録があり、他は欠損しているデータセットがあるとします。\n\n#先ほどと少しだけ違うデータセットを作成する\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n#year の欠損値を、今度は「上向き」に補完する\ndisease %&gt;% fill(year, .direction = \"up\")\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nこの例では、LOCF およびに BOCF は明らかに正しい方法でしたが、より複雑な状況ではこの方法が適切かどうかを判断するのが難しい場合もあります。例えば、初日から何日間か、患者の検査値が欠損しているとします。ある場合は、これは検査値に変動がないことを示していますが、患者が回復しており、値が初日とはまったく異なる可能性もあります！なので、少し注意してこれらのメソッドを使う必要があります。\n\n\n多重代入法\n先ほど紹介した mice パッケージの開発者によるオンラインブック（https://stefvanbuuren.name/fimd/）には多重代入法の説明と、なぜそれを使いたいのかが詳細に記されています。ここでは、方法の基本的な部分を説明します。\n多重代入法では、尤もらしい値で欠損値を代入したデータセットを複数作成します（データによってはより多くもしくは少なくデータセットを作成したい場合もあると思いますが、mice パッケージのデフォルトでは、5 つのデータセットが作成されます）。違いとしては、代入される値は、ある単一の値ではなく、予測された分布に基づき特定される値（したがっていくらかのランダムさを含んでいます）である、という点です。それぞれのデータセットに対してある種の予測モデルを用いる（mice には様々なオプションがあり、例えば予測平均マッチング、ロジスティック回帰、ランダムフォレストなどがあります）点では同じですが、mice パッケージでは様々なモデルの詳細についてまで考慮することが出来ます。\n代入されたデータセット群を作成したら、これらの新しいデータセットそれぞれに対して、もともと計画していた統計解析を行い、それらの結果を一つにプールします。この方法は、MCAR において、また MAR の多くの場合においてバイアスを減少するのに非常に有用で、より正確な標準誤差を得ることが出来ます。\n以下では、多重代入法を用いて、ラインリストのデータセット（より単純にした model_dataset を用いります）で、年齢と発熱のデータから体温を予測する方法を示します。\n\n# model_datasetにおける欠損をすべて代入し、新たに 10 つのデータセットを作成する\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) \n\nWarning: Number of logged events: 1\n\nmodel_fit &lt;- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))\n\n         term     estimate    std.error    statistic        df       p.value\n1 (Intercept) 3.703143e+01 0.0270863456 1.367162e+03  26.83673  1.583113e-66\n2   age_years 3.867829e-05 0.0006090202 6.350905e-02 171.44363  9.494351e-01\n3    feveryes 1.978044e+00 0.0193587115 1.021785e+02 176.51325 5.666771e-159\n\n\nここでは、mice のデフォルトの予測モデルである予測平均マッチングで欠損を補完しました。そして、それぞれの代入されたデータセットを値の推定に用いり、線形回帰によりそれぞれのデータセットにおいて得られた推定値をプールします。ここでは触れませんでしたが、mice パッケージを用いる際にはより詳細な方法や多重代入法に関する様々な設定を考慮する必要があります。例えば、常に数値データであるとは限らず、その場合は他の代入方法を用いる必要があります（mice パッケージでは、他の様々なデータの種類や補完が出来ます）。欠損データが非常に問題となる場合は、より頑健な解析結果を得るためには、単にコンプリートケースによる解析を行うよりも、多重代入法を用いる方が良いと言えるでしょう。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.jp.html#参考資料",
    "href": "new_pages/missing_data.jp.html#参考資料",
    "title": "20  データの欠損",
    "section": "20.7 参考資料",
    "text": "20.7 参考資料\nVignette on the naniar package\nGallery of missing value visualizations\nOnline book about multiple imputation in R by the maintainer of the mice package",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>データの欠損</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.jp.html",
    "href": "new_pages/standardization.jp.html",
    "title": "21  標準化率",
    "section": "",
    "text": "21.1 概要\n標準化には直接法と間接法という2つの主要な方法があります。 例えば、A国とB国の年齢と性別で調整した標準化死亡率を求め、それらの標準化死亡率を比較したいとします。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>標準化率</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.jp.html#概要",
    "href": "new_pages/standardization.jp.html#概要",
    "title": "21  標準化率",
    "section": "",
    "text": "直接法では、各A国とB国のそれぞれの年齢と性別層における、リスクに曝された人数と死亡数が分かっている必要があります。層の一例としては「女性で 15 - 44 歳」などになります。\n間接法では、各国の総死亡数と年齢・性別構成だけが分かっていればよいです。つまり、年齢ごとおよび性別ごとの死亡率や人口データが利用できない場合であっても、間接法を用いることができます。各層の人数が少なく、直接法の各層の推定値がかなりサンプリング変動による影響を受けると考えられる場合、間接法がより望ましいです。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>標準化率</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.jp.html#準備",
    "href": "new_pages/standardization.jp.html#準備",
    "title": "21  標準化率",
    "section": "21.2 準備",
    "text": "21.2 準備\n標準化がどのように行われるのかを説明するため、国 A と B から得られた年齢（5歳刻みの分類）と性別（女性、男性）ごとの架空の人口と死亡数のデータを用います。データセットを解析できる形にするため、以下の工程で準備を行っていきます。\n\nパッケージの読み込み\nデータの読み込み\n二国の人口データと死亡データの結合\n年齢性別層ごとに一列になっているデータを縦長に変換\n参照集団（世界標準人口）データをクリーニングし、二国のデータと結合\n\n実際の状況では、あなたのデータはフォーマットが異なっていることもあります。県、市、または別の管轄区域で分けられているかもしれません。あるいは、一行が各死亡になっていて、それぞれの死亡者毎（または死亡者の大部分）で年齢と性別の情報が得られているかもしれません。この場合は、各年齢性別層の死亡数と人口のデータセットを作成するために、データのグループ化、Pivoting data、記述表の章を確認してください。\n参照集団、標準人口のデータも必要です。この練習問題では world_standard_population_by_sex を使用します。世界標準人口は46ヶ国の人口に基づいており、1960年に作成されました。また、「標準」人口は沢山あります。例を挙げると、NHS Scotland のウェブサイトはヨーロッパ標準人口、世界標準人口、スコットランド標準人口に関して非常に有益な情報源です。\n\n\nパッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R basics の章をご覧ください。\n\npacman::p_load(\n     rio,                 # データのインポート・エクスポート\n     here,                # ファイルの場所を特定\n     stringr,             # 文字と文字列のクリーニング\n     frailtypack,         # dsr で必要：フレイルティモデルのため\n     dsr,                 # 標準化率\n     PHEindicatormethods, # 標準化のための代替のパッケージ\n     tidyverse)           # データマネジメントと視覚化\n\n注意：新しいバージョンの R を使用している場合、dsr パッケージは CRAN から直接ダウンロードできません。ただし、まだ CRAN のアーカイブから利用可能で、インストールして利用することができます。\n非Macユーザは以下を実行してください。\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos = NULL, type = \"source\")\n\n\n# 別の方法でも実行できます\nrequire(devtools)\ndevtools::install_version(\"dsr\", version = \"0.2.2\", repos = \"http:/cran.us.r.project.org\")\n\nMacユーザは以下を実行してください。\n\nrequire(devtools)\ndevtools::install_version(\"dsr\", version = \"0.2.2\", repos = \"https://mac.R-project.org\")\n\n\n\n人口データの読み込み\nこのハンドブックの全事例データのダウンロード方法については Download handbook and data の章を確認してください。以下の import() コマンドを実行すると、標準化の章のデータを我々の Github リポジトリから直接 R に読み込むことができます。\n\n# Github から直接国 A の人口データをインポート\nA_demo &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# Github から直接国 A の死亡データをインポート\nA_deaths &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n# Github から直接国 B の人口データをインポート\nB_demo &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# Github から直接国 B の死亡データをインポート\nB_deaths &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n# Github から直接標準人口のデータをインポート\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epiRhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\n最初に、二ヶ国の人口データ（5歳毎に分類した男性と女性の人数）を読み込み、「国 A」と「国 B」の比較を行っていきます。\n\n# 国 A\nA_demo &lt;- import(\"country_demographics.csv\")\n\n\n\n\n\n\n\n\n# 国 B\nB_demo &lt;- import(\"country_demographics_2.csv\")\n\n\n\n\n\n\n\n\n\n死亡数の読み込み\n興味のある期間中の年齢・性別毎の死亡数のデータもあります。以下の通り、各国の死亡数は別々のファイルに入っています。\n国 A の死亡数\n\n\n\n\n\n\n国 B の死亡数\n\n\n\n\n\n\n\n\n人口・死亡数のクリーニング\nこれらのデータは以下の方法で結合し変換する必要があります。\n\n二ヶ国の人口を一つのデータセットに結合し、各年齢性別層が一行になるように「縦長」に変形\n二ヶ国の死亡数を一つのデータセットに結合し、各年齢性別層が一行になるように「縦長」に変形\n死亡データを人口データに結合\n\n最初に、二ヶ国の人口データを結合し、縦長変換して、軽微なクリーニングを行います。詳細については Pivoting data の章を確認してください。\n\npop_countries &lt;- A_demo %&gt;%               # 国 A のデータセットから開始\n     bind_rows(B_demo) %&gt;%                # 各列名が一致しているため、国 B のデータを列方向に結合\n     pivot_longer(                        # 縦長に変換\n          cols = c(m, f),                 # これらの列を1つに結合\n          names_to = \"Sex\",               # カテゴリ（\"m\"または\"f\"）の情報を含む新しい列の名前\n          values_to = \"Population\") %&gt;%   # 数値の情報を含む新しい列の名前\n     mutate(Sex = recode(Sex,             # 明確にするために各値を再コード化\n                         \"m\" = \"Male\",\n                         \"f\" = \"Female\"))\n\n結合した人口データは、次のようになりました（クリックすることで国 A と B の両方を確認できます）。\n\n\n\n\n\n\n次に、死亡数のデータセットについても同様の処理を行います。\n\ndeaths_countries &lt;- A_deaths %&gt;%     # 国 A の死亡数のデータセットから開始\n     bind_rows(B_deaths) %&gt;%         # 各列名が一致しているため、国 B のデータを列方向に結合\n     pivot_longer(                   # 縦長に変換\n          cols = c(Male, Female),    # これらの列を1つに結合\n          names_to = \"Sex\",          # カテゴリ（\"m\"または\"f\"）の情報を含む新しい列の名前\n          values_to = \"Deaths\") %&gt;%  # 数値の情報を含む新しい列の名前\n     rename(age_cat5 = AgeCat)       # 明確にするために名前を再変更\n\n死亡数のデータは次のようになり、両国のデータが含まれています。\n\n\n\n\n\n\n次に、共通の列 Country, age_cat5, Sex に基づいて死亡数と人口データを結合します。これにより、列 Deaths が追加されます。\n\ncountry_data &lt;- pop_countries %&gt;% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\n\nさらに、変数 Sex, age_cat5, Country を因子型変数として分類し、水準の順序を forcats パッケージの fct_relevel() を用いて設定できます。なお、因子の水準を分類してもデータに目に見える変化はありません。ただし、arrange() コマンドを実行すると、データは国、年齢カテゴリ、性別でソートされます。\n\ncountry_data &lt;- country_data %&gt;% \n     mutate(\n          Country = fct_relevel(Country, \"A\", \"B\"),\n          \n          Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n          \n          age_cat5 = fct_relevel(\n               age_cat5,\n               \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n               \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n               \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n               \"60-64\", \"65-69\", \"70-74\",\n               \"75-79\", \"80-84\", \"85\")) %&gt;% \n     \n     arrange(Country, age_cat5, Sex)\n\n\n\n\n\n\n\n注意：各層の死亡数が少ない場合、年齢について10年または15年区切りのカテゴリの使用を検討してみてください\n\n\n参照集団データの読み込み\n最後に、直接標準化のために、参照集団（性別毎の世界「標準人口」）のデータを読み込みます。\n\n# 参照集団\nstandard_pop_data &lt;- import(\"world_standard_population_by_sex.csv\")\n\n\n\n\n\n\n\n\n\n\n参照集団データのクリーニング\nデータフレーム country_data と standard_pop_data について、年齢カテゴリの値を揃える必要があります。\n現段階では、standard_pop_data における age_cat5 の列の値には “years” や “plus” といった単語が含まれていますが、country_data の方はそうなっていません。そのため、年齢カテゴリの値を揃えなくてはいけません。ここでは、Characters and strings の章で解説した stringr パッケージの str_replace_all() を使用し、これらのパターンをスペースがない形（\"\"）に置換します。\nまた、dsr パッケージでは、標準人口について人数が含まれる列の名前が \"pop\" となっている事を想定しています。それにしたがって列名を変更しておきます。\n\n# 列の各値から、特定の文字列を削除\nstandard_pop_clean &lt;- standard_pop_data %&gt;%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),  # \"year\" を削除\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),   # \"plus\" を削除\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %&gt;%  # \" \" （スペース）を削除\n     \n     rename(pop = WorldStandardPopulation)                    # dsr パッケージのために、列名を \"pop\" に変更\n\n注意： str_replace_all() を使用してプラス記号を削除しようとしても、プラス記号が特別な記号なためうまくいきません。特別な記号の前にバックスラッシュを2つ入れて「エスケープ」する必要があります。例：str_replace_call(column, \"\\\\+\", \"\")。\n\n\n参照集団のデータセット作成\n最後に、以下で詳細を説明する PHEindicatormethods パッケージでは、標準人口と各国のイベント数と人口データが一つにまとまっている事を想定しています。これにしたがって、all_data という名前のデータセットを作成します。\n\nall_data &lt;- left_join(country_data, standard_pop_clean, by = c(\"age_cat5\", \"Sex\"))\n\n完成したデータセットは以下のようになります。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>標準化率</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.jp.html#dsr-パッケージ",
    "href": "new_pages/standardization.jp.html#dsr-パッケージ",
    "title": "21  標準化率",
    "section": "21.3 dsr パッケージ",
    "text": "21.3 dsr パッケージ\n以下では、dsr パッケージを用いて直接標準化率の計算と比較を行います。dsr パッケージでは、直接標準化率の計算と比較を行うことができますが、間接標準化率は計算できません。\nデータの準備の節では、各国と標準人口について別々のデータセットを作成しました。\n\ncountry_data オブジェクトは、国ごとの各層における人口と死亡数の人口統計表です\nstandard_pop_clean オブジェクトは、ここで用いる参照集団である世界標準人口の各層における人口が含まれています\n\ndsr パッケージのために、これらの分かれているデータセットを使用します。\n\n\n標準化率（Standardized rates）\n以下では、年齢と性別による各国の直接標準化率を計算します。計算には dsr() を使用します。\n注意点：dsr() は国の人口とイベント数（死亡数）のデータフレームと別の参照集団のデータフレームに分かれている事を想定しています。また、この参照集団データセットの単位時間あたりの人口の列の名前が “pop” になっている事（これについては、データの準備の節でも確認しました）も想定しています。\n以下のコードに注釈を入れたように、この関数には沢山の引数があります。注目すべきところは、event = は列 Deaths に設定され、fu = (“follow-up”) は列 Population に設定されていることです。また、比較したいサブグループは列 Country と設定し、age_cat5 と Sex に基づいて標準化を行っています。この最後の2列には特に引数名が割り当てられていません。詳細は ?dsr を確認してください。\n\n# 年齢と性別による各国の直接標準化率の計算\nmortality_rate &lt;- dsr::dsr(\n     data = country_data,          # 各層の死亡数が含まれている方のデータの指定\n     event = Deaths,               # 各層の死亡数が含まれる列\n     fu = Population,              # 各層の人口が含まれる列\n     subgroup = Country,           # 比較の単位\n     age_cat5,                     # 他の列：これらにより率を標準化\n     Sex,\n     refdata = standard_pop_clean, # 人数の列 pop が含まれる参照集団データ\n     method = \"gamma\",             # 95%信頼区間の計算方法\n     sig = 0.95,                   # 有意水準\n     mp = 100000,                  # 100,000人あたりの率を計算したい\n     decimals = 2)                 # 小数点以下の桁数\n\n# 見た目がきれいなHTML形式の表で結果表示\nknitr::kable(mortality_rate)       # 標準化前と標準化後の死亡率を表示\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubgroup\nNumerator\nDenominator\nCrude Rate (per 1e+05)\n95% LCL (Crude)\n95% UCL (Crude)\nStd Rate (per 1e+05)\n95% LCL (Std)\n95% UCL (Std)\n\n\n\n\nA\n11344\n86790567\n13.07\n12.83\n13.31\n23.57\n23.08\n24.06\n\n\nB\n9955\n52898281\n18.82\n18.45\n19.19\n19.33\n18.46\n20.22\n\n\n\n\n\n上のように、国 A の粗死亡率は国 B よりも低いですが、年齢と性別による直接標準化を行った後の標準化率は国 A の方が高いことがわかります。\n\n\n\n標準化率比（Standardized rate tratios）\n\n# 標準化率比（RR）の計算\nmortality_rr &lt;- dsr::dsrr(\n     data = country_data,          # 各層の死亡数が含まれている方のデータの指定\n     event = Deaths,               # 各層の死亡数が含まれる列\n     fu = Population,              # 各層の人口が含まれる列\n     subgroup = Country,           # 比較の単位\n     age_cat5,                     # 標準化したい特性変数\n     Sex,                          \n     refdata = standard_pop_clean, # 人数の列 pop が含まれる参照集団データ\n     refgroup = \"B\",               # 比較の参照水準\n     estimate = \"ratio\",           # 推定値の種類\n     sig = 0.95,                   # 有意水準\n     mp = 100000,                  # 100,000人あたりの率を計算したい\n     decimals = 2)                 # 小数点以下の桁数\n\n# 結果の表示\nknitr::kable(mortality_rr) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Ratio (RR)\n95% LCL (RR)\n95% UCL (RR)\n\n\n\n\nA\nB\n23.57\n1.22\n1.17\n1.27\n\n\nB\nB\n19.33\n1.00\n0.94\n1.06\n\n\n\n\n\n標準化率は国 B よりも国 A の方が 1.22 倍（ 95 ％信頼区間は 1.17 倍 - 1.27 倍）高いです。\n\n\n\n標準化率差（Standardized rate difference）\n\n# 標準化率差（RD）の計算\nmortality_rd &lt;- dsr::dsrr(\n     data = country_data,          # 各層の死亡数が含まれている方のデータの指定\n     event = Deaths,               # 各層の死亡数が含まれる列\n     fu = Population,              # 各層の人口が含まれる列\n     subgroup = Country,           # 比較の単位\n     age_cat5,                     # 標準化したい特性変数\n     Sex,                        \n     refdata = standard_pop_clean, # 人数の列 pop が含まれる参照集団データ\n     refgroup = \"B\",               # 比較の参照水準\n     estimate = \"difference\",      # 推定値の種類\n     sig = 0.95,                   # 有意水準\n     mp = 100000,                  # 100,000人あたりの率を計算したい\n     decimals = 2)                 # 小数点以下の桁数\n\n# 結果の表示\nknitr::kable(mortality_rd)\n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Difference (RD)\n95% LCL (RD)\n95% UCL (RD)\n\n\n\n\nA\nB\n23.57\n4.24\n3.24\n5.24\n\n\nB\nB\n19.33\n0.00\n-1.24\n1.24\n\n\n\n\n\n国 A は国 B と比較して、100,000 人あたり 4.24 人（ 95 ％信頼区間は 3.24 人-5.24 人）死亡が多いです。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>標準化率</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.jp.html#standard_phe",
    "href": "new_pages/standardization.jp.html#standard_phe",
    "title": "21  標準化率",
    "section": "21.4 PHEindicatormethods パッケージ",
    "text": "21.4 PHEindicatormethods パッケージ\nPHEindicatormethods パッケージを使用すると、別のやり方で標準化率を計算できます。このパッケージでは、直接標準化も間接標準化も行うことができます。以下では、両方の例を示します。\nこの節では、データの準備の節の最後で作成したデータフレーム all_data を使用します。このデータフレームは各国の人口と死亡数、および世界標準人口が含まれています。このデータフレームについてはこちらから確認できます。\n\n\n直接標準化率\n以下では、最初にデータを国ごとにグループ化し、各国の直接標準化率を求めるためにそれを phe_dsr() に代入します。\n注意点：参照集団のデータは国毎のデータフレーム内の列または別のベクトル型オブジェクトとして指定できます。国毎のデータフレーム内の列として与える場合、stdpoptype = \"field\" を指定する必要があります。ベクトルとして与える場合、stdpoptype = \"vector\" を指定する必要があります。後者の場合、レコードが位置でマッチングされるため、各層による行の順序が国毎のデータフレームと参照集団で同じになっていることを確認する必要があります。以下の例では、参照集団は国毎のデータフレーム内の列として与えています。\n詳しくは、ヘルプ ?phr_dsr またはその他の資料の節のリンクを確認してください。\n\n# 各国の年齢と性別による直接標準化率の計算\nmortality_ds_rate_phe &lt;- all_data %&gt;%\n     group_by(Country) %&gt;%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # 観測イベント数の列\n          n = Population,             # 各層の非標準人口の列\n          stdpop = pop,               # 各層の標準人口\n          stdpoptype = \"field\")       # ベクトルで与える場合は \"vector\"、データフレーム内の列の場合は \"field\"\n\n# 結果の表示\nknitr::kable(mortality_ds_rate_phe)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\ntotal_count\ntotal_pop\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\nA\n11344\n86790567\n23.56686\n23.08107\n24.05944\n95%\ndsr per 100000\nDobson\n\n\nB\n9955\n52898281\n19.32549\n18.45516\n20.20882\n95%\ndsr per 100000\nDobson\n\n\n\n\n\n\n\n\n間接標準化率\n間接標準化のためには、参照集団の各層の死亡数と人口のデータが必要です。この例では、参照集団の standard_pop_clean に各層の死亡数が含まれていないので、国 B を参照集団として用いて国 A の間接標準化率を計算します。\n以下では、最初に国 B から参照集団のデータを作成します。次に、間接標準化率を求めるため、国 A の死亡数と人口データと参照集団のデータを calculate_ISRate() に代入します。もちろん、国 A と B を逆にすることも可能です。\n注意点：この例では、参照集団は別のデータフレームとして与えています。この場合、レコードが位置によってマッチングされるため、x =, n =, x_ref =, n_ref = のベクトルがすべて国毎のデータフレームの標準化カテゴリ（層）の値と同じ順序になっていることを確認する必要があります。\n詳しくは、ヘルプ ?phr_isr またはその他の資料の節のリンクを確認してください。\n\n# 参照集団データを作成\nrefpopCountryB &lt;- country_data %&gt;% \n     filter(Country == \"B\") \n\n# 国 A の年齢と性別による間接標準化率の計算\nmortality_is_rate_phe_A &lt;- country_data %&gt;%\n     filter(Country == \"A\") %&gt;%\n     PHEindicatormethods::calculate_ISRate(\n          x = Deaths,                        # 観測イベント数の列\n          n = Population,                    # 各層の非標準人口の列\n          x_ref = refpopCountryB$Deaths,     # 各層の参照死亡数\n          n_ref = refpopCountryB$Population) # 各層の参照人口\n\n# 結果の表示\nknitr::kable(mortality_is_rate_phe_A)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nobserved\nexpected\nref_rate\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\n11344\n15847.42\n18.81914\n13.47123\n13.22446\n13.72145\n95%\nindirectly standardised rate per 100000\nByars",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>標準化率</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.jp.html#参考資料",
    "href": "new_pages/standardization.jp.html#参考資料",
    "title": "21  標準化率",
    "section": "21.5 参考資料",
    "text": "21.5 参考資料\ndsr を用いた他の再現可能なコードを参照したい場合は、このvignette を確認してください。\nPHEindicatormethods を用いた別の例については、このウェブサイトを見てください。\nまた、PHEindicatormethods の参照マニュアルの pdf も確認してください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>標準化率</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.jp.html",
    "href": "new_pages/moving_average.jp.html",
    "title": "22  移動平均",
    "section": "",
    "text": "22.1 準備",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>移動平均</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.jp.html#準備",
    "href": "new_pages/moving_average.jp.html#準備",
    "title": "22  移動平均",
    "section": "",
    "text": "パッケージをロードする\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R basics の章をご覧ください。\n\npacman::p_load(\n  tidyverse,      # データマネージメントと可視化のため\n  slider,         # 移動平均の計算のため\n  tidyquant       # ggplot内の移動平均の計算のため\n)\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストのインポート\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nラインリストの最初の50行を以下に表示します。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>移動平均</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.jp.html#slider-を利用した計算",
    "href": "new_pages/moving_average.jp.html#slider-を利用した計算",
    "title": "22  移動平均",
    "section": "22.2 slider を利用した計算",
    "text": "22.2 slider を利用した計算\nプロットする前にデータフレームを使って移動平均を計算するには、この方法を使用します。\nslider パッケージには rolling regressions（移動平均）や累積和、rolling averages（データの時期をずらして回帰する手法）などを計算するために、いくつかの “sliding window” 関数を提供します。これはデータフレームを行（row）のベクトルとして扱い、データフレーム上の行ごとの反復計算が可能になります。\nここで、いくつかの代表的な関数を提示します：\n\nslide_dbl() - sliding window を用いた数字型（つまり、“_dbl”）の列を介して行う演算処理\n\nslide_sum() - slide_dbl()の rolling sum のショートカット関数\nslide_mean() - slide_dbl()の rolling average のショートカット関数\n\nslide_index_dbl() - windows（小範囲） の進行をインデックス化するための別の列を使用し、数字型の列に rolling window を適用する（一部の日付が存在しないデータセットで、日付による rolling をする場合に便利）\n\nslide_index_sum() - インデックスありの rolling sum のショートカット関数\nslide_index_mean() - インデックスありの rolling mean のショートカット関数\n\n\nslider パッケージはほかにも様々な関数があり、この章の Resources セクションで紹介しています。ここでは、最も一般的な機能について簡単に説明します。\n実引数\n\n.x, デフォルトでは第1引数となります。反復処理を行い、関数を適用するベクトルを指定します。\n.i = slider 機能の “index” バージョンのために、“index” をロールするための列を用意します（以下のセクションを参照）\n.f =, デフォルトでは2番目の引数となり、以下のどちらかを指定します：\n\n括弧なしで書かれた関数（例えば mean など）\n関数に変換される数式。例えば、~ .x - mean(.x) の場合は、現在の値からウィンドウの平均値を引いた結果を返します\n\nさらなる詳細はこの reference material を参照してください。\n\nWindow size（小範囲の大きさ）\n.before、.after のいずれか、または両方の引数を使用して、window sizeを指定してください：\n\n.before = - 整数を指定\n.after = - 整数を指定\n.complete = - 完全なwindow（範囲を指定する必要のない場合）に対してのみの計算を行いたい場合は TRUE に設定してください\n\n例えば、現在の値とその前の6日間の値を含む7日間のウィンドウを表示するためには、.before = 6 というように使います。中央値を基準としたウィンドウにするためには、.before = と .after = の両方に同じ値を指定します。\nデフォルトでは、.complete = は FALSE となっており、完全な行のウィンドウが存在しない場合、関数は利用可能な行を使用して計算を行います。TRUE に設定すると、完全なウィンドウでのみ計算が実施されるように制限することになります。\nWindow の拡張\n累積演算を行うためには、.before = 引数を Inf に設定します。これにより、現在の値とそれより前の全ての値に対して計算が行われます。\n\n日付による rolling\n応用疫学での rolling 計算の最も一般的な使用例は、ある指標を時系列でみることでしょう。例えば、毎日の症例数をもとにした発生数（incidence）の測定などです。\n全ての日付に値がある時系列のデータがある場合、Time series and outbreak detection の章で紹介されているように、slide_dbl() を使用してもよいでしょう。\nしかし、応用疫学分野では、イベントが記録されていない日付が欠損していることがあります。このような場合には、slider パッケージの関数の “index” バージョンを使用するのがベストです。\n\n\nインデックス化されたデータ\n以下では、感染者のラインリストに slide_index_dbl() を使った例を示します。ここでは、移動7日間発生数（7日間の window を使用したケースの合計）を計算することを目的とします。もし移動平均の例を探しているのであれば、grouped rolling のセクションを参照してください。\nまず、daily_counts というデータセットを作成し、dplyr パッケージの count() から計算された linelist の毎日の症例数を反映させましょう。\n\n# デーリーカウントのデータセットを作成\ndaily_counts &lt;- linelist %&gt;% \n  count(date_hospitalisation, name = \"new_cases\")\n\nここに、daily_counts のデータフレームがあります - nrow(daily_counts) 行があり、各日は1行で表されていますが、特に流行の初期には存在しない日もあります（その日に入院した症例はいませんでした）。\n\n\n\n\n\n\nslide_dbl() のような標準的な rolling 関数は、7日間ではなく7行のウィンドウを使用するという認識を持つことが重要です。そのため、データに入っていない日付がある場合、いくつかのウィンドウは実際には7日間よりも長くなります！\nslide_index_dbl() を使うと、「スマート」な rolling window を実現することができます。“index” とは、この関数が rolling window の “index” として別の列を使うことを意味します。window は単にデータフレームの行に基づいているわけではないのです。\nインデックス列が日付の場合、ウィンドウの範囲を .before = や .after = にして、lubridate パッケージの days() や months() の単位で指定することができます。このようにすると、関数のおかげでウィンドウに存在しない欠損日（NA 値として）も含まれることになります。\nそれでは、比較をしてみましょう。以下では、通常の7日間の rolling した発生数とインデックス window を利用した7日間の rolling した発生数を計算します。\n\nrolling &lt;- daily_counts %&gt;% \n  mutate(                                # 新しい列を作る\n    # slide_dbl() を使う\n    ###################\n    reg_7day = slide_dbl(\n      new_cases,                         # 新しいケースを計算する\n      .f = ~sum(.x, na.rm = T),          # 欠損値が除外された sum() 関数\n      .before = 6),                      # ウィンドウは当行と6つ前の行\n    \n    # slide_index_dbl() を使う\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases,                       # 新しいケースを計算する\n        .i = date_hospitalisation,       # インデックス化された date_onset \n        .f = ~sum(.x, na.rm = TRUE),     # 欠損値が除外された sum()\n        .before = days(6))               # ウィンドウは当日と6つ前の日\n    )\n\n最初の7行の通常列では、それぞれの行が7日以内ではないにもかかわらず、カウントが増加していることを確認してください！隣接する「インデックス化」された列では、データがない日にちが考慮されているため、少なくともケースの差が大きい流行のこの時期においては、7日間の合計値はかなり低くなっています。\n\n\n\n\n\n\nでは、ggplot() を用いて、これらのデータをプロットしてみましょう。\n\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nグループ別の rolling\nslider 関数を使う前にデータをグループ化した場合、sliding window はグループごとに適用されます。by group で必要な順序で行をアレンジするように注意してください。\nSliding window は新しいグループが始まるたびに再スタートします。したがって、注意しなくてはならないのは、データがグループ化されていて、.complete = TRUE を設定している場合、グループ間の移動のたびに空の値が発生するということです。関数が行を下方に移動すると、グループ化された列を移動するたびに計算を可能にする最小のウィンドウサイズが生じ、再スタートします。\nデータのグループ化に関する詳細は、データのグループ化 の章を参照してください。\n以下では、病院別かつ日付別にラインリストの症例をカウントしています。次に、行を昇順に並べます。まず病院別に並べ、その中で日付別に並べます。続いて、group_by() を設定します。そして、新しい移動平均を作ることができます。\n\ngrouped_roll &lt;- linelist %&gt;%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %&gt;% \n\n  arrange(hospital, date_hospitalisation) %&gt;%   # 病院別、続いて日付別に行を並べる\n  \n  group_by(hospital) %&gt;%              # 病院でグループ化\n    \n  mutate(                             # 移動平均  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases,                 # ケース/病院-日のカウント\n      .i = date_hospitalisation,      # 入院日のインデックス\n      .f = mean,                      # mean() を使う                  \n      .before = days(6)               # 当日と6日前までの使用\n      )\n  )\n\nこちらが、新しいデータセットです：\n\n\n\n\n\n\nggplot() の facet_wrap() に ~ hospital と指定することで、データをグループ別（ここでは病院別）に表示し、移動平均をプロットすることができます。楽しいのでここでは、毎日の症例数を示す geom_col() と、7日間の移動平均を示す geom_line() という2つの幾何学図形をプロットしてみます。\n\nggplot(data = grouped_roll)+\n  geom_col(                       # 日ごとのケースカウントを灰色のバーで表示\n    mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(                      # 病院ごとに色分けして移動平均を表示\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # 病院ごとにミニプロットを作成\n  theme_classic()+                 # 背景をシンプルに \n  theme(legend.position = \"none\")+ # 凡例を非表示にする\n  labs(                            # プロットのラベルを追加する\n    title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")\n\n\n\n\n\n\n\n\n警告： “slide() was deprecated in tsibble 0.9.0 and is now defunct. Please use slider::slide() instead.” というエラーが出た場合、tsibble パッケージの slide() をマスクしていることを意味します。 slider::slide_dbl() のように、コマンドパッケージを指定して修正してください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>移動平均</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.jp.html#ggplot-内の-tidyquant-パッケージによる計算",
    "href": "new_pages/moving_average.jp.html#ggplot-内の-tidyquant-パッケージによる計算",
    "title": "22  移動平均",
    "section": "22.3 ggplot() 内の tidyquant パッケージによる計算",
    "text": "22.3 ggplot() 内の tidyquant パッケージによる計算\ntidyquant パッケージは、移動平均を異なるアプローチで計算します - 今回は ggplot() のコマンド内の例です。\nlinelist では、データは発症日別にカウントされ、色あせた線としてプロットされています（alpha &lt; 1）。上に重ねているのは、 tidyquant パッケージの geom_ma() で作成された選で、7日間（n = 7）のウィンドウが設定され、色と太さが指定されています。\ngeom_ma() はデフォルトでは、単純移動平均（ma_fun = \"SMA\"）を使用しますが、以下のようなほかのタイプを指定することもできます：\n\n“EMA” - 指数移動平均（最近の観測値に重きを置く）\n\n“WMA” - 加重移動平均（wts は移動平均における観測値の重みづけに使用される）\nその他の機能については、関数の説明を参照してください\n\n\nlinelist %&gt;% \n  count(date_onset) %&gt;%                 # 日ごとのケースをカウントする\n  drop_na(date_onset) %&gt;%               # 発症日がないケースを除外する\n  ggplot(aes(x = date_onset, y = n))+   # ggplot を始める\n    geom_line(                          # そのままの数値をプロットする\n      size = 1,\n      alpha = 0.2                       # 半透明の線\n      )+             \n    tidyquant::geom_ma(                 # plot moving average\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # 移動平均の表示\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n\ntidyquant パッケージで利用できるオプションの更なる詳細については、ビニエット（vignette） を参照してください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>移動平均</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.jp.html#参考資料",
    "href": "new_pages/moving_average.jp.html#参考資料",
    "title": "22  移動平均",
    "section": "22.4 参考資料 { ｝",
    "text": "22.4 参考資料 { ｝\nslider パッケージの参考になるオンライン vignette はこちらをご覧ください\nslider パッケージのgithubページ\nslider パッケージの vignette\ntidyquant vignette\n週末や祝日を「スキップ」する必要がある場合は、almanac パッケージがおすすめです。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>移動平均</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html",
    "href": "new_pages/time_series.jp.html",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "",
    "text": "23.1 概観\nこのタブでは、時系列分析のためのいくつかのパッケージの使用方法を示します。主に tidyverts ファミリーのパッケージを使用していますが、感染症疫学に適したモデルをフィットさせるために、RECON trending パッケージも使用しています。\n以下の例では、ドイツのカンピロバクターに関するsurveillanceパッケージのデータセットを使用していることに注意してください（詳細はハンドブックのハンドブックとデータのダウンロードを参照してください）。しかし、同じコードを複数の国や他の層を持つデータセットで実行したい場合は、r4epis github repo にコードテンプレートの例がありますので、そちらを参照してください。\n扱うトピックは以下の通りです。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#概観",
    "href": "new_pages/time_series.jp.html#概観",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "",
    "text": "時系列データ\n\n記述統計\n\n回帰式のあてはめ\n\n2つの時系列の関係\n\nアウトブレイクの検出\n\n遮断された時系列",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#準備",
    "href": "new_pages/time_series.jp.html#準備",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.2 準備",
    "text": "23.2 準備\n\nパッケージ\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(rio,          # ファイルのインポート\n               here,         # ファイルのロケーター\n               tidyverse,    # データマネジメント + ggplot2の描画\n               tsibble,      # 時系列データセットの操作\n               slider,       # 移動平均の計算のため\n               imputeTS,     # 欠損値のフィルタリングのため\n               feasts,       # 時系列分解と自己相関のため\n               forecast,     # sinとcosの項をデータに当てはめる（注：feastsの後に読み込む必要がある）\n               trending,     # モデルの当てはめと査定\n               tmaptools,    # 地名から地理座標（lon/lat）を取得する関数\n               ecmwfr,       # copernicus sateliate CDS APIとのインタラクションのため\n               stars,        # .nc（天候データ）ファイルの読み込みのため\n               units,        # 測定ユニット（天候データ）の定義のため\n               yardstick,    # 適切なモデルを探すため\n               surveillance  # 異常検知のため\n               )\n\n\n\nデータのロード\n本ハンドブックで使用しているすべてのデータは、ハンドブックとデータのダウンロードの章の手順でダウンロードできます。\nここでは、2001年から2011年にドイツで報告されたカンピロバクター症例の週次カウントをデータセットとして例示しています。 ここをクリックすると、このデータファイル（.xlsx）  をダウンロードすることができます。\nこのデータセットは、surveillance パッケージで利用できるデータセットの縮小版です。 (詳細は surbeillance package パッケージを読み込み、 ?campyDE を参照してください)\nこれらのデータを rio （.xlsx, .csv, .rds など多くのファイルタイプを扱うことができます）パッケージの import() を使ってインポートします。\n\n# Rにcountsをインポート\ncounts &lt;- rio::import(\"campylobacter_germany.xlsx\")\n\n最初の10行のカウントが以下に表示されます。\n\n\n\n\n\n\n\n\nデータをきれいにする\n以下のコードで、日付カラムが適切なフォーマットであることを確認します。このタブでは tsibble パッケージを使用し、 yearweek() が暦週変数を作成するために使用されています。他にもいくつかの方法がありますが（詳細は 日付型データ の章を参照してください）、時系列の場合は1つのフレームワーク（tsibble）に収めるのがベストです。\n\n## 日付カラムが適切なフォーマットであることを確認する\ncounts$date &lt;- as.Date(counts$date)\n\n## 歴週変数を作成する\n## ISOの定義に準拠した月曜日から始まる週の定義にフィットさせる\ncounts &lt;- counts %&gt;% \n     mutate(epiweek = yearweek(date, week_start = 1))\n\n\n\n天候データのダウンロード\nこの章の 2つの時系列の関連 では、カンピロバクターの症例数と気候データを比較します。\n世界各地の気候データは、EUのコペルニクス衛星からダウンロードできます。これらは正確な測定値ではなくモデルに基づいていますが（補間に似ています）、全世界を1時間ごとにカバーし、予測もできるという利点があります。\nこれらの各気候データファイルは、ハンドブックとデータのダウンロードの章からダウンロードできます。\nここではデモンストレーションとして、 ecmwfr パッケージを使用して Copernicus 気候データストアからこれらのデータを取得するための R コードを紹介します。この機能を利用するには無料のアカウントの作成が必要です。パッケージのウェブサイトには、この方法に関する便利なウォークスルーがあります。以下は、適切な API キーを取得した上で、これを実行する方法のサンプルコードです。下記の X をお客様のアカウントIDに置き換えていただく必要があります。一度に1年分のデータをダウンロードしないと、サーバーがタイムアウトしてしまうので注意が必要です。\nデータをダウンロードしたい場所の座標がわからない場合は、tmaptools パッケージを使って、オープンストリートマップから座標を引き出すことができます。別の選択肢として、photon パッケージがありますが、これはまだ CRAN にはリリースされていません。photon パッケージの良い点は、検索に複数のマッチがあった場合に、より多くの文脈的なデータを提供することです。\n\n## 位置情報の取得\ncoords &lt;- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## ERA-5のクエリに対応したフォーマットでlong/latsをまとめる(bounding box) \n## (1つの点が欲しいだけなので、座標を繰り返すことはできない)\nrequest_coords &lt;- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## copernicus satellite (ERA-5 reanalysis)からモデル化したデータを引っ張ってくる。\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## 天気データ用のキーを設定\nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## 対象となる年ごとに実行（そうしないとサーバーがタイムアウトする）\nfor (i in 2002:2011) {\n  \n  ## クエリを作成する\n  ## 方法はこちらを参照：https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## 上記の Addins ボタンを使って request を list に変更（Python で list 化)\n  ## Target は出力ファイルの名前です！！\n  request &lt;- request &lt;- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## ファイルをダウンロードして、現在の作業ディレクトリに保存\n  file &lt;- wf_request(user     = \"XXXXX\",  # ユーザーID（認証用）\n                     request  = request,  # request\n                     transfer = TRUE,     # ファイルのダウンロード\n                     path     = here::here(\"data\", \"Weather\")) ## 保存データへのパス\n  }\n\n\n\n天候データの読み込み\n気候データをハンドブックからダウンロードした場合も、上記のコードを使用した場合も、コンピュータの同じフォルダに10年分の “.nc” 気候データファイルが保存されているはずです。\n以下のコードを使用して、これらのファイルを stars パッケージで R にインポートします。\n\n## 天気フォルダへのパスの定義\nfile_paths &lt;- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # あなた自身のファイルパスとの置き換え\n  full.names = TRUE)\n\n## 現在の興味ある名前のものだけを残す \nfile_paths &lt;- file_paths[str_detect(file_paths, \"germany\")]\n\n## 全てのファイルをstartsオブジェクトとして読み込み\ndata &lt;- stars::read_stars(file_paths)\n\nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \n\n\nこれらのファイルがオブジェクト data としてインポートされたら、データフレームに変換します。\n\n## データフレームへの変更\ntemp_data &lt;- as_tibble(data) %&gt;% \n  ## 変数の追加と単位の修正\n  mutate(\n    ## 歴週変数の作成\n    epiweek = tsibble::yearweek(time), \n    ## 日付変数の作成（カレンダーの週の始まり）\n    date = as.Date(epiweek),\n    ## 気温をケルビンから摂氏へ変更\n    t2m = set_units(t2m, celsius), \n    ## 降水量をメートル単位からミリ単位へ変更\n    tp  = set_units(tp, mm)) %&gt;% \n  ## 週でグループ化（日付も残す）\n  group_by(epiweek, date) %&gt;% \n  ## 週平均を取得\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))\n\n`summarise()` has grouped output by 'epiweek'. You can override using the\n`.groups` argument.",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#時系列データ",
    "href": "new_pages/time_series.jp.html#時系列データ",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.3 時系列データ",
    "text": "23.3 時系列データ\n時系列データを構造化して扱うためのさまざまなパッケージがあります。前述の通り、ここでは tidyverts ファミリーのパッケージに焦点を当て、時系列オブジェクトを定義するために tsibble パッケージを使用します。データセットが時系列オブジェクトとして定義されていると、分析の構造化が非常に容易になります。\nこれには、 tsibble() を使用して「インデックス」、つまり、対象となる時間単位を指定する変数を指定します。ここでは、 epiweek という変数を使っています。\n例えば、県別の週間カウントのデータセットがあったとすると、key = という引数でグループ化変数を指定することもできます。 これにより、グループごとの分析が可能となります。\n\n## 時系列オブジェクトの定義\ncounts &lt;- tsibble(counts, index = epiweek)\n\nclass(counts) を見ると、 tidy なデータフレーム(“tbl_df”, “tbl”, “data.frame”)であることに加えて、時系列データフレーム(“tbl_ts”)の追加特性を持っていることがわかります。\nデータは ggplot2 パッケージを使って簡単に見ることができます。このプロットから、明確な季節パターンがあり、欠落がないことがわかります。しかし、毎年年明けの報告には問題があるようで、年末の最終週は件数が減り、翌年の第1週は件数が増えます。\n\n## 週ごとのケースを折れ線グラフにする\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()\n\n\n\n\n\n\n\n\n警告： ほとんどのデータセットはこの例のようにきれいではありません。 重複や欠落を以下のようにチェックする必要があります。。\n\n\n重複\ntsibble では観測値の重複を認めていません。そのため、各行が一意、またはグループ内で一意である必要があります（key 変数）。 このパッケージには、重複しているかどうかのTRUE/FALSEベクトルを与える are_duplicated() や，重複している行のデータフレームを与える duplicates() など、重複を識別するのに役立つ関数がいくつかあります。\n必要な行の選択方法の詳細については重複データの排除の章を参照してください。\n\n## 行が重複しているかどうかのTRUE/FALSEのベクトルを得る\nare_duplicated(counts, index = epiweek) \n\n## 重複している行のデータフレームを取得する\nduplicates(counts, index = epiweek) \n\n\n\n\n欠損値\n上記の簡単な検査では見逃しがないことを確認しましたが、新年頃に報告が遅れる問題があるようにも見えました。この問題に対処する1つの方法は、これらの値を欠損に設定して値を入力することです。時系列データに対する代入の最も簡単な方法は、最後の欠損していない値と次の欠損していない値の間を直線で結ぶことです。これを行うために、 imputeTS パッケージのna_interpolation() を使用します．\n代入の他のオプションについては、欠損データの処理の章を参照してください。\n別の方法として、移動平均を計算して用いることでこれらの明らかな報告の問題をスムーズにすることができます（次のセクション、および移動平均の章を参照してください）。\n\n## 報告書の課題で週数ではなく欠勤数で変数を作成\ncounts &lt;- counts %&gt;% \n     mutate(case_miss = if_else(\n          ## epiweekが52、53、1 または 2を含む場合\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## 欠損値をセット\n          NA_real_, \n          ## そうでない場合、case に値を保持\n          case\n     ))\n\n## 直線的な傾向で欠損値を補う方法\n## 隣接する2点の間\ncounts &lt;- counts %&gt;% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## 元の値と比較してどのような値が代入されたかを確認する\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成\n  theme_classic()",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#記述統計",
    "href": "new_pages/time_series.jp.html#記述統計",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.4 記述統計",
    "text": "23.4 記述統計\n\n\n移動平均\n値が上下に短期間で大きく変動するようなデータの場合は、移動平均を計算することが有効です。以下の例では、各週で、前の4週間の平均件数を計算します。これは、データをスムーズにして解釈しやすくするためのものです。私たちの場合、これにはあまり意味がないため、さらなる解析のために補間されたデータにこだわります。 詳細は、移動平均の章を参照してください。\n\n## 移動平均変数の作成（欠損値の処理）\ncounts &lt;- counts %&gt;% \n     ## ma_4W 変数の作成\n     ## ケース変数の各行をスライドさせる\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## すべての行について name を計算する\n                               ~ mean(.x, na.rm = TRUE),\n                               ## 4週前を使う\n                               .before = 4))\n\n## 違いを一目で分かるように作成\nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n周期性\n以下では、周期表を作成するためのカスタム関数を定義します。R での関数の書き方は関数の作成の章を参照してください。\nまず，関数を定義します．この関数の引数には、counts列を持つデータセット、データセットの最初の週を表すstart_week =、1年に何回の期間があるかを示す数字（例：52, 12）、そして最後に出力スタイルが含まれます（詳細は以下のコードを参照してください）。\n\n## 関数の引数\n#####################\n## xはデータセット\n## countsはx内のカウントデータまたはレートの変数\n## start_weekはデータセットの最初の週\n## periodは1年での単位数\n## outputは スペクトルの周期表を返すか、ピークの週数を返すかの指定\n  ## ”periodogram\" or \"weeks\"\n\n# 関数の定義\nperiodogram &lt;- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## tsibble でないことを確認し、プロジェクトにフィルターをかけ、関心のある列だけ残す\n    prepare_data &lt;- dplyr::as_tibble(x)\n    \n    # prepare_data &lt;- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data &lt;- dplyr::select(prepare_data, {{counts}})\n    \n    ## spec.pgram で使用できるように、中間的な \"zoo\" 時系列を作成する\n    zoo_cases &lt;- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## 高速フーリエ変換を使わずにスペクトル・ピリオドグラムを得ることができる\n    periodo &lt;- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## ピークの週を返す\n    periodo_weeks &lt;- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## 最も多い頻度を持つ週を抽出するためのスペクトル・ピリオドグラムを取得する\n## （季節性の確認）\nperiodo &lt;- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## スペクトルと周期をデータフレームに取り込み、プロットする\nperiodo &lt;- data.frame(periodo$freq, periodo$spec)\n\n## 最も頻繁に発生する周期性を示す周期表を作成する\nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n\n\n\n\n\n\n\n# 昇順で週のベクトルを取得する\npeak_weeks &lt;- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")\n\n注釈： 上の週を使って sin と cos の項に追加することも可能ですが、ここではこれらの項を生成する関数を使用します（下記の回帰の項を参照）\n\n\n\n分解\n古典的分解は、時系列をいくつかの部分に分割するために使用され、それらの部分を組み合わせることで、目に見えるパターンを構成します。これらの異なる部分とは\n\nトレンド・サイクル（データの長期的な方向性）\n\n季節性（繰り返されるパターン\n\nランダム（トレンドと季節を取り除いた後に残るもの）\n\n\n## counts データセットの分解\ncounts %&gt;% \n  # 追加的な分解モデルを使用する\n  model(classical_decomposition(case_int, type = \"additive\")) %&gt;% \n  ## モデルから重要な情報を抽出する\n  components() %&gt;% \n  ## プロットを生成する\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n自己相関\n自己相関は、各週のカウント値とその前の週（ラグと呼ばれる）との関係を示します。\nACF() を使って，異なるラグでの関係を示す複数の線を示すプロットを作成することができます。ラグが 0 (x = 0) の場合、この線は観測値とそれ自体の関係を示すため、常に1になります（ここでは示していません）。ここで示されている最初の線（x = 1）は、各観測値とその前の観測値との関係（ラグ 1 ）を示し、2番目の線は、各観測値と直前の観測値との関係（ラグ 2 ）を示し、さらに 1 年後（ 52 週前）の観測値との関係を示すラグ 52 まで続きます。\nPACF()（部分自己相関）を使うと同じような関係が見られますが、他のすべての週の間で調整されています。これは、周期性を決定するための情報としては不十分です。\n\n## counts データセットを使用\ncounts %&gt;% \n  ## 1年分のラグを使用して自己相関を計算する\n  ACF(case_int, lag_max = 52) %&gt;% \n  ## プロットを表示する\n  autoplot()\n\n\n\n\n\n\n\n## counts データセットを使用する\ncounts %&gt;% \n  ## 1年分のラグを使用して部分自己相関を計算する\n  PACF(case_int, lag_max = 52) %&gt;% \n  ## プロットを表示\n  autoplot()\n\n\n\n\n\n\n\n\nLjung-Box 検定（ stats パッケージ）を使用して、時系列の独立性の帰無仮説を正式に検定することができます（つまり、自己相関がない）。 有意な p 値は、データに自己相関があることを示唆します。\n\n## 独立性を検定する\nBox.test(counts$case_int, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  counts$case_int\nX-squared = 462.65, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#回帰式の当てはめ",
    "href": "new_pages/time_series.jp.html#回帰式の当てはめ",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.5 回帰式の当てはめ",
    "text": "23.5 回帰式の当てはめ\n時系列には多くの異なる回帰をフィットさせることができますが、ここでは、負の二項回帰を当てはめる方法を示します。 これは、感染症のカウントデータに最も適しているからです。\n\n\nフーリエ列\nフーリエ列は、sin と cosin の曲線に相当します。違いは、データを説明するのに最も適した曲線の組み合わせを見つけてフィットさせることです。\n1つのフーリエ列をフィッティングするだけなら、周期表で最も頻繁に発生するラグ（ここでは 52 週）に対して、sinとcosinをフィッティングするのと同義になります。ここでは forecast パッケージの fourier() を使用しています。\n以下のコードでは、 $ を使って代入しています。これは、 fourier() が2つの列（sin と cosin）を返すので、これらを “fourier” と呼ばれるリストとしてデータセットに追加しているためです。このリストは回帰分析において通常の変数と同様に利用できます。\n\n## epiweek と case_int の変数を使ってフーリエ列を追加する\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  fourier(K = 1)\n\n\n\n\n負の二項回帰\nベースとなる stats パッケージや MASS パッケージの関数（例： lm(), glm(), glm.nb()）を用いて回帰の当てはめを行えます。しかしここでは trending パッケージの関数を使用します。これは適切な信頼区間と予測区間を計算できるからです（これは他の方法では利用できません）。構文は同じで、アウトカム変数を指定した後、チルダ（~）を入力し、プラス（+）で区切って関心のある様々な暴露変数を追加します。\nもう一つの違いは、まずモデルを定義してそれをデータに fit() することです。これは、同じ構文で複数の異なるモデルを比較できるという点で便利です。\nヒント： もし、数ではなく率を使いたい場合は、 offset(log(population) を追加することで、対数オフセット項として population 変数を含めることができます。レートを生成するには、 predict() を使う前に population を 1 に設定する必要があります。\nヒント： ARIMA や prophet などのより複雑なモデルの当てはめについては、fable パッケージをご参照ください。。\n\n## 当てはめたいモデル（負の二項回帰）の定義\nmodel &lt;- glm_nb_model(\n  ## 関心のあるアウトカムとしてケースの番号をセットする\n  case_int ~\n    ## トレンドを説明するため epiweek を使用する\n    epiweek +\n    ## 季節性を説明するためフーリエ列を使用する\n    fourier)\n\n## counts データセットを使用してモデルを当てはめる\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## 信頼区間と予測区間を計算する\nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nestimate_res &lt;- data.frame(observed$result)\n\n## 回帰式をプロットする\nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## モデル推定値の線を追加する\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## 予測区間のバンドを追加する\n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## 観察されたケースの数を現す線を追加する\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成する\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n残差\n我々のモデルが観測されたデータにどれだけフィットしているかを理解するには、残差を見る必要があります。 残差は、観測されたカウントとモデルから推定されたカウントとの差です。これは、単純に case_int - estimate を使って計算することもできますが、 residuals() は，回帰から直接残差を抽出してくれます。\n下の図からわかることは、モデルで説明できる変動のすべてを説明できていないということです。もっとフーリエ列をフィットさせて、振れ幅に対処すべきかもしれません。しかし、この例では、このままにしておきます。このプロットは、我々のモデルがピークとトラフ（カウントが最高と最低の時）で悪く、観測されたカウントをより過小評価する可能性があることを示しています。\n\n## 残差を計算する\nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = fitted_model$result[[1]]$residuals)\n\n## 残差は時間経過で概ね一定か？（そうでない場合： アウトブレイク？治療の変化？）\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## 残差に自己相関があるか（誤差にパターンがあるか？）\nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## 残差が正規分布しているか（過小または過大推定か？）\nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## 観測されたカウントとその残差を比較する\n  ## パターンがないべき \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## 残差の自己相関を正式に検定する\n## H0 は残差がホワイトノイズ系列（つまりランダム）であるとする\n## 独立性を検定する\n## p 値が有意であればランダムではありません。\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 336.25, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#つの時系列の関係性",
    "href": "new_pages/time_series.jp.html#つの時系列の関係性",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.6 2つの時系列の関係性",
    "text": "23.6 2つの時系列の関係性\nここでは、気象データ（特に気温）を用いてカンピロバクターの症例数を説明する方法を見てみます。\n\n\nデータセットのマージ\nweek の変数を使ってデータセットを結合することができます。結合の詳細については、ハンドブックのデータの結合のセクションを参照してください。\n\n## 左結合で、counts にすでに存在する行だけを保持する\n## temp_data から、date 変数を除外する（そうしないと重複する）\ncounts &lt;- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")\n\n\n\n\n記述統計\nまず、データをプロットして、明らかな関係があるかどうかを確認します。 下のプロットは、2つの変数の季節性に明確な関係があることを示しています。温度がケース番号の数週間前にピークに達することがあります。 データピボットについての詳細は、ハンドブックのデータの縦横変換のセクションを参照してください。\n\ncounts %&gt;% \n  ## 関心のある変数を保持する\n  select(epiweek, case_int, t2m) %&gt;% \n  ## 縦型のフォーマットにデータを変更する\n  pivot_longer(\n    ## epiweekをキーとして使用する\n    !epiweek,\n    ## 列名を新たな \"measure\" 列に移動させる\n    names_to = \"measure\", \n    ## セルの値を新たな \"values\" 列に移動させる\n    values_to = \"value\") %&gt;% \n  ## 上記のデータセットでプロットを作成する\n  ## epiweekをX軸、値（カウント/摂氏）をY軸にプロット\n  ggplot(aes(x = epiweek, y = value)) + \n    ## 気温とケースの数について分離したプロットを作成\n    ## それらを書くY軸に配置する\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## 両方を線にしてプロットする\n    geom_line()\n\n\n\n\n\n\n\n\n\n\n\nラグと相互相関\nケースと温度の間にどの週が最も高い関係にあるかを正式に検証するために\nこれには feasts パッケージの相互相関関数 (CCF()) が使用可能です。 また（ arrange ではなく） autoplot() を使って視覚化することもできます。\n\ncounts %&gt;% \n  ## 補完された和と気温の間の相互相関を計算する\n  CCF(case_int, t2m,\n      ## 最大のラグを52週としてセットする\n      lag_max = 52, \n      ## 相関係数を返す\n      type = \"correlation\") %&gt;% \n  ## 相関係数を降順に並び替える\n  ## 最も関連するラグを表示する\n  arrange(-ccf) %&gt;% \n  ## 上位10のみ表示する\n  slice_head(n = 10)\n\n# A tsibble: 10 x 2 [1W]\n        lag   ccf\n   &lt;cf_lag&gt; &lt;dbl&gt;\n 1      -4W 0.749\n 2      -5W 0.745\n 3      -3W 0.735\n 4      -6W 0.729\n 5      -2W 0.727\n 6      -7W 0.704\n 7      -1W 0.695\n 8      -8W 0.671\n 9       0W 0.649\n10      47W 0.638\n\n\nこのことから、4週間のラグが最も相関性が高いことがわかりますので、ラグ付きの温度変数を作って回帰に含めます。\n警告： 遅延した温度変数のデータの最初の4週間が欠けている（NA）ことに注意してください - データを取得するための4週間前のデータがないからです。このデータセットを トレンド の predict() で使用するためには、 predict() の中の simulate_pi = FALSE 引数をさらに下の方で使用する必要があります。simulate オプションを使用したい場合は、以下のコードチャンクに drop_na(t2m_lag4) を追加することで、これらのミスを削除し、新しいデータセットとして保存しなければなりません。\n\ncounts &lt;- counts %&gt;% \n  ## 4週でラグされた気温の変数を作成する\n  mutate(t2m_lag4 = lag(t2m, n = 4))\n\n\n\n\n2変数における負の二項分布\n前述のように負の二項回帰を当てはめます。今回は、4週間遅れの温度変数を加えます。\n注意： predict() の引数の中で simulate_pi = FALSE を使用していることに注意してください。これは、 trending のデフォルトの動作として、 ciTools パッケージを使用して予測区間を推定するためです。これは、 NA が含まれている場合には機能せず、また、より荒い間隔を生成します。詳細は ?trending::predict.trending_model_fit を参照してください。\n\n## 当てはめたいモデル（負の二項分布）を定義する\nmodel &lt;- glm_nb_model(\n  ## 関心のあるアウトカムとしてケースの数をセットする\n  case_int ~\n    ## トレンドの説明のために epiweek を使用する\n    epiweek +\n    ## 季節性の説明のためにフーリエ列を使用する\n    fourier + \n    ## 4週間ラグされた気温を使用する\n    t2m_lag4\n    )\n\n## counts データセットを使用してモデルの当てはめを行う\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## 信頼区間と予測区間を計算する\nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\n個々の項を調べるために get_model() を使用して trending フォーマットから元の負の二項回帰を取り出し、指数化された推定値とそれに関連する信頼区間を取得するために、これを broom パッケージの tidy() に渡します。\nこのことからわかるのは、トレンドと季節性を調整した後のラグ付き気温は症例数（推定値～ 1 ）と似通っており、有意に関連していることがわかります。 これは、ラグ付き気温が将来の症例数を予測するのに適した変数であることを示唆しています（気候予測は容易に入手可能です）。\n\nfitted_model %&gt;% \n  ## 元の負の二項回帰を抽出する\n  get_fitted_model() #%&gt;% \n\n[[1]]\n\nCall:  glm.nb(formula = case_int ~ epiweek + fourier + t2m_lag4, data = data.frame(counts), \n    init.theta = 32.80689607, link = log)\n\nCoefficients:\n (Intercept)       epiweek  fourierS1-52  fourierC1-52      t2m_lag4  \n   5.825e+00     8.464e-05    -2.850e-01    -1.954e-01     6.672e-03  \n\nDegrees of Freedom: 504 Total (i.e. Null);  500 Residual\n  (4 observations deleted due to missingness)\nNull Deviance:      2015 \nResidual Deviance: 508.2    AIC: 6784\n\n  ## 結果についての tidy なデータフレームを取得する\n  # tidy(exponentiate = TRUE, \n  #      conf.int = TRUE)\n\nこのモデルを可視化すると、観測された症例数のより正確な推定が可能かもしれないことがわかります。\n\nestimate_res &lt;- data.frame(observed$result)\n\n## 回帰式をプロットする\nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## モデルの推定値の線を追加する\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## 予測区間のバンドを追加する\n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## 観測されたケースの数の線を追加する\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成する\n  theme_classic()\n\n\n\n\n\n\n\n\n\n残差\n私たちのモデルが観測されたデータにどれだけフィットしているかを見るために、再び残差を調査します。 ここでの結果と解釈は前回の回帰のものと似ており、温度なしのよりシンプルなモデルにこだわる方が実現性が高いかもしれません。\n\n## 残差を計算する\nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = case_int - estimate)\n\n## 残差は時間経過で概ね一定か？（そうでない場合： アウトブレイク？治療の変化？）\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## 残差に自己相関があるか（誤差にパターンがあるか？）\nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## 残差が正規分布しているか（過小または過大推定か？） \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## 観測されたカウントとその残差を比較する\n  ## パターンがないべき \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## 残差の自己相関を正式に検定する\n## H0 は残差がホワイトノイズ系列（つまりランダム）であるとする\n## 独立性を検定する\n## p 値が有意であればランダムではない\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 339.52, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#アウトブレイク",
    "href": "new_pages/time_series.jp.html#アウトブレイク",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.7 アウトブレイク",
    "text": "23.7 アウトブレイク\nここでは、集団発生を検知する2つの（類似した）方法を紹介します。\n1つ目は、上記のセクションを基にしています。\n過去の年に回帰を当てはめるために trending パッケージを使用し、次の年以降に何が起こるかを予測します。観察された数が予測を上回っていれば、アウトブレイクが発生していることを示唆しています。 2つ目の方法は、同様の原理に基づいていますが、 surveillance パッケージを使用します。このパッケージには、異常を検出するためのさまざまなアルゴリズムが含まれています。\n注意： 通常は現在の年（現在の週までのカウントしかわからない場合）におけるアウトブレイクの発生に関心があります。この例では、2011年の第39週にいると仮定しています。\n\n\ntrending パッケージ\nこの方法ではベースライン（通常は約5年分のデータ）を定義します。\nベースラインのデータに回帰分析を行い、それをもとに次年度の推定値を予測します。\n\n\n日付のカットオフ\n日付を一箇所で定義し、それを残りのコードで使用するのが簡単です。\nここでは、開始日（観測を開始した日）とカットオフ日（ベースライン期間の終了日であり、予測したい期間の開始日）を定義します。 また、対象となる年(これから予測するもの)が何週目であるかも定義します。\nヒント： この例では、現在、2011年9月末（ “2011W39” ）にいることにしています。\n\n## 開始日（いつ観測を開始したか）を定義する\nstart_date &lt;- min(counts$epiweek)\n\n## カットオフ週（ベースラインの最終、予測期間の開始）を定義する\ncut_off &lt;- yearweek(\"2010-12-31\")\n\n## 関心のある最終日を定義する（例：予測の最後）\nend_date &lt;- yearweek(\"2011-12-31\")\n\n## 関心のある期間（年）における週数を取得\nnum_weeks &lt;- as.numeric(end_date - cut_off)\n\n\n\n\n行の追加\nTidyverse 形式で予測するためには、データセットに適切な数の行が必要です。すなわち、上で定義した end_date まで、各週に1行ずつです。 以下のコードでは、グループ化変数によってこれらの行を追加することができます。例えば、1つのデータセットに複数の国がある場合、各国をグループとし、それぞれの国に適切な行を追加することができます。 tsibble パッケージの group_by_key() でこのグループ化を行い、グループ化されたデータを dplyr パッケージの group_modify() および add_row() に渡すことができます。次に、現在データにある最大の週の1つ後から最終週までの週の順序を指定します。\n\n## 年末までの欠損週を追加する\ncounts &lt;- counts %&gt;%\n  ## 地域でグループ化する\n  group_by_key() %&gt;%\n  ## 各グループに対して最も高いepiweekから年末までの行を追加する\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))\n\n\n\n\nフーリエ列\nフーリエ列を再定義する必要があります。これは、基準日にのみフーリエ列をフィットさせ、翌年のフーリエ列を予測（外挿）したいからです。 そのためには、 fourier() からの2つのリストの出力を組み合わせる必要があります。1つ目はベースラインデータに対するもので、2つ目は（h引数を定義することで）対象となる年の予測です。\n備考： 行を結合するためには tidyverse の bind_rows ではなく、 rbind() を用いなければなりません。これは、フーリエ列がリスト（個別に名前がついていない）であるためです。\n\n## フーリエ列（sincos）を定義する\ncounts &lt;- counts %&gt;% \n  mutate(\n    ## 2010年のカットオフ日前後の週のフーリエ列を組み合わせる\n    ## （nb. フーリエ列は予測される）\n    fourier = rbind(\n      ## 過去の年のフーリエ列を取得する\n      fourier(\n        ## 2011年以前の行のみ保持する\n        filter(counts, \n               epiweek &lt;= cut_off), \n        ## サイン、コサインの項を1つのセットとして含める\n        K = 1\n        ), \n      ## 2011年におけるフーリエ列を予測する（ベースラインデータを用いる）\n      fourier(\n        ## 2011年以前の行のみ保持する\n        filter(counts, \n               epiweek &lt;= cut_off),\n        ## サイン、コサインの項を1つのセットとして含める\n        K = 1, \n        ## 52週後を予測する\n        h = num_weeks\n        )\n      )\n    )\n\n\n\n\nデータの分割と回帰式の当てはめ\n次に、データセットをベースライン期間と予測期間に分割する必要があります。これは、 group_by() の後に dplyr パッケージの group_split() を使って行い、カットオフ前とカットオフ後の2つのデータフレームを持つリストを作成します。\n次に，purrr パッケージの pluck() を使ってリストからデータセットを取り出し（角括弧を使った場合と同じです，例：dat[[1]]），ベースラインデータにモデルを当てはめ、カットオフ後の関心のあるデータに対して predict() を使います．\npurrr パッケージについてはループと反復処理・リストの操作の章を参照してください。\n注意： predict() の引数で simulate_pi = FALSE を使用していることに注意してください。これは、 trending パッケージのデフォルトの動作として、 ciTools パッケージを使用して予測区間を推定するためです。これは、NAカウントがある場合には機能せず、また、より詳細な間隔を生成します。 詳細は ?trending::predict.trending_model_fit を参照してください。\n\n# 当てはめと予測のためにデータを分割する\ndat &lt;- counts %&gt;% \n  group_by(epiweek &lt;= cut_off) %&gt;%\n  group_split()\n\n## 当てはめたいモデル（負の二項回帰）を定義する\nmodel &lt;- glm_nb_model(\n  ## 関心のあるアウトカムとしてケースの数をセットする\n  case_int ~\n    ## トレンドの説明のために epiweek を使用する\n    epiweek +\n    ## 季節性の説明のためにフーリエ列を使用する\n    fourier\n)\n\n# どのデータをあてはめに使用し、どのデータを予測に使用するかを定義する\nfitting_data &lt;- pluck(dat, 2)\npred_data &lt;- pluck(dat, 1) %&gt;% \n  select(case_int, epiweek, fourier)\n\n# モデルの当てはめを行う\nfitted_model &lt;- trending::fit(model, data.frame(fitting_data))\n\n# 当てはめたデータのconfintと推定値を得る\nobserved &lt;- fitted_model %&gt;% \n  predict(simulate_pi = FALSE)\n\n# 予測したいデータで予測する\nforecasts &lt;- fitted_model %&gt;% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## ベースラインと予測されたデータセットを結合する\nobserved &lt;- bind_rows(observed$result, forecasts$result)\n\n前述のように、モデルを ggplot で可視化することができます。95% 予測区間を超えて観測された数のアラートを赤いドットで強調しています。今回は、予測開始時刻を示す縦線も加えています。\n\n## 回帰式をプロットする\nggplot(data = observed, aes(x = epiweek)) + \n  ## モデル推定値についての線を追加する\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## 予測区間のバンドを追加する\n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## 観測されたケースの数についての線を追加する\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## 期待値以上の観測値観測されたケースについての点をプロットする\n  geom_point(\n    data = filter(observed, case_int &gt; upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## 予測開始の箇所を表示するために水平線とラベルを追加する\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成する\n  theme_classic()\n\nWarning: Removed 13 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n予測と妥当性検証\n残差を調べるだけでなく、モデルが将来のケースをどの程度予測できるかを調べることも重要です。これによりあなたの設定した閾値による警告の信頼性を知ることができます。\n伝統的な検証方法としては、一つ前の年をどの程度予測できるかを確認していました（なぜなら、「今の年」の症例数がまだわからないからです）。例えば今回のデータセットでは、2002年から2009年までのデータを使って2010年を予測し、その予測の正確さを確認します。その後、2010年のデータを含むようにモデルを修正し、それを使って2011年の数を予測します。\n下の図は Hyndman et al による “Forecasting principles and practice” に掲載されています。\n 図は著者の許可を得て転載しています。\nこの場合のデメリットは、使用可能なすべてのデータを使用していないことと、予測に使用する最終モデルではないことです。\nもう一つの方法は、交差妥当性と呼ばれる方法です。このシナリオでは、利用可能なすべてのデータをロールオーバーさせ、1年先を予測するための複数のモデルに適合させます。 以下の同じ [Hyndman et al text]((https://otexts.com/fpp3/) の図のように、それぞれのモデルにはより多くのデータを使用します。 例えば、1つ目のモデルは2002年を使って2003年を予測し、2つ目は2002年と2003年を使って2004年を予測する、といった具合です。図は著者の許可を得て転載しています。\n以下では、 purrr パッケージの map() を使用して各データセットをループさせます。次に、推定値を1つのデータセットにまとめ、元の症例数とマージし、 yardstick パッケージを使用して精度の測定値を計算します。以下の4つの指標を計算しました。平均平方根誤差（RMSE: root mean square error）、平均絶対誤差（MAE: mean absolute error）、平均絶対尺度誤差（MASE: mean absolute scaled error）、平均絶対パーセント誤差（MAPE: mean absolute percent error）です。\n注意： predict() の引数で simulate_pi = FALSE を使用していることに注意してください。これは trending のデフォルトの動作が ciTools パッケージを使用して予測区間を推定することだからです。これは これはNAカウントがある場合には機能せず、また、より荒い間隔を生成します。 詳細は ?trending::predict.trending_model_fit を参照してください。\n\n## 交差確認法： スライディングウィンドウに基づいて1週間先を予測する\n\n## データを52週分（前+後）に分割して表示する\n## 52週先を予測する\n## (観察の連鎖がどんどん長くなり、古いデータが残る）\n\n## ロールオーバーさせたい窓を定義する\nroll_window &lt;- 52\n\n## 何週間先を予測したいかを定義する\nweeks_ahead &lt;- 52\n\n## 繰り返しの、長いデータセットを作成する\n## 各データセットに一意のIDを付与する\n## 関心のある年（例： 2011年）の前のケースのみを使用する\ncase_roll &lt;- counts %&gt;% \n  filter(epiweek &lt; cut_off) %&gt;% \n  ## 週とケースの数の変数のみを保持する\n  select(epiweek, case_int) %&gt;% \n    ## 最新の x 観測値を除外する\n    ## 何週間先まで予測するかによって\n    ##（そうでない場合は\"\"unknownへの実際の予測となる） \n    slice(1:(n() - weeks_ahead)) %&gt;%\n    as_tsibble(index = epiweek) %&gt;% \n    ## グループ化された ID を作成するために、 x の後のウィンドウで各週をロールオーバーする\n    ## ローリングウィンドウの指定に応じて\n    stretch_tsibble(.init = roll_window, .step = 1) %&gt;% \n  ## 「以前」のケースがないため - 最初の組み合わせを削除する\n  filter(.id &gt; roll_window)\n\n\n## それぞれのデータセットに対して、以下のコードを実行する\nforecasts &lt;- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## 現在の折り返しをフィットさせるのみ\n  mini_data &lt;- filter(case_roll, .id == i) %&gt;% \n    as_tibble()\n  \n  ## 予測するための空のデータセットを作成する\n  forecast_data &lt;- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## 予測データを元のデータに追加する\n  mini_data &lt;- bind_rows(mini_data, forecast_data)\n  \n  ## 最新の非欠損カウントデータに基づいてカットオフを定義する\n  cv_cut_off &lt;- mini_data %&gt;% \n    ## 欠損していない行のみを保持する\n    drop_na(case_int) %&gt;% \n    ## 最新の週を取得する\n    summarise(max(epiweek)) %&gt;% \n    ## 抽出したものはデータフレームには含まれない\n    pull()\n  \n  ## mini_data を tsibble に戻す\n  mini_data &lt;- tsibble(mini_data, index = epiweek)\n  \n  ## フーリエ列（sincos）を定義する\n  mini_data &lt;- mini_data %&gt;% \n    mutate(\n    ## カットオフ日の前後の週のフーリエ列を組み合わせる\n    fourier = rbind(\n      ## 以前の年のフーリエ列を取得する\n      forecast::fourier(\n        ## カットオフ以前の行のみを保持する\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off), \n        ## サイン・コサイン項のセットを1つ含める\n        K = 1\n        ), \n      ## 後の年についてのフーリエ列を予測する（ベースラインデータを用いて）\n      fourier(\n        ## カットオフ以前の行のみを保持する\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off),\n        ## サイン・コサインの項を1つ含める\n        K = 1, \n        ## 52週先を予測する\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  ## 当てはめと予測のためにデータを分割する\n  dat &lt;- mini_data %&gt;% \n    group_by(epiweek &lt;= cv_cut_off) %&gt;%\n    group_split()\n\n  ## 当てはめたいモデルを定義する（負の二項回帰）\n  model &lt;- glm_nb_model(\n    ## 関心のあるアウトカムとしてケースの数をセットする\n    case_int ~\n      ## 傾向を説明するために epiweek を使います。\n      epiweek +\n      ## 季節性を説明するためにフーリエ列を使用する\n      fourier\n  )\n\n  # どのデータを当てはめと予測に使用するかを定義する\n  fitting_data &lt;- pluck(dat, 2)\n  pred_data &lt;- pluck(dat, 1)\n  \n  # モデルの当てはめを行う\n  fitted_model &lt;- trending::fit(model, data.frame(fitting_data))\n  \n  # 予測したいデータを予想する\n  forecasts &lt;- fitted_model %&gt;% \n    predict(data.frame(pred_data), simulate_pi = FALSE)\n  forecasts &lt;- data.frame(forecasts$result[[1]]) %&gt;% \n    ## 週と予想する推定値のみを保持する\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## リストを全ての予測を含むデータフレームにする\nforecasts &lt;- bind_rows(forecasts)\n\n## 予測値と観測値を結合する\nforecasts &lt;- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## {yardstick} を用いて指標を計算する\n  ## RMSE： Root mean squared error（平均二乗偏差）\n  ## MAE：  Mean absolute error  （平均絶対誤差）\n  ## MASE： Mean absolute scaled error（平均絶対スケール誤差）\n  ## MAPE： Mean absolute percent error（平均絶対パーセント誤差）\nmodel_metrics &lt;- bind_rows(\n  ## 予測されたデータセット内の観測値と推定値を比較\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %&gt;% \n  ## 指標タイプと結果のみを保持する\n  select(Metric  = .metric, \n         Measure = .estimate) %&gt;% \n  ## 後で行を結合できるようにワイドフォーマットで作成する\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## モデルの指標を返す\nmodel_metrics\n\n# A tibble: 1 × 4\n   rmse   mae  mase  mape\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  252.  199.  1.96  17.3\n\n\n\n\n\n\nsurveillance パッケージ\nこのセクションでは、アウトブレイク検出アルゴリズムに基づいて警告の閾値を作成するために surveillance パッケージを使用します。このパッケージにはいくつかの異なる手法がありますが、ここでは2つのオプションに焦点を当てます。詳細については、使用したアルゴリズムの application と theory に関するこれらの論文を参照してください。\n最初のオプションでは、改良型の Farrington 法を使用します。これは負の二項一般化線形モデル（トレンドを含む）に適合し、過去の発生（外れ値）をダウンウェイトして、閾値を作成します。\n2つ目のオプションでは glrnb メソッドを使用します。これも負の二項一般化線形モデルに当てはめますが、トレンドとフーリエ列を含んでいます（そのため、ここはメリットです）。この回帰は「統制平均」（～適合値）を計算するために使用されます。そして、各週の平均にシフトがあるかどうかを評価するために、計算された一般化された尤度比統計を使用します。各週のしきい値は、前の週を考慮していることに注意してください。各週の閾値は過去の週を考慮しているため、持続的なシフトがある場合はアラームが作動します。 （また、各アラームの後、アルゴリズムはリセットされることにも注意してください）。\nsurveillance パッケージを使用するためには、まず、フレームワークに適合する “surveillance time series” オブジェクトを定義する必要があります（sts() を使用）。\n\n## surveillance time series オブジェクトを定義する\n## 備考: 母集団オブジェクトに分母を含められる（?stsを参照ください）。\ncounts_sts &lt;- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## start_date から年のみを保持するサブセット\n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## start_date から週のみを保持するサブセット\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## データの種類を定義する（このケースでは週次）\n                  freq = 52)\n\n## 含めたい週の範囲を定義する（例：予測期間）\n## 備考： sts オブジェクトは、週を指定せずにオブザベーションをカウントするだけ\n## sts オブジェクトは、週や年の識別子を割り当てずに観測値をカウントしているだけなので、我々のデータを使って適切な観測値を定義する\nweekrange &lt;- cut_off - start_date\n\n\n\nFarrington 法\n次に、 Farrington メソッドの各パラメータを list で定義します。そして、 farringtonFlexible() を使用してアルゴリズムを実行し、 farringtonmethod@upperbound を使用してアラートの閾値を抽出し、データセットに含めることができます。また、 farringtonmethod@alarm を使用して各週にアラートが発生した(閾値を超えた)場合のTRUE/FALSEを抽出することも可能です。\n\n## コントロール群を定義する\nctrl &lt;- list(\n  ## 閾値が必要な期間を定義する（例： 2011年）\n  range = which(counts_sts@epoch &gt; weekrange),\n  b = 9, ## ベースラインを何年前にするか\n  w = 2, ## 移動窓のサイズ\n  weightsThreshold = 2.58, ## 過去の発生事例への再重みづけ（改良型の Noufaily 法 - オリジナルの提案1）\n  ## pastWeeksNotIncluded = 3, ## 利用可能なすべての週を使う (Noufaily は 26 を落とすことを提案)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 通常は 0.05 だが、改良された方法では 1 が推奨される（つまり、常に保持される）\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## farrington の柔軟な方法を適用する\nfarringtonmethod &lt;- farringtonFlexible(counts_sts, ctrl)\n\n## オリジナルのデータセットに閾値という新たな変数を作成する\n## farrington からの上界を含む\n## 備考： これは2011年の週のみを対象とする（そのため、行をサブセット化する必要がある）\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] &lt;- farringtonmethod@upperbound\n\n前に実施したように、結果を ggplot によって可視化できます。\n\nggplot(counts, aes(x = epiweek)) + \n  ## 観測されたケースを線として追加する\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## 収差アルゴリズムの上界を追加する\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## 色を定義する\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成する\n  theme_classic() + \n  ## legend のタイトルを除外する\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nGLRNB 法\nGLRNB 法の場合も同様に各パラメータを「リスト」で定義します。そしてアルゴリズムを当てはめ、上界を抽出します。\n注意： この方法は、閾値の計算に「ブルートフォース」（ブートストラップ法に似た方法）を使用するため、長い時間がかかることがあります！\n詳細は GLRNB ドキュメント（vignette） を参照してください。\n\n## 統制するオプションを定義する\nctrl &lt;- list(\n  ## 閾値が必要な期間を定義する (例：2011年)\n  range = which(counts_sts@epoch &gt; weekrange),\n  mu0 = list(S = 1,    ## 含めるフーリエ列（ハーモニクス）の数\n  trend = TRUE,   ## トレンドを含めるかどうか\n  refit = FALSE), ## それぞれの警告の後、モデルを再度当てはめるかどうか\n  ## cARL = GLR 統計の閾値（任意）\n     ## 3 ~ 偽陽性を最小限に抑えるための中間地点\n     ## 1 glm.nbの99%PIにフィット - ピーク後の変化あり（警告のために閾値を下げる）\n   c.ARL = 2,\n   # theta = log(1.5), ## アウトブレイクにおける症例数の50%増加に等しい\n   ret = \"cases\"     ## ケースの数として閾値の上界を返す\n  )\n\n## glrnb 法の適用\nglrnbmethod &lt;- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## 元のデータセットに閾値と名付けた新たな変数をセットする\n## glrnb の上界を含む\n## 備考: これは2011年の週のみを対象としている（そのため、行をサブセット化する必要がある）\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] &lt;- glrnbmethod@upperbound\n\n前述と同様にアウトプットを可視化します。\n\nggplot(counts, aes(x = epiweek)) + \n  ## 観測されたケースの数を線として追加する\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## aberration アルゴリズムの上界を追加する\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## 色を定義する\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成する\n  theme_classic() + \n  ## タイトルのレジェンドを除外する\n  theme(legend.title = element_blank())",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#中断された時系列",
    "href": "new_pages/time_series.jp.html#中断された時系列",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.8 中断された時系列",
    "text": "23.8 中断された時系列\n中断された時系列（セグメント回帰や介入分析とも呼ばれる）は、病気の発生率に対するワクチンの影響を評価する際によく使用されます。しかし、これは広義の介入や導入の影響を評価するのに使用可能です。例えば、病院の手順の変更や、集団への新しい病気の導入などです。 今回の例では、2008 年末にドイツでカンピロバクターの新しい株が出現したと仮定し、それが患者数に影響を与えるかを調査します。今回も負の二項回帰を使用します。今回の回帰では、介入前（または新菌株の出現）と介入後（前後の期間）の2つの部分に分割します。これにより、2つの期間を比較した罹患率比を算出することができます。式を説明するとわかりやすいかもしれません（そうでなければ無視してください！）。\n負の2項回帰は次の通り定義できます。\n\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]\nここで\n\\(Y_t\\) は \\(t\\) 時点で観測された症例数\n\\(pop_t\\) は、 \\(t\\) 時点での10万人単位の人口規模（ここでは使用しません）。\n\\(t_0\\) は前期間の最後の年（移行期間がある場合はその期間も含みます）。\n\\(δ(x)\\) は指標関数（x≤0なら0、x&gt;0なら1）。\n\\((x)^+\\) はカットオフ演算子（x&gt;0ならx、それ以外は0）。\n\\(e_t\\) は残差を表します。\n必要に応じてトレンドや季節などの項を追加することができます。\n\\(β_2 \\times δ(t-t_0) + β_3 \\times(t-t_0 )^+\\) は、後の期間の一般化された線形部分であり、前期はゼロです。 これは、 \\(β_2\\) と \\(β_3\\) の推定値は介入の効果であることを意味します。\nここでは利用可能なすべてのデータを使用するため、予測を行わずにフーリエ列を再計算する必要があります（つまり、過去にさかのぼって計算することになります）。さらに、回帰に必要な追加の項を計算する必要があります。\n\n## epiweek と case_int variabless を使用してフーリエ列を追加する\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  fourier(K = 1)\n\n## 介入の週を定義する\nintervention_week &lt;- yearweek(\"2008-12-31\")\n\n## 回帰分析のための変数を定義する\ncounts &lt;- counts %&gt;% \n  mutate(\n    ## 公式における t に対応させる\n      ## 週数 (epiweeks をそのまま使うこともできるだろう)\n    # 線形 = 行の数（epiweek）\n    ## 公式におけるデルタ（t-t0）に対応させる\n      ## 前と後の介入期間\n    intervention = as.numeric(epiweek &gt;= intervention_week), \n    ## 公式に置ける（(t-t0)^+ に対応させる\n      ## 介入後の週の数\n      ## ## (0から計算で出てくる数字のうち、大きい方を選ぶ)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n\n次に、これらの項を使って負の二項回帰をあてはめ、変化率の表を作成します。この例では、有意な変化はありませんでした。\n注意： predict() の引数で simulate_pi = FALSE を使用していることに注意してください。これは trending のデフォルトの動作が ciTools パッケージを使用して予測区間を推定することだからです。 これはNAカウントがある場合には機能せず、また、より細かい間隔を生成します。詳細は ?trending::predict.trending_model_fit を参照してください。\n\n## 当てはめたいモデル（負の二項回帰）を定義する\nmodel &lt;- glm_nb_model(\n  ## 関心のあるアウトカムとしてのケースの数をセットする\n  case_int ~\n    ## トレンドの説明のために epiweek を使用する\n    epiweek +\n    ## 季節性の説明のためにフーリエ列を使用する\n    fourier + \n    ## 前あるいは後ろの期間であるかを追加する\n    intervention + \n    ## 介入後の期間を追加する\n    time_post\n    )\n\n## countsデータセットを使用して、モデルを当てはめる\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## 信頼区間と予測区間を算出する\nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\n\n## 推定値と変化率をテーブル内に表示する\nfitted_model %&gt;% \n  ## 元の負の二項回帰を抽出する\n  get_model() %&gt;% \n  ## 結果についての tidy なデータフレームを取得する\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %&gt;% \n  ## 介入の値のみを保持する\n  filter(term == \"intervention\") %&gt;% \n  ## 推定値と CIs について、 IRR を変化率に変換する\n  mutate(\n    ## 関心のあるそれぞれの列に対して新しい列を作成する\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## 変化率を算出する公式を適用する\n            .f = function(i) 100 * (i - 1), \n      ## \"_perc\" という名前の接尾語を新たな列に追加する\n      .names = \"{.col}_perc\")\n    ) %&gt;% \n  ## 特定の列のみを保持する（そして列名を変更）。\n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)\n\n前述のように、回帰の出力を視覚化できます。\n\nestimate_res &lt;- data.frame(observed$result)\n\n\nggplot(estimate_res, aes(x = epiweek)) + \n  ## 観測されたケースの数を追加する\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## モデル推定値についての線を追加する\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## 予測区間のバンドを追加する\n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## 予測開始の場所を示すため、垂直線とラベルを追加する\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## 色を定義する\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## 伝統的なプロット（軸が黒で背景が白）を作成する\n  theme_classic()\n\nWarning: Unknown or uninitialised column: `upper_pi`.\n\n\nWarning in max(observed$upper_pi): no non-missing arguments to max; returning\n-Inf",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.jp.html#参考資料",
    "href": "new_pages/time_series.jp.html#参考資料",
    "title": "23  時系列分析とアウトブレイクの検出{#time-series}",
    "section": "23.9 参考資料",
    "text": "23.9 参考資料\nforecasting: principles and practice textbook\nEPIET timeseries analysis case studies\nPenn State course Surveillance package manuscript",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>時系列分析とアウトブレイクの検出{#time-series}</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.jp.html",
    "href": "new_pages/epidemic_models.jp.html",
    "title": "24  エピデミックモデリング",
    "section": "",
    "text": "24.1 概要\n流行のモデリングのためのツールが増加してきており、最小の労力でかなり複雑な分析を行うことができるようになっています。このセクションでは、これらのツールをどのように使用するかについての概要を説明します：\nここではこれらの基礎となっている方法論や統計学的な手法の概要を説明する意図はありませんので、関連論文へのリンクについては Resources tab を参照してください。ここで説明するツールを使用する前に、手法を理解しておくことで、正確に結果を解釈できるようになります。\n以下はこのセクションで作成するアウトプットの１つの例です。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>エピデミックモデリング</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.jp.html#概要",
    "href": "new_pages/epidemic_models.jp.html#概要",
    "title": "24  エピデミックモデリング",
    "section": "",
    "text": "実効再生産数（effective reproduction number）Rt や倍化時間（doubling time）などに関連する統計量を推定する\n将来のインシデンスの短期的な予測（プロジェクション）を実施する",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>エピデミックモデリング</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.jp.html#準備",
    "href": "new_pages/epidemic_models.jp.html#準備",
    "title": "24  エピデミックモデリング",
    "section": "24.2 準備",
    "text": "24.2 準備\nRt の推定には EpiNow パッケージと EpiEstim パッケージという2つの異なる手法を使用し、症例（ケース）の発生数の予測には projections パッケージを用います。以下のコードチャンクは、（本章の）分析に必要なパッケージのローディングを示しています。\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n   rio,          # ファイルをインポート\n   here,         # ファイルロケーター\n   tidyverse,    # データマネジメント + ggplot2 のグラフィックス\n   epicontacts,  # トランスミッションネットワークの分析\n   EpiNow2,      # Rt 推定\n   EpiEstim,     # Rt 推定\n   projections,  # 発生数のプロジェクション\n   incidence2,   # 発生データの取り扱い\n   epitrix,      # 便利な epi の機能\n   distcrete     # 離散的な遅れの分布\n)\n\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください）。\n\n# クリーンなラインリストの取り込み\nlinelist &lt;- import(\"linelist_cleaned.rds\")",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>エピデミックモデリング</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.jp.html#rt-の推定",
    "href": "new_pages/epidemic_models.jp.html#rt-の推定",
    "title": "24  エピデミックモデリング",
    "section": "24.3 Rt の推定",
    "text": "24.3 Rt の推定\n\nEpiNow2 vs. EpiEstim\n再生産数 R は、疾病の感染性を示す指標であり、感染者 1 人あたりの二次感染者数の期待値として定義されます。感受性保持者しかいないような集団では、この値は基本再生産数 R0 を意味します。しかし、集団内の感受性保持者はアウトブレイクやパンデミックの期間中に変化し、また様々な対策が講じられるため、感染性の指標として最も一般的に使用されるのは実効再生産数です（ある時刻 t における感染者1人あたりの二次感染者数の期待値）。\nEpiNow2 パッケージは最も洗練された Rt 推定のためのフレームワークを提供しています。ほかに一般的に使用されている EpiEstim パッケージと比較して、2つの重要な利点があります：\n\n報告の遅れを考慮しているので、直近のデータが不完全の場合であっても Rt を推定することができます。\n報告日ではなく、感染日に基づいて Rt を推定するので、遅れを生じずすぐに Rt の変化として介入の効果が反映されま。\n\nしかし、2つの重要なデメリットもあります：\n\n世代時間の分布（一次感染者から二次感染者までの遅れの分布）、潜伏期間の分布（感染から症状発現までの遅れの分布）、およびデータに関連するその他の遅れの分布（例えば、報告の日付がある場合、症状発現から報告までの遅れの分布）に関する知識が必要です。これにより、より正確な Rt を推定できますが、EpiEstim パッケージは発症間隔発症間隔（一次感染者の症状発現から二次感染者の症状発現までの遅れの分布）のみを必要とし、これのみが唯一利用可能な分布である場合があります。\nEpiNow2 パッケージは EpiEstim パッケージに比べて著しく遅く、約100～1000倍の差があるといわれています！例えば、このセクションで利用するサンプルアウトブレイクにおける Rt 推定には、約4時間かかります（これは高い精度を確保するために多数の反復処理を行ったためであり、必要に応じて短縮することも可能ですが、アルゴリズムが一般的に遅いという点は変わりません）。定期的に Rt の推定値を更新している場合は、この方法は現実的ではないかもしれません。\n\nそのため、どのパッケージを選ぶかは、利用できるデータや時間、計算資源によります。\n\n\nEpiNow2\n\n遅れの分布の推定\nEpiNow2 パッケージの実行に必要な遅れの分布は、手持ちのデータによって異なります。基本的には、感染日から Rt 推定に使用したいイベント日までの遅れを記述できるものである必要があります。もし発症日を使っている場合、これは単に潜伏期間の分布となります。報告日を使用している場合は、感染から報告までの遅れの分布が必要です。この分布はなかなか直接知ることができないため、EpiNow2 パッケージでは複数の遅れの分布をつなぎ合わせることができます。この場合、感染から症状発現までの遅れ（例えば潜伏期間、これは既知であることが多いです）と、症状発現から報告までの遅れ（これは自分でデータから推定できる場合が多いです）です。\n例のラインリストではすべての症例について発症日がわかっているので、データ（例えば症状の発現日など）を感染日に結びつけるためには、潜伏期間の分布が必要になります。この分布は、データから推定するか、既存文献から値を引用することができます。\nエボラ出血熱の潜伏期間を平均9.1日、標準偏差7.3日、最大値を30日とする文献からの推定値（引用論文）は、以下のように規定されます：\n\nincubation_period_lit &lt;- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n\nEpiNow2 パッケージでは、これらの遅れの分布が対数（log）スケールで提供される必要があり、そのため、各値に log がついていることに注意してください（紛らわしいことに、自然スケールで提供されなければならない max パラメータを除く）。mean_sd と sd_sd は、平均値と標準偏差の推定値の標準偏差を定義します。上記のケースではこれらは知られていないため、かなり恣意的な値である0.1を選択しました。\n今回のｂ分析ではその代わりに、bootstrapped_dist_fit() を用いて、ラインリストから潜伏期間の分布を推定しました。\n\n## 潜伏期間の推定\nincubation_period &lt;- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n\nもう一つ必要な分布は、世代時間です。感染時刻と感染伝播のリンクに関するデータがあるので、感染者と被感染者のペアの感染時刻の遅れを計算することで、ラインリストからこの分布を推定することができます。これには epicontacts パッケージにある便利な get_pairwise() を使います。この関数を使うと、感染ペア間のラインリスト上の2組の特性の違いを計算することができます。epicontacts オブジェクトを作成します（詳しくは 感染連鎖の図式化 の章を参照してください）：\n\n## コンタクトの作成\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## epicontacts オブジェクトの作成\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\n次に、get_pairwise で計算した感染ペア間の感染時刻の差をガンマ分布にあてはめました：\n\n## ガンマ分布に従う世代時間の推定\ngeneration_time &lt;- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)\n\n\n\nEpiNow2 パッケージの実行\nあとはラインリストから日々のインシデンスを計算するだけですが、dplyr パッケージの group_by() と n() で簡単にできます。EpiNow2 パッケージでは、列名が date と confirm でなければならないことに注意してください。\n\n## 発症日からインシデンスを得る\ncases &lt;- linelist %&gt;%\n  group_by(date = date_onset) %&gt;%\n  summarise(confirm = n())\n\nそして、epinow() を使って Rt を推定することができます。入力に関して、いくつかの注意点を挙げます：\n\ndelays の引数には、任意の数の「連鎖した」遅れの分布を与えることができます。delay_opts() 内で incubation_period オブジェクトと一緒に入れるだけです。\nreturn_output は、出力ファイルに保存されるのではなく、R の中で貸せされるようになっています。\nverbose は、進捗状況の読み上げを指定します。\nhorizon は、将来のインシデンスを何日分予測するかを示します。\nstan の因数に追加のオプションを渡して、推定を実行する期間を指定します。samples 数と chains 数を増やすと、不確実性の特徴をよく表したより正確な推定値が得られますが、実行には時間がかかります。\n\n\n## epinow を走らせる\nepinow_res &lt;- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)\n\n\n\nアウトプットの分析\nコードの実行が終了すると、以下のように簡単にサマリーをプロットすることができます。画像をスクロールすると、全体を見ることができます。\n\n## サマリーフィギュアのプロット\nplot(epinow_res)\n\n\n\n\n\n\n\n\nまた、様々なサマリー統計量を見ることもできます：\n\n## サマリーテーブル\nepinow_res$summary\n\n                                 measure                  estimate\n                                  &lt;char&gt;                    &lt;char&gt;\n1: New confirmed cases by infection date                4 (2 -- 6)\n2:        Expected change in daily cases                    Unsure\n3:            Effective reproduction no.        0.88 (0.73 -- 1.1)\n4:                        Rate of growth -0.012 (-0.028 -- 0.0052)\n5:          Doubling/halving time (days)          -60 (130 -- -25)\n    numeric_estimate\n              &lt;list&gt;\n1: &lt;data.table[1x9]&gt;\n2:              0.56\n3: &lt;data.table[1x9]&gt;\n4: &lt;data.table[1x9]&gt;\n5: &lt;data.table[1x9]&gt;\n\n\nさらなる分析やカスタムプロットのために $estimates$summarised を介して要約された毎日の推定値にアクセスすることができます。これをデフォルトの data.table から、dplyr パッケージで使いやすいように tibble に変換します。\n\n## サマリーを抽出して、tibble に変換\nestimates &lt;- as_tibble(epinow_res$estimates$summarised)\nestimates\n\n\n\n\n\n\n\n例として、倍化時間と Rt をプロットしてみましょう。極端に高い倍化時間をプロットしないように、Rt が1を大きく上回っている流行の最初の数か月だけを見ています。\nlog(2)/growth_rate という計算式を用いて、推定された成長率（growth rate）から倍化時間を算出しています。\n\n## 中央値プロットのために横型のデータフレームを作ります\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date &lt; as.Date(\"2014-09-01\")\n  ) %&gt;%\n  ## 成長率を倍化時間に変換\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## 変形を反映した変数名の変更\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## 分位値プロットのために縦長のデータフレームを作る\ndf_long &lt;- df_wide %&gt;%\n  ## ここでは、マッチした分位値を利用します（例：lower_90 から upper_90）\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## プロットする\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## label_parsedを使用して、添え字ラベルを許可する\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## 分位値の透明度を手動で定義する\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nEpiEstim\nEpiEstim パッケージを走らせるために、日々のインシデンスのデータを提供し、発症間隔（一次症例と二次症例の症状発現までの遅れの分布）を指定する必要があります。\nインシデンスデータは、ベクトル、データフレーム、またはオリジナルの incidence パッケージから得られた incidence オブジェクトとして、EpiEstim パッケージに提供できます。輸入感染例とローカルで感染した例を区別することもできます：詳細は ?estimate_R のドキュメントを参照してください。\nここでは incidence2 パッケージを使って、インプットを作成します。incidence2 パッケージの例については 流行曲線（エピカーブ） の章を参照してください。incidence2 パッケージには estimateR() が期待するインプットとは完全に一致しないアップデートがあったため、いくつかの小さな追加手順が必要となります。incidence オブジェクトは日付とそれぞれのケースカウントをもつ tibble で構成されています。tidyr パッケージの complete() を使用して、すべての日付が含まれていることを確認し（症例がない日も含む）、後のステップで estimate_R() で期待されるものと一致するように列を rename() します。\n\n## 発症日からインシデンスを得る\ncases &lt;- incidence2::incidence(linelist, date_index = \"date_onset\") %&gt;% # 日ごとにケースカウントを得る\n  tidyr::complete(date_index = seq.Date(                              # すべての日付が表示されていることを確認\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %&gt;%                                       # NA カウントを0に変換する\n  rename(I = count,                                                   # estimateRで期待されるな目に変更\n         dates = date_index)\n\nこのパッケージにはは発症間隔を指定するためのいくつかのオプションがあり、その詳細はドキュメントの ?estimate_R に記載されています。ここではそのうちの2つを取り上げます。\n\n文献から引用した発症間隔の推定値の使用\nオプションの method = \"parametric_si\" を使用すると、 make_config() で作成した config オブジェクトに発症間隔の平均値と標準偏差を手動で指定することができます。ここでは、この論文で定義されている平均値12.0、標準偏差5.2を使用しています。\n\n## config の作成\nconfig_lit &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\n\nそして、estimate_R() で Rt の推定をすることができます：\n\ncases &lt;- cases %&gt;% \n     filter(!is.na(date))\n#create a dataframe for the function estimate_R()\ncases_incidence &lt;- data.frame(dates = seq.Date(from = min(cases$dates),\n                               to = max(cases$dates), \n                               by = 1))\ncases_incidence &lt;- left_join(cases_incidence, cases) %&gt;% \n     select(dates, I) %&gt;% \n     mutate(I = ifelse(is.na(I), 0, I))\n\nJoining with `by = join_by(dates)`\n\nepiestim_res_lit &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_lit\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n\nあとはアウトプットのサマリーをプロットします：\n\nplot(epiestim_res_lit)\n\n\n\n\n\n\n\n\n\n\nデータから推定した発症間隔の推定値の使用\n症状の発症日と感染伝播のリンクデータがあるので、感染者と被感染者のペアの発症日の遅れを計算することで、ラインリストから発症間隔を推定することもできます。EpiNow2 パッケージのセクションで行ったように、epicontacts パッケージの get_pairwise() を使います。この関数は感染ペア間のラインリスト上の2組の特性の違いを計算することができます。まず epicontacts オブジェクトを作成します（詳細は 感染連鎖の図式化 の章を参照）：\n\n## コンタクトの作成\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## epicontacts オブジェクトの作成\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\n次に、get_pairwise() を用いて感染ペア間の発症日の差をガンマ分布に当てはめます。離散化された分布が必要とされるため、このフィッティング手順には epitrix パッケージの便利な fit_disc_gamma() を使用します。\n\n## ガンマ分布に従う発症間隔の推定\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\nその後に、config オブジェクトに情報を与え、 EpiEstim を再実行して結果を描画しましょう。\n\n## config の作成\nconfig_emp &lt;- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## epiestim を走らせる\nepiestim_res_emp &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_emp\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n## アウトプットをプロットする\nplot(epiestim_res_emp)\n\n\n\n\n\n\n\n\n\n\n推定時間枠（ウィンドウ）の設定\nデフォルトのオプションでは週単位の平滑化された推定値を提供していますが、正確な推定値を得るために、アウトブレイク初期に Rt を推定していることを警告する機能もあります。以下に示すように、推定の開始日を遅く設定することで、変更できます。残念ながら、EpiEstim パッケージはこれらの推定時間を指定するのに非常に面倒な方法しか提供しておらず、そのためには各時間ウィンドウの開始日と終了日を参照する整数のベクトルを提供しなければなりません。\n\n## 6月1日から始まる日付のベクトルを定義する\nstart_dates &lt;- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %&gt;%\n  ## 数字型に変換するために開始日を引く\n  `-`(min(cases$dates)) %&gt;%\n  ## convert to integer\n  as.integer()\n\n## 1週間の平滑化ウィンドウに6日分を追加する\nend_dates &lt;- start_dates + 6\n  \n## config を作成する\nconfig_partial &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n\nここで、EpiEstim を再び実行してみると、推定値は6月からしか出ないことがわかります：\n\n## epiestim を走らせる\nepiestim_res_partial &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## アウトプットをプロットする\nplot(epiestim_res_partial)\n\n\n\n\n\n\n\n\n\n\nアウトプットの分析\n主なアウトプットは $R でアクセスできます。Rt のプロットと Rt とその日に報告された症例数で与えられた「伝播能力」の指標を作成します（これは次世代の感染者数の期待値として表されます）。\n\n## 中央値のために横型のデータフレームを作成します\ndf_wide &lt;- epiestim_res_lit$R %&gt;%\n  rename_all(clean_labels) %&gt;%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %&gt;%\n  mutate(\n    ## t_startからt_endまでの日付の中央値を抽出する\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %&gt;%\n  ## 日々の発生データを統合する\n  left_join(cases, \"dates\") %&gt;%\n  ## すべてのr推定値のリスクを計算する\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %&gt;%\n  ## r推定値とリスク推定値を分離する\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %&gt;%\n  ## 因子（ファクタ）のレベルを割り当てる\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## クォンタイル（分位値）から縦型のデータフレームを作成する\ndf_long &lt;- df_wide %&gt;%\n  select(-variable, -median) %&gt;%\n  ## r/riskの推定値と分位値を分離する\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %&gt;%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## プロットを作成する\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## label_parsed を使用して、添え字ラベルをつける\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## 分位値の透明度を手動で定義する\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>エピデミックモデリング</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.jp.html#インシデンス発生数の予測プロジェクション",
    "href": "new_pages/epidemic_models.jp.html#インシデンス発生数の予測プロジェクション",
    "title": "24  エピデミックモデリング",
    "section": "24.4 インシデンス（発生数）の予測（プロジェクション）",
    "text": "24.4 インシデンス（発生数）の予測（プロジェクション）\n\nEpiNow2\nRt の推定に加えて、EpiNow2 パッケージは EpiSoon パッケージとの統合により、Rt のプロジェクションや症例数のプロジェクションもサポートします。必要なのは、epinow() の呼び出しで horizon 引数を指定して、何日先までプロジェクションしたいかを示すことだけです。このセクションでは、epinow_res オブジェクトに格納されている分析のアウトプットをプロットします。\n\n## プロットの一番小さい日付を設定する\nmin_date &lt;- as.Date(\"2015-03-01\")\n\n## 要約された推定値を抽出する\nestimates &lt;-  as_tibble(epinow_res$estimates$summarised)\n\n## 発生症例数の生データを抽出する\nobservations &lt;- as_tibble(epinow_res$estimates$observations) %&gt;%\n  filter(date &gt; min_date)\n\n## 症例数の予測値を抽出する\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date &gt; min_date\n  )\n\n## 分位値プロットのためにさらに横型のフォーマットに変換する\ndf_long &lt;- df_wide %&gt;%\n  ## ここで、分位値を一致させる（たとえば lower_90 から upper_90）\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## プロットする\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## 分位値の透明度を手動で定義する\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n予測（プロジェクション）\nRECON が開発した projections パッケージでは、実効再生産数 Rt と発症間隔の知識だけで非常に簡単に短期的なインシデンスの予測を行うことができます。ここでは、文献から得られた発症間隔の推定値を使用する方法と、ラインリストから得られた独自の推定値を使用する方法について説明します。\n\n文献での発症間隔の推定値を利用\nprojections パッケージには、distcrete パッケージに含まれる distcrete クラスの離散化された発症間隔の分布が必要です。ここでは、この論文 で定義された平均12.0、標準偏差5.2のガンマ分布を使用します。これらの値をガンマ分布に必要な shape（形状）および scale（尺度）パラメータに変換するために、epitrix パッケージの gamma_mucv2shapescale() を使用します。\n\n## 変動係数から形状と尺度パラメータを得ることができます\n##（例：平均値に対する標準偏差の比）\nshapescale &lt;- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## distcrete オブジェクトを作成する\nserial_interval_lit &lt;- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n\nここでは、発症間隔が正しいことを確認するために簡単なチェックを行います。先ほど定義したガンマ分布の確率密度に $d でアクセスしますが、これは dgamma を呼び出した時と同じです。\n\n## 発症間隔が正しいことを確認する\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\n\n\nデータによる発症間隔の推定値を利用\n我々は症状の発症日と感染リンク（transmission links）のデータがあるので、感染者と被感染者のペアの発症日の遅れを計算することで、ラインリストから発症間隔を推定することもできます。EpiNow2 のセクションで行ったように、epicontacts パッケージの get_pairwise() を用います。この関数によって、感染ペア（transmission pairs）間のラインリスト上の2組の特性の違いを計算することができます。まず epicontacts オブジェクトを作成します（感染連鎖の図式化 の章を参照）：\n\n## コンタクトの作成\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## epicontacts オブジェクトの作成\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\n次に、get_pairwise() を用いて、計算した感染ペアの発症日の差をガンマ分布にあてはめます。離散化された分布が必要なため、この適合（fitting）手順には epitrix パッケージの便利な fit_disc_gamma() を使います。\n\n## ガンマ分布に従う発症間隔の分布を推定する\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## 推定値\nserial_interval[c(\"mu\", \"sd\")]\n\n$mu\n[1] 11.51047\n\n$sd\n[1] 7.696056\n\n\n\n\n発生数（インシデンス）の予測（プロジェクション）\n将来のインシデンスをプロジェクションするためには、過去の発生数を incidence オブジェクトの形で値供することに加えて、妥当な Rt 値のサンプルを与える必要があります。前のセクション（Rt推定）で EpiEstim によって作成され、epiestim_res_emp オブジェクトに格納された Rt の推定値を使用して、インシデンスの予測値を作成します。以下のコードでは、アウトブレイクの最後の時間ウィンドウの Rt の平均値と標準偏差の推定値を抜き出し（ベクトルの最後の要素にアクセスするために tail() を使用）、rgamma()を使用してガンマ関数から10000の値をシミュレーションします。また、事前予測に使用したいRt 値の独自のベクトルを提供することもできます。\n\n## 発症日からincidenceオブジェクトを作成\ninc &lt;- incidence::incidence(linelist$date_onset)\n\n256 missing observations were removed.\n\n## 最新の推定値から妥当な r 値を抽出する\nmean_r &lt;- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r &lt;- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale &lt;- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r &lt;- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## 分布をチェック\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nそして、project() を使って、実際の予測を行います。n_days 引数で何日間プロジェクションするかを指定し、n_sim 引数でシミュレーション回数を指定します。\n\n## プロジェクションの作成\nproj &lt;- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n\nそして、plot() と add_projections() を使って、インシデンスとプロジェクションを簡単にプロットすることができます。各括弧演算子（[]）を使用すると、incidenceオブジェクトを簡単に分けることができ、最近のケースのみを表示することができます。\n\n## インシデンスとプロジェクションのプロット\nplot(inc[inc$dates &gt; as.Date(\"2015-03-01\")]) %&gt;%\n  add_projections(proj)\n\n\n\n\n\n\n\n\nまた、アウトプットをデータフレームに変換することで、日々の症例数の生（raw）の推定値を簡単に取り出すことができます。\n\n## 生データをデータフレームに変換する\nproj_df &lt;- as.data.frame(proj)\nproj_df",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>エピデミックモデリング</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.jp.html#資料",
    "href": "new_pages/epidemic_models.jp.html#資料",
    "title": "24  エピデミックモデリング",
    "section": "24.5 資料",
    "text": "24.5 資料\n\nEpiEstim に実装されている方法論を説明した論文はここです。\nEpiNow2 に実装されている方法論を説明した論文はここです。\nRt を推定するための様々な方法論と実用上の配慮すべき点を説明した論文はここです。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>エピデミックモデリング</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html",
    "href": "new_pages/contact_tracing.jp.html",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "",
    "text": "25.1 データ準備",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html#データ準備",
    "href": "new_pages/contact_tracing.jp.html#データ準備",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  rio,          # データのインポート  \n  here,         # 相対パスの設定  \n  janitor,      # データクリーニング\n  lubridate,    # 日付型データ\n  epikit,       # age_categories() \n  apyramid,     # 人口ピラミッド\n  tidyverse,    # データの処理と可視化\n  RColorBrewer, # 配色デザイン\n  formattable,  # 見やすい表の作成\n  kableExtra    # 表のフォーマットの整備\n)\n\n\n\nデータのインポート\nまず、接触者と接触者追跡状況（フォローアップ）のサンプルデータセットをインポートします。この章で使用するサンプルデータは、ネストされていない形で Go.Data API から取得され、“.rds” ファイル形式です。\nハンドブックとデータのダウンロード の章から、このハンドブックで使用するすべてのデータをダウンロードできます。\nこの章で使用するサンプルデータのみをダウンロードする場合は、以下のリンクをご利用ください。\n クリックしてダウンロード 感染症例サンプルデータ（.rds ファイル） \n クリックしてダウンロード 接触者サンプルデータ （.rds ファイル） \n クリックしてダウンロード 追跡サンプルデータ （.rds ファイル）  \n\n\n\n上のリンクからダウンロードしたファイルは、Go.Data API（API の詳細についてはこちら）が提供するデータであり、加工されていないため、データをインポートした後、この章で使いやすいようにデータの前処理を行います。Go.Data データの取得について、詳細が知りたい方は、こちら をご覧ください。\n以下のコードでは、rio パッケージの import() を使用してサンプルデータセットをインポートしていますが、データをインポートする方法は他にも数多くあります。詳細を知りたい方は、 インポートとエクスポート の章を参照してください。以下のコードでは、here() を使用してファイルパスを指定していますが、コードを実行する際は、使用しているコンピュータ固有のファイルパスに変更してください。データをインポートした後、select() を使用して特定の列のみを選択し、必要のない変数を除外します。\n\n感染症例データ\nこのサンプルデータ（cases データセット）には、感染者の情報が含まれています。\n\ncases &lt;- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %&gt;% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)\n\n以下は、このデータセットに含まれている nrow(cases) 人の感染者登録データの一覧です。\n\n\n\n\n\n\n\n\n接触者データ\nこのサンプルデータ（contacts データセット）は、接触者に関わる情報が含まれた表です。以下のコードを実行する際も、お手元の環境に適したファイルパスを指定してください。データをインポート後、以下の順に従ってデータクリーニングを行います。\n\nage_class 変数を因子（ファクタ）型に設定し、レベルを逆にならべ、若い年齢が最初に来るようにする\n特定の列のみを選択し、選択した列のうち1つの列の名前を変更する\nadmin_2_name 変数で空欄があった場合、 “Djembe” を割り当て、後ほど作成するデータ可視化の例をわかりやすくする\n\n\ncontacts &lt;- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %&gt;% \n  mutate(age_class = forcats::fct_rev(age_class)) %&gt;% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %&gt;% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))\n\n以下は、このデータセットに含まれている nrow(contacts) 人の接触者データの一覧です。\n\n\n\n\n\n\n\n\n追跡データ\nこのサンプルデータ（followups データセット）には、「フォローアップ」の記録が含まれています。各接触者は、感染への曝露後 14 日間、毎日 1 回、連絡を取る必要があります。\nデータをインポートした後、いくつかのデータ加工を行います。特定の列を選択し、文字列変数である followup_status をすべて小文字に変換します。\n\nfollowups &lt;- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %&gt;% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %&gt;% \n  mutate(followup_status = str_to_lower(followup_status))\n\n以下では、追跡データの最初の nrow(followups) 人を表示しています。 （各行は 追跡調査の 1 回の記録を表し、追跡調査の結果は followup_status 列に記録されています）。\n\n\n\n\n\n\n\n\n関連データ\nここでは、感染症例と接触の関係性を表すデータをインポートします。表示する列を絞り込んでおきましょう。\n\nrelationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)\n\n以下は、「関連データ」の最初の 50 行です。感染症例と接触の関係がすべて含まれています。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html#記述統計",
    "href": "new_pages/contact_tracing.jp.html#記述統計",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "25.2 記述統計",
    "text": "25.2 記述統計\nこのハンドブックの他の章で説明されている分析手法や R コードを使用し、感染者、接触者、そして感染者と接触者の関連について記述的な分析を行うことができます。以下に、いくつか例を示します。\n\n人口統計\n人口ピラミッドとリッカート尺度 の章で紹介したように、年齢や性別の分布を可視化することができます（ここでは、apyramid パッケージを使用しています）。\n\n接触者の年齢と性別\n以下の人口ピラミッドは、接触者の年齢分布を男女別に比較したものです。年齢が不明の接触者は、一番上の unknown に含まれていることに注意してください。年齢不明の接触者を人口ピラミッドから除外することもできますが、その場合は、何人除外されたのかを、プロット下部に注意書きとして記すことをおすすめします。\n\napyramid::age_pyramid(\n  data = contacts,                                   # 接触者サンプルデータを使用\n  age_group = \"age_class\",                           # 年齢変数（因子型）を指定\n  split_by = \"gender\") +                             # 性別による比較\n  labs(\n    fill = \"Gender\",                                 # 凡例のタイトル\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # 図のタイトル\n  theme_minimal()                                    # 背景テーマの設定\n\n\n\n\n\n\n\n\n他にも、感染者と接触者両方の年齢が含まれている Go.Data の関連データ（relationships データセット）を使用すると、感染者と接触者の年齢層の違いを表す人口ピラミッドを作成することもできます。関連データを用いて人口ピラミッドを作成する場合は、年齢変数をカテゴリー化し、数字型から因子（ファクタ）型にする必要があります（詳しくは、データクリーニングと主要関数の章を参照ください）。また、ggplot2 パッケージで図をプロットしやすくするために、データを縦型（long型）に変換する必要があります（詳細は、データの縦横変換をご覧ください）。\n\nrelation_age &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  transmute(                              # transmute() は mutate() と基本は同じだが、言及されていないすべての列を排除する機能を含む\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %&gt;% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # データを縦型（long 型）に変換する\n\n\nrelation_age\n\n# A tibble: 200 × 2\n   category         age_class\n   &lt;chr&gt;            &lt;fct&gt;    \n 1 source_age_class 80+      \n 2 target_age_class 15-19    \n 3 source_age_class &lt;NA&gt;     \n 4 target_age_class 50-54    \n 5 source_age_class &lt;NA&gt;     \n 6 target_age_class 20-24    \n 7 source_age_class 30-34    \n 8 target_age_class 45-49    \n 9 source_age_class 40-44    \n10 target_age_class 30-34    \n# ℹ 190 more rows\n\n\n前処理した関連データ（relationships データセット）を使用し、先ほどと同じように age_pyramid() を使用して人口ピラミッドをプロットしてみましょう。ただし、 gender 変数を使用するのではなく、 category 変数（感染者か接触者のどちらであるかを示す変数）を使用する必要があります。\n\napyramid::age_pyramid(\n  data = relation_age,                               # 上のコードで作成したデータセットを使用\n  age_group = \"age_class\",                           # 年齢変数（因子型）を指定\n  split_by = \"category\") +                           # 感染者と接触者でグループ分け\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # 各グループの色と名前を指定\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # 凡例のタイトル\n    title = \"Age Pyramid of COVID-19 contacts and cases\")+ # 図のタイトル\n  theme_minimal()                                              # 背景テーマの設定\n\n\n\n\n\n\n\n\n他にも、感染者の職業の内訳などの特徴も可視化することができます（ここでは、感染症例データ（cases のデータセット）を使用し、円グラフを作成します）。\n\n# データを前処理し、職業ごとの感染者数を産出する\nocc_plot_data &lt;- cases %&gt;% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # 欠損値を可視化する（NA をカテゴリーとする）\n         occupation = forcats::fct_infreq(occupation)) %&gt;%   # 頻度順で因子型のレベルを並べかえる\n  count(occupation)                                          # 職業ごとの感染者数を算出する\n  \n# 円グラフを作成する\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Known occupations of COVID-19 cases\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n感染者一人当たりの接触者数\n接触者を見つけるための疫学調査の質や、市民がどの程度公衆衛生施策を遵守しているかを評価するための重要な指標として、感染者一人当たりの接触者数があげられます。\nデータ構造にもよりますが、すべての感染者と接触者を含むデータセットがあれば、感染者一人当たりの接触者数を算出し、評価を行うことができます。Go.Data のデータでは、関連データ（relationships データセット）に、感染者（sources）と接触者（targets）の関連に関する情報が含まれています。\n関連データ（relationships データセット）では、各行が接触者の記録を示し、感染元となった感染者についての情報が記載されています。このデータセットには、複数の感染者と関連している接触者はありませんが、もし複数の感染者と関連している接触者がいる場合には、そのような接触者データを精査し、事前に処理を行う必要があります（この章では触れていません）。\nまず、感染者一人当たりの接触者数を算出し、データフレーム（data frame）として保存します。\n\ncontacts_per_case &lt;- relationships %&gt;% \n  count(source_visualid)\n\ncontacts_per_case\n\n   source_visualid  n\n1   CASE-2020-0001 13\n2   CASE-2020-0002  5\n3   CASE-2020-0003  2\n4   CASE-2020-0004  4\n5   CASE-2020-0005  5\n6   CASE-2020-0006  3\n7   CASE-2020-0008  3\n8   CASE-2020-0009  3\n9   CASE-2020-0010  3\n10  CASE-2020-0012  3\n11  CASE-2020-0013  5\n12  CASE-2020-0014  3\n13  CASE-2020-0016  3\n14  CASE-2020-0018  4\n15  CASE-2020-0022  3\n16  CASE-2020-0023  4\n17  CASE-2020-0030  3\n18  CASE-2020-0031  3\n19  CASE-2020-0034  4\n20  CASE-2020-0036  1\n21  CASE-2020-0037  3\n22  CASE-2020-0045  3\n23            &lt;NA&gt; 17\n\n\ngeom_histogram() を使用し、ヒストグラムを作成します。\n\nggplot(data = contacts_per_case)+        # 上のコードで作成したデータセットを使用\n  geom_histogram(mapping = aes(x = n))+  # 感染者一人当たりの接触者数のヒストグラムを作成\n  scale_y_continuous(expand = c(0,0))+   # y軸の0より下の余分なスペースを削除\n  theme_light()+                         # 図の背景テーマの設定\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html#接触者追跡調査フォローアップ",
    "href": "new_pages/contact_tracing.jp.html#接触者追跡調査フォローアップ",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "25.3 接触者追跡調査（フォローアップ）",
    "text": "25.3 接触者追跡調査（フォローアップ）\nほとんどの追跡データには、隔離された人の毎日の症状チェックの結果を記録した接触者調査（フォローアップ）のデータが含まれています。接触者調査の記録を分析することで、今後の公衆衛生施策の策定に役立ち、追跡できなくなる危険性のある接触者や、疾患を発症する危険性のある接触者を特定することができます。\n\nデータの前処理\n接触者調査に関する情報は、様々なフォーマットで記録されています。例えば、Excel シートに各接触者を 1 行ごとに記録し、調査の結果を1日ごとに列に記録した、横型（wide 型）データなどです。縦型（long 型）データと横型（wide 型）の詳細や、データの縦横変換の方法については、 データの縦横変換 の章を参照してください。\nGo.Data からダウンロードしたデータは、追跡データ（followups データセット）に含まれており、調査の記録が各行に記載されている縦型データとなっています。以下では、接触者追跡調査データの最初の50行を表示しています。\n\n\n\n\n\n\n&lt;style=“color:orange;”&gt;注意: 接触者調査（フォローアップ）に関するデータを扱う際は、重複した調査記録に注意してください。ある接触者に対し、同じ日に複数の調査（フォローアップ）が誤って行われる可能性があります。例えば、調査員が接触者と連絡がとれなかった際にその記録を午前中に提出し、後に連絡できた際に 2 つ目の記録を提出することが起こりえます。重複した記録をどのように処理するかについては、調査の運用状況によりますが、重複記録を含んだデータを提示する際は、重複記録をどのように処理したかを明確に記載してください。\n\n追跡データ（followups データセット）に、重複している記録がいくつあるのか、チェックしてみましょう。\n\nfollowups %&gt;% \n  count(contact_id, date_of_followup) %&gt;%   # 接触者ID毎に、調査日の頻度を算出\n  filter(n &gt; 1)                             # 1日2回以上調査が行われた日を表示\n\n  contact_id date_of_followup n\n1       &lt;NA&gt;       2020-09-03 2\n2       &lt;NA&gt;       2020-09-04 2\n3       &lt;NA&gt;       2020-09-05 2\n\n\nここで扱っているサンプルデータでは、ID のない記録だけが該当しています。下のコードで、重複した記録を排除していきます。重複記録を排除することで、1 日に 1 人につき 1 回の調査記録のみ残るようになります。 詳細は、重複データの排除の章をご覧ください。ここでは、最新の調査記録が正しいものであると仮定します。また、下のコードでは、一緒に followup_number 列（調査の「日」ごとに作成され、1 ～ 14 日まである）をクリーニングします。\n\nfollowups_clean &lt;- followups %&gt;%\n  \n  # 重複記録の排除\n  group_by(contact_id, date_of_followup) %&gt;%        #接触者ID、調査日ごとに記録をグループ化する\n  arrange(contact_id, desc(date_of_followup)) %&gt;%   # 接触者ID毎に、調査日の降順で記録を並び替える（日付の新しい順）\n  slice_head() %&gt;%                                  # 接触者ID毎に、最新の調査日の記録のみ残す  \n  ungroup() %&gt;% \n  \n  # 他の前処理\n  mutate(followup_number = replace(followup_number, followup_number &gt; 14, NA)) %&gt;% # 調査日のエラーの処理\n  drop_na(contact_id)                               # 接触者IDが欠損してる記録を排除する\n\nそれぞれの調査記録には、調査の結果（接触者と連絡が取れたか、また、連絡が取れた場合は接触者に症状があったか、など）が記録されています。janitor パッケージの tabyl() 、または base R の table() に followup_status 変数を指定して実行すると、調査結果の分布が確認できます（詳細は、記述統計表の作り方の章をご覧ください）。\nこのデータセットでは、“seen_not_ok” は「いくつか症状がある」、“seen_ok” は「症状がない」という意味です。\n\nfollowups_clean %&gt;% \n  tabyl(followup_status)\n\n followup_status   n    percent\n          missed  10 0.02325581\n   not_attempted   5 0.01162791\n   not_performed 319 0.74186047\n     seen_not_ok   6 0.01395349\n         seen_ok  90 0.20930233\n\n\n\n\n追跡調査状況を時系列でプロットする\n日付データは連続しているため、date_of_followup を x 軸に指定したヒストグラムを使用し、追跡データ（followups のデータセット）を時系列でプロットできます。aes() 内の fill = 引数に followup_status 変数を指定することで、「積み上げ型」のヒストグラムを作成し、labs() 内の fill = 引数を使用して凡例のタイトルを作成することができます。\nこのデータセットを使用して作成したヒストグラムでは、接触者の分布が波状に確認され（おそらく感染者の流行の波と連動している）、追跡調査が行われていない場合が多く、流行の過程で調査の達成状況が改善されていないことがわかります。\n\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # followup_status 変数のすべての値を凡例に表示する（図に表示されていないものも含めて）\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # 動的なサブタイトルをつける\n\n\n\n\n\n\n\n\n&lt;style=“color: orange;”&gt;注意: 同一コードで複数のプロットを作成する場合（複数の管轄区域に同じプロットを提示する場合など）、データの完成度やデータの構成が異なっていても、凡例は同じように表示されるようにする必要があります。例えば、作成した複数の図の中に followup_status 変数（調査結果変数）のすべてのカテゴリーがデータに含まれていない図があるかもしれませんが、含まれていない結果のカテゴリーについても凡例に表示したい場合です。上のような ggplot を使用した図では、scale_fill_discrete() 内で drop = FALSE に指定すると、図に表示されていないカテゴリーを含むすべてのカテゴリーを凡例に表示することができます。表の場合は、すべてのカテゴリーのカウントを表示する tabyl() を使用するか、または、dplyr パッケージの count() に.drop = FALSE を追加し、すべてのカテゴリーのカウントを含めることができます。\n\n\n\n追跡調査状況を接触者別にプロットする\n調査対象のアウトブレイクの規模が小さい場合は、各接触者のフォローアップ状況を個別に確認したい場合があります。この追跡データ（followups データセット）には、調査の日にち「番号」を示す列がすでに含まれています（1 ～ 14 日まで一日ごとに列が作成してあります）。調査日ごとの列がデータにない場合は、曝露日（調査対象の接触者が感染者と接触した日）とその接触者に対して調査を開始した日の差を計算し、1 ～ 14 日まで一日ごとに列を作成する必要があります。\nデータのわかりやすい視覚化の例として（アウトブレイクの規模が大きくなければ）、geom_tile() を用いたヒートマップがあります。詳細は、ヒートマップ の章をご覧ください。\n\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # 灰色のグリッド線をひく\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))\n\n\n\n\n\n\n\n\n\n\n追跡調査状況をクループ別にプロットする\nこのような接触者追跡調査に関するデータは、疫学調査の業務的意思決定のために日ごとまたは週ごとに閲覧されていることが多いと思います。group_by() で指定する列を調整することにより、地域別や調査チーム別など、より意味のある集計結果をプロットすることができます。\n\nplot_by_region &lt;- followups_clean %&gt;%                                        # 前処理した followups のデータセットを使用する\n  count(admin_1_name, admin_2_name, followup_status) %&gt;%   # 地域別、調査チーム別のカウントを算出する (新たに 'n' 列を作成する)\n  \n  # ggplot() を使用して図を作成する\n  ggplot(                                         # ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # admin_2_name の因子（ファクタ）レベルを 'n' 列のカウントをもとに並び替える\n                  y = n,                            # 'n' 列のカウントをy軸に指定する\n                  fill = followup_status,           # フォローアップの結果カテゴリーごとに色付けする\n                  label = n))+                      # geom_label() 用              \n  geom_col()+                                     # 積み上げ型棒グラフ\n  geom_text(                                      # テキストを追加する\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # 図の背景のテーマの設定\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # facet_wrap で図の右側に admin_1_name を表示する \n\nplot_by_region",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html#重要業績評価指標kpi",
    "href": "new_pages/contact_tracing.jp.html#重要業績評価指標kpi",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "25.4 重要業績評価指標（KPI）",
    "text": "25.4 重要業績評価指標（KPI）\n接触者追跡調査の成果を評価するために、進捗や目標達成状況を様々なレベルで細分化された期間で算出し、モニターする重要業績評価指標（Key Performance Indicator: KPI）があります。KPI には多くの種類がありますが、計算方法と基本的な表のフォーマットを理解すると、様々な KPI を入れたり外したりすることが簡単にできます。\n接触者調査の KPI については、ResolveToSaveLives.org など、参考となる資料がたくさんあります。KPI 作成作業の多くは、データ構造を確認し、すべての選択・除外基準を考えることです。以下に、Go.Data を使用した KPI の例を示します。\n\n\n\n\n\n\n\n\n\nカテゴリー\nKPI\n分子\n分母\n\n\n\n\nプロセスの評価 - 接触者追跡調査の迅速さ\n全感染者のうち、感染報告から24時間以内に疫学調査が行われ、隔離された感染者の割合\nCOUNT OF case_id WHERE (date_of_reporting - date_of_data_entry) &lt; 1 day AND (isolation_startdate - date_of_data_entry) &lt; 1 day\nCOUNT OF case_id\n\n\nプロセスの評価 - 接触者追跡調査の迅速さ\n全接触者のうち、感染者の接触報告から24時間以内に通知され、隔離された接触者の割合\nCOUNT OF contact_id WHERE followup_status == “SEEN_NOT_OK” OR “SEEN_OK” AND date_of_followup - date_of_reporting &lt; 1 day\nCOUNT OF contact_id\n\n\nプロセスの評価 - 感染症検査の完了率\n全感染者のうち、症状発現から3日以内に検査され、疫学調査が行われた者の割合\nCOUNT OF case_id WHERE (date_of_reporting - date_of_onset) &lt; =3 days\nCOUNT OF case_id\n\n\nアウトカムの評価 - 全体評価\n全感染者のうち、感染報告前に接触者として報告されていた者の割合\nCOUNT OF case_id WHERE was_contact == “TRUE”\nCOUNT OF case_id\n\n\n\nこのセクションでは、接触者追跡調査状況を複数の管轄区域にわたって表示する表を作成していきます。表を作成した後、formattable パッケージを使用し、更に見やすく表を編集していきます（flextable などの他のパッケージを使用することもできます。詳細は、見やすい表の作り方 の章を参照してください）。\n表の作成手順は、接触者追跡調査に関するデータの構造によりって変わります。 dplyr パッケージを使用してデータを要約する方法についての詳細は、記述統計表の作り方 の章をご覧ください。\nここでは、データの変化に合わせて連動する表を作成します。結果を面白くするために、特定の日に report_date （この表を提示し、追跡調査の進捗を報告する日）を設定し、表を作成します（この例では、2020年6月10日を選びます）。データは report_date でフィルタリングされ、report_date の日、または、report_date より以前に報告された記録のみ残ります。\n\n# report_date (報告日)を設定する\nreport_date &lt;- as.Date(\"2020-06-10\")\n\n# report_date (報告日)でデータセットをフィルタリングする\ntable_data &lt;- followups_clean %&gt;% \n  filter(date_of_followup &lt;= report_date)\n\nreport_date でフィルタリング後、以下の手順でデータを整理し、表を作成していきます。\n\n追跡データ（followups データセット）を選択し、各接触者について、以下 3 つの関心のある指標を算出します。\n\n\n一番最近行った調査の日付（接触者と連絡が取れたかなどの調査結果は問わない）\n接触者と連絡が取れた調査のうち、最も新しい日付\n接触者と連絡が取れた最新の調査での、接触者の状況（例：症状あり又は症状なし）\n\n\nステップ 1 で作成したデータを、曝露日（感染者と接触した日）などの接触者に関する他の情報を含む接触データに結合します。次に、各接触者について、曝露日からの日数など、関心のある指標を算出します。\n結合したデータを、管轄区域別（admin_2_name）にグループ化し、管轄区域別の要約統計量を算出します。\n最後に、作成した表の形式を整えます。\n\nでは、以上の手順を実際に R で実行していきましょう。ステップ 1：追跡データ（followups データセット）を整備し、必要な指標を算出する。\n\nfollowup_info &lt;- table_data %&gt;% \n  group_by(contact_id) %&gt;% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %&gt;% \n  ungroup()\n\n作成したデータセットを以下に表示します。\n\n\n\n\n\n\nステップ 2：次に、作成したデータセットを接触者データ（contacts データセット）に結合し、他に必要な指標を算出します。\n\ncontacts_info &lt;- followup_info %&gt;% \n  right_join(contacts, by = \"contact_id\") %&gt;% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\n\n2 つのデータセットを結合すると、データは以下のようになります。接触データに含まれていた列は右側に、算出した関心のある指標は一番右に表示されます。\n\n\n\n\n\n\nステップ 3：結合したデータを、管轄区域別にグループ化し、区域別に要約統計量を算出します。\n\ncontacts_table &lt;- contacts_info %&gt;% \n  \n  group_by(`Admin 2` = admin_2_name) %&gt;%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure &lt; 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure &gt;= 8 & days_since_exposure &lt; 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen &gt;= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %&gt;% \n    \n  arrange(desc(`Registered contacts`))\n\n\n\n\n\n\n\nステップ 4：formattable と knitr パッケージを使用し、見やすいように表を整えていきます。また、report_date （報告日）に関する脚注を追記します。\n\ncontacts_table %&gt;%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %&gt;%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %&gt;%\n  kable_styling(\"hover\", full_width = FALSE) %&gt;%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %&gt;% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf contacts currently under follow up\n\n\nStatus of last visit\n\n\n\nAdmin 2\nRegistered contacts\nActive contacts\nIn first week\nIn second week\nBecame case\nLost to follow up\nNever seen\nFollowed up - signs\nFollowed up - no signs\nNot Followed up\n\n\n\n\nDjembe \n59\n30\n44\n0\n2\n15\n22\n0\n0\n0\n\n\nTrumpet\n3\n1\n3\n0\n0\n0\n0\n0\n0\n0\n\n\nVenu \n2\n0\n0\n0\n2\n0\n2\n0\n0\n0\n\n\nCongas \n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\nCornet \n1\n0\n1\n0\n1\n0\n1\n0\n0\n0\n\n\n\nNote: \n\n\n\n\n\n\n\n\n\n\n\n\n Data are current to Jun 10 2020",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html#感染連鎖の可視化",
    "href": "new_pages/contact_tracing.jp.html#感染連鎖の可視化",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "25.5 感染連鎖の可視化",
    "text": "25.5 感染連鎖の可視化\nヒートマップ の章で解説したように、geom_tile() を使用して「誰が誰から感染したか」を可視化するヒートマップを作成することができます。\nGo.Data では、接触者データ（contacts データセット）に新しい接触者が追加されると、API によって、関連データ（relationships データセット）に、その接触者と接触した感染者の関係情報が追加されます。relationships データセットには、各接触者と接触した感染者の情報が含まれているので、このデータセットを使用すると比較的簡単にヒートマップを作成することができます。以下に、関連データ（relationships データセット）の最初の 50 行を表示します。\n\n\n\n\n\n\n接触者と感染者の年齢を比較した人口ピラミッドを 25.2 記述統計のセクションで作成したように、必要な変数以外を除外し、接触者と感染者の両方について、年齢をカテゴリー化する必要があります。\n\nheatmap_ages &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  mutate(                            # transmuteはmutateと似ていますが、他の列をすべて除外します\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \n\nまず、ヒートマップ の章で解説したように、クロス集計表を作成します。\n\ncross_tab &lt;- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab\n\n            target_cases\nsource_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54\n       0-4     0   0     0     0     0     0     0     0     0     1     0\n       5-9     0   0     1     0     0     0     0     1     0     0     0\n       10-14   0   0     0     0     0     0     0     0     0     0     0\n       15-19   0   0     0     0     0     0     0     0     0     0     0\n       20-24   1   1     0     1     2     0     2     1     0     0     0\n       25-29   1   2     0     0     0     0     0     0     0     0     0\n       30-34   0   0     0     0     0     0     0     0     1     1     0\n       35-39   0   2     0     0     0     0     0     0     0     1     0\n       40-44   0   0     0     0     1     0     2     1     0     3     1\n       45-49   1   2     2     0     0     0     3     0     1     0     3\n       50-54   1   2     1     2     0     0     1     0     0     3     4\n       55-59   0   1     0     0     1     1     2     0     0     0     0\n       60-64   0   0     0     0     0     0     0     0     0     0     0\n       65-69   0   0     0     0     0     0     0     0     0     0     0\n       70-74   0   0     0     0     0     0     0     0     0     0     0\n       75-79   0   0     0     0     0     0     0     0     0     0     0\n       80+     1   0     0     2     1     0     0     0     1     0     0\n            target_cases\nsource_cases 55-59 60-64 65-69 70-74 75-79 80+\n       0-4       1     0     0     0     0   0\n       5-9       1     0     0     0     0   0\n       10-14     0     0     0     0     0   0\n       15-19     0     0     0     0     0   0\n       20-24     1     0     0     0     0   1\n       25-29     0     0     0     0     0   0\n       30-34     1     0     0     0     0   0\n       35-39     0     0     0     0     0   0\n       40-44     1     0     0     0     1   1\n       45-49     2     1     0     0     0   1\n       50-54     1     0     1     0     0   1\n       55-59     0     0     0     0     0   0\n       60-64     0     0     0     0     0   0\n       65-69     0     0     0     0     0   0\n       70-74     0     0     0     0     0   0\n       75-79     0     0     0     0     0   0\n       80+       0     0     0     0     0   0\n\n\n次に、クロス集計表を縦型（long 型）データに変換します。\n\nlong_prop &lt;- data.frame(prop.table(cross_tab))\n\n最後に、接触者がどの年齢層の感染者から感染したかを年齢層別に表すヒートマップを作成します。\n\nggplot(data = long_prop)+       # long型データを使用（Freq変数を割合として使用）\n  geom_tile(                    # タイルで可視化\n    aes(\n      x = target_cases,         # x軸を接触者の年齢層に指定\n      y = source_cases,     # y軸を感染者の年齢層に指定\n      fill = Freq))+            # Freq変数でタイルを色付け\n  scale_fill_gradient(          # タイルの色の調整\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # プロット、軸、凡例のタイトルを指定\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # 凡例のタイトル\n  )",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.jp.html#参考資料",
    "href": "new_pages/contact_tracing.jp.html#参考資料",
    "title": "25  接触者の追跡{#contact-tracing}",
    "section": "25.6 参考資料",
    "text": "25.6 参考資料\nhttps://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting\nhttps://worldhealthorganization.github.io/godata/\nhttps://community-godata.who.int/",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>接触者の追跡{#contact-tracing}</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html",
    "href": "new_pages/survey_analysis.jp.html",
    "title": "26  標本調査データ分析",
    "section": "",
    "text": "26.1 概要\nこの章では、標本調査データ分析のためのいくつかのパッケージの使用方法を説明します。\nほとんどの調査用 R パッケージは、重み付け分析を行うために surveyパッケージに依存しています。本章では、survey パッケージと同様に srvyr パッケージ（tidyverse スタイルのコーディングを可能にする survey パッケージのラッパー）および gtsummary パッケージ（出版原稿レベルの整った表の出力を可能にする survey パッケージのラッパー）を使用します。オリジナルの survey パッケージは、tidyverse スタイルのコーディングはできませんが、調査重み付け一般化線形モデル（survey-weighted generalised linearmodel）を使用できるという利点があります（後日この章に追加される予定です）。また、sitrep パッケージの関数を使用して、標本抽出法による重み付けを作成するデモも行います（注：このパッケージは現在 CRAN にはありませんが、Github からインストールできます）。\nこの章のほとんどは、“R4Epis” プロジェクトで行われた作業に基づいています。詳細なコードと R markdown テンプレートファイルについては、“R4Epis” の Github ページを参照してください。survey パッケージを利用したのコードの一部は、EPIET ケーススタディの初期バージョンに基づいています。\n現在、この章では標本サイズの計算や標本抽出法そのものについては触れていません。簡単に利用できる標本サイズ計算機については、OpenEpi を参照してください。ハンドブックの GIS の基礎の章には、いずれ空間的無作為抽出のセクションが設けられ、本章には、標本サイズの計算だけでなく、無作為抽出するための「標本抽出枠」（sampling frame）のセクションが設けられる予定です。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#概要",
    "href": "new_pages/survey_analysis.jp.html#概要",
    "title": "26  標本調査データ分析",
    "section": "",
    "text": "調査データ\n観察期間\n重み付け\n調査デザイン対象\n記述的分析\n重み付けされた割合\n重み付けされた比率",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#準備",
    "href": "new_pages/survey_analysis.jp.html#準備",
    "title": "26  標本調査データ分析",
    "section": "26.2 準備",
    "text": "26.2 準備\n\nパッケージ\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。 pacman パッケージの p_load_gh() 関数を使って、まだ CRAN で公開されていない github 上のパッケージをインストールして読み込むデモも行っています。\n\n## CRAN からパッケージを読み込む\npacman::p_load(rio,          # ファイルのインポート\n               here,         # ファイルパスの指定\n               tidyverse,    # データ管理 + ggplot2 のグラフ\n               tsibble,      # 時系列データセットを扱う\n               survey,       # 調査関数\n               srvyr,        # survey パッケージ用の dplyr ラッパー\n               gtsummary,    # 表作成のための survey パッケージ\n               apyramid,     # 年齢ピラミッド作成のためのパッケージ\n               patchwork,    # ggplot を組み合わせるためのパッケージ\n               ggforce       # 沖積図・サンキーダイアグラム\n               ) \n\n## load packages from github\npacman::p_load_gh(\n     \"R4EPI/sitrep\"          # 観察期間・重み付け関数\n)\n\n\n\nデータの読み込み\n本章で使用する例示用データセットです。\n\n架空の死亡率調査データ\n調査対象地域の架空の母集団\n架空の死亡率調査データのデータ辞書\n\nこれらは、MSF OCA 倫理審査委員会が事前に承認した調査に基づいています。架空のデータセットは、“R4Epis” プロジェクトの一環として作成されました。これはすべて、OpenDataKit をベースにしたデータ収集ソフトウェアである KoboToolbox を使って収集したデータに基づいています。\nKobo では、収集したデータだけでなく、そのデータセットのデータ辞書もエクスポートできます。データの前処理が容易になり、変数や質問文を調べるのに便利なので、この方法を強くお勧めします。\nヒント： Kobo のデータ辞書形式（例、MSF-survey-dict.xlsx）では、調査ごとシートに分かれており、各シートの “name” 列に変数名（質問）が記載されています。各変数がとり得る値（回答の選択肢）は、“options” シートで設定されています。“options” シートでは、“name” 列には選択肢の省略形が、“label::english” および “label::french” 列にはそれぞれの言語で適切な長さの選択肢が表示されています。Epidict パッケージの msf_dict_survey() 関数を使って、Kobo データ辞書形式の Excel ファイルをインポートすると、対象の調査シートがデータフレームに変換されるので、調査データをコード記述に簡単に利用できます。\n注意：ハンドブックとデータのダウンロード からダウンロードできる例示用データセット（survey_dict.xlsx）は、Kobo からの単純なエクスポートとは出力形式が異なります（Koboでは、異なる質問表をそれぞれ個別にエクスポートします）異なる質問表をマージするには、以下の「調査データ」のセクションを参照してください。\nデータセットは rio パッケージの import() 関数を使ってインポートされます。データをインポートするさまざまな方法については、データのインポート・エクスポートの章を参照してください。\n\n# 調査データをインポートする\nsurvey_data &lt;- rio::import(\"survey_data.xlsx\")\n\n# データ辞書を R にインポートする\nsurvey_dict &lt;- rio::import(\"survey_dict.xlsx\") \n\n調査データの最初の 10 行を以下に示します。\n\n\n\n\n\n\n適切な重みを作成するために、標本を抽出した集団（母集団）についてのデータをインポートしましょう。このデータの形式はいろいろなファイル形式で作成できますが、以下に例示するような形式をお勧めします（このデータは、Excel に直接入力しても作成できます）。\n\n# 母集団データをインポートする\npopulation &lt;- rio::import(\"population.xlsx\")\n\n母集団データの最初の 10 行を以下に示します。\n\n\n\n\n\n\nクラスター調査の場合は、クラスター単位で調査の重みを加えることが必要な場合もあります。クラスター単位のデータは上記と同じ手段でインポートできます。あるいは、クラスターや世帯のカウント数が少ない場合は、以下のように入力してクラスターとクラスターが含む世帯数の 2 つの列を定義できます。いずれの方法にしても、調査データと一致するクラスターを識別する列と、各クラスターが含む世帯数を表す列が必要になります。\n\n## 各クラスターの世帯数を定義する\ncluster_counts &lt;- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))\n\n\n\nデータの前処理（データクリーニング）\n日付を値として持つ変数（列）が適切な形式であることを以下で確認しています。他にもいくつかの方法がありますが（詳しくは「日付型データ」の章をご覧ください）、データ辞書を使って日付を定義するのが手っ取り早くて簡単です。\nまた、epikit パッケージの age_categories() 関数を使って、年齢グループの変数を作成します（詳細はデータクリーニングと主要関数の章を参照）。さらに、各クラスターがどの担当保健所に含まれるかを定義する文字型変数（列）を作成します。\n最後に、yes/no で回答されている変数（列）をすべて TRUE/FALSE の値を取る変数に上書きします。値が yes/no のままであると、これらの変数は survey パッケージの人口を扱う関数で使用できません。\n\n## survery_dict オブジェクトからtype 列に値 date を持つ行を選択する \nDATEVARS &lt;- survey_dict %&gt;% \n  filter(type == \"date\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## 前行でフィルタした行の \"name\" 列の値が survey_data オブジェクト内の変数名（列名）と、一致した行をフィルタする\n  pull(name) # type 列に値 date を持つ行を選択する\n  \n## survey_data オブジェクト内の変数（列）で DATEVARS に含まれる変数（列）を日付型に変更する \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## 年齢が月単位の値（1 歳未満）を年齢の変数に加える（12 で割る）\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## 年齢層を格納する変数を定義する\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## 他に cluster_number 変数（列）の内容を基にした health_distinct （担当保健所）という文字型変数（列）を作成する\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## survey_dict オブジェクトから type 列 に yn を値として持つ行を選択する \nYNVARS &lt;- survey_dict %&gt;% \n  filter(type == \"yn\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## 前行でフィルタした行の \"name\" 列の値が survey_data オブジェクト内の変数名（列名）と、一致した行をフィルタする\n  pull(name) # type 列に値 yn を持つ行を選択する\n  \n## survey_data オブジェクト内の変数（列）で YNVARS に含まれる変数（列）をロジカル型に変更する \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(all_of(YNVARS), str_detect, pattern = \"yes\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#調査データ",
    "href": "new_pages/survey_analysis.jp.html#調査データ",
    "title": "26  標本調査データ分析",
    "section": "26.3 調査データ",
    "text": "26.3 調査データ\n標本調査の方法には、さまざまな標本抽出法があります。このセクションでは、以下の標本抽出法のコード実装例を紹介します。 - 層化抽出法 - クラスター抽出法 - 層化クラスター抽出法\n「データの読み込み」セクションで例示したように、（調査票をどのように計画するかにもよりますが）各レベル（水準）のデータは、Kobo から別々のデータセットとしてエクスポートされます。下記のコード例では、世帯と、その世帯内の個人がそれぞれ 1 つのレベルで表現されています。\nこの 2 つのレベルは、一意の識別子で紐付けられています。Kobo のデータセットの場合、識別子は世帯レベルの “_index” という変数の値であり、各個人レベルの “_parent_index” という変数名の値と一致します。left_join() による結合操作で、識別子が一致する個人ごとに世帯の新しい行が作成されます。詳細はハンドブックのデータの結合の章を参照してください。\n\n## 個人データと世帯データを結合し、完全なデータセットを作成する\nsurvey_data &lt;- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## 個人と世帯の 2 つのレベルの組み合わせで、新たに識別子を作成する\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#観察期間",
    "href": "new_pages/survey_analysis.jp.html#観察期間",
    "title": "26  標本調査データ分析",
    "section": "26.4 観察期間",
    "text": "26.4 観察期間\n死亡率調査において、対象期間における適切な死亡率を算出するために、各個人が対象地域にどのくらいの期間、居住したかという情報が必要です。この居住に関する情報は、すべての調査に当てはまるわけではありませんが、特に死亡率調査の場合は重要です。なぜなら、移動人口や避難民人口を含んだ状況で頻繁に行われる調査だからです。\n死亡率調査を行うためには、まず、対象期間を設定する必要があります。対象期間の設定は、想起期間（リコール期間、質問に答える際に参加者にその期間の健康状態を考慮して回答を求める期間）としても知られています。例えば、この対象期間を利用して、対象期間外の死亡報告などは、不適切な日付として欠損値を設定できます。\n\n## 想起期間の開始日・終了日を設定する\n## データセットに日付型変数（列）として設定\n## (例：転入日や質問日)\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end   = as.Date(\"2018-05-01\")\n  )\n\n\n# ルールに基づいて不適切な日付に NA を設定する \n## 例：想起期間開始前の転入、想起期間終了後の転出\nsurvey_data &lt;- survey_data %&gt;%\n      mutate(\n           arrived_date = if_else(arrived_date &lt; recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date &lt; recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date &gt; recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date &gt; recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n\n次に、日付型の値を格納している変数（列）を使って、観察期間開始日と観察期間終了日を設定します。sitrep パッケージの find_start_date() 関数と find_end_date() 関数を使って、観察期間開始・終了イベント発生理由とそれぞれの日付を調べます。そして、調べた観察期間開始・終了の日付を使って観察日数（person-time）を計算します。\n観察期間開始日：想起期間内の適切なイベント開始の中で最も古い日付。想起期間の開始日（事前に設定する）、または該当するイベントがある場合は想起期間開始以後の日付（例：転入や出生など）が割り当てられる\n観察期間終了日：想起期間内の適切なイベント終了の中で最も新しい日付。想起期間の終了日（事前に設定する）、または該当するイベントがある場合は想起期間終了以前の日付（例：転出や死亡など）が割り当てられる\n\n## 観察期間開始日、観察期間終了日、それぞれのイベント発生理由を格納するための新しい変数（列）を作成する\nsurvey_data &lt;- survey_data %&gt;% \n     ## イベント発生理由が、出生、転入（世帯の転入、難民キャンプの転入）のうち\n     ## 入力された最も古い日付を選択する\n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end   = \"recall_end\",\n                  datecol      = \"startdate\",\n                  datereason   = \"startcause\" \n                 ) %&gt;%\n     ## イベント発生理由が、転出（難民キャンプの転出ふくむ）、死亡、調査の終了のうち\n     ## 入力された最も新しい日付を選択する\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end   = \"recall_end\",\n                datecol      = \"enddate\",\n                datereason   = \"endcause\" \n               )\n\n\n## 想起期間開始・終了時点で継続して居住していた記録にラベルをつける（出生・死亡を除く）\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(\n       ## 想起期間の開始日を個人の観察期間開始日に設定する（個人の観察期間開始日が欠損している場合への対応） \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## 個人の観察期間開始日が、出生日と等しくなく、かつ、想起期間開始日と等しい場合、\n       ## 観察期間開始理由を \"Present at start\" と設定する \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## 想起期間の終了日を個人の観察期間終了日に設定する（個人の観察期間終了日が欠損している場合への対応） \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## 個人の観察期間終了日が、死亡日と等しくなく、かつ、想起期間終了日に等しい場合は、\n       ## 観察期間終了理由を \"Present at end\" と設定する\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## 観察期間を日単位で計算し obstime 変数（列）に設定する\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(obstime = as.numeric(enddate - startdate))",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#調査の重み付け",
    "href": "new_pages/survey_analysis.jp.html#調査の重み付け",
    "title": "26  標本調査データ分析",
    "section": "26.5 調査の重み付け",
    "text": "26.5 調査の重み付け\n調査の重み付けを実行する前に、誤った観測値の除外が必要です。例えば、負の観察期間が入力されている観察値がある場合、その詳細を確認する必要があります（sitrep パッケージの assert_positive_timespan() で負の観察期間の記録を一覧できます）。他に必要な前処理は、空行の除外や（例えば drop_na(uid) を使用して）、重複した行の除外です（詳細はハンドブックの 重複データの排除の章を参照してください）。同意（インフォームド・コンセント）が取れていない記録（“concent” 変数（列）が false）も除外する必要があります。\n下記例では、除外したいケースを抽出して、別のデータフレーム（dropped）に保存します。この抽出操作により、調査分析から除外された症例を明示できます。次に、dplyr パッケージの anti_join() 関数を使用して、調査データ（survey_data）オブジェクトからこれらの除外された症例を削除します。\n危険： 体重の変数や、調査デザインに関連する変数（年齢、性別、層やクラスターの変数など）に欠損値があってはいけません。\n\n## 除外した症例を別のデータフレームとして保存しておけば、除外理由を説明できる（例：同意がないもしくは、誤った市区町村・クラスター)\ndropped &lt;- survey_data %&gt;% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## 除外された症例データセットを使用して、調査データセットから未使用の記録（行）を削除する\nsurvey_data &lt;- anti_join(survey_data, dropped, by = names(dropped))\n\n前述のように、3 つの異なる標本抽出法（層化抽出法、クラスター抽出法、層化クラスター抽出法）について、重みを追加する方法を示します。これらの抽出法には、母集団、標本の両方とも，またはいずれか一方の集団に関する情報が必要です。下記例では、層化クラスター抽出法のための重みを追加するコードを使用しますが、研究デザインに最も適したものを使用してください。\n\n# 層化抽出法 ------------------------------------------------------------------------\n# 年齢層別（age_group）、性別（sex）、担当保健所（health_district）各変数（列）についての各個人の重みを含んでいる（層化されている）\n# \"surv_weight_strata\" という変数（列）を作成する\nsurvey_data &lt;- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## クラスター抽出法 ------------------------------------------------------------------\n\n# 1 世帯あたりのインタビュー対象者（interviewed）の人数を得る\n# 次に、世帯（親クラスター）の識別子を格納する変数のカウントを持つ変数（列）を追加する（cluster_counts）\nsurvey_data &lt;- survey_data %&gt;%\n  add_count(index, name = \"interviewed\")\n\n\n## クラスターの重みを作成する\nsurvey_data &lt;- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# 層化クラスター抽出法 --------------------------------------------------------------\n# クラスターと層化をかけ合わせた重み（surv_weight_strata * surv_weight_cluster）を作成する（surv_weight_cluster_strata）\nsurvey_data &lt;- survey_data %&gt;%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#調査デザインオブジェクト",
    "href": "new_pages/survey_analysis.jp.html#調査デザインオブジェクト",
    "title": "26  標本調査データ分析",
    "section": "26.6 調査デザインオブジェクト",
    "text": "26.6 調査デザインオブジェクト\n研究デザイン（抽出法）に合わせて調査デザインオブジェクト（survey design object）を作成します。データフレーム（survey_data）と同様に、重み付け人口比率などの計算に使用します。必要な変数（列）がすべて作成されていることを確認してから行います。\n抽出法の設定には下記の 4 つの選択肢がありますが、使用しない抽出法に関するコードはコメントアウトしてください。 - 単純無作為抽出法 - 層化抽出法 - クラスター抽出法 - 層化クラスター抽出法\nこのテンプレートでは、2 つの異なる層（担当保健所 A と B）で標本調査をクラスター化したと仮定します。したがって、全体の推定値を得るためには、クラスターと層の重みを組み合わせる必要があります。\n前述したように、抽出法に沿った分析を行うために 2 つのパッケージが用意されています。古典的なものは survey パッケージで、それから tidyverse コーディングに適したオブジェクトや関数を作る srvyr パッケージというラッパーがあります。両方ともデモを行いますが、本章のコードのほとんどは srvyr パッケージベースのオブジェクトを使用することに注意してください。1 つの例外は、gtsummary パッケージが survey パッケージのオブジェクトしか受け付けないことです。\n\n26.6.1 Survey パッケージ\nsurvey パッケージの構文は、base R の構文を効果的に使用するため、パイプ （%&gt;%） やその他の dplyr パッケージの構文を使用することはできません。survey パッケージでは、svydesign() 関数を使用して、適切なクラスタ、重み、層を持つ調査オブジェクト（survey object）を定義します。\n注釈：svydesign() の引数に指定する変数の前にチルダ記号（~）を記述しなければいけません。なぜなら、survey パッケージは、formula オブジェクトに基づいて関数の引数に変数を割り当てる base R の構文を使用しているためです。\n\n# 単純無作為抽出法 ------------------------------------------------------------------\nbase_survey_design_simple &lt;- svydesign(ids = ~1, # クラスター ID なしを意味する 1 を指定\n                   weights = NULL,               # 重みはなし\n                   strata = NULL,                # 単純無作為抽出法であるため層の指定はなし\n                   data = survey_data            # データセットを指定する必要あり\n                  )\n\n## 層化抽出法 -----------------------------------------------------------------------\nbase_survey_design_strata &lt;- svydesign(ids = ~1,  # クラスター ID なしを意味する 1 を指定\n                   weights = ~surv_weight_strata, # 以前のコードチャンクで作成した層化に対応する重みの変数を指定\n                   strata = ~health_district,     # 層化抽出法の指定は担当保健所（health_district）ごとに層化する\n                   data = survey_data             # データセットを指定する必要あり\n                  )\n\n# クラスター抽出法 ------------------------------------------------------------------\nbase_survey_design_cluster &lt;- svydesign(ids = ~village_name, # クラスター ID を市区町村（village_name）に指定\n                   weights = ~surv_weight_cluster, # 以前のコードチャンクで作成したクラスターに対応する重みの変数を指定\n                   strata = NULL,                 # クラスター抽出法であるため層の指定はなし\n                   data = survey_data              # データセットを指定する必要あり\n                  )\n\n# 層化クラスター抽出法 --------------------------------------------------------------\nbase_survey_design &lt;- svydesign(ids = ~village_name,      # クラスター ID に市区町村（village_name）を指定\n                   weights = ~surv_weight_cluster_strata, # 以前のコードチャンクで作成した重みの変数を指定\n                   strata = ~health_district,             # 層化抽出法の指定は担当保健所（health_district）で層化を行う\n                   data = survey_data                     # データセットを指定する必要あり\n                  )\n\n\n\n26.6.2 Srvyr パッケージ\nSrvyr パッケージでは、as_survey_design() 関数を使うことができます。as_survey_design() は、svydesign() と同じ引数を取りますが、パイプ演算子（%&gt;%）を使えるので、チルダ記号（~）を使う必要はありません。\n\n## 単純無作為抽出法 ------------------------------------------------------------------\nsurvey_design_simple &lt;- survey_data %&gt;% \n  as_survey_design(ids = 1, # クラスター ID なしを意味するは 1 を指定 \n                   weights = NULL, # 重みはなし\n                   strata = NULL # 単純無作為抽出法であるため層の指定はなし\n                  )\n## 層化抽出法 ------------------------------------------------------------------------\nsurvey_design_strata &lt;- survey_data %&gt;%\n  as_survey_design(ids = 1, # クラスター ID なしは 1 を指定\n                   weights = surv_weight_strata, # 以前のコードチャンクで作成した重みの変数を指定\n                   strata = health_district # 層化抽出法の指定は担当保健所（health_district）ごとに層化する\n                  )\n## クラスター抽出法 ------------------------------------------------------------------\nsurvey_design_cluster &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # クラスター ID を指定\n                   weights = surv_weight_cluster, # 以前のコードチャンクで作成した重みの変数を指定\n                   strata = NULL # 抽出は単純に（層はなし）\n                  )\n\n## 層化クラスター --------------------------------------------------------------\nsurvey_design &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # クラスター ID に市区町村（village_name）を指定\n                   weights = surv_weight_cluster_strata, # 以前のコードチャンクで作成した重みの変数を指定\n                   strata = health_district # 層化抽出法の指定は担当保健所（health_district）ごとに層化する\n                  )",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#記述的分析",
    "href": "new_pages/survey_analysis.jp.html#記述的分析",
    "title": "26  標本調査データ分析",
    "section": "26.7 記述的分析",
    "text": "26.7 記述的分析\n基本的な記述的分析と視覚化は、ハンドブックの他の章で広範囲にカバーされているので、ここでは触れません。詳細は、記述統計表の作り方、簡単な統計的検定、見やすい表の作り方、ggplot の基礎、R Markdown で作るレポートの章を参照してください。\nこのセクションでは、標本の偏りを調査し、その偏りの程度を視覚化する方法に焦点を当てます。また、沖積図・サンキーダイアグラムを使って、調査環境における人口の流れを視覚化することも検討します。\n一般的には、以下のような記述的な分析を含めることを検討すべきです。\n\n対象となるクラスター、世帯、個人の最終的な数\n分析から除外された人の数とその理由\nクラスターあたりの世帯数と世帯あたりの人数の中央値（範囲）\n\n\n26.7.1 標本抽出のバイアス\n各年齢層の割合を、標本と母集団の間で比較します。これは、潜在的な標本抽出のバイアスを明らかにするために重要です。同様の操作を性別に対して適用して分布を調べられます。\n標本と母集団の比較（二項検定）で設定される p 値は単なる指標であり、母集団と比較した標本集団の分布の記述的な議論（または次のセクションの年齢ピラミッドによる視覚化）は、二項検定自体よりも重要であることに注意してください。なぜなら、標本サイズを大きくすると、データを重み付けした後では、p 値は無関係な差になることが多いからです。\n\n## 標本の人数と年齢層ごとの人口構成比率\nag &lt;- survey_data %&gt;% \n  group_by(age_group) %&gt;% \n  drop_na(age_group) %&gt;% \n  tally() %&gt;% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## 母集団の人数と年齢層ごと人口構成比率\npropcount &lt;- population %&gt;% \n  group_by(age_group) %&gt;%\n    tally(population) %&gt;%\n    mutate(proportion = n / sum(n))\n\n## 2 つの表の列を結合し、年齢別にグループ化し、二項検定を行って、\n## 標本の n/total が母集団の n/total と有意に異なるかどうかを調べる\n  ## 次の行では、2 つのデータセットの列の最後に接尾文字を追加している\njoined_table &lt;- left_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %&gt;%\n  group_by(age_group) %&gt;%\n  ## broom::tidy(binom.test()) は、二項検定の結果からデータフレームを作成し、\n  ## 変数（列） p.value, parameter, conf.low, conf.high, method, and alternative を追加する\n  ## ここでは p.value のみを使用する\n  ## 信頼区間を報告したい場合は、他の列を含めることができる\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %&gt;%\n  unnest(cols = c(binom)) %&gt;% # important for expanding the binom.test data frame\n  mutate(proportion_pop = proportion_pop * 100) %&gt;%\n  ## 偽陽性を補正するために p 値を調整する \n  ## （複数の年齢層をテストしたことによる）\n  ## これは、多くの年齢カテゴリーがある場合にのみ違いが生じる\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %&gt;%\n                      \n  ## 0.001 を超える p 値のみ示す(0.001 未満は &lt;0.001 として示す)\n  mutate(p.value = ifelse(p.value &lt; 0.001, \n                          \"&lt;0.001\", \n                          as.character(round(p.value, 3)))) %&gt;% \n  \n  ## 列の名前を適切に変更する\n  select(\n    \"Age group\" = age_group,\n    \"Study population (n)\" = n,\n    \"Study population (%)\" = proportion,\n    \"Source population (n)\" = n_pop,\n    \"Source population (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )\n\n\n\n26.7.2 人口統計ピラミッド\n人口統計（または年齢-性別）ピラミッドは、母集団の分布を視覚化する簡単な方法です。また、調査の層別に年齢と性別の記述統計表を作成することも検討する価値があります。ここでは、上記で作成した調査デザインオブジェクト（study design object）を使用して、加重比例が可能な apyramid パッケージを使用して説明します。人口ピラミッドとリッカート尺度 の章で、人口統計ピラミッドを作成するための他の選択肢について詳しく説明しています。また、apyramid パッケージの age_pyramid() ラッパー関数を使用して、人口比率のプロットを作成するためのコーディングを省きます。\n前述の標本抽出のバイアスのセクションで例示した母集団と標本の人口比率の差の二項検定のように、このセクションでは、我々の標本抽出した集団が元の母集団と実質的に異なるかどうか、そして重み付けがこの差を修正するかどうかを可視化を扱います。コードを実行するために、ggplot パッケージの出力を並べて表示するために patchwork パッケージを使用します。詳細はハンドブックの ggplot のヒント の章の「図の中に図を挿入する」のセクションを参照してください。このセクションでは、「母集団」、「重み付けされていない標本集団」、「重み付けされた標本集団」を視覚化します。また、調査の各層ごとに視覚化も可能です。ここでの例では、stack_by = \"health_district\" という引数を使用します（詳細は ?plot_age_pyramid を参照してください）。\n注釈：人口ピラミッドのプロットでは、x 軸と y 軸が反転します。\n\n## x 軸の範囲とラベルを定義する ---------------------------------------------\n## (これらの数値をグラフの値として更新する)\nmax_prop &lt;- 35      # 表示させたい人口比率の上限を選ぶ \nstep &lt;- 5           # 表示させたいラベル間のスペースを選ぶ\n\n## 上記の数値を使って、軸の区切りのベクトルを定義する\nbreaks &lt;- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## 上記の数値を使って、軸の範囲のベクトルを定義する\nlimits &lt;- c(max_prop/100 * -1, max_prop/100)\n\n## 上記の数値を使って、軸のラベルのベクトルを定義する\nlabels &lt;-  c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## プロットを個別に作成する  --------------------------------------------------\n\n## 母集団をプロットする\n## 注：全体の人口を対象にして集計する必要がある（例：担当保健所によるクラスタリングを行わない）\nsource_population &lt;- population %&gt;%\n  ## 年齢と性別が因子型であることを明示する\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %&gt;% \n  group_by(age_group, sex) %&gt;% \n  ## 各担当保健所内の人口数を足し合わせる\n  summarise(population = sum(population)) %&gt;% \n  ## グループ化を解除して全体の比率を算出する\n  ungroup() %&gt;% \n  mutate(proportion = population / sum(population)) %&gt;% \n  ## 人口ピラミッドをプロットする\n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## x 軸（表示状は垂直方向に表示される）のラベルのみを表示（設定しないと、他の 3 つのプロットすべてにラベル表示が繰り返される）\n  labs(title = \"Source population\", \n       y = \"\", \n       x = \"Age group (years)\") + \n  ## すべてのプロットの x 軸（垂直表示）のスケールを同一にする \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## 重み付けされていない標本集団をプロットする\nsample_population &lt;- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## y 軸（表示状は水平方向に表示される）のラベルのみを表示（設定しないと、他の 3 つのプロットすべてにラベル表示が繰り返される）\n  labs(title = \"Unweighted sample population\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## すべてのプロットの y 軸（水平表示）のスケールを同一にする \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## 重み付けされた標本人口をプロットする\nweighted_population &lt;- survey_design %&gt;% \n  ## make sure the variables are factors\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %&gt;%\n  age_pyramid(\n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## グラフタイトルを表示（設定しないと、他の 3 つのプロットすべてにラベル表示が繰り返される）\n  labs(title = \"Weighted sample population\", \n       y = \"\", \n       x = \"\")  + \n  ## すべてのプロットの y 軸（水平表示）のスケールを同一にする \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## 3 つのプロットを組み合わせる  ----------------------------------------------------\n## 隣接する 3 つのプロットを + で結合する\nsource_population + sample_population + weighted_population + \n  ## 凡例を 1 つだけ表示し、テーマを定義する \n  ## テーマを plot_layout() と組み合わせるための & の使用法に注意する\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\",                    # move legend to bottom\n        legend.title = element_blank(),                # remove title\n        text = element_text(size = 18),                # change text size\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # turn x-axis text\n       )\n\n\n\n\n\n\n\n\n\n\n26.7.3 沖積図・サンキーダイアグラム\n個人個人の観測開始とアウトカムを視覚化することは、概要を把握するのに非常に役立ちます。移動人口比率を考慮する非常に分かりやすいグラフ描画方法があります。また、コホートや、個人の状態に遷移があるその他の状況などを描画する数多くのグラフがあります。これらのグラフには、沖積図、サンキー、パラレルセットなど、いくつかの異なる表現があり、詳細はハンドブックのフローチャート・サンキー図・タイムラインの章に記載されています。\n\n## 標本調査データの要約\nflow_table &lt;- survey_data %&gt;%\n  count(startcause, endcause, sex) %&gt;%  # 観察期間開始理由（startcause）、観察期間終了理由（endcause）、性別（sex）変数（列）のカウントを取得する\n  gather_set_data(x = c(\"startcause\", \"endcause\"))     # プロットのために startcause、endcause の形式を縦長から横長に変更する\n\n\n## データセットをプロットする\n  ## x 軸は観察期間開始理由（startcause）と観察期間終了理由（endcause）\n  ## gather_set_data では、可能な組み合わせごとに ID を生成する\n  ## y で分割すると、可能性のある開始と終了の組み合わせを取得できる\n  ## 値を n とすると、数となる（比率に変更することも可能）\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## 性別での色分け \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +\n  ## ラベルボックスをグレーにする\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") +\n  ## 文字の色や角度の変更する（調整が必要）\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) +\n  ## 軸ラベルを削除する\n  theme_void()+\n  # 凡例を図の下に移動\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#重み付けされた人口比率",
    "href": "new_pages/survey_analysis.jp.html#重み付けされた人口比率",
    "title": "26  標本調査データ分析",
    "section": "26.8 重み付けされた人口比率",
    "text": "26.8 重み付けされた人口比率\nこのセクションでは、重み付けされた人口数と人口比率の表を、関連する信頼区間とデザイン効果（標本の分散の、同じ要素数の単純無作為標本の分散に対する比）とともに作成する方法を詳しく説明します。survey パッケージ、srvyr パッケージ、sitrep パッケージ、gtsummary パッケージの関数を使った 4 つの異なる方法があります。標準的な疫学スタイルの表を作成するための最小限のコーディングには、srvyr パッケージのラッパーである sitrep 関数をお勧めしますが、これはまだ CRAN に掲載されておらず、将来変更される可能性があることに注意してください。それ以外では、srvyr パッケージが tidyverse のワークフローに最もうまく適合するのに対し、survey パッケージのコードは長期的に最も安定していると思われます。gtsummary パッケージの関数群は多くの可能性を秘めていますが、この記事を書いている時点では実験的で不完全なもののようです。\n\n26.8.1 Survey パッケージ\nsurvey パッケージから svyciprop() 関数を使用して、重み付けされた人口比率とそれに伴う 95% 信頼区間を得ることができます。適切なデザイン効果は、svyprop() ではなく、svymean() を使用して抽出できます。svyprop()は、0 から 1 の間の値（または TRUE/FALSE）しか受け付けませんので、カテゴリー変数は使えないことに注意する必要があります。\n注釈： survey パッケージ由来の関数は、srvyr パッケージデザイン・オブジェクトも受け入れますが、ここでは一貫性を保つために survey パッケージデザイン・オブジェクトを使用しています。\n\n## 重み付けされた死亡数を生成する\nsvytable(~died, base_survey_design)\n\ndied\n     FALSE       TRUE \n1406244.43   76213.01 \n\n## 重み付けされた人口比率を生成する\nsvyciprop(~died, base_survey_design, na.rm = T)\n\n              2.5% 97.5%\ndied 0.0514 0.0208  0.12\n\n## デザイン効果を得る\nsvymean(~died, base_survey_design, na.rm = T, deff = T) %&gt;% \n  deff()\n\ndiedFALSE  diedTRUE \n 3.755508  3.755508 \n\n\n上記のような survey パッケージの関数を組み合わせて、以下のように独自に定義した svy_prop という関数を作成できます。この関数と purrr パッケージの map() を使って、複数の変数を反復処理し、表を作成できます。purrr パッケージの詳細については、ハンドブックのループと反復処理・リストの操作の章を参照してください。\n\n# 重み付けされた死亡数、人口比率、信頼区間、デザイン効果を計算する関数を定義する\n# x は引用符で囲まれた変数\n# design は survey パッケージのデザインオブジェクト\n\nsvy_prop &lt;- function(design, x) {\n  \n  ## 興味のある変数を計算式に入れる \n  form &lt;- as.formula(paste0( \"~\" , x))\n  ## svytable からカウントの TRUE 列だけを残す\n  weighted_counts &lt;- svytable(form, design)[[2]]\n  ## 割合を計算する（100 倍にして ％ を算出）\n  weighted_props &lt;- svyciprop(form, design, na.rm = TRUE) * 100\n  ## 信頼区間を抽出し、乗算してパーセンテージを求める\n  weighted_confint &lt;- confint(weighted_props) * 100\n  ## svymean を使ってデザイン効果を計算し、TRUE の列だけを残す\n  design_eff &lt;- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## 1 つのデータフレームにまとめる\n  full_table &lt;- cbind(\n    \"Variable\"        = x,\n    \"Count\"           = weighted_counts,\n    \"Proportion\"      = weighted_props,\n    weighted_confint, \n    \"Design effect\"   = design_eff\n    )\n  \n  ## テーブルをデータフレームとして返す\n  full_table &lt;- data.frame(full_table, \n             ## remove the variable names from rows (is a separate column now)\n             row.names = NULL)\n  \n  ## 数値を数字型に戻す\n  full_table[ , 2:6] &lt;- as.numeric(full_table[, 2:6])\n  \n  ## データフレームを返す\n  full_table\n}\n\n## 複数の変数を反復してテーブルを作成する \npurrr::map(\n  ## 関心のある変数を定義する\n  c(\"left\", \"died\", \"arrived\"), \n  ## 使用する関数とその関数の引数（design）を指定する\n  svy_prop, design = base_survey_design) %&gt;% \n  ## リストを単一のデータフレームにまとめる\n  bind_rows() %&gt;% \n  ## 四捨五入する\n  mutate(across(where(is.numeric), round, digits = 1))\n\n  Variable    Count Proportion X2.5. X97.5. Design.effect\n1     left 701199.1       47.3  39.2   55.5           2.4\n2     died  76213.0        5.1   2.1   12.1           3.8\n3  arrived 761799.0       51.4  40.9   61.7           3.9\n\n\n\n\n26.8.2 Srvyr パッケージ\nsrvyr パッケージでは、dplyr パッケージの構文を使って表を作成できます。survey_mean() が使用され、割合引数が指定されていること、また、デザイン効果の計算にも同じ関数が使用されていることに注意してください。これは、srvyr パッケージが、前述のセクションで使われている survey パッケージ関数群の svyciprop() と svymean() の両方を内包しているからです。\n注釈： srvyr パッケージを使ってカテゴリカル変数から人口比率を求めることはできないようです。もしこの操作が必要であれば、sitrep パッケージを使用する以降のセクションをチェックしてください。 \n\n## srvyr パッケージのデザイン・オブジェクトの使用\nsurvey_design %&gt;% \n  summarise(\n    ## 重み付けされた死亡数を生成する\n    counts = survey_total(died), \n    ## 重み付けされた人口比率と信頼区間の生成する \n    ## 100 倍にしてパーセンテージを算出する\n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## デザイン効果を生成する\n    deff = survey_mean(died, deff = TRUE)) %&gt;% \n  ## 興味のある行だけを残す\n  ## (標準誤差をドロップして、人口比率の計算を繰り返す)\n  select(counts, props, props_low, props_upp, deff_deff)\n\n# A tibble: 1 × 5\n  counts props props_low props_upp deff_deff\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 76213.  5.14      2.08      12.1      3.76\n\n\nここでも purrr パッケージを使って、複数の変数を反復処理する関数を書くことができます。purrr の詳細については、ハンドブックのループと反復処理・リストの操作の章を参照してください。\n\n# 重み付けされた死亡数、人口比率、信頼区間、デザイン効果を計算する関数の定義する\n# design は survey パッケージのデザインオブジェクト\n# x は引用符で囲まれた変数\n\n\nsrvyr_prop &lt;- function(design, x) {\n  \n  summarise(\n    ## survey パッケージのデザインオブジェクトを使用する\n    design, \n    ## 重み付けされた死亡数を生成する \n    counts = survey_total(.data[[x]]), \n    ## 重み付けされた人口比率と信頼区間の生成する\n    ## 100 倍にしてパーセンテージを求める \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## デザイン効果を求める\n    deff = survey_mean(.data[[x]], deff = TRUE)) %&gt;% \n  ## 変数名を追加する\n  mutate(variable = x) %&gt;% \n  ## 興味のある行だけを残す\n  ## (標準誤差をドロップして、人口比率の計算を繰り返す)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## 複数の変数を反復してテーブルを作成する \npurrr::map(\n  ## 関心のある変数を定義する\n  c(\"left\", \"died\", \"arrived\"), \n  ## 使用する関数とその関数の引数（design）を指定する\n  ~srvyr_prop(.x, design = survey_design)) %&gt;% \n  ## リストを単一のデータフレームにまとめる\n  bind_rows()\n\n# A tibble: 3 × 6\n  variable  counts props props_low props_upp deff_deff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 left     701199. 47.3      39.2       55.5      2.38\n2 died      76213.  5.14      2.08      12.1      3.76\n3 arrived  761799. 51.4      40.9       61.7      3.93\n\n\n\n\n26.8.3 Sitrep パッケージ\nsitrep パッケージの tab_survey() は、srvyr パッケージのラッパーであり、最小限のコーディングで重み付けされた表を作成できます。また、カテゴリカル変数の加重割合を計算することもできます。\n\n## survey_design オブジェクトを使用する\nsurvey_design %&gt;% \n  ## 興味のある変数の名前を引用符をつけずに渡す\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE,   # デザイン効果を求める\n             pretty = TRUE  # 人口比率と95%信頼区間を統合する\n             )\n\nWarning: removing 257 missing value(s) from `education_level`\n\n\n# A tibble: 9 × 5\n  variable        value            n  deff ci               \n  &lt;chr&gt;           &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            \n1 arrived         TRUE       761799.  3.93 51.4% (40.9-61.7)\n2 arrived         FALSE      720658.  3.93 48.6% (38.3-59.1)\n3 left            TRUE       701199.  2.38 47.3% (39.2-55.5)\n4 left            FALSE      781258.  2.38 52.7% (44.5-60.8)\n5 died            TRUE        76213.  3.76 5.1% (2.1-12.1)  \n6 died            FALSE     1406244.  3.76 94.9% (87.9-97.9)\n7 education_level higher     171644.  4.70 42.4% (26.9-59.7)\n8 education_level primary    102609.  2.37 25.4% (16.2-37.3)\n9 education_level secondary  130201.  6.68 32.2% (16.5-53.3)\n\n\n\n\n26.8.4 Gtsummary パッケージ\ngtsummary パッケージには、信頼区間やデザイン効果を追加するための組み込み関数がまだないようです。ここでは、信頼区間を追加するための関数を定義し、tbl_svysummary() を使って作成した gtsummary パッケージのテーブルに信頼区間を追加する方法を示します。\n\nconfidence_intervals &lt;- function(data, variable, by, ...) {\n  \n  ## 信頼区間を抽出し、乗算してパーセンテージを求める\n  props &lt;- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## 信頼区間を抽出する\n  as.numeric(confint(props) * 100) %&gt;% ## 数値化してパーセンテージを乗算する\n    round(., digits = 1) %&gt;%           ## 1 桁に四捨五入する\n    c(.) %&gt;%                           ## 行列から数値を抽出する\n    paste0(., collapse = \"-\")          ## 1 つの文字列にまとめる\n}\n\n## survey パッケージのデザインオブジェクトを使用する\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died),   ## 含めたい変数を定義する\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %&gt;% ## 興味のある統計量を定義する\n  add_n() %&gt;%  ## 重み付けされた総数を加える\n  add_stat(fns = everything() ~ confidence_intervals) %&gt;% ## 信頼区間を加える\n  ## カラムのヘッダーを変更する\n  modify_header(\n    list(\n      n ~ \"**Weighted total (N)**\",\n      stat_0 ~ \"**Weighted Count**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )\n\n\n\n\n\n\n\n\nCharacteristic\nWeighted total (N)\nWeighted Count1\n95%CI\n\n\n\n\narrived\n1,482,457\n761,799 (51%)\n40.9-61.7\n\n\nleft\n1,482,457\n701,199 (47%)\n39.2-55.5\n\n\ndied\n1,482,457\n76,213 (5.1%)\n2.1-12.1\n\n\n\n1 n (%)",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#重み付けされた比率",
    "href": "new_pages/survey_analysis.jp.html#重み付けされた比率",
    "title": "26  標本調査データ分析",
    "section": "26.9 重み付けされた比率",
    "text": "26.9 重み付けされた比率\n重み付けされた比率（例えば死亡率のような）については同様に、survey パッケージや srvyr パッケージを使うことができます。さらに、複数の変数を反復処理する関数（前のセクションのものと同様）を書くこともできます。上記のように gtsummary パッケージのための関数を作れますが、現在のところ相当の処理を行う関数はパッケージにありません。\n\n26.9.1 Survey パッケージ\n\nratio &lt;- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci &lt;- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)\n\n      obstime    2.5 %   97.5 %\ndied 5.981922 1.194294 10.76955\n\n\n\n\n26.9.2 Srvyr パッケージ\n\nsurvey_design %&gt;% \n  ## 観察期間を考慮した死亡率\n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )\n\n# A tibble: 1 × 3\n  mortality mortality_low mortality_upp\n      &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1      5.98         0.349          11.6",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.jp.html#参考資料",
    "href": "new_pages/survey_analysis.jp.html#参考資料",
    "title": "26  標本調査データ分析",
    "section": "26.10 参考資料",
    "text": "26.10 参考資料\nUCLA 統計ページ\nアンケートデータを無料で分析\nsrvyr パッケージ\ngtsummary パッケージ\nEPIET 調査のケーススタディ",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>標本調査データ分析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html",
    "href": "new_pages/survival_analysis.jp.html",
    "title": "27  生存時間解析",
    "section": "",
    "text": "27.1 概要\n生存時間解析（survival analysis）は、個々人において観測されるイベント時間（コホート研究や集団ベースの研究では追跡期間）と呼ばれる期間の後に発生するイベント（疾病の発生、疾病からの治癒、死亡、治療に反応した後の再発など）を個人または集団について記述する事に着目した方法です。イベント時間を決定するためには、起点 (組入日や診断日などを用いることができます) の時間を定義する必要があります。\nつまり、生存時間解析の推測対象は、起点とイベントの間の時間となります。 近年の医学研究では、例えば治療効果を評価する臨床研究や、多種多様ながんの生存指標を評価する疫学研究などにおいて生存時間解析がよく用いられています。\n通常、その記述結果は生存確率を通じて提示されます。また、生存確率とは、興味のあるイベントが期間 \\(t\\) を経過した時点で発生していない確率です。\n打切り: ある個人が追跡終了時点までに興味のあるイベントを発生せず、その人の正しいイベント時間が不明な場合に打切りが発生します。この章では右側打切りに重点を置いています。打切りの詳細と一般の生存時間解析については、文献を参照してください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html#準備",
    "href": "new_pages/survival_analysis.jp.html#準備",
    "title": "27  生存時間解析",
    "section": "27.2 準備",
    "text": "27.2 準備\n\nパッケージの読み込み\nR において生存時間解析を行うために最もよく用いられるパッケージの1つは survival パッケージです。まず最初に、survival パッケージとこの節で用いる他のパッケージをインストールした後に、これらのパッケージの読込みを行います。\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\n# この章で必要なパッケージのインストールと読込\npacman::p_load(\n     survival,      # 生存時間解析\n     survminer,     # 生存時間解析\n     rio,           # データのインポート\n     here,          # ファイルの相対パス\n     janitor,       # 表の作成\n     SemiCompRisks, # 事例データと準競合リスクデータのための発展的なツール\n     tidyverse,     # データの操作と可視化\n     Epi,           # 疫学の統計解析\n     survival,      # 生存時間解析\n     survminer      # 生存時間解析：発展的な Kaplan-Meier 曲線\n)\n\nこの章では、前のほとんどの章でも用いられているラインリストを用いて生存時間解析を行います。また、正しい生存時間データを得るために、ラインリストにいくつかの変更を加えていきます。\n\n\nデータセットのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストのインポート\nlinelist_case_data &lt;- rio::import(\"linelist_cleaned.rds\")\n\n\n\nデータマネジメントと変換\n簡潔に言うと、生存時間データは以下の3つの特徴を持っているといえます：\n\n従属変数または反応変数は矛盾なく定義されたイベントの発生までの時間で、\n観測値は打切りを受け、データが解析される時点で興味のあるイベントが発生していないことがいくつかの観測単位で認められ、\nイベント発生時間に対する影響を評価またはコントロールしたい予測変数や説明変数があります。\n\nそのため、上記の構造に沿うための変数を作成してから生存時間分析を実行していきます。\n以下のものを定義します：\n\nこの解析に必要な新しいデータフレーム linelist_surv\n興味のあるイベントをここでは「死亡」とします（すると、生存確率は起点の時間からある特定の時間が経過したあとで生存している確率となります）\n追跡時間（futime）を、発症時間からアウトカムの時間までの日数とします\n回復した人か、または最終的なアウトカムが観測されなかった人、つまり「イベント」が観測されなかった人（event=0）を打切りとします。\n\n注意： 実際のコホート研究では、起点と追跡終了の時間の情報は観測された個々人で既知であるため、発症日やアウトカムの日付が不明な観測値は削除します。また、発症日がアウトカムの日付よりも遅い場合は誤りであると考えられるため、これも削除します。\nヒント： 日付データに対して超過（&gt;）または未満（&lt;）のフィルタリングを行うと欠測値を持つ行も一緒に削除できるため、日付の誤りに対するフィルタリングによって欠測したデータを一緒に削除することができます。\n次に、case_when() を用いて3つだけ水準を持つ age_cat_small 列を作成します。\n\n# linelist_case_data から新しいデータ linelist_surv を作成\n\nlinelist_surv &lt;- linelist_case_data %&gt;% \n     \n     dplyr::filter(\n          # 誤りまたは発症日かアウトカムの日付に欠測がある観測値を削除\n          date_outcome &gt; date_onset) %&gt;% \n     \n     dplyr::mutate(\n          # 死亡した人を1とし右側打切りの人を0としたイベント変数を作成\n          event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n          \n          # 追跡時間（日）の変数を作成\n          futime = as.double(date_outcome - date_onset), \n          \n          # 3つだけ水準を持つ新しい年齢カテゴリ変数を作成\n          age_cat_small = dplyr::case_when( \n               age_years &lt; 5  ~ \"0-4\",\n               age_years &gt;= 5 & age_years &lt; 20 ~ \"5-19\",\n               age_years &gt;= 20   ~ \"20+\"),\n          \n          # 上のステップでは age_cat_small が character 型で作成されるため\n          # factor 型に変換し、水準を指定します\n          # 値が NA のものは NA のままになり、例えば水準 \"unkown\" などには置換されません\n          # そのため、次の解析ではこれらを削除する必要があるので注意してください\n          age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n     )\n\nヒント： 作成された変数 futime と event および outcome のクロス集計を行うことで、新しい列を検証することができます。この検証の他にも、生存時間解析の結果を解釈する時には、この集計に加えて追跡期間中央値を示すことは良い習慣です。\n\nsummary(linelist_surv$futime)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    6.00   10.00   11.98   16.00   64.00 \n\n# 作成された新しいイベント変数とアウトカム変数のクロス集計\n# 意図した通りにコードが動いているかどうかを確認する\nlinelist_surv %&gt;% \n     tabyl(outcome, event)\n\n outcome    0    1\n   Death    0 1952\n Recover 1547    0\n    &lt;NA&gt; 1040    0\n\n\nここで、正しく分類できているかどうかを確認するために、新しい変数 age_cat_small と古い変数 age_cat のクロス集計を行います\n\nlinelist_surv %&gt;% \n     tabyl(age_cat_small, age_cat)\n\n age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n           0-4 834   0     0     0     0     0     0   0   0\n          5-19   0 852   717   575     0     0     0   0   0\n           20+   0   0     0     0   862   554    69   5   0\n          &lt;NA&gt;   0   0     0     0     0     0     0   0  71\n\n\n次に、linelist_surv データのいくつかの変数（新しく作成された変数も含む）について、最初の10人分の観測値を確認します。\n\nlinelist_surv %&gt;% \n     select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %&gt;% \n     head(10)\n\n   case_id age_cat_small date_onset date_outcome outcome event futime\n1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\n\n\n新しい年齢分類の性別ごとのより詳細な分布を得るために、列 age_cat_small と gender のクロス集計も行うことができます。ここでは、記述統計表の作り方の章で説明した janitor パッケージの tabyl() と adorn 関数を使用します。\n\n\nlinelist_surv %&gt;% \n     tabyl(gender, age_cat_small, show_na = F) %&gt;% \n     adorn_totals(where = \"both\") %&gt;% \n     adorn_percentages() %&gt;% \n     adorn_pct_formatting() %&gt;% \n     adorn_ns(position = \"front\")\n\n gender         0-4          5-19           20+          Total\n      f 482 (22.4%) 1,184 (54.9%)   490 (22.7%) 2,156 (100.0%)\n      m 325 (15.0%)   880 (40.6%)   960 (44.3%) 2,165 (100.0%)\n  Total 807 (18.7%) 2,064 (47.8%) 1,450 (33.6%) 4,321 (100.0%)",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html#生存時間解析の基本",
    "href": "new_pages/survival_analysis.jp.html#生存時間解析の基本",
    "title": "27  生存時間解析",
    "section": "27.3 生存時間解析の基本",
    "text": "27.3 生存時間解析の基本\n\nSurv 型オブジェクトの作成\nはじめに、survival パッケージの Surv() を用いて、追跡時間とイベントの変数から生存時間解析のオブジェクトを作成します。\nこのステップを実行すると、時間の情報と興味のあるイベント（死亡）が観測されたかどうかの情報が集約された Surv 型のオブジェクトが作成されます。このオブジェクトは最終的に後で出てくるモデル式の右辺で用いられます（詳細についてはマニュアル。\n\n# 右側打切りデータに Surv() 構文を使用\nsurvobj &lt;- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\n\n\n\n\n\n\nここで、確認のため linelist_surv データのいくつかの重要な変数について最初の10行を表示します。\n\nlinelist_surv %&gt;% \n     select(case_id, date_onset, date_outcome, futime, outcome, event) %&gt;% \n     head(10)\n\n   case_id date_onset date_outcome futime outcome event\n1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n3   893f25 2014-05-21   2014-05-29      8 Recover     0\n4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n6   369449 2014-06-02   2014-06-07      5   Death     1\n7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n8   1389ca 2014-06-05   2014-06-09      4   Death     1\n9   2978ac 2014-06-06   2014-06-15      9   Death     1\n10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n\n\nさらに、survobj の最初の10要素を表示します。基本的には追跡時間のベクトルが表示され、右側打切りの観測値の場合は “+” も表示されます。各値が上の出力と下の出力でどのようになっているか確認してください。\n\n# このベクトルの最初の10要素を表示し、どのようになっているかを確認\nhead(survobj, 10)\n\n [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+\n\n\n\n\n最初の解析の実行\nまず、survfit() を用いて survfit オブジェクト を作成し、解析を始めます。survfit() は、全体（周辺）生存曲線の Kaplan Meier（KM）推定値を得るための標準の解析を行います。KM 推定値はイベントの観測時点でジャンプする階段関数となっています。最終的な survfit オブジェクト は1つかまたはそれ以上の生存曲線を含んでおり、モデルを指定する formula 構文の反応変数として Surv オブジェクトを用いることで作成されます。\n注釈： Kaplan-Meier 推定量は生存関数のノンパラメトリック最尤推定量（maximum likelihood estimate; MLE）です（詳細についてはその他の情報を確認してください）。\nこの survfit オブジェクト は生命表（life table）と呼ばれるものに要約されます。追跡時間（time）のイベントが発生した各時間区間について（昇順で）：\n\nイベント発生のリスクに晒された（イベントも打切りも経験していない人の）人数（n.risk）\nイベントが発生した人数（n.event）\n上記から求めたイベントを発生していない確率（死亡していない確率、または特定の時間まで生存する確率）\n最後に、その確率の標準誤差と信頼区間が求められ表示されます\n\n以下では、上で作成した Surv 型のオブジェクト “survobj” を反応変数とした formula を用いて KM 推定値を求めます。“~ 1” は全体の生存に対するモデルを実行することを意味します。\n\n# Surv 型オブジェクト \"survobj\" を反応変数としたモデル式を用いて KM 推定値を求めます\n# \"~ 1\" は全体の生存に対するモデルを実行することを意味します\nlinelistsurv_fit &lt;-  survival::survfit(survobj ~ 1)\n\n# 詳細をみるための要約を表示\nsummary(linelistsurv_fit)\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1   4539      30    0.993 0.00120        0.991        0.996\n    2   4500      69    0.978 0.00217        0.974        0.982\n    3   4394     149    0.945 0.00340        0.938        0.952\n    4   4176     194    0.901 0.00447        0.892        0.910\n    5   3899     214    0.852 0.00535        0.841        0.862\n    6   3592     210    0.802 0.00604        0.790        0.814\n    7   3223     179    0.757 0.00656        0.745        0.770\n    8   2899     167    0.714 0.00700        0.700        0.728\n    9   2593     145    0.674 0.00735        0.660        0.688\n   10   2311     109    0.642 0.00761        0.627        0.657\n   11   2081     119    0.605 0.00788        0.590        0.621\n   12   1843      89    0.576 0.00809        0.560        0.592\n   13   1608      55    0.556 0.00823        0.540        0.573\n   14   1448      43    0.540 0.00837        0.524        0.556\n   15   1296      31    0.527 0.00848        0.511        0.544\n   16   1152      48    0.505 0.00870        0.488        0.522\n   17   1002      29    0.490 0.00886        0.473        0.508\n   18    898      21    0.479 0.00900        0.462        0.497\n   19    798       7    0.475 0.00906        0.457        0.493\n   20    705       4    0.472 0.00911        0.454        0.490\n   21    626      13    0.462 0.00932        0.444        0.481\n   22    546       8    0.455 0.00948        0.437        0.474\n   23    481       5    0.451 0.00962        0.432        0.470\n   24    436       4    0.447 0.00975        0.428        0.466\n   25    378       4    0.442 0.00993        0.423        0.462\n   26    336       3    0.438 0.01010        0.419        0.458\n   27    297       1    0.436 0.01017        0.417        0.457\n   29    235       1    0.435 0.01030        0.415        0.455\n   38     73       1    0.429 0.01175        0.406        0.452\n\n\nsummary() を用いる際には times オプションを追加することができ、求めたい特定の時点における生存確率などの情報を確認することができます。\n\n# 特定の時点における要約を表示\nsummary(linelistsurv_fit, times = c(5, 10, 20, 30, 60))\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    5   3899     656    0.852 0.00535        0.841        0.862\n   10   2311     810    0.642 0.00761        0.627        0.657\n   20    705     446    0.472 0.00911        0.454        0.490\n   30    210      39    0.435 0.01030        0.415        0.455\n   60      2       1    0.429 0.01175        0.406        0.452\n\n\nまた、print() を用いることもできます。引数に print.rmean = TRUE を指定すると、平均生存時間と標準誤差を表示することができます。\n注釈： 制限付き平均生存時間（restricted mean survival time; RMST）は生存の要約指標の 1 つであり、がんの生存時間解析で使われるようになってきています。RMST は、しばしば制限時間 \\(T\\) までに観測された人に対して求めた生存曲線の曲線下面積として定義されます（詳細についてはその他の情報の節を確認してください）。\n\n# linelistsurv_fit オブジェクトを平均生存時間とその標準誤差とともに表示します\nprint(linelistsurv_fit, print.rmean = TRUE)\n\nCall: survfit(formula = survobj ~ 1)\n\n        n events rmean* se(rmean) median 0.95LCL 0.95UCL\n[1,] 4539   1952   33.1     0.539     17      16      18\n    * restricted mean with upper limit =  64 \n\n\nヒント： Surv オブジェクト を survfit() の中に直接書くこともでき、コードを1行節約することができます。その場合、次のように書きます：linelistsurv_quick &lt;- survfit(Surv(futime, event) ~ 1, data = linelist_surv)。\n\n\n累積ハザード\nsummary() 以外にも、str() を用いて survfit() オブジェクトの構造についての詳細を確認できます。survfit() オブジェクトは16個の要素を持つリストになっています。\nこれらの要素の中には重要な要素（cumhaz という実数型のベクトル）があります。これは累積ハザードの図示に用いることができます。ハザードは瞬間イベント発生率です（文献を確認してください）。\n\nstr(linelistsurv_fit)\n\nList of 16\n $ n        : int 4539\n $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n $ type     : chr \"right\"\n $ logse    : logi TRUE\n $ conf.int : num 0.95\n $ conf.type: chr \"log\"\n $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n $ call     : language survfit(formula = survobj ~ 1)\n - attr(*, \"class\")= chr \"survfit\"\n\n\n\n\n\nKaplan–Meier 曲線の作成\nKM 推定値が計算されていれば、「Kaplan-Meier 曲線」を描画できる基本の plot() を用いて、時間を通じた生存確率を視覚化できます。言い換えると、以下の曲線は集団全体における生存状況を標準的な図で表したものです。\nこの曲線から、追跡時間の最小値と最大値を容易に確認できます。\n簡単な解釈を説明すると、時点0においては全ての人が生存しており生存確率は100%です。この確率は死亡が発生するにつれて時間とともに減少していきます。追跡時間が60日が経過した後の生存割合は約40%です。\n\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",     # x 軸のラベル\n     ylab = \"Survival Probability\",  # y 軸のラベル\n     main = \"Overall survival curve\" # 図のタイトル\n)\n\n\n\n\n\n\n\n\nKM 推定値の信頼区間もデフォルトで描画されますが、plot() コマンドの conf.int = FALSE オプションを追加することで信頼区間を非表示にできます。\n興味のあるイベントは「死亡」であるため、1から生存割合を引いたものの曲線を描くと累積発生率の図が得られます。これは lines() で描くことができ、元々あるプロットに情報が追加されます。\n\n# オリジナルのプロット\nplot(\n     linelistsurv_fit,\n     xlab = \"Days of follow-up\",       \n     ylab = \"Survival Probability\",       \n     mark.time = TRUE,              # 曲線上にイベントのマークを追加：\"+\" を全てのイベント時点に表示\n     conf.int = FALSE,              # 信頼区間を非表示\n     main = \"Overall survival curve and cumulative mortality\"\n)\n\n# 元のプロットに追加の曲線を描画\nlines(\n     linelistsurv_fit,\n     lty = 3,             # 分かりやすくするために異なる線種を使用\n     fun = \"event\",       # 生存ではなく累積イベントを描画\n     mark.time = FALSE,\n     conf.int = FALSE\n)\n\n# プロットに凡例を追加\nlegend(\n     \"topright\",                               # 凡例の位置\n     legend = c(\"Survival\", \"Cum. Mortality\"), # 凡例のテキスト\n     lty = c(1, 3),                            # 凡例で用いる線種\n     cex = .85,                                # 凡例テキストのサイズを定義するパラメータ\n     bty = \"n\"                                 # 凡例にボックスを非表示\n)",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html#生存曲線の比較",
    "href": "new_pages/survival_analysis.jp.html#生存曲線の比較",
    "title": "27  生存時間解析",
    "section": "27.4 生存曲線の比較",
    "text": "27.4 生存曲線の比較\n観測された参加者または患者における異なる群の生存を比較するためには、最初にそれぞれの生存曲線を確認し、独立した群間の差を評価する仮説検定を行う必要があるかもしれません。この比較は、性別、年齢、治療法、合併症などに基づいたグループに関するものになるかもしれません。\n\nログランク検定\nログランク検定（log-rank test）は、2つまたはそれ以上の独立した群における生存状況を比較する主要な仮説検定で、生存曲線が同一（重なっている）かそうでないかの仮説検定と考えることができます（帰無仮説として群間の生存確率に差がないことを仮定しています）。survival パッケージの survdiff() は、オプションで rho = 0 を指定した場合（デフォルトの設定がこれになっています）にログランク検定を実行できます。ログランク統計量はカイ二乗検定統計量と同様に漸近的にカイ二乗分布に従うため、この仮説検定の結果としてカイ二乗統計量と p 値が出力されます。\nまずは性別ごとの生存曲線を比較してみましょう。そのため、最初に視覚化を行ってみます（2つの生存曲線が重なるかどうかを確認します）。新しい survfit オブジェクト は少し異なる formula を用いて作成されます。そして、survdiff オブジェクト が作成されます。\nモデル式を記述している formula の右辺に ~ gender を指定することで、全体の生存ではなく性別ごとのプロットを作成できます。\n\n# 性別に基づいて新しい survfit オブジェクトを作成\nlinelistsurv_fit_sex &lt;-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n\n新しいオブジェクトを作成すると、性別ごとの生存曲線を作成できます。色や凡例を決める前に、性別の列の水準の順番を見てみましょう。\n\n# 色を設定\ncol_sex &lt;- c(\"lightgreen\", \"darkgreen\")\n\n# プロットを作成\nplot(\n     linelistsurv_fit_sex,\n     col = col_sex,\n     xlab = \"Days of follow-up\",\n     ylab = \"Survival Probability\")\n\n# 凡例の追加\nlegend(\n     \"topright\",\n     legend = c(\"Female\",\"Male\"),\n     col = col_sex,\n     lty = 1,\n     cex = .9,\n     bty = \"n\")\n\n\n\n\n\n\n\n\nそして、survdiff() を用いて生存曲線の群間差の仮説検定を行うことができます。\n\n# 生存曲線の差の仮説検定を実行\nsurvival::survdiff(\n     Surv(futime, event) ~ gender, \n     data = linelist_surv\n)\n\nCall:\nsurvival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n\nn=4321, 218 observations deleted due to missingness.\n\n            N Observed Expected (O-E)^2/E (O-E)^2/V\ngender=f 2156      924      909     0.255     0.524\ngender=m 2165      929      944     0.245     0.524\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\n女性と男性の生存曲線が重なっているのが分かり、ログランク検定の結果も生存状況の性差を示唆していませんでした。\n他の R パッケージでも生存曲線の群間差の図示と群間差の仮説検定を同時に行うことができます。survminer パッケージの ggsurvplot() を用いると、各群の生存曲線とリスク集合の表とログランク検定の p 値を表示することができます。\n注意： ggsurvplot() では survfit オブジェクト に加えて そのオブジェクトを作成するのに用いたデータを再度指定する必要があります。エラーメッセージが表示されてしまうので、忘れずに指定してください。\n\nsurvminer::ggsurvplot(\n     linelistsurv_fit_sex, \n     data = linelist_surv,          # linelistsurv_fit_sex を作成するのに用いたデータを再度指定\n     conf.int = FALSE,              # KM 推定値の信頼区間を非表示\n     surv.scale = \"percent\",        # y 軸の確率を % で表示\n     break.time.by = 10,            # x 軸の時間を 10 日刻みで表示\n     xlab = \"Follow-up days\",\n     ylab = \"Survival Probability\",\n     pval = T,                      # ログランク検定の p 値を表示\n     pval.coord = c(40, .91),       # 座標を指定して p 値を表示\n     risk.table = T,                # 下にリスク集合の表を表示\n     legend.title = \"Gender\",       # 凡例のタイトル\n     legend.labs = c(\"Female\", \"Male\"),\n     font.legend = 10, \n     palette = \"Dark2\",             # カラーパレットの指定\n     surv.median.line = \"hv\",       # 生存時間中央値の位置に縦と横の補助線を描画\n     ggtheme = theme_light()        # シンプルなテーマを使用\n)\n\n\n\n\n\n\n\n\nまた、感染源（汚染源）による生存の違いを検証したい場合があるかもしれません。\nこのケースについては、alpha = 0.05 でのログランク検定により十分な生存確率の差があると考えることにします。葬儀により感染した患者の生存確率は他の場所で感染した患者の生存確率よりも高く、生存に対するベネフィットがあるのかもしれません。\n\nlinelistsurv_fit_source &lt;-  survfit(\n     Surv(futime, event) ~ source,\n     data = linelist_surv\n)\n\n# プロット\nggsurvplot( \n     linelistsurv_fit_source,\n     data = linelist_surv,\n     size = 1, linetype = \"strata\",   # 線種\n     conf.int = T,\n     surv.scale = \"percent\",  \n     break.time.by = 10, \n     xlab = \"Follow-up days\",\n     ylab= \"Survival Probability\",\n     pval = T,\n     pval.coord = c(40, .91),\n     risk.table = T,\n     legend.title = \"Source of \\ninfection\",\n     legend.labs = c(\"Funeral\", \"Other\"),\n     font.legend = 10,\n     palette = c(\"#E7B800\", \"#3E606F\"),\n     surv.median.line = \"hv\", \n     ggtheme = theme_light()\n)\n\nWarning in geom_segment(aes(x = 0, y = max(y2), xend = max(x1), yend = max(y2)), : All aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html#cox-回帰分析",
    "href": "new_pages/survival_analysis.jp.html#cox-回帰分析",
    "title": "27  生存時間解析",
    "section": "27.5 Cox 回帰分析",
    "text": "27.5 Cox 回帰分析\nCox の比例ハザードモデル（Cox proportional hazards model / Cox regression model）は生存時間解析の最も一般的な回帰モデルの一つです。Cox 回帰モデルは、比例ハザード性の仮定などの適切に用いるために検証を必要とする 重要な仮定 をおくため、他のモデルを用いることもできます。詳細は文献を確認してください。\nCox の比例ハザードモデルにおける効果の尺度は ハザード率（hazard rate）で、これは特定の時点までイベントが発生しなかった人のイベント発生リスク（この章の例では、死亡のリスク）になっています。通常、独立な群におけるハザードの比較に興味があるためハザード比（hazard ratio; HR）を用います。ハザード比は多重ロジスティック回帰分析におけるオッズ比に相当する指標です。survival パッケージの coxph() は、Cox 回帰モデルの当てはめに用いられます。survival パッケージの cox.zph() は、当てはめたモデルについて比例ハザード性の仮定に対する仮説検定に用いることができます。\n注釈： 確率は0から1の間の値をとります。一方で、ハザードは単位時間当たりのイベント発生数の期待値を表しています。\n\nある説明変数に対するハザード比が1に近ければ、その説明変数は生存に影響を与えていません\nハザード比が1より小さければ、その説明変数は保護的です（すなわち、生存の改善に関連があります）\nハザード比が1より大きければ、その説明変数はリスクの上昇（生存の悪化）に関連があります。\n\n\nCox 回帰モデルの当てはめ\nまずは、年齢と性別が生存に与える影響を評価するために、モデルの当てはめを行います。モデルの当てはめ結果を表示するだけで、以下の情報が得られます：\n\n回帰係数の推定値 coef、この値は説明変数とアウトカムの間の関連を定量化したものです\nこれらの値を解釈のために指数変換した exp(coef)、これはハザード比になっています\nこれらの値の標準誤差 se(coef)\nz スコア：回帰係数の推定値が 0 から何標準誤差離れているか\np 値：回帰係数が 0 かどうかの仮説検定における p 値。\n\nCox 回帰モデルのオブジェクトに summary() を適用すると、ハザード比の推定値の信頼区間や別の仮説検定の結果などのより詳細な情報が得られます。\n最初の共変量 gender の効果は最初の行に表示されています。ここには genderm（男性）と表示されており、最初の水準（“f”）、つまり女性が性別の参照水準となっていることが分かります。そのため、パラメータは女性に対する男性の結果として解釈します。また、p 値から、性別によるハザードの期待値に対する影響または性別と全死亡率の間に関連があるとは言えないです。\n同様に、年齢群についても差があるとは言えないです。\n\n# Cox 回帰モデルの当てはめ\nlinelistsurv_cox_sexage &lt;-  survival::coxph(\n     Surv(futime, event) ~ gender + age_cat_small, \n     data = linelist_surv\n)\n\n# モデルの当てはめ結果の表示\nlinelistsurv_cox_sexage\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n                      coef exp(coef) se(coef)      z     p\ngenderm           -0.03149   0.96900  0.04767 -0.661 0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n\nLikelihood ratio test=2.8  on 3 df, p=0.4243\nn= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n# モデルの要約\nsummary(linelistsurv_cox_sexage)\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n  n= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n                      coef exp(coef) se(coef)      z Pr(&gt;|z|)\ngenderm           -0.03149   0.96900  0.04767 -0.661    0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ngenderm               0.969     1.0320    0.8826     1.064\nage_cat_small5-19     1.099     0.9103    0.9680     1.247\nage_cat_small20+      1.052     0.9509    0.9176     1.205\n\nConcordance= 0.514  (se = 0.007 )\nLikelihood ratio test= 2.8  on 3 df,   p=0.4\nWald test            = 2.78  on 3 df,   p=0.4\nScore (logrank) test = 2.78  on 3 df,   p=0.4\n\n\nモデルの当てはめを行い結果を見るのは面白いですが、最初に比例ハザード性の仮定が成り立つかどうかを検討しておくと、時間の節約になります。\n\ntest_ph_sexage &lt;- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage\n\n              chisq df    p\ngender        0.454  1 0.50\nage_cat_small 0.838  2 0.66\nGLOBAL        1.399  3 0.71\n\n\n注釈： Cox モデルの当てはめでは2つ目の引数 method を指定でき、タイの取り扱い方法を変更することができます。デフォルトは “efron” で、他にも “breslow” や “exact” が指定できます。\n他のモデルとして感染源や発症から入院までの日数をリスク因子として追加します。今回は、まず比例ハザード性の仮定の評価を先に行ってみます。\nこのモデルには連続値の説明変数（days_onset_hosp）が含まれています。このような場合、パラメータ推定値の解釈は、説明変数が1単位増加したときに増加する対数相対ハザードの期待値、となります。まずは、比例ハザード性の仮定の評価を行います。\n\n# モデルの当てはめ\nlinelistsurv_cox &lt;-  coxph(\n     Surv(futime, event) ~ gender + age_years + source + days_onset_hosp,\n     data = linelist_surv\n)\n\n\n# 比例ハザード性の仮説検定\nlinelistsurv_ph_test &lt;- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test\n\n                   chisq df       p\ngender           0.45062  1    0.50\nage_years        0.00199  1    0.96\nsource           1.79622  1    0.18\ndays_onset_hosp 31.66167  1 1.8e-08\nGLOBAL          34.08502  4 7.2e-07\n\n\nまた、survminer パッケージの ggcoxzph() を用いて、この仮定に対する視覚的な評価を行うことができます。\n\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n\n\n\n\n\n\n\n\nモデルの当てはめ結果から、発症から入院までの日数と全死亡率の間に負の関連があることが示唆されます。ハザードの期待値は、性別などを固定したもとで、発症から入院までの日数が1日遅くなると0.9倍となっていました。もっと直接的に説明すると、発症から入院までの日数が1日伸びると、死亡のリスクが10.7%（coef *100）減少する、となります。\nまた、モデルの結果は感染源と全死亡率の間の正の関連も示していました。これについては、他の感染による患者は葬儀で感染した患者と比べて死亡リスクが高い（1.21倍）という結果でした。\n\n# モデルの要約を表示\nsummary(linelistsurv_cox)\n\nCall:\ncoxph(formula = Surv(futime, event) ~ gender + age_years + source + \n    days_onset_hosp, data = linelist_surv)\n\n  n= 2772, number of events= 1180 \n   (1767 observations deleted due to missingness)\n\n                     coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \ngenderm          0.004710  1.004721  0.060827  0.077   0.9383    \nage_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \nsourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \ndays_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\ngenderm            1.0047     0.9953    0.8918    1.1319\nage_years          0.9978     1.0023    0.9930    1.0025\nsourceother        1.1953     0.8366    1.0133    1.4100\ndays_onset_hosp    0.9012     1.1097    0.8764    0.9267\n\nConcordance= 0.566  (se = 0.009 )\nLikelihood ratio test= 71.31  on 4 df,   p=1e-14\nWald test            = 59.22  on 4 df,   p=4e-12\nScore (logrank) test = 59.54  on 4 df,   p=4e-12\n\n\nこの関係を表にして確認することもできます：\n\nlinelist_case_data %&gt;% \n     tabyl(days_onset_hosp, outcome) %&gt;% \n     adorn_percentages() %&gt;%  \n     adorn_pct_formatting()\n\n days_onset_hosp Death Recover   NA_\n               0 44.3%   31.4% 24.3%\n               1 46.6%   32.2% 21.2%\n               2 43.0%   32.8% 24.2%\n               3 45.0%   32.3% 22.7%\n               4 41.5%   38.3% 20.2%\n               5 40.0%   36.2% 23.8%\n               6 32.2%   48.7% 19.1%\n               7 31.8%   38.6% 29.5%\n               8 29.8%   38.6% 31.6%\n               9 30.3%   51.5% 18.2%\n              10 16.7%   58.3% 25.0%\n              11 36.4%   45.5% 18.2%\n              12 18.8%   62.5% 18.8%\n              13 10.0%   60.0% 30.0%\n              14 10.0%   50.0% 40.0%\n              15 28.6%   42.9% 28.6%\n              16 20.0%   80.0%  0.0%\n              17  0.0%  100.0%  0.0%\n              18  0.0%  100.0%  0.0%\n              22  0.0%  100.0%  0.0%\n              NA 52.7%   31.2% 16.0%\n\n\nこのデータにおいて、なぜこの様な関連が見られたのかについて考え、検討する必要があります。入院まで時間がかかっていても生き延びていた患者はもともと重症度が低かった可能性があるという説明が可能です。また、別の説明も考えられ、シミュレーションによる疑似データセットを使用したため、このパターンが現実を反映していないのかもしれません。\n\n\n\nフォレストプロット\nCox 回帰モデルの結果について、survminer パッケージの ggforest() を用いて、フォレストプロットによる可視化を行うことができます。\n\nggforest(linelistsurv_cox, data = linelist_surv)",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html#生存時間モデルにおける時間依存性共変量",
    "href": "new_pages/survival_analysis.jp.html#生存時間モデルにおける時間依存性共変量",
    "title": "27  生存時間解析",
    "section": "27.6 生存時間モデルにおける時間依存性共変量",
    "text": "27.6 生存時間モデルにおける時間依存性共変量\n以下の節の一部は、Dr. Emily Zabor の許可を得て Survival analysis in R の素晴らしい解説から引用しています。\n前の節では、Cox 回帰モデルを用いて興味のある共変量と生存アウトカムの間の関連を評価する方法を説明しました。しかし、これらの解析では、共変量がベースライン時点、つまりイベントの追跡が始まる前に測定されていること想定していました。\n興味のある共変量が追跡を開始した後で測定されているとどうなるでしょうか？もしくは、時間で変化する共変量がある場合はどうなるでしょう？\n例えば、臨床検査値を繰り返し測定した臨床データを扱っている場合、その値は時間の経過とともに変化する可能性があります。これは 時間依存性共変量（Time Dependent Covariate） の一例です。時間依存性共変量を扱うためには特別な準備が必要です。しかし、幸運なことに Cox 回帰モデルはとても柔軟であり、また、survival パッケージと一連のツールを用いてこのタイプのデータをモデル化することができます。\n\n時間依存性共変量の設定\nR において時間依存性共変量の解析を行うためには特別なデータセットを準備する必要があります。興味があれば survival パッケージの著者による、より詳細な説明（Using Time Dependent Covariates and Time Dependent Coefficients in the Cox Model を確認してください。\nここでは、SemiCompRisks パッケージの BMT という新しいデータセットを使用します。このデータは137名の骨髄移植患者のデータです。この節で扱う変数は以下の通りです：\n\nT1 - 死亡時間または最終追跡時間 (日)\ndelta1 - 死亡の指示変数；1-死亡、0-生存\n\nTA - 急性移植片対宿主病発生までの時間\ndeltaA - 急性移植片対宿主病の指示変数；\n1 - 急性移植片対宿主病の発生あり\n0 - 急性移植片対宿主病の発生なし\n\nbase の R コマンド data() を用いて、SemiCompRisks パッケージからこのデータセットを読み込みます。このコマンドは R パッケージに含まれているデータを読み込むことができます。以下を実行すると、BMT というデータフレームが R 上に読み込まれます。\n\ndata(BMT, package = \"SemiCompRisks\")\n\n\n患者固有の ID の追加\nBMT データには患者固有の ID がありませんが、時間依存性共変量の解析には固有の ID 変数が必要です。そのため、tidyverse の tibble パッケージの rowid_to_column() を用いて my_id という新しい ID の列を作成します（データフレームの最初に1から始まる連番の ID の列を追加します）。そして、このデータフレームの名前は bmt としました。\n\nbmt &lt;- rowid_to_column(BMT, \"my_id\")\n\nこのデータセットは以下のようになります：\n\n\n\n\n\n\n\n\n患者の行の展開\n次に、時間依存性共変量のために再構成したデータセットを作成するために、補助関数 event() および tdc() とともに tmerge() を使用していきます。目標は、各患者のデータが異なる値の deltaA を持つ時間区間になるように分割し、データセットを再構成することです。このデータの場合、各患者は急性移植片対宿主病を発症したか否かに応じて、最大で2行のデータを持つことができます。以下では、急性移植片対宿主病を発症したかどうかの新しい指示変数を agvhd と呼ぶことにします。\n\ntmerge() は各患者の異なる共変量の値に応じて複数の時間区間の縦長の long 型データセットを作成します\nevent() は新しく作成された時間区間に対応する新しいイベントの指示変数を作成します\ntdc() は新しく作成された時間区間に対応する新しい時間依存性共変量の列（agvhd）を作成します\n\n\ntd_dat &lt;- \n     tmerge(\n          data1 = bmt %&gt;% select(my_id, T1, delta1), \n          data2 = bmt %&gt;% select(my_id, T1, delta1, TA, deltaA), \n          id = my_id, \n          death = event(T1, delta1),\n          agvhd = tdc(TA)\n     )\n\n上記のコードで何が行われるのか、最初の5人の患者のデータを見てみましょう。\n元のデータにおける各変数の値は以下のようになっていました：\n\nbmt %&gt;% \n     select(my_id, T1, delta1, TA, deltaA) %&gt;% \n     filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1   TA deltaA\n1     1 2081      0   67      1\n2     2 1602      0 1602      0\n3     3 1496      0 1496      0\n4     4 1462      0   70      1\n5     5 1433      0 1433      0\n\n\n新しいデータセットにおける同じ患者のデータは以下のようになります：\n\ntd_dat %&gt;% \n     filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1 tstart tstop death agvhd\n1     1 2081      0      0    67     0     0\n2     1 2081      0     67  2081     0     1\n3     2 1602      0      0  1602     0     0\n4     3 1496      0      0  1496     0     0\n5     4 1462      0      0    70     0     0\n6     4 1462      0     70  1462     0     1\n7     5 1433      0      0  1433     0     0\n\n\nこのデータでは、一部の患者は2つの行を持っており、各行が新しい変数 agvhd に異なる値を持つ2つの区間に対応するようになっています。例えば、患者1は agvhd の値が0の時間0から67の区間と、agvhd の値が1の時間67から2081の区間の2つの行を持っています。\n\n\n\n時間依存性共変量を持つ Cox 回帰モデル\nデータを再構成し、新しく時間依存性共変量の変数 aghvd が追加されたので、単純な1つの時間依存性共変量を持つ Cox 回帰モデルを当てはめてみましょう。前の節で用いたものと同じ coxph() を用いることができますが、Surv() で各区間の開始時間と終了時間を指定する必要があります。これは引数 time1 = と time2 = で指定します。\n\nbmt_td_model = coxph(\n     Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n     data = td_dat\n)\n\nsummary(bmt_td_model)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    agvhd, data = td_dat)\n\n  n= 163, number of events= 80 \n\n        coef exp(coef) se(coef)    z Pr(&gt;|z|)\nagvhd 0.3351    1.3980   0.2815 1.19    0.234\n\n      exp(coef) exp(-coef) lower .95 upper .95\nagvhd     1.398     0.7153    0.8052     2.427\n\nConcordance= 0.535  (se = 0.024 )\nLikelihood ratio test= 1.33  on 1 df,   p=0.2\nWald test            = 1.42  on 1 df,   p=0.2\nScore (logrank) test = 1.43  on 1 df,   p=0.2\n\n\nまた、survminer パッケージの ggforest() を用いて Cox 回帰モデルの結果を可視化してみます：\n\nggforest(bmt_td_model, data = td_dat)\n\n\n\n\n\n\n\n\nフォレストプロット、信頼区間、および p 値から分かるように、この単純なモデルにおいては死亡と急性移植片対宿主病の間に強い関連があるとは言えませんでした。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.jp.html#参考資料",
    "href": "new_pages/survival_analysis.jp.html#参考資料",
    "title": "27  生存時間解析",
    "section": "27.7 参考資料",
    "text": "27.7 参考資料\nSurvival Analysis Part I: Basic concepts and first analyses\nSurvival Analysis in R\nSurvival analysis in infectious disease research: Describing events in time\nChapter on advanced survival models Princeton\nUsing Time Dependent Covariates and Time Dependent Coefficients in the Cox Model\nSurvival analysis cheatsheet R\nSurvminer cheatsheet\nPaper on different survival measures for cancer registry data with Rcode provided as supplementary materials",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html",
    "href": "new_pages/gis.jp.html",
    "title": "28  GIS の基本",
    "section": "",
    "text": "28.1 概要\nデータに空間情報があることで、アウトブレイクの状況について多くの洞察が得られ、次のような質問に答えることができます。\nこの GIS の章では、疫学業務担当者がアウトブレイク対応において知りたいニーズに応えることを目的としています。ここでは、tmap と ggplot2 パッケージを使って、基本的な空間データの可視化方法を学びます。また、sf パッケージを使用して、基本的な空間データの管理とクエリの方法についても説明します。最後に、spdep パッケージを用いて、空間的関係、空間的自己相関、空間回帰など、空間統計の概念に簡単に触れます。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#概要",
    "href": "new_pages/gis.jp.html#概要",
    "title": "28  GIS の基本",
    "section": "",
    "text": "現在の疾病のホットスポットはどこか？\nホットスポットは時系列でどのように変化しているか？\n医療施設へのアクセスはどうなっているか？改善が必要か？",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#重要な用語",
    "href": "new_pages/gis.jp.html#重要な用語",
    "title": "28  GIS の基本",
    "section": "28.2 重要な用語",
    "text": "28.2 重要な用語\nここでは、いくつかの重要な用語を紹介します。GIS と空間分析について詳しく知りたい方は、「リソース」節に掲載されている長いチュートリアルやコースをご覧になることをお勧めします。\nGIS（Geographic Information System, 地理情報システム） - GIS とは、空間データを収集、管理、分析、視覚化するためのフレームワークまたは環境のことです。\n\nGIS ソフトウェア\n一般的な GIS ソフトウェアの中には、マウス操作で地図の作成や空間分析ができるものがあります。これらのツールには、コードを覚える必要がない、アイコンや機能を手動で選択して地図上に配置するのが簡単であるなどの利点があります。ここでは、人気のある2つのソフトウェアを紹介します。\nArcGIS - ESRI 社が開発した商用の GIS ソフトウェアで、非常に人気がありますますが、かなり高価です。\nQGIS - フリーのオープンソース GIS ソフトウェアで、ArcGIS でできることもおおむねできます。ここでQGIS をダウンロードすることができます。\nR を GIS として使用することは、「マウス操作」ではなく「コマンドライン・インターフェース」（目的の結果を得るためにはコーディングが必要）であるため、最初は敷居が高く感じられるかもしれません。しかし、繰り返し地図を作成したり、再現性のある分析を行う必要がある場合には、これは大きな利点となります。\n\n\n空間データ\nGIS で使用される空間データには、主にベクトルデータとラスターデータの 2 種類があります。\nベクトルデータ - GIS で使用される空間データの最も一般的な形式です。ベクトルデータは、頂点とパスの幾何学的なフィーチャ (feature; 「地物」とも訳される) で構成されています。ベクトルの空間データは、さらに3つの広く使用されるタイプに分類されます。\n\n点 - 点は、座標系における特定の位置を表す座標ペア(x,y)で構成されます。点は空間データの最も基本的な形態であり、地図上の症例（例：患者の家）や場所（例：病院）を表すのに使用されます。\n線 - 線は、2つの接続された点で構成されます。線には長さがあり、道路や川などを表すのに使われます。\nポリゴン - ポリゴンは、点で接続された少なくとも3つの線分で構成されています。ポリゴンのフィーチャは、面積だけでなく、長さ（すなわち、面の外周の長さ）を持っています。ポリゴンは、地域（例：村）や構造（例：病院の実際の面積）を示すときに使用されます。\n\nラスターデータ - 空間データの代替フォーマットであるラスターデータは、セル（ピクセルなど）のマトリックスで、各セルには高さ、温度、傾斜、森林被覆などの情報が含まれています。これは、航空写真や衛星画像などでよく見られます。ラスターデータは、ベクトルデータの下の「基図」としても使用されます。\n\n\n空間データの可視化\nGIS ソフトウェアでは、空間データを地図上に視覚的に表現するために、それぞれのフィーチャがどこにあるのか、お互いの関係について十分な情報を提供する必要があります。ベクトルデータを使用している場合、ほとんどのユース症例では、この情報は通常シェープファイルに保存されます。\nシェープファイル - シェープファイルは、線、点、ポリゴンで構成される「ベクトル」空間データを保存するための一般的なデータフォーマットです。1つのシェープファイルは、実際には少なくとも3つのファイル（.shp、.shx、.dbf）の集合体です。シェープファイルを読み取るためには、これらのサブコンポーネントファイルがすべて同一のディレクトリ（フォルダ）に存在する必要があります。これらの関連ファイルは、ZIPフォルダに圧縮してメールで送信したり、ウェブサイトからダウンロードすることができます。\nシェープファイルには、フィーチャ自体の情報だけでなく、地球の表面のどこにあるかという情報も含まれています。空間データをどのように「平面化」するかは、地図の見た目や解釈に大きな影響を与えるため、重要なポイントとなります。\n座標参照系 (Coordinate Reference Systems, CRS)  - CRS とは、地球上の地理的フィーチャを特定するために使用される座標ベースのシステムです。CRSにはいくつかの重要な要素があります。\n\n座標系 (Coordinate System) - 非常にたくさんの座標系があるため、自分が使用する座標がどの座標系を用いているのかを必ず確認してください。緯度/経度の度数を用いたものは一般的ですが、UTM 座標が利用されていることもあります。\n単位 (Units) - 座標系の単位を知ることができます（例：小数点で表された度、メートル）。\n測地系 (Datum) - 地球上の特定のモデルの、特定のバージョンを指します。測地系は長年にわたって改訂されてきたので、地図として表示されるレイヤー（マップレイヤー）が同じ測地系を使用していることを確認してください。\n投影 (Projection) - 実際には丸い地球を平らな表面（地図）に投影するために使用された数式への参照。\n\n以下に示すマッピングツールを使用しなくても、空間データを要約することができることも覚えておいてください。地域別（例：地区、国など）のシンプルな表があれば十分なこともあります。\n訳注: 日本で主に利用されている CRS は次のような ものがあります。\n\n平面直角座標系（世界測地系）I〜XIII EPSG: 2443-2455\nJGD2000 GRS80楕円体 EPSG:4612\nJGD2011 GRS80楕円体 EPSG:6668 （東日本大震災以降の大規模地殻変動を反映）",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#はじめての-gis",
    "href": "new_pages/gis.jp.html#はじめての-gis",
    "title": "28  GIS の基本",
    "section": "28.3 はじめての GIS",
    "text": "28.3 はじめての GIS\n地図を作るためには、以下の通り、いくつかの重要な要素について、考え、また入手しなければありません。\n\nデータセット - これは空間データ形式（上述のようにシェープファイルなど）の場合もあれば、空間形式ではない場合もあります（例えば、単なる csv など）。\nデータセットが空間フォーマットでない場合は、参照データも必要です。参照データは、データの空間表現と関連する属性で構成されており、特定のフィーチャの位置情報やアドレス情報を含む資料などがあります。\n\n事前に定義された地理的境界線（例えば、行政区域）を扱う場合、参照シェープファイルは、政府機関やデータ共有組織から自由にダウンロードできることが多いです。迷ったときは、「[地域名] shapefile」とグーグルで検索してみるとよいでしょう。\n住所情報はあっても緯度・経度がないような場合は、 ジオコーディング・エンジン（geocoding engine）を使ってデータの空間参照データを取得する必要があるかもしれません。\n\nデータセットの情報を対象者に、どのように見せたいかというアイデア。地図には様々な種類がありますが、どの種類の地図が自分のニーズに最も適しているかを考えることが重要です。\n\n訳注：日本の主なGISデータ：  * 国勢調査 * 国土数値地図 * 国土地理院基盤地図 * G空間情報センター\n\nデータを可視化するための地図のタイプ\n色分け（Choropleth）地図 - 主題図の一種で、色、濃淡、またはパターンを使って、ある属性の値に関連して地理的な地域を表現するもの。例えば、大きな値は小さな値よりも濃い色で示されます。このタイプの地図は、ある変数と、それが定義された地域や地政学的エリアでどのように変化するかを視覚化する場合に特に便利です。\n\n\n\n\n\n\n\n\n\n症例密度ヒートマップ - 主題図の一種で、値の強さを色で表しますが、データをグループ化するために定義された地域や地政学的な境界線は使用しません。このタイプの地図は、一般的に「ホットスポット」や、点が高密度または集中しているエリアを示すために使用されます。\n\n\n\n\n\n\n\n\n\n点密度マップ - は、データの属性値をドットで表現する主題図タイプです。このタイプのマップは、データの散らばりを視覚化し、クラスターを視覚的にスキャンするのに適しています。\n等級シンボルマップ（段階のあるシンボルマップ） - 色分け地図に似ている主題図ですが、属性の値を色で表すのではなく、その値に対応するシンボル（通常は円）を使用します。例えば、大きな値は小さな値よりも大きなシンボルで示されます。このタイプの地図は、地域ごとのデータの大きさや量を視覚化したい場合に最適です。\nまた、複数の異なるタイプの視覚化を組み合わせて、複雑な地理的パターンを示すこともできます。例えば、下の地図の症例（点）は、最も近い医療施設に応じて色分けされています（凡例参照）。大きな赤い円は、一定の半径を持つ医療施設のキャッチメントエリアを示し、赤色の症例点は、キャッチメントの範囲外にある症例を示しています。\n\n\n\n\n\n\n\n\n\n注：この GIS の章の主な焦点は、現場でのアウトブレイク対応の状況に基づいています。そのため、この章の内容は、基本的な空間データの操作、視覚化、および分析をカバーしています。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#準備",
    "href": "new_pages/gis.jp.html#準備",
    "title": "28  GIS の基本",
    "section": "28.4 準備",
    "text": "28.4 準備\n\nパッケージを読み込む\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細はR の基礎の章をご覧ください。\n\npacman::p_load(\n  rio,           # データをインポート\n  here,          # ファイルの位置を探す\n  tidyverse,     # データを処理、プロット (ggplot2 パッケージを含む)\n  sf,            # Simple Featureフォーマットによる空間データの管理\n  tmap,          # シンプルな地図を作成、インタラクティブな地図と静的な地図の両方に対応\n  janitor,       # 列名のクリーニング\n  OpenStreetMap, # ggplot map に OSM 基図を追加\n  spdep          # 空間統計\n  ) \n\nCRAN “Spatial Task View”では、空間データを扱うすべての R パッケージの概要を見ることができます。\n\n\n症例データサンプル\nここでは分かりやすくするため、シミュレーションされたエボラ出血熱の linelist データフレームから1000件のランダムなサンプルを使って作業します（計算上、少ない件数で作業すると、このハンドブックでの表示が容易になります）。続いて、「前処理された」ラインリスト（linelist） をクリックしてダウンロードできます（.rdsファイル）。\nここではランダムにサンプルを取っているので、実際にコードを実行してみると、ここに表示されている結果とは若干異なる結果になるかもしれません。\nデータを rio パッケージの import() を使ってインポートします（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを扱えるパッケージです。詳細はデータのインポート・エクスポートの章を参照してください）。\n\n# import clean case linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")  \n\n次に、base R の sample() を使って 1000 行のランダムなサンプルを抽出します。\n\n# ラインリストの行数から1000個のランダムな行番号を生成\nsample_rows &lt;- sample(nrow(linelist), 1000)\n\n# サンプル行の全ての列だけを保持するラインリストにサブセットする\nlinelist &lt;- linelist[sample_rows,]\n\nそして、データフレーム型である linelist を “sf”（空間フィーチャ）型のオブジェクトに変換していきます。この ラインリストには、各症例の居住地の経度と緯度を表す “lon” と “lat” の2つの列があるので、これは簡単です。\nここでは、sf（空間的フィーチャ）パッケージとその関数、 st_as_sf() を使用して、linelist_sf という新しいオブジェクトを作成します。この新しいオブジェクトは、基本的には linelist と同じですが、列 lon と lat を座標列として指定し、点を表示する際の座標参照系 (CRS) を割り当てています。4326では、GPS座標の標準である World Geodetic System 1984 (WGS84) に基づいた座標が指定されています。\n\n# sfオブジェクトを生成\nlinelist_sf &lt;- linelist %&gt;%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nこれがオリジナルの linelist データフレームの中身です。このデモでは、date_onset と geometry（上記の経度と緯度のフィールドから作成されたもので、データフレームの最後の列）の列のみを使用します。\n\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n\n\n\n\n\n\n\n行政境界シェープファイル\nシエラレオネ (Sierra Leone): 行政境界シェープファイル\n事前に、Humanitarian Data Exchange (HDX) ウェブサイトからシエラレオネのすべての行政（admin）境界データをダウンロードしておきました。あるいは、ハンドブックとデータのダウンロードの章で説明しているように、私たちの R パッケージを介して、このデータやその他のサンプルデータをダウンロードすることもできます。\nでは、いよいよ Admin Level 3 のシェープファイルを R に保存するために、以下の作業を行います。\n\nシェープファイルをインポートする\n列名を加工する\n興味のある地域だけを残すために行を抽出する\n\nシェープファイルをインポートするには、sf パッケージの read_sf() を使います。ファイルのパスは here() で与えられます。- 今回の場合、ファイルはRプロジェクトの “data”、“gis”、“shp” というサブフォルダに “sle_adm3.shp” として格納されています（詳細は データのインポート・エクスポート と R プロジェクトの設定 の章を参照してください）。独自のファイルパスを設定してください。\n次に、janitor パッケージの clean_names() を使って、シェープファイルの列名を標準化します。また、filter() を使って、admin2name が “Western Area Urban” または “Western Area Rural” の行だけを残します。\n\n# ADM3 level clean\nsle_adm3 &lt;- sle_adm3_raw %&gt;%\n  janitor::clean_names() %&gt;% # 列名の標準化\n  dplyr::filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # 特定の地域を残してフィルター\n\n下の表は、インポートし、クリーニングした後のシェープファイルの様子です。右側にスクロールして、admin レベル 0（国）、admin レベル 1、admin レベル 2、そして最後に admin レベル 3 の列があることがわかります。それぞれのレベルには、キャラクター名と固有の識別子 “pcode” があります。たとえば、SL（Sierra Leone） → 04（Western） → L0410（Western Area Rural）→ L0040101（Koya Rural）のように、pcode は admin レベルが上がるごとに拡張されます。\n\n\n\n\n\n\n\n\n人口データ\nシエラレオネ: ADM3 ごとの人口\nこれらのデータは、HDX からダウンロードすることもできますし（リンクはこちら）、この章ハンドブックとデータのダウンロードで説明しているように、epirhandbook パッケージを介してダウンロードすることもできます。.csv ファイルの読み込みには、import() を使用します。また、インポートしたファイルを clean_names() に渡して列名の構文を標準化します。\n\n# ADM3 ごとの人口\nsle_adm3_pop &lt;- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %&gt;%\n  janitor::clean_names()\n\n人口ファイルはこのようになっています。右にスクロールすると、各行政区域に male、female、total の列があり、さらに年齢層別の列に人口の内訳が表示されています。\n\n\n\n\n\n\n\n\n医療施設\nシエラレオネ: OpenStreetMap からの医療施設\n今回も HDX から医療施設の位置情報をダウンロードしました。こちら または ハンドブックとデータのダウンロードの章の指示に従ってください。\n施設の位置を示す点のシェープファイルを read_sf() でインポートし、列名をクリーニングしてから、病院（“hospital”）、診療所（“clinic”）、医師（“doctor”） のいずれかのタグが付けられた点だけを残すように抽出しました。\n\n# OSM 医療施設の shapefile\nsle_hf &lt;- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %&gt;% \n  janitor::clean_names() %&gt;%\n  dplyr::filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))\n\n右にスクロールすると、施設名と geometry 座標が表示されます。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#座標のプロット",
    "href": "new_pages/gis.jp.html#座標のプロット",
    "title": "28  GIS の基本",
    "section": "28.5 座標のプロット",
    "text": "28.5 座標のプロット\nX-Y座標（経度・緯度で表される点）をプロットする最も簡単な方法は、今回の場合、準備編で作成した linelist_sf オブジェクトから直接、点として描画することです。\ntmap パッケージ は、わずか数行のコードで、静的（“plot” モード）とインタラクティブ（“view” モード）の両方に対応したシンプルなマッピング機能を提供します。tmap パッケージ の構文は ggplot2 パッケージ と似ていて、コマンド同士を + で追加していきます。詳しくはこの vignette をご覧ください。\n\ntmap モードを設定。ここでは plot モードを使い、静的なアウトプットを作成します。\n\n\ntmap_mode(\"plot\") # \"view\" または \"plot\" を選択\n\n以下では、点を単独でプロットしています。tm_shape() は、linelist_sf オブジェクトとともに提供されます。次に、tm_dots() でサイズと色を指定して点を追加します。linelist_sf は sf オブジェクトなので、緯度・経度座標と座標系（CRS）を格納する2つの列はすでに指定されています。\n\n# 症例（点）のみ\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n\n\n\n\n\n\n\n\n点だけでは、あまり意味がありません。そこで、行政境界もマッピングする必要があります。\nここでも tm_shape() を使いますが（documentation 参照）、症例の点のシェープファイルを提供する代わりに、行政境界のシェープファイル（ポリゴン）を提供します。\nbbox = の引数（bbox は “bounding box” の略）で、座標の境界を指定することができます。まず bbox なしの地図表示を行い、次に bbox ありの地図表示を行います。\n\n# 行政境界（ポリゴン）のみ\ntm_shape(sle_adm3) +               # 行政境界のシェープファイル\n  tm_polygons(col = \"#F7F7F7\")+    # ポリゴンを薄い灰色で表示\n  tm_borders(col = \"#000000\",      # 境界を色と線の太さで表示\n             lwd = 2) +\n  tm_text(\"admin3name\")            # 各ポリゴンについて表示する列テキスト\n\n\n# 上と同様、ただしバウンディングボックス引数から縮尺を指定\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # 角\n                  -13.2, 8.5)) +  # 角\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nそして、今度は点とポリゴンの両方を一緒に表示します。\n\n# すべてまとめる\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # 地図にタイトルを付ける\n\n\n\n\n\n\n\n\nR でのマッピングオプションの比較については、こちらの ブログ記事 をご覧ください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#空間結合",
    "href": "new_pages/gis.jp.html#空間結合",
    "title": "28  GIS の基本",
    "section": "28.6 空間結合",
    "text": "28.6 空間結合\nデータセットと別のデータセットを 結合 することについては知っているでしょう。いくつかの方法は、このハンドブックのデータの結合の章で説明しています。空間結合は、同様の目的を持ちますが、空間的な関係を利用します。観測値を正しく一致させるために列の共通の値に頼るのではなく、あるフィーチャが他のフィーチャの中に入っているとか、他のフィーチャに最近傍であるとか、他のフィーチャから一定の半径のバッファ内にあるなど、空間的な関係を利用することができます。\nsf パッケージには、空間結合のための様々なメソッドが用意されています。st_join メソッドや空間結合の種類については、こちらの参考資料に詳しい説明があります。\n\nポリゴン内の点\n症例に行政単位を空間割当て\nここで興味深い問題があります。症例のラインリストには、症例の admin 単位に関する情報が含まれていません。このような情報は、最初のデータ収集段階で収集するのが理想的ですが、空間的な関係（つまり、点がポリゴンと交差する）に基づいて、個々の症例に admin 単位を割り当てることもできます。\n以下では、症例の位置（点）と ADM3 の境界（ポリゴン）を空間的に交差させます。\n\nlinelist（点）から始める\n\n結合のタイプを “st_intersects” に設定して、境界線に空間的に結合する\nselect() を使用して、新しい行政境界列のうち特定のものだけを残す\n\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # 空間交差に基づいて行政境界を linelist に結合\n  sf::st_join(sle_adm3, join = st_intersects)\n\nsle_adms のすべての列がラインリストに追加されました！各症例には、該当する行政区域レベルの詳細を示す列が追加されました。この例では、新しい列のうち 2 つ（admin レベル3）だけを残したいので、古い列名を select() して、追加したい2つだけを選択します。\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # 空間交差に基づいて、行政境界ファイルをラインリストに結合\n  sf::st_join(sle_adm3, join = st_intersects) %&gt;% \n  \n  # 古い列名はそのままに、新たに2つの admin の列名を追加\n  select(names(linelist_sf), admin3name, admin3pcod)\n\n下の図は、最初の10件と、ポリゴン図形と空間的に交差する点に基づいて付けられた admin レベル3（ADM3）の行政境界を表示しています。\n\n# これで、各症例に ADM3 名がついたことが確認できます。\nlinelist_adm %&gt;% select(case_id, admin3name, admin3pcod)\n\nSimple feature collection with 1000 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -13.27122 ymin: 8.448085 xmax: -13.20576 ymax: 8.490227\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     case_id     admin3name admin3pcod                   geometry\n3043  67c121 Mountain Rural   SL040102 POINT (-13.21702 8.477598)\n3482  c20282       West III   SL040208  POINT (-13.26324 8.48435)\n1458  896214      Central I   SL040201 POINT (-13.22616 8.472034)\n1787  c3cd3c Mountain Rural   SL040102 POINT (-13.22406 8.449782)\n2038  e99fd4         East I   SL040203 POINT (-13.21619 8.488201)\n531   17948b        East II   SL040204  POINT (-13.22345 8.48359)\n3628  667306       West III   SL040208 POINT (-13.25386 8.458322)\n4692  45a9ab       West III   SL040208   POINT (-13.269 8.461356)\n2425  b3b0b4        West II   SL040207 POINT (-13.23461 8.468532)\n145   64b7b0       West III   SL040208 POINT (-13.27062 8.478093)\n\n\n空間結合の前にはできなかった、行政単位での症例の表現が可能になりました。\n\n# 行政単位ごとに症例の数を含むデータフレームを新規作成\ncase_adm3 &lt;- linelist_adm %&gt;%          # 新しい admin 列を含むラインリストで始める\n  as_tibble() %&gt;%                      # 見やすいように tibble に変換\n  group_by(admin3pcod, admin3name) %&gt;% # 名前と pcode で行政単位をグループ化\n  summarise(cases = n()) %&gt;%           # 要約と行数のカウント\n  arrange(desc(cases))                 # 下り順に並べ替え\n\ncase_adm3\n\n# A tibble: 10 × 3\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;\n 1 SL040102   Mountain Rural   285\n 2 SL040208   West III         222\n 3 SL040207   West II          183\n 4 SL040204   East II          110\n 5 SL040203   East I            65\n 6 SL040201   Central I         62\n 7 SL040206   West I            30\n 8 SL040202   Central II        20\n 9 SL040205   East III          20\n10 &lt;NA&gt;       &lt;NA&gt;               3\n\n\nまた、行政単位ごとの症例数の棒グラフを作成することもできます。\nこの例では、ggplot() を linelist_adm で始めているので、頻度で棒グラフを並べる fct_infreq() などの因子型のための関数を適用することができます（ヒントは 因子（ファクタ）型データ の章を参照してください）。\n\nggplot(\n    data = linelist_adm,                     # admin unit 情報を含むラインリストで始める\n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # x軸は行政単位、件数で並べ替え\n  geom_bar()+                                # 帽を作成、高さは行数\n  coord_flip()+                              # adm を読みやすくするためにXとYを入れ替える\n  theme_classic()+   # 背景を単純に\n  labs(                                      # タイトルとラベル\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n最近傍\n最寄の医療施設／集客エリアを探す\n病気のホットスポットに関連して、医療施設がどこにあるかを知っておくと便利かもしれません。\nここでは、st_join() (sf パッケージ)の st_nearest_feature 結合メソッドを使って、個々の症例に最も近い医療施設を可視化することができます。\n\nまず、シェープファイルのラインリスト linelist_sf を用意します。\n保健施設や診療所の位置（点）である sle_hf と空間的に結合します。\n\n\n# 各症例に最も近い医療施設\nlinelist_sf_hf &lt;- linelist_sf %&gt;%                  # linelist shapefile で始める\n  st_join(sle_hf, join = st_nearest_feature) %&gt;%   # 症例データから最も近い診療所からのデータ\n  select(case_id, osm_id, name, amenity) %&gt;%       # 残しておくべき列、例えば id, name, type, と医療施設の位置情報\n  rename(\"nearest_clinic\" = \"name\")                # 分かりやすいように名前を変更\n\n以下（最初の50行）のように、それぞれの症例には最寄りの診療所や病院のデータがあることがわかります。\n\n\n\n\n\n\n約30％の症例で “Den Clinic” が最も近い医療機関であることがわかります。\n\n# 医療施設ごとに症例を数える\nhf_catchment &lt;- linelist_sf_hf %&gt;%   # 最寄りの診療所データを含むラインリストで始める\n  as.data.frame() %&gt;%                # shapefile をデータフレームに変換\n  count(nearest_clinic,              # （診療所の）\"name\" で行を数える\n        name = \"case_n\") %&gt;%         # 数えたデータの列に \"case_n\" と命名\n  arrange(desc(case_n))              # 下がり順で並べ替え\n\nhf_catchment                         # console に表示\n\n                         nearest_clinic case_n\n1                            Den Clinic    346\n2       Shriners Hospitals for Children    324\n3         GINER HALL COMMUNITY HOSPITAL    182\n4                             panasonic     53\n5 Princess Christian Maternity Hospital     43\n6                     ARAB EGYPT CLINIC     25\n7                                  &lt;NA&gt;     14\n8                  MABELL HEALTH CENTER     13\n\n\n結果を可視化するために、tmap パッケージ を使用することができます。\n\ntmap_mode(\"view\")   # tmap モードをインタラクティブに設定\n\n# 症例と診療所の点をプロット\ntm_shape(linelist_sf_hf) +            # 症例をプロット\n  tm_dots(size=0.08,                  # 最も近い診療所で症例を色分け\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # 診療所を大きい黒い点でプロット\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # 施設名でオーバーレイ\ntm_view(set.view = c(-13.2284, 8.4699, 13), # 縮尺を調整 (中心座標, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cases, colored by nearest clinic\")\n\n\n\n\n\n\n\nバッファ\nまた、最も近い医療施設から徒歩2.5km（約30分）以内にある症例がどれくらいあるかを調べることもできます。\n注: より正確な距離を計算するためには、UTM（地球を平面に投影したもの）などの各地域の地図投影系に sf オブジェクトを再投影するのがよいでしょう。この例では、簡単にするために、世界測地系（WGS84）の地理的座標系（地球は球状/円形の表面で表現され、そのため単位は10進法の度数）にしておきます。ここでは、一般的な換算として、1度＝約111kmとします。\n地図投影法と座標系については、こちらのesriの記事をご覧ください。こちらのブログ では、様々なタイプの地図投影について、また、興味のある分野や地図・分析の文脈に応じて、どのように適切な投影を選ぶことができるかについて述べられています。\nまず、各医療施設の周囲に半径約2.5kmの円形バッファを作成します。これは tmap パッケージ の st_buffer() で行います。地図の単位は緯度・経度の10進法であるため、“0.02” は度数として解釈されます。地図の座標系がメートル単位の場合は、数値もメートル単位で指定する必要があります。\n\nsle_hf_2k &lt;- sle_hf %&gt;%\n  st_buffer(dist=0.02)       # 約2.5kmに度数を変換\n\n以下のように、バッファゾーン自体を作ります：\n\ntmap_mode(\"plot\")\n# 円バッファを作成\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # 診療所を大きい赤丸でプロット\n  tm_dots(size=0.3, col='black')      \n\n\n\n\n\n\n\n\n次に、st_join() の st_intersects 結合タイプを使って、これらのバッファと症例（点）を交差させます。これによって、バッファからのデータが、交差している点に結合されます。\n\n# バッファで症例を交差\nlinelist_sf_hf_2k &lt;- linelist_sf_hf %&gt;%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %&gt;%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %&gt;%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n\nこれによって結果を数えることができます。1000件のうち1000件は、どのバッファとも交差していない（値が欠けている）ので、最寄りの医療施設から徒歩30分以上の場所に住んでいることになります。\n\n# どの医療施設バッファとも交差しなかった症例\nlinelist_sf_hf_2k %&gt;% \n  filter(is.na(osm_id.y)) %&gt;%\n  nrow()\n\n[1] 1000\n\n\nその結果、どのバッファとも交わらなかった症例が赤で表示されるように可視化されます。\n\ntmap_mode(\"view\")\n\n# まず症例を点で表示\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# 診療所を大きい黒点でプロット\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# 医療施設バッファをポリラインで重ねる\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# どの医療施設バッファにもない症例を赤点で強調\ntm_shape(linelist_sf_hf_2k %&gt;%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# タイトルを追加\ntm_layout(title = \"Cases by clinic catchment area\")\n\n\n\n\n\n\n\n他の空間結合\njoinの引数は、このほかに以下の値をとります。 (ドキュメントより)\n\nst_contains_properly\n\nst_contains\n\nst_covered_by\n\nst_covers\n\nst_crosses\n\nst_disjoint\n\nst_equals_exact\n\nst_equals\n\nst_is_within_distance\n\nst_nearest_feature\n\nst_overlaps\n\nst_touches\n\nst_within",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#色分けchoropleth地図",
    "href": "new_pages/gis.jp.html#色分けchoropleth地図",
    "title": "28  GIS の基本",
    "section": "28.7 色分け（Choropleth）地図",
    "text": "28.7 色分け（Choropleth）地図\n色分け地図は、あらかじめ定義されたエリア（通常は行政単位や保健エリア）ごとにデータを視覚化するのに役立ちます。例えば、感染発生対応では、発生率の高い特定の地域にリソースを割り当てる際に役立ちます。\nすべての症例に行政単位名が割り当てられたので（上記の「空間結合」のセクションを参照）、症例数をエリア別にマッピングすることができます（色分け地図）。\nADM3 ごとの人口データもあるので、この情報を先に作成した case_adm3 テーブルに追加することができます。\nまず、前のステップで作成したデータフレーム case_adm3 から始めます。これは、各行政単位とその症例数の要約表です。\n\n人口データ sle_adm3_pop は、dplyr パッケージ の left_join() を用いて、case_adm3 データフレームの admin3pcod 列と sle_adm3_pop データフレームの adm_pcode 列に共通する値に基づいて結合されています。データの結合の章を参照）。\nselect() を新しいデータフレームに適用して、有用な列だけを残す - total は総人口です。\nmutate() を用いて、人口 10,000 人あたりの症例数を新しい列として計算します。\n\n\n# 人口データを追加し、１万人当たりの症例数を計算\ncase_adm3 &lt;- case_adm3 %&gt;% \n     left_join(sle_adm3_pop,                             # 人口データから列を追加 \n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %&gt;%  # 二つの列の共通の値に基づく結合\n     select(names(case_adm3), total) %&gt;%                 # 重要な列のみ保持、総人口など\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # 10000あたりの症例数の列を作成、小数点以下３桁で四捨五入\n\ncase_adm3                                                # console に表示\n\n# A tibble: 10 × 5\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases  total case_10kpop\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;  &lt;int&gt;       &lt;dbl&gt;\n 1 SL040102   Mountain Rural   285  33993       83.8 \n 2 SL040208   West III         222 210252       10.6 \n 3 SL040207   West II          183 145109       12.6 \n 4 SL040204   East II          110  99821       11.0 \n 5 SL040203   East I            65  68284        9.52\n 6 SL040201   Central I         62  69683        8.90\n 7 SL040206   West I            30  60186        4.99\n 8 SL040202   Central II        20  23874        8.38\n 9 SL040205   East III          20 500134        0.4 \n10 &lt;NA&gt;       &lt;NA&gt;               3     NA       NA   \n\n\nこのテーブルを ADM3 のポリゴンシェープファイル と結合してマッピングします。\n\ncase_adm3_sf &lt;- case_adm3 %&gt;%                 # 行政単位での症例と感染率で始める\n  left_join(sle_adm3, by=\"admin3pcod\") %&gt;%    # shapefile データと共通列で結合\n  select(objectid, admin3pcod,                # 指定した列のみ保持\n         admin3name = admin3name.x,           # 一つの列名をきれいにする\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %&gt;%                        # プロットできるように座標を保持\n  drop_na(objectid) %&gt;%                       # NA 行を取り除く\n  st_as_sf()                                  # shapefile に変換\n\n結果をマッピング。\n\ncase_adm3_sf &lt;- na.omit(case_adm3_sf)\n\n# tmap mode\ntmap_mode(\"plot\")               # 静的地図を表示\n\n# ポリゴンをプロット\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # 症例数の列で色分け\n        tm_text(\"admin3name\")   # 表示に名前を付ける\n\n\n\n\n\n\n\n\nインシデンス率もまた地図にします。\n\n# 1万人あたりの症例\ntmap_mode(\"plot\")             # 静的ビューモード\n\n# プロット\ntm_shape(case_adm3_sf) +                # ポリゴンをプロット\n  tm_polygons(\"case_10kpop\",            # 症例率を含む列で色分け\n              breaks=c(0, 10, 50, 100), # 色分けの値を定義\n              palette = \"Purples\"       # 紫色のカラーパレットを使用\n              ) +\n  tm_text(\"admin3name\")                 # テキストを表示",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#ggplot2-で地図作成",
    "href": "new_pages/gis.jp.html#ggplot2-で地図作成",
    "title": "28  GIS の基本",
    "section": "28.8 ggplot2 で地図作成",
    "text": "28.8 ggplot2 で地図作成\nすでに ggplot2 パッケージ の使用に慣れている場合は、データの静的なマップを作成する代わりに、ggplot2 パッケージを使用することができます。geom_sf() は、データに含まれる特徴 (点、線、多角形) に応じて異なるオブジェクトを描画します。例えば、ポリゴンを含む sf データを使った ggplot() の中で geom_sf() を使うと、色分け地図を作ることができます。\nこれがどのように機能するかを説明するために、先ほど使用した ADM3 ポリゴンのシェープファイルから始めます。このポリゴンは、シエラレオネの Admin Level 3 の地域であることを思い出してください。\n\nsle_adm3\n\nSimple feature collection with 12 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 20\n   objectid admin3name   admin3pcod admin3ref_n admin2name admin2pcod admin1name\n *    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n 1      155 Koya Rural   SL040101   Koya Rural  Western A… SL0401     Western   \n 2      156 Mountain Ru… SL040102   Mountain R… Western A… SL0401     Western   \n 3      157 Waterloo Ru… SL040103   Waterloo R… Western A… SL0401     Western   \n 4      158 York Rural   SL040104   York Rural  Western A… SL0401     Western   \n 5      159 Central I    SL040201   Central I   Western A… SL0402     Western   \n 6      160 East I       SL040203   East I      Western A… SL0402     Western   \n 7      161 East II      SL040204   East II     Western A… SL0402     Western   \n 8      162 Central II   SL040202   Central II  Western A… SL0402     Western   \n 9      163 West III     SL040208   West III    Western A… SL0402     Western   \n10      164 West I       SL040206   West I      Western A… SL0402     Western   \n11      165 West II      SL040207   West II     Western A… SL0402     Western   \n12      167 East III     SL040205   East III    Western A… SL0402     Western   \n# ℹ 13 more variables: admin1pcod &lt;chr&gt;, admin0name &lt;chr&gt;, admin0pcod &lt;chr&gt;,\n#   date &lt;date&gt;, valid_on &lt;date&gt;, valid_to &lt;date&gt;, shape_leng &lt;dbl&gt;,\n#   shape_area &lt;dbl&gt;, rowcacode0 &lt;chr&gt;, rowcacode1 &lt;chr&gt;, rowcacode2 &lt;chr&gt;,\n#   rowcacode3 &lt;chr&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\ndplyr パッケージ の left_join() を使って、マッピングしたいデータをシェープファイルオブジェクトに追加することができます。この例では、先ほど作成した case_adm3 データフレームを使って、行政区ごとの症例数をまとめていますが、データフレームに格納されているどのようなデータでも、同様の方法でマッピングすることができます。\n\nsle_adm3_dat &lt;- sle_adm3 %&gt;% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join = どちらのデータオブジェクトにもある場合にのみ残す\n\nselect(sle_adm3_dat, admin3name.x, cases) # console に選択した変数を表示\n\nSimple feature collection with 9 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 9 × 3\n  admin3name.x   cases                                                  geometry\n  &lt;chr&gt;          &lt;int&gt;                                        &lt;MULTIPOLYGON [°]&gt;\n1 Mountain Rural   285 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.4…\n2 Central I         62 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.48…\n3 East I            65 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.49…\n4 East II          110 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.4…\n5 Central II        20 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.4…\n6 West III         222 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.4…\n7 West I            30 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.49…\n8 West II          183 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.4…\n9 East III          20 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.4…\n\n\nggplot2 パッケージ を使って、地域別の症例数の棒グラフを作成するには、次のように geom_col() を呼び出します。\n\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # 'cases' 下がり順でx軸を並べ替え\n               y=cases)) +                                  # y軸は地域ごとの症例数\n  theme_bw() + \n  labs(                                                     # 図のテキストを設定\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # 見やすいようにx軸を45度傾ける\n\n\n\n\n\n\n\n\nもし、ggplot2 パッケージ を使って症例数の色分け地図を作りたい場合は、同様の構文で geom_sf() を呼び出すことができます。\n\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # 症例数で塗りつぶしが変化するように設定\n\n\n\n\n\n\n\n\nそして、例えば、ggplot2 パッケージ で統一されている文法を使って、地図の外観をカスタマイズすることができます。\n\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # 色の段階を変更\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # 図のテキストを設定\n       subtitle = \"Admin level 3\"\n  )\n\n\n\n\n\n\n\n\nggplot2 パッケージ に慣れているRユーザーにとって、geom_sf()は、実装がシンプルで直接的であり、基本的な地図の可視化に適しています。詳しくは、geom_sf() ビニエット（vignette） または ggplot2 book をご覧ください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#基図",
    "href": "new_pages/gis.jp.html#基図",
    "title": "28  GIS の基本",
    "section": "28.9 基図",
    "text": "28.9 基図\n\nOpenStreetMap\n以下では、OpenStreetMap の機能を使って ggplot2 パッケージを利用したマップの基図を作成する方法を説明します。他の方法としては、Google への無料登録が必要な ggmap パッケージ を使用する方法があります(詳細)。\nOpenStreetMap パッケージは、自由に編集可能な世界地図を作成する共同プロジェクトです。基本となるジオロケーション・データ（都市、道路、自然、空港、学校、病院、道路などの位置情報）は、このプロジェクトの主要なアウトプットと考えられています。\nまず、OpenStreetMap パッケージをロードして、そこから基図を取得します。\n次に、オブジェクト map を作成します。これは、OpenStreetMap パッケージの openmap() を使用して定義します (documentation)。以下のものを用意します。\n\nupperLeft と lowerRight 基図タイルの境界を指定する2つの座標ペア。\n\nここでは、ラインリストの行の最大値と最小値を入れているので、地図は動的にデータに反応します。\n\nzoom = (null の場合は自動的に決定されます)\n\ntype = 基図の種類 - ここではいくつかの可能性を挙げていますが、コードは現在、最初のもの（[1]）である “osm” を使用しています。\nmergeTiles = TRUEを選択したので、ベースタイルはすべて1つに統合されます。\n\n\n# パッケージをロード\npacman::p_load(OpenStreetMap)\n\n# 緯度経度の範囲に基図を切り取る。タイル種別を選択。\nmap &lt;- OpenStreetMap::openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # 基図のタイルの制限\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\n\n今、この基図を OpenStreetMap パッケージの autoplot.OpenStreetMap() を使ってプロットしてみると、軸の単位が緯度・経度座標ではない違う座標系を使っていることがわかります。緯度/経度で保存されている）症例の位置を正しく表示するには、これを変更する必要があります。\n\nautoplot.OpenStreetMap(map)\n\nそこで、 OpenStreetMap パッケージの openproj() を使って、地図を緯度/経度に変換したいと思います。基図 map と、必要な座標系（CRS）を指定します。ここでは、WGS 1984投影の “proj.4”文字列を指定していますが、他の方法でCRSを指定することもできます。(proj.4文字列が何であるかを理解するには、このページを参照してください)\n\n# 座標系 WGS84\nmap_latlon &lt;- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n\nプロットを作成すると、軸に沿って緯度と経度の座標が表示されています。座標系が変換されたことになります。これで、症例を重ね合わせても正しくプロットできるようになりました。\n\n# 地図をプロット。ggplot を使うためには、\"autoplot\" が必須。\nautoplot.OpenStreetMap(map_latlon)\n\n\n\n\n\n\n\n\n詳しくはチュートリアルこちらとこちらをご覧ください。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#等高線密度ヒートマップ",
    "href": "new_pages/gis.jp.html#等高線密度ヒートマップ",
    "title": "28  GIS の基本",
    "section": "28.10 等高線密度ヒートマップ",
    "text": "28.10 等高線密度ヒートマップ\n以下では、基図の上に症例の等高線付き密度ヒートマップを作成する方法を説明します。まず、ラインリストから始めます（1症例につき1行）。\n\n上述のように OpenStreetMap から基図タイルを作成する\n\nlinelist の症例を、緯度と経度の列を使ってプロットする。\nggplot2 パッケージの stat_density_2d() を使って、点を密度ヒートマップに変換する。\n\n緯度・経度座標を持つ基図があれば、その上に事例の居住地の緯度・経度座標を使ってプロットすることができます。\n基図を作成するための関数 autoplot.OpenStreetMap() をベースにして、ggplot2 パッケージ の関数を使えば、以下の geom_point() のように簡単に上に追加することができます。\n\n# 地図をプロット。ggplot と使うためには autoplot が必須。\nautoplot.OpenStreetMap(map_latlon)+                 # 基図から始める\n  geom_point(                                       # ラインリストの経度と緯度の列から xy の点を追加\n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # 凡例を完全に削除\n  labs(x = \"Longitude\",                                  # タイトルとラベル\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n\n\n\n\n\n\n\n\n上のマップは、特に点が重なっているところは、解釈が難しいかもしれません。そこで、 ggplot2 パッケージの stat_density_2d() を用いて 2 次元密度マップを作成することができます。ラインリストの緯度/軽度座標を使用していますが、2D カーネル密度推定を行い、その結果を等高線で表示します（地形図のように）。完全なドキュメントはこちらをご覧ください。\n\n# 基図から始める\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # 密度プロットを追加\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # カラースケールを指定\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # ラベル \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")\n\n\n\n\n\n\n\n\n\n\n時系列ヒートマップ\n上の密度ヒートマップは、累積症例を示しています。このヒートマップをラインリストから得られた症状の発症月に基づいて分割 （facet） することで、時空間的なアウトブレイクを調べることができます。\nまず、linelistで、発症した年と月の新しい列を作成します。base R の format() は、日付の表示方法を変更します。ここでは “YYYY-MM”とします。\n\n# 発症した月を抽出\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# 値を調査\ntable(linelist$date_onset_ym, useNA = \"always\")\n\n\n2014-04 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 \n      1      12      17      40      87     172     190     126     106      80 \n2015-02 2015-03 2015-04    &lt;NA&gt; \n     48      43      37      41 \n\n\nここでは、密度ヒートマップに ggplot2 パッケージによる分割列を導入するだけです。facet_wrap() が適用され、新しい列が行として使用されます。わかりやすくするために、分割列の数を 3 に設定しました。\n\n# パッケージ\npacman::p_load(OpenStreetMap, tidyverse)\n\n# 基図から始める\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # 密度プロットを追加\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # カラースケールを指定\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # ラベル\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # 発症した month-year でプロットを分割\n  facet_wrap(~ date_onset_ym, ncol = 4)",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#空間統計",
    "href": "new_pages/gis.jp.html#空間統計",
    "title": "28  GIS の基本",
    "section": "28.11 空間統計",
    "text": "28.11 空間統計\nこれまでの議論のほとんどは、空間データの視覚化に焦点を当ててきました。しかし、空間統計を使用し、データ内の属性の空間的な関係を定量化したいような場合もあるでしょう。ここでは、空間統計の主要な概念を簡単に説明し、より包括的な空間分析を行いたい場合に参考となるリソースを紹介します。\n\n空間的な関係\n空間統計を計算する前に、データのフィーチャ間の関係を特定する必要があります。空間的な関係を概念化する方法は数多くありますが、シンプルで一般的に適用できるモデルは「隣接関係」です。具体的には、境界を共有している、または「隣り合っている」エリア間に地理的な関係があると考えます。\nspdep パッケージで使用している sle_adm3 データの行政区域ポリゴン間の隣接関係を定量化することができます。ここでは、共点隣接 (queen contiguity) を指定します。こちらは、地域がその境界に沿って少なくとも1つの点を共有していれば、隣り合っていることを意味します。この他には、共辺隣接 (rook) を指定することもできます。こちらは、地域がその境界に沿って境界縁を共有していれば、隣り合っていることを意味します。この違いは些細なことですが、この事例は不規則なポリゴンですので、場合によっては queen と rook の選択が影響を与えることもあります。\n\nsle_nb &lt;- spdep::poly2nb(sle_adm3_dat, queen=T) # 隣接を作成\nsle_adjmat &lt;- spdep::nb2mat(sle_nb)    # 隣接関係をまとめた行列の作成\nsle_listw &lt;- spdep::nb2listw(sle_nb)   # listw (重みのリスト) オブジェクトを作成 -- 後で使います\n\nsle_nb\n\nNeighbour list object:\nNumber of regions: 9 \nNumber of nonzero links: 30 \nPercentage nonzero weights: 37.03704 \nAverage number of links: 3.333333 \n\nround(sle_adjmat, digits = 2)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\nattr(,\"call\")\nspdep::nb2mat(neighbours = sle_nb)\n\n\n上の図は、sle_adm3 データの 9 つのリージョン間の関係を示しています。スコア 0 は2つの地域が隣り合っていないことを示し、0以外の値は隣り合っていることを示しています。行列の値は、各地域の行の重みの合計が 1 になるようにスケーリングされています。\nこれらの隣接関係を視覚化するより良い方法は、プロットすることです。\n\nplot(sle_adm3_dat$geometry) +                                           # 地域境界をプロット\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # 隣接関係を追加\n\n\n\n\n\n\n\n\nここでは、隣接するポリゴンを特定するために、隣接アプローチを用いました。特定した隣接は、隣接ベース近傍 (contiguity-based neighbors) と呼ばれることもあります。しかし、これは、どの地域が地理的な関係を持っていると予想されるかを選択する一つの方法に過ぎません。地理的関係を特定するため別の方法で、最も一般的な方法は、以下のような距離ベース近傍を生成することです。\n\nK-最近傍 - セントロイド（各ポリゴン領域の地理的に重み付けされた中心）間の距離に基づいて、n個の最も近い領域を近傍として選択します。最大距離の近さのしきい値を指定することもできます。spdep パッケージでは、knearneigh() が使えます（ドキュメントを参照）。\n距離閾値近傍 - 距離閾値以内のすべての近傍を選択します。spdep パッケージでは、これらの近傍関係は dnearneigh() を使って特定できます（ドキュメントを参照）。\n\n\n\n空間的自己相関\nよく引用されるトブラーの地理学の第一法則では、「すべてのものは他のすべてのものに関係しているが、近くのものは遠くのものより関係している」とされています。疫学においては、ある地域における特定の健康結果のリスクは、遠くの地域よりも近隣の地域に類似していることを意味していることが多いです。この概念は、「空間的自己相関」として正式に定義されています。これは、類似した値を持つ地理的フィーチャが空間的に集まっているという統計的特性です。空間的自己相関の統計的測定は、データにおける空間的クラスタリングの程度を定量化し、クラスタリングが発生する場所を特定し、データ内の異なる変数間の空間的自己相関の共通パターンを特定するために使用することができます。このセクションでは、空間的自己相関の一般的な測定方法とRでの計算方法について説明します。\nMoran’s I - これは、ある地域での変数の値と、近隣の地域での同じ変数の値との間の相関のグローバルな要約統計です。通常、Moran’s I 統計量は、-1 から 1 の範囲をとります。0 は、空間的な相関のパターンがないことを示し、1 や -1 に近い値は、それぞれ空間的な自己相関（似たような値が近くにある）や空間的なばらつき（似ていない値が近くにある）が強いことを示しています。\n例として、先ほどマッピングしたエボラ出血熱の症例の空間的自己相関を定量化するために、Moran’s I 統計量を計算してみます（これは、シミュレーションされた linelist データフレームからの症例のサブセットであることを覚えておいてください）。spdep パッケージには、この計算を行うための、moran.test() があります。\n\nmoran_i &lt;-spdep::moran.test(sle_adm3_dat$cases,    # 指定の変数で数値ベクトル\n                            listw=sle_listw)       # 隣接関係を要約したlistwオブジェクト\n\nmoran_i                                            # Moran's I 検定の結果を表示\n\n\n    Moran I test under randomisation\n\ndata:  sle_adm3_dat$cases  \nweights: sle_listw    \n\nMoran I statistic standard deviate = 1.5529, p-value = 0.06023\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n        0.1985893        -0.1250000         0.0434230 \n\n\nmoran.test() の出力を見ると、Moran’s I 統計量は round(moran_i$estimate[1],2) となっています。これは、データに空間的な自己相関が存在することを示しています。具体的には、エボラ出血熱の患者数が同程度の地域は、近くにある可能性が高いということです。moran.test() で得られるp値は、空間的自己相関がないという帰無仮説の下での期待値との比較によって生成され、正式な仮説検定の結果を報告する必要がある場合に使用できます。\nLocal Moran’s I - 上で計算した（グローバルな）Moran’s I 統計を分解することで、局所的な空間的な自己相関を識別することができます。これを利用すると、データ内の特定のクラスターの識別を行うことができます。この統計は、LISA（Local Indicator of Spatial Association）統計量と呼ばれることもあり、個々の地域における空間的自己相関の程度を要約したものです。この値は、地図上の「ホット」と「コールド」な場所を見つけるのに役立ちます。\n例として、上で使用したエボラ出血熱の症例数に対して、spdep パッケージの local_moran() を用いて、Local Moran’s I を計算し、地図上に描画することができます。\n\n# local Moran's I を計算\nlocal_moran &lt;- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # 指定の変数\n  listw=sle_listw                                  # 隣接の重み付けをした listw オブジェクト\n)\n\n# 結果を sf データに結合\nsle_adm3_dat&lt;- cbind(sle_adm3_dat, local_moran)    \n\n# 地図をプロット\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nGetis-Ord Gi* - これもホットスポットの分析によく使われる統計です。この統計が人気である理由は、ArcGIS のホットスポット分析ツールで使われていることに関係しています。この統計は、通常、近隣地域間の変数の値の差は正規分布に従うはずだという仮定に基づいています。このツールは、z-score を利用したアプローチを用いて、指定された変数の値が近隣の地域に比べて統計的に特定の変数の値が有意に高い（ホットスポット）または低い（コールドスポット）地域を特定します。\nspdep パッケージの localG() を使って Gi* 統計量を計算し、マッピングすることができます。\n\n# local G 分析を実行\ngetis_ord &lt;- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# 結果を sf データに結合\nsle_adm3_dat$getis_ord &lt;- as.numeric(getis_ord)\n\n# 地図をプロット\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\n上のとおり、Getis-Ord Gi* のマップは、先に作成した Local Moran’s の地図とは若干異なっています。これは、これらの2つの統計量を計算するために使用される方法がわずかに異なることを反映しています。どちらを使用すべきかは、特定の事例とあなたが関心を持っているリサーチクエスチョンに依存します。\nLee’s L test - これは、二変量の空間相関に関する統計的な検定です。与えられた変数 x の空間パターンが、x に空間的に関連すると仮定された別の変数 y の空間パターンに類似しているかどうかを検定することができます。\n例として、シミュレーションしたエボラ出血熱の患者数の空間パターンが、人口の空間パターンと相関しているかどうかを検証してみましょう。まず始めに、sle_adm3 データに population 変数が必要です。先ほど読み込んだ sle_adm3_pop データフレームの total 変数を使うことができます。\n\nsle_adm3_dat &lt;- sle_adm3_dat %&gt;% \n  rename(population = total)                          # 列名 total を population に変更\n\n2つの変数の空間パターンを並べて視覚化することで、似ているかどうかをすぐに確認することができます。\n\ntmap_mode(\"plot\")\n\ncases_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + \n  tm_layout(main.title=\"Cases\")\npop_map &lt;- tm_shape(sle_adm3_dat) + \n  tm_polygons(\"population\") + \n  tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arrange into 2x1 facets\n\n\n\n\n\n\n\n\n視覚的には、この 2 つのパターンは似ていないように見えます。spdep パッケージの lee.test() を使って、2 つの変数の空間的自己相関のパターンが関連しているかどうかを統計的に検定することができます。L 統計量は、パターン間に相関がなければ 0 に近く、強い正の相関があれば（パターンが似ている場合は）1 に近く、強い負の相関があれば（パターンが逆の場合は）-1 に近くなります。\n\nlee_test &lt;- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # 比較する変数１\n  y=sle_adm3_dat$population,     # 比較する変数２\n  listw=sle_listw                # 隣接重みづけのある listw オブジェクト\n)\n\nlee_test\n\n\n    Lee's L statistic randomisation\n\ndata:  sle_adm3_dat$cases ,  sle_adm3_dat$population \nweights: sle_listw  \n\nLee's L statistic standard deviate = -0.9507, p-value = 0.8291\nalternative hypothesis: greater\nsample estimates:\nLee's L statistic       Expectation          Variance \n      -0.14860489       -0.04300702        0.01233740 \n\n\n上記の出力では、2つの変数の Lee’s L 統計量が round(lee_test$estimate[1],2) となり、弱い負の相関があることを示しています。これは、症例のパターンと人口が互いに関連していないという私たちの視覚的な評価を裏付けるものであり、症例の空間的なパターンは、厳密には高リスク地域の人口密度の結果ではないという証拠となります。\nLee’s L 統計は、空間的に分布する変数間の関係について、このような推論を行うのに役立ちます。しかし、2 つの変数間の関係の性質をより詳細に記述したり、交絡を調整したりするには、空間回帰技術が必要になります。以下では、これらについて簡単に説明します。\n\n\n空間回帰\n空間データの変数間の関係を統計的に推論したい場合があります。このような場合には、空間回帰の手法、つまり、データ内のユニットの空間的な構成を明示的に考慮した回帰のアプローチを検討することが有用です。GLM のような標準的な回帰モデルではなく、空間回帰モデルを検討する必要がある理由は以下の通りです。\n\n標準的な回帰モデルは、残差が互いに独立していることを前提としています。標準回帰モデルは、残差が互いに独立であると仮定していますが、強い空間的自己相関がある場合、標準回帰モデルの残差は空間的にも自己相関している可能性が高く、この仮定に反することになります。これは、モデルの結果を解釈する際に問題となる可能性があり、そのような場合には、空間モデルを使用することが望ましいでしょう。\nまた、回帰モデルでは、変数 x の効果がすべての観測点で一定であることを仮定します。空間的に異質である場合、推定したい効果は空間によって異なる可能性があり、その違いを定量化することに興味があるかもしれません。このような場合、空間回帰モデルは効果の推定と解釈をより柔軟に行うことができます。\n\n空間回帰アプローチの詳細については、このハンドブックの範囲外です。このセクションでは、最も一般的な空間回帰モデルとその用途の概要を説明し、この分野をさらに探求したい場合に役立つ参考文献を紹介します。\n空間誤差モデル - これらのモデルは、空間ユニット間の誤差項が相関していると仮定していますが、その場合、データは標準的な最小二乗法(OLS) モデルの仮定に反することになります。空間誤差モデルは、「同時自己回帰（SAR）モデル」と呼ばれることもあります。空間誤差モデルは、 spatialreg パッケージの errorsarlm()（空間回帰関数、以前は spdep パッケージの一部だった）を使ってフィットさせることができます。\n空間ラグモデル - このモデルは、ある地域 i の従属変数が、i の独立変数の値だけでなく、i に隣接する地域のそれらの変数の値にも影響されると仮定しています。空間誤差モデルと同様に、空間ラグモデルもまた、同時自己回帰（SAR）モデルと呼ばれることがあります。 空間ラグモデルは、spatialreg パッケージの lagsarlm() を使ってフィットさせることができます。\nspdep パッケージには、標準的な最小二乗法 (OLS) モデル、空間ラグモデル、空間誤差モデルを決定するための便利な診断テストがいくつか含まれています。これらのテストは、ラグランジュ乗数診断と呼ばれ、データの空間依存性のタイプを特定し、どのモデルが最も適切かを選択するために使用することができます。lm.LMtests() を用いると、すべてのラグランジュ乗数検定を計算することができます。Anselin (1988) は、ラグランジュ乗数検定の結果に基づいて、どの空間回帰モデルを使用するかを決定するための便利なフローチャートツールも提供しています。\n\n\n\n\n\n\n\n\n\nベイズ階層モデル - ベイズを用いた手法は、いくつかの応用例において空間分析で一般的に使用されています。最も一般的なのは 疾患マッピング です。症例データの分布がまばらであったり（例えば、稀な結果の場合）、統計的に「ノイズが多い」場合には、潜在的な空間プロセスを考慮して疾病リスクの「平滑化された」推定値を生成するために使用することができるので、ベイズを用いた手法の方が好まれます。これにより、推定値の質が向上する可能性があります。また、データに存在する可能性のある複雑な空間的相関パターンを（選択することで）事前に指定することができ、独立変数と従属変数の両方における空間依存および非依存の変動を説明することができます。Rでは、CARbayes パッケージ（ ビニエット（vignette） 参照）や R-INLA（website や textbook 参照）を用いてベイズ階層モデルをフィットさせることができます。また、R は JAGS や WinBUGS のようなベイズ推定を行う外部ソフトウェアを呼び出すのにも使うことができます。",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.jp.html#参考資料",
    "href": "new_pages/gis.jp.html#参考資料",
    "title": "28  GIS の基本",
    "section": "28.12 参考資料",
    "text": "28.12 参考資料\n\nR Simple Features and sf package vignette\nR tmap package vignette\nggmap: Spatial Visualization with ggplot2\nIntro to making maps with R, overview of different packages\nSpatial Data in R (EarthLab course)\nApplied Spatial Data Analysis in R textbook\nSpatialEpiApp - a Shiny app that is downloadable as an R package, allowing you to provide your own data and conduct mapping, cluster analysis, and spatial statistics.\nAn Introduction to Spatial Econometrics in R workshop",
    "crumbs": [
      "データ分析",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html",
    "href": "new_pages/tables_presentation.jp.html",
    "title": "29  見やすい表の作り方",
    "section": "",
    "text": "29.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html#準備",
    "href": "new_pages/tables_presentation.jp.html#準備",
    "title": "29  見やすい表の作り方",
    "section": "",
    "text": "パッケージの読み込み\nflextable パッケージをインストールして読み込みましょう。以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  rio,            # インポート/エクスポート\n  here,           # ファイルパス指定\n  flextable,      # HTML表を作成 \n  officer,        # 作表に関するヘルパー関数\n  tidyverse)      # データ管理、要約、ビジュアライゼーション\n\n\n\nデータをインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）\n\n# ラインリストをインポート\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nラインリスト の最初の 50 行を以下に表示します。\n\n\n\n\n\n\n\n\nテーブルの準備\nflextable パッケージを使い始める 前 に、テーブルをデータフレームとして 作成する 必要があります。janitor や dplyr などのパッケージを利用してデータフレームを作成する方法を学ぶには 記述統計表の作り方およびデータの縦横変換の章をご覧ください。表を表示したい内容に行と列を整えることが必要です。その後、データフレームを flextable に渡して、色、ヘッダ、フォントなどを設定していきます。\n以下は、 記述統計表の作り方 の章の例で、症例 linelist を病院ごとに患者の転帰と CT 値をまとめたデータフレームに変換し、下部に合計（Total）行を設定したものです。出力結果を table として保存します。\n\ntable &lt;- linelist %&gt;% \n  \n  # 病院と転帰のグループごとの要約量を取得\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # データのグループ化\n  summarise(                                           # 関心のある指標の要約する列を新規作成\n    N = n(),                                            # 病院-転帰グループごとの行数     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # グループごとのCTの中央値\n  \n  # 合計行を追加\n  ############\n  bind_rows(                                           # 前の表とこのミニ表の合計を結合する\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # hospitalごとではなく、outcomeのみでグループ化     \n      summarise(\n        N = n(),                                       # データセット全体の行数     \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # データセット全体のCTの中央値\n  \n  # 横にピボット変換してフォーマット\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # 縦から横への縦横変換\n    values_from = c(ct_value, N),                       # CT値とカウント列からの新規の値\n    names_from = outcome) %&gt;%                           # 転帰を新しい列名に\n  mutate(                                              # 新しい列の追加\n    N_Known = N_Death + N_Recover,                               # 転帰がわかっている症例数\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # 死亡症例のパーセント（小数点1桁）\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% #回復症例のパーセント（小数点1桁）\n  select(                                              # 列の再並び替え\n    hospital, N_Known,                                   # 最初の列\n    N_Recover, Pct_Recover, ct_value_Recover,            # 回復症例の列\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # 死亡症例の列\n  arrange(N_Known)                                    # 行を低い順から高い順に（合計は最下部）\n\ntable  # 出力\n\n# A tibble: 7 × 8\n# Groups:   hospital [7]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Missing          1125       514 45.7%                     21     611 54.3%    \n6 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n7 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html#flextable-の基本",
    "href": "new_pages/tables_presentation.jp.html#flextable-の基本",
    "title": "29  見やすい表の作り方",
    "section": "29.2 flextable の基本",
    "text": "29.2 flextable の基本\n\nflextable を作成する\nflextable オブジェクトを作成・管理するために、まずデータフレームを flextable() に渡します。その結果を my_table として保存します。\n\nmy_table &lt;- flextable(table) \nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nこのようにした後、 my_table オブジェクトをさらに flextable パッケージに含まれる表をフォーマットするための関数に次々とパイプ演算子で渡していくことができます。\nこの章では、わかりやすくするために、途中の段階でテーブルを my_tableとして保存し、段階的に flextable の機能を追加していきます。最初から最後までの すべて のコードをまとめて見たい場合は、下記のすべてのコードをまとめるセクションをご覧ください。\nflextable パッケージのコードの各行の一般的な構文は以下の通りです。:\n\nfunction(table, i = X, j = X, part = \"X\"), と記載して:\n\n‘function’ には、列の幅を決める width() 、背景色を設定する bg() 、テキストを中央/右/左に揃えるかどうかを設定する align() など、さまざまな関数のうちのひとつを指定することができます。\ntable = は、データフレームの名前ですが、データフレームを関数にパイプ演算子で渡している場合は、記述する必要はありません。\npart = 関数がテーブルのどの部分に適用されるかを示します。例：“header”、“body”、“all”。\ni = 関数を適用する 行 を、‘X’ に行番号を入力して指定します。複数の行、例えば 1 行目から 3 行目までを指定する場合は、 i = c(1:3) とします。なお、 ‘body’ を選択した場合、最初の行はヘッダセクションの下から始まります。\nj = は、関数を適用する 列 を、‘x’ に列番号または列名を入力して指定します。複数の列、例えば 5列目と6列目を指定する場合は、 j = c(5,6) とします。\n\n\nflextable パッケージのフォーマット関数の全リストは ここ でご覧いただけます。また、 ?flextableと入力してドキュメントを確認することもできます。\n\n\n列の幅\nautofit() を使うと、各セルに 1 行分のテキストしか入らないように表をうまい具合に引き伸ばすことができます。qflextable() は、 flextable() および autofit()を簡潔にした便利なものです。\n\nmy_table %&gt;% autofit()\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nしかし、セル内の値が非常に長く、表がページに収まらない場合など、必ずしも適切ではない場合があります。\nその代わりに、 width() で幅を指定することができます。以下の例では、1 列目、2 列目、4 列目から 8 列目にそれぞれ異なる幅を指定しています。\n\nmy_table &lt;- my_table %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\n列のヘッダ\n表の内容をわかりやすくするために、ヘッダをより明確にしたいことがあります。\nこの表では、同じサブグループをカバーする列がグループ化されるように、2 つ目のヘッダレイヤを追加したいと思います。そのために、 top = TRUEの add_header_row() を使用します。各列の新しい名前を values =に指定し、 後で統合することがわかっている列には空の値\"\" を指定します。\nまた、別の set_header_labels() コマンドで、2 つ目のヘッダのヘッダ名を変更します。\n最後に、特定の列のヘッダをトップヘッダに「結合」するために、 merge_at() を使用してトップヘッダ行の列のヘッダを結合します。\n\nmy_table &lt;- my_table %&gt;% \n  \n  add_header_row(\n    top = TRUE,                # 既存のヘッダ列の上に新しいヘッダを配置\n    values = c(\"Hospital\",     # 各列のヘッダ値は以下の通り\n               \"Total cases with known outcome\", \n               \"Recovered\",    # この列と次の2つの列のトップレベルのヘッダ\n               \"\",\n               \"\",\n               \"Died\",         # この列と次の2つの列のトップレベルのヘッダ\n               \"\",             # 「死亡」と統合させるので空欄のまま\n               \"\")) %&gt;% \n    \n  set_header_labels(         # 元のヘッダ行の列名を変更\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # 3列目から5列目までを新しいヘッダ行に水平に結合\n  merge_at(i = 1, j = 6:8, part = \"header\")     # 6列目から8列目までを新しいヘッダ行に水平に結合\n\nmy_table  # print\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\n罫線と背景\n罫線や内線などの調整は、さまざまな flextable パッケージの関数で行うことができます border_remove()で既存の罫線をすべて削除することから始めると、簡単な場合が多いです。\nそして、 theme_box()、theme_booktabs()、 theme_alafoli()にテーブルを渡すことで、デフォルトの罫線テーマを適用することができます。\n多彩な機能で縦線や横線を入れることができます。 hline() と vline() は、それぞれ指定した行や列に線を追加する関数です。それぞれの関数の中で、 part = の部分を “all”、“body”、“header” のいずれかに指定する必要があります。縦線の場合は j =までの列を、横線の場合は i =までの行を指定します。また、 vline_right()、vline_left()、 hline_top()、 hline_bottom() などの関数は、外側のみに線を追加します。\nこれらのすべての関数において、実際の罫線のスタイル自体は border = で指定する必要があり、 officer パッケージの fp_border() を使用した別のコマンドで出力しなければなりません。この関数は、線の幅と色を定義するのに役立ちます。以下のように、表コマンドの上で定義することができます。\n\n# 罫線のスタイルを定義する\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# 表に罫線を追加\nmy_table &lt;- my_table %&gt;% \n\n  # 既存の罫線をすべて削除\n  border_remove() %&gt;%  \n  \n  # 既定のテーマ設定のまま水平線を追加\n  theme_booktabs() %&gt;% \n  \n  # 回復症例 と 死亡症例のセクションを分けるために縦線を追加\n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # 2列目\n  vline(part = \"all\", j = 5, border = border_style)       # 5列目\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nフォントと配置\nflextable パッケージの align() を使って、病院名のある左端の列以外のすべての列を中央揃えにします。\n\nmy_table &lt;- my_table %&gt;% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nさらに、ヘッダのフォントサイズを大きくして、ボールドに変更することもできます。また、全体の行を太字にすることもできます。\n\nmy_table &lt;-  my_table %&gt;%  \n  fontsize(i = 1, size = 12, part = \"header\") %&gt;%   # ヘッダのフォントサイズを調整\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;%     # ヘッダの太字を調整\n  bold(i = 7, bold = TRUE, part = \"body\")           # 合計行の太字を調整する（本文7行目）\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\ncolformat_num() を使用して、比率の列のみを小数点 1 桁まで表示することができます。なお、これはデータ管理の段階で round() を用いて行うこともできます。\n\nmy_table &lt;- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nセルの結合\nヘッダ行で水平方向にセルを結合したように、merge_at() で行 （i） と列 （j） を指定して垂直方向にセルを結合することもできます。ここでは、「Hospital（病院）」と「Total cases with known outcome（転帰がわかっている症例の合計数）」の値を垂直方向に結合して、スペースを確保しています。\n\nmy_table &lt;- my_table %&gt;% \n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\n背景色\n表の内容をヘッダと区別するために、背景色の変更などの書式設定を追加したい場合があります。この例では、表の本文をグレーに変更します。\n\nmy_table &lt;- my_table %&gt;% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html#条件付き書式設定",
    "href": "new_pages/tables_presentation.jp.html#条件付き書式設定",
    "title": "29  見やすい表の作り方",
    "section": "29.3 条件付き書式設定",
    "text": "29.3 条件付き書式設定\n例えば、55% 以上の症例が死亡した場所など、あるルールを満たす列のすべての値を強調表示することができます。基準を i = または j = の引数に入れ、その前にチルダ ~を付けるだけです。表示する見出しの値ではなく、データフレームの列を参照します。\n\nmy_table %&gt;% \n  bg(j = 7, i = ~ Pct_Death &gt;= 55, part = \"body\", bg = \"red\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nまた、関心のある病院など、特定の基準を満たす行全体を強調表示することもできます。そのためには、列(j) の指定を外すだけで、基準がすべての列に適用されます。\n\nmy_table %&gt;% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html#tbl_pres_all",
    "href": "new_pages/tables_presentation.jp.html#tbl_pres_all",
    "title": "29  見やすい表の作り方",
    "section": "29.4 すべてのコードをまとめる",
    "text": "29.4 すべてのコードをまとめる\n以下に、上記のセクションのコードをすべてまとめて示します。\n\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # インポート/エクスポート\n  here,           # ファイルパス指定\n  flextable,      # HTML表を作成 \n  officer,        # 作表に関するヘルパー関数\n  tidyverse)      # データ管理、要約、ビジュアライゼーション\n\ntable &lt;- linelist %&gt;% \n\n  # 病院と転帰のグループごとの要約を取得\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # データのグループ化\n  summarise(                                           # 関心のある指標の要約する列を新規作成\n    N = n(),                                            # 病院-転帰グループごとの行数     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # グループごとのCTの中央値\n  \n  # 合計行を追加\n  ############\n  bind_rows(                                           # 前の表とこのミニ表の合計を結合する\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # 病院をなくして転帰のみでグループ化     \n      summarise(\n        N = n(),                                       # データセット全体の行数     \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # データセット全体のCTの中央値\n  \n  # ピボットの幅とフォーマット\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # 縦持ちから横持ちへの縦横変換\n    values_from = c(ct_value, N),                       # CT値とカウント列からの新規の値\n    names_from = outcome) %&gt;%                           # 転帰を新しい列名に\n  mutate(                                              # 新しい列の追加\n    N_Known = N_Death + N_Recover,                               # 転帰がわかっている症例数\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # 死亡症例のパーセント（小数点1桁）\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # 回復症例のパーセント（小数点1桁）)\n  select(                                              # 列の再並び替え\n    hospital, N_Known,                                   # 最初の列\n    N_Recover, Pct_Recover, ct_value_Recover,            # 回復症例の列\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # 死亡症例の列\n  arrange(N_Known) %&gt;%                                 # 行を低い順から高い順に（合計は最下部）\n\n  # フォーマット\n  ############\n  flextable() %&gt;%              # 表は上からパイプ演算子で渡す\n  add_header_row(\n    top = TRUE,                # 既存のヘッダ列の上に新しいヘッダを配置\n    values = c(\"Hospital\",     # 各列のヘッダ値は以下の通り\n               \"Total cases with known outcome\", \n               \"Recovered\",    # この列と次の2つの列のトップレベルのヘッダ\n               \"\",\n               \"\",\n               \"Died\",         # この列と次の2つの列のトップレベルのヘッダ\n               \"\",             # 「死亡」と統合させるので空欄のまま\n               \"\")) %&gt;% \n    set_header_labels(         # 元のヘッダ行の列名を変更\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # 3列目から5列目までを新しいヘッダ行に水平に結合\n  merge_at(i = 1, j = 6:8, part = \"header\") %&gt;%  \n  border_remove() %&gt;%  \n  theme_booktabs() %&gt;% \n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # 2行目 \n  vline(part = \"all\", j = 5, border = border_style) %&gt;%   # 5行目\n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\") %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1) %&gt;% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %&gt;% \n  bg(., part = \"body\", bg = \"gray95\")  %&gt;% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %&gt;% \n  colformat_num(., j = c(4,7), digits = 1) %&gt;%\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;% \n  bold(i = 7, bold = TRUE, part = \"body\")\n\n`summarise()` has grouped output by 'hospital'. You can override using the\n`.groups` argument.\n\ntable\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html#表の保存",
    "href": "new_pages/tables_presentation.jp.html#表の保存",
    "title": "29  見やすい表の作り方",
    "section": "29.5 表の保存",
    "text": "29.5 表の保存\nこの表を出力方式にはいろいろな方法があります。\n\n単一のテーブルとして保存\n表を Word、PowerPoint、HTML、または画像（PNG）ファイルとしてエクスポートすることができます。これを行うには、次のいずれかの機能を使用します。:\n\nsave_as_docx()\nsave_as_pptx()\nsave_as_image()\nsave_as_html()\n\n最初の引数の構文に注意してください - flextable オブジェクトの名前（例： my_table）だけを指定することもできますし、以下のように「名前」を指定することもできます（名前は “my table” です）。名前を付けると、Word で表のタイトルとして表示されます。PNG 画像として保存するコードもご紹介します。\n\n# 表のタイトルに合わせ 'my table' を必要に応じて編集   \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\n\nなお、flextable を画像として保存するには、 webshot または webshot2 パッケージが必要です。画像は背景が透明になることがあります。\nflextable パッケージの出力の ‘live’ バージョンを意図したドキュメント形式で表示したい場合は、 print() を使用し、 preview =に以下のいずれかを指定します。ドキュメントは、指定したソフトウェアプログラムでコンピュータ上に「ポップアップ」して開きますが、保存はされません。この方法は表が１ページやスライドに収まるかを確認する場合や、別の文書に素早く表をコピーするような場合に便利です。引数の preview に “pptx” または “docx” を指定して print() を使用することができます。\n\nprint(my_table, preview = \"docx\") # Word文書の例\nprint(my_table, preview = \"pptx\") # Powerpointの例\n\n\n\nR マークダウンで表を出力\nこの表は、表オブジェクトが R マークダウンチャンク内で呼び出された場合、自動化ドキュメントである R マークダウン出力に統合することができます。つまり、データが変更される可能性のあるレポートの一部としてテーブルを更新し、数値をリフレッシュすることができます。\n詳細は、本ハンドブック R Markdown で作るレポート の章をご覧ください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.jp.html#参考資料",
    "href": "new_pages/tables_presentation.jp.html#参考資料",
    "title": "29  見やすい表の作り方",
    "section": "29.6 参考資料",
    "text": "29.6 参考資料\nflextable の完全解説版はこちら://ardata-fr.github.io/flextable-book/ The Github サイト こちら\nflextable の全機能のマニュアルは こちらからご覧いただけます。\nコード付きの美しい flextable の例を集めたギャラリーは こちらからご覧いただけます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>見やすい表の作り方</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html",
    "href": "new_pages/ggplot_basics.jp.html",
    "title": "30  ggplot の基本",
    "section": "",
    "text": "30.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#準備",
    "href": "new_pages/ggplot_basics.jp.html#準備",
    "title": "30  ggplot の基本",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  tidyverse,      # ggplot2 やその他データマネジメントに関するツールが含まれています\n  janitor,        # cleaning and summary tables\n  ggforce,        # ggplot extras\n  rio,            # インポートとエクスポート\n  here,           # ファイル・ロケーター\n  stringr         # 文字列に関する作業   \n)\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください）。\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nラインリストの最初の 50 行を以下に表示します。ここでは、連続変数である age、wt_kg（キログラム単位の体重）、ct_blood（CT値）、days_onset_hosp（発症日と入院日の差）に注目します。\n\n\n\n\n\n\n\n\n一般的なクリーニング\nプロット用のデータを準備する際には、できるだけ 「tidy な（整然とした）」 データの基準に沿うようにするのがよいでしょう。その方法については、本ハンドブックのデータ管理の章、データクリーニングと主要関数 などで説明しています。\nプロットに適したデータを準備する簡単な方法としては、データの内容を表示に適したものにすることが挙げられますが、これは必ずしもデータ操作に適しているとは限りません。例えば、次のようなことです。\n\n文字列の NA 値を “Unknown” という文字列で置き換える。\n列の値が所定の序列レベルになるように因子型に変換することを検討する。\nアンダースコアなどの「データに適した」値を通常のテキストまたはタイトルケースに変更するように、一部の列をクリーニングする（データクリーニングと主要関数 を参照）。\n\n以下に、この作業の例を示します。\n\n# 列の表示をより分かりやすい名前にします\nlinelist &lt;- linelist %&gt;%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m を Male に\n                            gender == \"f\" ~ \"Female\",      # f を Female に\n                            is.na(gender) ~ \"Unknown\"),    # NA を Unknown に\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # outcome の NA を Unknown に置換\n  )\n\n\n\n縦長のデータへの転回\nデータ構造の問題として、ggplot2 パッケージではデータを転回して縦に長いフォーマットにしたいこともよくあります。詳しくはデータの縦横変換の章をご覧ください。\n\n\n\n\n\n\n\n\n\n例えば、linelist に登録されている各症例とその症状のような、「横に広い」フォーマットのデータについてプロットしたいとします。以下では、symptoms_data という mini-linelist を作成し、case_id と症状の列のみを格納します。\n\nsymptoms_data &lt;- linelist %&gt;% \n  select(c(case_id, fever, chills, cough, aches, vomit))\n\nこの mini-linelist の最初の 50 行は次のようになっています。それぞれの症状を列にして「横に広く」フォーマットされているのが分かります。\n\n\n\n\n\n\n特定の症状を持つ症例の数をプロットしたい場合、各症状が特定の列であるという事実によって制限されます。しかし、症状の列を転回して、次のように縦に長いフォーマットにすることができます。\n\nsymptoms_data_long &lt;- symptoms_data %&gt;%    # symptoms_data と名付けた \"mini\" linelist から始めます\n  \n  pivot_longer(\n    cols = -case_id,                       # case_id を除いた全ての列（全ての症状に関する列）を転回します\n    names_to = \"symptom_name\",             # 症状に関する新しい列の名前を割り当てます\n    values_to = \"symptom_is_present\") %&gt;%  #  「はい、もしくはいいえ」の値をもつ新しい列の名前を割り当てます\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # NA を unknown に変換します\n\nこちらが最初の 50 行です。case には 5 つの行があることに注意してください - それぞれの症状ごとに 1 つの列があります。新しい列である symptom_name と symptom_is_present は、転回した結果です。このフォーマットは、他の操作にはあまり役に立たないかもしれませんが、プロットには便利であることに注意してください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ggplotの基礎",
    "href": "new_pages/ggplot_basics.jp.html#ggplotの基礎",
    "title": "30  ggplot の基本",
    "section": "30.2 ggplotの基礎",
    "text": "30.2 ggplotの基礎\n「グラフィックの文法」- ggplot2\nggplot2 パッケージでのプロットは、作図レイヤーやデザイン要素を重ねて「追加」することが基本で、各コマンドはプラス記号（ + ）で前のコマンドに追加されます。その結果として、保存、修正、印刷、エクスポートなどが可能なマルチレイヤーの作図オブジェクトができあがります。\nggplot オブジェクトは非常に複雑になることがありますが、基本的なレイヤーの順番は、通常次のようになります。\n\n土台となる ggplot() コマンドから始めます。これは ggplot を「開く」もので、次に続く関数を + で追加することができます。一般的には、データセットもこのコマンドで指定します。\n“geom” レイヤーの追加 - これらの関数は、データを棒グラフ、折れ線グラフ、散布図、ヒストグラムなどの幾何学（図形）として視覚化します（組み合わせも可能です）。これらの関数は、すべて接頭辞として geom_ で始まります。\n軸ラベル、タイトル、フォント、サイズ、配色、凡例、軸回転などのデザイン要素をプロットに追加することができます。\n\n骨格となるコードの簡単な例を以下に示します。それぞれの要素については，以下のセクションで説明します。\n\n# my_data の列を赤い点としてデータをプロットします\nggplot(data = my_data)+                   # \"my_data\" というデータを使います\n  geom_point(                             # 点（ドット）のレイヤーを追加します\n    mapping = aes(x = col1, y = col2),    # \"map\" の列を軸にします\n    color = \"red\")+                       # geom の他の設定\n  labs()+                                 # タイトル、軸ラベル、などを追加します\n  theme()                                 # 色、フォント、サイズなどデータではない要素（軸やタイトルなど）を編集します",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ggplot",
    "href": "new_pages/ggplot_basics.jp.html#ggplot",
    "title": "30  ggplot の基本",
    "section": "30.3 ggplot()",
    "text": "30.3 ggplot()\nggplot2 のプロットの最初のコマンドは ggplot() です。このコマンドは、レイヤーを追加するための真っ白なキャンバスを作成します。さらに、+ 記号でレイヤーを追加するための方法を「開放」します。\n通常、ggplot() コマンドは、プロットのために data = 引数を含みます。これは、プロットの後続のレイヤーに使用されるデフォルトのデータセットを設定します。\nこのコマンドは、閉じた括弧の後に + を付けて終了します。これは、コマンドを「オープン」な状態にします。ggplot は、完全なコマンドが最後に + のない最後のレイヤーを含む場合にのみ、実行/表示されます。\n\n# これは真っ白なキャンバスであるプロットを作成します\nggplot(data = linelist)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#geoms",
    "href": "new_pages/ggplot_basics.jp.html#geoms",
    "title": "30  ggplot の基本",
    "section": "30.4 Geoms",
    "text": "30.4 Geoms\n真っ白なキャンバスはもちろん十分ではありません。データから幾何学（図形）を作成する必要があります（例：棒グラフ、ヒストグラム、散布図、箱ひげ図）。\nこれは、最初の ggplot() コマンドにレイヤー “geom” を追加することで行います。“geom” を作成する多くの ggplot2 パッケージの関数があります。これらの関数はそれぞれ “geom_” で始まるので、ここでは geom_XXXX() と一般的に呼びます。ggplot2 パッケージには 40 以上の geom があり、ggplot2 のファンが作ったものもたくさんあります。ggplot2 gallery でそれらを見ることができます。いくつかの一般的な geom を以下に示します。\n\nヒストグラム - geom_histogram()\n棒グラフ - geom_bar() あるいは geom_col() （棒グラフのセクションをご覧ください）\n箱ひげ図 - geom_boxplot()\n点（例：散布図） - geom_point()\n折れ線グラフ - geom_line() あるいは geom_path()\n傾向線 - geom_smooth()\n\n1 つのプロットで、1 つまたは複数の geom を表示できます。それぞれの geom は、前の ggplot2 パッケージのコマンドに + で追加され、後の geom が前の geom の上にプロットされるように、順次プロットされます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ggplot_basics_mapping",
    "href": "new_pages/ggplot_basics.jp.html#ggplot_basics_mapping",
    "title": "30  ggplot の基本",
    "section": "30.5 データをプロットにマッピングする",
    "text": "30.5 データをプロットにマッピングする\nほとんどの geom 関数は、形状を作成するために何を使用するかを指示する必要があります。つまり、軸、形状の色、形状のサイズなどのプロットの構成要素にどのようにデータの列をマッピング（割り当て）するかを指示する必要があります。ほとんどの geom では、データの列にマッピングされなければならない必要不可欠な要素は、x 軸と（必要に応じて）y 軸です。\nこの「マッピング」は、mapping = という引数で行われます。mapping に与えるマッピングは、aes() でラップしなければならないので、以下に示すように、mapping = aes(x = col1, y = col2) のように記述します。\n以下、ggplot() コマンドでは、linelist の症例がデータとして設定されています。mapping = aes() の引数では、age 列が x 軸に、wt_kg 列が y 軸にマッピングされています。\n+ の後にプロットコマンドが続きます。“geom” 関数の geom_point() で図形を作成します。この geom は、上記の ggplot() コマンドのマッピングを継承しています。つまり、geom はどの軸と列がグラフに割り当てられているかをすでに知っている状態であり、それらの関係をキャンパス上の点として視覚化していきます。\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\n\n\n\n\n\n\n\n\n別の例として、以下のコマンドでは、同じデータを使用して、少しだけ違うマッピングと異なる geom を利用しています。geom_histogram() では、x 軸にマッピングされた列が必要なだけで、y 軸のカウントは自動的に生成されます。\n\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nプロットの視覚的特性（エステティック）\nggplot の用語では、プロットのエステティック（aesthetic）には特定の意味があります。これは、プロットされたデータの視覚的特性を意味します。ここでの「エステティック」は、プロットされたデータの幾何学的形状を意味しており、タイトル、軸ラベル、背景色など、一般的な英語で「エステティック」という言葉から連想されるような周辺の表示は含まれていないことに注意してください。ggplot では、これらの詳細は “theme” と呼ばれ、theme() コマンドで調整されます（このセクションを参照）。\nしたがって、プロットオブジェクトの視覚的特性とは、プロットされたデータの色、サイズ、透過性、配置などのことです。すべての geom が同じオプションを持つわけではありませんが、多くの geom で使用することができます。以下にいくつかの例を示します。\n\nshape = geom_point() で指定した点を、点、星、三角、四角…のように表示します。\nfill = 棒グラフや箱ひげ図などの内側を塗りつぶす色\ncolor = 棒グラフや箱ひげ図などの外郭線、または geom_point() を使用する場合は点の色。\nsize = 大きさ（線の太さ、点の大きさなど）\nalpha = 透過度（1 = 不透明、0 = 不可視）\nbinwidth = ヒストグラムの階級の幅\nwidth = “棒グラフ” の列の幅\nlinetype = 線の種類 (例：実線、破線、点線)\n\nこれらのプロットオブジェクトの視覚的特性は、2 つの方法で値を割り当てることができます。\n\n静的な値（例：color = \"blue\"）を割り当て、プロットされたすべてのオブザベーションに適用する。\nデータの列に割り当てられ（例：color = \"hospital\"）、各観測値の表示はその列の値に依存する。\n\n\n\n\n静的な値の設定\nプロットオブジェクトの視覚的特性を静的なものにしたい場合、つまり、データの中のすべての観測値に対して同じものにしたい場合は、geom の中にその割り当てを記述しますが、mapping = aes() の引数の外に記述します。これらの割り当ては、size = 1 や color = \"blue\" のようになります。以下に 2 つの例を示します。\n\n1 つ目の例では、mapping = aes() は ggplot() コマンドの中にあり、軸にはデータの中の年齢と体重の列がマッピングされています。プロットの視覚的特性である color =, size =, alpha = （透明度）は静的な値に割り当てられています。わかりやすくするために、これは geom_point() の中で行われていますが、後から他の geom を追加してプロットの視覚的特性に異なる値を設定することもできます。\n2 つ目の例では、ヒストグラムでは x 軸のみを列にマッピングする必要があります。ヒストグラムの binwidth =, color =, fill =（内部色）, alpha = は、再び geom 内で静的な値に設定されます。\n\n\n# 散布図\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # データと軸のマッピングを設定\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # 静的な点の視覚的特性を設定\n\n# ヒストグラム\nggplot(data = linelist, mapping = aes(x = age))+       # データと軸を設定\n  geom_histogram(              # ヒストグラムを表示\n    binwidth = 7,                # 階級の広さ\n    color = \"red\",               # 階級の線の色\n    fill = \"blue\",               # 階級の内側の色\n    alpha = 0.1)                 # 階級の透過度\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n列の値に応じたスケーリング\nもう一つの方法は、プロットオブジェクトの美しさを列の値に応じて調整することです。この方法では、この視覚的特性の表示は、データのその列における観測値に依存することになります。列の値が連続的であれば、その視覚的特性の表示尺度（凡例）は連続的になります。列の値が離散的であれば、凡例には各値が表示され、プロットされたデータは明確に「グループ化」されているように見えます（詳しくはこの章のグループ化のセクションをご覧ください）。\nこれを実現するには、プロットの視覚的特性を列名（引用符で囲まれていないもの）にマッピングします。これは、mapping = aes() 内で行う必要があります（注：後述するように、コード内にはマッピングの割り当てを行う場所がいくつかあります）。\n以下に 2 つの例を示します。\n\n1 つ目の例では、（各ポイントの）color = が age の列にマッピングされ、凡例にスケールが表示されています。この例では、目盛りが存在していることを覚えておいてください。後ほどそれらを修正する方法を示します。\n2 つ目の例では、2 つの新しいプロットの視覚的特性が列にマッピングされています（color = と size =）。一方、プロットの視覚的特性である shape = と alpha = は、mapping = aes() を使わずに、静的な値にマッピングされています。\n\n\n# 散布図\nggplot(data = linelist,   # データを設定\n       mapping = aes(     # 列名をマッピング\n         x = age,           # x 軸に age をマッピング\n         y = wt_kg,         # y 軸に weight をマッピング\n         color = age)\n       )+     # color に age をマッピング\n  geom_point()         # データを点として表示 \n\n# 散布図\nggplot(data = linelist,   # データを設定\n       mapping = aes(     # 列名をマッピング\n         x = age,           # x 軸に age をマッピング           \n         y = wt_kg,         # y 軸に weight をマッピング\n         color = age,       # color に age をマッピング\n         size = age))+      # size に age をマッピング\n  geom_point(             # データを点として表示\n    shape = \"diamond\",      # 点を菱形として表示\n    alpha = 0.3)            # 点の透過度を30%として表示\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n注：軸の割り当ては、常にデータの列に割り当てられます（静的な値ではありません）。これは常に mapping = aes() 内で行われます。\n複数の geom を持つプロットなど、より複雑なプロットを作成する場合には、プロットのレイヤーと視覚的特性を把握しておくことが重要になります。以下の例では、size = が geom_point() と geom_smooth() の 2 回割り当てられていますが、どちらも静的な値です。\n\nggplot(data = linelist,\n       mapping = aes(           # 列名をマッピング\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # データの各行に点を追加\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # トレンドラインの追加\n    method = \"lm\",              # 線形性に基づく方法\n    size = 2)                   # サイズ（線の太さ）を2に\n\n\n\n\n\n\n\n\n\n\nマッピングのアサインをする場所\nmapping = aes() 内のマッピングは、プロットコマンドの中のいくつかの場所に書くことができ、また複数回書くこともできます。これは、一番最初の ggplot() コマンドの中に書くこともできますし、その下の個々の geom ごとに書くこともできます。ニュアンスは以下の通りです。\n\nトップの ggplot() コマンドで作成されたマッピング割り当ては、 x = と y = が継承されるように、下にあるすべての geom でデフォルトとして継承されます。\n1 つの geom 内で行われたマッピング割り当ては、その geom にのみ適用されます。\n\n同様に、トップの ggplot() で指定された data = は、それ以下のすべての geom にデフォルトで適用されますが、geom ごとにデータを指定することもできます（ただし、これはより難しいです）。\nこのように、以下の各コマンドは同じプロットを作成します。\n\n# これらのコマンドは、同じプロットを作成します\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))\n\n\n\nグループ\nデータをグループ化して「グループ別にプロット」することも簡単にできます。実際に、あなたはすでにこれを行っています。\nmapping = aes() の中で、「グループ化」列を適切なプロットの視覚的特性に割り当てます。上の例では、連続値の場合、age 列にポイント size = を割り当てました。しかし、これは離散的・カテゴリカルな列にも同じように作用します。\n例えば、ポイントを性別ごとに表示したい場合は、mapping = aes(color = gender) とします。凡例が自動的に表示されます。この割り当ては、トップの ggplot() コマンドの中の mapping = aes() の中で行うことができます（そして、geom に継承されます）。また、geom の中の別の mapping = aes() の中で設定することもできます。両方の方法を以下に示します。\n\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n# この代替コードも、同じプロットを生成します\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)\n\ngeom に応じて、データをグループ化するために異なる引数を使用する必要があることに注意してください。geom_point() の場合は、color =, shape =, size = のいずれかを使用することになるでしょう。 一方、geom_bar() の場合は、fill = を使用することになるでしょう。 これは、geom と、グループ化を反映させたいプロットの美しさに依存しています。\n参考までに、データをグループ化する最も基本的な方法は、mapping = aes() のgroup = 引数のみを使用することです。しかし、これだけでは、色、塗りつぶし、形は変わりません。また、凡例も作成されません。しかし、データはグループ化されているので、統計表示には影響があるかもしれません。\nプロット内のグループの順序を調整するには、ggplot のヒントの章または因子（ファクタ）型データの章を参照してください。グループ化されたプロットの例は、以下の連続データやカテゴリーデータのプロットのセクションにたくさんあります。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ggplot_basics_facet",
    "href": "new_pages/ggplot_basics.jp.html#ggplot_basics_facet",
    "title": "30  ggplot の基本",
    "section": "30.6 Facets / Small-multiples",
    "text": "30.6 Facets / Small-multiples\nファセット、もしくは、“small-multiples” とは、 1 つのプロットを複数のパネルに分割するためのもので、データグループごとに 1 つのパネル（「ファセット」）が用意されている。同じ種類のプロットが複数回作成され、それぞれが同じデータセットのサブグループを使用してものになります。\nファセット化は ggplot2 パッケージに付属する機能で、ファセット化された「パネル」の凡例と軸は自動的に整列します。ggplot のヒントの章で説明されている他のパッケージ（cowplot パッケージや patchwork パッケージ）もあり、まったく異なるプロットを 1 つの図にまとめるのにも使われます。\nファセット化は、以下の ggplot2 パッケージの関数のいずれかで行います。\n\nfacet_wrap() 一つの変数の各レベルごとに異なるパネルを表示する。例の一つとしては、地域の病院ごとに異なる流行曲線（エピカーブ）を表示することができます。ファセットは、変数が他の順序が定義された因子でない限り、アルファベット順に並べられます。\n\n\nファセットのレイアウトを決定するために、特定のオプションを呼び出すことができます。例えば、nrow = 1 または ncol = 1 で、ファセット化されたプロットが配置される行または列の数を制御することができます。\n\n\nfacet_grid() これは、第二の変数をファセットの配置に加えたいときに使用します。ここでは、グリッドの各パネルは、2 つの列の値の間の交点を示しています。例えば、病院と年齢グループの組み合わせごとに、病院が上（列）に、年齢グループが横（行）に沿った疫学曲線を示します。\n\n\nサブグループがグリッドで表示されるため、nrow および ncol は関係ありません。\n\nこれらの関数はそれぞれ、ファセット化する列を指定するための数式シンタックスを受け付けます。両方とも、チルダ ~ の両側に 1 つずつ、最大 2 つの列を受け入れます。\n\nfacet_wrap()では、多くの場合、facet_wrap(~hospital) のようにチルダ ~ を先行させて 1 つの列だけを記述します。しかし、facet_wrap(outcome ~ hospital) のように 2 つの列を書くこともできます。それぞれのユニークな組み合わせは、別のパネルに表示されますが、グリッドには配置されません。見出しには結合された用語が表示され、これらは列と行の間の特定のロジックではありません。ファセット変数を 1 つだけ指定する場合は、ピリオド . が数式の反対側のプレースホルダーとして使用されます（コード例を参照）。\nfacet_grid() では、数式に 1 つまたは 2 つの列を指定することもできます（グリッドの row ~ columns ）。1 つだけ指定したい場合は、facet_grid(. ~ hospital) や facet_grid(hospital ~ .) のように、チルダの反対側にピリオド . を置くことができます。\n\nファセットはすぐに圧倒的な量の情報を含むことができるので、ファセットを選択する各変数のレベルが多すぎないようにするのが良いでしょう。ここでは、malaria データセット（ハンドブックとデータのダウンロードを参照）を使った簡単な例を紹介します。malaria データセットは、施設におけるマラリアの毎日の症例数を年齢層別に集計したものです。\n以下では、インポートして、簡単な修正を行います。\n\n# これらのデータは、マラリアの症例を施設ごとに日ごとにカウントしたものです\nmalaria_data &lt;- import(here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;%  # インポート\n  select(-submitted_date, -Province, -newid)                                 # 不要な列の削除\n\nmalaria データの最初の 50 行を以下に示します。malaria_tot という列がありますが、年齢グループ別のカウントの列もあります（これらは 2 番目の facet_grid() の例で使用されます）。\n\n\n\n\n\n\n\nfacet_wrap()\nとりあえず、malaria_tot と District の列に注目してみましょう。年齢別カウントの列は今回は無視します。geom_col() を使って流行曲線（エピカーブ）をプロットします。これは、malaria_tot 列で指定された y 軸の高さに、各日の列を生成します（データはすでに日ごとのカウントなので、geom_col() を使います - 棒グラフを参照）。\nfacet_wrap() コマンドを追加する際には、チルダを指定し、次にファセットする列を指定します（ここでは District ）。チルダの左側に別の列を配置することもできますが、これは各組み合わせに対して 1 つのファセットを作成することになりますので、代わりに facet_grid() で行うことをお勧めします。この使用例では、District のユニークな値ごとに 1 つのファセットが作成されます。\n\n# District によってファセットされたプロット\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # カウントデータを列としてプロットします\n  theme_minimal()+                              # 背景のパネルを簡素化します\n  labs(                                         # プロットのラベルやタイトルなどを追加します\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # ファセットが作られます\n\n\n\n\n\n\n\n\n\n\nfacet_grid()\nfacet_grid() を使って、2 つの変数をクロスさせることができます。例えば、District と age を交差させたいとしましょう。さて、これらのデータを ggplot が好む「縦に長い」フォーマットにするために、年齢の列にいくつかのデータ変換を行う必要があります。年齢グループはそれぞれ独自の列を持っていますが、ここでは age_group という 1 つの列と num_cases という別の列に分けます。このプロセスの詳細については、データの縦横変換の章を参照してください。\n\nmalaria_age &lt;- malaria_data %&gt;%\n  select(-malaria_tot) %&gt;% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # 縦長に転回する列を選びます\n    names_to = \"age_group\",      # 列名を age_group にします\n    values_to = \"num_cases\"      # 値を 1 つの列（num_cases）にまとめます\n  ) %&gt;%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\n\nこれで、最初の 50 行のデータは次のようになります。\n\n\n\n\n\n\n2 つの変数を facet_grid() に渡すとき、x が行、y が列である数式表記 (例: x ~ y ) を使用するのが最も簡単です。ここでは、facet_grid() を使って、 age_group とDistrict の列の組み合わせごとにプロットを表示しています。\n\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(District ~ age_group)\n\n\n\n\n\n\n\n\n\n\n自由または固定軸\nファセット化の際に表示される軸のスケールは、デフォルトでは必ずしも常に適切ではありません。これは、相互比較には便利ですが、必ずしも適切ではありません。\nfacet_wrap() または facet_grid() を使用する場合、scales = \"free_y\" を追加することで、各パネルで固定された y 軸のスケールを開放（自由に）して、そのデータサブセットを適切な範囲で表示させることができます。これは、サブカテゴリーの 1 つで実際のカウントが小さく、トレンドが見えにくい場合に特に有効です。また、“free_y” の代わりに “free_x” と書けば、x 軸（日付など）にも同じことができますし、両方の軸を同様に開放するために、引数の値として “free” と設定することもできます。facet_grid では、同じ行のファセットでは y スケールが同じになり、同じ列のファセットでは x スケールが同じになることに注意してください。\nfacet_grid のみを使用する場合、space = \"free_y\" または space = \"free_x\" を追加することで、ファセットの実際の高さまたは幅が中の図の値に重み付けされます。これは、scales = \"free\"（y または x）がすでに適用されている場合にのみ機能します。\n\n# 自由な y 軸\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # カウントデータを列としてプロットします\n  theme_minimal()+                              # 背景のパネルを簡素化します\n  labs(                                         # プロットのラベルやタイトルなどを追加します\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # ファセットが作られます\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nファセット内の因子レベルの順序\nファセット内の因子レベルの順序を変更する方法については、こちらの記事を参照してください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#プロットの保存",
    "href": "new_pages/ggplot_basics.jp.html#プロットの保存",
    "title": "30  ggplot の基本",
    "section": "30.7 プロットの保存",
    "text": "30.7 プロットの保存\n\nプロットの保存\nデフォルトでは ggplot() コマンドを実行すると、プロットは RStudio の Plots ペインに表示されます。しかし、代入演算子 &lt;- を使い、名前を付けてプロットをオブジェクトとして保存することもできます。そうすれば、オブジェクト名自体が呼び出されて実行されない限り、表示されません。プロット名を print() で囲んで表示することもできますが、これは、複数のプロットを一度に表示するための for ループの中でプロットを作成する場合など、特定の状況でのみ必要となります（ループと反復処理・リストの操作の章を参照）。\n\n# プロットを定義します\nage_by_wt &lt;- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# 表示する\nage_by_wt    \n\n\n\n\n\n\n\n\n\n\n保存されたプロットの修正\nggplot2 パッケージの良いところは、（上記のように）プロットを定義して、その名前から始まるレイヤーを追加できることです。元のプロットを作ったすべてのコマンドを繰り返す必要はありません。\n例えば、上で定義したプロット age_by_wt を修正して、50 歳のところに縦線を入れるには、単に + と記載して、続けてプロットに新しいレイヤーを追加し始めることができます。\n\nage_by_wt+\n  geom_vline(xintercept = 50)\n\n\n\n\n\n\n\n\n\n\nプロットのエクスポート\nggplot のエクスポートは、ggplot2 パッケージの ggsave() で簡単にできます。この関数は 2 つの方法で動作させることができます。\n\nプロットオブジェクトの名前を指定した後、ファイルのパスと拡張子付きの名前を指定します。\n\n例： ggsave(my_plot, here(\"plots\", \"my_plot.png\"))\n\nファイルパスのみを指定してコマンドを実行すると、最後に出力されたプロットが保存されます。\n\n例： ggsave(here(\"plots\", \"my_plot.png\"))\n\n\nファイルパスに拡張子を指定することで、png、pdf、jpeg、tiff、bmp、svgなどのファイル形式でエクスポートすることができます。\nまた、引数として、width =、height =、units =（“in”、“cm”、“mm” のいずれか）を指定することができます。また、プロットの解像度を表す数字（例：300）で dpi ＝ を指定することもできます。関数の詳細については、?ggsave を入力するか、オンラインのドキュメントを参照してください。\nまた、here() 構文を使って、必要なファイルパスを指定することもできます。詳しくは、データのインポート・エクスポート](#importing)の章をご覧ください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ラベル",
    "href": "new_pages/ggplot_basics.jp.html#ラベル",
    "title": "30  ggplot の基本",
    "section": "30.8 ラベル",
    "text": "30.8 ラベル\nグラフを作成していると、必ずプロットのラベルを追加したり調整したくなるでしょう。これらは、labs() の中で行うことが、最も簡単な方法です。labs() は、geom と同じように + でプロットに追加されます。\nlabs() では、これらの引数に文字列を指定することができます。\n\nx = と y = x 軸と y 軸のタイトル（ラベル）\n\ntitle = プロットのメインタイトル\n\nsubtitle = プロットのサブタイトル、タイトルの下に小さいテキストで表示\n\ncaption = プロットのキャプション、デフォルトでは右下に表示される\n\n以下は、以前に作成したプロットですが、ラベルがより良いものになっています。\n\nage_by_wt &lt;- ggplot(\n  data = linelist,   # データを設定\n  mapping = aes(     # map aesthetics to column values\n         x = age,           # x 軸に age をマッピング\n         y = wt_kg,         # y 軸に weight をマッピング\n         color = age))+     # 色に age をマッピング\n  geom_point()+           # データを点として表示\n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt\n\n\n\n\n\n\n\n\nキャプションの割り当てでは、stringr パッケージの str_glue() を使って、文字列テキストの中にダイナミックな R コードを埋め込んだことに注目してください。キャプションには、“Data as of:” キャプションには、linelist の最大入院日を反映した “Data as of:”の日付が表示されます。詳しくは、文字型・文字列型データの章をご覧ください。\n凡例のタイトルを指定する際の注意点：凡例には複数の尺度を設定できるため、「凡例タイトル」の引数は 1 つではありません。labs() の中で、凡例の作成に使われるプロットの視覚的特性の引数を書き、この方法でタイトルを指定することができます。たとえば、上記では、color = age を割り当てて凡例を作成しました。したがって、color = を labs() に指定し、希望する凡例のタイトル（大文字の A の “Age” ）を割り当てます。aes(fill = COLUMN) で凡例を作成した場合は、labs() で fill = と書き、その凡例のタイトルを調整します。ggplot のヒントの章のカラースケールのセクションでは、凡例の編集についての詳細と、scales_() を使った別の方法が紹介されています。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ggplot_basics_themes",
    "href": "new_pages/ggplot_basics.jp.html#ggplot_basics_themes",
    "title": "30  ggplot の基本",
    "section": "30.9 テーマ",
    "text": "30.9 テーマ\nggplot2 パッケージの優れた点の 1 つは、プロットを自由にコントロールできることです-何でも定義できます！前述したように、データの形や幾何学的形状に関係のないプロットのデザインは、theme() 内で調整されます。例えば、プロットの背景色、グリッドラインの有無、テキスト（タイトル、サブタイトル、キャプション、軸テキスト…）のフォント／サイズ／色／配置などです。これらの調整は、次の 2 つの方法で行うことができます。\n\n全体的な調整を行うための完全なテーマ theme_() の追加 - theme_classic() 、theme_minimal() 、theme_dark() 、theme_light() 、theme_grey() 、theme_bw() などがあります。\n\ntheme() 内でプロットの個別の要素を調整する\n\n\n完全なテーマ\n完全なテーマ関数の使い方は複雑ではなく非常に簡単なので、ここではその機能を紹介し、詳細な説明を省略します。なお、theme() による微調整は、完全なテーマを使用した後に行う必要があります。\n完全なテーマの終わりに、空の括弧をつけて書いてください。\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModify theme\ntheme() は多数の引数を設定することができ、それぞれの設定がプロットの特定の要素を編集します。すべての引数を網羅することはできませんが、一般的なパターンを説明し、必要な引数名を見つける方法を示します。基本的な構文は以下の通りです。\n\ntheme() 内で、編集したいプロット要素の引数名を plot.title = のように書きます。\nその引数に element_() を与えます。\nよく使うのは element_text() ですが、キャンバスの背景色を指定する element_rect() や、プロット要素を削除する element_blank() などもあります。\n\n\n\nelement_() の中で、引数の設定を書いてあなたの望む微調整を行ってください。\n\nさて、ここまでの説明はかなり抽象的でしたので、いくつか例を挙げてみましょう。\n下のプロットはとてもくだらなく感じるかもしれませんが、プロットを調整するための様々な方法を示すことができます。\n\nまず上で定義した age_by_wt というプロットに theme_classic() を追加します。\n\nより細かい調整のために、theme() を追加し、調整する各プロット要素に 1 つの引数を加えます。\n\n引数を logical sections で整理すると良いでしょう。以下に使用されている引数のいくつかを説明します。\n\nlegend.position = は、“bottom” 、“top” 、“left” 、“right” といった単純な値を受け付ける点で独特です。しかし、一般的にテキスト関連の引数は、 element_text() 内に詳細を記述する必要があります。\n\nelement_text(size = 30) でタイトルの大きさを設定します。\n\nelement_text(hjust = 0) でキャプションの水平方向の配置（右から左へ）を設定します。\n\nサブタイトルのイタリック化を element_text(face = \"italic\") で設定します。\n\n\nage_by_wt + \n  theme_classic()+                                 # 事前に設定されたテーマの調整\n  theme(\n    legend.position = \"bottom\",                    # 凡例を下に移動\n    \n    plot.title = element_text(size = 30),          # タイトルのサイズを30に\n    plot.caption = element_text(hjust = 0),        # 左揃えのキャプション\n    plot.subtitle = element_text(face = \"italic\"), # サブタイトルを斜体に\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # x 軸テキストのみの調整\n    axis.text.y = element_text(size = 15),         # y 軸テキストのみの調整\n    \n    axis.title = element_text(size = 20)           # 両方の軸の調整\n    )     \n\n\n\n\n\n\n\n\nここでは、特によく使われる theme() の引数を紹介します。例えば、.x や .y を付加して 1 つの軸だけに変更を適用するなど、いくつかのパターンに気づくでしょう。\n\n\n\n\n\n\n\ntheme() の引数\n調整する内容\n\n\n\n\nplot.title = element_text()\nタイトル\n\n\nplot.subtitle = element_text()\nサブタイトル\n\n\nplot.caption = element_text()\nキャプション（ファミリー、フェイス、カラー、サイズ、アンル、vjust、hjust…）\n\n\naxis.title = element_text()\n軸タイトル（ x と y の両方）（サイズ、面、角度、色…）\n\n\naxis.title.x = element_text()\n軸タイトル x 軸のみ（ y 軸のみの場合は .y を使用）\n\n\naxis.text = element_text()\n軸のテキスト（xとyの両方）\n\n\naxis.text.x = element_text()\n軸テキスト x 軸のみ ( y 軸のみの場合は .y を使用）\n\n\naxis.ticks = element_blank()\n軸の目盛りの削除\n\n\naxis.line = element_line()\n軸線（色、サイズ、線の種類：実線、破線、点線など）\n\n\nstrip.text = element_text()\nファセットストリップテキスト（色、面、サイズ、角度など）\n\n\nstrip.background = element_rect()\nファセットストリップ（フィル、カラー、サイズなど）\n\n\n\nしかし、テーマの引数は非常に多いです。これら全てをどうやって覚えればよいのでしょうか？心配しないでください。すべてを覚えるのは不可能です。幸いなことに、あなたを助けるためのツールがいくつかあります。\n引数に関する完全なリストは、テーマの修正に関する tidyverse パッケージの文書にあります。\n&lt;style=“color: darkgreen;”&gt;ヒント：ggplot2 パッケージから theme_get() を実行すると、90 以上の theme() 引数のリストがコンソールに表示されます。\n\n&lt;style=“color: darkgreen;”&gt;TIP： もしプロットの要素を削除したくなったら、theme() を通して行うこともできます。element_blank() を引数に渡せば、その要素は完全に消えてしまいます。凡例については、legend.position = \"none\" と設定します。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#色",
    "href": "new_pages/ggplot_basics.jp.html#色",
    "title": "30  ggplot の基本",
    "section": "30.10 色",
    "text": "30.10 色\nggplot tipsの章のカラースケールの項をご覧ください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#ggplot2へのパイピング",
    "href": "new_pages/ggplot_basics.jp.html#ggplot2へのパイピング",
    "title": "30  ggplot の基本",
    "section": "30.11 ggplot2へのパイピング",
    "text": "30.11 ggplot2へのパイピング\nパイプを使ってデータをクリーニング・変換すると、変換したデータを ggplot() に簡単に渡すことができます。\n関数から関数へデータセットを渡すパイプは、ggplot() が呼ばれると + に移行します。なお、この場合、パイプでつながれたデータセットとして自動的に定義されるので、data = 引数を指定する必要はありません。\nこれは、次のようになります。\n\nlinelist %&gt;%                                                     # linelist から始めます\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # 列を選択します\n  pivot_longer(                                                  # 縦長のデータに転回します\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # 欠測値を置換します\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  \n  ggplot(                                                        # ggplotの開始！\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#連続データのプロット",
    "href": "new_pages/ggplot_basics.jp.html#連続データのプロット",
    "title": "30  ggplot の基本",
    "section": "30.12 連続データのプロット",
    "text": "30.12 連続データのプロット\nこの章では、連続データをプロットする多くの例を見てきました。ここでは、これらを簡単に整理し、いくつかのバリエーションを紹介します。 ここで扱う可視化は以下の通りです。\n\n1 つの連続変数のプロット：\n\nヒストグラム、連続変数の分布を示す典型的なグラフ。\n箱ひげ図（Box and Whiskerとも呼ばれる）、25、50、75 パーセントタイル、分布の最後尾、外れ値（重要な制限）を示します。\nジッタープロット、すべての値を ‘ジッター’ された点として表示し、2 つの値が同じであっても、（ほとんど）すべてを見ることができます。\nバイオリンプロット、連続変数の分布を、‘バイオリン’ の対称的な幅に基づいて表示します。\nSinaプロット、ジッタープロットとバイオリンプロットを組み合わせたもので、個々の点が分布の対称的な形で表示されます（ ggforce パッケージを使用）。\n\n2 つの連続変数の散布図\n3 つの連続変数のヒートマップ（ ヒートマップ の章へのリンク）\n\n\nヒストグラム\nヒストグラムは棒グラフに似ていますが、連続変数の分布を測定するという点で異なります。「棒」の間にはスペースがなく、geom_histogram() には 1 つの列しか与えられません。\n以下は、ヒストグラムを生成するためのコードです。ヒストグラムは、連続データを範囲に分け、高さの異なる隣り合った棒で表示します。これは geom_histogram() を使って行われます。geom_histogram() 、geom_bar() 、geom_col() の違いについては、ggplot の基本の章の 「棒グラフ」の項を参照してください。\nここでは、症例の年齢分布を表示します。mapping = aes() で、分布を見たい列を指定します。この列は、x 軸にも y 軸にも割り当てることができます。\n行は、数値化された年齢に基づいて「階級」に割り当てられ、これらの階級は棒でグラフ化されます。bins = で階級の数を指定すると、ヒストグラムの最小値と最大値の間に等間隔でブレークポイントが置かれます。bins = が指定されていない場合は、適切な階級の数が推測され、プロットの後にこのメッセージが表示されます。\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nbins = に階級の数を指定したくない場合は、代わりに軸の単位で binwidth = を指定することができます。ここでは、さまざまな階級と階級幅を示す例をいくつか紹介します。\n\n# A) 一般的なヒストグラム\nggplot(data = linelist, aes(x = age))+  # x 変数を与えます\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) より多い階級\nggplot(data = linelist, aes(x = age))+  # x 変数を与えます\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) より少ない階級\nggplot(data = linelist, aes(x = age))+  # x 変数を与えます\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n# D) より多い階級\nggplot(data = linelist, aes(x = age))+  # x 変数を与えます\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n滑らかに描画した各階級の割合を見るには、geom_density() を使用します。\n\n# 平滑化した割合の軸\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# 積み上げ・平滑化した割合の軸\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n（連続した列のデータの）「積み上げられた」ヒストグラムを得るには、以下のいずれかの方法があります。\n\ngeom_histogram() の fill = 引数を aes() 内で使用し、グループ化された列に割り当てます。\ngeom_freqpoly() を使用します。こちらの方が読みやすいでしょう（binwidth = を設定できます）。\n\nすべての値の比率を見るには、y = after_stat(density) を設定します（この構文を正確に使用してください-あなたのデータに応じて変更しないでください）。注意：これらの比率はグループごとに表示されます。\n\nそれぞれを以下に示します（*それぞれで color = vs fill = を使用していることに注意）。\n\n#「積み上げられた」ヒストグラム\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# 頻度\nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# 割合の軸\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# 平滑化した割合の軸\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n少し楽しみたい方は、ggridges パッケージの geom_density_ridges を試してみてください（ビニエット（vignette）はこちら）。\nヒストグラムについての詳細は、tidyverse の geom_histogram() のページを参照してください。\n\n\n箱ひげ図\n箱ひげ図は一般的ですが、重要な制限があります。例えば、両峰性の分布など、実際の分布が不明瞭になることがあります。詳しくは、R graph gallery や data-to-viz article の記事を参照してください。しかし、四分位範囲と外れ値はきれいに表示されるので、分布をより詳細に表示する他の種類のグラフの上に重ねて表示することができます。\n以下に、箱ひげ図の構成要素を示します。\n\n\n\n\n\n\n\n\n\ngeom_boxplot() を使って箱ひげ図を作成する場合、通常は aes() 内で 1 つの軸（x または y）のみをマッピングします。指定された軸は、プロットが水平か垂直かを決定します。\nほとんどの geom では、aes() 内で color = や fill = などに列を視覚的特性をとして割り当てることで、グループごとにプロットを作成します。しかし、箱ひげ図の場合は、グループ化された列を割り当てられていない軸（ x または y ）に割り当てることで実現します。下のコードは、データセット内のすべての年齢値を箱ひげ図にしたもので、次のコードは、データセット内の（欠損していない）性別ごとに 1 つの箱ひげ図を表示するものです。NA（欠損）の値は、削除しない限り、別の箱ひげ図として表示されることに注意してください。この例では、各プロットが異なる色になるように、outcome の列を fill に設定していますが、これは必須ではありません。\n\n# A) 箱ひげ図\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # y 軸だけマッピング ( x はなし)\n  labs(title = \"A) Overall boxplot\")\n\n# B) グループごとの箱ひげ図\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # 凡例を除く\n  labs(title = \"B) Boxplot by gender\")      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n散布図の端に箱ひげ図を追加するコード（“marginal” プロット）については、ggplot のヒントの章をご覧ください。\n\n\nバイオリンプロット、ジッタープロット、sinaプロット\n以下は、分布を示すバイオリンプロット（geom_violin）とジッタープロット（geom_jitter）を作成するコードです。aes() 内にこれらのオプションを挿入することで、塗りつぶしや色もデータによって決定されるように指定できます。\n\n# A) グループごとのジッタープロット\nggplot(data = linelist %&gt;% drop_na(outcome),      # 欠損値を除く\n       mapping = aes(y = age,                     # 連続値\n           x = outcome,                           # グループ化する変数\n           color = outcome))+                     # 色の変数\n  geom_jitter()+                                  # ジッタープロットを作成\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) グループごとのバイオリンプロット\nggplot(data = linelist %&gt;% drop_na(outcome),       # 欠損値を除く\n       mapping = aes(y = age,                      # 連続値\n           x = outcome,                            # グループ化する変数\n           fill = outcome))+                       # 塗りつぶしの変数\n  geom_violin()+                                   # バイオリンプロットを作成\n  labs(title = \"B) violin plot by gender\")    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggforce パッケージの geom_sina() を使って、この 2 つを組み合わせることができます。sinaは、ジッターポイントをバイオリンプロットの形でプロットします。バイオリンプロットに重ねて表示すると（透明度を調整して）、視覚的に解釈しやすくなります。\n\n# A) グループごとの sina プロット\nggplot(\n  data = linelist %&gt;% drop_na(outcome), \n  aes(y = age,           # 数値の変数\n      x = outcome)) +    # グループ化する変数\n  geom_violin(\n    aes(fill = outcome), # バイオリンの背景の色\n    color = \"white\",     # 白の輪郭\n    alpha = 0.2)+        # 透過度\n  geom_sina(\n    size=1,                # ジッターのサイズの変更\n    aes(color = outcome))+ # 点の色\n  scale_fill_manual(       # death/recoverごとにバイオリンの背景の色\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # death/recoverごとに点の色\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # グレイの背景の削除\n  theme(legend.position = \"none\") +                # 不要な凡例の削除\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      \n\n\n\n\n\n\n\n\n\n\n2 つの連続変数\n同様の構文で geom_point() を使用すると、2 つの連続変数を互いに散布図にプロットすることができます。これは、分布ではなく実際の値を示すのに便利です。年齢と体重の基本的な散布図を (A) に示します。(B) では、facet_grid() を使って、linelist の 2 つの連続変数の関係を示しています。\n\n# weight と age の基本的な散布図 \nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# 性別とエボラのアウトカムごとの weight と age の基本的な散布図\nggplot(data = linelist %&gt;% drop_na(gender, outcome), # gender/outcome について欠損値がないものを保持\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 つの連続変数\n3 つの連続変数を表示するには、fill = 引数を利用してヒートプロットを作成します。各「セル」の色は、3 つ目の連続データの列の値を反映します。詳しくはggplot のヒントの章と、ヒートマップの章に例があります。\nR で 3D プロットを作成する方法はありますが、実践的な疫学では解釈が難しいことが多く、意思決定にはあまり役に立ちません。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#カテゴリカルなデータのプロット",
    "href": "new_pages/ggplot_basics.jp.html#カテゴリカルなデータのプロット",
    "title": "30  ggplot の基本",
    "section": "30.13 カテゴリカルなデータのプロット",
    "text": "30.13 カテゴリカルなデータのプロット\nカテゴリカルなデータには、文字値、ロジカル値（TRUE ／ FALSE）、因子（因子（ファクタ）型データの章を参照）などがあります。\n\n準備\n\nデータの構造\nカテゴリカルなデータについて最初に理解すべきことは、それが linelist の症例のような生の観測値として存在しているのか、それとも数や割合を保持するようやくまたは集約したデータフレームとして存在しているのかということです。データの状態によって、使用するプロット関数が変わります。\n\nデータが生の観測値で、観測ごとに 1 行の場合は、 geom_bar() を使用するでしょう。\nデータがすでにカウントや割合に集約されている場合は、geom_col() を使用するでしょう。\n\n\n\n列のデータ型と値の順序\n次に、プロットしたい列のデータ型を調べます。ここでは、まず base R の class() を使って hospital を、そして janitor パッケージの tabyl() を使って調べます。\n\n# hospital 列のデータ型を確認する - それは文字列である\nclass(linelist$hospital)\n\n[1] \"character\"\n\n# 病院の列の中の値と割合を見る\nlinelist %&gt;% \n  tabyl(hospital)\n\n                             hospital    n    percent\n                     Central Hospital  454 0.07710598\n                    Military Hospital  896 0.15217391\n                              Missing 1469 0.24949049\n                                Other  885 0.15030571\n                        Port Hospital 1762 0.29925272\n St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n\n\nデフォルトの設定では、アルファベット順に並んだ病院名が文字として表示されていることが確認できます。‘other’ と ‘missing’ の値がありますが、これらは、内訳を表示する際に最後に表示するサブカテゴリにする方が好ましいです。そこで、この列を因子型に変更し、並び替えを行います。この内容については、因子（ファクタ）型データの章で詳しく説明しています。\n\n# 因子に変換し、順序を定義することで、\"Other\" と \"Missing\" が最後になります\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\n\n\nlevels(linelist$hospital)\n\n[1] \"St. Mark's Maternity Hospital (SMMH)\"\n[2] \"Port Hospital\"                       \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Other\"                               \n[6] \"Missing\"                             \n\n\n\n\n\ngeom_bar()\n棒の高さ（または積み重ねられた棒の高さ）にデータの関連する行の数を反映させたい場合は、geom_bar() を使用します。これらの棒は、 width = が調整されない限り、棒の間に隙間ができます。\n\n軸列の割り当ては 1 つだけにしてください（通常は x 軸）。x と y を指定すると、Error: stat_count() can only have an x or y aesthetic. が表示されます。\nmapping = aes() 内で fill = の割り当てを追加することで、積み上げ棒グラフを作成できます。\n反対側の軸は、行数を表すため、デフォルトでは “count” というタイトルになります。\n\n下の例では、y 軸に outcome を割り当てていますが、x 軸にしても問題ありません。文字の値が長い場合は、棒を横にして凡例を下に配置した方が見栄えが良い場合があります。この場合、fct_rev() で反転させ、missing と other を一番下にしています。\n\n# A) 全症例のアウトカム\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) 病院ごとの全症例のアウトカム\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_col()\n棒グラフの高さ（または積み重ねられた棒グラフの高さ）に、データに含まれる事前に計算された値を反映させたい場合は、geom_col() を使用します。多くの場合、これらは要約や「集約」された数や割合です。\ngeom_col() に両軸の列を割り当てます。一般的に、x 軸の列は離散的で、y 軸の列は数値です。\n例えば、次のようなデータセットの outcome があるとします：\n\n\n# A tibble: 2 × 3\n  outcome     n proportion\n  &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 Death    1022       56.2\n2 Recover   796       43.8\n\n\n以下は、エボラ出血熱患者の転帰の分布を示す簡単な棒グラフを作成するための geom_col を使用したコードです。geom_col では、x と y の両方を指定する必要があります。ここで、x は x 軸に沿ったカテゴリー変数、y は生成された proportion の列の割合です。\n\n# 全ての症例のアウトカム\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\n\n\n\n\n\n\n\n\n病院別の内訳を表示するには、より多くの情報を含み、「縦に長い」形式の表が必要です。この表は、outcome と hospital を組み合わせたカテゴリーの頻度で作成します（グループ化のtipsについては、データのグループ化の章を参照）。\n\noutcomes2 &lt;- linelist %&gt;% \n  drop_na(outcome) %&gt;% \n  count(hospital, outcome) %&gt;%  # 病院別、アウトカム別の数を取得\n  group_by(hospital) %&gt;%        # 割合は病院全体に対するものなのでグループ化する\n  mutate(proportion = n/sum(n)*100) # 病院全体の割合を計算する\n\nhead(outcomes2) # データのプレビュー\n\n# A tibble: 6 × 4\n# Groups:   hospital [3]\n  hospital                             outcome     n proportion\n  &lt;fct&gt;                                &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n3 Port Hospital                        Death     785       57.6\n4 Port Hospital                        Recover   579       42.4\n5 Central Hospital                     Death     193       53.9\n6 Central Hospital                     Recover   165       46.1\n\n\nそして、フォーマットを追加した ggplot を作成します。\n\n軸の反転：coord_flip() で軸を反転させて、病院名を読めるようにしました。\n列を横に並べる：position = \"dodge\" という引数を追加し、死亡と回復の棒を重ねるのではなく、並べて表示するようにしました。積み重ねられた棒はデフォルトです。\n列の幅：‘width’ を指定して、可能な限りの幅の半分の幅で列を表示します。\n列の順序：scale_x_discrete(limit=rev) を使用して、‘Other’ と ‘Missing’ が最下部になるように、y 軸のカテゴリの順序を反転させました。scale_y_discrete ではなくそれを使ったのは、視覚的には y 軸上にあっても、病院は aes() の x 引数で述べられているからであることに注意してください。ggplot は、私たちがそうしないように指示しない限り、カテゴリーを後ろ向きに表示するようですので、このようにしています。\nその他の詳細：labs と scale_fill_color にそれぞれラベル／タイトルと色が追加されました。\n\n\n# 病院別の全症例のアウトカム\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # あらかじめ計算された割合の表示\n      y = fct_rev(hospital),          # レベル順を逆にして、一番下に Missing と other\n      fill = outcome),                # aアウトカムごとに積み上げ\n    width = 0.5)+                    # より細い棒\n  theme_minimal() +                  # 最小限のテーマ\n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # 凡例のタイトル\n       y = \"Count\",                  # y 軸のタイトル\n       x = \"Hospital of admission\")+ # x 軸のタイトル\n  scale_fill_manual(                 # 色を手動で追加\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) \n\n\n\n\n\n\n\n\n割合は二値をとるので、‘recover’ を削除して、死亡した人の割合だけを表示した方が好ましいかもしれません。この処理は単に描画の目的のためだけのものです。\ngeom_col() を日付データ（例：集計データからのエピカーブ）で使用する場合は、棒の間の「ギャップ」ラインを取り除くために、width = 引数を調整する必要があります。日次データを使用する場合は width = 1 とします。週単位の場合は、width = 7 です。月ごとに日数が異なるため、月を指定することはできません。\n\n\ngeom_histogram()\nヒストグラムは棒グラフのように見えるかもしれませんが、連続変数の分布を測定するという点で異なります。「棒」の間にはスペースがなく、geom_histogram() には 1 つの列しか与えられません。bin_width = や breaks = といったヒストグラム特有の引数があり、データの階級分け方法を指定します。上記の連続データのセクションと流行曲線（エピカーブ）の章に詳細が記載されています。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.jp.html#参考資料",
    "href": "new_pages/ggplot_basics.jp.html#参考資料",
    "title": "30  ggplot の基本",
    "section": "30.14 参考資料",
    "text": "30.14 参考資料\n特に ggplot については、膨大な量のヘルプがオンラインで提供されています。次をご覧ください。\n\nggplot2 cheat sheet\nanother cheat sheet\ntidyverse ggplot basics page\nplotting continuous variables\nR for Data Science pages on data visualization\ngraphics for communicaton",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>ggplot の基本</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html",
    "href": "new_pages/ggplot_tips.jp.html",
    "title": "31  ggplotのヒント",
    "section": "",
    "text": "31.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#準備",
    "href": "new_pages/ggplot_tips.jp.html#準備",
    "title": "31  ggplotのヒント",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードにより必要なパッケージを読み込みます。このハンドブックでは pacman パッケージの p_load() を使うことで、パッケージのインストールと読み込みを同時に行っています。インストールされたパッケージの読み込みはRの基本パッケージ base に含まれる library() でも可能です。詳細はR の基礎の章を参照してください。\n\npacman::p_load(\n  tidyverse,      # ggplot2およびその他の関数\n  rio,            # 読み込み・書き出し\n  here,           # ファイル位置指定\n  stringr,        # 文字の操作\n  scales,         # 数値の操作\n  ggrepel,        # スマートなラベル作成\n  gghighlight,    # 図の一部のハイライト\n  RColorBrewer    # 色スケール\n)\n\n\n\nデータの読み込み\nこのページでは、エボラウイルスパンデミックのシミュレーションデータから、症例リストを読み込みます。チュートリアルに沿って操作したい場合は、こちらのリンクから整頓されたラインリスト（.rdsファイル）をダウンロードしてください。 rio パッケージの import() を使ってデータを読み込みます（この関数は.xlsx、.csv、.rdsなど多くのファイル形式を処理できます。詳細はインポートとエクスポートの章を参照してください）。\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\n以下にラインリストの最初の 50 行を表示します。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#ggplot_tips_colors",
    "href": "new_pages/ggplot_tips.jp.html#ggplot_tips_colors",
    "title": "31  ggplotのヒント",
    "section": "31.2 color、fill、座標軸などのスケール",
    "text": "31.2 color、fill、座標軸などのスケール\nggplot2 で描画する図のエステティック属性（size、color、shape、fill、座標軸など）をデータフレームの列に対応させるとき、それぞれの “scale” を操作することで、どのように図に反映するかを詳細に調整することができます。\n\n31.2.1 配色\nggplot2 を使う上で最初に躓きやすいものが配色の調整です。この節では点や線、棒グラフやタイルなど、図のオブジェクト（geoms/shapes）の配色を扱うことに注意してください。テキストやタイトル、背景などの色の調整に関しては ggplot の基礎の章のテーマの節を参照してください。\n図のオブジェクトの “色” を調整するとき、影響されるエステティクスパラメータは color =（外側の色）もしくは fill =（内側の色）です。geom_point() では例外的に color =のみを調整することで、点の色（内と外両方）を操作します。\n色を指定するには、R が認識できる \"red\" のような色の名前（こちらのリストを参照するか、?colors コマンドで一覧が表示できます）か、\"#ff0505\" のような16進コードを用います。\n\n# ヒストグラム\nggplot(data = linelist, mapping = aes(x = age))+       # データと軸を指定\n  geom_histogram(              # ヒストグラムを表示\n    binwidth = 7,                # ビンの幅\n    color = \"red\",               # ビンの外側の色\n    fill = \"lightblue\")          # ビンの内側の色\n\n\n\n\n\n\n\n\n前章 ggplot の基礎のデータを図にマップするの章で示した通り、fill = や color = などのエステティック属性は mapping = aes() の外側と内側どちらからでも定義できます。aes() の外側で定義する場合、値は定数でなければならず（例 color = \"blue\"）、その geom で描画される全てのデータポイントに適応されます。内側から定義する場合、エステティック属性は color = hospital のようにデータフレームの列に対応され、描画のされ方は各行の値に依存します。以下にいくつかの例を示します：\n\n# 点と線の色を単一色で指定する\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# 連続数からなる列に色を対応させる\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# 離散数からなる列に色を対応させる\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# 棒グラフのfillを離散数からなる列、colorを単一色で指定する\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nスケール\n列をエステティクスに対応させると（例 x =、y =、fill =、color =…）、 図にスケールとレジェンドが加わります。上記の例を見ると、スケールが連続数、離散数、日付など、スケールが対応する列のデータ型によって変化する様子が分かると思います。列に対応するエステティクスが複数あるときは、スケールもその数だけ存在します。\nスケールは一連の scales_() 関数を使うことで操作することができます。これらの関数は scale_AESTHETIC_METHOD() のように、3 つの部分からなります：\n\n最初の部分 scale_() は共通です。\n2 つ目の部分 AESTHETIC はスケールを調整したいエステティック属性（_fill_、_shape_、_color_、_size_、_alpha_…) が入ります - ここには _x_ や _y_ も含まれます。\n\n最後に来る METHOD は列のデータ型または目的に応じて _discrete()、continuous()、_date()、_gradient()、_manual() などが入ります。その他のオプションもありますが、ここに挙げたものが最もよく使われます。\n\nスケールを操作する際は、適切な関数を使うことに気をつけてください。間違った関数を使うと、狙った結果が得られません。複数のスケールがある場合も、複数の対応する関数を用いてそれらを操作することができます\n\n\nスケール引数\nスケールを操作するための関数はそれぞれ独自の、しかし一部は共通した、引数を持ちます。?scale_color_discrete などのコマンドを R コンソールで実行することで、引数の解説を表示できます。\n連続数のスケールでは、breaks = と seq()（以下の例のように to =、from =、and by =を引数に取ります）を組み合わせて操作します。さらに expand = c(0,0) を設定することで軸の両端の余白を削除できます。この引数は _x_ または _y_ を含むスケール関数のいずれでも使用できます。\n離散数のスケールでは、レベルが表示される順序を breaks =、値の表示を labels =で操作できます。以下の例のように、各引数に文字ベクトルを指定してください。また、NA は na.translate = FALSE で簡単に除外することができます。\n日付スケールについては流行曲線の章でより詳しく解説しています。\n\n\nマニュアルでの調整\n“マニュアル” スケール関数を用いることの利点の一つとして、望む色を具体的に指定することができます。これらの関数は scale_xxx_manual() の形（例：scale_colour_manual() や scale_fill_manual()）を取ります。例を通して下に挙げた引数の使用法をそれぞれ見ていきましょう。\n\nvalues =により色を指定します。\n\nna.value =により NA の色を指定します。\n\nlabels =により凡例中の表記を指定します。\n\nname =により凡例のタイトルを指定します。\n\n以下の例では、まず棒グラフを初期設定で作成します。次に 3 つのスケール – 連続数の y 軸、離散値の x 軸、fill（バー内部の色指定）のマニュアル調整 – を変更したグラフを作成します。\n\n# 初期設定 - スケール調整なし\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n\n\n\n\n\n\n# スケール調整あり\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # 背景をシンプルにする\n  \n  scale_y_continuous(                # 連続数のy軸（カウント）\n    expand = c(0,0),                 # パディングなし\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # 離散値のx軸（性別）\n    expand = c(0,0),                  # パディングなし\n    drop = FALSE,                     # 全ての因子型のレベルを表示（データに存在しないものを含む）\n    na.translate = FALSE,             # NAを図から除外\n    labels = c(\"Died\", \"Recovered\"))+ # 表記の変更\n    \n  \n  scale_fill_manual(                  # fillの色をマニュアル指定する（バー内部の色）\n    values = c(\"m\" = \"violetred\",     # 色の指定\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          # レジェンドの表記を変更（\"=\"を使い間違いをなくす）\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # レジェンドタイトル\n    na.value = \"grey\"                 # 欠測地の色を指定\n  )+\n  labs(title = \"Adjustment of scales\") # fillレジェンドのタイトルを設定\n\n\n\n\n\n\n\n\n\n\n連続数の座標軸スケール\nデータを座標軸に反映させる場合でも、スケール関数を用いて表示方法を操作することができます。よくある例として、y 軸などの座標軸を連続数からなる列に対応させる場合を紹介します。\nscale_y_continuous() を用いて、座標軸のブレークや値の表示方法を変更することを考えます。前述のとおり、breaks = により入力する一連の数字によって座標軸上のブレークポイントが指定できます。ここで入力された数字が座標軸上に表示される数字に対応します。c() ベクターにより表示させたい数字を直接入力するか、base 関数 seq() を用いて表示される数字の開始（from =）と終わり（to =）、インターバル（by =）をそれぞれ入力することができます。\n\n# 基本構文 – スケール操作なし\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n割合をパーセントで表示する\n座標軸に対応させるデータの値が割合のとき、以下のようにスケール関数中に labels = scales::percent を加えることで、簡単にパーセント表示に変更することができます。\n値の種類を文字に変更し “%” を付加することでもパーセント表示が得られますが、その場合データが連続数ではなくなるため好ましくありません。\n\n# 元々の割合表示\n#############################\nlinelist %&gt;%                                   # ラインリストから始める\n  group_by(hospital) %&gt;%                       # 病院毎にグループ分け\n  summarise(                                   # 要約列の作成\n    n = n(),                                     # グループ毎の行数\n    deaths = sum(outcome == \"Death\", na.rm=T),   # グループ毎の死亡数\n    prop_death = deaths/n) %&gt;%                   # グループ毎の死亡割合\n  ggplot(                                      # 図の作成\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# パーセント表示\n########################################\nlinelist %&gt;%         \n  group_by(hospital) %&gt;% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %&gt;% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # 割合をパーセント表示\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLog スケール\nLogスケールを用いるには、trans = \"log2\" をスケール関数に加えます。例として、各地域とその preparedness_index および累積症例数を列にもつデータフレームを考えます。\n\nplot_data &lt;- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data\n\n  region preparedness_index cases_cumulative\n1      A                8.8               15\n2      B                7.5               45\n3      C                3.4               80\n4      D                3.6               20\n5      E                2.1               21\n6      F                7.9                7\n7      G                7.0               51\n8      H                5.6               30\n9      I                1.0             1442\n\n\n地域 “I” の症例数は他と比べて遥かに高くなっています。このような場合、y 軸を log スケールにすることで、症例数が少ない地域間の差異を見やすくすることができます。\n\n# もともとのy軸スケール\npreparedness_plot &lt;- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # 地域毎のデータを表す散布図\n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # テキストラベルの追加\n  theme_minimal()\n\npreparedness_plot                  # 図を表示\n\n\n# y軸をlogスケールで表示\npreparedness_plot+                   # 上記の図を修正する\n  scale_y_continuous(trans = \"log2\") # y軸のスケールを変更\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n勾配スケール\n配色に勾配スケールを用いることで、表現の幅を広げることができます。初期設定でも美しい図が得られますが、値や切り捨て値などの詳細を調整したい場合もあります。\nここでは、コンタクトトレーシングの章で扱った各症例とその感染源の年齢を値に持つデータを用いて、連続数に対応するカラースケールの調整方法を紹介します。\n\ncase_source_relationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_age, target_age) \n\n以下の例では、ラスターヒートマップを描画します。ヒートマップについての詳細はここでは扱わず（前段落のリンクを参照してください）、カラースケールの変更方法に焦点を当てます。ggplot2 の stat_density2d() 関数についてはこちらを参照してください。fill スケールが連続数であることに注意してください。\n\ntrans_matrix &lt;- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\n\nここでいくつかのバリエーションを紹介します：\n\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nブレークポイントを変更する例も見ていきましょう：\n\nscale_fill_gradient() は2つの色（high/low）を入力に取ります\nscale_fill_gradient() は values =で長さの制限なく色のベクトルを入力に取ります。間の値は自動で補完されます。\nscales::rescale() によって各色が勾配のどの位置に置かれるかを指定できます。この関数は数字ベクトルをとり、0 から 1 の間で色の位置をリスケールします。\n\n\ntrans_matrix + \n  scale_fill_gradient(     # 2色スケール\n    low = \"aquamarine\",    # 低い値の色\n    high = \"purple\",       # 高い値の色\n    na.value = \"grey\",     # NAの色\n    name = \"Density\")+     # レジェンドタイトル\n  labs(title = \"Manually specify high/low colors\")\n\n# 3色以上の指定\ntrans_matrix + \n  scale_fill_gradientn(    # 3色（low/mid/high）\n    colors = c(\"blue\", \"yellow\",\"red\") # ベクターで色を指定\n  )+\n  labs(title = \"3-color scale\")\n\n# rescale()で色の配置を調整\ntrans_matrix + \n  scale_fill_gradientn(    # 任意の数の色を指定\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # 色の位置を0から1の間で指定\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# limitsにより配色される下限・上限値を設定\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nカラーパレット\n\nColorbrewer と Viridis\n一般的に、もし既成のカラーパレットを使いたい場合は scale_xxx_brewer もしくは scale_xxx_viridis_y 関数を利用することができます。\n‘brewer’ 関数は colorbrewer.org にあるパレットを使用します。\n‘Viridis’ 関数は viridis（色覚障害の方でも見やすい！）パレットを使用します。Viridis は “色付きでも白黒でも同様に認識でき、かつ色覚障害があるひとにも識別しやすい色調になっています。”（詳細はこちらとこちらのリンクを参照してください。）カラーパレットが連続数、離散数、もしくはビニングスケールかによって、関数の末尾を変更します（例：離散数では scale_xxx_viridis_d）。\n作成した図は色覚障害シミュレータで色覚障害があるひとへの見え方をテストするようにしましょう。赤と緑の配色は色覚障害がある場合は識別しづらいため、こちらで紹介されているように “熱冷”（赤・青）配色を代わりに用いましょう。\nここでは ggplot の基礎の章で扱った例を用いて、さまざまな配色を見ていきましょう。\n\nsymp_plot &lt;- linelist %&gt;%                                         # ラインリストから始める\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # 列を選択\n  pivot_longer(                                                  # データを伸長\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # 欠測値を入れ替える\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  ggplot(                                                        # ggplotの入力開始！\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  # 初期設定による配色で表示\n\n#################################\n# print with manually-specified colors\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # 個別に色を指定する\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # 因子型の並び替え\n    name = \"\"                           # タイトルなし\n  ) \n\n#################################\n# viridisによる離散スケールの配色\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#離散値の順序変更",
    "href": "new_pages/ggplot_tips.jp.html#離散値の順序変更",
    "title": "31  ggplotのヒント",
    "section": "31.3 離散値の順序変更",
    "text": "31.3 離散値の順序変更\nggplot2 に慣れないうちは、図に現れる離散値の順序変更はしばしば難しく感じられるでしょう。しかし、一度仕組みを理解すれば簡単です。一般的に離散値は factor として扱われ、アルファベット順に並べられます。これを並べ替えるには、因子型のレベルを表示したい順序に変更するだけです。factor の並べ替えについてのさらなる詳細は 因子（ファクタ）型の章を参照してください。\n例として年齢グループの並べ替えを見てみましょう。初期設定ではアルファベット順に従い、5-9 歳のグループは図の中央に配置されています。因子型のレベルを変更することで、これを 0-4 歳の後に移動することができます。\n\nggplot(\n  data = linelist %&gt;% drop_na(age_cat5),                         # age_cat5を欠測した行の削除\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # 因子型のレベルの変更\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n31.3.0.1 ggthemr\nggthemr パッケージも有用なパッケージの１つです。こちらの Github からチュートリアルに従ってダウンロードできます。このパッケージはとても美しいカラーパレットを使用できますが、扱える色の数に上限があるため、7-8 色以上の図を作成する際には注意が必要です。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#等高線プロット",
    "href": "new_pages/ggplot_tips.jp.html#等高線プロット",
    "title": "31  ggplotのヒント",
    "section": "31.4 等高線プロット",
    "text": "31.4 等高線プロット\n等高線プロットは、散布図だとデータポイントが多く重なり合ってしまうような場合（“オーバープロッティング” といいます）に有用です。先程の症例-感染源の年齢データを、ここでは stat_density2d() と stat_density2d_filled() を用いて地形図のように等高線プロットで描画します。統計学的な詳細についてはこちらを参照してください。\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#周辺分布",
    "href": "new_pages/ggplot_tips.jp.html#周辺分布",
    "title": "31  ggplotのヒント",
    "section": "31.5 周辺分布",
    "text": "31.5 周辺分布\ngeom_point() による散布図の外側にデータ分布を示すには、ggExtra パッケージの ggMarginal() が有用です。オブジェクトとして保存したプロットデータを、以下のように ggMarginal() に入力します。いくつかの重要な引数を示します：\n\ntype = を用いてプロットのタイプを “histogram”、“density”、“boxplot”、“violin”、“densigram” のいずれかに指定する必要があります。\n初期設定では、x 軸と y 軸両方に分布図が表示されます。どちらか一方のみにしたい場合は、margins =を “x” または “y” に設定します。\n他に設定できる引数として fill =（バーの内側の色）color =（線の色）、size =（メインの図とマージン部分の比率。数字が大きいほどマージン部分は小さくなります）があります。\nxparams =と yparams =を用いて、座標軸を指定してその他のパラメータを設定できます。以下の例では、軸ごとに異なるビンの幅を指定しています。\n\n周辺分布にデータ内のグループ（ggplot() 内のエステティクスで color =に指定されている列）を反映させることもできます。その場合は以下のように、ggMarginal() 内の groupColour =もしくは groupFill =を TRUE に設定します。\nより詳しい解説はこちらのビネット、R グラフギャラリーもしくは ?ggMarginal を R コンソールに入力して表示できるページを参照してください。\n\n# ggExtraのインストールと読み込み\npacman::p_load(ggExtra)\n\n# 体重と年齢を基本の散布図で図示する\nscatter_plot &lt;- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n\nヒストグラムを周辺図として追加する場合は type = \"histogram\" を指定します。さらに groupFill = TRUE と設定することで多重ヒストグラムを描画できます。\n\n# ヒストグラム\nggMarginal(\n  scatter_plot,                     # 周辺分布図を追加\n  type = \"histogram\",               # ヒストグラムを指定\n  fill = \"lightblue\",               # バー内の色を指定\n  xparams = list(binwidth = 10),    # x軸側の分布図のパラメータ\n  yparams = list(binwidth = 5))     # y軸側の分布図のパラメータ\n\n\n\n\n\n\n\n\nグループ毎に色分けされた周辺分布図：\n\n# 性別毎に色分けされた散布図\n# ggplotのcolorを性別の列に対応させる。ggMarginalのgroupFillをTRUEに設定する。\nscatter_plot_color &lt;- ggplot(data = linelist %&gt;% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n\n\n\n\n\n\n\n\nsize =によって周辺分布図のサイズを指定します。数字が小さいほど大きな周辺分布図が得られます。また color =も設定できます。以下の例は周辺分布ボックスプロットで、margins =により片方の軸にのみ表示させています：\n\n# ボックスプロット\nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # x軸側にのみ周辺分布図を表示\n  type = \"boxplot\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#スマートラベリング",
    "href": "new_pages/ggplot_tips.jp.html#スマートラベリング",
    "title": "31  ggplotのヒント",
    "section": "31.6 スマートラベリング",
    "text": "31.6 スマートラベリング\nggplot2 では図中にテキストを表示することもできます。しかし、テキストと図中のデータポイントが重なり読みづらくなってしまうということがしばしば起こります。R の base 関数ではこの問題を解決することは難しいですが、ggrepel という追加パッケージを使うことでうまく処理することができます！\nggrepel パッケージは geom_label() と geom_text() それぞれの代わりとなる新しい関数geom_label_repel() と geom_text_repel() を提供してくれます。これらの関数を基本関数の代わりに使うだけで、整ったラベルを作ることができます。これらの関数内では aes() を通常通り設定しますが、その中で label =によりラベルに使いたい列（例：患者 ID や名前など）を指定します。また str_glue() を使えば、以下の例のように複数の列を改行（\\n）で繋いでより複雑なラベルを作ることも可能です。\nいくつかのヒントを示します：\n\nmin.segment.length = 0 と設定すると常にデータポイントとラベルを繋ぐ線が描画され、逆に min.segment.length = Inf と設定すれば常に線は描画されません。\nsize = を aes() の外側で設定することで文字サイズを指定できます。\nforce =によりラベルとデータポイント間をどの程度離すかを設定できます（初期設定は 1 ）。\nfill =を aes() 内で設定することでラベルの色を指定できます。\n\nその場合、レジェンドには文字 “a” が表示されますが、これは guides(fill = guide_legend(override.aes = aes(color = NA))) により除くことができます。\n\n\nより詳細なチュートリアルはこちらを参照してください。\n\npacman::p_load(ggrepel)\n\nlinelist %&gt;%                                               # ラインリスト\n  group_by(hospital) %&gt;%                                   # 病院でグループ分け\n  summarise(                                               # 病院毎にまとめた新しいデータフレームを作る\n    n_cases = n(),                                           # 病院毎の症例数\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # 病院毎の発症までの平均日数\n  ) %&gt;% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # ggplotにデータを入力\n  geom_point(size = 2)+                                    # 散布図\n  geom_label_repel(                                        # ラベルの追加\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # ラベルの表示を指定\n      ), \n    size = 3,                                              # ラベルの文字サイズ\n    min.segment.length = 0)+                               # 全てのデータポイントとラベル間に線を表示              \n  labs(                                                    # 図と座標軸のタイトル\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\n\n\n\n\n\n\n\n\n一部のデータポイントのみをラベルすることもできます - 通常の ggplot() 構文内の data =により、それぞれの geom レイヤーに異なるデータセットを指定します。以下の例では全てのデータポイントを描画しつつ、一部のデータポイントのみをラベルします。\n\nggplot()+\n  # 全ての点を灰色にする\n  geom_point(\n    data = linelist,                                   # 全てのデータポイントを描画\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # 灰色・半透明の点\n  \n  # 一部の点を黒くする\n  geom_point(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # フィルターしたデータを指定\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # 初期設定通り黒・透明化なしの点\n  \n  # 一部の点にラベルを付加する\n  geom_label_repel(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # フィルターしたデータのみをラベルする\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # 臨床結果ごとに色分け\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # str_glue()によりラベルを作成\n    min.segment.length = 0) +                                  # 全てのデータポイントとラベル間に線を表示\n  \n  # レジェンド内の文字\"a\"を削除\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # 座標軸のラベル\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#時間スケール",
    "href": "new_pages/ggplot_tips.jp.html#時間スケール",
    "title": "31  ggplotのヒント",
    "section": "31.7 時間スケール",
    "text": "31.7 時間スケール\nggplot で時間スケールを使用すると聞くと難しく感じるかもしれませんが、いくつかのキーになる関数を用いることでとても簡単に行うことができます。時間や日付を扱う際は、変数が正しくフォーマットされていることを確認してください。詳細は日付の扱いの章または前章 ggplotの基礎内流行曲線の章を参照してください。\nggplot2 で日付を扱う際に最も有用な関数はスケール関数（scale_x_date()、scale_x_datetime()、そしてそれらに対応する y 軸用の関数）です。これらの関数を用いることで、軸ラベルの個数やフォーマットを変更することができます。日付のフォーマットについては、working with dates をまた参照してください！date_breaks や date_labels といった引数により日付の表示方法を変更することができます：\n\ndate_breaks により軸スケールの区切り間隔を変更できます。入力は文字列を用います（例：\"3 months\" や \"2 days\" など）。\ndate_labels により日付の表示方法を変更できます。ここでも文字列でフォーマットを指定します（例：“%b-%d-%Y”）。\n\n\n# 観測された発症日から流行曲線を作成する\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # 1ヶ月ごとに軸ラベルを表示する\n    date_breaks = \"1 months\",\n    # 月・日をラベルとして表示する\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\nx 軸に日付ラベルを作成するかんたんな方法のひとつは、scales パッケージの関数 label_date_short() を scale_x_date() の labels = 引数として渡すことです。関数 label_date_sort() は自動的に日付ラベルを作成します。（詳しくはこちらのリンクをご参照ください）。この関数のもうひとつの利点として、日次、週次、月次、年次と時間経過とともにラベルが自動的に調整されます。\n本ハンドブックの 32 章 流行曲線（エピカーブ）の複数の日付ラベル節に詳しい例示がありますが、参考のため以下にも例示します。\n\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    labels = scales::label_date_short()  # 自動的に日付ラベルを作成\n  )+\n  theme_classic()",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#特定の要素を強調する",
    "href": "new_pages/ggplot_tips.jp.html#特定の要素を強調する",
    "title": "31  ggplotのヒント",
    "section": "31.8 特定の要素を強調する",
    "text": "31.8 特定の要素を強調する\n図中の特定の要素を強調することで、全てのデータポイントを表示しつつ、任意の変数や事象について注意を引くことができます。これについて ggplot2 の基本関数はあまり得意ではありませんが、追加パッケージ gghighlight により簡単に行うことができます。このパッケージは ggplot の基本構文と容易に組み合わせることができます。\ngghighlight パッケージの gghighlight() を用います。入力には論理文を用います – これにより様々な要素を強調した図を作成することができますが、ここではラインリストから年齢の分布を、臨床結果を強調しながら図示してみましょう。\n\n# gghighlightを読み込む\nlibrary(gghighlight)\n\n# outcome列内のNA値を\"Unknown\"で入れ替える\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# 全症例の年齢分布をヒストグラムで図示\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # 患者が亡くなっている症例の分布を強調する\n\n\n\n\n\n\n\n\nこれはファセットプロットとの相性も良いです – ファセットに用いた変数を図ごとに強調することができます！以下では週ごとの症例数を用いて流行曲線を作成し、病院ごとに分けて描画します（color =と facet_wrap() に hospital を設定）。\n\n# 週ごとの症例数をヒストグラムで表示\nlinelist %&gt;% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %&gt;% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # ファセット図毎に該当病院を強調\n  facet_wrap(~hospital)                              # 病院毎にファセットする",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#複数のデータセットをプロットする",
    "href": "new_pages/ggplot_tips.jp.html#複数のデータセットをプロットする",
    "title": "31  ggplotのヒント",
    "section": "31.9 複数のデータセットをプロットする",
    "text": "31.9 複数のデータセットをプロットする\n複数のデータセットの座標軸を正確に揃えることは簡単ではありません。以下の 2 つのアプローチのどちらかを取りましょう：\n\n図を作成する前にデータを統合し、元のデータセットを区別するための列を追加する。\ncowplot などのパッケージを用いて複数の図を組み合わせる（以下参照）。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#図の組み合わせ",
    "href": "new_pages/ggplot_tips.jp.html#図の組み合わせ",
    "title": "31  ggplotのヒント",
    "section": "31.10 図の組み合わせ",
    "text": "31.10 図の組み合わせ\n複数の図を組み合わせるのに非常に便利な 2 つのパッケージが cowplot と patchwork です。 このページでは主に cowplot に焦点を当てつつ、patchwork についても一部で使用例を紹介します。\ncowplot のイントロダクションはこちらで見ることができます。含まれる各関数の詳細についてはこちらを参照してください。ここでは一部の最もよく用いられるものについて使用例を見ていきます。\ncowplot パッケージは ggplot2 と並行して使われます - cowplot を使うことで、ggplot2 で作成した複数の図と凡例を 1 つにまとめて表示することができます。入力にRの base 関数で作成した図を用いることも可能です。\n\npacman::p_load(\n  tidyverse,      # データの整理と図示\n  cowplot,        # 図の組み合わせ\n  patchwork       # 図の組み合わせ\n)\n\n図のファセット（ggplot の基礎の章を参照）は便利な手法ではあるものの、表示方法に限りがあるため、望んだ図が得られないことがままあります。代わりに、複数の図を組み合わせて 1 つの図にしてしまうことも可能です。そのためのパッケージとして cowplot、gridExtra、patchwork の3つがあり、どれも大まかに同様の結果を得ることができます。ここでは cowplot に焦点を当て、使い方を見ていきましょう。\n\nplot_grid()\ncowplot パッケージには多くの関数がありますが、そのうち最も使いやすいものが plot_grid() です。この関数は、複数の図をグリッドにそって並べることができます。ここではマラリアデータセットを使って、地区毎の症例数、および時間毎の流行曲線を並べて図示する例を見ていきます。\n\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# 地区毎の症例数を棒グラフで図示\np1 &lt;- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# 時間毎の流行曲線\np2 &lt;- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 2行1列で2つの図を並べる\n                   ncol = 1,\n                   nrow = 2,\n                   # 上下の図の高さの比を2:3に設定\n                   rel_heights = c(2, 3))\n\n\n\n\n\n\n\n\n\n\n凡例を組み合わせる\nもし複数の図が同じ凡例を持つ場合、それらを統合することは比較的単純です。上記の例と同様 cowplot により図を組み合わせ、そのうちの 1 つを残してレジェンドを取り除きます。\n複数の図が異なるレジェンドを持つ場合は、以下のアプローチを取ります：\n\ntheme(legend.position = \"none\") を用いてレジェンドを持たない図を作成する。\n以下の例のように get_legend() を用いて各図 – レジェンドを表示するよう変更したもの - からレジェンドを抜き出す。\n抽出したレジェンドをレジェンドパネルにまとめる。\n図とレジェンドパネルを組み合わせる。\n\n先ずは、2 つの図をレジェンドを統合せずに組み合わせます（美しくなく非効率なスペースの使い方）：\n\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\n\nplot_grid() でレジェンドはそのままに図を組み合わせます：\n\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n\n\n\n\n\n\n\n\n次に、凡例を統合した場合を見てみましょう。初めに凡例なしの図を作成し（theme(legend.position = \"none\"）、cowplot パッケージの get_legend() により凡例を別に抽出します。凡例を抜き出す際には、+ シンボルを用いて、配置（“right”）やタイトルも指定しながら凡例を戻し入れる必要があります。最後に2つの凡例を上下に結合し、先に作成した図と組み合わせて完成です！\n\n# レジェンドなし図1を作成\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# レジェンドなし図2を作成\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# p1（p1 + レジェンド）からレジェンドを抜き出す\nleg_p1 &lt;- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # レジェンドの抜き出し\n                                      legend.justification = c(0,0.5))+ # レジェンドの配列\n                                labs(fill = \"Outcome\"))                 # レジェンドタイトル\n# p2（p2 + レジェンド）からレジェンドを抜き出す\nleg_p2 &lt;- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # レジェンドの抜き出し\n                                      legend.justification = c(0,0.5))+  # レジェンドの配列\n                                labs(fill = \"Age Category\"))             # レジェンドタイトル\n\n# レジェンド配置用の空白図を作成\n#blank_p &lt;- patchwork::plot_spacer() + theme_void()\n\n# レジェンドパネルを作成。2つのレジェンドを上下に組み合わせる（もしくは上記コメント中のplot_spacer()を用いる）\nlegends &lt;- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# 2つの図とレジェンドパネルを組み合わせる\ncombined &lt;- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # 図を表示\n\n\n\n\n\n\n\n\n上記のアプローチはこちらのポストを参照し、 レジェンド配置のための小さな修正をこちらを参考に加えています。\nコラム：cowplot の “cow” は cowplot パッケージ製作者の名前 - Claus O. Wilke - から来ています。\n\n\n図の中に図を挿入する\ncowplot では図の内部にさらに違う図を表示することもできます。使用に際していくつかの注意点があります：\n\ncowplot パッケージの theme_half_open() でメインの図を指定します；凡例は図の上部もしくは下部に配置すると良いでしょう。\n埋め込む図を作成します。凡例の必要のない図を用いることが好ましいです。さらに以下のように、element_blank() を用いてプロットの theme 要素を削除することができます。\nggdraw() によりメインの図と組み合わせます。さらに draw_plot() により内部プロットの座標（埋め込む図の左下隅の位置 x と y）、高さと幅をメイン図との比で指定します。\n\n\n# メイン図の作成\nmain_plot &lt;- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# 埋め込み図の作成\ninset_plot &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# 2つの図を組み合わせる\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)\n\n\n\n\n\n\n\n\nより深く知りたい場合は、以下のビニエット（vignette）を参照してください：\nWilke 研究室\ndraw_plot() 使用の手引き",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#二重座標軸",
    "href": "new_pages/ggplot_tips.jp.html#二重座標軸",
    "title": "31  ggplotのヒント",
    "section": "31.11 二重座標軸",
    "text": "31.11 二重座標軸\nggplot2 を使用していて、1 つの図に 2 つ目の y 軸を表示したい場合があります。データの可視化において、そのような二重 y 軸の正当性は議論の的であり、またしばしば推奨されないものではありますが、あなたの上司がそれを求めてくるかもしれません。ここでは、それを実現する 1 つの方法を紹介します：cowplot を用いて、異なる y 軸を持つ 2 つの図を組み合わせましょう。\nこの方法では、2 つの独立した図を作成します – y 軸を 1 つは左側に、もう 1 つは右側に持つようにします。どちらも theme_cowplot() を使用して作成し、x 軸は同一でなくてはなりません。次に、作成した 2 つの図を重ね合わせます。これらは cowplot の持つ機能の内のほんの 1 つですが、こちらのページでさらに詳しく解説されています。\n以下では例として、流行曲線を週毎の死亡患者数のパーセンテージを示す折れ線グラフと重ね合わせます。この例のように日付を x 軸に持つ図を重ね合わせるのは、例えば棒グラフを他の図と重ね合わせる場合などに比べてより複雑です。いくつか注意点を挙げます：\n\n流行曲線と折れ線グラフは、描画前に週毎の値に変換し、さらに date_breaks と date_labels が同じ値を取るようにします - これは 2 つの図が完全に同じ x 軸を持つようにするためです。\n片方の図の y 軸は scale_y_continuous() の position =によって右側に移動します。\nどちらの図も theme_cowplot() を使用します。\n\nちなみに Epidemic curves の章でも別の例 - 累積症例数と流行曲線を組み合わせ - を示しています。\n図 1 の作成\n流行曲線を作成します。ここでは geom_area() をその紹介も兼ねて使用します（曲線下面積の図示）。\n\npacman::p_load(cowplot)            # cowplotの読み込み\n\np1 &lt;- linelist %&gt;%                 # 図をオブジェクトとして保存\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # 図の表示\n\n\n\n\n\n\n\n\n図 2 の作成\n週毎の死亡患者のパーセンテージを示す折れ線グラフを作成します。\n\np2 &lt;- linelist %&gt;%         # 図をオブジェクトとして保存\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %&gt;% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # 図の表示\n\n\n\n\n\n\n\n\nalign_plots() によって2つの図の縦横（“hv”、または “h”、“v”、“none” のいずれか）を重ね合わせます。全ての軸（上下左右）についても同様に “tblr” で指定します。出力はリスト（要素 2 つ）になります。\n最後に ggdraw()（cowplot パッケージ）を用いて、aligned_plots 内の各図を指定することで 2 つの図を重ねて表示します。\n\naligned_plots &lt;- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # 2 つの図の配置を合わせリストオブジェクトとして保存\naligned_plotted &lt;- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # 重ね合わせた図を保存\naligned_plotted                                                                # 図の表示",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#役に立つパッケージ",
    "href": "new_pages/ggplot_tips.jp.html#役に立つパッケージ",
    "title": "31  ggplotのヒント",
    "section": "31.12 役に立つパッケージ",
    "text": "31.12 役に立つパッケージ\nggplot2 を使いこなすうえで、いくつかの R パッケージが非常に便利です：\n\nggplot2 を GUI 上で操作する：equisse\n“このアドインは ggplot2 を使用したインタラクティブなデータ解析を可能にします。棒グラフ、曲線、散布図、ヒストグラム、ボックスプロットや sf オブジェクトなどを作成し、できた図を書き出したり、それらを作成するためのコードを抽出することができます。”\nインストールおよびアドインの立ち上げは RStudio のメニューまたは esquisse::esquisser() コマンドから行うことができます。\nこちらの Github ページと\n使用手引きを参照してください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#その他",
    "href": "new_pages/ggplot_tips.jp.html#その他",
    "title": "31  ggplotのヒント",
    "section": "31.13 その他",
    "text": "31.13 その他\n\n数の表記\n図を作成する前に以下のコマンドを使用することで、数の科学的表記をオフにすることができます：\n\noptions(scipen=999)\n\nまたは以下のように、scales パッケージの number_format() を特定の値または列に対して使用します。\nscales パッケージに含まれる関数を用いることで、数の表記方を簡単に変更することができます。これらはデータフレームの列に対しても使用できますが、ここでは例を示すため個別の数値に対して使用しています。\n\nscales::number(6.2e5)\n\n[1] \"620 000\"\n\nscales::number(1506800.62,  accuracy = 0.1,)\n\n[1] \"1 506 800.6\"\n\nscales::comma(1506800.62, accuracy = 0.01)\n\n[1] \"1,506,800.62\"\n\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")\n\n[1] \"1.506.800,62\"\n\nscales::percent(0.1)\n\n[1] \"10%\"\n\nscales::dollar(56)\n\n[1] \"$56\"\n\nscales::scientific(100000)\n\n[1] \"1e+05\"",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.jp.html#参考文献",
    "href": "new_pages/ggplot_tips.jp.html#参考文献",
    "title": "31  ggplotのヒント",
    "section": "31.14 参考文献",
    "text": "31.14 参考文献\nインスピレーション ggplot グラフギャラリー\nデータの表示 欧州疾病予防管理センター 調査データの表示方法についてのガイドライン\nファセットとラベル ラベラーを使ったファセット図のラベル変更 ラベラー\nファクターの並べ替え fct_reorder\nfct_inorder\nボックスプロットの並べ替え\nggplot2 の変数の並べ替え\nデータサイエンスのための R - 因子型\nレジェンド\nレジェンドの並べ替え\nキャプション キャプションの整列\nラベル\nggrepel\nチートシート ggplot2 による美しい図の作り方",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>ggplotのヒント</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html",
    "href": "new_pages/epicurves.jp.html",
    "title": "32  流行曲線（エピカーブ）",
    "section": "",
    "text": "32.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#準備",
    "href": "new_pages/epicurves.jp.html#準備",
    "title": "32  流行曲線（エピカーブ）",
    "section": "",
    "text": "パッケージの読み込み\n解析に必要な標準パッケージを読み込みます。 このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R パッケージについての詳細は、R の基礎 の章を参照してください。\n\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) \n\n\n\n32.1.1 データのインポート\nこの章では2つのデータセットを使用します。\n\n流行のシミュレーションデータから作成された症例ごとのデータ（ラインリスト）\n\n同じ流行のシミュレーションデータから作成された病院ごとの症例数の集計値\n\nデータセットは、rio パッケージの import() を使ってインポートします。データをインポートする様々な方法については、データのインポート・エクスポート の章を参照してください。\nラインリスト（linelist）\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。この章の内容をお手元の環境で実行したい方は、ハンドブックとデータのダウンロード の章をご覧ください。ファイルが作業ディレクトリにある場合、ファイルパスにはファイル名のみ指定します。\n\nlinelist &lt;- import(\"linelist_cleaned.rds\") \n\n以下に、最初の 50 行を表示します。\n\n\n\n\n\n\n病院ごとの症例数\n以下のコードで、病院ごとの週別の集計数を含んだデータセットを linelist から作成します。\n\n# 集計データをRにインポート\ncount_data &lt;- linelist %&gt;% \n  group_by(hospital, date_hospitalisation) %&gt;% \n  summarize(n_cases = dplyr::n()) %&gt;% \n  filter(date_hospitalisation &gt; as.Date(\"2013-06-01\")) %&gt;% \n  ungroup()\n\n以下に、最初の 50 行を表示します。\n\n\n\n\n\n\n\n\nパラメータの設定\nレポートを作成する際に、データの現在の日付（「データ日」）を設定することができます。data_date オブジェクトにデータ日を定義することで、データセットをフィルタリングする際や脚注を書く際に用いることができます。\n\n## レポート用に日付を設定\n## メモ：Sys.Date()でも最新の日付を設定することができます\n## note: can be set to Sys.Date() for the current date\ndata_date &lt;- as.Date(\"2015-05-15\")\n\n\n\n日付の確認\n各日付列のデータ型が日付型であることを確信し、また、適切な範囲であるかを確認します。欠損値を除外（ na.rm=TRUE ）した上で range() を用いて範囲を確認することができますし、 ヒストグラムで確認する場合は hist() あるいは以下のように ggplot() を使って簡単に行うこともできます。\n\n# 発症日の範囲を確認\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#ggplot2-を用いた流行曲線",
    "href": "new_pages/epicurves.jp.html#ggplot2-を用いた流行曲線",
    "title": "32  流行曲線（エピカーブ）",
    "section": "32.2 ggplot2 を用いた流行曲線",
    "text": "32.2 ggplot2 を用いた流行曲線\nggplot() を使用して流行曲線を作成すると、より柔軟にカスタマイズできますが、多くの手順と ggplot() の動作の理解が必要です。\n症例の集計単位（週、月など）や日付軸のラベルの間隔を、_手動で_注意して制御する必要があります。\n以下の例では、linelist データセットの一部（Central Hospital の症例のみ）を使用しています。\n\ncentral_data &lt;- linelist %&gt;% \n  filter(hospital == \"Central Hospital\")\n\nggplot() を使用した流行曲線の作成は、以下の 3 つの要素に分かれます。\n\nラインリストの症例を、特定の「分割」ポイントで区別される「ビン」に集約したヒストグラム\n\n軸のスケールとそのラベル\n\nタイトル、ラベル、キャプションなど、グラフの見た目に関するテーマ\n\n\n症例のビンの指定\nここでは、症例をヒストグラムのビン（「バー」とも呼ばれる）に集約する方法を説明します。ここで重要なのは、ヒストグラムのビンへの症例の集約は、必ずしも x 軸に表示される日付と同じ間隔ではないということです。\n以下は、日次と週次の流行曲線を作成するための最も簡単なコードです。\nggplot() コマンドでは、データセットを data = で指定します。 この土台の上に、ヒストグラムの形状を + で追加します。geom_histogram() では、date_onset 列が x 軸にマッピングされるように指定します。また、geom_histogram() 内では、aes() 内ではなく、ヒストグラムの binwidth = を日単位で設定します。この ggplot2 の構文が分かりにくい場合は、ggplot の基礎 の章を参照して下さい。\n注意：binwidth = 7 を使って週別の症例数をプロットすると、7日間の最初のビンは、最初の症例で開始されます。特定の週を作成するには、以下のセクションを参照してください。\n\n# daily \nggplot(data = central_data) +          # データセットの指定\n  geom_histogram(                      # ヒストグラムの追加\n    mapping = aes(x = date_onset),     # 日付列をx軸に指定\n    binwidth = 1)+                     # 1日ごとのビンを指定\n  labs(title = \"Central Hospital - Daily\")                # タイトル\n\n# weekly\nggplot(data = central_data) +          # データセットの指定 \n  geom_histogram(                      # ヒストグラムの追加\n      mapping = aes(x = date_onset),   # 日付列をx軸に指定\n      binwidth = 7)+                   # 7日ごとのビンを指定、最初の症例から始まる（！）\n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # タイトル\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nこの Central Hospital のデータセットの最初の症例は、症状が出たのが 1 日目だったことに注目しましょう。\n\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")\n\n[1] \"Thursday 01 May, 2014\"\n\n\nヒストグラムのビンの区切りをマニュアルで指定するには、binwidth = を使用せず、代わりに breaks = に日付のベクトルを指定します。\n日付のベクトルは、R base の seq.Date() で作成します。この関数は、開始日 from = 、終了日 to = と日単位 by = を引数に取ります。例えば、以下のコマンドは、1 月 15 日から 6 月 28 日までの月ごとの日付を返します。\n\nmonthly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # 表示\n\n [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\"\n [6] \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\"\n[11] \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\"\n[16] \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n\n\nこのベクトルは、geom_histogram() に breaks = として与えることができます。\n\n# 月ごと \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # 上で定義した日付ベクトルを指定 vector of breaks                    \n  labs(title = \"Monthly case bins\")   # タイトル\n\n\n\n\n\n\n\n\nby = \"week\" を設定すると、単純な週単位の日付列を返すことができます。以下はその一例です。\n\nweekly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n\nまた、開始日と終了日を指定する代わりに、週単位のビンが最初の症例の前の月曜日から始まるようにコードを書くこともできます。以下の例では、これらの日付ベクトルを使用します。\n\n# CENTRAL HOSPITAL データにおける月曜日だけを含んだ日付ベクトル\nweekly_breaks_central &lt;- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # 最初の症例以前の月曜日の日付\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # 最後の症例以後の月曜日の日付\n  by   = \"week\")\n\n上に書かれている少し複雑なコードを紐解いてみましょう。\n\n「from」の数値（日付ベクトルの最初の日付）は以下のようにして設定されます。\n\nlubridate パッケージの floor_date() に date_onset 列の最少の値（na.rm=TRUE で欠損値を除外した min() で得られる値）を渡します。この時に floor_date() に「week」を指定すると、各週の開始日が月曜日 (week_start = 1) であるとした場合に、その症例の 「week」 の開始日が返されます。\n\n同様に、「to 」の数値（日付ベクトルの最後の日付）は、逆の関数である ceiling_date() を用いて、最後の症例の翌月曜日を返すように作成されます。\n\nseq.Date() の引数 by には、日、週、月の任意の数を指定することができます。\n\nweek_start = 7 を使用することで日曜から開始される週にすることができます。\n\nこれらの日付ベクトルは本章全体で使用するため、全体のデータに対するものも以下で定義しておきます（上記は Central Hospital のみ）。\n\n#  全体のデータにおける日付ベクトルの作成\nweekly_breaks_all &lt;- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # 最初の症例以前の月曜日の日付\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # 最後の症例以後の月曜日の日付\n  by   = \"week\")\n\nこれらの seq.Date() の出力は、ヒストグラムのビンの区切りだけでなく、ビンから独立した日付ラベルの区切りを作成するためにも使用できます。日付ラベルについては、後のセクションで詳しく説明します。\nヒント：bin breaks と date label breaks をあらかじめ名前付きのベクトルとして保存しておき、breaks = にそのベクトルを指定することで、よりシンプルな ggplot() コマンドにすることができます。\n\n\n週別流行曲線の例\n以下は日付ラベル、縦罫線を含んだ、月曜始まりの週別流行曲線を作成するための詳細なサンプルコードです。このセクションは、すぐにコードを必要とするユーザーのためのものです。それぞれの側面（テーマ、日付ラベルなど）を深く理解するためには、以降のセクションを参照して下さい。注目すべき点として以下があります。\n\nヒストグラムのビンの区切りは、上で説明したように seq.Date() で定義され、最も早い症例の前の月曜日から始まり、最後の症例の後の月曜日で終わります。\n\n日付ラベルの間隔は scale_x_date() の中の date_breaks = で指定します。\n\n日付ラベルの間の縦罫線の間隔は date_minor_breaks = で指定します。\n\n日付ラベルが正しいビンにカウントされているか確認するため geom_histogram() の closed = \"left\" オプションを指定します。\nx軸とy軸のスケールで expand = c(0,0) を使用すると、軸の両側の余分なスペースがなくなり、日付ラベルが最初のバーから始まるようにできます。\n\n\n# 月曜日ごとの集計\n#############################\n# 週ごとの日付ベクトルの作成\nweekly_breaks_central &lt;- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # 最初の症例以前の月曜日の日付\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # 最後の症例以後の月曜日の日付\n      by   = \"week\")    # 7日間隔に指定\n\n\nggplot(data = central_data) + \n  \n  # ヒストグラムの作成：ビンの分割数の指定：最初の症例の前の月曜日から始まり、最後の症例の後の月曜日を終了する\n  geom_histogram(\n    \n    # マッピング\n    mapping = aes(x = date_onset),  # 日付列をx軸にマッピング\n    \n    # ビンの分割指定\n    breaks = weekly_breaks_central, # 上で定義したビンの分割\n      \n    closed = \"left\",  # 分割の開始から症例数をカウントする\n    \n    # bars\n    color = \"darkblue\",     # 枠線の色指定\n    fill = \"lightblue\"      # 棒グラフの色の指定\n  )+ \n    \n  # x軸ラベル\n  scale_x_date(\n    expand            = c(0,0),           # X軸の前後の余分なスペースを削除\n    date_breaks       = \"4 weeks\",        # 日付ラベルと主要な縦罫線を4週ごとに表示。\n    date_minor_breaks = \"week\",           # 小縦罫線を1週ごとに表示\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # 日付ラベルのフォーマット\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # y軸の前後の余分なスペースを削除\n  \n  # テーマの指定\n  theme_minimal()+                # 背景を簡潔なものに指定\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # 脚注を左寄せに配置\n                                face = \"italic\"), # キャプションをイタリック体に指定\n    axis.title = element_text(face = \"bold\"))+    # 軸タイトルを太字に指定\n  \n  # 脚注を含んだラベル\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\n\n日曜始まりの週\ndate_breaks = \"weeks\" は月曜始まりの週に対してのみ機能するため、日曜始まりの週に対して上記の可視化を行うには、いくつかの修正が必要です。\n\nヒストグラムビンの分割点を日曜日に設定する必要があります （week_start = 7）。\n\nscale_x_date() 内で、日付ラベルと縦罫線が日曜日に揃うように、breaks = と minor_breaks = に同様の日付の分割点を設定する必要があります。\n\n例えば、日曜始まりの週に対する scale_x_date() コマンドは、以下のようになります。\n\nscale_x_date(\n    expand = c(0,0),\n    \n    # 日付ラベルと縦罫線の間隔を指定\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # 最初の症例以前の月曜日の日付\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # 最後の症例以後の月曜日の日付\n      by   = \"4 weeks\"),\n    \n    # 小縦罫線の間隔を指定 \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # 最初の症例以前の月曜日の日付\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # 最後の症例以後の月曜日の日付\n      by   = \"week\"),\n   \n    # 日付ラベルのフォーマット\n    #date_labels = \"%a\\n%d %b\\n%Y\")+         # 曜日＋日付と省略月名と年\n    label = scales::label_date_short())      # automatic label formatting\n\n\n\n\nグループ化・値による色分け\nヒストグラムのビンは、グループごとに色分けして積み重ねることができます。グループ化する列を指定するには、以下の変更を行います。詳しくは、ggplot の基礎 の章を参照してください。\n\naes() 内で、列名を group = と fill = の引数に指定します。\n\naes() の外側にある fill = の引数は、内側の引数を上書きするので削除してください。\n\naes() の内側の引数はグループごとに適用されますが、外側の引数はすべてのビンに適用されます （例えば、外側の color = で色を指定して、各ビンの枠線を同じ色で表示することができます）。\n\n以下は、aes() コマンドでヒストグラムのビンを性別でグループ化、色分けする場合のコード例です。\n\naes(x = date_onset, group = gender, fill = gender)\n\n以下で適用してみます。\n\nggplot(data = linelist) +     # データセットの指定（全病院データ）\n  \n  # ヒストグラムの作成: ビンの分割点の指定、 最初の症例の前の月曜日から始まり、最後の症例の次の月曜日で終わるように設定する\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # hospital でグループ化する\n      fill = hospital),       # hospital 毎に棒グラフを色分けする\n    \n    # ビン分割を月曜始まりの週ごとにする\n    breaks = weekly_breaks_all,   # 上のコードで定義済みの全症例に対する月曜始まりの週毎に分割する    \n    \n    closed = \"left\",          # 分割の開始から症例数をカウントする\n\n    # 枠線の色の指定\n    color = \"black\")\n\n\n\n\n\n\n\n\n\n\n色の調整\n\n各グループの色分けをマニュアルで設定するには、 scale_fill_manual() を使用します（scale_color_manual() とは別の関数であることに注意してください！）。\n\n色のベクトルを適用するには、values = 引数を使用します。\n\n欠損値の色を指定するには、na.value = を使用します。\n\nlabels = 引数を使用して、凡例の項目名を変更します。念の為に、c(\"old\" = \"new\", \"old\" = \"new\") のような名前付きベクトルとして指定するか、データ自体の値を調節してください。\n凡例のタイトルを指定するためには、name = を使用します。\n\n色やパレットに関する詳しい情報は、ggplot の基礎 の章を参照してください。\n\n\nggplot(data = linelist)+           # データセットの指定（全病院データ）\n  \n  # ヒストグラムの作成\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # hospital でグループ化する\n        fill = hospital),          # hospital 毎に棒グラフを色分けする\n    \n    # ビン分割\n    breaks = weekly_breaks_all,    # 上のコードで定義済みの全症例に対する月曜始まりの週毎に分割する  \n    \n    closed = \"left\",               # 分割の開始から症例数をカウントする\n\n    # 枠線の色の指定\n    color = \"black\")+              # 枠線の色の指定\n  \n  # マニュアルでの色の指定\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # 色の指定 - 順番に注意!\n\n\n\n\n\n\n\n\n\n\nレベル順の調整\nグループ化されたヒストグラムの積み重ねの順番は、グループ化された列を因子型にし、各因子のレベルの順番（とその表示ラベル）を指定することで調整します。詳しくは、因子（ファクタ）型データ の章、または、ggplot の基礎 の章をご覧ください。\n因子（ファクタ）型データ の章で説明されているように、グラフを作成する前に forcats パッケージの fct_relevel() 関数を使用し、グループ化したい列を因子型に変換してレベル順をマニュアルで調整してください。\n\n# forcats パッケージの読み込み\npacman::p_load(forcats)\n\n# hospital をfactor 型としてデータセットを定義する\nplot_data &lt;- linelist %&gt;% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # factor 型に変換した後に\"Missing\"と\"Other\" 列が棒グラフの上に来るようにレベル順を調整する\n\nlevels(plot_data$hospital) # レベル順を表示する\n\n[1] \"Missing\"                             \n[2] \"Other\"                               \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\n以下の例では、hospital 列を上記のように統合した上で凡例の順番を guides() 関数を用いて逆にして、“Missing” が凡例の一番下に来るように変更しています。\n\nggplot(plot_data) +                     # レベル順を変更した新しい hospital を使用する\n  \n  # ヒストグラムの作成\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # hospital でグループ化する\n        fill = hospital),               # hospital 毎に棒グラフを色分けする\n    \n    breaks = weekly_breaks_all,         # 以前のコードで定義済みの全症例に対する月曜始まりの週毎に分割する  \n    \n    closed = \"left\",                    # 分割の開始から症例数をカウントする\n\n    color = \"black\")+                   # 枠線の色の指定\n    \n  # x軸のラベル\n  scale_x_date(\n    expand            = c(0,0),         # X軸の前後の余分なスペースを削除\n    date_breaks       = \"3 weeks\",      # データを3週ごとに表示\n    date_minor_breaks = \"week\",         # 縦縦罫線を1週ごとに表示\n    label = scales::label_date_short())+ # 日付ラベルのフォーマット\n  \n  # y軸のラベル\n  scale_y_continuous(\n    expand = c(0,0))+                   # y軸の前後の余分なスペースを削除\n  \n  # 手動での色の指定、順番に注意！\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # 外観の変更\n  theme_minimal()+                      # 背景を簡潔なものに指定\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # 脚注をイタリック体にして左に幅寄せ\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # 軸タイトルを太字に\n  \n  # ラベルの指定\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")\n\n\n\n\n\n\n\n\nヒント：凡例の順番を逆にするには、次の ggplot2 コマンドを使用します: guides(fill = guide_legend(reverse = TRUE)).\n\n\n凡例の調整\n凡例やスケールについては、ggplot のヒント の章で詳しく説明していますが、以下にその要約を記載します。\n\n凡例のタイトルを編集するには、scale 関数か、labs(fill = \"Legend title\") を使用する（color = aesthetic を使用している場合は labs(color = \"\") を使用する）\ntheme(legend.title = element_blank()) で凡例のタイトルを削除\ntheme(legend.position = \"top\") （“bottom”, “left”, “right” で凡例をそれぞれ下、左、右に配置。または”none” で凡例が削除される）\ntheme(legend.direction = \"horizontal\") で凡例を水平に配置\nguides(fill = guide_legend(reverse = TRUE)) で凡例の順序を逆にする\n\n\n\n棒グラフの横並び表示\nグループ化されたヒストグラムのビンを積み重ねではなく横並びに表示するには、geom_histogram() 内で position = \"dodge\" と指定します（aes() の外で指定する）。\n2 つ以上のグループがある場合、読みにくくなることがあるため、代わりにファセット化された可視化（グループごとにヒストグラムを表示する）を行った方が良いかも知れません。以下の例では、見やすくするために性別の欠測値を削除しています。\n\nggplot(central_data %&gt;% drop_na(gender))+   # 性別の欠損値を除外する\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # gender でグループ化する\n          fill = gender),         # gender 毎に棒グラフを色分けする\n        \n        # ヒストグラムのビン分割の指定\n        breaks = weekly_breaks_central,   # 上で定義したビンの分割\n        \n        closed = \"left\",          # 分割の開始から症例数をカウントする\n        \n        color = \"black\",          # 枠線の色の指定\n        \n        position = \"dodge\")+      # 棒グラフを横並びに指定\n                      \n  \n  # x軸のラベル\n  scale_x_date(expand            = c(0,0),         # X軸の前後の余分なスペースを削除\n               date_breaks       = \"3 weeks\",      # データを3週ごとに表示\n               date_minor_breaks = \"week\",         # 縦縦罫線を1週ごとに表示\n               label = scales::label_date_short())+ # 日付ラベルのフォーマット\n  \n  # y軸のラベル\n  scale_y_continuous(expand = c(0,0))+             # y軸の前後の余分なスペースを削除\n  \n  #手動での色の指定\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # 手動での色の指定、順番に注意！\n                    na.value = \"grey\" )+     \n\n  # 外観の変更\n  theme_minimal()+                                               # 背景を簡潔なものに指定\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # 脚注をイタリック体にして左に幅寄せ\n        axis.title = element_text(face = \"bold\"))+               # 軸タイトルを太字に\n  \n  # ラベルの指定\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # 凡例のタイトルを指定\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")\n\n\n\n\n\n\n\n\n\n\n軸の範囲\n軸の値の範囲を決める方法は 2 つあります。\n一般的な方法は、xlim = c(min, max) と ylim = c(min, max) を包含する coord_cartesian() コマンドを使用することです（それぞれで min と max の値を指定します）。これは、実際にデータを削除するのではなく「ズーム」として機能し、統計量や要約尺度において重要です。\nもう一つの方法として、scale_x_date() 内で limits = c() を使用して、最初の日付と最後の日付を設定することもできます。\n以下はその一例です。\n\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # 最初の日付を指定し、最後の日付は指定しない\n\n同様に、新しい症例が報告されていない場合でも、x 軸を特定の日付（例えば現在の日付）まで伸ばしたい場合は、次のように指定します。\n\nscale_x_date(limits = c(NA, Sys.Date()) # 最後の日付を現在の日付に指定\n\n警告：y軸の区切りや範囲の設定には注意が必要です（例：0 から 30 までを 5 ごとに分割: seq(0, 30, 5))。このようなやり方では、データが設定範囲外の値だった場合にグラフが極端に短くなる場合があります！\n\n\n日付軸のラベルと罫線\nヒント：日付軸のラベルはデータの集約とは関係ありませんが、ビン分割、日付ラベル、垂直罫線を視覚的に美しいように揃えるために重要です\n日付ラベルと罫線を変更するには、以下のいずれかの方法で scale_x_date() を使用します。\n\nヒストグラムのビン分割が日、月、月曜始まりの週、月、年である場合：\n\ndate_breaks = を使用して、ラベルと大きい罫線の間隔を指定します（例：“day”、 “week”、 “3 weeks”、“month”、“year”）\ndate_minor_breaks = を使用して（日付ラベルの間の）小さい縦罫線の間隔を指定します\n最初の棒グラフからラベルを開始するために expand = c(0,0) を追加します\n日付のラベルの書式を指定するには date_labels = を使用します。日付型データ の章では、役立つヒントを紹介しています（改行には \\n を使用など）\n\nヒストグラムのビン分割が日曜始まりの週：\n\nbreaks = と minor_breaks = を使用してそれぞれ一連の日付の区切りを指定します\n上記のように date_labels = と expand = を使用して調節することも可能です\n\n\n注意点：\n\nseq.Date() を使用して日付のベクトルを作成する方法については、ggplot の基礎 の章を参照して下さい。\n日付ラベルを作成するためのヒントについては、こちら のウェブサイト、または、本ハンドブックの 日付型データ の章を参照してください。\n\n\n2つの例の比較\n以下は、ビン分割とラベル、罫線が整列しているグラフと整列していないグラフの比較です。\n\n# 7日ごとのビン分割＋月曜ラベル\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 最初の症例から7日ごとのビン分割\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),               # X軸の前後の余分なスペースを削除\n    date_breaks = \"3 weeks\",       # データを3週ごとに表示\n    date_minor_breaks = \"week\",    # 縦罫線を1週ごとに表示\n    label = scales::label_date_short())+  # 日付ラベルのフォーマット\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # y軸の前後の余分なスペースを削除\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7日ごとのビン分割＋月\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                  # X軸の前後の余分なスペースを削除\n    date_breaks = \"months\",           # 月の一番はじめの日\n    date_minor_breaks = \"week\",       # 縦罫線を1週ごとに表示\n    label = scales::label_date_short())+   # 日付ラベルのフォーマット\n  \n  scale_y_continuous(\n    expand = c(0,0))+                 # y軸の前後の余分なスペースを削除\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# マニュアルでビン分割を月曜日に指定\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # 最初の症例の前の月曜日から始まる7日ごとのビン分割を指定\n    breaks = weekly_breaks_central,    # 本章で定義済み\n    \n    closed = \"left\",                   # 分割の開始から症例数をカウントする\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # X軸の前後の余分なスペースを削除\n    date_breaks = \"4 weeks\",           # 4週ごとの月曜日\n    date_minor_breaks = \"week\",        # 月曜始まりの週\n    label = scales::label_date_short())+    # 日付ラベルのフォーマット\n  \n  scale_y_continuous(\n    expand = c(0,0))+                  # y軸の前後の余分なスペースを削除\n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# ラベルを月にして整列\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # 最初の症例の前の月曜日から始まる7日ごとのビン分割を指定\n    breaks = weekly_breaks_central,    # 本章で定義済み\n    \n    closed = \"left\",                   # 分割の開始から症例数をカウントする\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # X軸の前後の余分なスペースを削除\n    date_breaks = \"months\",            # 4週ごとの月曜日\n    date_minor_breaks = \"week\",        # 月曜始まりの週\n    label = scales::label_date_short())+           # 日付ラベルのフォーマット\n  \n  scale_y_continuous(\n    expand = c(0,0))+                  # y軸の前後の余分なスペースを削除\n  \n  theme(panel.grid.major = element_blank())+  # 大きい縦罫線の削除\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# マニュアルでビン分割とラベルを日曜日に指定\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # 最初の症例の前の日曜日から始まる7日ごとのビン分割を指定\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    closed = \"left\",                    # 分割の開始から症例数をカウントする\n\n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # 最初の症例の前の日曜日から始まる3週間ごとのラベルと大きい罫線を指定\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # 最初の症例の前の日曜日から始まる7日ごとの小さい罫線を指定\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    label = scales::label_date_short())+  # 日付ラベルのフォーマット\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # y軸の前後の余分なスペースを削除\n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n集計データ\nラインリストではなく、施設や地域などの集計データのみがあることが多くあります。集計データのみでも ggplot() で流行曲線を作成することができますが、コードが少し異なります。このセクションでは、先述のデータ準備のセクションでインポートした count_data データセットを使用します。このデータセットは、linelist に含まれている症例数を日別にカウントしたデータです。最初の 50 行を以下に表示します。\n\n\n\n\n\n\n\n日別カウントデータの可視化\n日別カウントデータから流行曲線を作成することができます。以下は以前のコードとの相違点です。\n\naes() 内で、日別カウントデータを y = に指定します（この場合、列名は n_cases です）。\ngeom_histogram() に引数 stat = \"identity\" を追加し、ヒストグラムのビンの高さをデフォルトの行数ではなく、y = として指定します。\n棒グラフの間に縦の白線が入らないように、width = の引数を追加します。日別データの場合、1 に設定します。週別カウントデータの場合は 7 に設定します。月別のカウントデータでは、（各月で日数が異なるため）白線が問題となりますので、x 軸を因子型（月）に変換して geom_col() を使用することを検討して下さい。\n\n\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # 日別カウントデータ の場合は set width = 1 で棒グラフの間のスペースを適切にする\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")\n\n\n\n\n\n\n\n\n\n\n週別カウントデータの可視化\nもしデータが週ごとの症例数であれば、以下と同じようになっているはずです（count_data_weekly というデータセット名にしています）。\n以下に表示した count_data_weekly の最初の 50 行を見ると、週単位で症例が集計されていることがわかります。各週は、週の最初の日（デフォルトでは月曜日）で表示されています。\n\n\n\n\n\n\nx = 引数に epiweek 列を指定して流行曲線をプロットします。y = 引数にカウント列（この例では、n_cases_weekly 列）を指定し、上で説明したように stat = \"identity\" を追加することを忘れないで下さい。\n\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x軸に疫学週を指定（日付型として）\n      y = n_cases_weekly,    # y軸に週別カウントデータを指定\n      group = hospital,      # hospital でグループ化して色分け\n      fill = hospital),\n    stat = \"identity\")+      # カウントデータをプロットする場合に必要\n     \n  # x軸のラベル\n  scale_x_date(\n    date_breaks = \"2 months\",      # データを2か月ごとに表示\n    date_minor_breaks = \"1 month\", # 縦罫線を1か月ごとに表示\n    label = scales::label_date_short())+       # 日付ラベルのフォーマット（月の下に年を記載）\n     \n  # 色パレットを指定 （RColorBrewer パッケージを使用）\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")\n\n\n\n\n\n\n\n\n\n\n\n移動平均\n詳細な説明については、移動平均 の章を参照して下さい。以下は、slider パッケージで移動平均を計算する方法の 1 つです。この方法では、移動平均はプロットする前にデータセット上で計算されます。\n\nデータを日別、週別など必要に応じて集計します（データのグループ化 の章を参照）。\n\nslider パッケージの slide_index() で移動平均の列を新しく作成します。\n\n移動平均を geom_line() で 流行曲線の上（後）にプロットします。\n\n詳細は slider パッケージの説明を参照して下さい。\n\n# パッケージの読み込み\npacman::p_load(slider)  # 移動平均の計算に slider を使用\n\n# 週別カウントと7日間移動平均のデータセットを作成\n#######################################################\nll_counts_7day &lt;- linelist %&gt;%    # ラインリスト\n  \n  ## 日別にカウント\n  count(date_onset, name = \"new_cases\") %&gt;%   # \"new cases\"という名前の列を作成\n  drop_na(date_onset) %&gt;%                     # 発症日欠損症例を除外\n  \n  ## 7日間移動平均数を計算\n  mutate(\n    avg_7day = slider::slide_index(    # 新しい列を作成\n      new_cases,                       # new_cases 列の値を用いる\n      .i = date_onset,                 # date_onset 列の含まれていない日付も移動平均に含める\n      .f = ~mean(.x, na.rm = TRUE),    # 欠損値を除外した上で平均をとる\n      .before = 6,                     # 日別に6日前までのデータを移動平均に含める\n      .complete = FALSE),              # 次のステップのために FALSE に設定する\n    avg_7day = unlist(avg_7day))       # list型から数字型に変換\n\n\n# プロット\n######\nggplot(data = ll_counts_7day) +  # 以前のコードで定義済みのデータセット\n    geom_histogram(              # ヒストグラムの作成\n      mapping = aes(\n        x = date_onset,          # x軸の日付列を指定\n        y = new_cases),          # y軸に日別のカウント数を指定\n        stat = \"identity\",       # カウントデータように指定\n        fill=\"#92a8d1\",          # かっこいい色を指定\n        colour = \"#92a8d1\",      # 枠線も同じ色に指定\n        )+ \n    geom_line(                   # 移動平均の線グラフを作成\n      mapping = aes(\n        x = date_onset,          # x軸の日付列を指定\n        y = avg_7day,            # y軸に日別の移動平均を指定\n        lty = \"7-day \\nrolling avg\"), # 線グラフの凡例を記載\n      color=\"red\",               # 線グラフの色の指定\n      size = 1) +                # 線グラフの太さの指定\n    scale_x_date(                # 日付軸のスケール\n      date_breaks = \"1 month\",\n      label = scales::label_date_short(),\n      expand = c(0,0)) +\n    scale_y_continuous(          # y軸のスケール\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # 凡例のタイトルを削除\n\n\n\n\n\n\n\n\n\n\nファセット化・プロットの小分割\n他の ggplot と同様に、ファセット化されたグラフ（「複数の小さなグラフを並べたグラフ」）を作成することができます。ggplot の基礎 の章で説明されているように、 facet_wrap() と facet_grid() のどちらかを使用することができますが、ここでは facet_wrap() を使って説明します。流行曲線の作成においては、1 つの列に対してのみファセットするだけでよいので、一般的に facet_wrap() の方が簡単です。\n一般的な構文は facet_wrap(rows ~ cols) で、チルダ (~) の左側はファセット化プロットの「行」に対する列の名前、チルダの右側はファセット化プロットの「列」に対する列の名前です。最も簡単な例では、チルダの右側に 1 つの列を指定します: facet_wrap(~age_cat)\nフリースケール\n各ファセットの軸のスケールを同じ値に「固定」（デフォルト）するか、「自由」（ファセット内のデータに基づいて変更する）にするかを指定します。これは、facet_wrap() 内の scales = 引数で、“free_x” か “free_y” か “free” を指定することでできます。\nファセットの列数と行数\nfacet_wrap() 内で ncol = または nrow = で指定することができます。\nパネルの順番\n順序を変更するには、ファセットを作成するために使用される因子型列のレベルの順序を変更します。\n外観\nフォントサイズ、ヘッダ、色などは、以下のような引数を持つ theme() で変更することができます。\n\nstrip.text = element_text() (サイズ、ヘッダ、色、角度など)\nstrip.background = element_rect() (例：element_rect(fill=“grey”))\nstrip.position = (ファセットのタイトルが記載されるボックスの場所を指定：“bottom”, “top”, “left”, or “right”)\n\nファセットラベル\nファセットプロットのラベルは、列の「ラベル」を用いるか「ラベラー（labeller）」の使用によって変更することができます。\nggplot2 の関数 as_labeller() を用いて、ラベラーを作成した後に、以下のように facet_wrap() の labeller = 引数に作成したラベラーを指定します。\n\nmy_labels &lt;- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n\n以下は、age_cat 列でファセットしたグラフの作成例です。\n\n# プロットの作成\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # aes() 内の引数はグループされる\n      \n    color = \"black\",      # aes() 外の引数は全データに適用される\n        \n    # ビン分割\n    breaks = weekly_breaks_central, # 以前のコードで定義済み （ggplot セクション参照）\n    closed = \"left\" # count cases from start of breakpoint\n    )+  \n                      \n  # x軸のラベル\n  scale_x_date(\n    expand            = c(0,0),         # X軸の前後の余分なスペースを削除\n    date_breaks       = \"2 months\",     # データを2月ごとに表示\n    date_minor_breaks = \"1 month\",      # 縦罫線を1月ごとに表示\n    label = scales::label_date_short())+     # 日付ラベルのフォーマット\n  \n  # y軸のラベル\n  scale_y_continuous(expand = c(0,0))+                       # y軸の前後の余分なスペースを削除\n  \n  # テーマの指定\n  theme_minimal()+                                           # 背景を簡潔なものに指定\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # 脚注をイタリック体にして左に幅寄せ\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # 軸タイトルを太字に\n  \n  # ファセットの作成\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # ラベル\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # 凡例のタイトル\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\nラベラーの詳細については、こちら のウェブサイトを参照してください。\n\nファセットの背景に全体の流行曲線を表示\n各ファセットの背景に全体の流行曲線を表示するには、ggplot で作成した図に gghighlight パッケージの gghighlight() を追加します。すべてのファセットにおける y 軸の最大値が、全体の流行曲線の頂点になっていることに注意して下さい。gghighlight パッケージの例は、ggplot の基礎 の章で多く紹介されています。\n\nggplot(central_data) + \n  \n  # グループ化された流行曲線\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # aes() 内の引数はグループされる\n    \n    color = \"black\",    # aes() 外の引数は全データに適用される\n    \n    # ビン分割\n    breaks = weekly_breaks_central, # 以前のコードで定義済み （ggplot セクション参照）\n    \n    closed = \"left\" # 分割の開始から症例数をカウントする\n    )+     # 以前のコードで定義済み （ggplot セクション参照）                \n  \n  # ファセットの背景に全体の流行曲線を灰色で示す\n  gghighlight::gghighlight()+\n  \n  # x軸のラベル\n  scale_x_date(\n    expand            = c(0,0),         # X軸の前後の余分なスペースを削除\n    date_breaks       = \"2 months\",     # データを2月ごとに表示\n    date_minor_breaks = \"1 month\",      # 縦罫線を1月ごとに表示 \n    label = scales::label_date_short())+     # 日付ラベルのフォーマット\n  \n  # y軸のラベル\n  scale_y_continuous(expand = c(0,0))+  # y軸の前後の余分なスペースを削除\n  \n  # テーマの指定\n  theme_minimal()+                                           # 背景を簡潔なものに指定\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # 脚注をイタリック体にして左に幅寄せ\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # 軸タイトルを太字に\n  \n  # ファセットの作成\n  facet_wrap(\n    ~age_cat,                          # それぞれのプロットに age_cat のグループを表示\n    ncol = 4,                          # 列数を指定\n    strip.position = \"top\",            # ファセットタイトルの位置を指定\n    labeller = my_labels)+             # 上で定義した labeller の指定\n  \n  # ラベル\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # 凡例のタイトル\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\n\n\n全データを含んだファセットの作成\n全データを含むファセットボックスを表示したい場合は、データセット全体を複製し、複製したものを 1 つのファセットとして扱います。以下で自作する関数（ヘルパー関数）である CreateAllFacet() を使用すると可能です（このヘルパー関数は、こちら のページで紹介されているものです）。この関数を実行すると、行の数が 2 倍になり、facet という新しい列が作られます。その中で新たに複製された行は「all」という値を、元の行は facet 列の元の値を持つようになります。その後にこの facet 列に対してファセットを行います。\nまず、ヘルパー関数を作成して実行し、利用できるようにします。\n\n# helper 関数を定義する\nCreateAllFacet &lt;- function(df, col){\n     df$facet &lt;- df[[col]]\n     temp &lt;- df\n     temp$facet &lt;- \"all\"\n     merged &lt;-rbind(temp, df)\n     \n     # ファセット値を因子型に指定\n     merged[[col]] &lt;- as.factor(merged[[col]])\n     \n     return(merged)\n}\n\n次にこのヘルパー関数をデータセットの age_cat 列に適用します。\n\n# 複製されたデータセットに新たに「facet」列を追加し、別のファセットレベルとして「all」年齢区分を表示する。\ncentral_data2 &lt;- CreateAllFacet(central_data, col = \"age_cat\") %&gt;%\n  \n  # 因子のレベルを指定\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `facet = fct_relevel(...)`.\nCaused by warning:\n! 1 unknown level in `f`: 70+\n\n# レベルのチェック\ntable(central_data2$facet, useNA = \"always\")\n\n\n  all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  &lt;NA&gt; \n  454    84    84    82    58    73    57     7     9 \n\n\nggplot() コマンドにおける注意点は、以下の通りです。\n\n使用するデータセットは central_data2（行数が 2 倍になり、新しい列 “facet” が追加）\nラベラーを使用する場合は、更新する必要があります。\n必要であれば：縦に積み重ねたファセットを実現するために、ファセット列を式の行側に移動し、右側を “.” (facet_wrap(facet~.)) に置き換え、ncol = 1とします。保存される png ファイルの幅と高さの調整が必要になります（ggplot の基礎 の章で紹介している ggsave() を参照してください）。\n\n\nggplot(central_data2) + \n  \n  # グループ化された流行曲線\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # aes() 内の引数はグループされる\n        color = \"black\",    # aes() 外の引数は全データに適用される\n        \n        # ビン分割\n        breaks = weekly_breaks_central, # 以前のコードで定義済み （ggplot セクション参照）\n        \n        closed = \"left\", # 分割の開始から症例数をカウントする\n        )+    # 以前のコードで定義済み （ggplot セクション参照）\n                     \n  # x軸のラベル\n  scale_x_date(\n    expand            = c(0,0),         # X軸の前後の余分なスペースを削除\n    date_breaks       = \"2 months\",     # データを2月ごとに表示\n    date_minor_breaks = \"1 month\",      # 縦罫線を1月ごとに表示\n    label = scales::label_date_short())+     # 日付ラベルのフォーマット\n  \n  # y軸のラベル\n  scale_y_continuous(expand = c(0,0))+  # y軸の前後の余分なスペースを削除\n  \n  # テーマの指定\n  theme_minimal()+                                           # 背景を簡潔なものに指定\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # 脚注をイタリック体にして左に幅寄せ\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # ファセットの作成\n  facet_wrap(facet~. ,                            # それぞれのプロットに一つのファセットを指定\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # 凡例のタイトル\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#暫定データ",
    "href": "new_pages/epicurves.jp.html#暫定データ",
    "title": "32  流行曲線（エピカーブ）",
    "section": "32.3 暫定データ",
    "text": "32.3 暫定データ\n流行曲線で示される最新のデータは、多くの場合、暫定的な値であり、報告遅れのために後から症例数が追加される可能性があることを明示した方が良いでしょう。これは、直近の日数分を垂直線や長方形で囲むことで行うことができます。ここでは、2 つの方法を紹介します。\n\nannotate() の使用：\n\n線の場合は annotate(geom = \"segment\") を使用します。 x、 xend、 y、 yend を指定し、サイズ、線の種類(lty）、色を調整します。\n\n長方形の場合は annotate(geom = \"rect\") を使用します。 xmin/xmax/ymin/ymax を指定し、色とアルファ値を調整します。\n\nデータを暫定的なステータスでグループ化し、それらのビンを異なる色で表示します。\n\n注意：長方形を作成するために geom_rect() を試すかも知れませんが、ラインリストの場合は上手くいきません。この関数は、各観測点・行に対して 1 つの長方形を重ねる関数です！非常に低いアルファ値（例えば 0.01）を使用するか、他の方法を用いてください。\n\nannotate() の使用\n\nannotate(geom = \"rect\") 内で、 xmin と xmax に日付型の引数を指定する必要があります。\nこれらのデータは週単位のビンに集約されており、最後のビンは最後のデータポイントの次の月曜日まで伸びているので、影がかったエリアは4週間をカバーしているように見えるかもしれないことに注意してください。\nannotate() の例は こちら を参考にしてください。\n\n\nggplot(central_data) + \n  \n  # ヒストグラム\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # 以前のコードで定義済み\n    \n    closed = \"left\", # 分割の開始から症例数をカウントする\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                   # X軸の前後の余分なスペースを削除\n    date_breaks = \"1 month\",           # 月の最初の日\n    date_minor_breaks = \"1 month\",     # 月の最初の日\n    label = scales::label_date_short())+          # 日付ラベルのフォーマット\n  \n  # ラベルとテーマの指定\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # 暫定データに対して半透明の影をかける\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # 日付型である必要があることに注意\n    xmax  = as.Date(Inf),                                          # 日付型である必要があることに注意\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # annotate()では alpha 値で直感的に簡単に透明度を変えられる\n    fill  = \"red\")+\n  \n  # 黑の縦線を追加する\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 最終日の21日前\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # 線がy = 0 の場所から始まるように指定\n    yend  = Inf,       # 線が一番上まで続くように指定\n    size  = 2,         # 線の太さを指定\n    color = \"black\",\n    lty   = \"solid\")+   # 線の種類 （例； \"solid\", \"dashed\"）\n\n  # 長方形の中に文字を追加\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\n\n\n\n\n\n\n\n\n黒い縦線の追加は以下のコードでも可能ですが、以下のように geom_vline() を使うと、高さは調整できなくなります。\n\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")\n\n\n\nビンの色を変える\n別の方法として、暫定データが反映されたビン自体の色や表示を調整することもできます。データ前処理の段階で新しい列を作り、作成した新しい列を使ってデータをグループ化し、暫定データの aes(fill = ) を他の棒グラフと異なる色やアルファ値にすることができます。\n\n# 列の追加\n############\nplot_data &lt;- central_data %&gt;% \n  mutate(tentative = case_when(\n    date_onset &gt;= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # 直近7日分の データは暫定である\n    TRUE                                       ~ \"Reliable\")) # それ以外は 暫定ではない\n\n# プロット\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # ヒストグラム\n  geom_histogram(\n    breaks = weekly_breaks_central,   # 以前のコードで定義済み\n    closed = \"left\", # 分割の開始から症例数をカウントする\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                   # X軸の前後の余分なスペースを削除\n    date_breaks = \"3 weeks\",           # データを3週ごとに表示\n    date_minor_breaks = \"week\",        # 縦罫線を1週ごとに表示\n    label = scales::label_date_short())+      # 日付ラベルのフォーマット\n  \n  # ラベルとテーマの指定\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # 凡例のタイトルを削除",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#複数の日付ラベル",
    "href": "new_pages/epicurves.jp.html#複数の日付ラベル",
    "title": "32  流行曲線（エピカーブ）",
    "section": "32.4 複数の日付ラベル",
    "text": "32.4 複数の日付ラベル\n月や年など複数レベルの日付ラベルを、下位のラベルと重複することなく表示したい場合は、以下の方法のいずれかを試してみて下さい。\ndate_labels や labels の引数で、各ラベルの一部を下の行に配置するために \\n 使うことができることも可能です。しかし、以下のコードを使うと、年や月を下の行に、かつ一度のみ表示することが可能です。\nまず、最も簡単な方法は、scales パッケージの関数 label_date_short() を、scale_x_date() 内の labels = 引数に使用することです（注意：以下の例ように空の括弧 () を含めることを忘れないようにしてください）。 label_date_short() は、効率的な日付ラベルを自動的に作成します（詳しくは こちら のウェブサイトをご覧ください）。この関数のもう一つの特長は、データが日、週、月、年と時間と共に拡大していくのに応じて、ラベルが自動的に調整されることです。\n\nggplot(central_data) + \n\n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = weekly_breaks_central,   # 以前のコードで定義済み （ggplot セクション参照）\n    closed = \"left\",                  # 分割の開始から症例数をカウントする\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n\n  # y-axis scale as before \n  scale_y_continuous(expand = c(0,0))+\n\n  # x-axis scale sets efficient date labels\n  scale_x_date(\n    expand = c(0,0),                      # X軸の前後の余分なスペースを削除\n    labels = scales::label_date_short())+ # 自動的に日付ラベルを生成\n\n  # labels and theme\n  labs(\n    title = \"Using label_date_short()\\nTo make automatic and efficient date labels\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()\n\n\n\n\n\n\n\n\nもう一つの方法は、以下のようにファセット化を行うことです。\n\n症例数は、外観上の理由から週単位で集計されています。詳細は、本章の「集計データ」のセクションを参照して下さい。\nヒストグラムの代わりに geom_area() が使われていますが、これは、以下のファセット化のアプローチがヒストグラムではうまく機能しないためです。\n\n週別にデータをカウント\n\n# 週別にデータをカウントしたデータセットを作成\n#######################################\ncentral_weekly &lt;- linelist %&gt;%\n  filter(hospital == \"Central Hospital\") %&gt;%   # フィルター\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %&gt;%  \n  count(week) %&gt;%                              # 週別にカウント\n  drop_na(week) %&gt;%                            # 発症日不明症例を除外\n  complete(                                    # 症例が一例もなかった週を0で埋める\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # NAを0に変換\n\nグラフの作成\n\n# 軸タイトルの年に対して枠線なしのグラフの作成\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # xとyを全プロットに対して指定\n  geom_line(stat = \"identity\",              # カウントデータを用いて線グラフを作成\n            color = \"#69b3a2\") +            # 線グラフの色\n  geom_point(size=1, color=\"#69b3a2\") +     # 週ごとに点を作成\n  geom_area(fill = \"#69b3a2\",               # 線グラフの下のエリアを塗りつぶす\n            alpha = 0.4)+                   # 塗りつぶしの透明度の指定\n  scale_x_date(date_labels=\"%b\",            # 日付ラベルのフォーマット（月名を示す）\n               date_breaks=\"month\",         # 日付ラベルを月ごとで分割\n               expand=c(0,0)) +             # X軸の前後の余分なスペースを削除\n  scale_y_continuous(\n    expand  = c(0,0))+                      # y軸の前後の余分なスペースを削除\n  facet_grid(~lubridate::year(week),        # （日付列の）年でファセット\n             space=\"free_x\",                \n             scales=\"free_x\",               # x軸をデータの範囲で調整（ファセット間で固定しない）\n             switch=\"x\") +                  # ファセットのラベルを下に持ってくる\n  theme_bw() +\n  theme(strip.placement = \"outside\",                  # ファセットのラベルの場所\n          strip.background = element_blank(),         # ファセットの背景の塗りつぶしをなくす\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_blank(),             # ファセットの境界線をなくす\n          panel.spacing=unit(0,\"cm\"))+                # ファセット間のスペースをなくす\n  labs(title = \"Nested year labels - points, shaded, no label border\")\n\n\n\n\n\n\n\n\n上記のファセット化の方法は、stackoverflow.com の こちら と こちら の投稿を参考に作成されました。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#軸グラフ",
    "href": "new_pages/epicurves.jp.html#軸グラフ",
    "title": "32  流行曲線（エピカーブ）",
    "section": "32.5 2軸グラフ",
    "text": "32.5 2軸グラフ\nデータ可視化のコミュニティー内では、2 軸グラフの有効性について激しい議論が交わされていますが、流行曲線やそれに類するグラフで、2 軸目に割合を重ねたものを見たいと思う疫学専門家は依然として多くいます。これについては ggplot のヒント の章で詳しく説明していますが、cowplot メソッドを使った一例を以下に示します。\n\n2 つの異なるプロットを作成し、cowplot パッケージで結合します。\n\n2 つのプロットはまったく同じ x 軸（範囲を設定する）を持つ必要があり、そうでないとデータとラベルがずれてしまいます。\n\nそれぞれ theme_cowplot() を使用し、一方は y 軸をプロットの右側に移動します。\n\n\n# パッケージの読み込み\npacman::p_load(cowplot)\n\n# 最初の流行曲線を作成\n#######################################\nplot_cases &lt;- linelist %&gt;% \n  \n  # 週別の症例をプロット\n  ggplot()+\n  \n  # ヒストグラムの作成 \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # 最初の症例の前の月曜から、最後の症例の次の月曜までが含まれる週ごとのビン分割を指定\n    breaks = weekly_breaks_all)+  # 以前に定義した週ごとの日付のベクトル\n        \n  # もう一つのグラフとの整合性を保つための最初と最後の日付の指定\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # 最初と最後の日付の指定\n  \n  # ラベル\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# 2つ目のグラフ（週ごとの死亡割合）の作成\n###########################################\nplot_deaths &lt;- linelist %&gt;%                        # ラインリスト\n  group_by(week = floor_date(date_onset, \"week\")) %&gt;%  # week 列を作成\n  \n  # 週ごとの死亡割合を集計\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %&gt;% \n  \n  # プロット\n  ggplot()+\n  \n  # 週ごとの死亡割合の線グラフ\n  geom_line(                                # 週ごとの死亡割合の線グラフの作成\n    mapping = aes(x = week, y = pct_died),  # y軸に pct_died 列を指定\n    stat = \"identity\",                      # 行番号（デフォルト）ではなく、pct_death 列をy軸に指定\n    size = 2,\n    color = \"black\")+\n  \n  # 最初のグラフと同じx軸の範囲にする\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # 最初と最後の日付の指定\n  \n  \n  # y軸の調整\n  scale_y_continuous(                # y軸の調整\n    breaks = seq(0,100, 10),         # 軸の分割をパーセント用に設定する\n    limits = c(0, 100),              # 軸の範囲をパーセント用に設定する\n    position = \"right\")+             # 軸を右に持ってくる\n  \n  # x軸のラベルを削除し、y軸のラベルを指定する\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # %軸のラベル\n  \n  theme_cowplot()                   # 2つのプロットを良い感じに重ねる\n\n次に cowplot を使って 2 つのプロットを重ね合わせます。x 軸を合わせること、y 軸のサイド、theme_cowplot() の使い方に注目してください。\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#累積症例数",
    "href": "new_pages/epicurves.jp.html#累積症例数",
    "title": "32  流行曲線（エピカーブ）",
    "section": "32.6 累積症例数",
    "text": "32.6 累積症例数\n症例のラインリストから始める場合、R base の cumsum() を使用して\\、アウトブレイクにおける日ごとの累積症例数の列を新たに作成します。\n\ncumulative_case_counts &lt;- linelist %&gt;% \n  count(date_onset) %&gt;%                # 日ごとの症例数（\"n\"列）\n  mutate(                         \n    cumulative_cases = cumsum(n)       # 日ごとの累積症例数列\n    )\n\n最初の 10 行は以下のようになります。\n\n\n\n\n\n\nこの累積症例数の列は、geom_line() を使用して、date_onset 列に対してプロットすることができます。\n\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n\n\n\n\n\n\n\n\nまた、上記や ggplot の基礎 の章で説明されている cowplot を使って、2 軸で流行曲線に重ねることもできます。\n\n#パッケージの読み込み\npacman::p_load(cowplot)\n\n# 最初のグラフである流行曲線を作成\nplot_cases &lt;- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# 2つ目のグラフである累積症例数の線グラフを作成\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\n\n次に cowplot を使って 2 つのプロットを重ね合わせます。x 軸を合わせること、y 軸のサイド、theme_cowplot() の使い方に注意してください。\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.jp.html#参考資料",
    "href": "new_pages/epicurves.jp.html#参考資料",
    "title": "32  流行曲線（エピカーブ）",
    "section": "32.7 参考資料",
    "text": "32.7 参考資料",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>流行曲線（エピカーブ）</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.jp.html",
    "href": "new_pages/age_pyramid.jp.html",
    "title": "33  人口ピラミッドとリッカート尺度",
    "section": "",
    "text": "33.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>人口ピラミッドとリッカート尺度</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.jp.html#準備",
    "href": "new_pages/age_pyramid.jp.html#準備",
    "title": "33  人口ピラミッドとリッカート尺度",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(rio,       # データのインポート\n               here,      # データの場所を指定する\n               tidyverse, # データのクリーニングと成形と図示（ggplot2 パッケージを含む）\n               apyramid,  # 年齢ピラミッドの作成に特化したパッケージ\n               janitor,   # 表とデータのクリーニング\n               stringr)   # タイトルや見出しなどの文字列操作\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください）。\n\n# 発症数ラインリストをインポートする \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n最初の 50 行が以下に表示されます。\n\n\n\n\n\n\n\n\nクリーニング\n従来の年齢・性別による人口ピラミッドを作るには、まずデータを以下のようにクリーニングする必要があります。\n\n性別の列のクリーニング\n解析方法に応じて、年齢を数値または年齢カテゴリとして保存\n\n年齢カテゴリを使用する場合、列の値はデフォルトの英数字か、因子型に変換することで、意図的に設定する順序に修正する必要があります。\n以下では、janitor パッケージの tabyl() を使用して、gender と age_cat5 列を確認します。\n\nlinelist %&gt;% \n  tabyl(age_cat5, gender)\n\n age_cat5   f   m NA_\n      0-4 640 416  39\n      5-9 641 412  42\n    10-14 518 383  40\n    15-19 359 364  20\n    20-24 305 316  17\n    25-29 163 259  13\n    30-34 104 213   9\n    35-39  42 157   3\n    40-44  25 107   1\n    45-49   8  80   5\n    50-54   2  37   1\n    55-59   0  30   0\n    60-64   0  12   0\n    65-69   0  12   1\n    70-74   0   4   0\n    75-79   0   0   1\n    80-84   0   1   0\n      85+   0   0   0\n     &lt;NA&gt;   0   0  86\n\n\nまた、age のヒストグラムを簡単に図示し、きれいに正しく分類されていることを確認します。\n\nhist(linelist$age)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>人口ピラミッドとリッカート尺度</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.jp.html#apyramid-パッケージ",
    "href": "new_pages/age_pyramid.jp.html#apyramid-パッケージ",
    "title": "33  人口ピラミッドとリッカート尺度",
    "section": "33.2 apyramid パッケージ",
    "text": "33.2 apyramid パッケージ\napyramid パッケージは、R4Epis プロジェクトの製品です。このパッケージについて、詳しくはこちらでご覧いただけます。このパッケージを使うと、年齢ピラミッドを素早く作ることができます。より細かな差異のある状況については、以下の ggplot() を使ったセクションをご参照ください。apyramid パッケージについては、R のコンソールに ?age_pyramid と入力することで、そのヘルプページをさらに詳しく読むことができます。\n\nラインリストのデータ\nクリーニングされた linelist データセットを使うことにより、age_pyramid() コマンド 1 つで年齢ピラミッドを作成することができます。このコマンドでは\n\ndata = の引数には、linelist データフレームを設定します。\nage_group = の引数 (Y 軸) には、カテゴリカルな年齢の列名 (引用符で囲む) を設定します。\nsplit_by = の引数（X 軸）には、性別の列を設定します。\n\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\n\n\n\n\n\n\n\n\nproportional = TRUE を含めることで、X 軸を発症数ではなく、発症数全体に対するパーセントで表示することができます。\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\n\n\n\n\n\n\n\n\nagepyramid パッケージを使用する際に、split_by 列が 2 値（例：男性・女性、はい・いいえ）である場合は、結果はピラミッドとして表示されます。しかし、split_by 列に 3 つ以上の値（NA を除く）がある場合、ピラミッドは、年齢層ごとに、ファセット（注目する因子型の値を部分集合として抽出したもの）とそれ以外のファセットを示す灰色の棒を「背景」に持つファセット棒グラフとして表示されます。この場合、split_by = の値は、各ファセットのパネルの上部にラベルとして表示されます。例えば、split_by = に hospital という列を指定した場合、以下のようになります。\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  \n\n\n\n\n\n\n\n\n\n欠測値\nsplit_by = または age_group = の列に欠測値 NA がある行は、欠測値ロジカル型定数 NA として定義されている場合、上記のファセット化は実行されません。デフォルトではこの行は表示されません。しかし、na.rm = FALSE を指定することで、棒グラフの隣とグラフの上部に別の年齢層として表示させることができます。\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # 患者の年齢と性別の欠測値を表示する\n\n\n\n\n\n\n\n\n\n\n割合、色、見た目\nデフォルトでは、棒グラフは発症数（% ではない）で、各年齢層内の破線は中央値を示し、グラフの色は緑と紫で表示されます。これらの引数はそれぞれ、以下のように調整することができます。\nまた、外観 (aesthetic) テーマやラベルの調整など、標準の ggplot() “+” シンタックスを使用して、追加の ggplot() コマンドをプロットに追加することができます。\n\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # 発症数ではなく、パーセントで表示する\n  show_midpoint = FALSE,            # 中央値の破線を削除する\n  #pal = c(\"orange\", \"purple\")      # ここでのグラフの色指定ができる（ラベルは不可）\n  )+                 \n  \n  # 追加の ggplot コマンド\n  theme_minimal()+                               # 背景をシンプルにする\n  scale_fill_manual(                             # グラフの色とラベルを指定する\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # X 軸と Y 軸を入れ替える\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # 凡例を下へ移動する\n    axis.text = element_text(size = 10, face = \"bold\"),  # フォント・サイズ\n    axis.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n集計データ\n上記の例では、データがラインリスト形式であり、1 つの観測が 1 行であることを想定しています。もし、データがすでに年齢カテゴリごとの発症数に集約されている場合でも、以下に示すように、apyramid パッケージを使用することができます。\n例示のため、ラインリストデータを年齢カテゴリごと、性別ごとの発症数に集約し、「横長」 形式にします。これにより、データがもともと集約されていたかのように、擬似的に作り出すことができます。データのグループ化とデータの縦横変換については、それぞれの章で詳しく解説しています。\n\ndemo_agg &lt;- linelist %&gt;% \n  count(age_cat5, gender, name = \"cases\") %&gt;% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %&gt;% \n  rename(`missing_gender` = `NA`)\n\n…これによりデータセットは、年齢カテゴリの列、男性の発症数の列、女性の発症数の列、欠測の数の列で表示されます。\n\n\n\n\n\n\nこのデータを年齢ピラミッドに設定するために、dplyr パッケージの pivot_longer() 関数で「縦長」のデータになるようにピボットします。なぜなら、ggplot() が一般的に「縦長」のデータを好み、apyramid パッケージは ggplot() を使用しているためです。\n\n# 集計されたデータを縦長形式にピボットする\ndemo_agg_long &lt;- demo_agg %&gt;% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # 列を長くする\n    names_to = \"gender\",                # カテゴリの新しい列名\n    values_to = \"counts\") %&gt;%           # 発症数の新しい列名\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # \"missing_gender\" を NA に変換する\n\n\n\n\n\n\n\n次に age_pyramid() の split_by = と count = の引数で、データ中のそれぞれの列を指定します。\n\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# 年齢カテゴリの列名\n                      split_by = \"gender\",   # 性別の列名\n                      count = \"counts\")      # 発症数の列名\n\n\n\n\n\n\n\n\n上記では、“m” と “f” の因子の順序が異なる（ピラミッドが逆）ことに注意してください。順序を調整するには、集計データの性別を因子型として再定義し、希望するレベルの順序に修正する必要があります。因子（ファクタ）型データの章をご参照ください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>人口ピラミッドとリッカート尺度</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.jp.html#demo_pyr_gg",
    "href": "new_pages/age_pyramid.jp.html#demo_pyr_gg",
    "title": "33  人口ピラミッドとリッカート尺度",
    "section": "33.3 ggplot()",
    "text": "33.3 ggplot()\nggplot() を使って年齢ピラミッドを作ると、より柔軟に対応できますが、手間がかかるうえ、ggplot() の動作への理解が必要です。また、うっかりミスをしやすくなります。\nggplot() を用いて人口ピラミッドを作るために、2 つの棒グラフ（性別ごとに 1 つ）を作成し、一方のプロットの値を負に変換します。そして棒グラフを垂直に表示するために X 軸と Y 軸を反転し、それらの基準点を中央で合わせてプロットを合体させます。\n\n準備\nこの方法では、年齢カテゴリである age_cat5 の列ではなく、年齢の数字型列を使用します。そこで、この年齢の数字型列の型が本当に数字型であることを確認します。\n\nclass(linelist$age)\n\n[1] \"numeric\"\n\n\n以下のようなロジックで、geom_histogram() の代わりに geom_col() を使って、カテゴリデータからピラミッドを作ることができます。\n\n\n\nプロットの作成\nまず、ggplot() を使ってこのようなピラミッドを作るには、以下のようなアプローチになることを理解してください。\n\nggplot() 内で、年齢の数字型列を使用して 2 つのヒストグラムを作成します。2 つのグループ化された値（ここでは、性別の男性と女性）それぞれについて 1 つずつ作成します。これを行うには、性別ごとのヒストグラムのデータを geom_histogram() コマンドの中で指定し、それぞれのフィルターを linelist に適用します。\n一方のグラフは正の値を持ち、もう一方のグラフは負の値に変換します。これにより、プロットの中央に 0 の値を持つ「ピラミッド」が形成されます。負の値は、ggplot2 パッケージ特有の用語である ..count.. を使用して - 1 をかけることにより作成されます。\ncoord_flip() コマンドは、X 軸と Y 軸を切り替え、その結果、グラフは垂直になり、ピラミッドを作成することができます。\n最後に、counts 軸の値のラベルを変更して、ピラミッドの両側で正の値として見えるようにしなければなりません（一方のグラフ描画用の値は負の値であるにもかかわらず）。\n\ngeom_histogram() を使った簡単なバージョンは以下のとおりです。\n\n  # ggplot を開始する\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # 女性のヒストグラム\n  geom_histogram(data = linelist %&gt;% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # 男性のヒストグラム (負に変換された値)\n  geom_histogram(data = linelist %&gt;% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # X 軸と Y 軸を切り替える\n  coord_flip() +\n  \n  # 発症数の軸目盛りの調整\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n\n\n\n\n\n\n\n\n警告：発症数を示す軸の上（下）限の設定が低すぎる場合、棒グラフの値がそれを超えると、棒グラフが完全に消えるか、ggplot() の機能により自動的に短縮され、不自然なグラフになってしまいます。日常的に更新されるデータを分析する場合は、この点に注意してください。以下のように、発症数を示す軸の上（下）限をデータに合わせて自動調整することで、防げます。\nこのシンプルな図に変更・追加できることは、以下を含めたくさんあります。\n\nデータに合わせて発症数の軸の目盛りを自動調整する（前述の警告にあるエラーを回避する）\n色と凡例のラベルを手動で指定する\n\n発症数をパーセンテージに変換する\n発症数を（全体に対する）パーセントに変換するには、プロットする前にデータ上でこの作業を行います。以下では、年齢と性別の発症数を取得し、次に ungroup() を実行し、そして新しいパーセント列を作成するために mutate() を実行しています。もし、男女別のパーセンテージが必要な場合は、ungroup のステップはスキップしてください。\n\n# 割合のデータセットを作成する\npyramid_data &lt;- linelist %&gt;%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %&gt;% \n  ungroup() %&gt;%                 # グループ化解除、そのためパーセンテージはグループごとではない\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,     # 男性を負の数に変換\n            TRUE          ~ NA_real_))    # NA 値の型も数字型でなければならない\n\n重要なのは、最大値と最小値を保存し、目盛りの上（下）限を把握することです。これらの変数はこの後の ggplot() コマンド内で使用します。\n\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nmax_per\n\n[1] 10.9\n\nmin_per\n\n[1] -7.1\n\n\n最後に、パーセントのデータに対して ggplot() を作成します。scale_y_continuous() を指定して、あらかじめ決まっていた長さをそれぞれの方向（正または「負」）に伸ばします。また、floor() と ceiling() を使って、軸目盛り上で適切な方向（下か上）に小数点以下を丸めています。\n\n# ggplot を開始する\n  ggplot()+  # デフォルトの X 軸は年齢(年)\n\n  # 発症数データのグラフ\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # それぞれの棒グラフの枠は白にする\n  \n  # X 軸と Y 軸を反転してピラミッドを縦にする\n  coord_flip()+\n  \n\n  # 軸の目盛りを調整する\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # 値は 2 単位ずつ並べる\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # 絶対値に％をつけて 2 単位ずつ表示する\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # 色や凡例のラベルを手動で指定する\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # 値のラベル（現在は X 軸と Y 軸が反転していることを忘れずに）\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # 表示用のテーマ\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )\n\n\n\n\n\n\n\n\n\n\n\nベースラインとの比較\nggplot() の柔軟性を利用すれば、「真の」または「ベースラインの」人口ピラミッドを表す 2 つめの棒グラフを背景に表示することができます。これは、観測値とベースラインの比較に適した視覚化を可能にします。\n人口のデータをインポートして表示します（ハンドブックとデータのダウンロードの章をご参照ください）。\n\n# 国 A の人口データのインポート\npop &lt;- rio::import(\"country_demographics.csv\")\n\n\n\n\n\n\n\nはじめにいくつかのデータ管理の手順を説明します。\n表示させたい年齢カテゴリの順番を記録します。ggplot() の実装にはいくつかの癖があるため、今回の具体例では、年齢カテゴリを文字列型ベクトルとして保存し、プロット関数で使用する方法が最も簡単です。\n\n# 年齢の正しいカテゴリレベルを記録する\nage_levels &lt;- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n\ndplyr パッケージの bind_rows() 関数を使って、人口のデータと発症数のデータを結合します。\n\nまず、両者がまったく同じ列名、年齢カテゴリの値、および性別の値を持つことを確認します。\n両者が同じデータ構造を持つようにします。年齢カテゴリ、性別、人数、全体に対する発症数の割合の列\n一方をもう一方の上に重ねて結合します (bind_rows())\n\n\n# 人口データ（集団全体に対するパーセント）の作成・変換\n########################################################\npop_data &lt;- pop %&gt;% \n  pivot_longer(      # 性別をピボットして列を縦長形式にする\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %&gt;% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # 集団全体に対するパーセント\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent,               # 男性の場合、パーセントを負に変換する\n     TRUE          ~ NA_real_))\n\n変更された人口のデータセットを確認します。\n\n\n\n\n\n\n今度は、同じデータ処理を発症数のラインリストにも適用してみましょう。全体の数ではなく、発症数の行から始まるので、少し異なります。\n\n# 年齢別・男女別の発症数データを作成し、全体に占める割合を表示する\n#######################################################\ncase_data &lt;- linelist %&gt;%\n  count(age_cat5, gender, name = \"counts\") %&gt;%  # 年齢と性別による発症数\n  ungroup() %&gt;% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # 年齢と性別の層による全体の数に対するパーセントを計算する\n    percent = case_when(                                     # 男性の場合、パーセントを負に変換する\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent,\n      TRUE          ~ NA_real_))\n\n変更された発症数のデータセットを確認します。\n\n\n\n\n\n\nこれで 2 つのデータフレームのデータ構造がそろい、一方がもう一方の上に重なっている状態です（列名は同じです）。それぞれのデータフレームに「名前」を付け、.id = 引数を使用して新しい列「data_source」を作成し、各行がどのデータフレーム由来であるかを示します。この列を使用して、ggplot() でフィルターをかけられます。\n\n# 発症数のデータと人口のデータを結合する（同じ列名、年齢カテゴリの値、性別の値）\npyramid_data &lt;- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n\nプロット関数でプロットの範囲を定義するために使用するパーセントの最大値と最小値を保存します。\n\n# パーセント軸の範囲を定義し、プロットの上（下）限に用いる\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nggplot() を用いてプロットします。\n\n人口データの棒グラフ 1 本（幅が広く、透明度の高い棒）\n発症数データの棒グラフ 1 本（幅が小さく、濃い棒グラフ）\n\n\n# ggplot を開始する\n##############\nggplot()+  # X 軸のデフォルトは年齢(年)\n\n  # 人口データのグラフ\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # 棒グラフの枠は黒にする\n    alpha = 0.2,                                    # 透過度を高くする\n    width = 1)+                                     # 棒グラフの幅は全幅にする\n  \n  # 症例データのグラフ\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # 年齢カテゴリを X 軸とする\n      y = percent,                                # ％ は元の Y 軸と同じ\n      fill = gender),                             # 男女別棒グラフ\n    colour = \"black\",                               # 棒グラフの枠は黒にする\n    alpha = 1,                                      # 透過しない \n    width = 0.3)+                                   # 棒グラフの幅を小さくする\n  \n  # X 軸と Y 軸を反転してピラミッドを縦にする\n  coord_flip()+\n  \n  # 年齢軸の順序が正しいことを手動で確認する\n  scale_x_discrete(limits = age_levels)+     # 前述のコードで定義したもの\n  \n  # パーセントの軸を設定する \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # 上記で定義された最小値と最大値\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # 最小値の % から最大値の % まで 2 単位ずつ表示する \n    labels = paste0(                                                       # ラベルについても同様に貼り付ける... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # 色と凡例ラベルを手動で指定する\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # データに色をつける\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # 凡例に表示されるラベルと記載順を変更する\n  ) +\n\n  # プロットのラベル、タイトル、見出し   \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # 表示用のテーマのオプション\n  theme(\n    legend.position = \"bottom\",                             # 凡例をグラフ下に移動する\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>人口ピラミッドとリッカート尺度</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.jp.html#リッカート尺度",
    "href": "new_pages/age_pyramid.jp.html#リッカート尺度",
    "title": "33  人口ピラミッドとリッカート尺度",
    "section": "33.4 リッカート尺度",
    "text": "33.4 リッカート尺度\nggplot() を使って人口ピラミッドを作成する方法は、リッカート尺度を用いた調査データのプロット作成にも使えます。\nデータを取り込みます（必要に応じてハンドブックとデータのダウンロード章をご参照ください）。\n\n# リッカート尺度による回答データを取り込む\nlikert_data &lt;- rio::import(\"likert_data.csv\")\n\n各回答者のカテゴリ分類（status）と、8 つの質問に対する4 段階のリッカート尺度（「非常に悪い」、「悪い」、「良い」、「非常に良い」）による 回答からなる、以下のようなデータからスタートします。\n\n\n\n\n\n\nまず、データ管理の手順をいくつか紹介します。\n\nデータを縦長形式にピボットする\n回答が概ね「肯定的」か「否定的」かによって、新しい列の direction を作成する\nstatus の列と Response の列の因子レベルの順序を設定する\n最大値を保存し、プロットの上（下）限が適切になるよう設定する\n\n\nmelted &lt;- likert_data %&gt;% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %&gt;% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # 「Very Poor」と「Poor」を逆にしないと実行できない\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# 軸の目盛りの上（下）限を設定するために最大値を保存する\nmelted_max &lt;- melted %&gt;% \n  count(status, Question) %&gt;% # 回答の値を得る\n  pull(n) %&gt;%                 # n 列\n  max(na.rm=T)                # 最大値を得る\n\nプロットを作ってみましょう。上記の年齢ピラミッドのように、2 つの棒グラフを作成し、そのうちの 1 つの値を負に反転させます。\n用いるデータは、集計された値ではなく、観測ごとに 1 行であるため、geom_bar() を使用します。値を負（*-1）に反転するために棒グラフの 1 つで特別な ggplot2 の用語 ..count.. を使用し、値がお互いに重なるように position = \"stack\" を設定します。\n\n# プロットの作成\nggplot()+\n     \n  # 「否定的」な回答の棒グラフ \n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # 値を負に反転する\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # 「肯定的」な回答の棒グラフ \n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # X 軸と Y 軸を反転させる\n     coord_flip()+\n  \n     # 0 の位置に黒い縦線をひく\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # ラベルをすべて正の数に変換する\n    scale_y_continuous(\n      \n      # X 軸の目盛りの上限\n      limits = c(-ceiling(melted_max/10)*11,    # 否定から肯定まで 10 ずつ並べ、端は外側に丸め、最も近い 5 にする\n                 ceiling(melted_max/10)*10),   \n      \n      # X 軸の目盛りの値\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # X 軸の目盛りのラベル\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # 目盛りに色を手動で割り当てる  \n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # 色分けする\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # 凡例を指定する\n     \n    \n     \n    # プロット全体をファセット化し、各質問はサブプロットにする\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # ラベル、タイトル、見出し\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # 表示の調整 \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # ファセットのサブタイトル\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # 各ファセットを黒枠で囲む",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>人口ピラミッドとリッカート尺度</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.jp.html#参考資料",
    "href": "new_pages/age_pyramid.jp.html#参考資料",
    "title": "33  人口ピラミッドとリッカート尺度",
    "section": "33.5 参考資料",
    "text": "33.5 参考資料\napyramid ドキュメント",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>人口ピラミッドとリッカート尺度</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.jp.html",
    "href": "new_pages/heatmaps.jp.html",
    "title": "34  ヒートマップ",
    "section": "",
    "text": "34.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ヒートマップ</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.jp.html#準備",
    "href": "new_pages/heatmaps.jp.html#準備",
    "title": "34  ヒートマップ",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、解析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについては、R の基礎 の章を参照してください。\n\npacman::p_load(\n  tidyverse,       # データ操作と可視化\n  rio,             # データのインポート\n  lubridate        # 日付処理\n  )\n\nデータセット\n感染伝播マトリックスのセクションでは、流行をシュミレートした症例ラインリストを使用し、報告率の時系列のセクションでは、日別のマラリア患者数のデータセットを使用しています。これらのデータの読み込みとクリーニングは、それぞれのセクションで行います。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ヒートマップ</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.jp.html#感染伝播マトリックス",
    "href": "new_pages/heatmaps.jp.html#感染伝播マトリックス",
    "title": "34  ヒートマップ",
    "section": "34.2 感染伝播マトリックス",
    "text": "34.2 感染伝播マトリックス\nヒートマップは、マトリックスを視覚化するのに便利です。マトリックス視覚化の一つの例として、アウトブレイクにおける「誰から誰に感染がうつったか」を図示することができます。これは、感染イベントに関するデータがあることが前提となっています。\nなお、接触者の追跡 の章には、別の（より単純な）データセットを用いて、ヒートマップによる接触マトリックスを作成する例が掲載されています。また、ggplot の基礎 の章では、この単純なデータを使用した密度マップの作成について説明しています。本章で扱う例は、症例のラインリストから始まるので、プロット可能なデータフレームになる前にかなりのデータ操作が必要ですが、その結果として多くのシナリオから選ぶことが可能になっています。\nまずは、エボラ出血熱の流行をシミュレーションした症例ラインリストを使います。こちら から「前処理済みの」ラインリスト（.rdsファイル）をダウンロードすることができ、rio パッケージの import() を使用してデータをインポートすることができます（.xlsx、.rds、.csv など多様なファイル形式のインポートに対応しています。詳しくは、データのインポート・エクスポート の章を参照してください）。\nラインリストの最初の 50 行を以下に表示します。\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nこのラインリストでは、\n\n1 症例ごとに 1 行となっており、それぞれの症例に case_id が振られています。\ninfector 列には、感染者の case_id が含まれており、その感染者も症例としてラインリストに含まれています。\n\n\n\n\n\n\n\n\nデータ準備\n目的：感染者と接触者を年代別にグループ分けし、感染者と接触者の年代別のグループを組み合わせた感染ペアを行として、その各感染ペアが全体に占める割合を数字型の列とする縦型のデータフレームを作成する必要があります。\nこれを実現するには、いくつかのデータ操作を行う必要があります。\n\n感染先のデータフレームの作成\nまず症例 ID、年代、感染源の ID を含むデータフレームを作成し、case_ages という変数名をつけます。最初の 50 行は以下のように表示されます。\n\ncase_ages &lt;- linelist %&gt;% \n  select(case_id, infector, age_cat) %&gt;% \n  rename(\"case_age_cat\" = \"age_cat\")\n\n\n\n\n\n\n\n\n\n感染源のデータフレームの作成\n次に、感染源のデータフレームを作成します。まず、感染源 ID のみの 1 列から構成されているデータフレームを作成し、欠損値を削除します（全ての症例の感染源が判明している訳ではない）。最初の 50 行は以下のように表示されます。\n\ninfectors &lt;- linelist %&gt;% \n  select(infector) %&gt;% \n  drop_na(infector)\n\n\n\n\n\n\n\n次に、感染源の年代を取得します。ラインリストには、感染源の症例の年代が直接は記載されていないため、簡単には取得できず、ラインリストと感染源 ID を結合する必要があります。感染源のデータフレームから始めて、左側に「ベースライン」のデータフレームの infector 列（感染者 ID 列）を書き、右側にラインリストの case_id 列を書いて両者を紐づけ、ラインリストを感染源のデータフレームに left_join() （左結合）します。\n結合すると、ラインリスト内の感染源の症例のデータ（年代）が、感染源の行に追加されました。最初の 50 行を以下に表示します。\n\ninfector_ages &lt;- infectors %&gt;%             # 感染源のデータフレームから始める\n  left_join(                               # それぞれの感染源の行にラインリストデータを追加する\n    linelist,\n    by = c(\"infector\" = \"case_id\")) %&gt;%    # infector列とcase id 列で紐付ける\n  select(infector, age_cat) %&gt;%            # 必要な列のみを抽出する\n  rename(\"infector_age_cat\" = \"age_cat\")   # 分かりやすいように列名を変更\n\n\n\n\n\n\n\n次に、感染先症例とその年代を、感染源症例とその年代に結合します。これらのデータフレームはそれぞれ infector という列を持っているので、この列で紐付けます。最初の行は以下のように表示されます。\n\nages_complete &lt;- case_ages %&gt;%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %&gt;%        # infector 列で紐付け\n  drop_na()                     # 欠損値のある行を削除\n\nWarning in left_join(., infector_ages, by = \"infector\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 6 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n以下は、感染先症例と感染源症例の年代階級別の症例数を単純にクロス集計したものです。分かりやすくするためにラベルをつけています。\n\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)\n\n       infectors\ncases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n  0-4   105 156   105   114   143   117    13   0\n  5-9   102 132   110   102   117    96    12   5\n  10-14 104 109    91    79   120    80    12   4\n  15-19  85 105    82    39    75    69     7   5\n  20-29 101 127   109    80   143   107    22   4\n  30-49  72  97    56    54    98    61     4   5\n  50-69   5   6    15     9     7     5     2   0\n  70+     1   0     2     0     0     0     0   0\n\n\nこの表をデータフレームに変換するには、base R の data.frame() を使います。これにより自動で縦型のデータフレームとなり、ggplot() に適した形となります。最初の行は以下のようになります。\n\nlong_counts &lt;- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\n\n\n\n\n\n\n\nさらに、base R の prop.table() をテーブルに適用して、数の代わりに全体の割合を出します。最初の 50 行は以下のようになります。\n\nlong_prop &lt;- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))\n\n\n\n\n\n\n\n\n\n\nヒートマップの作成\nさて、いよいよ ggplot2 パッケージで geom_tile() 関数を用いてヒートマップを作成します。色・塗りつぶしのスケール、特に scale_fill_gradient() 関数についてより広範囲に学びたい方は、ggplot の基礎 の章を参照してください。\n\ngeom_tile() の aes() で、x に case age、y に infector age を指定します。\n\nまた、aes() では、引数 fill = を Freq 列に指定します。これはタイルの色に変換される値です。\n\nscale_fill_gradient() でスケールカラーを設定します。高い値の色と、低い値の色を何色にするのかそれぞれ指定することができます。\n\nscale_color_gradient() とは異なることに注意してください！今回は塗りつぶしが必要です。\n\n色は 「fill」を介して作られるので、 labs() の fill = 引数を使って、凡例のタイトルを変更することができます。\n\n\nggplot(data = long_prop)+       # 割合が Freq 列に格納された縦型データを使用\n  geom_tile(                    # タイルで可視化\n    aes(\n      x = cases,         # x軸は感染先の年代\n      y = infectors,     # y軸は感染源の年代\n      fill = Freq))+            # タイルの色分けを Freq 列で決定する\n  scale_fill_gradient(          # タイルの色を調整する\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # ラベル\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # 凡例タイトル\n  )",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ヒートマップ</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.jp.html#報告率の時系列",
    "href": "new_pages/heatmaps.jp.html#報告率の時系列",
    "title": "34  ヒートマップ",
    "section": "34.3 報告率の時系列",
    "text": "34.3 報告率の時系列\n公衆衛生では、施設や管轄区域などにおける経時的な傾向を評価することが目的の一つであることがよくあります。このような経時的な傾向を可視化する方法の一つが、横軸を時間、縦軸を各施設としたヒートマップです。\n\nデータ準備\nまず、各施設におけるマラリアに関する日々の報告のデータセットをインポートします。データには、日付、州、地区、マラリアの症例数が含まれています。これらのデータをダウンロードする方法については、ハンドブックとデータのダウンロード の章を参照してください。以下は、データセットの最初の 30 行です。\n\nfacility_count_data &lt;- import(\"malaria_facility_count_data.rds\")\n\n\n\n\n\n\n\n\n集計とサマリー\nこのセクションの目的は、日別の施設ごとのマラリア患者数（前のタブで表示されています）を、週単位の施設ごとの報告率（この場合は、施設が何らかのデータを報告した日数の割合）に変換することです。以下の例では、Spring 地区のデータのみを表示します。\n以下のステップを実行します。\n\nデータを適切にフィルタリング（場所、日付ごと）します。\nlubridate パッケージの floor_date() を使って week 列を作成します。\n\nこの関数は、指定した日付の週の開始日を、指定した曜日（例：“Mondays”）で返します。\n\nデータは「場所」と「週」の列でグループ化され、「施設 - 週」の分析単位が作成されます。\n\nsummarise() 関数を使って、「施設 - 週」グループごとの統計サマリーを反映する新しい列を作成します。\n\n1 週間の日数 (固定値7)\n\n施設 - 週からの報告回数（7 件以上の可能性もあります！）\n\n施設 - 週で報告されたマラリア患者数の合計（興味がある場合）\n\nデータが報告された施設 - 週における日数\n\n施設 - 週の7日間のうち、データが報告された日数の割合\n\nこのデータフレームを right_join() （右結合）で、全ての「施設 - 週」の組み合わせを包括的なリストとして結合し、データセットを完成させます。全ての組み合わせの行列は、データフレーム（. で表されます）の 2 列に対して expand() 関数を適用することで作成されます。right_join() が使用されているので、expand() されたデータフレームのすべての行は保持され、必要であれば agg_weeks に追加されます。これらの新しい行は、NA（欠損値）の要約された値で表示されます。\n\n以下に順を追って説明します。\n\n# 週別の集計を作成する\nagg_weeks &lt;- facility_count_data %&gt;% \n  \n  # データのフィルタリング\n  filter(\n    District == \"Spring\",\n    data_date &lt; as.Date(\"2020-08-01\")) \n\nこれでデータセットの行数が 3038 行から 608 行になりました。\n次に、各行の週の開始日を示す week 列を作成します。これは、lubridate パッケージと floor_date() 関数を使って行います。この関数は「週」に設定され、週の始まりが月曜日（週の1日目、日曜日は 7 日目）になるように設定されています。\n\nagg_weeks &lt;- agg_weeks %&gt;% \n  # data_date 列から week 列を作成\n  mutate(\n    week = lubridate::floor_date(                     # week 列を新たに作成\n      data_date,                                      # 日付列\n      unit = \"week\",                                  # 週の開始を指定\n      week_start = 1))                                # 月曜スタートに指定 \n\n新しい week 列は、データフレームの一番右に表示されます。\n\n\n\n\n\n\nここで、データを「施設 - 週」にグループ分けし、「施設 - 週」ごとの統計データを作成するために集計を行います。詳細は、記述統計表の作り方 の章を参照してください。グループ化自体はデータフレームを変更しませんが、その後の要約統計の計算に影響します。\n最初の 30 行を以下に示します。目的の要約統計量を反映するために、列が完全に変更されたことに注意してください。各行は、1 つの「施設 - 週」を反映しています。\n\nagg_weeks &lt;- agg_weeks %&gt;%   \n\n  # 「施設 - 週」でグループ化\n  group_by(location_name, week) %&gt;%\n  \n  # グループ化されたデータに対して要約統計量の列を作成\n  summarize(\n    n_days          = 7,                                          # 1週間の日数（7日）\n    n_reports       = dplyr::n(),                                 # 「施設 - 週」 からの報告回数（7件以上の可能性あり）\n    malaria_tot     = sum(malaria_tot, na.rm = T),                # 「施設 - 週」 で報告されたマラリア患者数の合計\n    n_days_reported = length(unique(data_date)),                  # データが報告された「施設 - 週」における日数\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;%  # 「施設 - 週」 の7日間のうち、データが報告された日数の割合\n  ungroup(location_name, week)                                    # 次の処理で expand() が動作するように ungroup() を実行\n\n\n\n\n\n\n\n最後に、以下のコマンドを実行して、報告のなかった週も含めて、可能性のある全ての「施設 - 週」の組み合わせがデータ中に存在することを確認します。\n確認するために、 right_join() を使用して week 列と location_name の列の全ての組み合わせを含むようにデータセットを拡張します（データセットは「. 」で表されます）。詳細は、データの縦横変換 の章にある expand() 関数のドキュメントを参照してください。このコードを実行する前の段階ではデータセットには 107 行が含まれています。\n\n# 可能な全ての施設-週の組み合わせを作成\nexpanded_weeks &lt;- agg_weeks %&gt;% \n  tidyr::expand(location_name, week)  # 可能な施設-週の組み合わせすべてを含んだデータフレームを作成する\n\n全 180 行の expanded_weeks は以下のようなデータになっています。\n\n\n\n\n\n\n以下のコードを実行する前の段階では、agg_weeks は 107 行でした。\n\n# 拡張された施設週間リストと right-join して、データの欠損を補填\nagg_weeks &lt;- agg_weeks %&gt;%      \n  right_join(expanded_weeks) %&gt;%                            # 可能な全ての施設-週の組み合わせが含まれるようにする\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # 欠損値を0に変換\n\nJoining with `by = join_by(location_name, week)`\n\n\nコードを実行した後、agg_weeks は 180 行に変わっています。\n\n\n\n\nヒートマップの作成\nggplot2 パッケージの geom_tile() を用いて ggplot グラフを作成します。\n\nx 軸の週は日付型（Date）に変換されているので、scale_x_date() が使用できます。\n\ny 軸の location_name は全ての施設名を表示します。\n\n塗りつぶしは p_days_reported に対して行われ、その「施設 - 週」の報告率を示します。\n\nscale_fill_gradient() は数値の塗りつぶしに使用され、高い値の色（high）、低い値の色（low）、NA の色を指定します。\n\nx 軸に scale_x_date() を使用し、2 週間ごとのラベルとその形式を指定します。\n\nテーマやラベルを必要に応じて調整することができます。\n\n\n\n\n基本プロット\n基本的なヒートマップは、デフォルトの色やスケールなどを使用して、以下のように作成できます。上で説明したように、geom_tile() の aes() 内では、x 軸、y 軸、および fill = の列を指定する必要があります。fill は色として表示される数値です。\n\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))\n\n\n\n\n\n\n\n\n\n\n応用プロット\n以下のように、ggplot2 の関数を追加することで、このプロットをより美しくできます。詳細は、ggplot の基礎 の章を参照して下さい。\n\nggplot(data = agg_weeks)+ \n  \n  # データをタイルで表示\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # 罫線を白に指定\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # 日付軸\n  scale_x_date(\n    expand = c(0,0),             # 両端の余分なスペースを削除\n    date_breaks = \"2 weeks\",     # 2週間ごとの日付ラベルを指定\n    date_labels = \"%d\\n%b\")+     # 月の上に日付を表示 (\\n は改行を示す)\n  \n  # テーマ\n  theme_minimal()+                                  # 背景を簡潔にする\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # 凡例の高さの指定\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # 凡例の幅の指定\n    \n    axis.text.x = element_text(size=12),              # 軸のテキストサイズの指定\n    axis.text.y = element_text(vjust=0.2),            # 軸のテキストの場所の調整\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # 軸のタイトルのサイズの指定と太字フォントの指定\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # タイトルを右揃えにして、サイズを大きく、太字にする\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # 脚注を右揃えにしてイタリック体にする\n    )+\n  \n  # 凡例\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # 凡例のタイトルを指定\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\n\n\n\n\n\n\n\n\n\n\ny軸の順番の調整\n現在、各施設は下から上へ「アルファベット順」に並んでいます。y 軸の施設の順番を調整したい場合は、対象の列を因子型に変換して順番を指定してください。詳細は、因子（ファクタ）型データ の章を参照して下さい。\n施設数が多く、全てを書き出すのは大変なので、別の方法として、データフレームに施設を並べ、その結果得られる名前の列を因子レベルの順序とすることを試みます。以下では、location_name 列を因子に変換し、そのレベルの順序を、全期間における施設ごとの報告日の合計数に基づいて設定します。\nそのために、まず施設ごとの総報告数を昇順に並べたデータフレームを作成します。このベクトルを使って、プロットにおける因子レベルの順序を決めることができます。\n\nfacility_order &lt;- agg_weeks %&gt;% \n  group_by(location_name) %&gt;% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %&gt;% \n  arrange(tot_reports) # 昇順\n\nデータフレームは以下のようになります。\n\n\n\n\n\n\nここで、上で扱ったデータフレームの列（facility_order$location_name）を使用して、データフレーム agg_weeks における location_name の因子レベルの順序を調整します。\n\n# パッケージの読み込み\npacman::p_load(forcats)\n\n# 因子を作成して、レベルを決める\nagg_weeks &lt;- agg_weeks %&gt;% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\n\nそして、次は location_name が順序付きの因子となるように、データを再プロットします。\n\nggplot(data = agg_weeks)+ \n  \n  # データをタイルで表示\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # 罫線を白に指定\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # 日付軸\n  scale_x_date(\n    expand = c(0,0),             # 両端の余分なスペースを削除\n    date_breaks = \"2 weeks\",     # 2週間ごとの日付ラベルを指定\n    date_labels = \"%d\\n%b\")+     # 月の上に日付を表示 (\\n は改行を示す)\n  \n  # テーマ\n  theme_minimal()+                                  # 背景を簡潔にする\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # 凡例の高さの指定\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # 凡例の幅の指定\n    \n    axis.text.x = element_text(size=12),              # 軸のテキストサイズの指定\n    axis.text.y = element_text(vjust=0.2),            # 軸のテキストの場所の調整\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # 軸のタイトルのサイズの指定と太字フォントの指定\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # タイトルを右揃えにして、サイズを大きく、太字にする\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # 脚注を右揃えにしてイタリック体にする\n    )+\n  \n  # 凡例\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # 凡例のタイトルを指定\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\n\n\n\n\n\n\n\n\n\n\n値の表示\nタイルの上に geom_text()レイヤーを追加して、各タイルの数値を表示することができます。小さなタイルがたくさんある場合、小さくてはっきり見えないかも知れないので注意して下さい！\n次のコードを追加します： geom_text(aes(label = p_days_reported)) これは、各タイルにテキストで数値を追加するコードです。表示される数字は、引数 label = に割り当てられた値で、以下の例では色のグラデーションを作成するためにも使用されているのと同じ数値列 p_days_reported を指定しています。\n\nggplot(data = agg_weeks)+ \n  \n  # データをタイルで表示\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # 罫線を白に指定\n  \n  # テキスト\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+      # タイルの上に数値を表示\n  \n  # タイルの塗りつぶし\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # 日付軸\n  scale_x_date(\n    expand = c(0,0),             # 両端の余分なスペースを削除\n    date_breaks = \"2 weeks\",     # 2週間ごとの日付ラベルを指定\n    date_labels = \"%d\\n%b\")+     # 月の上に日付を表示 (\\n は改行を示す)\n  \n  # テーマ\n  theme_minimal()+                                    # 背景を簡潔にする\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # 凡例の高さの指定\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # 凡例の幅の指定\n    \n    axis.text.x = element_text(size=12),              # 軸のテキストサイズの指定\n    axis.text.y = element_text(vjust=0.2),            # 軸のテキストの場所の調整\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # 軸のタイトルのサイズの指定と太字フォントの指定\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # タイトルを右揃えにして\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # 脚注を右揃えにしてイタリック体にする\n    )+\n  \n  # 凡例\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # 凡例のタイトルを指定\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ヒートマップ</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.jp.html#参考資料",
    "href": "new_pages/heatmaps.jp.html#参考資料",
    "title": "34  ヒートマップ",
    "section": "34.4 参考資料",
    "text": "34.4 参考資料\nscale_fill_gradient()\nR graph gallery - heatmap",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ヒートマップ</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html",
    "href": "new_pages/diagrams.jp.html",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "",
    "text": "35.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html#準備",
    "href": "new_pages/diagrams.jp.html#準備",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "",
    "text": "パッケージを読み込む\n以下のコードを実行すると、図の作成に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R のパッケージについての詳細は、R の基礎 を参照してください。\n\npacman::p_load(\n  DiagrammeR,     # フロー図\n  networkD3,      # 沖積図・サンキー図\n  tidyverse)      # データ管理と図作成\n\n\n\nデータをインポート\nこの章では、ほとんどデータセットを必要としません。しかし、サンキー図（Sankey diagram） のセクションでは、エボラ出血熱の流行をシミュレートした症例ラインリストを使用します。お手元の環境でこの章の内容を実行したい方は、こちら をクリックして「前処理済みの」ラインリストをダウンロードしてください（.rds 形式でダウンロードされます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、データのインポート・エクスポート の章をご覧ください）。\n\n# ラインリストをインポート\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nラインリストの最初の 50 行を以下に表示します。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html#フローチャート",
    "href": "new_pages/diagrams.jp.html#フローチャート",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "35.2 フローチャート",
    "text": "35.2 フローチャート\nR パッケージの DiagrammeR を使って、フローチャートを作成することができます。グラフは静的なものもあれば、データセットの変化に基づいて動的に調整することもできます。\nツール\n“Graphviz” で図を作成するには、grViz() を用います。この関数は、図を作成するための指示を含む文字列の入力を受け付けます。この文字列の中には、DOT と呼ばれる別の言語で書かれた指示が含まれていますが、基本は容易に学ぶことができます。\n基本的な構造\n\n指示を開始する grViz(\"\nグラフの方向性と名前を指定し、波括弧を開く - 例：digraph my_flow_chart {\nグラフ文（Graph 文） - レイアウト、ランク方向\nノード文 （Node 文） - ノードを作成\nエッジ文（Edge 文） - ノード間のリンクを与える\n指示を閉じる }\"\n\n\n簡単な例\n以下に 2 つの簡単な例を示します。\n最小限のプロットを作成します。\n\n# 最小限のプロット\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -&gt; b -&gt; c\n}\")\n\n\n\n\n\nもう一つは、公衆衛生の文脈でもう少し応用が効く例です。\n\ngrViz(\"                           # すべての指示は大きな文字列の中にある\ndigraph surveillance_diagram {    # digraph は directional graph という意味で、その後にグラフ名が入る\n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodes\n  #######\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]               # circle の大きさ\n  \n  １番目                          # ノードの名称\n  ２番目\n  ３番目\n\n  # edges\n  #######\n  １番目   -&gt; ２番目 [label = '症例移送']\n  ２番目   -&gt; ３番目 [label = '症例移送']\n}\n\")\n\n\n\n\n\n\n\n構文\n基本的な構文\nノード名とエッジ文は、スペース、セミコロン、改行で区切ることができます。\nランクの方向\nグラフ文の rankdir 引数を調整することで、プロットを左から右へと移動させることができます。デフォルトは TB（top-to-bottom）ですが、LR（left-to-right）、RL、BT のいずれかを指定できます。\nノード名\nノード名は、上の例のように単一の単語で構いません。複数の単語や特殊文字（括弧やダッシュなど）を使用する場合は、ノード名を一重引用符（' '）で囲みます。ノード名を短くして、以下のように角括弧（[ ]）で囲んでラベルを割り当てる方が簡単な場合があります。ノード名の中に改行を入れたい場合は、ラベルを介して行う必要があります。以下のように、一重引用符で囲んだノードラベルの中に \\n を使用してください。\nサブグループ\nエッジ文の中で、サブグループはエッジの両側に波括弧（{ }）で作成できます。エッジは括弧内のすべてのノードに適用され、省略可能です。\nレイアウト\n\ndot（rankdir を TB、LR、RL、BT のいずれかに設定）\nneato\ntwopi\ncirco\n\nノード - 属性値\n\nlabel（テキスト、半角スペースを含む場合は一重引用符で囲む）\n\nfillcolor（多数の色が使用可能）\n\nfontcolor\n\nalpha（透明度 0-1）\n\nshape（ellipse、oval、diamond、egg、plaintext、point、square、triangle）\n\nstyle\n\nsides\n\nperipheries\n\nfixedsize（縦（高さ）x 横（幅））\n\nheight\n\nwidth\n\ndistortion\n\npenwidth （境界線の太さ）\nx（左・右への変位）\n\ny（上・下への変位）\n\nfontname\n\nfontsize\n\nicon\n\nエッジ - 属性値\n\narrowsize\n\narrowhead（normal、box、crow、curve、diamond、dot、inv、none、tee、vee）\n\narrowtail\n\ndir（direction, ）\n\nstyle（dashed, …）\n\ncolor\n\nalpha\n\nheadport （矢印の前のテキスト）\ntailport （矢印の後のテキスト）\nfontname\n\nfontsize\n\nfontcolor\n\npenwidth （矢の太さ）\nminlen （長さの最長値）\n\n色名：16 進数の値または ‘X11’ の色名、X11 の詳細は こちら を参照してください。\n\n\n複雑な例\n以下の例は、上で作成した surveillance_diagram を発展させたもので、複雑なノード名、グループ化されたエッジ、色、スタイルを追加しています。\nDiagrammeR::grViz(\"               # すべての指示は大きな文字列の中にあります。\ndigraph surveillance_diagram {    # digraph は directional graph という意味で、その後にグラフ名が入ります。\n  \n  # graph 文\n  #################\n  graph [layout = dot,\n         rankdir = TB,            # layout top-to-bottom\n         fontsize = 10]\n  \n\n  # ノード (円)\n  #################\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary   [label = '第一\\n施設'] \n  Secondary [label = '第二\\n施設'] \n  Tertiary  [label = '第三\\n施設'] \n  SC        [label = 'サーベイランス\\n調整',\n             fontcolor = darkgreen] \n  \n  # エッジ\n  #######\n  Primary   -&gt; Secondary [label = ' 症例移送',\n                          fontcolor = red,\n                          color = red]\n  Secondary -&gt; Tertiary [label = ' 症例移送',\n                          fontcolor = red,\n                          color = red]\n  \n  # エッジのグループ\n  {Primary Secondary Tertiary} -&gt; SC [label = '症例報告',\n                                      fontcolor = darkgreen,\n                                      color = darkgreen,\n                                      style = dashed]\n}\n\")\n\n\n\n\n\n\nサブグラフのクラスター\nノードをボックス型のクラスターにまとめるには、同じ名前のサブグラフ（subgraph name {}）の中にノードを入れます。各サブグラフをバウンディングボックス内で識別するには、以下の 4 つのボックスで示すように、サブグラフの名前を “cluster” で始めます。\nDiagrammeR::grViz(\"             # すべての指示は大きな文字列の中にある\ndigraph surveillance_diagram {  # digraph は directional graph という意味で、その後にグラフ名が入る\n  \n  # グラフ文\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n\n  # ノード (円)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # circle の大きさ\n  \n  subgraph cluster_passive {\n    Primary   [label = '第一\\n施設] \n    Secondary [label = '第二\\n施設'] \n    Tertiary  [label = '第三\\n施設'] \n    SC        [label = 'サーベイランス\\n調整',\n               fontcolor = darkgreen] \n  }\n  \n  # ノード (ボックス)\n  ###############\n  node [shape = box,                     # ノードの形状\n        fontname = Helvetica]            # ノード中のフォント\n  \n  subgraph cluster_active {\n    Active [label = '能動的\\nサーベイランス'] \n    HCF_active [label = 'HCF\\n能動的探索']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'イベントベース\\nサーベイランス (EBS)'] \n    社会メディア\n    ラジオ\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = '地域参加型\\nサーベイランス (CBS)']\n    RECOs\n  }\n\n\n  # エッジ\n  #######\n  {Primary Secondary Tertiary} -&gt; SC [label = '症例報告']\n\n  Primary   -&gt; Secondary [label = '症例移送',\n                          fontcolor = red]\n  Secondary -&gt; Tertiary [label = '症例移送',\n                          fontcolor = red]\n  \n  HCF_active -&gt; Active\n  \n  {社会メディア ラジオ} -&gt; EBS\n  \n  RECOs -&gt; CBS\n}\n\")\n\n\n\n\n\n\nノードの形状\n以下の例は、こちらのチュートリアル から引用したもので、適用されたノード形状と、連続するエッジ接続の略記法を示しています。\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# ノードのグローバル・スタイルを定義します。必要に応じてボックス内でこれらを上書きすることができます。\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'データ 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'データ 2', shape = folder, fillcolor = Beige]\nprocess [label =  'データ \\n 処理']\nstatistical [label = '統計 \\n 解析']\nresults [label= '結果']\n\n# ノードIDを持つエッジ定義\n{data1 data2}  -&gt; process -&gt; statistical -&gt; results\n}\")\n\n\n\n\n\n\n\n出力\n出力の取り扱いと保存方法\n\n出力結果は、RStudio の Viewer ペインに表示されます。デフォルトでは右下に Files、Plots、Packages、Help と並んで表示されます。\n出力結果をエクスポートしたい場合は、Viewer ペインから “Save as image” （「画像として保存」）または “Copy to clipboard” （「クリップボードにコピー」）を選択してください。画像は指定したサイズに調整されます。\n\n\n\nパラメータ化された図形\n以下は、こちらのチュートリアル からの引用です。\n「パラメータ化された図形:：R で図形を設計することの大きな利点は、R の値をフローチャートに直接読み込んで、図形を分析に直結させることができることです。例えば、プロセスの各段階の後に値を削除するフィルタリングプロセスを作成したとすると、プロセスの各段階の後にデータセットに残っている値の数を図に表示することができます。これを実現するには、図の中で @@X 記号を直接使用し、プロットのフッターで [X]: を使用して参照します（X は一意の数値インデックス）。」\nパラメータ化された図形に興味をお持ちの方は、引用元のチュートリアルをご覧ください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html#沖積図サンキー図",
    "href": "new_pages/diagrams.jp.html#沖積図サンキー図",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "35.3 沖積図・サンキー図",
    "text": "35.3 沖積図・サンキー図\n\nパッケージを読み込む\n以下のコードを実行すると、図の作成に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base の library() を使用して読み込むこともできます。R パッケージの詳細については、R の基礎 の章を参照してください。\nここでは、図を作成するために networkD3 パッケージを読み込み、データ操作のための tidyverse パッケージも読み込んでいます。\n\npacman::p_load(\n  networkD3,\n  tidyverse)\n\n\n\nデータセットからプロット\nデータセット内のつながりをプロットします。以下では、networkD3 パッケージを linelist という症例ラインリストで使ってみます。オンラインチュートリアルをご覧になりたい方は、こちら を参照ください。\nまず、年齢区分と病院の組み合わせごとに、症例数を集計します。わかりやすくするために、年齢区分が欠落している症例は除外しました。また、hospital 列と age_cat 列の列名をそれぞれ source と target に変更します。これらの列は、沖積図の 2 つの面になります。\n\n# 病院と年齢区分で集計\nlinks &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = hospital,\n         target = age_cat)\n\nデータセットは次のようになります。\n\n\n\n\n\n\n次に、すべてのダイアグラム・ノードのデータフレームを、name という列で作成します。name 列は、hospital 列と age_cat 列のすべての値で構成されます。name 列を作成する前に、hospital 列と age_cat 列のデータ型が文字型となっているか確認してください。また、後述のコードで作成する ID 列（IDsource 列と IDtarget 列）をラベルではなく数字型に変更します。\n\n# ユニークなノード名\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\nnodes  # 表示\n\n                                   name\n1                      Central Hospital\n2                     Military Hospital\n3                               Missing\n4                                 Other\n5                         Port Hospital\n6  St. Mark's Maternity Hospital (SMMH)\n7                                   0-4\n8                                   5-9\n9                                 10-14\n10                                15-19\n11                                20-29\n12                                30-49\n13                                50-69\n14                                  70+\n\n\n次に、上述の count() で作成した links データフレームを編集します。 2 つの数値列 IDsource と IDtarget を追加します。これらはノード間のリンクを実際に反映・作成します。 これらの列にはソースノードとターゲットノードの行番号（位置）が入ります。 ポジション番号が（1 ではなく）0 から始まるように、1 を引きます。\n\n# 名前ではなく数値にマッチング\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\nlinks データセットは以下のようになります。\n\n\n\n\n\n\nでは、sankeyNetwork() を使用してサンキー図をプロットしてみましょう。 コンソールで ?sankeyNetwork を実行すると、関数内で使用される各引数について詳細を確認することができます。 なお、iterations = 0 を設定しないと、ノードの順番が期待通りにならないことがあります。\n\n# plot\n######\np &lt;- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # ノードの順序をデータ順にする\np\n\n\n\n\n\n次に、患者のアウトカムも含まれている例を示します。 なお、データ準備・前処理の段階で、年齢層と 病院、またこれとは別に病院とアウトカムの間の症例の数を計算し、bind_rows() で両者のカウントを結合しています。\n\n# 病院と年齢区分で集計\nage_hosp_links &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = age_cat,          # 列名の変更\n         target = hospital)\n\nhosp_out_links &lt;- linelist %&gt;% \n    drop_na(age_cat) %&gt;% \n    select(hospital, outcome) %&gt;% \n    count(hospital, outcome) %&gt;% \n    rename(source = hospital,       # 列名の変更\n           target = outcome)\n\n# リンクを結合\nlinks &lt;- bind_rows(age_hosp_links, hosp_out_links)\n\n# ユニークなノード名\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\n# ID番号を生成\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\n# プロットする\n######\np &lt;- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np\n\n\n\n\n\nhttps://www.displayr.com/sankey-diagrams-r/",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html#イベントのタイムライン",
    "href": "new_pages/diagrams.jp.html#イベントのタイムライン",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "35.4 イベントのタイムライン",
    "text": "35.4 イベントのタイムライン\n特定のイベントを表示するタイムラインを作るには、vistime パッケージを使用します。\n詳細は、こちらのドキュメント をご覧ください。\n\n# パッケージの読み込み\npacman::p_load(vistime,  # タイムラインを作成\n               plotly    # インタラクティブな可視化\n               )\n\nここでは、まず関心のあるイベントが含まれているデータセットをご紹介します。\n\n\n\n\n\n\n\np &lt;- vistime(data)    # vistime を適用  \n\nlibrary(plotly)\n\n# step 1: リストに変換  \npp &lt;- plotly_build(p)\n\n# step 2: マーカーの大きさ  \nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size &lt;- 10\n}\n\n# step 3: テキストの大きさ  \nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size &lt;- 10\n}\n\n\n# step 4: テキストの位置  \nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition &lt;- \"right\"\n}\n\n# 表示  \npp",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html#dags",
    "href": "new_pages/diagrams.jp.html#dags",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "35.5 DAGs",
    "text": "35.5 DAGs\n前述のように、DiagammeR パッケージと DOT 言語を使って手動で DAG を構築することができます。\nまた、ggdag や daggity などのパッケージもあります。\nDAG の紹介 ggdag に関するドキュメント\nR で dags を使用した統計的因果推論",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.jp.html#参考資料",
    "href": "new_pages/diagrams.jp.html#参考資料",
    "title": "35  フローチャート・サンキー図・タイムライン",
    "section": "35.6 参考資料",
    "text": "35.6 参考資料\n本章の DOT言語に関する大部分はこちら のチュートリアルを参考にしています。\nより詳細な DiagammeR に関するチュートリアルは、こちら を参照ください。\nサンキー図については、こちら のウェブサイトも参考にしてください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>フローチャート・サンキー図・タイムライン</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.jp.html",
    "href": "new_pages/combination_analysis.jp.html",
    "title": "36  複数回答データの分析",
    "section": "",
    "text": "36.1 データ準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>複数回答データの分析</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.jp.html#データ準備",
    "href": "new_pages/combination_analysis.jp.html#データ準備",
    "title": "36  複数回答データの分析",
    "section": "",
    "text": "パッケージを読む込む\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  tidyverse,     # データ管理と可視化\n  UpSetR,        # 複数回答データ分析用のパッケージ\n  ggupset)       # 複数回答データ分析用のパッケージ\n\n\n\n\nデータをインポートする\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください）。\n\n# ラインリストをインポートする \nlinelist_sym &lt;- import(\"linelist_cleaned.rds\")\n\nこのラインリストには、報告された 5 つの症状について、症状あり（yes）か症状なし（no）を示す変数（列）が含まれています。ggupset パッケージを使ってプロットを作成するために、変数の前処理が必要です。まず、データを確認しましょう（症状の変数（列）を確認するには、以下の表を右にスクロールしてください）。\n\n\n\n\n\n\n\n\n\n変数の値を変換する\nggupset パッケージが求めるフォーマットに合わせるため、dplyr パッケージの case_when() を使用し、症状あり（yes）と症状なし（no）を実際の症状名に変換します。症状なし（no）の場合は、値を空白にします。以下のコードを実行すると、症状に関するすべての値が NA か症状名のどちらかに変換されます。\n\n# 症状ごとに変数（列）の値を変換する\nlinelist_sym_1 &lt;- linelist_sym %&gt;% \n\n  # 症状あり（yes）または症状なし（no）を、症状名に変換する\n  # 変換前の値が (yes) であれば症状名 (fever) に置き換え、それ以外の値を NA に置き換える\nmutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n       chills = ifelse(chills == \"yes\", \"chills\", NA),\n       cough = ifelse(cough == \"yes\", \"cough\", NA),\n       aches = ifelse(aches == \"yes\", \"aches\", NA),\n       vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\n\n次に、最終的にプロットに使用する 2 つの変数（列）を作成します。\n\n患者ごとに、5 つすべての症状を結合した文字型変数（列）\nggupset パッケージが求めるフォーマットに合わせるため、その文字型変数（列）をリスト型に変換する\n\n以下のコードで使用されている stringr パッケージの unite() 関数についての詳細は、文字型データをご覧ください。\n\n# 上記のコードで作成した症状ごとの変数（列）を、セミコロンで結合し、all_symptoms という 1 つの変数（列）にする\nlinelist_sym_1 &lt;- linelist_sym_1 %&gt;% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %&gt;% \n  mutate(\n    # 作成した all_symptoms 列をリストで複製する（次のステップで使用する ggupset() 関数のため、リスト型への変換が必要）\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )\n\n上記のコードで作成したデータを以下に表示します。一番右の列が、複数の症状を結合したリスト型列です。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>複数回答データの分析</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.jp.html#ggupset-パッケージでプロットを作成する",
    "href": "new_pages/combination_analysis.jp.html#ggupset-パッケージでプロットを作成する",
    "title": "36  複数回答データの分析",
    "section": "36.2 ggupset パッケージでプロットを作成する",
    "text": "36.2 ggupset パッケージでプロットを作成する\n最初に、パッケージを読み込みます。\n\npacman::p_load(ggupset)\n\nプロットを作成していきます。まず、ggplot() と geom_bar() を使用し、次に ggupset パッケージの scale_x_upset() 関数を使用します。\n\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")\n\n\n\n\n\n\n\n\nggupset パッケージについての詳細は、こちらのページ をご覧ください。オフラインの場合は、RStudio のコンソールで ?ggupset を実行すると、パッケージに関する詳細を確認することができます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>複数回答データの分析</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.jp.html#upsetr-でプロットを作成する",
    "href": "new_pages/combination_analysis.jp.html#upsetr-でプロットを作成する",
    "title": "36  複数回答データの分析",
    "section": "36.3 UpSetR でプロットを作成する",
    "text": "36.3 UpSetR でプロットを作成する\nUpSetR パッケージを使用すると、 プロットを細かくカスタマイズすることができますが、ggupset パッケージよりも難易度が高いです。\n最初に、パッケージを読み込みます。\n\npacman::p_load(UpSetR)\n\n次に、データの前処理を行います。\nlinelist オブジェクトの各症状の変数（列）について、症状あり（yes）の値は 1 に、症状ない（no）の値は 0 に変換する必要があります。\n\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n     # convert the \"yes\" and \"no\" values into 1s and 0s\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n\nより効率的に処理する関数に興味がある場合は、論理構文に基づいて値を 1 と 0 に置き換える関数 +() を利用できます。この関数は、across() を利用し、複数の列を一度に置き換えます。（詳しくはデータクリーニングと主要関数を参照してください）。\n\n# \"yes\" という値を 1 や 0 に効率的に変換するコード\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n  \n  # \"yes\" を 1 へ \"no\" を 0 へ置き換える\n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n\nプロットをカスタマイズする upset() 関数で、症状に関する変数（列）のみを使用し、プロットを作成していきます。sets = 引数で、比較する症状の「集合（sets）」を指定する必要があります（組み合わせに使用するすべての症状の列の名前を指定する）。また、nsets = 引数と order.by = \"freq\" 引数を使用し、頻度の多い上位 X 個の組み合わせ（X は任意の数）のみを表示することもできます。\n\n# プロットを作成する\nlinelist_sym_2 %&gt;% \n  UpSetR::upset(\n       sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n       order.by = \"freq\",\n       sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n       empty.intersections = \"on\",\n       # nsets = 3,\n       number.angles = 0,\n       point.size = 3.5,\n       line.size = 2, \n       mainbar.y.label = \"Symptoms Combinations\",\n       sets.x.label = \"Patients with Symptom\")",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>複数回答データの分析</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.jp.html#参考資料",
    "href": "new_pages/combination_analysis.jp.html#参考資料",
    "title": "36  複数回答データの分析",
    "section": "36.4 参考資料",
    "text": "36.4 参考資料\nUpSetR パッケージの Github ページ\n試用できる UpSetR の Shiny アプリ\nUpSetR のドキュメント（高難易度）",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>複数回答データの分析</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.jp.html",
    "href": "new_pages/transmission_chains.jp.html",
    "title": "37  感染連鎖",
    "section": "",
    "text": "37.1 概略\n感染経路や接触者の追跡データを扱い、分析し、可視化するための主要なツールは、RECON 社の人々によって開発された epicontacts パッケージです。 ノードにカーソルを合わせて詳細を表示したり、ドラッグして移動したり、クリックして下流の症例を強調するなど、以下の動的なプロットを試してみてください。\nWarning in epicontacts::make_epicontacts(linelist = linelist, contacts =\ncontacts, : Cycle(s) detected in the contact network: this may be unwanted",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>感染連鎖</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.jp.html#準備",
    "href": "new_pages/transmission_chains.jp.html#準備",
    "title": "37  感染連鎖",
    "section": "37.2 準備",
    "text": "37.2 準備\n\nパッケージを読み込み\nまず、データの読み込みや操作に必要な標準パッケージを読み込みます。 このハンドブックでは、pacman パッケージの p_load() を使うことを強調しています。 p_load() は、必要に応じてパッケージをインストールし、そして使用するためにパッケージを読み込みます。R の base パッケージから library() を使用してパッケージを読み込めます。R のパッケージについての詳細は R の基礎 のページを参照してください。\n\npacman::p_load(\n   rio,          # ファイルをインポート\n   here,         # ファイルの位置\n   tidyverse,    # データ管理 + ggplot2 作図\n   remotes       # github からのパッケージインストール\n)\n\n開発版の epicontacts パッケージが必要になります。 pacman パッケージの p_install_github() 関数を使って GitHub からインストールできます。 以下のコマンドは一度だけ実行すればよく、パッケージを使用するたびに実行する必要はありません（その後は通常通り p_load() を使用できます）。\n\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n\n\nデータをインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。データをダウンロードして順を追って見たい方は、ハンドブックとデータのダウンロード章の説明をご覧ください。データは rio パッケージの import() 関数を利用してインポートしましょう。データをインポートする様々な方法については、インポートとエクスポートの章をご覧ください。\n\n# linelist をインポート\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nlinelist の最初の 50 行を以下に表示します。特に注目すべきは、case_id, generation, infector, source の列です。\n\n\n\n\n\n\n\n\nepicontacts オブジェクトを作成\n次に、epicontacts オブジェクトを作成する必要がありますが、これには 2 種類のデータが必要です。\n\n症例を文書化したラインリスト。列は変数で、行は固有の症例に対応します。\n固有の ID に基づいて症例間のリンクを定義するエッジリスト（これらは接触、伝播イベントなどになります）。\n\nすでに linelist があるので、症例間、特に ID 間のエッジリストを作成するだけです。 infector 列と case_id 列をリンクすることで、linelist から感染リンクを抽出できます。 この時点で、「エッジのプロパティ」を追加できます。 エッジプロパティは、症例自体ではなく、2 つの症例間のリンクを記述するあらゆる変数を意味します。 例として、感染イベントの場所を記述する location 変数と、接触の持続時間を日単位で記述する duration 変数をエッジプロパティへ追加してみます。\n以下のコードでは、dplyr パッケージの transmute 関数は mutate 関数と似ていますが、関数内で指定した列のみを保持する点が異なります。 drop_na 関数は、指定された列が NA 値を持つ行をフィルタリングします。ここでは、感染者が判明している行のみを保持します。\n\n## contacts を生成\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %&gt;%\n  drop_na(infector)\n\nこれで、make_epicontacts 関数を使って、epicontacts オブジェクトを作成できます。 linelist のどの列が症例の一意の識別子を指しているか、また contacts のどの列が各リンクに関係する症例の一意の識別子を指しているかを指定する必要があります。 リンクについては、感染が感染者から（from）症例へと（to）向かうという方向性を持っているので、それに合わせて from と to の引数を指定する必要があります。 今後の操作に影響するように directed 引数を TRUE に設定します。\n\n## epicontacts オブジェクトを生成\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n\nWarning in make_epicontacts(linelist = linelist, contacts = contacts, id =\n\"case_id\", : Cycle(s) detected in the contact network: this may be unwanted\n\n\nepicontacts オブジェクトを表示してみると、linelist の case_id の列名が id に、case_id と infector の列名が from と to に変更されています。 この変更により一貫性が確保され、その後の処理、視覚化、分析の操作が容易になります。\n\n## epicontacts オブジェクトを表示\nepic\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 5,888 cases in linelist; 3,800 contacts; directed \n\n  // linelist\n\n# A tibble: 5,888 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 8689b7          4 NA             2014-05-13 2014-05-14           2014-05-18  \n 3 11f8ea          2 NA             2014-05-16 2014-05-18           2014-05-30  \n 4 b8812a          3 2014-05-04     2014-05-18 2014-05-20           NA          \n 5 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 be99c8          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 369449          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 f393b4          4 NA             2014-06-05 2014-06-06           2014-06-18  \n10 1389ca          4 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 3,800 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Community         5\n 2 f90f5f b8812a Nosocomial        8\n 3 11f8ea 893f25 Community         8\n 4 aec8ec be99c8 Nosocomial        4\n 5 893f25 07e3e8 Nosocomial        8\n 6 133ee7 369449 Community         6\n 7 996f3a 2978ac Nosocomial        3\n 8 133ee7 57a565 Community         5\n 9 37a6f6 fc15ef Community         9\n10 9f6884 2eaa9a Nosocomial        7\n# ℹ 3,790 more rows",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>感染連鎖</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.jp.html#操作",
    "href": "new_pages/transmission_chains.jp.html#操作",
    "title": "37  感染連鎖",
    "section": "37.3 操作",
    "text": "37.3 操作\n\nサブセット化\nepicontacts オブジェクトの subset() メソッドは、特に、linelist のプロパティ（“ノード属性”）と contacts データベースのプロパティ（“エッジ属性”）に基づいてネットワークをフィルタリングできます。 これらの値は、名前付きリストとして、それぞれの引数に渡す必要があります。 例えば、以下のコードでは、感染日が 2014 年 4 月から 7 月の間（日付は範囲で指定）で、病院内で発生した感染リンクを持つ男性症例のみを linelist に残しています。\n\nsub_attributes &lt;- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 69 cases in linelist; 1,906 contacts; directed \n\n  // linelist\n\n# A tibble: 69 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 3 2978ac          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15  \n 4 57a565          4 2014-05-28     2014-06-13 2014-06-15           NA          \n 5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09  \n 6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09  \n 7 f327be          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14  \n 8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16  \n 9 a47529          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26  \n10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01  \n# ℹ 59 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 1,906 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f90f5f b8812a Nosocomial        8\n 2 aec8ec be99c8 Nosocomial        4\n 3 893f25 07e3e8 Nosocomial        8\n 4 996f3a 2978ac Nosocomial        3\n 5 9f6884 2eaa9a Nosocomial        7\n 6 a75c7f 7f5a01 Nosocomial       10\n 7 ab634e 99e8fa Nosocomial        3\n 8 5d9e4d 8bd1e8 Nosocomial        1\n 9 beb26e 959170 Nosocomial        4\n10 894024 e56412 Nosocomial        6\n# ℹ 1,896 more rows\n\n\nthin 関数を使って、引数に what = \"linelist\" を設定することで、contacts で見つかった症例を含むように linelist をフィルタリングしたり、引数に what = \"contacts\" を設定することで、contact で見つかった症例を含むように contacts をフィルタリングしたりできます。 以下のコードでは、epicontacts オブジェクトをさらにフィルタリングして、上記でフィルタリングした 4 月から 7 月の間に感染した男性の症例を含む感染リンクのみを保持しています。 この仕様に合うのは、2 つの既知の感染リンクだけであることがわかります。\n\nsub_attributes &lt;- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)\n\n[1] 3\n\n\nネットワークは、ノードやエッジの属性によるサブセットに加えて、特定のノードに接続されているコンポーネントのみを含むように切り取れます。 cluster_id 引数は、症例 ID のベクトルを取り、それらの ID に直接または間接的にリンクされた個人の linelist を返します。 以下のコードでは、2ae019 と 71577a を含むクラスタに合計 13 件の linelist が関与していることがわかります。\n\nsub_id &lt;- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)\n\n[1] 13\n\n\nまた、epicontacts オブジェクトの subset() メソッドでは、cs, cs_min, cs_maxという引数を使って、クラスタのサイズでフィルタリングできます。 以下のコードでは、10 件以上のクラスタにリンクしている症例のみを保持しており、そのクラスタ内には 271 件のラインリストの症例があることがわかります。\n\nsub_cs &lt;- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)\n\n[1] 271\n\n\n\n\nID にアクセス\nget_id() は、データセットに含まれる症例 ID の情報を取得するもので、 以下のようにパラメータを指定できます。\n\nlinelist：linelist データの ID\ncontacts：contacts データセットに含まれる ID（“from” と “to” の組み合わせ）\nfrom：contacts データセットの “from” 列の ID\nto：contacts データセットの “to” 列に含まれる ID\nall：いずれかのデータセットに含まれる ID\ncommon：contacts データセットと linelist の両方に出現する ID\n\n例えば、contacts データセットの最初の 10 個の ID は何でしょうか？\n\ncontacts_ids &lt;- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)\n\n [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\"\n [9] \"9f6884\" \"4802b1\"\n\n\nlinelist と contacts の両方に何個の ID があるでしょうか？\n\nlength(get_id(epic, \"common\"))\n\n[1] 4352",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>感染連鎖</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.jp.html#可視化",
    "href": "new_pages/transmission_chains.jp.html#可視化",
    "title": "37  感染連鎖",
    "section": "37.4 可視化",
    "text": "37.4 可視化\n\n基本のプロット\nepicontacts オブジェクトの可視化はすべて plot 関数で行います。 まず、subset 関数を使って、発症日が 2014 年 6 月の症例のみを含むように epicontacts オブジェクトをフィルタリングし、thin を使って、それらの症例にリンクしている contacts のみを含めます。\n\n## epicontacts オブジェクトをサブセット化\nsub &lt;- epic %&gt;%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %&gt;%\n thin(\"contacts\")\n\nそして、次のように簡単に基本的な動的なプロットを作成できます。\n\n## epicontacts オブジェクトをプロット\nplot(\n  sub,\n  width = 700,\n  height = 700\n)\n\n\n\n\n\nノードをドラッグして移動したり、ノードにカーソルを合わせて詳細情報を表示したり、ノードをクリックして接続された症例を強調表示したりできます。\nこのプロットをさらに変更するための引数は数多くあります。 ここでは主なものを説明しますが、関数の引数の完全な説明を得るには、?vis_epicontacts（epicontacts オブジェクトで plot を使用したときに呼び出される関数）経由でドキュメントをチェックしてください。\n\nノード属性を可視化\nノードの色、ノードの形、ノードの大きさは、node_color, node_shape, node_size という引数を用いて、linelist の任意の列にマッピングできます。 これは ggplot2 パッケージでおなじみの aes シンタックスに似ています。\nノードの色、形、サイズは以下のように指定できます。\n\n色 col_pal 引数を介して、以下のように各色を手動で指定するための名前付きリストを提供できます。または colorRampPalette(c(\"black\", \"red\", \"orange\")) のようなカラーパレット関数を提供することで、指定された色の間のグラデーションを提供できます。\n形 shapes 引数に名前付きリストを渡して、node_shape 引数で指定された linelist の列にあるユニークな要素ごとに 1 つの形を指定します。利用可能な形については codeawesome を参照してください。\nサイズ size_range 引数にノードの大きさの範囲を渡します。\n\n以下では、色は結果を、形は性別を、大きさは年齢を表す例を示しています。\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nエッジ属性を可視化\nエッジの色、幅、線種は、edge_color, edge_width, edge_linetype の各引数を用いて、コンタクトデータフレームの任意の列にマッピングできます。 エッジの色と幅は以下のように指定できます。\n\n色 は edge_col_pal で、col_pal と同様の方法で指定します。\n幅 width_range 引数にノードの大きさの範囲を渡すことで指定します。\n\n以下に例を示します。\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\n\n時間軸\nまた、x_axis の引数を linelist の列にマッピングすることで、ネットワークを時間軸に沿って可視化できます。 下の例では、x 軸は症状が現れた日付を表しています。 また、矢印が大きすぎないように arrow_size 引数を指定し、図が見づらくならないように label = FALSE を設定しています。\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n多数存在する追加の引数によって、このネットワークの外観を時間軸に沿ってより明確にできます。 これらの引数については、?vis_temporal_interactive で確認できます（x_axis を指定した epicontacts オブジェクトで plot を使用したときに呼び出される関数）。 以下、いくつか引数の例を紹介します。\n\n伝播ツリーの形状を指定\n伝播ツリー (transmission tree) の分岐の形状には大きく分けて 2 種類あり、network_shape 引数で指定できます。 1 つ目は、上図のような「枝分かれ」（branching）型で、2 つのノードを直線のエッジで接続します。 これは最も直感的な表現ですが、密に接続されたネットワークではエッジが重なってしまう可能性があります。 2 つ目の形状は「直角」（rectangle）で、これは系統樹のような木を表現します。 例えば、以下のようになります。\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n各症例のノードは position_dodge の引数を色々と試すことで、ユニークな垂直方向の位置を割り当てできます。 unlinked_pos 引数を使って、接続されていない症例（つまり、報告された contacts がない症例）の位置を指定します。\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n子ノードに対する親ノードの相対的な位置は、parent_pos 引数で指定できます。 デフォルトでは、親ノードは中央に配置されますが、下に配置したり（parent_pos = 'bottom'）、上に配置したり（parent_pos = 'top'）できます。\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nプロットと図を保存\nVisNetwork パッケージの visSave 関数を使うと、プロットを動的な自己完結型の html ファイルとして保存できます。\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %&gt;%\n  visNetwork::visSave(\"network.html\")\n\nこれらのネットワーク出力を画像として保存するのは、残念ながらあまり簡単ではなく、ファイルを html として保存した後、webshot パッケージを使ってこのファイルのスクリーンショットを撮る必要があります。 以下のコードでは、上記で保存した html ファイルを PNG に変換しています。\n\nwebshot(url = \"network.html\", file = \"network.png\")\n\n\n\n\nタイムライン\nまた、各症例の X 軸に表示されているネットワークのタイムラインを表示できます。 これは、例えば、症例の位置や結果が出るまでの時間を可視化するために使用できます。 タイムラインを生成するには、症例 ID、「イベント」の開始日、「イベント」の終了日を示す少なくとも3つの列からなるデータフレームを作成する必要があります。 また、他の列をいくつでも追加し、タイムラインのノードとエッジのプロパティにマッピングできます。 以下のコードでは、症状が出た日から結果が出た日までのタイムラインを作成し、ノードの形と色を定義するために使用する結果と病院の変数を保持しています。 複数の病院間で転院した場合など、症例ごとに複数のタイムライン行・イベントを持つことができることに注意してください。\n\n## timeline を生成\ntimeline &lt;- linelist %&gt;%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n\n上記のタイムラインオブジェクトを timeline 引数に渡します。 タイムラインのアトリビュートをタイムラインのノードの色、形、サイズにマッピングする方法は、前のセクションで定義したのと同じですが、各タイムラインの開始ノードと終了ノードの 2 つのノードがあり、それぞれ別の引数を持ちます。 例えば、tl_start_node_color はどのタイムラインの列が開始ノードの色にマッピングされるかを定義し、tl_end_node_shape はどのタイムラインの列が終了ノードの形にマッピングされるかを定義します。 また、色、幅、線種、ラベルを tl_edge_* 引数でタイムラインの edge にマッピングもできます。\n引数についての詳しい説明は、?vis_temporal_interactive (epicontactsオブジェクトをプロットするときに呼ばれる関数)を参照してください。 各引数は以下のコードでも注釈がついています。\n\n## shapes を定義\nshapes &lt;- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## colours を定義\ncolours &lt;- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## プロットを作成\nplot(\n  sub,\n  ## x 軸を発症日に指定\n  x_axis = \"date_onset\",\n  ## ネットワーク形状に rectangular を使用\n  network_shape = \"rectangle\",\n  ## 症例ノードの形状に gender 列を割り当て\n  node_shape = \"gender\",\n  ## ノードの色にはどの列も割り当てない。\n  ## デフォルトでは node id に割り当てられており、色スキームが滅茶苦茶になってしまうので、重要\n  node_color = NULL,\n  ## 症例 node の大きさを 30 にする。(これは文字列ではありません。\n  ## node_size は列に割り当てていないので、実際のノード の大きさと解釈されます。)\n  node_size = 30,\n  ## 感染 link の大きさを 4 にする。(これは文字列ではありません。\n  ## edge_width は列に割り当てていないので、実際の edge の大きさと解釈されます。)\n  edge_width = 4,\n  ## timeline オブジェクトを渡す\n  timeline = timeline,\n  ## timeline オブジェクトのノードの末端形状を outcome 列に割り当て\n  tl_end_node_shape = \"outcome\",\n  ## ノード末端の大きさを 15 にする。(これは文字列ではありません。\n  ## 引数は列に割り当てていないので、実際のノードの大きさと解釈されます。)\n  tl_end_node_size = 15,\n  ## timeline edge の色を hospital 列に割り当て\n  tl_edge_color = \"hospital\",\n  ## timeline エッジの大きさを 2 にする。(これは文字列ではありません。\n  ## 引数は列に割り当てていないので、実際のエッジの大きさと解釈されます。)\n  tl_edge_width = 2,\n  ## エッジのラベルに hospital 変数を割り当て\n  tl_edge_label = \"hospital\",\n  ## 全員のノード属性の形状を指定 (定義済み)\n  shapes = shapes,\n  ## 色パレットを指定 (定義済み)\n  col_pal = colours,\n  ## 矢印の大きさを 0.5 に設定\n  arrow_size = 0.5,\n  ## 凡例を 2 列に\n  legend_ncol = 2,\n  ## フォントの大きさを設定\n  font_size = 15,\n  ## 日付のフォーマットを設定\n  date_labels = c(\"%d %b %Y\"),\n  ## ノードの下に ID ラベルをプロットしない\n  label = FALSE,\n  ## 高さを指定\n  height = 1000,\n  ## 幅を指定\n  width = 1200,\n  ## 各症例のノードがユニークな y 座標を持つようにする\n  ## これをしないと異なる症例が重なってしまうので、\n  ## タイムラインを使うときには重要\n  position_dodge = TRUE\n)\n\nWarning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed\nas ID not found in linelist or start/end date is NA",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>感染連鎖</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.jp.html#解析",
    "href": "new_pages/transmission_chains.jp.html#解析",
    "title": "37  感染連鎖",
    "section": "37.5 解析",
    "text": "37.5 解析\n\n要約化\nネットワークのプロパティの概要は、summary 関数で取得できます。\n\n## epicontacts オブジェクトを要約\nsummary(epic)\n\n\n/// Overview //\n  // number of unique IDs in linelist: 5888\n  // number of unique IDs in contacts: 5511\n  // number of unique IDs in both: 4352\n  // number of contacts: 3800\n  // contacts with both cases in linelist: 56.868 %\n\n/// Degrees of the network //\n  // in-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n\n  // out-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n\n  // in and out degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   1.000   1.078   1.000   7.000 \n\n/// Attributes //\n  // attributes in linelist:\n generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n\n  // attributes in contacts:\n location duration\n\n\n例えば、両方の症例が登録されている contact は 57％しかありません。 これは、このような感染連鎖に関わる症例のうちかなりの数の登録データがないことを意味しています。\n\n\nペアの特徴\nget_pairwise() 関数は、接触データセットの各ペアに応じて、linelist の変数を処理できます。 以下の例では、linelist から発症日を抽出し、各ペアの発症日の差を計算しています。 この比較から得られる値は、シリアル・インターバル (si) を表します。\n\nsi &lt;- get_pairwise(epic, \"date_onset\")   \nsummary(si)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    5.00    9.00   11.01   15.00   99.00    1820 \n\ntibble(si = si) %&gt;%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1820 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nget_pairwise() は、比較に使われる列のデータ型を解釈し、それに応じて値の比較方法を調整します。 上記の si の例のように、数値や日付の場合、この関数は値を引きます。 文字やカテゴライズされた列に適用された場合、get_pairwise() は値をくっつけます。 この関数は任意の処理も可能なので（引数 “f” を参照）、これらの離散的な組み合わせを簡単に集計・分析できます。\n\nhead(get_pairwise(epic, \"gender\"), n = 10)\n\n [1] \"f -&gt; m\" NA       \"m -&gt; m\" NA       \"m -&gt; f\" \"f -&gt; f\" NA       \"f -&gt; m\"\n [9] NA       \"m -&gt; f\"\n\nget_pairwise(epic, \"gender\", f = table)\n\n           values.to\nvalues.from   f   m\n          f 464 516\n          m 510 468\n\nfisher.test(get_pairwise(epic, \"gender\", f = table))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  get_pairwise(epic, \"gender\", f = table)\np-value = 0.03758\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6882761 0.9892811\nsample estimates:\nodds ratio \n 0.8252575 \n\n\nここでは、感染リンクと性別との間に有意な関連が見られます。\n\n\nクラスターを特定\nget_clusters() 関数を使って、epicontacts オブジェクト内の連結成分を特定できます。 まず、クラスター情報を含む data.frame を取得するために使います。\n\nclust &lt;- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42 \n\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\n最大のクラスターを見てみましょう。 このためには、epicontacts オブジェクトにクラスタ情報を追加し、それをサブセット化して、最大のクラスタだけを残します。\n\nepic &lt;- get_clusters(epic)\nmax_size &lt;- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))\n\n\n\n\n\n\n\n度数を計算\nノードの度数 (degree) は、他のノードとのエッジや接続の数に相当しています。 get_degree() は epicontacts ネットワークに対してこの値を計算する簡単な方法を提供します。 この文脈において、度数が高いほど、多くの人と接触していた個人であることを示しています。 type の引数は、in-degree と out-degree の両方をカウントしたいことを示し、only_linelist の引数は、ラインリストに含まれる症例についてのみ度数を計算したいことを示します。\n\ndeg_both &lt;- get_degree(epic, type = \"both\", only_linelist = TRUE)\n\n最も多く接触した人（上から順に 10 人）は誰でしょうか？\n\nhead(sort(deg_both, decreasing = TRUE), 10)\n\n916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n     7      6      6      6      5      5      5      5      5      5 \n\n\n平均接触回数はどのくらいですか？\n\nmean(deg_both)\n\n[1] 1.078473",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>感染連鎖</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.jp.html#参考資料",
    "href": "new_pages/transmission_chains.jp.html#参考資料",
    "title": "37  感染連鎖",
    "section": "37.6 参考資料",
    "text": "37.6 参考資料\nepicontacts ページ では、パッケージの機能の概要を説明しており、より詳細なドキュメント（vignette）も含まれています。\ngithub ページ は、問題提起や機能のリクエストに利用できます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>感染連鎖</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.jp.html",
    "href": "new_pages/phylogenetic_trees.jp.html",
    "title": "38  系統樹",
    "section": "",
    "text": "38.1 概要\n系統樹とは、生物の遺伝暗号の配列に基づいて、その近縁性や進化を可視化・記述するためのものです。\n系統樹は、遺伝子配列から、距離に基づく方法（近傍結合法など）や、特徴に基づく方法（最尤法やベイズ・マルコフ連鎖モンテカルロ法など）を用いて構築することができます。次世代シーケンシング（NGS）は、価格が手頃になり、感染症の原因となる病原体を記述するために公衆衛生の分野で広く使われるようになってきました。携帯型のシーケンサーを使用することで、解析時間を短縮し、リアルタイムでアウトブレイク調査に必要なデータを得ることができます。NGS データは、発生した菌株の起源や発生源、その繁殖を特定したり、抗菌剤耐性遺伝子の有無を判定したりするのに利用できます。また、サンプル間の遺伝的関連性を可視化するために、系統樹を構築します。\nこのページでは、系統樹とデータフレーム形式の追加サンプルデータを組み合わせて可視化することができる ggtree パッケージの使い方を学びます。これにより、パターンを観察し、アウトブレイクのダイナミックな理解を深めることができます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>系統樹</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.jp.html#準備",
    "href": "new_pages/phylogenetic_trees.jp.html#準備",
    "title": "38  系統樹",
    "section": "38.2 準備",
    "text": "38.2 準備\n\nパッケージの読み込み\nこのコードチャンクは、分析に必要なパッケージの読み込みを示しています。このハンドブックでは pacman の p_load() を重視しています。p_load() は必要に応じてパッケージをインストールし、使用するためにパッケージを読み込みます。インストールされたパッケージは R の base パッケージの library() でも読み込みできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  rio,             # インポート／エクスポート\n  here,            # 相対的なファイルパス\n  tidyverse,       # 一般的なデータマネジメントと可視化\n  ape,             # 系統樹ファイルのインポートとエクスポート\n  ggtree,          # 系統樹の可視化\n  treeio,          # 系統樹の可視化\n  ggnewscale)      # 色に関するレイヤーの追加\n\n\n\nデータのインポート\n本章で扱われるデータは、ハンドブックとデータのダウンロード の章の説明に従ってダウンロードできます。\n系統樹の保存形式にはいくつかの種類があります（ Newick、NEXUS、Phylip など）。一般的なのはNewickファイル形式（.nwk）で、これは木をコンピュータで読める形で表現するための標準的なものです。つまり、木全体を “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59);” のような文字列形式で表現し、すべてのノードと先端、そしてそれらの関係（枝の長さ）を列挙することができます。\n注： 系統樹ファイル自体にはシーケンスデータは含まれておらず、単に配列間の遺伝的距離の結果であることを理解しておくことが重要です。したがって、ツリーファイルからシーケンスデータを抽出することはできません。\nまず、ape パッケージの read.tree() 関数を使って、Newick の系統樹ファイルを .txt 形式で読み込み、“phylo” 型のリストオブジェクトに格納しておきます。必要に応じて、here パッケージの here() 関数を使用して、相対ファイルパスを指定します。\n注：このケースでは、Github からのダウンロードや取り扱いを容易にするために、newick ツリーを .txt ファイルとして保存しています。\n\ntree &lt;- ape::read.tree(\"Shigella_tree.txt\")\n\ntree オブジェクトを調べてみると、299 個の先端（またはサンプル）と 236 個のノードが含まれています。\n\ntree\n\n\nPhylogenetic tree with 299 tips and 236 internal nodes.\n\nTip labels:\n  SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\nNode labels:\n  17, 29, 100, 67, 100, 100, ...\n\nRooted; includes branch lengths.\n\n\n次に、rio パッケージの import() 関数を用いて、性別、原産国、抗菌薬への薬剤耐性など、シーケンスされた各サンプルの追加情報を含む .csv ファイルとして保存された表をインポートします。\n\nsample_data &lt;- import(\"sample_data_Shigella_tree.csv\")\n\n以下は、データの最初の 50 行です。\n\n\n\n\n\n\n\n\nクリーニングと点検\nデータのクリーニングと点検を行います。正しいサンプルデータを系統樹に割り当てるためには、sample_data データフレームの Sample_ID カラムの値が、tree ファイルの tip.labels の値と一致する必要があります。\nR の base パッケージの head() を使って最初の 6 つのエントリーを見ることで、 tree ファイルの tip.labels のフォーマットをチェックします。\n\nhead(tree$tip.label) \n\n[1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\"\n[6] \"S17BD05939\"\n\n\nまた、sample_data データフレームの最初の列が Sample_ID であることを確認します。R の base パッケージの colnames() を使って、データフレームのカラム名を調べます。\n\ncolnames(sample_data)   \n\n [1] \"Sample_ID\"                  \"serotype\"                  \n [3] \"Country\"                    \"Continent\"                 \n [5] \"Travel_history\"             \"Year\"                      \n [7] \"Belgium\"                    \"Source\"                    \n [9] \"Gender\"                     \"gyrA_mutations\"            \n[11] \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n[13] \"MIC_CIP\"                   \n\n\nデータフレーム内の Sample_IDs を見て、フォーマットが tip.label と同じであることを確認します（例：文字はすべて大文字、文字と数字の間に余分なアンダースコア _ がない、など）。\n\nhead(sample_data$Sample_ID) # もう一度、head() を使用して、初めの 6 つのデータだけ確認する\n\n[1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\"\n[6] \"S18BD02657\"\n\n\nまた、すべてのサンプルが tree ファイルに存在するかどうか、あるいはその逆かどうかを、一致する部分と一致しない部分に TRUE または FALSE のロジカルベクトルを生成することで比較することができます。これらは、簡単にするために、ここでは表示しません。\n\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\n\nこれらのベクトルを使って、 tree 上にないサンプル ID を表示することができます（結果として、そのような例はありません）。\n\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]\n\ncharacter(0)\n\n\n調べてみると、データフレーム内の Sample_ID のフォーマットが、tip.labels のサンプル名のフォーマットに対応していることがわかります。これらは、同じ順序でソートされていなくてもマッチします。\nこれで準備完了です。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>系統樹</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.jp.html#単純な系統樹の可視化",
    "href": "new_pages/phylogenetic_trees.jp.html#単純な系統樹の可視化",
    "title": "38  系統樹",
    "section": "38.3 単純な系統樹の可視化",
    "text": "38.3 単純な系統樹の可視化\n\n様々な系統樹のレイアウト\nggtree には様々なレイアウトが用意されており、目的に応じて最適なものを選ぶことができます。以下にいくつかのデモンストレーションを紹介します。他のオプションについては、このオンラインブックを参照してください。\n以下は、ツリーレイアウトの例です。\n\nggtree(tree)                                            # 単純な線形の系統樹\nggtree(tree,  branch.length = \"none\")                   # 全ての先端が揃えられた単純な線形の系統樹\nggtree(tree, layout=\"circular\")                         # 単純な円形の系統樹\nggtree(tree, layout=\"circular\", branch.length = \"none\") # 全ての先端が揃えられた単純な円形の系統樹\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n単純な系統樹とサンプルデータ\nsample_data データフレームを tree ファイルに接続するには、%&lt;+% 演算子を使用します。 系統樹の最も簡単な注釈は、先端にサンプル名を追加することと、先端のポイントや必要に応じて枝に色を付けることです。\n以下は、円形の系統樹の例です。\n\nggtree(tree, layout = \"circular\", branch.length = 'none') %&lt;+% sample_data + # %&lt;+% で、tree にサンプルデータを追加する\n  aes(color = Belgium)+                       # データフレームの変数に応じて分枝に色付ける\n  scale_color_manual(\n    name = \"Sample Origin\",                      # カラースキームの名前\n    breaks = c(\"Yes\", \"No\"),                     # 変数の異なるオプション\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # 凡例の中で異なるオプションをどのように命名するか\n    values = c(\"blue\", \"black\"),                  # 変数に割り当てたい色\n    na.value = \"black\") +                        #  NA 値を黒に\n  new_scale_color()+                             # 別の変数の配色を追加する\n    geom_tippoint(\n      mapping = aes(color = Continent),          # 大陸別の先端の色。\"shape = \" を加えて形状を変更する\n      size = 1.5)+                               # 先端のポイントのサイズを定義する\n  scale_color_brewer(\n    name = \"Continent\",                    # カラースキームの名前（凡例ではこのように表示される\n    palette = \"Set1\",                      # brewer パッケージに付属しているカラーセットを選ぶ\n    na.value = \"grey\") +                    # NA 値はグレーを選択\n  geom_tiplab(                             # 枝の先端にサンプルの名前を追加 \n    color = 'black',                       # (テキストラインは + で好きなだけ追加できるが、隣り合うように配置するにはオフセット値を調整する必要がある)\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align = TRUE)+    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # グラフのタイトル\n  theme(\n    axis.title.x = element_blank(), # x 軸のタイトルを削除\n    axis.title.y = element_blank(), # y 軸のタイトルを削除\n    legend.title = element_text(    # 凡例のタイトルのフォントサイズとフォーマットを定義する\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # 凡例テキストのフォントサイズとフォーマットを定義する\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # プロットタイトルのフォントサイズとフォーマットを定義する\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # 凡例の配置を決める\n    legend.box = \"vertical\",        # 凡例の配置を決める\n    legend.margin = margin())   \n\n\n\n\n\n\n\n\n他の ggplot オブジェクトと同じように、ggsave() を使ってツリープロットをエクスポートすることができます。このように書くと、ggsave() は最後に生成された画像を指定されたファイルパスに保存します。here() や相対ファイルパスを使えば、サブフォルダなどにも簡単に保存できることを覚えておいてください。\n\nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>系統樹</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.jp.html#系統樹の操作処理加工",
    "href": "new_pages/phylogenetic_trees.jp.html#系統樹の操作処理加工",
    "title": "38  系統樹",
    "section": "38.4 系統樹の操作・処理・加工",
    "text": "38.4 系統樹の操作・処理・加工\n非常に大きな系統樹であっても、その中の一部分にしか興味がない場合があります。例えば、歴史的または国際的なサンプルを含む系統樹を作成して、データセットが全体像の中でどこに当てはまるかを大まかに把握する場合です。しかし、データをより詳しく見るためには、大きな系統樹の一部だけを確認したいとします。\n系統樹ファイルはシーケンシングデータの解析結果に過ぎないので、ファイル内のノードや枝の順番を操作することはできません。これらは、生の NGS データから以前の解析ですでに決定されています。しかし、部分的に拡大したり、部分的に非表示にしたり、系統樹の一部をサブセットにしたりすることは可能です。\n\n拡大\n系統樹を “切断” するのではなく、一部だけをより詳しく調べたい場合は、ズームインして特定の部分を表示することができます。\nまず、系統樹全体を線形のフォーマットでプロットし、系統樹の各ノードに数字のラベルを追加します。\n\np &lt;- ggtree(tree,) %&lt;+% sample_data +\n  geom_tiplab(size = 1.5) +                # すべての枝の先端に、tree ファイルのサンプル名をラベル付ける\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # 系統樹内のすべてのノードにラベルを付ける\n\np  # 表示する\n\n\n\n\n\n\n\n\nある特定の枝（右に突き出ている）にズームインするには、ggtree オブジェクト p で viewClade() を使用し、ノード番号を指定すると、より詳しく見ることができます。\n\nviewClade(p, node = 452)\n\n\n\n\n\n\n\n\n\n\n枝の折り畳み\nしかし、この枝を無視したい場合もあるので、collapse() を使って同じノード（ノード番号 452）で枝を折り畳むことができます。このツリーは p_collapsed として定義されます。\n\np_collapsed &lt;- collapse(p, node = 452)\np_collapsed\n\n\n\n\n\n\n\n\n分かりやすくするために、p_collapsed をプリントする際に、折り畳まれた枝のノードに geom_point2()（青い菱形）を追加しています。\n\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # 折り畳んだノードに記号を割り当てる\n            size = 5,                     # 記号のサイズを定義する\n            shape = 23,                   # 記号の形を定義する\n            fill = \"steelblue\")           # 記号の塗りつぶしを定義する\n\n\n\n\n\n\n\n\n\n\n系統樹の分割（サブセット）\nより永続的な変更を行い、作業用の縮小された新しい系統樹を作成したい場合は、 tree_subset() でツリーの一部をサブセットします。そして、それを新しい newick tree ファイルか .txt ファイルとして保存します。\n\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %&lt;+% sample_data +               # %&lt;+% 演算子を使って、サンプルデータを追加する\n  geom_tiplab(size = 1)+                                # すべての枝の先端にサンプル名をラベル付けしてツリーファイルに保存\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # 系統樹内のすべてのノードにラベルを付ける\n theme(\n   legend.position = \"none\",                            # 凡例も全て削除\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\n\n\n\n\n\n\n\n\nここで、ノード 528 で系統樹をサブセットする（ノード 528 以降の枝の中の先端だけを残す）ことにして、それを新しい sub_tree1 オブジェクトとして保存したとします。\n\nsub_tree1 &lt;- tidytree::tree_subset(\n  tree,\n  node = 528)                                            # ノード 528 で系統樹をサブセットする\n\nsubset tree 1 を見てみましょう。\n\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\n\n\n\n\n\n\n\n\nまた、1 つの特定のサンプルに基づいてサブセットすることもできます。その際には、含める「後ろ」のノード数を指定します。系統樹の同じ部分を、サンプル（ここでは S17BD07692）に基づいて 9 ノードさかのぼってサブセットし、新しい sub_tree2 オブジェクトとして保存します。\n\nsub_tree2 &lt;- tidytree::tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back は、先端（各サンプル）から何ノード後方に移動するかを定義する\n\nsubset tree 2 を見てみましょう。\n\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n\n\n\n\n\n\n\n\nまた、ape パッケージの write.tree() 関数を使って、新しい系統樹を Newick 型やテキストファイルとして保存することもできます。\n\n# .nwk フォーマットで保存\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# .txt フォーマットで保存\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')\n\n\n\n系統樹内でのノードの回転\n前述したように、ツリー内の先端やノードの順序を変更することはできません。これは、遺伝子の関連性に基づいており、視覚的な操作の対象にはならないからです。しかし、視覚的にわかりやすくするために、ノードの周りに枝を回転させることはできます。\nまず、ノードのラベルとともに新しい subset tree 2 をプロットして、操作したいノードを選び、それを ggtree plot オブジェクト p に格納します。\n\np &lt;- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # 系統樹内のすべてのノードにラベルを付ける\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\n\n\n\n\n\n\n\n\nその後、 ggtree::rotate() や ggtree::flip() を使ってノードを操作することができます。 注：どのノードを操作しているかを示すために、まず、ggtree の geom_hilight() 関数を適用して、興味のあるノードのサンプルをハイライトし、その ggtree プロットオブジェクトを新しいオブジェクト p1 に格納します。\n\np1 &lt;- p + geom_hilight(  # ノード 39 を青くハイライトし、\"extend =\" でカラーブロックの長さを定義する\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # ノード 37 を黄色くハイライトする\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # 表示する\n\n\n\n\n\n\n\n\nここで、オブジェクト p1 のノード 37 を回転させ、ノード 38 上のサンプルが一番上に移動するようにします。回転したツリーを新しいオブジェクト p2 に格納します。\n\np2 &lt;- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # 表示する\n\n\n\n\n\n\n\n\nまた、flip コマンドを使って、オブジェクト p1 のノード 36 を回転させ、ノード 37 を上に、ノード 39 を下に切り替えることもできます。反転したツリーを新しいオブジェクト p3 に格納します。\n\np3 &lt;-  flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # 表示する\n\n\n\n\n\n\n\n\n\n\nサンプルデータを付加したサブツリーの例\nサブツリーのノード 39 で 2017 年と 2018 年に発生したクローン拡大を伴う症例のクラスタを調査しているとします。他の近縁種の株の起源を見るために、株の分離年に加えて、渡航歴と国別の色を追加します。\n\nggtree(sub_tree2) %&lt;+% sample_data +     # %&lt;+% 演算子を使って sample_data にリンクしている\n  geom_tiplab(                          # すべての枝の先端に、ツリーファイルのサンプル名をラベル付けする\n    size = 2.5,\n    offset = 0.001,\n    align = TRUE) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # 系統樹の x 軸の 下限、上限を設定\n  geom_tippoint(aes(color=Country),     # 大陸別に先端を色付ける\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                          # 隔離された年をテキストラベルとして先端に追加\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    align = TRUE)+ \n  geom_tiplab(                          # 先端のテキストラベルに渡航歴を赤で表示\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align = TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # プロットタイトルの追加\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                    # x 軸にラベルを付ける \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n私たちの観察によると、アジアからの菌株の輸入があり、それが何年もかけてベルギーで伝播し、今回の流行を引き起こしたと考えられます。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>系統樹</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.jp.html#より複雑な系統樹サンプルデータのヒートマップの追加",
    "href": "new_pages/phylogenetic_trees.jp.html#より複雑な系統樹サンプルデータのヒートマップの追加",
    "title": "38  系統樹",
    "section": "より複雑な系統樹：サンプルデータのヒートマップの追加",
    "text": "より複雑な系統樹：サンプルデータのヒートマップの追加\nggtree::gheatmap() 関数を使用して、抗菌薬耐性遺伝子のカテゴリー的な存在や、実際に測定された抗菌薬耐性の数値など、より複雑な情報をヒートマップの形で追加することができます。\nまず、系統樹をプロットし（これは線形でも円形でも構いません）、それを新しい ggtree plot のオブジェクト p に保存する必要があります。ここでは、パート 3 の sub_tree を使用します)。\n\np &lt;- ggtree(sub_tree2, branch.length='none', layout='circular') %&lt;+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\n\n\n\n\n\n\n\n\n次に、データの準備です。異なる変数を新しい配色で可視化するために、データフレームを目的の変数にサブセットします。行の名前として Sample_ID を追加することが重要で、そうしないとデータを tip.labels の系統樹にマッチさせることができません。\nこの例では、性別と、赤痢菌感染症の治療に使用される重要な第一選択抗菌薬であるシプロフロキサシンへの耐性を与える可能性のある変異を調べたいと思います。\n性別のデータフレームを作成します。\n\ngender &lt;- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) &lt;- sample_data$Sample_ID\n\nシプロフロキサシン耐性をもたらす gyrA 遺伝子の変異について、データフレームを作成します。\n\ncipR &lt;- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) &lt;- sample_data$Sample_ID\n\n実験室で測定されたシプロフロキサシンの最小発育阻止濃度（MIC）のデータフレームを作成します。\n\nMIC_Cip &lt;- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) &lt;- sample_data$Sample_ID\n\n系統樹に性別の二値のヒートマップを追加した最初のプロットを作成し、それを新しい ggtree plot のオブジェクト h1 に格納します。\n\nh1 &lt;-  gheatmap(p, gender,                                 # 性別データフレームのヒートマップレイヤーをツリープロットに追加する\n                offset = 10,                               # offset は、ヒートマップを右方向に移動する\n                width = 0.10,                              # width は、ヒートマップのカラムの幅を定義する\n                color = NULL,                              # color は、ヒートマップの列の境界線を定義する\n         colnames = FALSE) +                               # ヒートマップのカラム名を隠す\n  scale_fill_manual(name = \"Gender\",                       # 性別の配色と凡例の定義\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nその後、シプロフロキサシンに対する耐性を付与する gyrA 遺伝子の変異の情報を追加しています。\n注：WGS データにおける染色体の点変異の有無は、Zankari らが開発した PointFinder ツールを用いて事前に判断しています（参考文献の項を参照）。\nまず、既存のプロットオブジェクト h1 に新しい配色を割り当てて、今のオブジェクト h2 に格納します。これにより、ヒートマップの 2 つ目の変数の色を定義・変更することができます。\n\nh2 &lt;- h1 + new_scale_fill() \n\n次に、2 つ目のヒートマップレイヤーを h2 に追加し、合成したプロットを新しいオブジェクト h3 に格納します。\n\nh3 &lt;- gheatmap(h2, cipR,         # ヒートマップの 2 行目に Ciprofloxacin の耐性変異を追加\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh3\n\n\n\n\n\n\n\n\n以上のプロセスを繰り返し、まず既存のオブジェクト h3 に新しいカラースケール層を追加し、次に得られたオブジェクト h4 に各菌株に対するシプロフロキサシンの最小発育阻止濃度（MIC）の連続データを追加して、最終的なオブジェクト h5 を作成します。\n\n# まず、新しいカラーリングを追加する\nh4 &lt;- h3 + new_scale_fill()\n\n# そして、その 2 つを組み合わせて新しいプロットを作る\nh5 &lt;- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # ここでは、MIC の連続変数のグラデーションカラースキームを定義する\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5\n\n\n\n\n\n\n\n\nこれと同じことを、線形の系統樹についても行うことができます。\n\np &lt;- ggtree(sub_tree2) %&lt;+% sample_data +\n  geom_tiplab(size = 3) + # 先端にラベル付け\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\n\n\n\n\n\n\n\n\nまず、性別を追加します。\n\nh1 &lt;-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nそして、もう一つの配色レイヤーを追加した後に、シプロフロキサシン耐性変異を追加します。\n\nh2 &lt;- h1 + new_scale_fill()\nh3 &lt;- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n h3\n\n\n\n\n\n\n\n\nそして、実験室で決められた最小発育阻止濃度（MIC）を加えます。\n\nh4 &lt;- h3 + new_scale_fill()\nh5 &lt;- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>系統樹</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.jp.html#参考資料",
    "href": "new_pages/phylogenetic_trees.jp.html#参考資料",
    "title": "38  系統樹",
    "section": "38.5 参考資料",
    "text": "38.5 参考資料\n\nhttp://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors\nhttps://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html\nhttps://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\n\nEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: a novel web tool for WGS-based detection of antimicrobial resistance associated with chromosomal point mutations in bacterial pathogens, Journal of Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764–2768, https://doi.org/10.1093/jac/dkx217",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>系統樹</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.jp.html",
    "href": "new_pages/interactive_plots.jp.html",
    "title": "39  動的な図の作成",
    "section": "",
    "text": "39.1 準備",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>動的な図の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.jp.html#準備",
    "href": "new_pages/interactive_plots.jp.html#準備",
    "title": "39  動的な図の作成",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードを実行すると、分析に必要なパッケージが読み込まれます。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  rio,       # インポート・エクスポート\n  here,      # ファイルパス\n  lubridate, # 日付の操作\n  plotly,    # 動的な作図\n  scales,    # 軸やスケールの調整\n  tidyverse  # データの処理と可視化\n  ) \n\n\n\nはじめは ggplot() 関数から\nこの章では、動的な図に変換したい図表を ggplot() 関数を用いて作成するところから始めることを想定しています。この章では、このハンドブックの多くの章で使われている linelist ケースを使って、このようなプロットをいくつか作ってみます。\n\n\nデータのインポート\nまず始めに、エボラ出血熱のシミュレーションで得られた症例がクリーニングされたラインリストの取り込みをします。続きをご覧になりたい方は、 class=‘download-button’&gt;クリックして「クリーニングされた」ラインリストをダウンロードしてください（.rdsファイルとして）。rio パッケージの import() 関数を使ってデータの読み込みをします（.xlsx, .csv, .rdsなどの多くのファイルの種類を扱うことができます。\n\n# 結果のラインリストの取り込み\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nラインリストの最初の50行を以下に表示します。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>動的な図の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.jp.html#ggplotly-関数によるプロット",
    "href": "new_pages/interactive_plots.jp.html#ggplotly-関数によるプロット",
    "title": "39  動的な図の作成",
    "section": "39.2 ggplotly() 関数によるプロット",
    "text": "39.2 ggplotly() 関数によるプロット\nplotly パッケージの ggplotly() 関数を使うと、ggplot() 関数の出力を動的な図へかんたんに変換できます。ggplot() 関数の出力を保存して、それを ggplotly() 関数にパイプするだけです。\n下の図は、ある週に死亡した症例の割合を表すシンプルな線をプロットしたものです。\nまず、疫学週毎のサマリーデータを作成し、結果が判明している症例のうち死亡した症例の割合を計算します。\n\nweekly_deaths &lt;- linelist %&gt;%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %&gt;%  # 疫学週毎のデータの作成とグループ化\n  summarise(                                              # 新しいサマリーデータフレームの作成:\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # 結果が判明しているグループごとの症例数\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # 死亡したグループごとの症例数\n    pct_death = 100*(n_death / n_known_outcome)           # 結果が判明している症例のうち、死亡した症例の割合\n  )\n\nweekly_deaths データセットの最初の50行を示します。\n\n\n\n\n\n\nそして、ggplot2 パッケージで geom_line() 関数を使ってプロットを作成します。\n\ndeaths_plot &lt;- ggplot(data = weekly_deaths)+            # weekly_deaths データを使用する\n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # 折れ線グラフの作成\n\ndeaths_plot   # 出力\n\n\n\n\n\n\n\n\nこのプロットオブジェクトを以下のように ggplotly() 関数に渡すだけで、動的に表示できます。線の上にマウスを置くと、x と y の値が表示されます。図を拡大したり、ドラッグしたりすることができます。また、図の右上には、アイコンが表示されています。順に、以下のことができます。\n\n今表示されている図を PNG 画像としてダウンロードする\n選択範囲を指定して拡大\n“Pan”, つまり図をクリック＆ドラッグすることで図を移動させる\n拡大、縮小、またはデフォルトの縮尺に戻る\n軸のスケールをデフォルトに戻す\n動的にグラフ上の点からx軸、y軸に伸びる点線である “spike lines” のオン・オフを切り替える\nグラフ線上にカーソルを置いていないときにデータを表示するか否かの設定\n\n\ndeaths_plot %&gt;% plotly::ggplotly()\n\n\n\n\n\nグループ化されたデータも、ggplotly() 関数で動作します。下記の図は、結果ごとにグループ化された週毎の流行曲線（エピカーブ）を作成したものです。積み上げられた棒グラフは動的に表示されています。凡例の各項目をクリックしてみてください（現れたり消えたりします）。\n\n# incidence2 パッケージを用いた流行曲線（エピカーブ）の作成\np &lt;- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %&gt;% plot(fill = outcome)\n\n\n# 動的な図へ\np %&gt;% plotly::ggplotly()",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>動的な図の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.jp.html#変更修正",
    "href": "new_pages/interactive_plots.jp.html#変更修正",
    "title": "39  動的な図の作成",
    "section": "39.3 変更・修正",
    "text": "39.3 変更・修正\n\nファイルサイズ\nR Markdown で生成された HTML にエクスポートする場合（本書のように！）、図をできるだけ小さなデータサイズにすることが望まれます（ほとんどの場合悪影響はありません）。そのためには、動的な図オブジェクトを plotly パッケージの partial_bundle() 関数にパイプします。\n\np &lt;- p %&gt;% \n  plotly::ggplotly() %&gt;%\n  plotly::partial_bundle()\n\n\n\nボタン\n標準的な plotly のボタンの中には、余計なものや邪魔なものがあるので、それらを取り除くことができます。これは、plotly パッケージの config() 関数の出力をパイプでつなぎ、削除したいボタンを指定するだけで可能です。以下の例では、削除するボタンの名前をあらかじめ指定し、引数の modeBarButtonsToRemove = に渡しています。 また、displaylogo = FALSE とすることで、 plotly パッケージのロゴを削除しています。\n\n## これらのボタンは不要なので削除する\nplotly_buttons_remove &lt;- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np &lt;- p %&gt;%          # 上記のボタンを使わずに動的な図を再定義する\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>動的な図の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.jp.html#ヒートタイル",
    "href": "new_pages/interactive_plots.jp.html#ヒートタイル",
    "title": "39  動的な図の作成",
    "section": "39.4 ヒートタイル",
    "text": "39.4 ヒートタイル\nヒートタイルを含むほとんどの ggplot() プロットオブジェクトを動的に変えることができます。ある施設が州へデータを報告した日数の割合を表示する下記の図の作成方法についてヒートマップの章で説明しています。\nここでは詳細な説明はしませんが、コードを紹介します。\n\n# データのインポート\nfacility_count_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# Spring 地区におけるデータを週毎に集約\nagg_weeks &lt;- facility_count_data %&gt;% \n  filter(District == \"Spring\",\n         data_date &lt; as.Date(\"2020-08-01\")) %&gt;% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %&gt;% \n  group_by(location_name, week, .drop = F) %&gt;%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;% \n  ungroup(location_name, week) %&gt;%\n  right_join(tidyr::expand(., week)) %&gt;% \n  mutate(week = aweek::week2date(week))\n\n# プロットの作成\nmetrics_plot &lt;- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # 出力\n\n\n\n\n\n\n\n\n以下では、上記のグラフを動的にして、単純化したボタンやファイルサイズを修正しています。\n\nmetrics_plot %&gt;% \n  plotly::ggplotly() %&gt;% \n  plotly::partial_bundle() %&gt;% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>動的な図の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.jp.html#参考文献",
    "href": "new_pages/interactive_plots.jp.html#参考文献",
    "title": "39  動的な図の作成",
    "section": "39.5 参考文献",
    "text": "39.5 参考文献\nPlotly はR だけではなく、Python（JavaScript で作られているため、実際にはあらゆるデータサイエンスで用いられている言語）でも動作します。詳しくは plotly のウェブサイトをご覧ください。",
    "crumbs": [
      "データの可視化",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>動的な図の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html",
    "href": "new_pages/rmarkdown.jp.html",
    "title": "40  R Markdown で作るレポート",
    "section": "",
    "text": "40.1 準備\nR Markdown の背景\n関連するコンセプトといくつかのパッケージについての説明として：\nまとめると、バックグラウンドで 実行されるプロセス（それらのステップを全て知る必要はありません！）は、knitr に .Rmd ファイルを与えることに関わっています。このパッケージは、R コードチャンクを実行し、R コードとその出力を含む、新規の .md (markdown) ファイルを生成します。.md ファイルは、それから、完成品：（Microfoft Word ドキュメント、 HTML ファイル、powerpoint ドキュメント、pdf など）を作成するために pandoc で処理されます。\n(ソース： https://rmarkdown.rstudio.com/authoring_quick_tour.html):\nインストール\nR Markdown の出力を生成するためには以下に挙げるものがインストールされている必要があります：\npacman::p_load(tinytex)     # tinytex パッケージのインストール\ntinytex::install_tinytex()  # TinyTeX ソフトウェアをインストールするための R コマンド",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#準備",
    "href": "new_pages/rmarkdown.jp.html#準備",
    "title": "40  R Markdown で作るレポート",
    "section": "",
    "text": "Markdown は、プレーンテキストで文書を記述できる “言語” です。それで、記述された文書は、html や他の形式に変換できます。これは、R 言語に特化したものではありません。Markdown で記載されたファイルは, ’ .md’ 拡張子を持ちます。\nR Markdoen: は、R 言語に特化した markdown 言語の一種です。- それは、markdown 言語を用いて、テキストを生成し R コードを埋め込み、そのアウトプットを表示するための文書を記載することが可能です。 R Markdown ファイルは ‘.Rmd’ 拡張子を持ちます。\nrmarkdown - パッケージ: このパッケージをR上で利用することで、 .Rmd ファイルを希望の形式に描画することができます。このパッケージの目的は、markdown（文書）のシンタクスを変換することです。つまり、更に下記パッケージが必要です…\nknitr: この R パッケージは、コードチャンクを読み取り、実行し、さらに「編み上げて」（knit して）文書に差し込みます。このようにすることで、表やグラフをテキストとともに文書に含むことができます。\nPandoc: 最後に、pandoc は、word/pdf/powerpoint などに出力を実際に変換します。R とは分離したソフトフェアですが、RStudio とともに自動的にインストールされます。\n\n\n\n\n\n\n\nrmarkdown パッケージ(knitr も自動的にインストールされます)\nRStudio とともにインストールされる Pandoc。もし RStudio を使用していない場合は、ここから Pandoc をダウンロード可能です： http://pandoc.org\nもし PDF 出力を生成したい場合は（少し変則的ですが）、LaTeX のインストールが必要です。事前に、 LaTeX をインストールしていない R Markdown ユーザには、TinyTex (https:yihui.name/tinytex/) のインストールをおすすめします。下記のコマンドでインストール可能です：",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#はじめに",
    "href": "new_pages/rmarkdown.jp.html#はじめに",
    "title": "40  R Markdown で作るレポート",
    "section": "40.2 はじめに",
    "text": "40.2 はじめに\n\nrmarkdown R パッケージのインストール\nrmarkdown R パッケージをインストールします。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R basics の章をご覧ください。\n\npacman::p_load(rmarkdown)\n\n\n\n新規 Rmd ファイルの作成\nRStudio 内で新規の R markdown ファイルを開には、File を選択し、それから、New file を選択し、R markdown... を選択します。\n\n\n\n\n\n\n\n\n\nR Studio は、あなたにどの出力を行うかを選択するオプションを提示します。Html 文書をここでは作りたいので、下記の例では、“HTML” を選択しています。Title と Author は重要ではありません。希望する出力文書形式が選択肢の中になくても心配いりません。いずれかひとつの文書形式を選択した後、文書の中で変更することができます。\n\n\n\n\n\n\n\n\n\nこの操作で、新規の .Rmd スクリプトが開かれます。\n\n\n知っておくべき重要事項\nワーキングディレクトリ\nマークダウンファイルのワーキングディレクトリは、Rmd ファイル自身が保存された場所になります。例えば、もし R プロジェクトが ~/Docuents/projectX 内にあり、Rmd ファイル自体がサブフォルダ ~/Documents/projectX/markdownfiles/markdown.Rmd にある場合、マークダウン内に記載されたコード read.csv(\"data.csv\") は、プロジェクトに含まれるスクリプトが通常自動的に検索するプロジェクトのルートフォルダではなく、markdownfiles フォルダ内の csv ファイルを検索します。\n他の場所のファイルを参照するには、絶対ファイルパス、あるいは、here パッケージのいずれかを使用する必要があるでしょう。here パッケージは、ワーキングディレクトリを R プロジェクトのルートフォルダに設定します。詳細は、このハンドブックのR プロジェクトの設定 および データのインポート・エクスポート の章で説明されています。例えば、projectX フォルダ内にある “data.csv” というファイルをインポートするためのコードは、import(here(\"data.csv\")) となります。\n注意、R markdown スクリプト内で setwd() を使用することは推奨されません。このコマンドは、これが書かれたコードチャンク内にのみ適用されます。\n共有フォルダ上とローカルコンピュータ上での作業について\n共有ネットワークドライブ上で実行するとき、R Markdown は pandoc の問題とぶつかるので、作業フォルダを自身のローカルコンピュータ上のフォルダにすることが推奨されます。例えば、’ My Documents’ 内のプロジェクトなど。もし、Git を使用している（非常におすすめです！）場合、ローカルコンピュータ上で作業することに慣れていると思います。より詳細は、このハンドブックの ネットワークドライブで R を使用する場合 および エラーとヘルプ の章をご覧ください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#r-markdown-を形作る部品",
    "href": "new_pages/rmarkdown.jp.html#r-markdown-を形作る部品",
    "title": "40  R Markdown で作るレポート",
    "section": "40.3 R Markdown を形作る部品",
    "text": "40.3 R Markdown を形作る部品\nR Markdown 文書は通常の R スクリプトと同じように RStudio 内で編集可能です。新規 R Markdown スクリプトを開いたとき、RStudio は R Markdown スクリプトの様々なセクションを説明するテンプレートを表示することで手助けしようとします。\n下記は、html 出力を生成することを目的とした新しい Rmd スクリプトを始めたときに表示される内容です。（前節で説明した通り）\n\n\n\n\n\n\n\n\n\nご覧の通り、Rmd ファイル内には３つの基本コンポーネントがあります：YAML、Markdown テキスト、そして、R コードチャンクです。\nこれらが生成され、文書の出力になります。下記の図をご覧ください：\n\n\n\n\n\n\n\n\n\n\nYAML メタデータ\n「YAML メタデータ」 あるいは単に ‘YAML’ と呼ばれる情報は、R Markdown 文書の冒頭にあります。スクリプトのこのセクションでは、Rmd ファイルに生成する出力の種類、書式設定、および文書の表題、作成者、日付などのメタデータを設定します。ここで言及しきれない他の用途があります。（「出力の生成」 で説明されます）。インデントが重要であることに注意してください。タブは利用できませんが、スペースが使用可能です。\nこのセクションは、ダッシュ３つ --- のみの行で開始する必要があります。そして、ダッシュ３つ --- のみの行で閉じねばなりません。YAML パラメタは、key:value のペアで設定されます。YAML でのコロンの場所は重要です。key:value ペアは、コロンで区切られます（等号記号ではありません！）。\nYAML は文書のメタデータで開始される必要があります。これら、 YAML パラメタ（インデントされていない）の順序は重要ではありません。例えば次のような形です：\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"2024-05-08\"\nYAML 値の中で R コードを使用するには、インラインコード（バックティック内に r が前置されます）としてだけてなく、引用符内の記述（上記の記述例中の data: 箇所をご覧ください）として記述します。\n上記の画像内では、デフォルトの出力が html ファイルになるように選択したため、YAML 中に output: html_document と記述されています。しかしながら、この記述を powerpoint_presentation、word_document や pdf_document にも変更できます。\n\n\nテキスト\nこのセクションは、題名と見出しを含めた文書の本文です。この本文は、多くの他のソフトウェアで使用されている “markdown” 言語で記述されています。\n下記に本文を記入する核となる方法を記載します。より広範な文書は、RStudio ウェブサイト上の R Markdown “cheatsheet” をご覧ください。\n\n新規行の挿入\nR Markdown の特徴として、新しい行を始めるためには、半角スペース２つ を前の行末に入力し、Enter/Return キーを押す必要があります。\n\n\n強調\n本文を下記の記号で囲むことで出力の表示方法を変更します。\n\nアンダースコアで囲む（_text_）あるいは、１つのアスタリスクで囲む（*text*）ことで イタリック体 になります\nアスタリスク 2 個で囲む（**text**）ことで、ボールド体 になります。\nバックティックで囲む（text）ことで文書をコード片として表示します。\n\nフォントの実際の見た目は特定のテンプレートを使用して設定できます（YAML メタデータの中で指定します。タブの例を参照してください）。\n\n\n文字色\nR Markdown に文字色を変えるためのシンプルな仕組みはありません。回避策の一つとして、もし出力が HTML 文書であれば、markdown テキストに HTML 行を挿入します。下記の HTML コードは、行内のテキストを、ボールド体で赤色に表示します。\n&lt;span style=\"color: red;\"&gt;**_DANGER:_** This is a warning.&lt;/span&gt;  \nDANGER: This is a warning.\n\n\n題名と見出し\nR Markdown スクリプト内における本文中のハッシュ記号は、見出しを生成します。これは R コードチャンク内の通常の R スクリプトのコメント / 注釈 / 評価を外すためのハッシュ記号とは違います。\n新規行の行頭に、異なる数のハッシュ記号を置くことで、異なるレベルの見出しが生成できます。ハッシュ記号 1 個は、題名や主題となる見出しとなります。ハッシュ記号 2 個は、第２レベルの見出しになります。第３レベル、第４レベルの見出しは、ハッシュ記号を連続で追加することによって生成されます。\n# 第１レベルの見出し・題名\n\n## 第２レベルの見出し\n\n### 第３レベルの見出し\n\n\n箇条書きと番号付き箇条書き\n箇条書きを作成するには、アスタリスク（*）を使用します。前段を書き終えたあと、半角スペースを 2 個入力し、Enter/Return キーを 2 回入力します。それから、箇条書きを開始します。アスタリスクと、箇条書きの本文の間に半角スペース 1 個を入力します。各箇条書きの本文を入力し終わるたびに、半角スペース 2 個を入力し、Enter/Return キーを入力します。インデントを加えることで、入れ子の箇条書きが同じように機能します。番号付きの箇条書きも同じように入力しますが、アスタリスクの代わりに、1), 2) などのように入力します。下記は R Markdown スクリプトがどのように見えるかを示しています。\nHere are my bullets (there are two spaces after this colon):  \n\n* Bullet 1 (followed by two spaces and Enter/Return)  \n* Bullet 2 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 1 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 2 (followed by two spaces and Enter/Return)  \n  \n\n\nテキストのコメントアウト\n“#” を使用して R チャンク内の R コード行をコメントアウトできるように、R Markdown テキストを「コメントアウト」できます。テキストを選択状態にして、Ctrl+Shift+c（Mac の場合は Cmd+Shift+c）を押すだけです。テキストは矢印で囲まれ、文字色が緑に変わります。出力には現れません。\n\n\n\n\n\n\n\n\n\n\n\n\nコードチャンク\nR コード実行のためのスクリプトのセクションは、「チャンク」と呼ばれます。パッケージをロードしたり、データをインポートしたり、実際のデータ管理と、視覚化を、ここで実行できます。多くのコードチャンクを利用することで、Rコードを部分的に文章によって分けて管理すると便利に使えるでしょう。注意：これらの「チャンク」は文書の本文部分とは若干異なる背景色に見えます。\n各チャンクは、バックティック 3 個で始まる行と、チャンクのパラメタを含む中カッコ（{ }）で開始されます。チャンクは、更にバックティック 3 個で終了します。\n新しいチャンクを作成するには、自分で入力するか、キーボード・ショートカット、“Ctrl + Alt + i”（Mac では Cmd + Shift + r）を使用するか、スクリプトエディタの上辺にある緑色の ‘insert a new code chunk’ アイコンをクリックします。\n中カッコ { } の内容に関する注意事項：\n\nチャンク内の言語名が R であることを示すため ’ r’ で開始されます\nr のあとに続いて、オプションでチャンクの「名前」を記入することができます。必須ではありませんが、作業を整理するために役立ちます。チャンクに名前をつける場合、常に一意の名前をつける必要があります。そうしない場合、レンダリング時に R からエラーが通知されます\n中カッコは他に、tag=value と書かれたオプションをつけることが可能です。例えば：\n\neval = FALSE は、R コードを実行しません\necho = FALSE は、チャンク内の R ソースコードを出力文書に含めません\nwarning = FALSE は、R コードが生成する警告文を出力しません\nmessage = FALSE は、R コードが生成するいかなるメッセージも出力しません\ninclude = チャンクの出力（例、プロット）を文書に含めるかどうかを TRUE/FALSE で指定します\nout.width = と out.height = はスタイルを設定します out.width = \"75%\"\nfig.align = \"center\" は、図がページ全体を通してどのように配置されるかを調整します\nfig.show='hold' は、チャンクが複数の図を出力し、それらを並べて出力したい場合、次のオプションとペアで使用します（out.width = c(\"33%\", \"67%\")）。図をそれを生成するコードの下に表示するfig.show='asis' とともに設定可能です。'hide' を指定することで非表示にし、'animate' と指定することで複数の図を一つのアニメーションにします。\n\nチャンクヘッダは一行で記述されなければいけません\nピリオド、アンダースコア、半角スペースを使わないようにしてください。セパレータが必要な場合は、ハイフン（ - ）を使用してください\n\nknitr オプションについて詳しくは、こちらをご覧ください。\n上記のオプションの一部は、チャンクの右上にある設定ボタンを使用してマウス操作で設定できます。この設定ボタンでは、チャンクのどの部分をレンダリングされた文書に含めるか、つまり、コード、出力、警告文を指定できます。この指定は、中カッコに記述済みの設定として表示されます。例えば、’ Show output only’ を指定した場合、echo=FALSE が中カッコに記述されます。\n\n\n\n\n\n\n\n\n\nまた、チャンクの右上には、 2 個の矢印があり、チャンク内のコード、または、現在のチャンク以前のチャンク内のコードを実行するのに役立ちます。これらのアイコンにカーソルを合わせると、何を実行するかがわかります。\nスクリプト内のすべてのチャンクにグローバルオプションを設定するには、スクリプト内の一番最初の R コードチャンクで設定できます。例えば、コード自体ではなく、各コードのチャンクの出力のみが表示されるように、次のコマンドを R コードチャンクに含めることが可能です：\n\nknitr::opts_chunk$set(echo = FALSE) \n\n\nテキスト内 R コード\nバックティック内に最小限の R コードを含めることもできます。バックティック内で、コードを “r” と半角スペースで開始します。これにより、RStudio はこのコードを、R コードとして評価します。下記の例を参照してください。\n下記の例は、複数の見出しレベルと箇条書きを表示していて、現在の日付を返す R コード（Sys.Date()）を使用して出力された日付を評価しています。\n\n\n\n\n\n\n\n\n\n上記の例は、単純（現在の日付を表示する）ですが、同じシンタクスを使用して、より複雑な R コードによって生成された値を表示することができます（例、列の最小値、中央値、最大値を計算する）。スクリプト内のこれ以前の R コードチャンクで生成された R オブジェクトや、値を統合することができます。\n例として、下記のスクリプトは、tidyverse 関数を用いて、18 歳未満のケース割合を計算し、オブジェクト less18、total、less18prop を生成します。この動的な値は、後続のテキストに挿入されます。word 文書に組み込んだ場合どのように見えるかを確認しましょう。\n\n\n\n\n\n\n\n\n\n\n\n\n画像\n次の２つの方法のうちいずれかで R Markdown に画像を埋め込むことができます：\n\n![](\"path/to/image.png\")  \n\nもし上記の方法がうまく行かなかったら、knitr::include_graphics() を試してください。\n\nknitr::include_graphics(\"path/to/image.png\")\n\n（ファイルパスは、here パッケージを使用して記述できることを覚えていますか？）\n\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))\n\n\n\n表\nハイフン（ - ）とバー（ | ）を使用して、表を組みます。バーの前やバー間のハイフンの数で、セル内のテキストが折り返されるまでの空白の数が設定されます。\nColumn 1 |Column  2 |Column 3\n---------|----------|--------\nCell A   |Cell B    |Cell C\nCell D   |Cell E    |Cell F\n上記のコードは下記の表を生成します：\n\n\n\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\nCell A\nCell B\nCell C\n\n\nCell D\nCell E\nCell F\n\n\n\n\n\nタブ分けされたセクション\nHTML 出力の場合、セクションを「タブ」に分けることができます。.tabset を見出し直後の中カッコ { } 中に設定するだけです。この設定をした見出しより下位の見出しは（同じレベルに他の見出しが現れるまで）ユーザがクリック可能なタブとして表示されるでしょう。より詳しくは、こちらをご覧ください。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.tabset のあとに、タブに、「積み重ねられた」見た目を付与する追加のオプションである .tabset-pills を追加できます。タブを含む HTML 出力を表示中に、 Ctrl+f 検索は、非表示のタブではなく、「アクティブ」 なタブのみを検索することに注意してください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#ファイル構造",
    "href": "new_pages/rmarkdown.jp.html#ファイル構造",
    "title": "40  R Markdown で作るレポート",
    "section": "40.4 ファイル構造",
    "text": "40.4 ファイル構造\nR Markdown と関連する R スクリプトを構造化するいくつかの方法があります。各方法は、利点と欠点があります：\n\n自己内包型 R Markdown - レポートに必要な全ては、R Markdown にインポートもしくは生成されます\n\n他のファイルを取り込む - 外部 R スクリプトを source() コマンドで実行することができ、その出力を Rmd 内で利用できます\n子スクリプト - source() のもう一つの方法\n\n「runfile」 の活用 - R Markdown にレンダリングする前に、R スクリプト内のコマンドを実行します\n\n\n自己内包型 Rmd\n比較的単純なレポートの場合、R Markdown スクリプトを「自己内包」として、外部スクリプトを含まないように構成することを選択できます。\nコードチャンクや、パッケージの読み込みなど、R markdown を実行するために必要なものを全て、Rmd ファイルにインポートあるいは生成して含めます。「自己内包型」アプローチは、多くのデータ処理を行う必要がなく（例えば、クリーンなあるいは、セミクリーンなデータを取り込むとき）、R Markdown をレンダリングするために多くの時間を必要としない場合に適しています。\nこのシナリオの場合、R Markdown スクリプトの論理的な構成は下記のようになります：\n\nグローバルな knitr オプションを設定します\nパッケージを読み込みます\nデータをインポートします\nデータを処理します\n出力を生成します（表、プロットなど）\n該当する場合は、出力を保存します（.csv, .png など）\n\n\n他のファイルを取り込む\n「自己内包型」 アプローチのひとつのバリエーションは、R Markdown コードチャンクに他の R スクリプトを “source”（実行）させることです。この方法により R Markdown スクリプトが整理、単純化され、管理しやすくなります。この方法は、レポートの冒頭に、最終的な数値を表示させたいときにも役立ちます。このアプローチでは、最終的な R Markdown スクリプトは、前処理された出力を文書へ組み込むだけです。\nこのアプローチの一つの方法は、R スクリプト（ファイルパスと拡張子を含むファイル名）を base R コマンドの source() に渡すことです。\n\nsource(\"your-script.R\", local = knitr::knit_global())\n# or sys.source(\"your-script.R\", envir = knitr::knit_global())\n\nR Markdown 内で source() を使用する場合、外部ファイルは Rmd ファイルがレンダリングされる過程で実行されることに注意してください。そのため、各スクリプトは、レポートをレンダリングするたびに実行されます。ゆえに、これらの source() コマンドを R Markdown 内に記述しても実行時間を短縮することはなく、R Markdown の生成時に出力されたエラーが引き続き出力されるため、デバッグを大幅に支援することもありません。\nもう一つの方法は、knitr オプションの child = を活用することです。\n様々な R 環境に注意する必要があります。環境内で生成されたオブジェクトは、R Markdown で使用される環境で必ずしも利用可能とは限りません。\n\n\n\nRunfile\nこのアプローチは、render() コマンドを含む R スクリプトを利用し、R Markdown に渡すオブジェクトを前処理します。\n例えば、render() を実行する前に、パッケージを読み込んだり、データを読み込みクリーニングにしたり、目的のグラフを生成したりすることさえできます。これらのステップは、R スクリプト、または source() で取り込まれる他のスクリプトで行う必要がある可能性があります。これらのコマンドが同じ RStudio セッションで生成され、オブジェクトが環境に保存されている限り、オブジェクトを Rmd 内で呼び出すことが可能です。そのため、R markdown それ自身は、事前に作成されたオブジェクトを出力に含める、最終行程のためだけに利用されることとなります。この方法は、もし何か誤りがあるときにデバッグがはるかに容易です。\nこの方法は、下記の理由で便利です：\n\nより多くの情報を含むエラーメッセージ - エラーメッセージが、 R Markdown ではなく R スクリプトから生成されます。R Markdown ではどのチャンクにエラーがあるか表示されるだけで、どの行であるかは知らせてくれません。\n該当する場合は、render() コマンドの前に長い処理を実行できます。- この処理は、１回だけしか実行されません。\n\n下記は、分割された R スクリプトの例です。前処理した data オブジェクトを現在の R 環境に取り込み、render() を使用して、“create_output.Rmd” をレンダリングしています。\n\ndata &lt;- import(\"datafile.csv\") %&gt;%       # データを読み込み、環境に保存する\n  select(age, hospital, weight)          # 限定された列を選択する\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Rmd ファイルを生成する\n\n\n\nフォルダ構成\nワークフローは、作成された文書や図用の ‘output’ フォルダや、クリーンになったデータ用の ‘data’ や ‘inputs’ フォルダなど、全体的なフォルダ構造にも関与します。ここではこれ以上詳細に言及しませんが、定期レポート作成の効率化の章をご覧ください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#文書の生成",
    "href": "new_pages/rmarkdown.jp.html#文書の生成",
    "title": "40  R Markdown で作るレポート",
    "section": "40.5 文書の生成",
    "text": "40.5 文書の生成\n下記の方法で、文書を生成できます：\n\nRStudio のスクリプトエディタの上辺にある “Knit” ボタンを手動で押す（素早く、簡単です）\nrender() コマンドを実行する（R Markdown スクリプトの外部で実行される）\n\n\n選択肢 1： “Knit” ボタン\nRmd ファイルを開いたら、ファイルの上辺にある ‘Knit’ アイコン（ボタン）を押します。\nR Studio は R コンソールの近くにある ’ R Markdown’ タブに進行状況を表示します。処理が完了すると、文書は自動的に開かれます。\n文書は、R markdown スクリプトと同じフォルダに、同じ名前で保存されます（拡張子を除く）。この保存方法は、明らかにバージョン管理には理想的ではありません（文書は、手動でファイルを移動させない限り、knit するたびに上書きされます）。ファイルの名前を自分で変更する必要があるでしょう（例、日付を追加する）。\nこのボタンは、rmarkdown の render() 関数への RStudio のショートカットボタンです。この方法が有効なのは、必要なコンポーネントが存在する、あるいはファイル内で必要なものをソースしている自己内包型のR markdown のみです。\n\n\n\n\n\n\n\n\n\n\n\n選択肢 2： render() コマンド\nR Markdown 出力を生成する別の方法は、（rmarkdown パッケージの）render() 関数を実行することです。このコマンドは、R Markdown スクリプトの外で実行する必要があります。つまり、分割された R スクリプト（“run file” と呼ばれることが多い）で実行するか、R コンソールでスタンドアロンコマンドとして実行する必要があります。\n\nrmarkdown::render(input = \"my_report.Rmd\")\n\n“knit” と同じように、デフォルト設定では、Rmd 出力は、Rmd スクリプトと同じフォルダに、同じ名前で保存されます（ファイル拡張子を除いて）。例えば、“my_report.Rmd” が knit されると、word 文書に knit する場合 “my_report.docx” が生成されます。render() を使用すると、さまざまなオプションから設定を利用することができます。render() には、次の引数を与えることができます：\n\noutput_format = このオプションは、出力形式を変換します（例えば、\"html_document\", \"pdf_document\", \"word_document\", や \"all\"）。このオプションを、R Markdown スクリプト内の YAML で指定することも可能です。\noutput_file = このオプションは、出力ファイル（とファイルパス）の名前を指定します。以下に示すように、here() や str_glue() などの R 関数を介して生成することが可能です。\noutput_dir = このオプションは、ファイルを保存するディレクトリ（フォルダ）を指定します。Rmd ファイルが保存されているディレクトリ以外の代替を指定可能です。\noutput_options = スクリプト内の YAML を上書きするオプションのリストを引数として渡せます。\noutput_yaml = YAML 設定を含む .yml ファイルへのファイルパスを引数として渡せます。\nparams = 下記のパラメタセクションをご覧ください。\n完全な引数のリストはこちらです。\n\n一例として、バージョン管理を改善するために、下記のコマンドは、ファイル名に現在の日付を付加し、‘outputs’ サブフォルダ内に出力ファイルを保存します。ファイル名を生成するために、stringr パッケージの str_glue() 関数を使用して、（平文で書かれた）静的文字列と（中カッコ内に書かれた）動的 R スクリプトを 「接着」 します。例えば、2021 年 4 月 10 日の場合、下記のファイル名は、 “Report_2021-04-10.docx” となるでしょう。str_glue() についての詳細は、文字型・文字列型データ の章をご覧ください。\n\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) \n\nファイルがレンダリングされると、RStudio コンソールに 100% の進行表示が現れ、レンダリングが完了したことを示す終了メッセージが表示されます。\n\n\n選択肢 3： reportfactory パッケージ\nR パッケージの reportfactory は、レポートを定期的に実行するシナリオ（例、日毎、週毎…）に対応する R Markdown レポートを整理及び、コンパイルするための代替の方法を提供します。このパッケージにより複数の R Markdown ファイルのコンパイルと、それらの出力の管理が容易になります。一言でいうと、このパッケージは、R Markdown レポートを実行し、日付、時刻が自動的に挿入された出力のためのフォルダを生成し、“light” バージョン管理を行うことができる “factory” を提供します。\nこのワークフローについてより詳しくは、定期レポート作成の効率化 の章をご覧ください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#パラメタ化されたレポート",
    "href": "new_pages/rmarkdown.jp.html#パラメタ化されたレポート",
    "title": "40  R Markdown で作るレポート",
    "section": "40.6 パラメタ化されたレポート",
    "text": "40.6 パラメタ化されたレポート\nレポートを動的にするためにパラメタ化を使用することができます。これにより、特定の設定（例、特定の日付や、場所、特定の knit オプション）でレポートを実行可能です。下記では、基本的な部分を解説します。パラメタ化されたレポートについての詳細はオンラインにあります。\n例として、エボラ出血熱の流行をシミュレートした症例ラインリストを使用します。各病院の標準的なサーベイランスレポートを毎日実行するとします。パラメタを使用してどのように実行するかを示します。\n重要：動的レポートは、フォルダ内の R スクリプト内の単純な R オブジェクトを使用して正式なパラメタ構造（params: なし）を取らずに構築することも可能です。このことは、このセクションの最後で説明します。\n\nパラメタの設定\nR Markdown 出力をパラメタ値を指定するためのいくつかの選択肢があります。\n\n選択肢 1：YAML 内にパラメタを設定する\nYAML に params: オプションを含むように編集します。定義したいパラメタごとにステートメントをインデントします。下記の例では、特定の値をもたせたパラメタ data と hospital を生成しています。これらの値は、レポートが実行されるたびに変更の対象になります。出力を生成するために “Knit” ボタンを使用する場合、パラメタは YAML で設定したデフォルト値になります。同じように、render() を使用した場合、render() コマンドで特に値を指定しない限り、パラメタは、YAML で設定したデフォルト値になります。\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Central Hospital\n---\nバックグラウンドでは、上記のパラメタ値は、params と呼ばれる読み込み専用のリストに含まれています。それゆえ、環境内の他の R オブジェクト・値と同じように R コード内にパラメタ値を埋め込むことができます。params$ に続けてパラメタ名を入力するだけです。例えば、病院名を表す params$hospital（デフォルトでは、“Central Hospital” となります）。\nパラメタ値は、true や false という値を保持できるため、R チャンクの knitr オプションに埋め込むこともできることに注意してください。例えば、{r, eval=FALSE} の代わりに {r, eval=params$run} を設定できます。チャンクが事項されるかどうかは、run: パラメタの値によって異なります。\n日付のパラメタの場合、文字列として埋め込まれることに注意してください。つまり、params$date を R コードとして解釈させる場合は、as.Date() やその他の似た関数に渡して日付型（Date）に変換する必要があります。\n\n\n選択肢 2： render() 内にパラメタを設定する\n前述のように、“Knit” ボタンを押して出力を生成する代わりに、分割したスクリプトから render() 関数を実行することも可能です。後者の場合、そのレンダリングで使用されるパラメタを render() の引数である params = で指定できます。\nここで指定されるパラメタ値は、YAML 内にデフォルト値が記述されていた場合上書きすることに注意してください。この場合、値は character/string 値として定義されるべきなので、引用符で囲んで記述します。\n下記のコマンドは、“surveillance_report.Rmd” をレンダリングし、動的に出力ファイル名とフォルダを指定し、そして、２つのパラメタのリストとしてその値とともに params = 引数へ渡します。\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))\n\n\n\n選択肢 3： グラフィカルユーザーインタフェースを使用してパラメタを設定する\nよりインタラクティブに操作するために、グラフィカルユーザーインタフェース（GUI: Graphical User Interface）を使用してパラメタの値を手動で選択することもできます。この操作を行うには ‘Knit’ ボタンの隣りにあるドロップダウンメニューをクリックし、‘Knit with parameters’ を選択します。\nポップアップが表示され、文書の YAML で設定したパラメタ値を変更できます。\n\n\n\n\n\n\n\n\n\n下記のデモのように、params = \"ask\" を指定することで render() コマンドを通して同じ操作を実現できます。\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)\n\nしかしながら、ポップアップウィンドウに値を手入力することは、エラーやスペルミスの影響を受けます。ドロップダウンメニューを利用して、入力できる値に制限を追加することをお勧めします。この操作を行うには、YAML 内の各 params: 項目にいくつかの指定を追加します。\n\nlabel: その特定のドロップダウンメニューのタイトル\nvalue: デフォルト値（開始時の値）\ninput: ドロップダウンメニューへ select を設定\nchoices: ドロップダウンメニュー内で select の選択肢となる値を指定\n\n下記では、hospital パラメタにこれらの項目を記述しています。\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---\n上記の設定で knit する（‘knit with parameters’ ボタンもしくは、 render() のいずれかを使用する）場合、ポップアップウィンドウにドロップダウンオプションが表示され、そこから選択することができます。\n\n\n\n\n\n\n\n\n\n\n\n\nパラメタ化の例\n下記のコードは、R Markdown 内で各々 params$date と params$hospital として利用されている date と hospital パラメタを生成します。\nレポート出力結果内で、データが特定の病院名でどのようにフィルタされているかを確認します。グラフのタイトルは、正しい病院名と日付を示しています。ここでは、“linelist_cleaned.rds” ファイルを使用しますが、もしラインリストファイル自身にも、パラメタライズされた日付順に並ぶ日付スタンプが含まれている場合に、この方法は特に有効です。\n\n\n\n\n\n\n\n\n\nデフォルトのフォントとレイアウトで knit した場合の最終出力は下記です。\n\n\n\n\n\n\n\n\n\n\n\nparams を用いないパラメタ化\n分割した別のスクリプトから render() で R Markdown をレンダリングする場合は、params: 機能を使わずにパラメタ化の結果を出力できます。\n例えば、render() コマンドを含んだ R スクリプト内で render() コマンドより前に、2 つの R オブジェクト（値）として hospital と date を定義するだけです。R Markdown において、YAML 内に params: セクションは必ずしも必要ではありません。また、params$date ではなく、date オブジェクトとして、params$hospital ではなく、hospital オブジェクトとして参照します。\n\n# R Markdown とは分割された R スクリプトファイル\n\n# R オブジェクトの定義\nhospital &lt;- \"Central Hospital\"\ndate &lt;- \"2021-04-10\"\n\n# R markdown のレンダリング\nrmarkdown::render(input = \"create_output.Rmd\") \n\nこのアプローチを実行する場合、“knit with parameters” や、GUI の使用、knit オプションをパラメタに含めるなどができないことを意味します。しかしながら、コードが単純になるため、メリットとなる場合があります。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#レポート生成を繰り返し実行する",
    "href": "new_pages/rmarkdown.jp.html#レポート生成を繰り返し実行する",
    "title": "40  R Markdown で作るレポート",
    "section": "40.7 レポート生成を繰り返し実行する",
    "text": "40.7 レポート生成を繰り返し実行する\n各管轄区 / ユニットのレポートを生成するために、入力パラメタを変更して、レポート生成を複数回実行したい場合があります。これは、ループと反復処理・リストの操作 の章で詳細が説明されているイテレーション用のツールを用いることで実行できます。オプションには、purrr パッケージや、下記で説明する for loop の使用が含まれます。\n下記では、単純な for ループを用いて、関心のあるすべての病院のサーベイランスレポートを生成します。これは、（hospital パラメタを一つ一つ手動で変更する代わりに）1 つのコマンドで実行されます。レポートをレンダリングするコマンドは、レポート用 Rmd ファイル外に存在する必要があります。このスクリプトには、「ループ処理（loop through）」 するための定義済みオブジェクト - 今日の日付と病院名のベクタも含まれます。\n\nhospitals &lt;- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \n\n次に、ループを使用して、これらの値を render() コマンドへ渡します。このループは、hospitals ベクタの各値ごとに一度コマンドを実行します。文字 i は、現在のイテレーションで使用されている病院のインデクス位置（1 から 4）を表し、hospital_list[1] は ” Central Hospital” になります。この情報は、 render() コマンドの 2 つの位置で使用されます：\n\nファイル名に使用。2021 年 4 月 10 日に生成された場合、最初のイテレーション時のファイル名が “Report_Central Hospital_2021-04-10.docx” になり、作業ディレクトリの ‘output’ サブフォルダに保存される\nparams = に使用。 params$hospital の値が呼び出されるたびに Rmd が内部で病院名を使用するようにする。この例では、各病院で 1 つずつ、合計 4 つのファイルが生成される\n\n\nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#テンプレート",
    "href": "new_pages/rmarkdown.jp.html#テンプレート",
    "title": "40  R Markdown で作るレポート",
    "section": "40.8 テンプレート",
    "text": "40.8 テンプレート\n必要なフォーマットを含むテンプレート文書を使用することで、Rmd 出力の視覚的な外観を調整できます。例えば、必要な寸法、透かし、背景やフォントを含むページ ・スライドを持つ MS Word や Powerpoint ファイルを生成できます。\n\nWord 文書\nテンプレートを作成するには、新規 word 文書を開始（または、適切なフォーマットを持つ既存の出力を使用）して、スタイルを定義しフォントを編集します。スタイルにおいて、見出し 1, 2, 3 は個々の markdown 見出しレベルを示します（それぞれ # Header 1, ## Header 2 そして ### Header 3）。スタイルのメニュー上で右クリックし、「変更」 をクリックして、フォントの書式と段落を変更します（例えば、特定のスタイルの前にページ分割を挿入すると、間隔を空けることに役立ちます）。余白、ページサイズ、ヘッダーなどの word 文書の他の要素は、直接作業している通常の word 文書のように変更できます。\n\n\n\n\n\n\n\n\n\n\n\nPowerpoint 文書\n上記と同じように、新しいスライドを生成するか、適切なフォーマットを持つ既存の powerpoint ファイルを使用します。編集するには、「表示」、「スライドマスター」 をクリックします。この編集画面から、テキストボックスのテキストフォーマットと背景・ページのサイズを編集して、「マスター」 スライドの外観を変更できます。\n\n\n\n\n\n\n\n\n\n残念ながら、powerpoint ファイルの編集は、やや柔軟性にかけます：\n\n第一レベルの見出し（# Header 1）は自動的に新規スライドのタイトルになります\n## Header 2 テキストはサブタイトルとして表示されませんが、スライドのメインテキストボックスにテキストとして表示されます（スライドマスタで編集する方法を見つけない限りは）\n出力されたプロットと表は、自動的に新規スライドに表示されます。それらを組み合わせる場合、例として、ggplot を組み合わせるための patchwork 関数を使用して、同一のページに表示されるようにします。多数の画像を一つのスライドに組み合わせるために patchwork パッケージを使う方法は、このブログ記事をご覧ください\n\npowerpoint プレゼンテーションでより深いレベルで機能するツールについては、officer パッケージをご覧ください。\n\n\nYAML にテンプレートを統合する\nテンプレートが準備されたら、Rmd 内 YAML の ‘output’ 行の下、かつ、文書タイプが指定されている行の下に、その詳細を追加できます（分割された行として）。reference_doc は powerpoint のスライドテンプレートに使用できることに注意してください。\nテンプレートは、Rmd ファイルが保存されているのと同じフォルダ、もしくは、そのサブフォルダに保存するのが最も簡便です。\n---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---\n\n\nHTML ファイルのフォーマット\nHTML ファイルは、テンプレートを使用しませんが、YAML 内でスタイルを設定できます。HTML はインタラクティブな文書であり、特に柔軟性があります。ここでは、いくつかの基本的なオプションについて説明します。\n\n目次：下記の例のように toc: true オプションで目次を追加できます。さらに、toc_float: true オプションを使用することで、スクロールに合わせて、画面に表示される（フロート、“floats”）ように指定できます。\nテーマ：Bootswatch テーマライブラリからのいくつかの既成のテーマを参照可能です。下記の例では、cerulean テーマを使用しています。他には以下のオプションがあります：journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, と yeti。\nハイライト：このオプションを設定すると、ハイライトされたテキストの外観を変更できます（例、下記ではチャンク内のコード）。サポートされているスタイルは以下のものがあります、デフォルト、tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, や textmate。\n\n上記のオプションを YAML に統合する方法の例を次に示します。\n---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---\n以下は、フロートした目次があり、それぞれ異なるテーマとハイライトスタイルが選択されている HTML 出力の 2 つの例です：",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#動的コンテンツ",
    "href": "new_pages/rmarkdown.jp.html#動的コンテンツ",
    "title": "40  R Markdown で作るレポート",
    "section": "40.9 動的コンテンツ",
    "text": "40.9 動的コンテンツ\nHTML 出力では、動的な出力をレポートに含めることができます。下記に例を示します：\n\n表\nHTML レポートでは、フィルタとスクロールバーを付加して動的なコンテンツになるようにデータフレームやtibbles を出力できます。\nこのハンドブックで使用されている DT パッケージを用いて実現するには、次のようなコードチャンクを挿入します：\n\n\n\n\n\n\n\n\n\ndatatable() は、渡されたデータフレームを読者のために動的な表として出力します。rownames = FALSE を設定して、表の左端を単純化できます。filter = \"top\" は、各列にフィルタを付加します。option() 引数は、他の指定オプションを渡します。以下に 2 例を示します：pageLength = 5 は表示する行数を 5 行と指定します（残りの行は、矢印を用いてページング表示が可能です）。scrollX=TRUE は、表の最下段にスクロールバーを有効にします（列が右へ長く続く場合）。\nもしデータセットが非常に大きい場合、head() をデータフレームに用いて、先頭 X 行のみ表示することを検討してください。\n\n\nHTML ウィジェット\nR のための HTML ウィジェットは、JavaScript ライブラリを利用してインタラクティブ性を向上させる R パッケージの特別な型です。HTML R Markdown 出力にこれらを埋め込み可能です。\nこれらのウィジェットの一般的な例は下記を含みます：\n\nPlotly （本章内や、動的な図の作成 の章で使用されています）\nvisNetwork （このハンドブックの 感染連鎖の図式化 の章で使用されています）\nLeaflet （このハンドブックの GIS の基礎 の章で使用されています）\ndygraphs （時系列データのインタラクティブ表示に有用です）\nDT （datatable()）（フィルタ、ソート機能などを付加された動的な表の表示に使用されます）\n\nplotly パッケージの ggplotly() 関数は特に簡単です。動的な図の作成 の章をご覧ください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.jp.html#参考資料",
    "href": "new_pages/rmarkdown.jp.html#参考資料",
    "title": "40  R Markdown で作るレポート",
    "section": "40.10 参考資料",
    "text": "40.10 参考資料\nさらに詳しく学びたい方は、以下のウェブサイトをご覧ください。\n\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://rmarkdown.rstudio.com/articles_intro.html\n\nmarkdown と knittr, Rmarkdown についての良質な資料はこちらです。 https://stackoverflow.com/questions/40563479/relationship-between-r-markdown-knitr-pandoc-and-bookdown",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>R Markdown で作るレポート</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html",
    "href": "new_pages/reportfactory.jp.html",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "",
    "text": "41.1 準備",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#準備",
    "href": "new_pages/reportfactory.jp.html#準備",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "",
    "text": "パッケージの読み込み\nRStudio で、Github から最新版の reportfactory パッケージをインストールしましょう。\nインストールは、pacman パッケージの p_load_curreng_gh() を利用します。この関数を利用すると Github からパッケージの最新バージョンを強制的にインストールします。 関数に、“reconverse/reportfactory” という文字を引数として与えましょう。“reconverse” は Github 上の “organization”（リポジトリの所有権を持つアカウント名）を表し、“reportfactory” がパッケージのリポジトリ名を表します。 別のインストール方法としては、remotes パッケージの install_github() も利用できます。\n\n# Github からパッケージの最新版をインストールして読み込む\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # remotes パッケージを利用した別の方法はこちら",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#新規ファクトリーの作成",
    "href": "new_pages/reportfactory.jp.html#新規ファクトリーの作成",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "41.2 新規ファクトリーの作成",
    "text": "41.2 新規ファクトリーの作成\nnew_factory() を実行して、新規ファクトリーを作りましょう。実行すると、必要なものが含まれた新規 R プロジェクトフォルダが作成されます。デフォルトでは以下の動作となります。\n\n現在のワーキングフォルダに新規ファクトリー（new_factory フォルダ）が追加されます\n新規ファクトリー（new_factory フォルダ）内に “new_factory.Rproj” として新規 R プロジェクトが作成されます\nRStudio のセッションは、“new_factory.Rproj” に「移動」し、新たなセッションが開かれます\n\n\n# 以下のコマンドを実行すると現在の作業フォルダ配下に新規ファクトリー（new_factory フォルダ）が作成されます\nnew_factory()\n\n新規ファクトリー（new_facrtory フォルダ）の中には、自動的に以下のサブフォルダやファイルが作成されています。\n\n\n\n\n\n\n\n\n\n\nreport_sources フォルダ：レポートを生成する R Markdown スクリプトを保存する場所です。\noutputs フォルダ：生成されたレポートが保存される場所です。（例：HTML、Word、PDF などのファイル）\nscripts フォルダ：レポート作成時に呼び出される R スクリプトを保存する場所として利用できます。（例：R markdown スクリプトから呼び出されるスクリプトなど）\n\ndata フォルダ：データを保存する場所として利用できます。（サブフォルダとして “raw” と “clean” フォルダが含まれています）\n.here ファイル：here パッケージを使用して、サブフォルダ内のファイルを、.here ファイルが置かれているフォルダをルートフォルダとして相対的なパスを指定できます（詳細は R プロジェクトの設定 の章を参照してください）。\ngitignore ファイル：このファクトリーの R プロジェクトを Github リポジトリと関連付けた場合に備えて作成されています。（詳細は、Git と Github を使用したバージョン管理と共同作業 の章を参照してください）。\nREADME ファイル（空）：Github リポジトリを利用した場合に備えて作成されています。\n\n注意: “.here” ファイルなどのいくつかのドットで始まるファイルは、フォルダに存在していたとしてもコンピューターの設定によっては表示されない場合があります。\nnew_factory() コマンドのデフォルト設定のうち、実行時の動作を変更する引数をいくつか紹介します。\n\nfactory =： 新しく生成するファクトリーのフォルダ名を変更できます (デフォルトは “new_factory” です)\npath =：新規ファクトリーフォルダが作成されるパスを指定できます（デフォルトは現在の作業フォルダ）\nreport_sources =：レポート生成用の R Markdown スクリプトを保存するサブフォルダの名前を指定できます（デフォルトは “report_sources”）\noutputs =：生成されたレポートを保存するフォルダの名前を指定できます（デフォルトは “outputs”）\n\n全ての設定可能な引数リストは ?new_factory でヘルプファイルを参照してください。\n新規ファクトリーを作成すると、R のセッションは新しく作成された R プロジェクトに移されるので、再度 reportfactory パッケージを読み込む必要があります。\n\npacman::p_load(reportfactory)\n\nこれで準備が整いました。factory_overview() コマンドを実行すると、ファクトリーの構造（すべてのフォルダとファイル）を見ることができます。\n\nfactory_overview()            # コンソールにファクトリーフォルダのツリー構造を表示する\n\n以下の図のように、ファクトリーに含まれるフォルダとファイルが R コンソールに表示されます。“data” フォルダの中に “raw” と “clean” サブフォルダと例示用の CSV データが含まれています。また、同じく例示用の “example_report.Rmd” ファイルが “report_sources” フォルダに含まれています。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#レポートの作成",
    "href": "new_pages/reportfactory.jp.html#レポートの作成",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "41.3 レポートの作成",
    "text": "41.3 レポートの作成\nファクトリー用 R プロジェクトの中で、普段行うように R Markdown ファイルを作成して、“report_sources” フォルダに保存してみましょう。 R Markdown ファイルの作成方法は、R Markdown で作るレポートの章を参照してください。例示のため、ここでは次のようにファクトリーを変更しています。\n\n“daily_sitrep.Rmd” というファイル名の新規 R Markdown スクリプトを “report_sources” フォルダ内に保存します。（翻訳者注：ここで、sitrepとは、状況報告などを意味する英単語。“situation report” の略）\nレポート用のデータ（“linelist_cleaned.rds”）は、“data” フォルダ内の “clean” サブフォルダに保存します。\n\nfactory_overview() を実行すると、R Markdown ファイルが “report_sources” フォルダに、レポート用のデータファイルが “clean” サブフォルダに格納されています（以下の画像でのハイライト部分）。\n\n\n\n\n\n\n\n\n\n下記の画像は、R Markdown ファイル、“daily_sitrep.Rmd” の冒頭部分のスクリーンショットです。YAML ヘッダの output: html_document パラメータで、出力形式が HTML ファイルに設定されています。\n\n\n\n\n\n\n\n\n\nこの単純なスクリプトの中には以下のコマンドが記述されています。\n\n必要なパッケージを読み込むコード\nhere パッケージでファイルパスを指定して、“linelinst_cleaned.rds” データをインポートするコード（詳しくはデータのインポート・エクスポートの章を参照）\n\n\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\n\n\n症例ラインリストの要約表を表示し、export() で表を .csv ファイルとしてエクスポートするコード\n流行曲線（エピカーブ）を表示し、ggsave() で .png ファイルとしてエクスポートするコード\n\n次のコマンドで「report_sources」フォルダ内の R Markdown ファイルのリストを確認できます。\n\nlist_reports()",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#コンパイルレポートの生成",
    "href": "new_pages/reportfactory.jp.html#コンパイルレポートの生成",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "41.4 コンパイル、レポートの生成",
    "text": "41.4 コンパイル、レポートの生成\nreportfactory パッケージにおいて、R Markdown ファイルを「コンパイル」するとは、R markdown スクリプトが実行され、出力結果が作成されるという意味となります。（出力結果は、YAML ヘッダに記載されている出力形式となります。例、 HTML、Word、PDF など）\nファクトリーは、“outputs” フォルダ内に、日付とタイムスタンプ付きの出力用フォルダを自動生成します。\n出力レポート本体と、スクリプトからエクスポートされたファイル（csv、png、xlsx など）は、この自動生成されたフォルダに保存されます。さらに、R markdown スクリプトファイルそのものも、この自動生成されたフォルダに保存されます。そのため、スクリプトのバージョン履歴を管理できます。\nコンパイルによる出力生成は、R Markdown ファイルにおける、Knit して作成される通常の出力生成とは明確に異なります。Knit した場合は R markdown スクリプトが存在するフォルダに出力が保存されます。結果的に、この Knit の出力動作はフォルダが乱雑で整理されていない状態になりやすいのです。ファクトリーの目的は、頻繁にレポートを出力する必要がある場合の出力結果の整理整頓です。\n\nファイル名を指定してコンパイル\n特定のレポートをコンパイルするには、compile_reports() を実行し、reports = に R markdown スクリプト名（.Rmd 拡張子は含めない）を指定します。スクリプト名を指定する簡単な方法に、以下のように reports = を省略して、R Markdown スクリプト名を引用符（\"や'）で囲んで書く方法もあります。\n\n\n\n\n\n\n\n\n\n上記のコマンドは、“daily_sitrep.Rmd” レポートのみをコンパイルします。出力結果として HTML レポート、病院ごとの症例数の .csv、epicurve の .png 画像を、“outputs” フォルダ内のレポート専用のサブフォルダに保存します。また、保存フォルダ名にコマンド実行日付とタイムスタンプが付加されます。\nなお、スクリプト名の指定時に .Rmd 拡張子をつけた場合は、ファイル拡張子を正確に入力する必要があります（.rmd と .Rmd は別ファイルとして扱われます）。\nさらに、コンパイル時に “report_sources” フォルダにいくつかのファイルが一時的に表示されることがありますが、これらは最終出力時にあるべき “outputs” フォルダに転送されるため、すぐに消えるということに注意してください。\n\n\nリストインデックスを指定してコンパイル\nreports = に数字または数字ベクトルを指定することで、コンパイルする R markdown スクリプトを指定できます。これらの数字は list_reports() を実行した際に表示されるレポートリストのインデックスと一致している必要があります。\n\n# \"report_sources\" フォルダ内の 2 番目と 4 番目の R markdown ファイルをコンパイルする\ncompile_reports(reports = c(2, 4))\n\n\n\nすべてのファイルをコンパイルする\n“report_sources” フォルダ内の R Markdown レポートすべてをコンパイルするには、reports = 引数に TRUE を設定します。\n\n\n\n\n\n\n\n\n\n\n\nサブフォルダ内のファイルをコンパイルする\nレポートの目的ごとに “report_sources” フォルダに追加でサブフォルダを作成できます。サブフォルダ内の R markdown レポートをコンパイルするには、subfolder = 引数にサブフォルダ名を指定するだけです。下記は “report_sources” のサブフォルダ “for_partners” フォルダに存在する R markdown レポート（“summary_for_partners.Rmd”）をコンパイルするコード例です。\n\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\n\n以下のようにサブフォルダ名を reports = 引数に指定し、最後にスラッシュ（ / ）を付けることで、サブフォルダ内の全ての R markdown レポートをコンパイルできます。\n\ncompile_reports(reports = \"for_partners/\")\n\n\n\nパラメータ化\nR Markdown で作るレポート の章で述べたように、パラメータを指定してレポートを作成できます。 これらのパラメータは、引数 params = にリスト型としてまとめることで compile_reports() に渡すことができます。下記例の架空レポートでは、R Markdown スクリプトに 3 つのパラメータ（“most_recent_data”、“region”、“rates_denominator”）が指定されています。\n\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)\n\n\n\n実行ファイル（“run-file”）を利用する\n作成するレポートが複数ある場合は、各レポートに対応する compile_reports() コマンドを記述した R スクリプト（実行ファイル、“run-file”）の作成を検討してください。この R スクリプト内にレポート作成に必要なコマンドすべてを記述することで、ユーザーは実行するだけですべてのレポートをコンパイルできます。作成した実行ファイル（“run-file”）は “scripts” フォルダに保存します。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#出力結果",
    "href": "new_pages/reportfactory.jp.html#出力結果",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "41.5 出力結果",
    "text": "41.5 出力結果\n下記の画像は、何度かレポートをコンパイルした “outputs” フォルダの様子です（わかりやすくするためにハイライトを追加しています）。\n\n\n\n\n\n\n\n\n\n\n“outputs” フォルダ（緑でハイライト）の中には、“daily_sitrep”（青でハイライト）、“example_report”（黄でハイライト）、各 R markdown レポート出力用のサブフォルダが作成されています。\n各レポート出力用サブフォルダの中に、コンパイルを実行する度にタイムスタンプ付きサブフォルダが作られます。\n\nこれらのサブフォルダには、コンパイルを実行した日付と時間が記録されています (“2021-04-23_T11-07-36” は 2021 年 4 月 23 日 11 時 7 分 36 秒を表します)\n\nサブフォルダ名に付加される日付と時間のフォーマットは編集可能です。詳しくは ?compile_reports を確認してください。\n\nコンパイルで生成された各サブフォルダ内には、R markdown スクリプトの出力結果（ HTML 、PDF、Word など）と R markdown スクリプト（バージョン管理されています！）、その他のエクスポートされたファイル（table.csv、epidemic_curve.png など）が格納されます。\n\n下記の画像は、“daily_sitrep” レポートの日付と時刻のタイムスタンプが付加されたフォルダの中身です。フォルダへのファイルパスは強調のために、黄色でハイライトしています。\n\n\n\n\n\n\n\n\n\n最後に、以下のスクリーンショットに、HTML で出力されたレポートを示します。\n\n\n\n\n\n\n\n\n\n出力の一覧を確認するには、list_outputs()を使用してください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#その他",
    "href": "new_pages/reportfactory.jp.html#その他",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "41.6 その他",
    "text": "41.6 その他\n\nKnit\n必要であれば、“Knit” ボタンを押して、R Markdown レポートの 1 つを “Knit” できます。“Knit” した場合、デフォルトでは R markdown レポートが保存されている “report_sources” フォルダに出力されます。 以前のバージョンの reportfactory パッケージでは、“report_sources” に R markdown 以外のファイルがあるとコンパイルができませんでしたが、現在はそのようなことはありません。compile_reports() を実行してもエラーにはなりません。\n\n\nscripts フォルダ\n“scripts” フォルダには “runfiles”（実行ファイル）や R markdown スクリプトに読み込める .R スクリプトを格納することをお勧めします。複数のファイルにまたがるコードの構造化のためのヒントは、R Markdown で作るレポートの章をご覧ください。\n\n\n付加機能\n\nreportfactory パッケージの機能で、list_deps() 関数を使用して、全ファクトリーのレポート作成に必要なすべてのパッケージをリストアップできます。\nrfextras パッケージが開発されており、レポート作成を支援する以下のヘルパー関数が提供されています：\n\nload_scripts()：引数に指定したフォルダにある全ての .R スクリプトを実行・読み込みます（デフォルトでは scripts フォルダ）\nfind_latest()：ファイル名に日付を含んでいるファイルの最新版を探します（例：最新のデータセットなど）",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.jp.html#参考資料",
    "href": "new_pages/reportfactory.jp.html#参考資料",
    "title": "41  ルーチンで作成するレポートの整理",
    "section": "41.7 参考資料",
    "text": "41.7 参考資料\nreportfactory パッケージの Github ページ\nrfextras パッケージの Github ページ",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>ルーチンで作成するレポートの整理</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html",
    "href": "new_pages/flexdashboard.jp.html",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "",
    "text": "42.1 準備",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#準備",
    "href": "new_pages/flexdashboard.jp.html#準備",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "",
    "text": "パッケージの読み込み\nこのハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎 の章をご覧ください。\n\npacman::p_load(\n  rio,             # データのインポート・エクスポート\n  here,            # ファイルパスの指定\n  tidyverse,       # データの加工と可視化\n  flexdashboard,   # R Markdown レポートのダッシュボード版\n  shiny,           # 動的なダッシュボード、作図\n  plotly           # 動的な作図\n)\n\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、 クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください）。\n\n# linelist をインポートする\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nlinelist の最初の 50 行を以下に表示します。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#新規-r-markdown-ファイルを作成する",
    "href": "new_pages/flexdashboard.jp.html#新規-r-markdown-ファイルを作成する",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.2 新規 R Markdown ファイルを作成する",
    "text": "42.2 新規 R Markdown ファイルを作成する\nパッケージをインストールをした後、File &gt; New file &gt; R Markdown と選択して新規 R Markdown ファイルを作成してください。\n\n\n\n\n\n\n\n\n\n開いたウィンドウから “From Template” を選択して、次に、“Flex Dashboard” テンプレートを選んでください。その後、ドキュメントの名前をつけるように促されます。今回の例では、R Markdown ファイルを “outbreak_dashboard.Rmd” と命名しましょう。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#スクリプト",
    "href": "new_pages/flexdashboard.jp.html#スクリプト",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.3 スクリプト",
    "text": "42.3 スクリプト\nファイルに記述するスクリプトは、R Markdown 記法そのものです。そのため、R Markdown で作るレポート の章で解説した内容や記法と同じです。このセクションで、再度、簡単に記法を紹介し、この章で扱う R Markdown の出力形式との違いを示します。\n\nYAML ヘッダ\n記述するスクリプトの一番上には、“YAML” ヘッダがあります。YAML ヘッダは、3 本のダッシュ（---）で始め、3 本のダッシュ（---）で閉じる必要があります。YAML ヘッダのパラメータは key:values の組み合わせで記述します。YAML 記法では、半角スペースによるインデントとコロンの記述が大切です。key:value パラメータはイコール記号ではなく、コロンで分けらていることに注意が必要です。\nYAML ヘッダには文書のメタデータを記述する必要があります。YAML ヘッダに記述される（インデントされていない）パラメータの順番は重要ではありません。例えば次のような形です。\n\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\n\nインラインコードを書く（r に続いてバックティックの中に記述する）ように、YAML ヘッダの中で R コードを記述できます。また、上記 YAML ヘッダ例内の date パラメータにあるように、二重引用符中にも記述できます。\n必須の YAML ヘッダパラメータは output: です。このパラメータは、どのような種類のファイルを生成するかを指定します（例： html_document、pdf_document、word_document や powerpoint_presentation など）。flexdashboard パッケージにおいて、このパラメータの指定は少し混乱するかもしれません。output: パラメータを必ず output:flexdashboard::flex_dashboard と指定する必要があります。コロンの個数とアンダースコアに注意してください。ダッシュボード固有の追加のパラメータは YAML ヘッダ内の ouput:flexdashboard::flex_dashboard パラメータの行末に追加のコロンを入力し、その次の行から半角スペースで行頭をインデントして続くことが多いです。（具体例は、以下のコードにある orientation: と vertical_layout: のパラメータを参照してください）。\n\ntitle: \"My dashboard\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll\n\n上記に示したように、2 つの半角スペースで作られたインデントがサブパラメータの記述に利用されています。サブパラメータを追加する場合は、key:values: のように、上位となるパラメータの行末にコロンを追加で入力するのを忘れないようにしましょう。\nロジカル型値をパラメータに与える必要がある場合は、YAML ヘッダ内では小文字で記述される必要があります（true、false、null）。タイトルなど key:values 内の values の一部に、もしコロンやカッコなど記号を含む場合は values 全体を二重引用符で囲んでください。詳しくは以降のセクションで都度例示される YAML ヘッダを参照してください。\n\n\nコードチャンク\nR Markdown は複数の「チャンク（コードチャンク）」を含むことができます。複数行の R コードをチャンク内に書けて、これらのコードは通常の R スクリプトとして動作します。\nコードチャンクは、3 つのバックティックと、小文字の “r” が入った波括弧で作成され、3 つのバックティックで閉じられます。 キーボードショートカット、“Ctrl + Alt + i”（Mac では Cmd + Shift + r）、と入力するか、RStudio スクリプトエディタの上端にある “insert a new code chunk” と表示されている緑のボタンをクリックすることで新しいチャンクを作成してみてください。コードチャンクの例を以降、多数例示しています。\n\n\n本文（ナラティブテキスト）\nR コード「チャンク」の外には、本文（ナラティブテキスト）を書くことができます。R Markdown で作るレポートで解説されているように、アスタリスク（*）1 つでテキストを囲むことで斜体にできます。あるいは、アスタリスク 2 つ（**）でテキストを囲むことで強調体にできます。箇条書きや番号付き箇条書きは、改行、行頭インデント、行末にスペースが 2 つ入力された場合などで表示が変わります。\nR Markdown で作るレポート の章に記述されたように、インライン R コードはバックティック（）で囲まれたコード（``1+1` ``）の先頭に “r” をつけることで入力できます（前述した YAML ヘッダ例の date パラメータを参照してください）。\n\n\n見出し\nR Markdown で作るレポート の章で説明したように、見出しの大小はハッシュ記号の入力個数で表現されます。\nflexdashboard パッケージでは、見出し 1（#）はダッシュボードの「ページ」を作成します。見出し 2（##）は orientation: パラメータに応じてカラム（水平方向の表示枠）やロウ（垂直方向の表示枠）を作ります（詳細は下記を参照ください）。見出し 3（###）は図、表、テキストなど表示のためのパネルを作成します。\n# 見出し１ （ページ）\n\n## 見出し２ （垂直方向か水平方向に下位見出し内容を配置する）\n\n### 見出し３ （図、表などを表示するパネル）",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#セクションの属性",
    "href": "new_pages/flexdashboard.jp.html#セクションの属性",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.4 セクションの属性",
    "text": "42.4 セクションの属性\nダッシュボードの一部に適用する属性を指定するには、通常の R markdown 記法と同様に、見出しの後、波括弧 { } の中に key=value オプションを入れます。例えば、典型的な HTML の R markdown レポートでは、## My heading {.tabset} とすることで、小見出しをタブにまとめることができます。\n前段落の例では、見出しのテキスト部分の後に属性が記述されていることに注意してください。これらは、R コードチャンクの上部に入力される knitr パッケージのオプション（例えば、 out.height =）とは違います。\nflexdashboard パッケージの特徴的な属性には以下があります。\n\n{data-orientation=}：rows（ロウ：垂直方向配置）または columns（カラム：水平方向配置）のいずれかを値に設定します。ダッシュボードに複数のページがある場合は、各ページにこの属性を追加して、内容を配置する方向を指定してください (詳細は レイアウトセクション で説明しています)。\n\n{data-width=} と {data-height=}：同じ表示方向（水平方向配置または垂直方向配置）にレイアウトされたグラフ、カラム、ロウの相対的サイズを設定します。絶対的サイズは、flexbox CSS 表示エンジンによって、どのようなディスプレイデバイスでも表示範囲が最適になるように調整されます。\n\nグラフの高さは、YAML ヘッダパラメータの vertical_layout: fill と vertical_layout: scroll のどちらを設定するかにも依存します。scroll に設定した場合、グラフの高さは R コードチャンクの一般的な fig.height = オプションを反映します。\n\nサイズ指定に関する完全なドキュメントは flexdashboard パッケージの公式ウェブサイト を参照してください。\n\n{.hidden}：ページの最上段に表示されるナビゲーションバーから特定のページを除外するために利用します。\n{data-navmenu=}：ページレベルの見出し（#）に適用します。該当のページをナビゲーションバーのドロップダウン内のメニューとして表示します。 ドロップダウンメニューの名前を二重引用符で囲んで入力してください。 「レイアウト」セクション内の例をご参考ください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#layout",
    "href": "new_pages/flexdashboard.jp.html#layout",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.5 レイアウト",
    "text": "42.5 レイアウト\nこのセクションではダッシュボードのレイアウトを以下の方法で整形します。\n\nR Markdown の見出し記法（#、##、##など）を使用し、ページ、カラム・ロウ、チャートを追加する\nYAML ヘッダパラメータの orientation: を rows またはcolumns のいずれかに指定する\nブラウザの領域いっぱいにレイアウトを表示するか、スクロールさせて表示するかを指定する\n特定のセクションの見出しにタブを追加する\n\n\nページ\nR Markdown で、見出しレベル 1（#）はダッシュボードの「ページ」を意味します。デフォルトの設定では、ページは、一番上に表示されるナビゲーションバーに順番に並んで表示されます。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nページの見出しに {data-navmenu=} 属性を付けることで、ナビゲーションバー内の「メニュー」としてページをまとめることができます。等号演算子（=）の前後にスペースを入れると、うまくいきませんので、気を付けてください！\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。\n\n\n\n\n\n\n\n\n\nまた、{.sidebar} 属性を追加することで、ページやカラムをダッシュボードの左側にある「サイドバー」として表示できます。サイドバーには（どのページからも表示可能な）テキストを表示したり、shiny パッケージの動的機能を組み込んでいる場合は、スライダーやドロップダウンメニューなどのユーザ入力用コントローラを表示するのに便利です。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。\n\n\n\n\n\n\n\n\n\n\n\n内容の配置方向指定\nYAML ヘッダパラメータに orientation: を設定して、R Markdown の見出し 2（##）要素以下の内容を水平方向配置または垂直方向配置で並べるか指定します。orientation: columns（水平方向配置）または orientation: rows （垂直方向配置）のどちらかを設定しましょう。\n見出し 2（##） は、YAML ヘッダパラメータの orientation 設定に基づいて、新規カラム（水平方向配置）または新規ロウ（垂直方向配置）として解釈されます。\n例えば orientation: columns と設定すると、見出し 2 がダッシュボードのページに新規カラム（水平方向配置）として追加されます。以下の例のダッシュボードには、1 つのページ内に 2 つのカラムがあり、合計で 3 つのパネルがあります。カラムの相対的な幅は、以下のように {data-width=} 属性で調整できます。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。\n\n\n\n\n\n\n\n\n\norientation: rows を設定すると、見出し 2 はカラムの代わりに新規ロウを作成します。以下は上記と同じスクリプトですが、orientation: rows が設定されており、見出し 2 がカラムではなく ロウを生成するようになります。以下のように、{data-height=} で行の相対的な高さを調整することもできます。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。\n\n\n\n\n\n\n\n\n\nダッシュボードに複数のページがある場合、各ページのヘッダーに {data-orientation=} 属性を追加することで、各特定ページごとに配置方向を指定できます（引用符なしで rows または columns のどちらかを指定できます）。\n\n\nタブ\n他の HTML R Markdown の出力と同様に、{.tabset} 属性で表示内容をタブに分割できます。\nこの属性を必要な見出しの後に追加するだけです。その見出しの下位にある小見出しは、タブとして表示されるようになります。例えば、下記のスクリプトでは、右の “Colums 2”（##）がタブ化されており、流行曲線（エピカーブ）パネルと表パネル（見出し 3 ###）の内容がタブで表示されるようになりました。\n配置方向の設定が row であれば、垂直配置方向でも同じ分割ができます。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#表示内容を追加する",
    "href": "new_pages/flexdashboard.jp.html#表示内容を追加する",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.6 表示内容を追加する",
    "text": "42.6 表示内容を追加する\nそれでは、ダッシュボードを作り始めましょう。この章で作成するシンプルなダッシュボードは、1 ページ、2 カラム、4 パネルで構成されます。パネルをひとつひとつ組み立てながら解説します。\n表示内容には、テキスト、ggplot によるプロット、テーブルなど、R の標準的な出力を簡単に含めることができます（詳しくは、見やすい表の作り方の章を参照してください）。他の R Markdown スクリプトのように、R コードチャンク内に出力を生成するコードを追加するだけです。\n注：この章で作成する R markdown スクリプトの完成形と HTML ダッシュボードの出力をダウンロードできます。詳しくは、ハンドブックとデータのダウンロードの章をご覧ください。\n\nテキスト\nMarkdown テキストを入力し、他の R Markdown 出力のようにインラインコードを含めることができます。詳細についてはR Markdown で作るレポートの章を参照してください。\nこの章で作成するダッシュボードには、集計した結果を表示するテキストパネルが用意されています。パネル内にはアウトブレイクで報告された最新の入院日と症例数が自動的に変わるテキストを含みます。\n\n\n表\nパネルには表などを出力する R コードチャンクを含められます。この場合、テーブルを表示するために knitr パッケージの kable() 関数を使用すると、出力が最も見栄えよく見え、かつ、ウィンドウサイズに合わせて表示されます。flextable パッケージの関数を利用すると、要約表や、一部分を切り落とした表を作成できます。\n以下の例では linelist オブジェクトに count() コマンドを適用して、病院ごとの症例数の要約表を作成しています。最終的に、この要約表は knitr::kable() に渡され、ページ上では右側にスクロールバーが表示されます。kable() と kableExtra パッケージを使った表のカスタマイズについては、こちらのドキュメント を参照してください。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。\n\n\n\n\n\n\n\n\n\nもし、「ページ」内で、ユーザがデータフレームを抽出、並び変え、操作できるような動的な表を表示したい場合は、以下のコードのように、DT パッケージと datatable() 関数を使用します。\n以下のサンプルコードで、linelist データフレームが表示されます。rownames = FALSE を設定すると行番号表示を省略し、水平方向のスペースを節約できます。filter = \"top\" を設定すると、すべての列の一番上にフィルタを配置できます。その他の指定項目はリスト型にまとめて options = に渡します。以下では、options に 5 行ごとにデータフレーム内容が表示されるように pageLength = を設定し、かつ、ユーザが下部のスクロールバーを使って水平方向にスクロールできるように scrollX = を設定しています。引数 class = 'white-space: nowrap' は、各行が 1 行表示となることを保証します（各セル内で改行されません）。その他の引数や値については、 こちらを参照するか、?datatable と入力してみてください。\n\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = list(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )\n\n\n\nプロット\n通常の R スクリプトでプロットするようにダッシュボードページにプロットを表示できます。以下の例では、incidence2 パッケージを使用して、2 つの簡単なコマンドで年齢層別の「流行曲線（エピカーブ）」を作成しています（流行曲線（エピカーブ） の章を参照してください）。他にも、ggplot() を使用して、同じようにプロットを表示できます。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。\n\n\n\n\n\n\n\n\n\n\n\n動的なプロット\nまた、標準的な ggplot や他のプロットオブジェクトを plotly パッケージの ggplotly() に渡すこともできます (動的な図の作成 の章を参照してください)。この関数はプロットを動的にします。つまり、ユーザがプロットを「ズームイン」したり、すべての観測値（この例では、流行曲線（エピカーブ）中の年齢層別、週あたりの症例数）をマウスカーソルをグラフ上に置くことで表示したりできます。\n\nage_outbreak &lt;- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %&gt;% \n  plotly::ggplotly()\n\n上記スクリプトをダッシュボードで表示するとこんな感じです（gif）。この動的表示機能は、ダッシュボードを静的ファイルとして電子メールで送信しても機能します（インターネットに接続されていなくても表示可能）。\n\n\n\n\n\n\n\n\n\n\n\nHTML ウイジェット\nHTML widgets for R ウェブページには、多数の HTML ウィジェットのサンプルがあります。HTML ウィジェットはi JavaScript のライブラリを利用して動的操作性を高める R パッケージの特殊なダッシュボードパーツです。HTML ウィジェットは R Markdown 出力（flexdashboard など）や Shiny ダッシュボードに埋め込むことができます。\nHTML ウィジェットに利用できる R パッケージの一般的な使用例は、以下があります。\n\nPlotly パッケージ（この章と、本ハンドブックの動的な図の作成の章で使用されています）。\nvisNetwork パッケージ（本ハンドブックの感染連鎖の図式化の章で使用されています）。\nLeaflet パッケージ（本ハンドブックのGIS の基礎の章で使用されています。\ndygraphs パッケージ（時系列データを動的に表示するのに便利です）\nDT (datatable()) パッケージ（(フィルタ、ソートなどの機能を持つ動的なテーブルを表示するのに便利です）。\n\n以下は、visNetwork パッケージを使用した感染連鎖をダッシュボードページに追加する例です。R Markdown スクリプトの「Column 2」見出し 2 に追加する新しいコードのみを表示しています。追加するコード例の詳細は、ハンドブックの感染連鎖の図式化の章をご参照ください。\n\n\n\n\n\n\n\n\n\n上記スクリプトの実行結果です。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#コードの構造化",
    "href": "new_pages/flexdashboard.jp.html#コードの構造化",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.7 コードの構造化",
    "text": "42.7 コードの構造化\nここまでの例のようにすべてのコードを flexdashboard パッケージを利用した R Markdown スクリプト内に記述できます。また、より整理された簡潔なダッシュボード用の R スクリプトを作成するために、他の R スクリプトで管理または作成されたコード・図を呼び出せます。他の R スクリプトの呼び出しについては、R Markdown で作るレポートの章でより詳細に説明しています。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#shiny-パッケージを利用する",
    "href": "new_pages/flexdashboard.jp.html#shiny-パッケージを利用する",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.8 Shiny パッケージを利用する",
    "text": "42.8 Shiny パッケージを利用する\nR パッケージの shiny パッケージを共に用いると、ユーザの入力をより反映させるダッシュボードを作成できます。例えば、ユーザに管轄地域や日付範囲を選択（例、表示されるデータにフィルターをかけるなど）させ、選択内容に対応してグラフ表示が変化するようにできます。flexdashboard パッケージを用いた R スクリプトに shiny パッケージの柔軟性を組み込むには、スクリプトに少し変更を加えるだけです。\nflexdashboard パッケージを使わなくても、shiny パッケージを使ってアプリ・ダッシュボードを作成できます。ハンドブックのShiny で作るダッシュボードの章では、この方法について、shiny パッケージ固有の少々の構文、アプリのファイル構造、共有・配信方法の選択肢（無料の配信サーバを含む）についての概要を説明しています。構文と一般的なヒントは、flexdashboard パッケージの利用にも当てはまります。\nしかしながら、flexdashboard パッケージと shiny パッケージの機能を共に用いると、作成されるダッシュボードを根本的に変えることになります。shiny パッケージを組み込むと電子メールで送信し、誰でも開いて見ることができるような HTML 出力は生成されません。代わりに「アプリ」になります。スクリプトの上部にある「Knit」ボタンは「Run document」アイコンに置き換えられます。「Run document」アイコンを押すと、あなたのローカルコンピュータに、動的なダッシュボード（アプリ）のための配信サーバ（インスタンス）が動作しはじめます。\nshiny パッケージの機能を用いたダッシュボードを共有するには、以下のいずれかが必要となります\n\nR markdown スクリプトをユーザに送り、ユーザが自分の PC で R スクリプトを開き、アプリを実行する、または\nアプリ・ダッシュボードを、ユーザがアクセス可能な配信サーバにホストする\n\n上記のように、shiny パッケージの機能を統合することにはメリットもありますが、複雑さもあります。もし、電子メールで簡単に共有することが優先事項であり、shiny パッケージの動的機能を必要としないのであれば、「動的なプロット」セクションで例示したような ggplotly() による限定された動的機能の採用を考慮してください。\n以下では、ここまでの例で使用した “outbreak_dashboard.Rmd” を使い shiny パッケージを導入する簡単な例を紹介します。shiny を flexdashboard パッケージと共に用いるための詳細なドキュメントは、オンラインで入手可能です。\n\nshiny パッケージを利用する設定\n以下のように、YAML ヘッダに runtime: shiny パラメータを output: パラメータと同じインデントレベルで追加することで、flexdashboard パッケージと shiny パッケージの機能を共に用いることができます。\n---\ntitle: \"Outbreak dashboard (Shiny demo)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---\nユーザからの入力値を集約する入力用ウィジェットの配置に「サイドバー」を有効にすると便利です。「レイアウト」セクションで説明したように、カラム用の見出し 2 を作成し、{.sidebar} オプションを定義すると、左側にサイドバーが作成されます。このサイドバー用カラム内に shiny パッケージの input コマンドを含む、本文テキストと R コードチャンクを追加できます。\nアプリやダッシュボードが配信サーバでホストされていて、複数のユーザが同時に使用する可能性がある場合に有用な方法があります。まず、スクリプト内で最初に作成する R コードチャンクに global という名前を付けます。このコードチャンクにデータをインポート・ロードするためのコマンドを記述します。この特別な名前のコードチャンクは特別に振る舞い、チャンク中でインポートされたデータは一度だけインポートされ（繰り返されることなく）、アプリやダッシュボードにアクセスするすべてのユーザが利用できます。この設定により、アプリの起動速度が向上します。\n\n\nshiny パッケージを利用した実際の例\nこのセクションでは、flexdashboard パッケージを利用した R markdown スクリプト “outbreak_dashboard.Rmd” に shiny パッケージを追加します。追加する機能は、ユーザがドロップダウンメニューから病院を選択し、選択された病院の症例のみを反映した流行曲線（エピカーブ）を、動的なプロットとタイトルとともに表示する機能です。以下に作成概要を箇条書きにします。\n\nYAML ヘッダに runtime: shiny パラメータを追加する。\n\nスクリプトで最初に作成する R コードチャンク（セットアップチャンク）の名前を global に変更する。\nサイドバーを次の内容で作成する：\n\n個々の病院名を含むベクトルを作成するコード\n病院名を選択する selectInput() コマンド (shiny パッケージに含まれるドロップダウンメニュー)。選択内容は hospital_choice オブジェクトとして保存され、他のコードから input$hospital_choice として参照できます。\n\n流行曲線（エピカーブ）を表示するコード（Column 2、見出し 2 の下位見出し内）は renderPlot({ }) 中に記述されており、以下を含みます。\n\nlinelist オブジェクト内の hospital 変数（列）を input$hospital_choice に保存されている値に制限するフィルタ\ninput$hospital_choice` に保存されている値を反映した動的なプロットとタイトル\n\n\ninput$ に保存されている値を参照するコードは、(値に対応して表示（rendering）を変えるために) render({}) 関数の中になければならないことに注意してください。\n以下は、YAML ヘッダ、セットアップチャンク、サイドバーなどの記述を含む R markdown スクリプトの最初の部分です：\n\n\n\n\n\n\n\n\n\n以下は「Colums 2」と下位見出し、動的な流行曲線（エピカーブ）プロットのための記述です。\n\n\n\n\n\n\n\n\n\n上記を統合したダッシュボードの表示です。\n\n\n\n\n\n\n\n\n\n\n\nshiny パッケージを利用したその他の例\nshiny パッケージの動的機能と leaflet パッケージ内の地図を表示するためのウィジェット機能を使い、ダッシュボードに shiny パッケージと flexdashboard パッケージを利用した、健康関連を扱った例についてはオンラインブックGeospatial Health Data: Modeling and Visualization with R-INLA and Shiny の該当章をご覧ください。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#ユーザとの共有配信方法",
    "href": "new_pages/flexdashboard.jp.html#ユーザとの共有配信方法",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.9 ユーザとの共有、配信方法",
    "text": "42.9 ユーザとの共有、配信方法\nshiny パッケージの機能を含まないダッシュボードは、HTML ファイル（.html）を出力し、（サイズが許せば）メールで送信できます。この方法は、「ダッシュボード」をレポートとして送ることができ、ウェブサイトとしてホストするための配信サーバを用意する必要がないため、便利です。\nshiny パッケージの機能を利用した場合、出力ファイルをメールで送ることはできませんが、スクリプト自体を R ユーザに送ったり、「Shiny パッケージを利用する」セクションで説明したようにダッシュボードを配信サーバでホストすることが可能です。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.jp.html#参考資料",
    "href": "new_pages/flexdashboard.jp.html#参考資料",
    "title": "42  R Markdownで作るダッシュボード",
    "section": "42.10 参考資料",
    "text": "42.10 参考資料\nこの章で参考にした優れたチュートリアルは、以下のとおりです。これらを参考にすれば、おそらく 1 時間以内にあなた自身でダッシュボードを作成できます。\nhttps://bookdown.org/yihui/rmarkdown/dashboards.html\nhttps://rmarkdown.rstudio.com/flexdashboard/\nhttps://rmarkdown.rstudio.com/flexdashboard/using.html\nhttps://rmarkdown.rstudio.com/flexdashboard/examples.html",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>R Markdownで作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html",
    "href": "new_pages/shiny_basics.jp.html",
    "title": "43  Shiny で作るダッシュボード",
    "section": "",
    "text": "43.1 準備",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#準備",
    "href": "new_pages/shiny_basics.jp.html#準備",
    "title": "43  Shiny で作るダッシュボード",
    "section": "",
    "text": "パッケージの読み込み\nこのハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎の章をご覧ください。\nまずは、R パッケージの shiny をインストールするところからはじめていきます：\n\npacman::p_load(shiny)\n\n\n\nデータのインポート\nもしあなたがこのページのコードを理解したいのであればハンドブックとデータのダウンロードの章を見てください。そこには最終的な Shiny アプリを作成するための R のスクリプトとデータファイルへのリンクがあります。\nこれらのファイルを利用してアプリを再構築する場合は、解説の過程で作成される R のプロジェクトのフォルダ構造に注意してください（例 “data” フォルダや “funcs” フォルダ）。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#shiny-アプリの構造",
    "href": "new_pages/shiny_basics.jp.html#shiny-アプリの構造",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.2 Shiny アプリの構造",
    "text": "43.2 Shiny アプリの構造\n\n基本的なファイル構造\nshiny について理解するためには、まずアプリのファイル構造がどのように機能するかを理解する必要があります！まず、新しいディレクトリを作成する必要があります。これは、R Studioで、New Projectを選び、Shiny Web Application を選択することで簡単に作成できます。この操作で、shiny アプリの基本的な構造が作成されます。\nこのプロジェクトをひらくと、すでにapp.Rという名前の .R ファイルが作成されています。次の 2 つのうちのいずれか 1 つのファイル構造をとることが必須です：\n\napp.R、という名前の 1 つのファイルあるいは\n\n一方が ui.R でもう一方が server.R という名前の 2 つのファイル\n\nこの章では、app.R という名前をつける 1 つ目の方法を利用します。以下が例となるスクリプトです：\n\n# app.R の例\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n    # アプリのタイトル\n    titlePanel(\"My app\"),\n\n    # スライダーインプットウィジェットを含むサイドバー\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # グラフを表示する\n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n# ヒストグラムを描画するためのサーバーロジック関数を定義\nserver &lt;- function(input, output) {\n     \n     plot_1 &lt;- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot &lt;- renderPlot({\n       plot_1()\n    })\n}\n\n\n# アプリを実行する\nshinyApp(ui = ui, server = server)\n\nファイルを開くと、2 つのオブジェクトが定義されています - 1 つは ui オブジェクトで、もう 1 つは server オブジェクトです。これらのオブジェクトは全ての shiny アプリで定義する必要があり、アプリ自体の構造の中心です！実際には、上記で説明した 2 つのファイル構造間の違いは以下のみです。構造 1 では、ui オブジェクトと server オブジェクトが 1 つのファイルで定義されているのに対して、構造 2 では別々のファイルで定義されているだけです。注意：他の .R ファイルを source() 関数を利用してアプリで利用することも可能です（これは大規模なアプリでは必須となります）。\n\n\nserver オブジェクトと ui オブジェクト\n次に、実際に server オブジェクトと ui オブジェクトが何をするかを理解しなければなりません。一言でいうと、ユーザーが shiny アプリを操作するときに、常にこれら 2 つのオブジェクトが互いに作用しあいます。\nshiny アプリのユーザインタフェース（以下 UI）要素は、基本的なレベルにおいては、HTML インターフェイスを作る R のコードです。つまり、アプリの UI に表示されているものすべてを意味します。一般的には次のようなものを含みます：\n\n「ウィジェット」 - ドロップダウンメニュー、チェックボックス、スライダーなどユーザーが操作できるもの\nプロット、表など - R のコードで作成できる出力\nアプリのナビゲーションに関する要素 - タブ、ペインなど\n一般的なテキスト、ハイパーリンクなど\nHTML と CSS 要素 (後に解説します)\n\nUI において最も大切なことは、ui オブジェクトはユーザーから入力を受け取り、server オブジェクト内のロジックを生成する関数（以下、サーバーロジック関数）から受け取った出力を表示するということです。どのような時でも、ui オブジェクトの中でアクティブなコードが動くことはありません。UI における全ての変化は（多かれ少なかれ）サーバーロジック関数を経由したものです。そのため、プロットの表示やダウンロードなどの処理はサーバーロジック関数の中で実行する必要があります。\nアプリが立ち上がれば、shiny アプリのサーバーロジック関数はすべてのコードが実行される関数となります。この挙動は少し混乱しやすいです。サーバーロジック関数はユーザーが UI を操作すると効果的にreact（反応）し、それに応じてコードを実行します。もしサーバーロジック関数内でなにかが変われば、その変化は ui オブジェクトに再度渡され、その変化が表示されます。大切なことは、サーバーロジック関数内のコードが非連続的に実行される（と考えておくことが良いでしょう）という点です。 基本は、ui オブジェクトがサーバーロジック関数内のコードに影響を与えた場合は常に、自動的にサーバーロジック関数内のコードが実行されて、アウトプットオブジェクトが作成・表示されます。\nこの一連の動作は、今は難解に聞こえると思います。なので、これが実際にどのように動くかをいくつか例を体験して明快にしましょう。\n\n\nアプリを作成する前に\nアプリを作る前に、何を作りたいかを知ることはとても役立ちます。あなたが作る UI はコードで書かれるため、何か具体的なものを狙って作成しなければ、何を作っているかを可視化することができません。このような理由から、何が shiny アプリとして作れるか、沢山の例を見てアイデアを得ておくことは非常に有効です。もし、それらのアプリのソースコードを見ることができればもっと良いでしょう！この目的のための素晴らしいリソースは次のリンクにあります：\n\nRstudio アプリギャラリー\n\nどんなことができるかのイメージを持つことができれば、それをもとにどのような見た目のアプリを作りたいかを描いてみることも助けになります。 - これは、紙に書いても、絵を描くソフトを利用してもよいでしょう (PowerPoint、 MS paint、 など)。 最初のアプリは、単純なもので開始するのもよいでしょう！ネットでみつけたすごいアプリのコードをひな型として利用することを恥ずかしがる必要はありません - 全くのゼロから作ることに比べればはるかに楽に作ることができます！",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#ui-の作成",
    "href": "new_pages/shiny_basics.jp.html#ui-の作成",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.3 UI の作成",
    "text": "43.3 UI の作成\nアプリを作成する際には、最初に UI を作成した方が、何を作っているのかがわかりやすく、サーバーロジック関数のエラーでアプリがうまく動かなくなるリスクもありません。前述したように、UI を作成する際にはテンプレートを使用するのが良いでしょう。shiny アプリで利用できる標準的なレイアウトが沢山、shiny 基本パッケージに含まれています。また、shinydashboard のような拡張パッケージが沢山存在することを知っておいてもよいでしょう。まずは shiny の基本例を使って説明します。\nshiny の ui オブジェクトは、一般的に次のような順序でネスト（入れ子になった）した関数として定義されます。\n\n一般的なレイアウトを定義する関数（最も基本的なものとしては fluidPage() があるが、他にも沢山存在）\nレイアウトの中のパネル群：\n\nサイドバー関数 (sidebarPanel())\n「メイン」パネル関数 (mainPanel())\nタブ関数 (tabPanel())\n一般的な「カラム」（表示幅指定）関数 (column())\n\nウィジェット関数とアウトプット関数 - これらは入力をサーバーロジック関数に送ったり（ウィジェット関数）、出力をサーバーロジック関数から受け取ったり（アウトプット関数）する\n\nウィジェット関数は一般的には xxxInput() のような名前となっています 例 selectInput()\nアウトプット関数は一般的には xxxOutput() のような名前となっています 例 plotOutput()\n\n\n繰り返しになりますが、これらは抽象的で、可視化することは簡単ではありません、そのため、例を見るのが一番です！ マラリア施設数のデータを地区ごとに視覚化する基本的なアプリを作ってみましょう。 このデータは多くのパラメータを持っているので、エンドユーザーが自分で抽出して、年齢層や地区別にデータを見ることができれば素晴らしいです。とても単純な shiny のレイアウトを利用しましょう - サイドバーレイアウトです。これは、左側のサイドバーにウィジェットを配置し、右側にプロットを配置したレイアウトです。\nどのようなアプリにするかを計画しましょう。まずは、可視化したい地区を選択することができるセレクターからはじめましょう。次いで、別のセレクターを利用して興味のある年齢のグループ可視化します。これらの抽出条件を用いて、これらのパラメータを反映した流行曲線（エピカーブ）を表示することを目指しましょう。このために必要なのは：\n\n望む地区と興味のある年齢を選ぶことができる 2 つのドロップダウンメニュー。\n結果として出力されるエピカーブを表示する領域\n\nこれは次のようなものです:\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # 地区の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # 年齢の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # 流行曲線（エピカーブ）の描画\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\n上記の UI コードを使用して（server オブジェクト部分に何もコードがない状態で）app.R が実行されると、レイアウトは下記のようになります - プロットはサーバーロジック関数部分がないため描画されていませんが入力部分は動いていることに注意してください！\n\n\n\n\n\n\n\n\n\n入力部分は、ウィジェットがどのように機能するか説明する良い機会です。 - それぞれのウィジェットは inputId、label など各ウィジェット型に特有のオプションを設定することができます。 inputId は非常に重要です。これらは ui オブジェクトからサーバーロジック関数に情報を渡す ID として扱われます。そのため、ID は他と重複しないことが必要です。大規模なアプリの場合には、わかりやすい名前をつける努力が必要があり、ウィジェットで何を扱うのかを具体的に示す必要があります。\nそれぞれのウィジェットがどのような動作をするのかについて、完全な詳細を把握するにはドキュメント（公式文書）を注意深く読む必要があります。ウィジェットはその型に応じて、特定のデータ型をサーバーロジック関数に渡します。このデータの流れについて完全に理解しなければなりません。例えば、selectInput() は文字型をサーバーロジック関数に渡します：\n\nもし、最初のウィジェットで Spring を選択したら、それは、文字型オブジェクトである \"Spring\" をサーバーロジック関数に渡します。\nもし、ドロップダウンメニューから 2 項目を選択した場合、それらは文字型ベクトルとして渡されます（例 c(\"Spring\", \"Bolo\")）。\n\n他のウィジェットは違う型のオブジェクトをサーバーロジック関数に渡します！例えば：\n\nnumericInput() は数字型オブジェクトをサーバーロジック関数に渡します\ncheckboxInput() はロジカル型オブジェクト（TRUE か FALSE）をサーバーロジック関数に渡します\n\nまた、ここで年齢データに名前付きのベクトルを利用していることは注目に値するでしょう。 多くのウィジェットでは、名前付きベクトルを選択肢として利用すると、ベクトルの名前が選択できる表示として利用されますが、ベクトルの値がサーバーロジック関数に渡されます。つまり、誰かが “15+” をドロップダウンメニューから選択した場合、UI は\"malaria_rdt_15\" をサーバーロジック関数に渡します。これは、処理などで利用したいデータの列名そのものです！\nアプリで様々なことを行うために使用できるウィジェットがたくさんあります。 ウィジェットはアプリへのファイルのアップロードと出力のダウンロードも可能にします。基本的な shiny パッケージに含まれるウィジェットを拡張してくれる素晴らしいパッケージもあり、shinyWidgets パッケージはこのような拡張例の 1 つです。使用例を見るには次のリンクを確認してください：\n\n基礎的な shiny ウィジェットギャラリー\nshinyWidgets ギャラリー",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#アプリにデータを読み込む",
    "href": "new_pages/shiny_basics.jp.html#アプリにデータを読み込む",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.4 アプリにデータを読み込む",
    "text": "43.4 アプリにデータを読み込む\nアプリ開発の次のステップはサーバーロジック関数を動かすことです。これを実行するには、何らかのデータをアプリに入力しなければなりません。また、実行するべきすべての計算を理解する必要があります。エラーの発生している場所が明確がないことが多いため shiny アプリのデバッグは、簡単にはいきません。そのため、データの加工と可視化のコードが問題なく動くようになってからサーバーロジック関数を作り始められると理想的です。\nしたがって、ユーザーの入力に応じて変化する流行曲線（エピカーブ）を表示するアプリを作る状況では、この処理を通常の R スクリプトで実行するにはどのようなコードが必要かを考える必要があります。必要な工程は：\n\nパッケージの読み込み\nデータの読み込み\nデータの加工\nユーザーの入力に応じてデータを可視化する関数の作成\n\n上記のリストは非常にわかりやすく、それほど難しいことではないはずです。ここで重要なのは、このプロセスのうち、どの部分が一度だけ実行される必要があり、どの部分がユーザーの入力に応じて実行される必要があるのかを考えることです。なぜなら、shiny アプリは一般的には、アプリが実行される前にコードの一部分が一度だけ実行されるためです。大部分のコードをこの一度だけ実行される部分に移動することができれば、アプリのパフォーマンスが大きく改善するでしょう。この例では、データとパッケージの読み込みと基本的なデータの加工は一度の実行しか必要ありません。そのため、これらのコードをサーバーロジック関数の外に置くことができます。この変更の意味するところは、サーバーロジック関数の中に書く必要なコードは、可視化に関するコードだけということです。まず、これらの構成要素をすべてひとつのスクリプトとして開発してみましょう。ただし、今回は関数を使ってデータを可視化しているので、可視化をする関数のコードをサーバーロジック関数の外に置くことで、アプリの実行時に関数が実行環境中に存在するようにすることもできます。\n最初に、データを読み込みましょう。現在、新しいプロジェクトで作業を行っており、このプロジェクト構造を整然なままにしたいので、新しい data というディレクトリを作成してマラリアデータをそこに保存しましょう。下記のコードは、アプリの構造を整える際に最終的に削除する予定のテスト用スクリプトであり、以下のように実行します。\n\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# データの読み込み\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\nprint(malaria_data)\n\n# A tibble: 3,038 × 10\n   location_name data_date  submitted_date Province District `malaria_rdt_0-4`\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11\n 2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11\n 3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8\n 4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16\n 5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9\n 6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3\n 7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4\n 8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15\n 9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11\n10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19\n# ℹ 3,028 more rows\n# ℹ 4 more variables: `malaria_rdt_5-14` &lt;int&gt;, malaria_rdt_15 &lt;int&gt;,\n#   malaria_tot &lt;int&gt;, newid &lt;int&gt;\n\n\ntidy な形のデータを使用するほうが作業しやすいため、このデータを縦持ちのデータに変換する必要があります。年齢群が列になり、ケースも別の列になる形です。データの縦横変換の章で学んだようにこの処理は簡単にできます。\n\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)\n\n# A tibble: 12,152 × 7\n   location_name data_date  submitted_date Province District age_group       \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;           \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0-4 \n 2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5-14\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15  \n 4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot     \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0-4 \n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5-14\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15  \n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot     \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0-4 \n10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5-14\n# ℹ 12,142 more rows\n# ℹ 1 more variable: cases_reported &lt;int&gt;\n\n\nこれでデータの準備は終了しました！これで、「テスト用の R スクリプト」の項目 1、2、3 を終えたことになります。最後の、そして最も難しいタスクが、ユーザーが指定したパラメータを利用して流行曲線（エピカーブ）を描画する関数作成です。以前にもお伝えしたように、shiny を学ぶ全ての人が関数型プログラミングのセクション（関数の作成）を一読して、関数の仕組みを理解しておくことを強く推奨します！\n関数を定義する際に、どのパラメータを含めればよいか考えることは難しいかもしれません。shiny における関数型プログラミングでは、通常、全てのパラメータに対応したウィジェットが存在するので、パラメータの選択はすごく簡単です！現在取り組んでいるアプリを例にすると、地区分類でデータを絞り込めるようにしたいので、そのためのウィジェットを用意し、地区のパラメータを加え、絞り込み操作をアプリに実装しましょう。施設で絞り込む機能は（現状では）ないので、施設をパラメータとして追加する必要はありません。次の 3 つのパラメータを含む関数を作るところからはじめましょう！\n\n基となるデータセット\n選ばれた地区\n選ばれた年齢区分\n\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # データが残っていなければ NULL を返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # データが残っていなければ NULL を返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\n上記の関数の処理は比較的単純なため、関数の詳細な解説には踏み込みません。一点だけ注意することとしては、エラーを発生させないために NULL を返すことで対応しているということです。これは、shiny サーバーロジック関数がグラフオブジェクトではなくて NULL オブジェクトを生成すると UI には何も表示されないからです！この処理を行わなければアプリは頻繁に動きを止めてしまうため、この処理を入れることは大切です。\n追加で注意するべき点としては、district（地区選択）の入力を評価する場合の%in% 演算子の利用です。前述の通り、地区選択の入力は複数の値を含む文字型ベクトルとなる可能性があります。そのため、%in% 演算子の方が、== 演算子より柔軟に対応できます。\nそれでは、関数をテストしてみましょう！\n\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n\n\n\n\n\n\n\n\n関数がうまく動作した後は、関数で実現した機能がどのようにして shiny アプリに組み込まれていくのかを理解する必要があります。「スタートアップコード」（訳者注：サーバーロジック関数の外にコードをおいて実行を1回だけに制限する）の概念を前述しました。この概念をここではどのように実際にアプリに組み込むのかを見ていきましょう。スタートアップコードを実装する方法は二通りあります！\n\nスタートアップコードをapp.Rファイルの一番最初（UI の前）に記述する、か\nアプリのディレクトリに global.R という名前の新しいファイルをおいて、スタートアップコードをそのファイルの中に記述する\n\n特筆すべき点としては、一般的に大規模なアプリでは 2 番目の方法をとると管理がよりかんたんになります。2 番目の方法は、簡単にファイル構造をシンプルな方法で分割することができるからです。それでは、ここでは global.R スクリプトを完成させてみましょう。次のような形になるはずです：\n\n# global.R スクリプト\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n# データの読み込み\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\n# データを前処理し縦持ちデータへ変換する\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# グラフ描画をする関数を定義する\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # グラフのタイトルを作成する\n  if (!(\"All\" %in% district)) {            \n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # データが残っていなければNULLを返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # 年齢群で抽出する\n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # データが残っていなければNULLを返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\n簡単ですね！shiny の良い点の 1 つは、app.R、servver.R、ui.R、global.Rと名前がついたファイルを認識してくれることです。そのため、これらのファイルを紐付けるためのコードを一切書く必要がありません。上記のコードを global.R に直接記載しておくだけで、アプリの開始時に自動的に実行されます！\nまた、アプリの構成はグラフの描画をする関数を別の独自のファイルに移動させると改善します。これは、アプリが大規模になると非常に役立ちます。関数を別のファイルに分けるには、funcs という名前の別のディレクトリを作成して plot_epicurve.R という名前のファイルを作成してそこに関数を保存します。その後、global.R から次のコードを利用して関数を読み込みましょう。\n\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)\n\n注：shiny アプリでは常に local = TRUE と設定しなくてはなりません。なぜなら、サーバーマシン上にアプリを公開した際 source() 関数の動作に影響を及ぼすからです。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#アプリのサーバーロジック関数を作成する",
    "href": "new_pages/shiny_basics.jp.html#アプリのサーバーロジック関数を作成する",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.5 アプリのサーバーロジック関数を作成する",
    "text": "43.5 アプリのサーバーロジック関数を作成する\n大半のコードが出来上がったので、残りはサーバーロジック関数を作るだけです。この関数はアプリの最後のパーツです。そして最も理解することが難しいでしょう。サーバーロジック関数は大規模な R の関数ですが、小さな関数の集合、あるいは、アプリの機能の集合体であると考えると理解しやすいかもしれません。サーバーロジック関数に含まれる関数が第 1 行から順番に実行されるわけではないということを理解することが大切です。それら関数群には実行される順番はありますが、shiny アプリにおいていつ実行が開始されるかを完全に理解する必要はありません。とても基本的な理解としては、タスクあるいは関数は、開発者が特別にデフォルトと異なる設定を行った状況を除き、それら関数に影響を与えるインプットオブジェクトに何か変更が加えられた時に動き始めます。繰り返しになりますが、この説明は非常に抽象的ですが、とりあえず基本的な 3つの shiny オブジェクトを解説していきましょう。\n\nリアクティブソース - これはユーザーインプットの別の呼び方です。shiny サーバーロジック関数は作成したウィジェットを通じて ui オブジェクト内の出力値を受け取ることができます。ui オブジェクトの値が変更されるたびに、変更された値がサーバーロジック関数に渡されます。\nリアクティブコンダクター - これは shiny サーバーロジック関数の中にのみ定義される関数です。単純なアプリでは必要ではありませんが、サーバーロジック関数内のみで参照可能な他の処理で利用されるオブジェクトを作成します。一般的にはリアクティブコンダクターはリアクティブソース（textInput や sliderInput など）に依存します。\nエンドポイント - これはサーバーロジック関数から ui オブジェクトに渡されるアウトプットオブジェクトです。この章で作成しているアプリの例では、流行曲線（エピカーブ）が該当します。\n\nこれらのオブジェクトを念頭に置いて、サーバーロジック関数を順番に作成していきましょう。参考のためにもう一度 ui オブジェクトのコードを表示しておきます：\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # 地区の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # 年齢の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # 流行曲線（エピカーブ）の描画\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nこの ui オブジェクトのコードは次のものを含みます：\n\nインプットオブジェクト 2 つ:\n\n地区の選択用インプットウィジェット（select_district という inputId）\n年齢の選択用インプットウィジェット（select_agegroupという inputId）\n\nアウトプットオブジェクト 1 つ:\n\n流行曲線（エピカーブ）（malaria_epicurveというoutputId）\n\n\n以前ものべたように、インプットオブジェクトとアウトプットオブジェクトに設定したユニークな（重複がない）名前（inputId と outputId）が欠かせません。これらは、ユニークである必要があり、ui オブジェクトとサーバーロジック関数の間の情報のやり取りに利用されます。サーバーロジック関数の中では、input$inputID という構文でインプットオブジェクトを参照することができ、output$outputID という構文にアウトプットオブジェクトに出力を渡すことができます。このことを理解することは難しいので、まずは例を見てみましょう！\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}\n\n今回のような単純なアプリのサーバーロジック関数の内容は非常にわかりやすいです！サーバーロジック関数は 3 つの引数 - input、output、session をもつ関数であることに気づくでしょう -（現時点ではこれらの引数そのものについて理解することはそれほど重要ではありませんが、これらを関数の引数として設定することは大切です！）今回のサーバーロジック関数のタスクは 1 つしかありません。そのタスクとは、サーバーロジック関数の input 引数を先に作成したグラフ描画関数に渡してグラフを描画することです。インプットオブジェクトとアウトプットオブジェクトの名前が ui オブジェクトで設定した名前と完全に一致していることに注意してください。\nサーバーロジック関数がユーザーの入力をどのように反映するかの基本を理解するためには、以下に注意してくだい。インプットオブジェクトの変化をアウトプットオブジェクトは（基礎となる shiny パッケージを通じて）認識します。アウトプットオブジェクトはインプットオブジェクトが変化するたびに、サーバーロジック関数を再実行しグラフを作成します。上記コードでは、renderPlot() 関数も使用していることに注意してください。この関数は、グラフオブジェクトを ui オブジェクトのアウトプット関数に渡す型指定関数群の 1 種です。似たような動作をする関数はいくつかありますが、使用する関数が ui オブジェクトに渡すオブジェクトの型と一致していることを確認する必要があります。例えば：\n\nrenderText() - ui オブジェクトにテキストを送る\nrenderDataTable - ui オブジェクトに動的なテーブルを送る。\n\nこれらは、UI で使用されるアウトプット関数と一致する必要があることを覚えておいてください。つまり、renderPlot() は plotOutput() と対になり、renderText() は textOutput() と対になります。\nやっとちゃんと機能するアプリをつくることができました！ Rstudio のスクリプトウィンドウの右上にある Run App ボタンを押して実行することができます。 また、アプリを（Rstudio ではなく）デフォルトのブラウザで実行するように選択することもできます。ブラウザで実行することで他の人にどのように見えるかがより正確に反映されます。\n\n\n\n\n\n\n\n\n\nR コンソールでは、アプリが「反応を待っている」状態になっているのが楽しいですね。なにか入力してみましょう！",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#もっと沢山の機能を追加する",
    "href": "new_pages/shiny_basics.jp.html#もっと沢山の機能を追加する",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.6 もっと沢山の機能を追加する",
    "text": "43.6 もっと沢山の機能を追加する\nこの時点で、ようやくアプリが動き出しましたが、機能はほとんどありません。また、shiny ができることのほんの一部しか知ることができていません。まだまだ学ぶことはたくさんあります！このアプリに、さらに機能を追加していきましょう。追加すると良い機能は次のようなものです：\n\nいくつかの説明文\nグラフをダウンロードするためのボタン - これにより、ユーザーにアプリで生成した画像の高画質版を提供します\n特定の施設を指定できるインプットウィジェット\nダッシュボードの追加ページ - ここにはデータの表を掲載しましょう\n\n追加することはたくさんありますが、これを通して shiny の様々な機能を学ぶことができます。shiny について学ぶことは本当に沢山あります（shiny アプリは非常に高度なものになる可能性もありますが、アプリ開発者がパッケージの使い方について理解を深めれば、より快適に外部の学習ソースを使用できるようになると期待しています。).\n\n静的なテキストの追加\nまず、shiny アプリに静的なテキストを追加することについて考えましょう。基本的な知識を一度身につければ、アプリに静的なテキストを追加することはものすごく簡単です。静的なテキストは shiny アプリの中で変化しないため、一般的には静的なテキストはアプリの UI に記載されます（もし、テキストの内容を変化させたければ、テキストレンダリング関数をサーバーロジック関数内で利用しましょう）。ここでは詳しく説明しませんが、R を HTML や css と連携させることで、UI に様々な要素を追加することができます（カスタム要素の追加も可能です）。\nHTML や css は、ユーザーインターフェイスのデザインに明示的に関わる言語です。これらを深く理解する必要はありませんが、HTML は UI のオブジェクト（テキストボックスやテーブルなど）を作成し、css は一般的にそれらのオブジェクトのスタイルや見た目を変更するために使用されます。shiny は膨大な数の HTML タグにアクセスできます。これらは、ヘッダー、テキストの段落、改行、テーブルなど、特定の方法で振る舞うオブジェクトとして存在します。これらは、次のように利用できます：\n\nh1() - これは見出しのタグです。これにより囲まれたテキストが自動的に大きくなり、フォントフェイスや色などのデフォルトが変更されます（アプリの全体的なテーマに応じて変更されます）。h2()から h6()までどんどん副見出しを小さくしていくこともできます。使用例は下記です：\n\nh1(\"ヘッダー - セクション 1\")\n\np() - これは、段落のタグです。これは、囲まれたテキストを、テキスト本文と同様にするものです。このテキストは自動的に折り返され、比較的小さなサイズで表示されます（フッターは、もっと小さいかもしれません）。word 文書のテキスト本文のようなものだと思ってください。使用例は下記:\n\np(\"これは、私が自分のアプリの機能を説明するためのテキストです。\")\n\ntags$b() と tags$i() - これらはテキストが中に記載された場合に、太字 tags$b() や斜体 tags$i() で表現されます。\ntags\\(ul()`、`tags\\)ol()、tags\\(li()` - これらは、&lt;u&gt;リスト&lt;/u&gt;を作成する際に使用されるタグです。 これらはすべて以下の構文で使用され、ユーザーは順序付きのリスト（`tags\\)ol()； 数字がふられている）か、順序なしのリスト（tags\\(ul()`、中点がつけられている)を作成できます。tags\\)li()`は、どちらのタイプのリストであっても、リスト内の項目を表すのに使われます。 例：\n\n\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\n\n\nbr() と hr() - これらのタグは、改行と水平線 (改行あり)を作成します。アプリやテキストのセクションを区切るのに使いましょう！これらのタグにアイテムを渡す必要はありません（括弧は空のままでかまいません）。\ndiv() -これは、何でも含むことができる汎用のタグで、好きな名前にすることができます。UI の設計が進むと、これらを利用して UI を区分けしたり、特定のセクションに特定のスタイルを与えたり、サーバーと UI 要素の間に相互作用を持たせたりすることができます。 詳細は省きますが、知っておいて損はありません！\n\nなお、これらのオブジェクトはすべて、tags$... でアクセスできますし、いくつかは関数として呼び出すだけでアクセスできるものもあります。両者は事実上、同じ挙動ですが、誤って関数を上書きしないようにしたい場合には、より明確に tags$... スタイルを使用するとよいでしょう。また、これは利用可能なタグのすべてを網羅しているわけではありません。shiny で利用可能なすべてのタグの完全なリストは ここにあり、また、HTML を直接 UI に挿入することで、さらに多くのタグを利用することもできます！\n自信のある方は、HTMLタグの style 引数に、任意の css スタイリング要素を追加することもできます。この仕組みについては詳しく説明しませんが、UI の視覚的特性をテストするためのヒントとして、chrome（あるいは、ブラウザで実行している shiny アプリ）の HTML インスペクタモードを使用して、オブジェクトのスタイルを自分で編集するという方法があります！\nアプリにテキストを追加してみましょう\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # 地域の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # 年齢の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # 流行曲線（エピカーブ）の描画\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)\n\n\n\n\n\n\n\n\n\n\n\n\nリンクの追加\nハイパーリンクを貼るには、tags$a() に URL リンクとリンクテキストを入れて、以下のように使います。独立した段落を表示するにはp()の中に記載します。文章中の語句をハイパーリンクとして表示させたい場合は、ハイパーリンクとなる部分に tags$a() を使用します。ハイパーリンクを新しいブラウザウィンドウで開くようにするには、引数として target = \"_blank\" を追加してください。\n\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")\n\n\n\nダウンロードボタンを追加する\nそれでは、3つの機能のうち2つ目の機能を紹介しましょう。ダウンロードボタンは、アプリに追加するものとしてはかなり一般的なもので、簡単に作ることができます。ui オブジェクトに別のインプットウィジェットを追加し、サーバーロジック関数に別のアウトプットオブジェクトを追加してウィジェットと結合する必要があります。また、この例では、リアクティブコンダクターを追加します。\nまずは ui オブジェクトを更新しましょう。shiny には downloadButton() というウィジェット関数があるためこの作業は簡単です。このウィジェット関数に inputId とラベルを追加しましょう。\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # 地域の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # 年齢の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # 水平線\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # 流行曲線（エピカーブ）の描画\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nhr() タグを追加したことに注意してください。これは、ダウンロードウィジェットと入力値を操作するウィジェットの間に水平線を追加します。このタグも、先に紹介した HTML タグの 1 つです。\nui オブジェクトが準備できたので、サーバーロジック関数に要素を追加しなければなりません。ダウンロードは、サーバーロジック関数内の downloadHandler() 関数を利用して行われます。グラフの出力と同様に、ダウンロードボタンと同じ inputId をもつアウトプットオブジェクトに割り当てなければなりません。この関数は引数を 2 つ必要とします。filename と content です。これら 2 つとも関数として指定します。推測することが可能かもしれませんが、filename はダウンロードするファイルの名前を指定し、content は何をダウンロードするかを指定します。content はローカル環境に保存するデータを含みます。そのため、csv ファイルをダウンロードする場合は、rio::export() を利用します。ここでは、グラフをダウンロードするので、ggplot2::ggsave()を利用します。これをどのように実装するか見ていきましょう（サーバーロジック関数にはまだ追加しません）。\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nなお、content 関数は常に file という引数を取り、出力するファイルを指定された場所に保存します。また、上記コード内では重複があることに気づいたかもしれません。plot_epicurve() 関数をサーバーロジック関数内で、ダウンロードのためと描画のために 2 回利用しています。このことはアプリのパフォーマンスを劇的に低下させるようなことはありませんが、ユーザーが地区と年齢の設定をインプットウィジェットから変更した場合、および、プロットをダウンロードをした場合にコードが実行されてしまいます。大規模なアプリでは、このような最適されていないコードが繰り返されることで、ますますアプリ全体が重くなっていきます。そのため、パフォーマンスの観点からアプリをより効率化する方法を学んでおくことが推奨されます。効率化する方法をより理解しやすく言い換えるとすると、地区／年齢が変更されたときに流行曲線（エピカーブ）を描画するコードを実行させて、 renderPlot() と downloadHandler() 関数にその結果を利用させるということです。ここで、リアクティブコンダクターが登場します！\nリアクティブコンダクターは shiny サーバーロジック関数内にありユーザインプットに対応して反応的に生成される、出力はされないオブジェクトです。サーバーロジック関数内の別の部分で利用されるだけです。リアクティブコンダクターには沢山の種類がありますが、ここでは、基本となる 2 種類だけを見ていきます。\n1.reactive() - これが最も基本的なリアクティブコンダクターです。内部で使用されるインプットオブジェクトが変更されるたびに反応します（今作成しているアプリでの例では地区／年齢を指定するインプットウィジェットです）。\n2. eventReactive()- これは reactive() と同様な機能をもつリアクティブコンダクターです。違う点は、どのインプットオブジェクトがこのリアクティブコンダクターを反応させるかをユーザが指定できるという点です。これは、リアクティブコンダクターの処理に時間がかかるような場合に便利ですが、後で詳しく説明します。\n2 つの例をみてみましょう：\n\nmalaria_plot_r &lt;- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# 地区の選択が変更されたときにのみ実行\nmalaria_plot_er &lt;- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\neventReactive() を使う場合、どのインプットオブジェクトがこの関数内のコードを実行させるかを指定できます。今の状況ではそれほど便利ではないので、置いておきましょう。注：c() を利用して複数のインプットオブジェクトを指定することもできます。\nこの機能をサーバーロジック関数内に組み込む方法を見てみましょう：\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nダウンロード関数とプロットレンダリング関数の両方で reactive 関数で定義したアウトプットオブジェクトを呼び出しているだけであることがわかります。注意しなければならない、多くの人が引っかかるのが、 reactive 関数のアウトプットオブジェクトの使い方で、関数のように利用しなければならないということです。呼び出すには、空のカッコを最後につけることが必須です（例：malaria_plot()は正しく、malaria_plot は間違いです）。この部分を追加したことで、アプリは少し整理され、速くなり、epicurve 関数を実行するすべてのコードが 1 つの場所にあるため、変更も容易になりました。\n\n\n\n\n\n\n\n\n\n\n\n施設の選択を追加する\n次の機能に進みましょう。施設を選択するためのセレクターウィジェットの追加です。plot_epicurve 関数が、施設を選択した結果を受け取ることができるように、別の引数をとれるように実装していきます。これは、他の引数で実装したことを繰り返せばよいです。コードを更新して、テストしてみましょう。\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # データが残っていなければNULLを返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # データが残っていなければNULLを返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data &lt;- data %&gt;%\n      filter(location_name == facility)\n    \n    plot_title_facility &lt;- facility\n    \n  } else {\n    \n    plot_title_facility &lt;- \"all facilities\"\n    \n  }\n  \n  # データが残っていなければNULLを返す\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\n試して見ましょう：\n\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\n\n\n\n\n\n\n\n\n全ての施設がデータに含まれているため、どの地区にどの施設が含まれているかは明確ではなく、エンドユーザーにも同様にもわかりません。これでは、アプリの使い勝手が悪くなってしまうかもしれません。そのため、エンドユーザーが地区を選択すると、施設の UI の内容が動的に変化するようにするべきです！ウィジェット関数のオプションで使用する変数が多いので、global.R ファイルで ui オブジェクト内のオプションの一部をデータから生成することもできます。例えば、次のようなコードを global.R ファイルのデータ読み込み箇所の後に追加してもよいでしよう：\n\nall_districts &lt;- c(\"All\", unique(malaria_data$District))\n\n# 地区毎の施設名\nfacility_list &lt;- malaria_data %&gt;%\n  group_by(location_name, District) %&gt;%\n  summarise() %&gt;% \n  ungroup()\n\n変数の内容を確認してみましょう：\n\nall_districts\n\n[1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\n\n\n\nfacility_list\n\n# A tibble: 65 × 2\n   location_name District\n   &lt;chr&gt;         &lt;chr&gt;   \n 1 Facility 1    Spring  \n 2 Facility 10   Bolo    \n 3 Facility 11   Spring  \n 4 Facility 12   Dingo   \n 5 Facility 13   Bolo    \n 6 Facility 14   Dingo   \n 7 Facility 15   Barnard \n 8 Facility 16   Barnard \n 9 Facility 17   Barnard \n10 Facility 18   Bolo    \n# ℹ 55 more rows\n\n\nこの新しい変数は、サーバーロジック関数と ui オブジェクトから見える状態となっているため、ui オブジェクトに特に問題なく渡すことができます。UI も更新しておきましょう：\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # 地区の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # 年齢の選択用インプットウィジェット\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # 施設の選択用インプットウィジェット\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # 水平線\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # 流行曲線（エピカーブ）の表示\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\n選択肢を ui オブジェクトの中に直接記載（ハードコーディング）するのではなく、変数を利用して指定していることに注目してください。これにより、コードもよりコンパクトになる可能性があります。最後に、サーバーロジック関数を更新しましょう。新しいインプットオブジェクトを組み込むように関数を更新するのは簡単ですが（新しい引数として渡すだけです）、ユーザーが選択した地区を変更したときに UI を動的に更新することも忘れてはなりません。ここで理解していただきたいのは、アプリの実行中にウィジェットのインプットオブジェクトの値や動作を更新することはできますが、この更新のためのコードはサーバーロジック関数の中で実行する必要があります。この方法を学ぶためには、サーバーロジック関数に出力する新しい方法を理解する必要があります。\nこの方法を理解するために必要な関数は、observer 関数と呼ばれ、その振る舞いは reactive 関数と似ています。しかし、この 2 つには重要な違いが 1 つあります。\n\nreactive 関数は出力に直接影響を与えず、サーバーロジック関数内の他の場所で呼び出すことができるオブジェクトを生成します\nobserver 関数は サーバーロジック関数のアウトプットオブジェクトに影響を与えることができますが、それは他の関数の副作用によって行われます（他のこともできますが、実際にはこれが主な機能です）\n\nreactive 関数と同様に、observer 関数にも 2 つの種類があり、reacive 関数と同じ仕組みで分けられています。\n\nobserve() - この関数は、内部で使用されているインプットオブジェクトが変化するたびに実行されます。\nobserveEvent() - この関数は設定されたインプットオブジェクト が変化する度に実行されます。\n\nshiny で提供されているインプットウィジェットを更新する関数についての理解も必要です。これらの関数は、かなり簡単に実行できます。サーバーロジック関数の session オブジェクト（今は理解できなくても問題ありません）を 1 つ目の引数としてとしてとり、2 つ目に変更したい ui オブジェクトの inputId をとります。 3 つ目に、更新する基となるウィジェット selectInput() 関数によってすでに取得されている選択肢すべてを持つ新規のインプットオブジェクトを渡します。以上により、ウィジェットは自動的に更新されます。\nこの機能をサーバーロジック関数内で使用する場合の例を見てみましょう。エンドユーザーが地区を変更した場合、施設の一覧を地区別に抽出し、選択肢をその地区で利用可能なものだけとするように更新します（すべての施設を選択することもできます）。\n\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices &lt;- facility_list$location_name\n  } else {\n    new_choices &lt;- facility_list %&gt;%\n      filter(District == input$select_district) %&gt;%\n      pull(location_name)\n  }\n  \n  new_choices &lt;- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\n\n完成しました！上記コードをサーバーロジック関数内に足すと、動作します。新しいサーバーロジック関数は次のようになっているはずです：\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}\n\n\n\n\n\n\n\n\n\n\n\n\n表を含んだタブを追加する\n次に、アプリに追加したい最後の要素に移りましょう。 アプリの UI を 2 つのタブに分割します。1 つのタブには流行曲線（エピカーブ）を描画しているデータを動的に確認することができる表を挿入します。そのためには、shiny に付属するパッケージ化されたタブに関連した UI 要素を利用します。基本的には、下記の一般的な UI 構造の中に、メインパネルのほとんどを収めることができます。\n\n# ... は残りの ui オブジェクト部分を表す\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\n\nこの構造を今作成している ui オブジェクトに当てはめましょう。また、ここでは DT パッケージを使用します。 - これは、既存のデータから動的な表を作成するための素晴らしいパッケージです。この例では、DT::datatableOutput() で使用されているのを確認することができます。\n\nui &lt;- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # 地区の選択用インプットウィジェット\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # 年齢の選択用インプットウィジェット\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # 施設の選択用インプットウィジェット\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # 水平線\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\n\n以上で、アプリにタブが追加されました！サーバーロジック関数にも必要な編集を加えてみましょう。表としてレンダリングする前にデータを加工する必要がないので、これは非常に簡単です。malaria_data データを DT::renderDT() 経由で ui オブジェクトに描画するだけです！\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # データテーブルを ui オブジェクトに描画する\n  output$raw_data &lt;- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#shiny-アプリの共有",
    "href": "new_pages/shiny_basics.jp.html#shiny-アプリの共有",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.7 shiny アプリの共有",
    "text": "43.7 shiny アプリの共有\nアプリが完成したら、他の人と共有したいと思うこともあるでしょう。これが shiny の最大の利点です。そのためには、コードを直接共有することもできますし、サーバーマシン上で公開することもできます。コードを共有すれば、他の人があなたの実装した内容を見て、それに基づいてさらなる機能を構築することができますが、これは shiny の主な利点の1つを否定することになります。どういうことかというと、shiny は、エンドユーザーが R のインストールを行いメンテナンスする必要性をなくすことができます。このため、 R が苦手なユーザーとアプリを共有する場合は、サーバーマシン上で公開するアプリを共有する方がはるかに簡単です。\nもし、コードを直接共有したいのであれば、アプリの .zip ファイルを作成するか、あるいは、github にアプリを公開して、協力者を追加することもできます。 詳細はこちらの github のセクションを参照してください。\nしかし、アプリをオンラインで公開する場合は、もう少し作業が必要です。最終的には、あなたのアプリをウェブ URL からアクセスできるようにして、他の人が素早く簡単に到達できるようにしたいのです。残念ながら、アプリをサーバーマシン上で公開するには、公開するためのサーバーマシンが必要です！これに関しては、いくつかのホスティングするための選択肢があります。\n\nshinyapps.io：ここは shiny アプリを公開するのに最も簡単な場所です。設定は最小限です。無料でも利用できますが、いくつかの制限があります。\nRStudio Connect：これは、R サーバーのはるかに強力なバージョンで、shiny アプリの公開を含む多くの操作を行うことができます。しかし、使い方が難しく、初めての方にはあまりお勧めできません。\n\n本書では、初めての方でも利用しやすいように、shinyapps.io を使用します。無料のアカウントを作成してスタートすることもできますし、また、必要に応じてサーバーライセンスの追加などの料金プランもあります。利用するユーザー数が増えれば増えるほど、料金プランも高額になる可能性があるため、ご注意ください。少人数が使用するアプリを作りたい場合は、無料のライセンスが最適かもしれませんが、一般公開するアプリの場合はより高額のライセンスが必要になるかもしれません。\nまず、アプリがサーバーマシン上での公開に適していることを確認します。R セッションを再起動して、不要なコードが実行されずにアプリが起動することを確認してください。アプリのコードで定義されていないパッケージの読み込みやデータの読み取みをアプリが必要とする場合、サーバーマシン上では実行されないため、この確認は非常に重要です。また、アプリ内では明示的なファイルパスを使えないことにも注意してください。サーバーマシン上の環境で、ファイルパスはエラーの原因になります。here パッケージを使用することで、この問題は非常にうまく解決されます。最後に、会社のサーバーマシンなど、ユーザー認証を必要とするデータソースからデータを読み取る場合は、一般的にサーバーマシン上でアプリは動作しません。shiny サーバーをホワイトリストに登録する方法については、IT 部門と相談する必要があります。\nアカウントへのサインアップ\nアカウントを取得したら、Accounts 内にある tokens のページに移動します。このページでは、新しいトークンを追加します。トークンは、アプリのデプロイに使用されます。\nここからの作業で、アカウントのURLにアプリの名前が反映されることに注意してください。つまり、アプリの名前が「my app」であれば、URLは「xxx.io/my_app/」となります。アプリの名前は賢く選びましょう！全ての準備が完了です。deploy をクリックしましょう。成功していれば、選んだ URL でアプリが実行されているはずです。\nこのハンドブックでアプリ作成に関する何か？",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#参考資料",
    "href": "new_pages/shiny_basics.jp.html#参考資料",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.8 参考資料",
    "text": "43.8 参考資料\nここまでは、shiny の様々な側面を紹介してきましたが、shiny の機能の「さわり」に触れただけです。このガイドは入門編ですが、shiny を完全に理解するためには、さらに多くのことを学ぶ必要があります。アプリを作り始めて、徐々に機能を増やしていくのが良いでしょう。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#推奨される機能拡張パッケージ",
    "href": "new_pages/shiny_basics.jp.html#推奨される機能拡張パッケージ",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.9 推奨される機能拡張パッケージ",
    "text": "43.9 推奨される機能拡張パッケージ\n以下に、shiny の機能を拡張できる高品質なパッケージを集めました。順不同：\n\nshinyWidgets - このパッケージは、アプリで使用できるウィジェットを多数追加します。shinyWidgets::shinyWidgetsGallery()を実行すると、このパッケージで利用可能なウィジェットのセレクションが表示されます。 例は ここにあります。\nshinyjs - これは、javascript を利用することで shiny の実用性を大幅に向上させることができる優れたパッケージです。このパッケージの用途は非常にシンプルなものから高度なものまで様々ですが、まずは要素の非表示/表示、ボタンの有効化/無効化など、簡単な方法で UI を操作するために使ってみてはいかがでしょうか。ここにより沢山の例があります。\nshinydashboard - このパッケージは、shiny で使用可能な UI を大幅に拡張し、特に、様々な複雑なレイアウトのダッシュボードを作成できるようにします。ここに詳細があります。\nshinydashboardPlus - Shinydashboard フレームワークの機能をさらに充実させます！ ここで詳しく内容を確認できます。\nshinythemes - 豊富なプリセットテンプレートを利用して、shiny アプリのデフォルト css テーマを変更できます。 詳細はここ\n\nshiny に対応した動的な出力を作成するために使用できるパッケージも多数あります。\n\nDT は base-shiny に半統合されていますが、動的なテーブルを作成するための素晴らしい関数群を提供しています。\nplotly は、ユーザーがアプリ内で操作できる動的なグラフを作成するためのパッケージです。 また、plotly::ggplotly() を使って、プロットを動的なバージョンに変換することもできます！dygraphs と highcharter も同様に優れています。",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.jp.html#推奨されるリソース",
    "href": "new_pages/shiny_basics.jp.html#推奨されるリソース",
    "title": "43  Shiny で作るダッシュボード",
    "section": "43.10 推奨されるリソース",
    "text": "43.10 推奨されるリソース",
    "crumbs": [
      "レポートとダッシュボード",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Shiny で作るダッシュボード</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html",
    "href": "new_pages/writing_functions.jp.html",
    "title": "44  関数の作成",
    "section": "",
    "text": "44.1 準備",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#準備",
    "href": "new_pages/writing_functions.jp.html#準備",
    "title": "44  関数の作成",
    "section": "",
    "text": "パッケージの読み込み\n以下のコードは、分析に必要なパッケージの読み込みを行います。このハンドブックでは、パッケージを読み込むために、pacman パッケージの p_load() を主に使用しています。p_load() は、必要に応じてパッケージをインストールし、現在の R セッションで使用するためにパッケージを読み込む関数です。また、すでにインストールされたパッケージは、R の基本パッケージである base （以下、base R）の library() を使用して読み込むこともできます。R のパッケージに関する詳細は R の基礎の章をご覧ください。\n\n\nデータのインポート\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。データをダウンロードし同じように行いたい場合、ハンドブックとデータのダウンロードの章をご覧ください。データは rio パッケージの import() を利用してインポートしましょう。データをインポートする様々な方法については インポートとエクスポートの章をご覧ください。\nまた、この章の最後では、2013年のH7N9インフルエンザのデータを使用します。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#関数",
    "href": "new_pages/writing_functions.jp.html#関数",
    "title": "44  関数の作成",
    "section": "44.2 関数",
    "text": "44.2 関数\n関数はコードを理解しやすく、短く、エラーを起こしにくくすることができるため、プログラミングにおいて役立ちます(関数自体にエラーがない場合)。\nこのハンドブックをここまで読んでくださった方は、無数の関数に出会ったことになります。というのも、R ではすべての演算子が関数呼び出しになるからです。 +, for, if, [, $, { …. 例えば、x + y は '+'(x, y) と同じです。\nR は、複数の関数を共に扱う可能性が最も高い言語であり、また、ユーザが簡単に関数を書けるように十分なツールが提供されている言語の 1 つです。私たちはプログラムの繋がりを最初から最後まで考える必要はなく、R では複数の関数をベクトルのように使用したり、他の関数やリストの中で使用することもできます。\n関数型プログラミングに関する非常に高度な資料は数多く存在しますが、ここでは短い実用的な例を用いて、関数型プログラミングを始めるためのヒントを提供するにとどめます。その後、参考資料のリンクを参照して、さらに詳しい情報を得ることをお勧めします。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#なぜ関数を使うのか",
    "href": "new_pages/writing_functions.jp.html#なぜ関数を使うのか",
    "title": "44  関数の作成",
    "section": "44.3 なぜ関数を使うのか?",
    "text": "44.3 なぜ関数を使うのか?\n見出しの質問に答える前に、次の点が重要です。このハンドブックの ループと反復処理・リストの操作の章に、最初の R 関数を書くためのヒントがすでにあります。実際、if/else や loop の使用は、関数の中で多くの機能の中核です。なぜなら、複数の条件分岐によって、記述したコードが様々な場面に適用できたり、ループ文によってコードを繰り返し実行するのに役立ったりするからです。\n\n別々の変数やデータに、同じコードを複数回繰り返し適用するか？\n繰り返しの適用を取り除くことで、コード全体が大幅に短縮され、実行速度が速くなるか？\n記述したコードが他の箇所で再度使用されているが、再度使用されたコードの複数箇所で異なる値が使用される可能性はあるか？\n\n前述の質問の答えが YES であれば、おそらく関数を書く必要があるでしょう。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#r-でどのように関数を作成するか",
    "href": "new_pages/writing_functions.jp.html#r-でどのように関数を作成するか",
    "title": "44  関数の作成",
    "section": "44.4 R でどのように関数を作成するか?",
    "text": "44.4 R でどのように関数を作成するか?\nR の関数は主に 3 つの要素で構成されています:\n\nformals()、関数の呼び出し方を制御する引数のリストを返す\nbody()、関数内にコードを記述する。例、コードの記述方法によって、角括弧（{}）の内側や括弧（()）の後など\n\nそして、\n\nenvironment()、関数の変数の位置を特定するのに役立ち、関数が値を見つける方法を決定する\n\n関数を作成したら、関連する関数を呼び出すことで、これらの各構成要素を検証することができます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#基本的な構文と構造",
    "href": "new_pages/writing_functions.jp.html#基本的な構文と構造",
    "title": "44  関数の作成",
    "section": "44.5 基本的な構文と構造",
    "text": "44.5 基本的な構文と構造\n\n関数には適切な名前を付ける必要があり、名前を読んだだけでその内容が容易に理解できるようにしなければなりません。実際、Rの基本的な関数の大部分ですでに当てはまります。mean()、print()、summary() のような関数は、非常にわかりやすい名前となっています\n関数は、引数を必要とします。例えば、処理するデータや静的な値、その他のオプションオブジェクトなどです\nそして最後に、関数はその中核となるタスクと与えられた引数に基づいて出力を行います。通常、出力を得るためには、print() や return() などの組み込み関数を使用します。ロジカル値、数値、文字、データフレームなど、要するにあらゆる種類の R オブジェクトを出力できます。\n\n基本的に下記が関数の構成です:\n\nfunction_name &lt;- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\n\ncontain_covid19() という名前の関数を最初に作ります。\n\ncontain_covid19 &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n新しく作成した関数の要素を検証します。\n\nformals(contain_covid19)\n\n$barrier_gest\n\n\n$wear_mask\n\n\n$get_vaccine\n\nbody(contain_covid19)\n\n{\n    if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n        \"yes\") \n        return(\"success\")\n    else (\"please make sure all are yes, this pandemic has to end!\")\n}\n\nenvironment(contain_covid19)\n\n&lt;environment: R_GlobalEnv&gt;\n\n\nでは、作成した関数をテストしてみましょう。作成した関数を呼び出すには、他の R 関数と同様に、関数名を記述し、必要な引数を追加します。\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")\n\n[1] \"success\"\n\n\n明示的に各引数の名前をあらためて指定できます。しかし、R は各引数の定義順序を記憶しているので、あらためて指定しなくても、上記のコードは動作するはずです。つまり、引数の値を正しい順序で書く限り、関数を呼び出すときに引数の名前を省略できるのです。\n\ncontain_covid19(\"yes\", \"yes\", \"yes\")\n\n[1] \"success\"\n\n\n次に、片方の値が \"no\" または not \"yes\" の場合はどうなるかを見てみましょう。\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\n[1] \"please make sure all are yes, this pandemic has to end!\"\n\n\n関数定義に定義されていない引数を与えると、エラーが発生します:\n\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\nError in contain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\",  :    could not find function \"contain_covid19\"\n備考: 一部の関数(多くは非常に短くわかりやすい関数です)には、関数名を必要としないものもあり、コード内で直接使用したり、他の関数内で使用したりして、素早い実装ができます。 これらの関数は 無名関数 と呼ばれています。\n例えば、以下は、データセットの文字型変数のみを保持する無名関数です。\n\nlinelist %&gt;% \n  dplyr::slice_head(n=10) %&gt;%  #base R パッケージにある \"head\" 関数に相当し、データセットの最初の n 個の観測データを返す\n  select(function(x) is.character(x)) \n\n\n\n\n\n\n\n次は、観測データを 2 行ごと選択する関数です(例えば、患者ごとに多くのレコードを持つ縦持ちデータがある場合、日付や訪問で順番に並べた後などに適切なことがあります)。 この例では、dplyr 処理外に記述する適切な関数は、すべての行番号を含むベクトルに適用する function (x) (x%%2 == 0) となります。\n\nlinelist %&gt;%   \n   slice_head(n=20) %&gt;% \n   tibble::rownames_to_column() %&gt;% # 最終的な抽出行を明示するために、各観測行のインデックスを rowname として追加する\n   filter(row_number() %%2 == 0)\n\n\n\n\n\n\n\nbase R を利用すると以下のように書くことができます:\n\nlinelist_firstobs &lt;- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]\n\n\n\n\n\n\n\n注意: 関数を使うことがコード実装に役立つのは事実です。しかしながら、複数の関数を記述することに時間を浪費したり、あるいは、十分に考えられておらず、また、適切に書かれていない、つまり、結果としてエラーを返す関数の修正に時間を浪費する可能性があります。そのため、まず R のコードを書き、そのコードが意図した動作をすることを確認してから、上記のような 3 つの主要な要素を持つ関数にすることを推奨します。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#例",
    "href": "new_pages/writing_functions.jp.html#例",
    "title": "44  関数の作成",
    "section": "44.6 例",
    "text": "44.6 例\n\nそれぞれの列の割合を返す\n確かに、多くのパッケージには、情報を非常に簡単かつ良い方法で要約することができる素晴らしい関数がすでにあります。しかし、関数を書くことに慣れるための最初のステップとして自分で作ってみることにします。\n下記の例では、シンプルな関数を書くことで、同じコードを何度もコピーペーストする必要がないことを示します。\n\nproptab_multiple &lt;- function(my_data, var_to_tab){\n  \n  #表組みする前に対象となる各変数名を表示する\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #次の 2 つの関数の結果を行ごとに結合する\n        #対象となる変数を表にする: 数値のみ\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #対象となる各変数ごとに割合を計算し、その値を小数第 2 位に丸める\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")\n\n[1] \"gender\"\n\n\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n\nproptab_multiple(linelist, \"age_cat\")\n\n[1] \"age_cat\"\n\n\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n\nproptab_multiple(linelist, \"outcome\")\n\n[1] \"outcome\"\n\n\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nヒント: 上記のように、一般的なプログラミングと同様に、関数にコメントを付けることが非常に重要です。関数作成の目的は、コードを読みやすく、短く、効率的にすることであることを覚えておいてください。関数の名前を読んだだけで、その関数が何をするのか理解できるようにし、コメントを読むことでより詳細な情報を得られるようにします。\nもう一つの方法は、ループ内でこの関数を使用し、一度に処理を行うことです。:\n\nfor(var_to_tab in c(\"gender\",\"age_cat\",  \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}\n\n[1] \"gender\"\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n[1] \"age_cat\"\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n[1] \"outcome\"\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nよりシンプルな方法としては、“for loop” の代わりに base R の “apply” を使用することで、以下のように表現できます:\nヒント： R は関数型プログラミング言語として定義されており、ほとんどの場合、コードを実行する際には組み込み関数を使用します。関数の書き方に慣れるための良い習慣は、普段使用している基本的な関数がどのように作られているか内部動作を確認することです。そのための RStudio のショートカットは、関数名を選択してから Ctrl+F2 または fn+F2 またはCmd+F2(お使いのコンピュータによって異なります)を押します。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#purrr-の使用-繰り返し利用可能な関数の作成",
    "href": "new_pages/writing_functions.jp.html#purrr-の使用-繰り返し利用可能な関数の作成",
    "title": "44  関数の作成",
    "section": "44.7 purrr の使用: 繰り返し利用可能な関数の作成",
    "text": "44.7 purrr の使用: 繰り返し利用可能な関数の作成\n\nデータセット内の複数のカラムのデータ型を変更する\n例えば、分析やプロットのために、元の linelist データに含まれる多くの文字型変数を「因子型」に変換する必要があるとします。この変換ステップを何度も繰り返し実行する代わりに、lapply() を使えば、1 行のコードですべての文字型変数の変換を行うことができます\n注意: lapply() はリストを返すので、使用の際には変換の最終ステップとして追加の修正が必要になるかもしれません。\n同じことは purrr パッケージの map_if() を使って行うことができます。\n\nlinelist_factor2 &lt;- linelist %&gt;%\n  purrr::map_if(is.character, as.factor)\n\n\nlinelist_factor2 %&gt;%\n        glimpse()\n\nList of 30\n $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA ...\n $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" ...\n $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" ...\n $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" ...\n $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ...\n\n\n\n\n異なる変数で繰り返しグラフを作成する\nH7N9 発生時の患者の転帰の分布を、中国各省ごとに見ていくための円グラフを作成します。各省それぞれにコードを繰り返すのではなく、以下に作成する関数を適用するだけです。\n\n#highchart カラーテーマを使用するためのオプションの設定\noptions(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#\"chart_outcome_province\" という関数を作成する。この関数はデータセットと、結果の分布をプロットする州の名前を引数として取る。\n\nchart_outcome_province &lt;- function(data_used, prov){\n  \n  tab_prov &lt;- data_used %&gt;% \n    filter(province == prov,\n           !is.na(outcome))%&gt;% \n    group_by(outcome) %&gt;% \n    count() %&gt;%\n    adorn_totals(where = \"row\") %&gt;% \n    adorn_percentages(denominator = \"col\", )%&gt;%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %&gt;%\n    filter(outcome != \"Total\") %&gt;% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distibution of the outcome in:\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\n\n\n\n\nchart_outcome_province(flu_china,\"Zhejiang\")\n\n\n\n\nchart_outcome_province(flu_china,\"Jiangsu\")\n\n\n\n\n\n\n\n異なる変数で繰り返し表を作成する\n3 つの指標を作成して表にまとめ、各州ごとに作成します。指標は、発症から入院までの期間、回復の割合、症例の年齢の中央値です。\n\nindic_1 &lt;- flu_china %&gt;% \n  group_by(province) %&gt;% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %&gt;%\n  select(province, mean_delay_onset_hosp)  %&gt;% \n  distinct()\n     \n\nindic_2 &lt;-  flu_china %&gt;% \n            filter(!is.na(outcome)) %&gt;% \n            group_by(province, outcome) %&gt;% \n            count() %&gt;%\n            pivot_wider(names_from = outcome, values_from = n) %&gt;% \n    adorn_totals(where = \"col\") %&gt;% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%&gt;% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 &lt;-  flu_china %&gt;% \n            group_by(province) %&gt;% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %&gt;% \n  select(province, median_age_cases)  %&gt;% \n  distinct()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `median_age_cases = median(as.numeric(age), na.rm = TRUE)`.\nℹ In group 11: `province = \"Shanghai\"`.\nCaused by warning in `median()`:\n! NAs introduced by coercion\n\n#3 つの指標データセットの結合\n\ntable_indic_all &lt;- indic_1 %&gt;% \n  dplyr::left_join(indic_2, by = \"province\") %&gt;% \n        left_join(indic_3, by = \"province\")\n\n\n#指標を flextable で表示する\n\n\nprint_indic_prov &lt;-  function(table_used, prov){\n  \n  #まず、表示しやすいようにデータフレームを少し変換する\n  indic_prov &lt;- table_used %&gt;%\n    filter(province==prov) %&gt;%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %&gt;% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\",\"perc_recovery\",\"median_age_cases\"),\n   labels=c(\"Mean delay onset-hosp\",\"Percentage of recovery\", \"Median age of the cases\"))\n   ) %&gt;% \n    ungroup(province) %&gt;% \n    select(indic_label, value)\n  \n\n    tab_print &lt;- flextable(indic_prov)  %&gt;%\n    theme_vanilla() %&gt;% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print &lt;- tab_print %&gt;% \n                  autofit()   %&gt;%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %&gt;%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %&gt;%\n    flextable::bold(part = \"header\") %&gt;%\n    flextable::color(color = \"white\", part = \"header\") %&gt;% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de: \", prov)) %&gt;% \nbold(part = \"header\")\n \n tab_print &lt;- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\n\nIndicateurs pour la province de: ShanghaiIndicateursEstimationMean delay onset-hosp4.0Percentage of recovery46.7Median age of the cases67.0\n\nprint_indic_prov(table_indic_all, \"Jiangsu\")\n\nIndicateurs pour la province de: JiangsuIndicateursEstimationMean delay onset-hosp6.0Percentage of recovery71.4Median age of the cases55.0",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#関数をよりよく使うためのヒントとベストプラクティス",
    "href": "new_pages/writing_functions.jp.html#関数をよりよく使うためのヒントとベストプラクティス",
    "title": "44  関数の作成",
    "section": "44.8 関数をよりよく使うためのヒントとベストプラクティス",
    "text": "44.8 関数をよりよく使うためのヒントとベストプラクティス\n関数型プログラミングは、コードを簡単にし、その読み取りを容易にするためのものです。また、逆も成り立ちます。以下のヒントは、きれいなコードと読みやすいコードの作成に役立つでしょう。\n\n命名と構文\n\n環境に存在する他の関数と、容易に重複してしまう可能性のある名前の使用は避けてください\n関数名は短く、他の方が理解しやすいようにすることをお勧めします\n関数名には動詞を使い、引数名には名詞を使うのが好ましいです。\n\n\n\nカラム名と tidy evaluation\nコードに引数として与えられた列名を参照する方法を知りたい場合は、tidyverse programming guidance を参照ください。トピックの中には、tidy evaluationと包括演算子 { } (二重括弧)の利用方法が含まれています。\n前述した tidyverse チュートリアルページにある、テンプレートコード例です:\n\nvar_summary &lt;- function(data, var) {\n  data %&gt;%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))\n}\nmtcars %&gt;% \n  group_by(cyl) %&gt;% \n  var_summary(mpg)\n\n\n\nテストとエラー処理\n関数のタスクが複雑であればあるほど、エラーが発生する可能性は高くなります。そのため、エラーの原因がどこにあるのかを素早く理解し、エラーの修正方法を見つけるために、関数内に何らかの検証工程を加えることが必要な場合があります。\n\nmissing(引数) を用いて引数の欠落を確認することが推奨されます。この簡単な確認は “TRUE” もしくは “FALSE” を返します。\n\n\ncontain_covid19_missing &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask ==\"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")\n\n[1] \"please provide arg1\"\n[1] \"please provide arg2\"\n\n\nError in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\n\n\n\nより検出しやすいエラーには、stop() を使用します。\n\n\ncontain_covid19_stop &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\"))\n  \n  if (barrier_gest == \"yes\" & wear_mask ==\"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")\n\nError in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\n\n\n\nほとんどの組み込み関数は実行時に、特定の条件でポップアップするメッセージや警告があります。関数 message() や warning() を使って、これらのメッセージを自作の関数に組み込むことができます。\n引数として関数を受取り、安全な方法で実行する safely() を使うことで、エラーを処理することもできます。実際、この関数は、エラーが発生しても停止することなく実行されます。safely() は出力として、関数の結果とスキップしたエラーの2つのオブジェクトを持つリストを返します。\n\n下記コードでは、linelise 各行に対し mean() を実行し、次に safely() を実行することで結果とエラーを検証できます。\n\nmap(linelist, mean)\n\n$case_id\n[1] NA\n\n$generation\n[1] 16.56165\n\n$date_infection\n[1] NA\n\n$date_onset\n[1] NA\n\n$date_hospitalisation\n[1] \"2014-11-03\"\n\n$date_outcome\n[1] NA\n\n$outcome\n[1] NA\n\n$gender\n[1] NA\n\n$age\n[1] NA\n\n$age_unit\n[1] NA\n\n$age_years\n[1] NA\n\n$age_cat\n[1] NA\n\n$age_cat5\n[1] NA\n\n$hospital\n[1] NA\n\n$lon\n[1] -13.23381\n\n$lat\n[1] 8.469638\n\n$infector\n[1] NA\n\n$source\n[1] NA\n\n$wt_kg\n[1] 52.64487\n\n$ht_cm\n[1] 124.9633\n\n$ct_blood\n[1] 21.20686\n\n$fever\n[1] NA\n\n$chills\n[1] NA\n\n$cough\n[1] NA\n\n$aches\n[1] NA\n\n$vomit\n[1] NA\n\n$temp\n[1] NA\n\n$time_admission\n[1] NA\n\n$bmi\n[1] 46.89023\n\n$days_onset_hosp\n[1] NA\n\n\n\nsafe_mean &lt;- safely(mean)\nlinelist %&gt;% \n  map(safe_mean)\n\n$case_id\n$case_id$result\n[1] NA\n\n$case_id$error\nNULL\n\n\n$generation\n$generation$result\n[1] 16.56165\n\n$generation$error\nNULL\n\n\n$date_infection\n$date_infection$result\n[1] NA\n\n$date_infection$error\nNULL\n\n\n$date_onset\n$date_onset$result\n[1] NA\n\n$date_onset$error\nNULL\n\n\n$date_hospitalisation\n$date_hospitalisation$result\n[1] \"2014-11-03\"\n\n$date_hospitalisation$error\nNULL\n\n\n$date_outcome\n$date_outcome$result\n[1] NA\n\n$date_outcome$error\nNULL\n\n\n$outcome\n$outcome$result\n[1] NA\n\n$outcome$error\nNULL\n\n\n$gender\n$gender$result\n[1] NA\n\n$gender$error\nNULL\n\n\n$age\n$age$result\n[1] NA\n\n$age$error\nNULL\n\n\n$age_unit\n$age_unit$result\n[1] NA\n\n$age_unit$error\nNULL\n\n\n$age_years\n$age_years$result\n[1] NA\n\n$age_years$error\nNULL\n\n\n$age_cat\n$age_cat$result\n[1] NA\n\n$age_cat$error\nNULL\n\n\n$age_cat5\n$age_cat5$result\n[1] NA\n\n$age_cat5$error\nNULL\n\n\n$hospital\n$hospital$result\n[1] NA\n\n$hospital$error\nNULL\n\n\n$lon\n$lon$result\n[1] -13.23381\n\n$lon$error\nNULL\n\n\n$lat\n$lat$result\n[1] 8.469638\n\n$lat$error\nNULL\n\n\n$infector\n$infector$result\n[1] NA\n\n$infector$error\nNULL\n\n\n$source\n$source$result\n[1] NA\n\n$source$error\nNULL\n\n\n$wt_kg\n$wt_kg$result\n[1] 52.64487\n\n$wt_kg$error\nNULL\n\n\n$ht_cm\n$ht_cm$result\n[1] 124.9633\n\n$ht_cm$error\nNULL\n\n\n$ct_blood\n$ct_blood$result\n[1] 21.20686\n\n$ct_blood$error\nNULL\n\n\n$fever\n$fever$result\n[1] NA\n\n$fever$error\nNULL\n\n\n$chills\n$chills$result\n[1] NA\n\n$chills$error\nNULL\n\n\n$cough\n$cough$result\n[1] NA\n\n$cough$error\nNULL\n\n\n$aches\n$aches$result\n[1] NA\n\n$aches$error\nNULL\n\n\n$vomit\n$vomit$result\n[1] NA\n\n$vomit$error\nNULL\n\n\n$temp\n$temp$result\n[1] NA\n\n$temp$error\nNULL\n\n\n$time_admission\n$time_admission$result\n[1] NA\n\n$time_admission$error\nNULL\n\n\n$bmi\n$bmi$result\n[1] 46.89023\n\n$bmi$error\nNULL\n\n\n$days_onset_hosp\n$days_onset_hosp$result\n[1] NA\n\n$days_onset_hosp$error\nNULL\n\n\n以前述べたように、コードにコメントをつけることは、作業内容を明示するための良い方法です。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.jp.html#参考資料",
    "href": "new_pages/writing_functions.jp.html#参考資料",
    "title": "44  関数の作成",
    "section": "44.9 参考資料",
    "text": "44.9 参考資料\nR for Data Science link\nCheatsheet advance R programming\nCheatsheet purr Package\nVideo-ACM talk by Hadley Wickham: The joy of functional programming (how does map_dbl work)",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>関数の作成</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html",
    "href": "new_pages/directories.jp.html",
    "title": "45  ディレクトリの操作",
    "section": "",
    "text": "45.1 準備",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#準備",
    "href": "new_pages/directories.jp.html#準備",
    "title": "45  ディレクトリの操作",
    "section": "",
    "text": "fs パッケージ\nfs パッケージは、R の base パッケージ（以下 base R）関数のいくつかを改良し、ディレクトリの操作を簡単にし tidyverse パッケージの一部です。以下のセクションでは、しばしば fs パッケージからの関数を使用します。\n\npacman::p_load(\n  fs,             # ファイル、ディレクトリの操作\n  rio,            # インポート・エクスポート\n  here,           # 相対ファイルパス\n  tidyverse)      # データの管理と可視化\n\n\n\nディレクトリをデンドログラムツリーで表示する\nfs パッケージの dir_tree() 関数を使用します。\npath = にフォルダのファイルパスを指定し、1つの階層のみを表示するか(recurse = FALSE オプション)、全てのサブディレクトリの全てのファイルを表示するか(recurse = TRUE オプション)を指定します。 以下では、here() を R プロジェクトの略称として使用し、そのサブフォルダの “data” を指定しています。“data” には、この R ハンドブックで使用するすべてのデータが格納されています。 “data” とそのサブフォルダ内のすべてのファイルを表示するように設定します。(“cache”, “epidemic models”, “population”, “shp”, “weather” など).\n\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file6244422c3efa/data\n├── africa_countries.geo.json\n├── cache\n│   └── epidemic_models\n│       ├── 2015-04-30\n│       │   ├── estimated_reported_cases_samples.rds\n│       │   ├── estimate_samples.rds\n│       │   ├── latest_date.rds\n│       │   ├── reported_cases.rds\n│       │   ├── summarised_estimated_reported_cases.rds\n│       │   ├── summarised_estimates.rds\n│       │   └── summary.rds\n│       ├── epinow_res.rds\n│       ├── epinow_res_small.rds\n│       ├── generation_time.rds\n│       └── incubation_period.rds\n├── case_linelists\n│   ├── cleaning_dict.csv\n│   ├── fluH7N9_China_2013.csv\n│   ├── linelist_cleaned.rds\n│   ├── linelist_cleaned.xlsx\n│   └── linelist_raw.xlsx\n├── country_demographics.csv\n├── covid_example_data\n│   ├── covid_example_data.xlsx\n│   └── covid_shapefile\n│       ├── FultonCountyZipCodes.cpg\n│       ├── FultonCountyZipCodes.dbf\n│       ├── FultonCountyZipCodes.prj\n│       ├── FultonCountyZipCodes.sbn\n│       ├── FultonCountyZipCodes.sbx\n│       ├── FultonCountyZipCodes.shp\n│       ├── FultonCountyZipCodes.shp.xml\n│       └── FultonCountyZipCodes.shx\n├── covid_incidence.csv\n├── covid_incidence_map.R\n├── district_count_data.xlsx\n├── example\n│   ├── Central Hospital.csv\n│   ├── district_weekly_count_data.xlsx\n│   ├── fluH7N9_China_2013.csv\n│   ├── hospital_linelists.xlsx\n│   ├── linelists\n│   │   ├── 20201007linelist.csv\n│   │   ├── case_linelist20201006.csv\n│   │   ├── case_linelist_2020-10-02.csv\n│   │   ├── case_linelist_2020-10-03.csv\n│   │   ├── case_linelist_2020-10-04.csv\n│   │   ├── case_linelist_2020-10-05.csv\n│   │   └── case_linelist_2020-10-08.xlsx\n│   ├── Military Hospital.csv\n│   ├── Missing.csv\n│   ├── Other.csv\n│   ├── Port Hospital.csv\n│   └── St. Mark's Maternity Hospital (SMMH).csv\n├── facility_count_data.rds\n├── flexdashboard\n│   ├── outbreak_dashboard.html\n│   ├── outbreak_dashboard.Rmd\n│   ├── outbreak_dashboard_shiny.Rmd\n│   ├── outbreak_dashboard_test.html\n│   └── outbreak_dashboard_test.Rmd\n├── fluH7N9_China_2013.csv\n├── gis\n│   ├── africa_countries.geo.json\n│   ├── covid_incidence.csv\n│   ├── covid_incidence_map.R\n│   ├── linelist_cleaned_with_adm3.rds\n│   ├── population\n│   │   ├── sle_admpop_adm3_2020.csv\n│   │   └── sle_population_statistics_sierraleone_2020.xlsx\n│   └── shp\n│       ├── README.txt\n│       ├── sle_adm3.CPG\n│       ├── sle_adm3.dbf\n│       ├── sle_adm3.prj\n│       ├── sle_adm3.sbn\n│       ├── sle_adm3.sbx\n│       ├── sle_adm3.shp\n│       ├── sle_adm3.shp.xml\n│       ├── sle_adm3.shx\n│       ├── sle_hf.CPG\n│       ├── sle_hf.dbf\n│       ├── sle_hf.prj\n│       ├── sle_hf.sbn\n│       ├── sle_hf.sbx\n│       ├── sle_hf.shp\n│       └── sle_hf.shx\n├── godata\n│   ├── cases_clean.rds\n│   ├── contacts_clean.rds\n│   ├── followups_clean.rds\n│   └── relationships_clean.rds\n├── likert_data.csv\n├── linelist_cleaned.rds\n├── linelist_cleaned.xlsx\n├── linelist_raw.xlsx\n├── make_evd_dataset-DESKTOP-JIEUMMI.R\n├── make_evd_dataset.R\n├── malaria_app\n│   ├── app.R\n│   ├── data\n│   │   └── facility_count_data.rds\n│   ├── funcs\n│   │   └── plot_epicurve.R\n│   ├── global.R\n│   ├── malaria_app.Rproj\n│   ├── server.R\n│   └── ui.R\n├── malaria_facility_count_data.rds\n├── phylo\n│   ├── sample_data_Shigella_tree.csv\n│   ├── Shigella_subtree_2.nwk\n│   ├── Shigella_subtree_2.txt\n│   └── Shigella_tree.txt\n├── rmarkdown\n│   ├── outbreak_report.docx\n│   ├── outbreak_report.html\n│   ├── outbreak_report.pdf\n│   ├── outbreak_report.pptx\n│   ├── outbreak_report.Rmd\n│   ├── report_tabbed_example.html\n│   └── report_tabbed_example.Rmd\n├── standardization\n│   ├── country_demographics.csv\n│   ├── country_demographics_2.csv\n│   ├── deaths_countryA.csv\n│   ├── deaths_countryB.csv\n│   └── world_standard_population_by_sex.csv\n├── surveys\n│   ├── population.xlsx\n│   ├── survey_data.xlsx\n│   └── survey_dict.xlsx\n└── time_series\n    ├── campylobacter_germany.xlsx\n    └── weather\n        ├── germany_weather2002.nc\n        ├── germany_weather2003.nc\n        ├── germany_weather2004.nc\n        ├── germany_weather2005.nc\n        ├── germany_weather2006.nc\n        ├── germany_weather2007.nc\n        ├── germany_weather2008.nc\n        ├── germany_weather2009.nc\n        ├── germany_weather2010.nc\n        └── germany_weather2011.nc",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#ディレクトリ内のファイルを一覧表示する",
    "href": "new_pages/directories.jp.html#ディレクトリ内のファイルを一覧表示する",
    "title": "45  ディレクトリの操作",
    "section": "45.2 ディレクトリ内のファイルを一覧表示する",
    "text": "45.2 ディレクトリ内のファイルを一覧表示する\nディレクトリ内のファイル名だけをリストアップするには、base R の dir() を使用します。 例えば、下記のコマンドは R プロジェクトの “data” フォルダの “population” サブフォルダ内のファイル名をリストアップしています。相対的なファイルパスは here() を使ってえられます (詳しくは データのインポート・エクスポート 章を参照してください)。\n\n# ファイル名\ndir(here(\"data\", \"gis\", \"population\"))\n\n[1] \"sle_admpop_adm3_2020.csv\"                       \n[2] \"sle_population_statistics_sierraleone_2020.xlsx\"\n\n\nディレクトリのファイルのフルパスをリストアップするには、fs パッケージの dir_ls() を使用できます。 base R を使う場合は list.files() です。\n\n# ファイルパス\ndir_ls(here(\"data\", \"gis\", \"population\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file6244422c3efa/data/gis/population/sle_admpop_adm3_2020.csv\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file6244422c3efa/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n\n\nディレクトリ内の各ファイルに関するすべてのメタデータ情報(パス、更新日など)を得るには、 fs パッケージの dir_info() を使用します。\nこれは、ファイルの最終更新時刻を抽出したい場合、例えば、最新バージョンのファイルをインポートしたい場合などに特に有効です。この例については、データのインポート・エクスポート の章を参照してください。\n\n# ファイル情報\ndir_info(here(\"data\", \"gis\", \"population\"))\n\n以下は、関数から返されたデータフレームです。すべての列を見るには右にスクロールしてください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#ファイルの情報",
    "href": "new_pages/directories.jp.html#ファイルの情報",
    "title": "45  ディレクトリの操作",
    "section": "45.3 ファイルの情報",
    "text": "45.3 ファイルの情報\n特定のファイルに関するメタデータ情報を抽出するには，fs パッケージの file_info() (または base R の file.info()) を使用します。\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\n\n\n\n\n\n\nここでは、$ を使って結果のインデックスを指定し、modification_time の値のみを返すようにしています。\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time\n\n[1] \"2024-02-18 14:56:16 CET\"",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#存在するか確認する",
    "href": "new_pages/directories.jp.html#存在するか確認する",
    "title": "45  ディレクトリの操作",
    "section": "45.4 存在するか確認する",
    "text": "45.4 存在するか確認する\n\nR オブジェクト\nR オブジェクトが R の中に存在するかどうかを調べるには、base R の exists() を使用します(オブジェクト名を引用符で囲み渡してください)。\n\nexists(\"linelist\")\n\n[1] FALSE\n\n\nbase R パッケージの中には、“data” のような一般的なオブジェクト名を裏で使用しているものがあり、そういったオブジェクトは inherit = FALSE が指定されない限り、TRUE として表示されることに注意してください。これが、データセットに “data” という名前をつけない理由の 1 つです。\n\nexists(\"data\")\n\n[1] TRUE\n\nexists(\"data\", inherit = FALSE)\n\n[1] FALSE\n\n\n関数を書く場合、引数として渡した値が存在するかどうかを調べるには exists() ではなく、 base R の missing() を使うべきです。\n\n\nディレクトリ\nディレクトリが存在するかどうかを調べるには，fs パッケージの is_dir() にファイルパス(とファイル名)を与えてください．右にスクロールすると TRUE が表示されていることがわかります。\n\nis_dir(here(\"data\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file6244422c3efa/data \n                                                                 TRUE \n\n\n代替としては、base R の file.exists() があります。\n\n\nファイル\n特定のファイルが存在するかどうかを調べるには、fs パッケージの is_file() を使用します。下記の関数の結果を右にスクロールすると TRUE が表示されることがわかります。\n\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file6244422c3efa/data/case_linelists/linelist_cleaned.rds \n                                                                                                     TRUE \n\n\nbase R での代替は file.exists() です。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#作成",
    "href": "new_pages/directories.jp.html#作成",
    "title": "45  ディレクトリの操作",
    "section": "45.5 作成",
    "text": "45.5 作成\n\nディレクトリ\n新しいディレクトリ(フォルダ)を作成するには、fs パッケージの dir_create() を使用します。すでにディレクトリが存在する場合は、上書きされず、エラーも返されません。\n\ndir_create(here(\"data\", \"test\"))\n\n代替として、base R の dir.create() があります。これはディレクトリがすでに存在する場合はエラーを表示します。一方、dir_create() はエラーを返しません。\n\n\nファイル\n空のファイルは fs パッケージの file_create() で作成できます。ファイルがすでに存在する場合は、上書きされたり変更されたりすることはありません。\n\nfile_create(here(\"data\", \"test.rds\"))\n\nbase R での代替手段は file.create() です。しかし、ファイルがすでに存在する場合、この代替手段はファイルを削除します。file_create() を使用すれば、ファイルは変更されずに残ります。\n\n\n存在しない場合にのみ作成する\n作成中",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#削除",
    "href": "new_pages/directories.jp.html#削除",
    "title": "45  ディレクトリの操作",
    "section": "45.6 削除",
    "text": "45.6 削除\n\nR オブジェクト\nR オブジェクトを削除するには、base R の rm() を使用します。\n\n\nディレクトリ\nfs パッケージの dir_delete() を使用します。\n\n\nファイル\nfs パッケージの file_delete() でファイルを削除できます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#他のファイルを実行する",
    "href": "new_pages/directories.jp.html#他のファイルを実行する",
    "title": "45  ディレクトリの操作",
    "section": "45.7 他のファイルを実行する",
    "text": "45.7 他のファイルを実行する\n\nsource()\nある R スクリプトを別の R スクリプト中から実行する場合、base R の source() コマンドを使用できます。\n\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))\n\n以下は、上記の R スクリプトを表示し、スクリプトの右上にある “Source” ボタンをクリックすることと同じです。これはスクリプトを実行しますが、特に意図しない限り出力なく実行されます(R コンソールへの出力はありません)。[Interactive console] の章で、source() を使って R コンソールでユーザーと対話する例を参照してください。\n\n\n\n\n\n\n\n\n\n\n\nrender()\nrender() は source() のバリエーションで、R markdown のスクリプトで最もよく使用されます。R markdown ファイルを input = に指定し、output_format = (典型的には “html_document”、“pdf_document”、“word_document”、“” のいずれか) を指定します。\n詳しくは R Markdown で作るレポート をご覧ください。また render() のドキュメントをこちらから、もしくは ?render と入力して参照してください。\n\n\nディレクトリ内のファイルを実行する\nfor ループ を作成し、それを使って dir() で識別されるディレクトリ内のすべてのファイルを source() できます。\n\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # R プロジェクトの \"scripts\" フォルダにある各スクリプト名(拡張子 .R)に対して\n  source(here(\"scripts\", script))                        # scripts フォルダに存在する、同じ名前のファイルをソースとする\n}\n\n特定のスクリプトだけを実行したい場合は、次のように名前で識別できます。\n\nscripts_to_run &lt;- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}\n\nこちらは fs パッケージの関数と base R 関数の比較です。\n\n\nディレクトリ内のファイルをインポートする\n個別のファイルのインポートとエクスポートについては、データのインポート・エクスポート の章をご覧ください。\nまた、ファイル名に含まれる日付をもとに、またはファイルのメタデータを見て、自動的に最新のファイルをインポートする方法についても データのインポート・エクスポート の章を参照してください。\npurrr パッケージによるデモの例については、ループと反復処理・リストの操作 の章を参照してください:\n\nデータフレームを分割し、複数の CSV ファイルとして保存する\nデータフレームを分割し、1つの Excel ワークブック内で各パーツを別のシートとして保存する\n複数の CSV ファイルを取り込み、1 つのデータフレームにまとめる\n複数のシートを持つ Excel ワークブックをインポートして、1 つのデータフレームにまとめる",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#base-r",
    "href": "new_pages/directories.jp.html#base-r",
    "title": "45  ディレクトリの操作",
    "section": "45.8 base R",
    "text": "45.8 base R\n以下の list.files() と dir() 関数をご覧ください。これらは指定したディレクトリ内のファイルをリストアップするという同じ操作を行います。 ignore.case = や検索する特定のパターンを指定できます。\n\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)\n\n現在「開いている」ファイルは、「~$hospital_linelists.xlsx」のように、先頭にチルダを付けてフォルダ内に表示されます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.jp.html#参考資料",
    "href": "new_pages/directories.jp.html#参考資料",
    "title": "45  ディレクトリの操作",
    "section": "45.9 参考資料",
    "text": "45.9 参考資料\nhttps://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>ディレクトリの操作</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html",
    "href": "new_pages/collaboration.jp.html",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "",
    "text": "46.1 Git とはなにか？\nGit は、フォルダ内の変更を追跡することができるバージョン管理ソフトウェアです。Word や LibreOffice、Google Docs の「変更履歴」オプションのように、あらゆる種類のファイルに対して使用することができます。これは、バージョン管理のための最も強力で最も使用されるオプションの 1 つです。\nなぜ聞いたことがないのか？ ー ソフトウェア開発の経験がある人は日常的にバージョン管理ソフト（Git、Mercurial、Subversion など）の使い方を学んでいますが、データ分析分野の人はあまりバージョン管理スキルを教わっていません。そのため、疫学者のほとんどは学生時代にバージョン管理ソフトの存在を知らず、仕事する中で学ばなければなりません。\n待って、Github って聞いたことあるけど、同じなの？ ー 正確には違いますが、よく一緒に使うことがありますので、その方法をご紹介します。簡単に言いますと\nそこで、クライアント / GUI である Github Desktop を使用すると、バックグラウンドで Git を使用して、自分のコンピュータのローカルファイルと Github サーバーのリモートファイルの両方を管理することができます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#git-とはなにか",
    "href": "new_pages/collaboration.jp.html#git-とはなにか",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "",
    "text": "Git はバージョン管理システムで、ソフトウェアの一つです。あなたのコンピュータ上でローカルに使用することもできますし、あるフォルダをホストサイトと同期させることもできます。デフォルトでは、ターミナルを使って Git にコマンドラインで指示を与えます。\nGit クライアント /GUI を使えば、コマンドラインを使わずに、（少なくとも単純で超一般的なものについては）同じ動作を行うことができます。\nフォルダをホストサイトに保存して他の人と共同作業をしたい場合は、Github、Gitlab、Bitbucket などにアカウントを作成してください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#なぜ-git-と-github-を組み合わせて使うの",
    "href": "new_pages/collaboration.jp.html#なぜ-git-と-github-を組み合わせて使うの",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.2 なぜ Git と Github を組み合わせて使うの？",
    "text": "46.2 なぜ Git と Github を組み合わせて使うの？\nGit を使うことで、以下のようなことが期待されます。\n\n文書化されたバージョンを増分の変更とともにアーカイブし、以前の状態に簡単に戻すことができます。\n並行してブランチを持つこと、つまり、レビュー後に変更を統合するための構造化された方法で開発版/「動く」版を持つこと。\n\nこれは、他の人と共同作業をしなくても、自分のコンピュータでローカルに行うことができます。今までに\n\nコードの一部分を削除してしまって 2 ヶ月後には実際に必要だったことに気づいて後悔したり\n一時停止していたプロジェクトに戻ってきて、あるモデルにトリッキーな修正をしたかどうかを思い出そうとしたり\nmodel_1.R というファイルと、model_1_test.R というファイルと、model_1_not_working.R というファイルを用意して、いろいろ試してみたり\nファイル report.Rmd、ファイル report_full.Rmd、ファイル report_true_final.Rmd、ファイル report_final_20210304.Rmd、ファイル report_final_20210402.Rmd があり、自分のデータ保管技術を呪っていたのですね。\n\nGit は上記の手助けをしてくれるので、それだけでも学ぶ価値があります。\nしかし、Github のようなオンラインリポジトリと併用することで、共同プロジェクトをサポートすることができ、さらに強力になります。これにより、以下の点が促進されます。\n\n共同作業：他の人がレビュー、コメント、変更の承認/却下が可能\nコード、データ、アウトプットを共有し、一般から（またはチーム内で）フィードバックを募る\n\nまた、以下のことは避けることができます。\n\n「おっと、前回のバージョンを送るのを忘れていたので、2 日分の作業をこの新しいファイルでやり直さなければならない」\nMina、Henry、Oumar の 3 人が 1 つのスクリプトで同時に作業を行い、それぞれの変更を手動でマージする必要があります。\n2 人の人が Dropbox と Sharepoint で同じファイルを変更しようとすると、同期エラーが発生します。\n\n\n複雑なようですね、私はプログラマーではありませんが、、、\n確かに複雑なときもあります。高度な使い方の例は、とても怯んでしまいます。しかし、R や Excel のように、エキスパートにならなくてもツールのメリットを享受することができます。ちょっとした関数や概念を学ぶだけで、変更点の追跡、オンラインリポジトリ上でのファイルの同期、同僚との共同作業などが、ごく短時間でできるようになります。\n学習曲線を考えると、緊急時の状況でこれらのツールを学ぶのに最適なタイミングではないかもしれません。しかし、学習は段階的に行うことができます。いくつかの概念を身につければ、ワークフローは非常に効率的かつ迅速になります。Git を使った共同作業が必要なプロジェクトに携わっていないのであれば、共同作業で Git を使う前に、1 人で Git を使うことでツールの利用に自信を持つことができるでしょう。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#環境構築",
    "href": "new_pages/collaboration.jp.html#環境構築",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.3 環境構築",
    "text": "46.3 環境構築\n\nGit をインストール\nGit とは、コンピュータの舞台裏にあるエンジンのことで、変更、ブランチ（バージョン）、マージ、リバートを追跡することができます。まず、https://git-scm.com/downloadsから Git をインストールする必要があります。\n\n\nGUI をインストール (必須ではないが推奨)\nGit には独自のコマンド言語があり、コマンドライン・ターミナルに入力することができます。しかし、多くのクライアントソフトや GUI があり、開発者ではない人が日常的に Git と直接やりとりする必要はほとんどないでしょうし、GUI は通常、ファイルの変更やブランチを視覚化するツールを提供します。\n初心者向けのものから複雑なものまで、あらゆる OS で多くの選択肢が存在します。 初心者向けの GUI としては、この章で紹介する RStudio の Git ペインや Github Desktop などがあります。中級者向け（より強力だがより複雑）のオプションとしては、Sourcetree、Gitkracken、Smart Git などがあります。\nGit clients の簡単な解説\n注釈：実際にはすべての GUI が内部的に Git を使用しているので、複数の GUI を試してみたり、特定のプロジェクトで GUI を切り替えたり、 GUI がサポートしていないアクションのために時間的にコンソールを使用したり、あるいは Github 上でオンラインでさまざまなアクションを実行したりすることができます。\n後述するように、RStudio の Terminal ペイン（R コンソールの隣にあるタブ）や Git Bash ターミナルなどのターミナルに Git コマンドを書き込まなければならないこともあります。\n\n\nGithub アカウント\ngithub.com で無料のアカウントを登録します。\n携帯電話のアプリで 2 要素認証を設定するように表示されることがあります。詳しくは、Github の ヘルプドキュメント をご覧ください。\nGithub Desktop を使用している場合は、インストール後に以下の 手順 に従って Gitub の認証情報を入力することができます。認証情報を登録しておかないと、後で Github からプロジェクトをクローンしようとしたときに認証情報を求められます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#用語と概念と基本機能",
    "href": "new_pages/collaboration.jp.html#用語と概念と基本機能",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.4 用語と概念と基本機能",
    "text": "46.4 用語と概念と基本機能\nR を学ぶときのように、Git を理解するためにはかなりの量の用語を覚えなければなりません。 ここでは、Basics to get you going / interactive tutorialを参照してください。 次のセクションでは、GUI の使い方を紹介しますが、前提概念を理解するためにも、GUI を使うときにも必要になるので、このセクションで用語や概念を覚えておくといいでしょう。\n\nリポジトリ\nGit のリポジトリ（repo）とは、プロジェクトのすべてのサブフォルダーやファイル（データ、コード、画像など）とそれらの変更履歴を含むフォルダーのことです。リポジトリの変更を追跡するようになると、Git はすべての追跡情報を含む隠しフォルダを作成します。典型的な Git リポジトリは、R プロジェクトフォルダーです（ハンドブックの R プロジェクトの設定 の章を参照）。\n次のセクションでは、Github、Github Desktop、または RStudio からGit リポジトリを作成（inittialize）する方法を紹介します。\n\n\nコミット\nコミット（commit）とは、ある時点でのプロジェクトのスナップショットです。プロジェクトに変更を加えた場合、ファイルに加えられた変更（差分）を追跡するために、新しいコミットを作成します。例えば、何行かのコードを編集し、関連するデータセットを更新したとします。変更が保存されると、これらの変更を 1 つの「コミット」に束ねることができます。\n各コミットには固有の ID（ハッシュ）があります。バージョンコントロールの目的では、コミットに基づいてプロジェクトを過去に戻すことができるので、比較的小さくまとまったものにしておくとよいでしょう。また、「コミット・メッセージ」と呼ばれる変更内容の簡単な説明を添付します。\nステージされた変更とは？変更をステージするとは、次のコミットに備えて、変更をステージ・エリアに追加することです。これは、あるコミットにどの変更を含めるかをきめ細かく決められるということです。例えば、あるスクリプトでモデルの仕様を作成し、その後別のスクリプトで図を作成した場合、2 つの異なるコミットを作成することは理にかなっています（モデルではなく図の変更を戻したい場合に簡単にできます）。\n\n\nブランチ\nブランチは、リポジトリ内の変更点の中でも独立したラインとして表され、プロジェクトファイルの並行した別バージョンを意味します。\nブランチは、変更内容を main ブランチに反映させる前にテストするのに便利です。main ブランチは、通常、プロジェクトの主要/最終/ライブバージョンです。ブランチでの実験が終わったら、その変更を main ブランチにマージして取り込むことができますし、変更がうまくいかなかった場合はブランチを削除することもできます。\n注：ブランチを使う際に他の人と共同作業をする必要はありませんし、リモートのオンラインリポジトリがある必要もありません。\n\n\nローカルとリモートのリポジトリ\nクローンとは、Git リポジトリのコピーを別の場所に作成することです。\n例えば、Github からオンラインリポジトリをパソコンにクローンしたり、ローカルリポジトリから始めてオンラインで Github に クローンすることができます。\nリポジトリをクローンすると、プロジェクトファイルは 2 つの場所に存在することになります。\n\nあなたの物理的なコンピュータ上の ローカル リポジトリ。ここで、ファイルやコードに実際の変更を加えます。\nリモート、オンラインリポジトリ：Github リポジトリ（またはその他のウェブホスト）にあるプロジェクトファイルのバージョン。\n\nこれらのリポジトリを同期させるためには、より多くの機能を使うことになります。Sharepoint や Dropbox その他の同期ソフトウェアとは異なり、Git は自動的にオンラインのものに基づいてローカルのリポジトリを更新したり、その逆を行ったりしません。いつ、どのように同期させるかは、あなたが決めることです。\n\ngit fetch は、リモートリポジトリから新しい変更点をダウンロードしますが、ローカルリポジトリは変更しません。リモートリポジトリの状態をチェックしていると考えてください。\ngit pull は、リモートリポジトリから新しい変更点をダウンロードして、ローカルリポジトリを更新します。\nローカルで 1 つまたは複数のコミットを行った後、そのコミットをリモートリポジトリに git push できます。これにより、変更が Github 上に送信され、他の人が変更点を確認したり、必要に応じてプルできます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#始める-新規リポジトリを作成",
    "href": "new_pages/collaboration.jp.html#始める-新規リポジトリを作成",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.5 始める: 新規リポジトリを作成",
    "text": "46.5 始める: 新規リポジトリを作成\n新規リポジトリを作成する方法はたくさんあります。コンソールからでも、Github からでも、GUI からでも可能です。\n2 つの方法があります。\n\n既存または新規の Github リポジトリから新規 R プロジェクトを作成する (初心者の方にお勧めです)。または\n既存の R プロジェクトに Github リポジトリを作成する。\n\n\n最初に作成するファイル\n新規リポジトリを作成する際に、オプションで以下のファイルをすべて作成することもできますし、後からリポジトリに追加することもできます。これらのファイルは通常、リポジトリの “root” フォルダーに置かれます。\n\nREADME ファイルとは、あなたのプロジェクトがなぜ存在するのか、そしてそれを使うために何を知っておくべきなのかを理解するために、誰かに読んでもらうためのファイルです。最初は空ですが、後で完成させましょう。\n.gitignore ファイルとは、Git が無視すべき (変更を追跡しない) フォルダやファイルを各行に記述したテキストファイルのことです。詳細や例は こちら を参照ください。\n自分の作業に対して、ライセンスを選ぶことができます。他の人々は、どのような条件であなたの成果を使用したり複製したりできるかを知ることができます。詳しくは、Creative Commons licensesをご覧ください。\n\n\n\nGithub で新規リポジトリを作成する\n新規リポジトリを作成するには、Github にログインし、新規リポジトリを作成する緑色のボタンを探してください。新規の空リポジトリは、ローカルコンピュータにクローンできます（次のセクションを参照）。\n\n\n\n\n\n\n\n\n\nリポジトリを public （インターネット上で誰でも見ることができる）にするか private （許可を得た人だけが見ることができる）にするかを選択する必要があります。これは、データが機密である場合に重要な意味を持ちます。リポジトリがプライベートの場合、Github actions を使ってコードをクラウド上で自動的に実行する場合など、高度で特別な状況では、いくらかの課金が発生します。\n\n\nGithub リポジトリからのクローン\n既存の Github リポジトリをクローンして、コンピュータ上に新規ローカル R プロジェクトを作成することができます。\nGithub リポジトリは、すでに存在していてコンテンツが含まれているものでも、作成したばかりの空のリポジトリでもよいです。後者の場合、基本的には Github リポジトリとローカル R プロジェクトを同時に作成することになります（上記の説明を参照）。\n注釈：Github リポジトリのコントリビュート権を持っていない場合は、まずそのリポジトリを自分のプロファイルに フォーク (fork)してから、他の作業を進めることができます。フォークについては本章の最後で説明しますが、まずは他のセクションをお読みになることをお勧めします。\nステップ1： Github でリポジトリに移動し、緑色の “Code” ボタンをクリックして、HTTPS クローン URL をコピーします（以下の画像を参照）。\n\n\n\n\n\n\n\n\n\n次のステップは、どのような GUI でも実行できます。ここでは、RStudio と Github デスクトップを例に説明します。\n\nRStudio の場合\nRStudio で、File &gt; New Project &gt; Version Control &gt; Git をクリックして、新規 R プロジェクトを開始します。\n\n“Repository URL” を聞かれたら、Github から HTTPS URL を貼り付けます。\nR プロジェクトに短くてわかりやすい名前をつけます。\n新規 R プロジェクトをローカルに保存する場所を選択します。\n“Open in new session” にチェックを入れ、“Create project” をクリックします。\n\nこれで、Github リポジトリのクローンである、新規のローカル RStudio プロジェクトが開きました。また、このローカルプロジェクトと Github リポジトリがリンクされました。\n\n\nGithub Desktop の場合\n\nFile &gt; Clone a repository をクリックします。\nURL タブを選択します。\n最初のボックスに Github からの HTTPS URL をペーストする。\nローカルリポジトリを作成するフォルダを選択する。\n“CLONE” をクリックする。\n\n\n\n\n\n\n\n\n\n\n\n\n\n既存の R プロジェクトからの新規 Github リポジトリの作成\n別の設定方法として、コンテンツを含む既存の R プロジェクトがある場合、ここから Github リポジトリを作成します。\n\nプロジェクトのために、新規の空 Github リポジトリを作成します（上記の手順を参照）。\nこのリポジトリをローカルにクローンします（上記の HTTPS の手順を参照）。\n既存の R プロジェクトからすべてのコンテンツ（コード、データなど）を、この新規の空ローカルリポジトリにコピーします（例：コピー＆ペーストを使用）。\nRStudio で新規プロジェクトを開き、Git ペインに移動します。新規ファイル群はファイルの変更として登録され、Git によって追跡されるようになります。したがって、これらの変更をコミットとして束ねて、Github にプッシュできます。一旦プッシュすると、Github 上のリポジトリにすべてのファイルが反映されます。\n\nこのプロセスの詳細については、以下の Github のワークフローのセクションを参照してください。\n\n\nどのように見えますか？\n\nRStudio の場合\nGithub リポジトリを新規 R プロジェクトにクローンすると、RStudio に “Git” タブが表示されます。このタブは、R Environment と同じ RStudio のペインに表示されます。\n\n\n\n\n\n\n\n\n\n上の画像で丸で囲ったボタンは、後に参照するので注意してください（左から順に）。\n\n保存したファイルの変更をローカルブランチに Commit するボタン（新しいウィンドウが開きます）。\n青色の矢印で Pull （ローカル版のブランチに、そのブランチのリモート / Github 版で行われた変更を反映させる）\n緑の矢印で Push (ローカルバージョンのブランチのコミットや変更を、そのブランチのリモート / Github バージョンに送信)\nRStudio の Git タブ\n右側に表示されているローカルブランチをベースにして、新しいブランチを作成するためのボタン。ほとんどの場合、main ブランチからブランチを作成します。\n現在作業しているブランチ\nコードや他のファイルに加えた変更は、以下のように表示されます。\n\n\n\nGithub Desktop の場合\nGithub Desktop は、すべてのリポジトリを管理するための独立したアプリケーションです。Github Desktop を開くと、作業したいリポジトリを選択して、そこから Git の基本的な操作を行うことができます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#git-github-作業の流れ",
    "href": "new_pages/collaboration.jp.html#git-github-作業の流れ",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.6 Git + Github 作業の流れ",
    "text": "46.6 Git + Github 作業の流れ\n\n流れの概要\n上記のセットアップが完了すると、ローカルの R プロジェクトに接続された（クローンされた）Github レポジトリができあがります。(デフォルトで作成される) main ブランチは、いわゆる “live” バージョンで、 すべてのファイルが含まれています。修正を加えたいときには、main ブランチから new branch を作成するのがよいでしょう (“Make a Copy” のように)。 ブランチの作成は簡単で速く、Git の典型的な作業の進め方になります。\n典型的な作業の流れは次のとおりです。\n\nローカルリポジトリが最新であることを確認し、そうでない場合は更新します\n以前作業していたブランチに移動するか、新しいブランチを作成していくつかのことを試してみます\nローカルコンピュータでファイルを編集し、このブランチに 1 回または数回コミットします\nブランチのリモートバージョンに対し、あなたの変更で更新します（プッシュ）\nブランチに満足したら、作業用ブランチのオンライン版をオンラインの “main” ブランチにマージして、変更を移行します\n\n他のチームメンバーも、各々のブランチで同じことをしているかもしれませんし、あなたと同じ作業ブランチにコミットを追加しているかもしれません。\n以下では、上記のプロセスを順を追って詳しく説明します。ここでは、私たちが作成した概略図を紹介します。二元配置の表形式になっているので、疫学業務担当者にも理解しやすいでしょう。\n\n\n\n\n\n\n\n\n\nここに別の図があります。\n注釈：最近まで “master” ブランチという言葉が使われていましたが、現在は “main” ブランチと呼ばれています。\n\n\n\n\n\n\n\n\n\n画像ソース",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#新規ブランチを作成",
    "href": "new_pages/collaboration.jp.html#新規ブランチを作成",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.7 新規ブランチを作成",
    "text": "46.7 新規ブランチを作成\n作業するブランチを選択すると、Git は作業ディレクトリを、前回、選択したブランチで作業したときの状態にリセットします。\n\nRStudio の Git ペインの場合\n“main” ブランチにいることを確認し、紫のアイコンをクリックして新しくブランチを作成します（上の画像を参照）。\n\nブランチの名前を、一言で説明できる名前にするよう求められます（必要に応じてアンダースコアを使用できます）。\nローカルでは、同じ R プロジェクトに属していますが、“main” ブランチでの作業ではなくなっていることがわかります。\n新規ブランチを作成すると、Github のウェブサイトでもブランチとして表示されるようになります。\n\nブランチは、RStudio の Git ペインで History をクリックすると表示されます。\n\n\n\n\n\n\n\n\n\n\n\nGithub Desktop の場合\nこのプロセスは上記と非常によく似ており、ブランチに名前を付けるよう促されます。その後、“Publish you branch to Github” というプロンプトが表示され、新規ブランチがリモートリポジトリにも表示されるようになります。\n\n\n\n\n\n\n\n\n\n\n\nConsole の場合\n舞台裏で実際に行われているのは、git branch で新しくブランチを作成し、git checkout でそのブランチに移動することです (つまり、次のコミットがそのブランチで行われることを Git に伝えます)。あなたの git リポジトリで以下のコマンドを実行することと等しいです。\n\ngit branch my-new-branch  # 新規にブランチを作成\ngit checkout my-new-branch # 作成したブランチに移動\ngit checkout -b my-new-branch # 上の 2 つを同時に行う\n\nConsole の使い方については、末尾の Git コマンドの項を参照してください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#変更をコミット",
    "href": "new_pages/collaboration.jp.html#変更をコミット",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.8 変更をコミット",
    "text": "46.8 変更をコミット\nこれで、コードの編集や新規ファイルの追加、データセットの更新などができるようになりました。\nすべての変更は、それぞれのファイルが保存された時点から追跡されます。変更されたファイルは RStudio の Git タブ、Github Desktop、またはターミナルの git status コマンドで表示されます (下記参照)。\n実質的な変更 (コードへセクションの追加や更新など) を行った場合は、必ず一旦作業を停止して、その変更をコミットしてください。コミットとは、共通の目的に関連した変更の「カタマリ」と考えてください。変更をコミットした後でも、ファイルの修正を続けることは可能です。\nコミットに関するアドバイス: 一般的には、問題が発生したときに簡単に元に戻せるような小さなコミットを行い、共通の目的に関連する変更をまとめてコミットするのが良いでしょう。これを実現するためには、頻繁にコミットすることが必要です。最初のうちは、頻繁にコミットすることを忘れてしまうかもしれませんが、そのうちに習慣になります。\n\nRStudio の場合\n以下の例では、前回のコミット以降、R Markdown スクリプト「collaboration.Rmd」が変更され、いくつかの PNG 画像が追加されています。\n\n\n\n\n\n\n\n\n\nファイル名の横にある黄色、青、緑、赤の四角は何を表しているのか気になりますよね。下記が、RStudio cheatsheet からのスクリーンショットで、その意味を説明しています。なお、黄色の「？」がついた変更でも、ステージ、コミット、プッシュは可能です。\n\n\n\n\n\n\n\n\n\n\nGit タブの “Commit” ボタンを押すと、新しいウィンドウが開きます（下図）。\n左上のボックスにあるファイル名をクリックします。\nそのファイルに加えた変更を確認します（以下、緑または赤でハイライトされる）\nファイルをステージすると、その変更がコミットに反映されます。ファイル名の横にあるボックスにチェックを入れてください。あるいは、複数のファイル名をハイライトしてから “Stage” をクリックすることもできます。\n短くてわかりやすい コミット・メッセージを書く（必須）\n“Commit” ボタンを押します。成功またはエラーメッセージを示すポップアップ・ボックスが表示されます。\n\nこれで、さらに変更を加え、何度でもコミットすることができます。\n\n\n\n\n\n\n\n\n\n\n\nGithub Desktop の場合\n左側に変更されたファイルのリストが表示されます。テキストファイルを選択すると、右ペインに変更内容の概要が表示されます（この表示は、.docs や .xlsx などの複雑なファイルでは機能しません）。\n変更をステージするには、ファイル名の近くにある小さなボックスにチェックを入れます。このコミットに追加したいファイルを選択し、コミットに名前を付け、必要に応じてメッセージを付けて commit ボタンをクリックします。\n\n\n\n\n\n\n\n\n\n\n\nConsole の場合\n舞台裏では、ファイルを選択/ステージするための git add と、実際にコミットを行うための git commit という 2 つの機能が使われています。\n\ngit status # 変更を見る\n\ngit add new_pages/collaboration.Rmd  # コミットするファイルを選択 (= 変更をステージ)\n\ngit commit -m \"Github Desktop からコミットについて記述メッセージ\" # メッセージをつけて変更をコミット\n\ngit log  # 過去のコミットの情報を表示\n\n\n\n過去のコミットを修正\nある変更をコミットして作業を続けているうちに、（あなたの考えでは）過去のコミットに「属する」べき変更を行ったことに気付いた場合、どうなるでしょうか。 心配ありません。これらの変更は、前のコミットに追加することができます。\nRStudio では、COMMIT ボタンと同じ行に “Amend previous commit” ボックスがあるので、とてもわかりやすいはずです。\n理由は不明ですが、Github Desktop ではこの機能は実装されていません。コミットはしたが、まだプッシュはしていない場合、COMMIT ボタンのすぐ下に “UNDO” ボタンが表示されます。このボタンをクリックすると、コミットを元に戻すことができます（ただし、ステージされたファイルと コミット・メッセージは保持されます）。 変更内容を保存し、必要に応じて新規ファイルをコミットに追加し、再度コミットします。\nConsole では\n\ngit add [YOUR FILES] # 変更をステージ\n\ngit commit --amend  # 以前のコミットを修正\n\ngit commit --amend -m \"コミット・メッセージの更新\"  # 以前のコミットを修正「かつ」コミット・メッセージを更新\n\n注釈: すでに公開されており他の共同作業者と共有しているコミットを変更する前に、もう一度考えましょう。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#プルしてから変更を-github-にプッシュ",
    "href": "new_pages/collaboration.jp.html#プルしてから変更を-github-にプッシュ",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.9 プルしてから、変更を Github にプッシュ",
    "text": "46.9 プルしてから、変更を Github にプッシュ\n「まずプルしてからプッシュする」\nプロジェクトに取り掛かる前にフェッチしてプルし、ローカルコンピュータ上のブランチバージョンをリモート/Github バージョンで行われた変更に更新するのは良い習慣です。 プルは頻繁に行いましょう。躊躇することはありません。プッシュする前に必ずプルしましょう。\n変更が完了してコミットし、プロジェクトの状態に満足したら、コミットした内容をブランチのリモート/Github バージョンにプッシュします。\nリポジトリで作業している間は、この作業を繰り返します。\n注釈: リモートリポジトリにプッシュされた変更(そしておそらく他の人が既にプルした変更)を元に戻すよりも、コミットされたがプッシュされていない（つまりローカルに残っている）変更を元に戻す方がはるかに簡単なので、作業していたタスクの変更が終わった後でプッシュすると良いでしょう。\n\nRStudio の場合\nPULL - まず、フェッチとプルを同時に行う “Pull” アイコン（下向き矢印）をクリックします。\nPUSH - 緑色の “Push” アイコン（上向き矢印）をクリックします。Github のユーザー名とパスワードの入力を求められることがあります。最初に尋ねられたときには、2 つの Git コマンドラインを Terminal に入力する必要があるかもしれません。\n\ngit config –global user.email “you@example.com” （Github アカウントのメールアドレス）を設定\ngit config –global user.name “Github ユーザー名”\n\nこれらのコマンドの入力方法については、以下の Git コマンドのセクションを参照してください。\nヒント： パスワードの入力を頻繁に求められますか？SSH キーを使ってリポジトリに接続するには、このチュートリアルの 10 章と 11 章を参照してください（より複雑です）\n\n\nGithub Desktop の場合\n“Fetch origin” ボタンをクリックすると、リモートリポジトリに新しいコミットがあるかどうかを確認できます。\n\n\n\n\n\n\n\n\n\nGit がリモートリポジトリで新しいコミットを見つけると、このボタンは “Pull” ボタンに変わります。プッシュとプルに同じボタンが使われるので、事前にプルしておかないと変更をプッシュできません。\n\n\n\n\n\n\n\n\n\n“History” タブ（“Changes” タブの近く）に行くと、すべてのコミット（自分のコミットと他の人のコミット）を見ることができます。これは、共同作業者が何をしたかを知るための良い方法です。 コミット・メッセージや説明文がある場合はそれを読み、diffペインを使って 2 つのファイルのコードを比較することができます。\n\n\n\n\n\n\n\n\n\nすべてのリモートの変更がプルされ、少なくとも1つのローカルの変更がコミットされたら、同じボタンをクリックしてプッシュすることができます。\n\n\n\n\n\n\n\n\n\n\n\nConsole の場合\nなななんと！コマンド名は fetch と pull と push です。\n\ngit fetch  # リモートに新しいコミットはあるか?\ngit pull   # リモートのコミットをローカルブランチに持ってくる\ngit push   # ローカルへのコミットをリモートにプッシュ\n\n\n\nプルしたいがローカルで作業中である\nこの状況には時々遭遇します。 ローカルリポジトリで変更を加えたのに、リモートリポジトリにはあなたがプルしなかったコミットがあるという状況です。\nあなたのローカルの変更が上書きされる可能性があるので、Git はプルを拒否します。自分の変更を維持するための戦略はいくつかあります。Happy Git with Rでよく説明されていますが、その中でも主なものは次の 2 つです。\n\n変更をコミットし、リモートの変更を取得して、それを取り込み、必要に応じて衝突を解決して (後述のセクションを参照ください)、すべてをオンラインにプッシュする\n変更を「スタッシュ」し、プルしてスタッシュを解除 (復元) してから、コミットして衝突を解決してプッシュする。\n\nリモートでの変更に関連するファイルとローカルでの変更に関連するファイルが重なっていない場合は、Git は自動的にコンフリクトを解決することができます。\nGithub Desktop では、この操作をボタンで行うことができます。スタッシュするには、Branch &gt; Stash all changes と進みます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#ブランチをメインブランチにマージ",
    "href": "new_pages/collaboration.jp.html#ブランチをメインブランチにマージ",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.10 ブランチをメインブランチにマージ",
    "text": "46.10 ブランチをメインブランチにマージ\n変更が完了したら、その変更をメインブランチにマージする作業を始めましょう。状況に応じて、この作業を迅速に行うこともできますし、チームメイトを巻き込んで慎重にレビューや承認の手順を踏むこともできます。\n\nGithub Desktop でのローカル作業\nGithub Desktop を使ってローカルでブランチをマージすることもできます。まず、コミットを受け取る側のブランチ、つまり更新したい側のブランチに移動 (checkout) します。次に、メニューの Branch &gt; Merge into current branch をクリックします。インポート元のブランチを選択するボックスが表示されます。\n\n\n\n\n\n\n\n\n\n\n\nConsole の場合\nまず、変更を受け取るブランチに戻ります。これは通常は master ですが、別のブランチになることもあります。次に、作業中のブランチを master にマージします。\n\ngit checkout master  # master (あるいは、その他の branch) に戻る\ngit merge this_fancy_new_branch\n\nこのページでは、より高度なブランチ操作の例を示し、裏で何が起こっているかを少し説明しています。\n\n\nGithub でプル・リクエストの提出\n2 つのブランチを誰にも知らせずにマージすることも可能ですが、master ブランチに統合する前に、複数の人でマージについて議論したり調査したりすることがあります。このプロセスを支援するために、Github ではマージに関する議論を行うための機能として、プル・リクエスト (pull request, PR) を提供しています。\nプル・リクエスト（“PR”）とは、あるブランチを別のブランチにマージするためのリクエストです (「私の作業ブランチを “main” ブランチにプルしてほしい」というリクエストです)。 プル・リクエストには通常、複数のコミットが含まれます。プル・リクエストを受け入れてブランチにマージする前に、議論とレビューのプロセスが始まります。例えば、dplyr パッケージの githubでプル・リクエストの議論を読むことができます。\nプル・リクエスト（PR）は、下図のように Web サイトから直接送信することも、Github Desktop から送信することもできます。\n\nGithub リポジトリ（オンライン）にアクセスします。\n“Pull Requests” タブを表示し、“New pull request” ボタンをクリックします。\nドロップダウンメニューから、自分のブランチを main にマージするものを選択します。\nプル・リクエストの詳細なコメントを書き、“Create Pull Request” をクリックします。\n\n以下の画像では、“forests” というブランチが “main” にマージされるように選択されています。\n\n\n\n\n\n\n\n\n\nこれで、プル・リクエストが表示されるようになりました（以下の画像例）。\n\nタブの “Files changed” を確認すると、“main” ブランチがマージされた場合にどのように変化するかがわかります。\n右側には、Github ID をタグ付けすることで、チームのメンバーにレビューを要求することができます。main にマージするためには承認するレビューが 1 つ必要になるようにリポジトリの設定をすることもできます。\nプル・リクエストが承認されると、“Merge pull request” のボタンがアクティブになります。これをクリックします。\nマージが完了したら、以下の手順でブランチを削除します。\n\n\n\n\n\n\n\n\n\n\n\n\nコンフリクトの解決\n2 人の人間が同じ行を同時に変更すると、マージ・コンフリクトが発生します。Git はどちらのバージョンを残すかの判断はしませんが、コンフリクトが発生している場所を探すのには役立ちます。慌てないでください。 ほとんどの場合は、簡単に解決できます。\n例えば、Github の場合\n\n\n\n\n\n\n\n\n\nマージでコンフリクトが発生したら、そのファイルをエディターで開いてください。コンフリクトは文字列で示されます。\n\n\n\n\n\n\n\n\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD と ======= の間のテキストは、自分のローカルリポジトリから、======= と &gt;&gt;&gt;&gt;&gt;&gt;&gt; の間のテキストはもう一方のブランチ (origin や main などのブランチ) から来ています。\nどちらのバージョンのコードがいいかを決めて（あるいは、両方の変更点を含んだ 3 つ目のコードを書いて）、残りの部分を削除し、Git が付けたマーク (&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt; origin/master/your_branch_name) をすべて削除します。\nそして、ファイルを保存し、ステージし、コミットします。これが、マージされたバージョンを「公式」にするためのコミットです。その後、プッシュすることを忘れないでください。\nあなたと共同作業者の双方がプル＆プッシュを頻繁に行えば行うほど、コンフリクトは小さくなります。\n注釈：Console での操作に慣れてきたら、もっと多くの高度な merge オプションがあります（例：空白を無視する、共同作業者に優先権を与えるなど）。\n\n\nブランチの削除\nブランチが master にマージされて不要になったら、そのブランチを削除することができます。\n\n46.10.0.1 Github + RStudio\nGithub のリポジトリに行き、すべてのブランチを表示するボタンをクリックします（ブランチを選択するドロップダウンの横）。自分のブランチを見つけて、その横にあるゴミ箱アイコンをクリックします。ブランチの削除について詳しくはこちらをご覧ください。\n必ず、あなたのコンピュータのローカルでブランチを削除してください。これは自動的には行われません。\n\nRStudio から、main ブランチにいることを確認します。\nRStudio の “Terminal”（R コンソールの隣のタブ）で Git コマンドの入力に切り替え、次のように入力します。git branch -d branch_name、ここで “branch_name” は削除するブランチの名前です。\nGit タブを更新すると、ブランチは消えているはずです。\n\n\n\n46.10.0.2 Github Desktop の場合\n削除したいブランチをチェックアウトして、メニューの Branch &gt; Delete で削除してください。\n\n\n\nFork\nプロジェクトに貢献したいが権利がない場合や、個人的に使用するためにプロジェクトを更新したい場合には、 プロジェクトをフォークすることができます。フォークについての簡単な説明はこちらにあります。\nGithub で “Fork” ボタンをクリックします。\n\n\n\n\n\n\n\n\n\nこれでオリジナルのリポジトリがクローンされますが、あなたのプロファイルにもクローンされます。これで、Github 上に 2 つのバージョンのリポジトリが存在することになります。オリジナルのリポジトリは変更できませんが、クローンされたバージョンはあなたのプロファイルにあります。\n次に、前述のセクションで説明した方法のいずれかを使って、オンラインリポジトリの自分のプロファイル上のバージョンをローカルコンピュータにクローンします。 その後、新規ブランチを作成し、変更を加えてコミットし、リモートリポジトリにプッシュします。\n結果が十分だと判断したら、Github または Github Desktop からプル・リクエスト を作成して、元のリポジトリのオーナーやメンテナと会話を始めることができます。\n公式リポジトリの最新のコミットが必要な場合は？\n誰かが公式リポジトリに重要な変更を加え、それをあなたのクローンバージョンに含めたいとします。自分のフォークと公式リポジトリを同期させることは可能です。ターミナルを使うことになりますが、それほど複雑ではありません。 ほとんどの場合、次のことを覚えておく必要があります。\n\nupstream = 公式リポジトリ、あなたが変更できなかったリポジトリ\norigin = あなたの Github プロファイルにあるリポジトリのバージョン\n\nこのチュートリアル をお読みいただくか、以下の手順で進めてください。\nまず、Git ターミナル（あなたのリポジトリ内）で次のように入力します。\n\ngit remote -v\n\nupstream のリポジトリをまだ設定していない場合は、origin で始まる 2 行が表示されます。この行は、fetch と push が指すリモートリポジトリを示しています。覚えておいてほしいのは、origin は Github 上にある自分のリポジトリ示しているいうことです。例えば\n\n\n\n\n\n\n\n\n\nここで、新規リモートリポジトリを追加します。\n\ngit remote add upstream https://github.com/appliedepi/epiRhandbook_eng.git\n\nここでのアドレスは、Github がリポジトリをクローンしたときに生成するアドレスです (クローンについてのセクションを参照)。これで、4 つのリモート参照（ポインタ）ができています。\n\n\n\n\n\n\n\n\n\nこれで設定は完了したので、元の（upstream）リポジトリから変更を取得したいときはいつでも、更新したいブランチに行って（checkout）、以下コマンドを入力すればいいのです。\n\ngit fetch upstream # リモートリポジトリから新しいコミットを取得\ngit checkout the_branch_you_want_to_update\ngit merge upstream/the_branch_you_want_to_update  # upstream ブランチを自分のブランチにマージ\ngit push # 自分の remote リポジトリを更新\n\nコンフリクトが発生した場合は、「コンフリクトの解決」で説明しているように、解決しなければなりません。\n要約: フォークはクローンすることと同義ですが、Github サーバー側で行います。 残りの作業は、典型的な共同作業の流れに沿った実作業です（クローン、プッシュ、プル、コミット、マージ、プル・リクエストの提出…）。\n注釈：フォークは概念であって Git コマンドではありませんが、Bitbucket など他のホストにもあります。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#学んだこと",
    "href": "new_pages/collaboration.jp.html#学んだこと",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.11 学んだこと",
    "text": "46.11 学んだこと\n以下のことを学びました。\n\nGit を設定して、自分のフォルダの変更を追跡する。\nローカルのリポジトリを、リモートのオンラインリポジトリに接続する。\n\n変更をコミットする。\n\nローカルとリモートのリポジトリを同期させる。\n\n疫学業務担当者としての必要なことは、これだけでほぼ十分でしょう。私たちは通常、ソフトウェア開発者のような高度な使い方はしません。\nしかし、もっと高度なことをしたい（あるいはする必要がある）場合、Git にはコミットの履歴を単純化したり、1 つまたは複数のコミットを戻したり、コミットを cherry-pick（訳注：いいとこ取り、cherry-pick はgit のコマンドの一つ）したりといった、より強力な機能があることを知っておいてください。 このようなことをすると、まるで魔法のように聞こえるかもしれませんが、すでに基本的な知識を身につけているので、知識を積み上げるすることが容易になるのです。\nRStudio の Git ペインや Github Desktop は、初心者や日々の仕事での使用には適していますが、中級者や上級者向けの Git 機能への GUI は提供していないことに注意してください。 より完成度の高い GUI では、カーソル操作でより多くのことができるようになります（通常は、より複雑なレイアウトを犠牲にして）。\nリポジトリの追跡にはどんなツールでも使うことができるので、たまに試してみたいときやあまり一般的ではない複雑な作業をするときには GUI をインストールし、それ以外のときにはシンプルな GUI を使うということも簡単にできるということを覚えておきましょう （たとえば、ほとんどの時間は Github Desktop を使い、特定の作業をするときには SourceTree や Gitbash に切り替えるなど）。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#git",
    "href": "new_pages/collaboration.jp.html#git",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.12 Git コマンド",
    "text": "46.12 Git コマンド\n\nおすすめの学習方法\nGit のコマンドをインタラクティブなチュートリアルで学ぶには、このウェブサイトを参照してください。\n\n\nコマンドを入力する場所\nGit シェルでコマンドを入力します。\n選択肢 1 RStudio で新しく Terminal を開くことができます。このタブは R Console の隣にあります。文字が入力できない場合は、“Terminal” の下のドロップダウンメニューをクリックし、“New terminal” を選択します。ドル記号 “$” の後の点滅しているスペースにコマンドを入力します。\n\n\n\n\n\n\n\n\n\n選択肢 2 Git タブ（RStudio Environment ペインの近く）の青い「歯車」アイコンをクリックして、shell（コマンドを入力するターミナル）を開くこともできます。ドロップダウンメニューから “Shell” を選択します。新しいウィンドウが開くので、ドル記号 “$” の後にコマンドを入力します。\n選択肢 3 右クリックして “Git Bash here” を開くと、同じようなターミナルが表示されます。Git Bash の見つけ方、必要な bash コマンドなど、初心者向けの情報をご紹介します。\n\n\nサンプルコマンド\n以下では、一般的な git コマンドをいくつか紹介します。これらのコマンドを使う際には、どのブランチがアクティブ (チェックアウト済み) なのかを覚えておきましょう。\n以下のコマンドでは、&lt;name&gt; はブランチの名前を表します。 &lt;commit_hash&gt; は、特定のコミットのハッシュIDを表します。&lt;num&gt; は数字を表します。 &lt; と &gt; 記号は入力しないでください。\n\n\n\n\n\n\n\nGit コマンド\n内容\n\n\n\n\ngit branch &lt;name&gt;\n新規にブランチ &lt;name&gt; を作成\n\n\ngit checkout &lt;name&gt;\nブランチ &lt;name&gt; に移動\n\n\ngit checkout -b &lt;name&gt;\n新規にブランチを作成し移動\n\n\ngit status\n変更を見る\n\n\ngit add &lt;file&gt;\nファイルをステージ\n\n\ngit commit -m &lt;message&gt;\n現在のブランチにステージされた変更をメッセージ付きでコミット\n\n\ngit fetch\nリモートリポジトリからコミットをフェッチ\n\n\ngit pull\n現在のブランチのリモートリポジトリからコミットをプル\n\n\ngit push\nローカルのコミットをリモートにプッシュ\n\n\ngit switch\ngit checkout と同じ、今後はこちらに移行\n\n\ngit merge &lt;name&gt;\nブランチ &lt;name&gt; を現在のブランチにマージ\n\n\ngit rebase &lt;name&gt;\n現在のブランチから &lt;name&gt; へのコミットを修正",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.jp.html#参考資料",
    "href": "new_pages/collaboration.jp.html#参考資料",
    "title": "46  Git と Github を使ったバージョン管理と共同作業",
    "section": "46.13 参考資料",
    "text": "46.13 参考資料\nこの章の多くは、Jenny Bryan 氏によるこの “Happy Git with R”ウェブサイトを参考にしています。このウェブサイトには、Git や R に関連する一般的なエラーのトラブルシューティングに役立つセクションが用意されています。\nGithub.com documentation and start guideをご覧ください。\nRStudio の “IDE” cheatsheet には、RStudio での Git に関するヒントがあります。\nhttps://ohi-science.org/news/github-going-back-in-time\n初心者のための Git コマンド\nGit コマンドを学ぶためのインタラクティブチュートリアル。\nhttps://www.freecodecamp.org/news/an-introduction-to-git-for-absolute-beginners-86fa1d32ff71/: 自分のコンピュータ上の 1 つのフォルダの変更を追跡するための絶対的な基本を学ぶのに適しています。\nブランチを理解するための良い図解があります。https://speakerdeck.com/alicebartlett/git-for-humans\n基本的なことからより高度なことまでをカバーするチュートリアル\nhttps://tutorialzine.com/2016/06/learn-git-in-30-minutes\nhttps://dzone.com/articles/git-tutorial-commands-and-operations-in-git https://swcarpentry.github.io/git-novice/ (ショートコース) https://rsjakob.gitbooks.io/git/content/chapter1.html\nPro Git book は、公式のリファレンスとされています。 いくつかの章は大丈夫でしょうが、おおむね 技術的な内容になっています。Git を少し使ってみて、何が起こっているのか、どうすればいいのかをもう少し正確に知りたいと思ったら、この本はいい資料になるでしょう。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Git と Github を使ったバージョン管理と共同作業</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.jp.html",
    "href": "new_pages/errors.jp.html",
    "title": "47  よくあるエラー",
    "section": "",
    "text": "47.1 エラーメッセージの読み方\nR のエラーは不可解なことも多々あるので、Google が頼りになります。エラーメッセージを “R” で検索し、StackExchange.com、stackoverflow.com、community.rstudio.com、twitter(#rstats)、その他プログラマーが質問や回答を提出するためのフォーラムで最近の投稿を探します。似たような問題を解決した最近の投稿を探してみてください。\nいくら探しても答えが見つからない場合は、再現可能な例（“reprex”）を作成して、自分で質問を投稿することを検討してください。再現可能な例を作成してフォーラムに投稿する方法については、ヘルプの章を参照してください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>よくあるエラー</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.jp.html#よくあるエラー",
    "href": "new_pages/errors.jp.html#よくあるエラー",
    "title": "47  よくあるエラー",
    "section": "47.2 よくあるエラー",
    "text": "47.2 よくあるエラー\n以下に、いくつかの一般的なエラーと、その説明や解決策の可能性を示します。ここの内容は、Stack Overflow で R のエラーメッセージに関する最も一般的なフォーラムの投稿を分析した Noam Ross 氏の意見を部分的に参考にしています（分析結果はこちらをご覧ください）。\n\n打ち間違いエラー\nError: unexpected symbol in:\n  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\"\nエラー:   想定外のシンボルです  以下の部分: \n  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\"\n想定外のシンボル（“unexpected symbol”） と表示された場合は、カンマが抜けていないか確認してください。\n\n\nパッケージエラー\ncould not find function \"x\"...\n関数 \"x\" を見つけることができませんでした \nこれは、関数名を間違って入力したか、パッケージをインストールまたは読み込み忘れた可能性があります。\nError in select(data, var) : unused argument (var)\nselect(data, var) でエラー:使われていない引数 %s\n自分では dplyr::select() を使っているつもりでも、実際は select() 関数が MASS::select() によってマスクされています。dplyr:: を指定するか、パッケージの読み込み順を変えて、dplyr が他のパッケージの後に来るようにしてください。\nマスクされたことによるエラーは、この他に plyr::summary() や stats::filter() でよく発生します。conflicted パッケージの使用を検討してください。\nError in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’\ninstall.packages でエラー: ディレクトリ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’の変更を禁止にできません。 \n‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’を削除してください\nもし、“00LOCK” ファイルを削除なさいというエラーが出た場合、コンピュータのディレクトリにある “R” ライブラリ（例：R/win-library/）に行き、“00LOCK” というフォルダを探してください。これを手動で削除して、再度パッケージをインストールしてみてください。以前、インストール作業を中断してこの状態になったと考えられます。\n\n\nオブジェクトのエラー\nNo such file or directory:\nエクスポートまたはインポートしようとしたときにこのエラーが表示される場合は、次のことを確認してください。ファイルとファイルパスのスペルを確認してください。また、パスにスラッシュが含まれている場合は、前向きのスラッシュ / であり、後ろ向きのスラッシュ \\ （バックスラッシュ）ではないことを確認してください。また、正しいファイル拡張子を使用していることを確認してください（例：.csv、.xlsx）。\nobject 'x' not found \nエラー:  オブジェクト 'x' がありません \nこれは、参照しているオブジェクトが存在していないことを意味します。ここよりも前のコードが正しく実行されなかったのではないでしょうか？\nError in 'x': subscript out of bounds\n'x' でエラー : 添え字が許される範囲外です\nこのエラーは、存在しないもの（ベクトルやリストの要素）にアクセスしようとしたことを意味します。\n\n\n関数の文法エラー\n# mutate(x = recode(x, OLD = NEW) で変数 x を再定義せずに recode を実行した\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`.\n引数 \".x\" がありませんし、省略時既定値もありません \n上記のエラー（argument .x is missing, with no default）は、mutate() において、recode() や replace_na() のように、第一引数にカラム名を指定することが期待される関数を指定している場合によく見られます。よく忘れることがあります。\n\n\nロジカルに関連するエラー\nError in if\nif (...) { でエラー: \nこのエラーは、TRUE・FALSEで判定できないものに if 文が適用されたために発生したと考えられます。\n\n\n因子型のエラー\n# 因子型に、許されていない値 (\"Missing\") を追加しようとする ( replace_na をオプションで使用)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated\nこのエラーは無効な因子型の水準（level）に関するものです。このエラーが表示された場合、因子型（あらかじめ定義されたレベルを含む）の列があり、そこに新しい値を追加しようとした可能性があります。新しい値を追加する前に、文字列型に変換してください。\n\n\nプロットのエラー\nError: Insufficient values in manual scale. 3 needed but only 2 provided.\n例えば、ggplot() 関数の scale_fill_manual() オプションを values = c(“orange”, “purple”) と設定していた場合、因子型の水準の数が十分ではありません。NA が正しく因子型の水準になっているかどうかを確認してください。\nCan't add x object\nggplot のコマンドの最後に余分な + がついていると思われます。削除しましょう。\n\n\nR Markdown エラー\nエラーメッセージに Error in options[[sprintf(\"fig.%s\", i)]] のような内容が含まれている場合は、各チャンクの先頭にある knitr のオプションが、out.width = または out.height = を正しく使用しており、fig.width = および fig.height = を使用していないことを確認してください。\n\n\nその他\nパイプされた dplyr 動詞を再配置して、途中でパイプを交換しなかったのか、再配置した後に最後からパイプを削除し忘れていないかを確認してください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>よくあるエラー</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.jp.html#参考文献",
    "href": "new_pages/errors.jp.html#参考文献",
    "title": "47  よくあるエラー",
    "section": "47.3 参考文献",
    "text": "47.3 参考文献\nこちらは、Rのよくあるエラーについてのブログです: R programming errors faced by beginners",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>よくあるエラー</span>"
    ]
  },
  {
    "objectID": "new_pages/help.jp.html",
    "href": "new_pages/help.jp.html",
    "title": "48  ヘルプ",
    "section": "",
    "text": "48.1 Github に Issue を投稿する\n多くの R パッケージやプロジェクトのコードは、 Github.com にアップロードされています。Github に「Issue」を投稿することで、パッケージやプロジェクトの作成者と直に連絡をとることができます。\n作成した R パッケージやプロジェクトを Github にアップロードする方法は、第 46 章 Git と Github を使用したバージョン管理と共同作業の章で詳しく説明しています。\nGithub では、各プロジェクトがリポジトリに保管されます。各リポジトリには、コード、データ、アウトプット、ヘルプドキュメントなどが含まれています。また、「Issues」と呼ばれる作成者とのコミュニケーションの手段もあります。\n下の図は、incidence2 パッケージ（流行曲線（エピカーブ）を作成するために使用）の Github ページです。黄色で着色された箇所が「Issues」タブです。このパッケージには、5 つの Issue （未解決の質問、問題点、不具合の修正リクエスト等）があることがわかります。\n「Issues」タブを開くと、現在までに投稿されている Issue が表示されます。自分の質問や修正リクエストを新たに Issue として投稿する前に、既に投稿されている Issue に目を通し、同じ質問や修正リクエストがすでに投稿されていないかを確認しましょう。まだ投稿されていない場合は、右側にある緑色の「New issue」ボタンをクリックし、新しい Issue を作成・投稿することができます。新しい Issue の作成には、Github アカウントが必要です。\n新たに Issue を投稿する際は、以下で説明する方法で、最低限の再現可能なサンプルコード（reprex）を提示してください。また、Issue を投稿する際は R パッケージやプロジェクトの作成者に敬意を払い、あなたの質問や修正リクエストについて、丁寧に説明しましょう。R パッケージやプロジェクトの作成者の多くは、空き時間にボランティアで開発しています。（このハンドブックもそのような有志が集まって作成されました！）\n自分の Github リポジトリに投稿された Issue の取り扱い方法については、 Issue に関する Github のページをご覧ください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>ヘルプ</span>"
    ]
  },
  {
    "objectID": "new_pages/help.jp.html#再現可能なサンプルコードを作成する",
    "href": "new_pages/help.jp.html#再現可能なサンプルコードを作成する",
    "title": "48  ヘルプ",
    "section": "48.2 再現可能なサンプルコードを作成する",
    "text": "48.2 再現可能なサンプルコードを作成する\nオンラインフォーラムや Github の Issue に投稿する際には、再現可能なサンプルコード（英語で reprex と呼ばれる）を記載することが重要です。多くの人は、あなたが投稿した質問や不具合を解決するために、力を貸したいと思っています。第三者があなたの質問を理解し、解決の手助けをするためには、その問題を手元で再現できるサンプルコードが必要です。サンプルコードに必要な要件は以下の通りです。\n\nヘルプが必要な質問や問題を明確に説明する\n問題を再現するのに必要な最小限のデータとコードが含まれている\nすべてのオブジェクト（データ等）やパッケージを読み込むコード （library() や p_load()）が含まれているなど、再現性がある\n\n投稿する際は、機密データを含まないように注意してください！ 機密上の理由または他の理由で、実際に使用したデータをオンラインフォーラムや Github に投稿したくない、またはすべきでない場合は、データフレーム（data frame）を用いて別の異なるデータセットを作成する、または、R に組み込まれているデータセットを使用することをおすすめします（data() を入力すると、R に組み込まれているデータセットのリストが表示されます）。\n\nreprex パッケージとは？\nreprex パッケージを使用すると、再現可能なサンプルコードを簡単に作成することができます。\n\ntidyverse パッケージを読み込む（reprex は tidyverse パッケージに含まれています）。\n\n\n# tidyverse をインストールし、読み込む\npacman::p_load(tidyverse)\n\n\nR スクリプトで、投稿したい質問や問題のサンプルコードを作成する（パッケージやデータの読み込みに関するコードを始めに記載し、質問や問題について明確に説明するコードを段階的に書きましょう）。\n\n\n# 必要なパッケージを読む込む\npacman::p_load(\n     tidyverse,  # データ管理とデータ可視化のためのパッケージ\n     outbreaks)  # アウトブレイクについてのサンプルデータを提供するパッケージ\n\n# インフルエンザ流行曲線（エピカーブ）のラインリスト\noutbreak_raw &lt;- outbreaks::fluH7N9_china_2013  # outbreaks パッケージからデータを読み込む\n\n# データクリーニング（前処理）\noutbreak &lt;- outbreak_raw %&gt;% \n     mutate(across(contains(\"date\"), as.Date))\n\n# 流行曲線（エピカーブ）をプロットする\n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\n\n作成したコードをクリップボードにコピーし、以下のコマンドを実行します。\n\nreprex::reprex()\n\nRStudio の Viewer パネル（pane）に HTML で出力されたアウトプットが表示されます。このアウトプットには、すべてのコードと、警告メッセージ（warnings）、エラー、ならびに作成したプロットが含まれます。このアウトプットはクリップボードにもコピーされているので、Github の Issue やオンラインフォーラムに投稿する際、貼り付けて使用できます。\n\n\n\n\n\n\n\n\n\n\nsession_info = TRUE とした場合、sessioninfo::session_info() で出力されるアウトプットと、使用している R ならびに R パッケージのバージョンが表示されます。\nwd = 引数を使用した場合、作業ディレクトリを表示できます。\n引数についての詳細は、 こちらのページ を参照いただくか、 R で ?reprex コマンドを実行してください。\n\n上記で紹介したサンプルコードでは、 ggplot() 関数がエラーを引き起こしました。date_format = ではなく、date_labels = を使用する必要があります。\n\n\n最小限のデータとは？\n第三者があなたの質問に回答するためには、あなたのデータを使用する必要があります。理想は、第三者がコードを用いてデータを作成できることです。\n第三者が利用できる最小限のデータセットを作成するためには、データの匿名化や、実際のデータの一部のみを使用することが必要になります。\ndput() 関数を使用し、最小限のデータセットを作成することもできます（詳細については、後日追記します）。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>ヘルプ</span>"
    ]
  },
  {
    "objectID": "new_pages/help.jp.html#オンラインフォーラムに質問を投稿する",
    "href": "new_pages/help.jp.html#オンラインフォーラムに質問を投稿する",
    "title": "48  ヘルプ",
    "section": "48.3 オンラインフォーラムに質問を投稿する",
    "text": "48.3 オンラインフォーラムに質問を投稿する\n質問をオンラインフォーラムに投稿する前に、既に投稿されている質問をたくさん読み、上手に質問を説明している投稿と、そうではない投稿との違いを理解しましょう。質問を投稿する手順は、以下の通りです。\n\nまず、質問を投稿するかどうかを決めます。あなたの質問と同じ質問が既に投稿されていないか、そのフォーラムのウェブサイトを様々なキーワードで徹底的に検索しましょう。\n質問を投稿すると決めた場合、質問には、第三者にわかりやすい具体的なタイトルをつけましょう（「ヘルプが必要です！」「助けてください！」等、質問内容が明記されていないタイトルは避けましょう）。\n質問を書き始めます。質問を書く際の注意点は、以下の通りです。\n\n\n質問や問題に直面した状況とその問題を説明する\n似たような質問・問題の投稿に言及し、その投稿がどのようにあなたの質問に答えていないかを説明する\n第三者があなたの質問・問題についてよく理解するため、質問・問題に関連する情報を含める\n最低限の再現可能なサンプルコードを R セッションの情報（あなたがそのコードを実行した環境）とともに示す\nタイプミスや文法ミスに注意し、質問を段落に分けて読みやすくする\n\n\n質問投稿後は、投稿の更新状況を常にモニターし、第三者が更なる説明を求めた場合は、応答してください。ほとんどの回答者はボランティアであなたを助けています。回答者の方には、礼儀正しく、親切に対応しましょう。追加の質問がある場合は、先に投稿した質問内容に追加するべきか、別の質問として投稿すべきかを検討してください。\n回答が得られて質問が解決した場合は、投稿のステータスを解決済みに変更してください。解決済みのマークを付けることで、あなたと同じ質問をもつ他の人が、解決策を見つけやすくなります。\n\n良い質問をする方法についての詳細は、こちらの記事 や、 Stack Overflow の行動規範 をご覧ください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>ヘルプ</span>"
    ]
  },
  {
    "objectID": "new_pages/help.jp.html#参考資料",
    "href": "new_pages/help.jp.html#参考資料",
    "title": "48  ヘルプ",
    "section": "48.4 参考資料",
    "text": "48.4 参考資料\nTidyverse ウェブサイトのヘルプページは こちら\n最小限のデータセットを作成するためのヒントは こちら\ndput() 関数についての公式ドキュメントは こちら",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>ヘルプ</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.jp.html",
    "href": "new_pages/network_drives.jp.html",
    "title": "49  ネットワークドライブで R を使用する場合",
    "section": "",
    "text": "49.1 はじめに\nネットワークドライブや会社の共有ドライブで R を使用する場合、様々な問題が発生することがあります。この章では、ネットワークドライブで R を使用した場合によくあるエラーについて解説し、筆者の経験から得たアプローチ並びに対処法を提案します。また、R Markdown に関するヒントも紹介します。\nR をネットワークドライブで使用する場合の原則",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>ネットワークドライブで R を使用する場合</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.jp.html#はじめに",
    "href": "new_pages/network_drives.jp.html#はじめに",
    "title": "49  ネットワークドライブで R を使用する場合",
    "section": "",
    "text": "お使いのコンピュータの管理者権限が必要です。RStudio を管理者として実行するように設定してください。\nパッケージはできるだけ文字のあるドライブ（C: ドライブなど）のライブラリに保存してください。パスが 「\\」（バックスラッシュ）で始まるライブラリは、できるだけ使用しないでください。\nrmarkdown パッケージは、「\\」で始まるライブラリに保存しないでください。「\\」で始まるライブラリに保存した場合、TinyTex や Pandoc に接続できなくなります。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>ネットワークドライブで R を使用する場合</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.jp.html#管理者として-rstudio-を使用する",
    "href": "new_pages/network_drives.jp.html#管理者として-rstudio-を使用する",
    "title": "49  ネットワークドライブで R を使用する場合",
    "section": "49.2 管理者として RStudio を使用する",
    "text": "49.2 管理者として RStudio を使用する\nRStudio のアイコンを右クリックし、RStudio を開くと、「管理者として実行」のオプションが表示されます。お使いのコンピュータによっては、表示されない場合があります。その場合は、プロパティ（Properties）を開いてください。プロパティを開くと、「互換性（Compatibility）」オプションのあるウィンドウが表示されるので、「管理者として実行（Run as Administrator）」のチェックボックスにチェックを入れてください。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>ネットワークドライブで R を使用する場合</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.jp.html#便利なコマンド",
    "href": "new_pages/network_drives.jp.html#便利なコマンド",
    "title": "49  ネットワークドライブで R を使用する場合",
    "section": "49.3 便利なコマンド",
    "text": "49.3 便利なコマンド\nネットワークドライブ上で R を使用している際に直面した問題のトラブルシューティングに役立つコマンドをいくつか以下に紹介します。\nまず、R にインストール済みのパッケージが保存されている場所（ライブラリ）を知りたい場合は、以下のコードを実行するとライブラリのパスを確認できます。パスは、R がパッケージのインストール・読み込み・検索に使用している順序で表示されます。デフォルトライブラリを変更したい場合は、パスの順序を変更することでできます（2 つ下のコードを参照ください）。\n\n# ライブラリの場所を表示する\n.libPaths()                   # ライブラリパスを表示\n                              # 注意: 表示されたパスには全てのパッケージが含まれているが、C: 等いくつかのドライブに保存されたパッケージを表示するためには、\n                              # 管理者として RStudio を実行する必要がある場合もある\n                              # （管理者として実行しない場合は、install packages libraryのドロップダウンには表示されない）\n\nR がパッケージを検索する際に、「\\\\」で始まるライブラリや「D:」等の文字で始まる場所に保存されたライブラリを先に検索している場合は、R が検索するライブラリの順番を入れ替える必要があります。その場合は、以下のコードで .libPaths() の順序を変更することができます。\n\n# ライブラリの順序を変更する\n# 順序を変更することで、R がパッケージを検索する際の優先順位度が変更される。例えば、C: ドライブのライブラリを先に表示したい場合\nmyPaths &lt;- .libPaths() # パッケージライブラリのパスをオブジェクトにアサインする\nmyPaths &lt;- c(myPaths[2], myPaths[1]) # パスの順序を変更する\n.libPaths(myPaths) # 変更した順序のパスを再度アサインする\n\nR Markdown が Pandoc に接続する際にエラーが発生した場合は、以下のコードを使用して Pandoc が RStudio のどこにインストールされているかを確認できます。\n\n# Pandoc を探す\nSys.getenv(\"RSTUDIO_PANDOC\")  # Pandoc がどこにインストールされているか確認する\n\nどのライブラリからパッケージを読み込んでいるかを知りたい場合は、以下のコードを実行してください。\n\n# パッケージを探す\n# ライブラリの場所が表示される（複数のライブラリに保存されている場合は、最初のライブラリが表示される）\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\"))",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>ネットワークドライブで R を使用する場合</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.jp.html#よくあるエラー",
    "href": "new_pages/network_drives.jp.html#よくあるエラー",
    "title": "49  ネットワークドライブで R を使用する場合",
    "section": "49.4 よくあるエラー",
    "text": "49.4 よくあるエラー\n“Failed to compile…tex in rmarkdown” のエラーメッセージ\n\nTinyTex がインストールされているか確認してください。インストールされていない場合は、C: ドライブに TinyTex をインストールしてください。TinyTex のインストール方法については、R の基礎 の章をご覧ください。\n\n\n# tinytex がインストールされているか確認し、C: ドライブにインストールする\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # TRUE と表示されるはず (コロンが3つ必要なことに注意)\n\n“Internet routines cannot be loaded” のエラーメッセージ\n例）Error in tools::startDynamicHelp() : internet routines cannot be loaded\n\n32-bit 版の RStudio を試してみてください。RStudio の Tools/Global Options から 32-bit 版の R Studioに切り替えることができます。\n\n注意：32-bit 版の RStudio が Tools/Global Options の R Sessions/R version に表示されない場合は、お使いの RStudio のバージョンが古い（v1.2）場合があります。\n\nまたは、R をアンインストールし、32-bit 版の R をインストールしてください。\n\nパッケージをインストールする時に、C: ライブラリが選択できない\n\n管理者として RStudio を実行してください。管理者として実行すると、C: ライブラリが表示されます。\nRStudio を常に管理者として実行するように設定するには、RStudio アイコンを右クリックしてください。プロジェクトの RStudio アイコンをクリックして開かない R プロジェクトを開く場合に便利です。\n\n以下の画像は、パッケージのインストール先のライブラリを手動で選択する方法を示しています。RStudio の「パッケージ （Packages）」パネルを開き、「インストール（Install）」をクリックすると表示されます。\n\n\n\n\n\n\n\n\n\nPandoc Error 1 が表示された\nR Markdown ファイルをニット（knit）する際、「pandoc error 1」が表示された場合は、以下の方法で対処してください。\n\n複数のライブラリがある場合は、文字で始まるドライブ（C: ドライブ等）がライブラリの先頭になるように、ライブラリを並べ替えてください（前述の「便利なコマンド」セクションを参照してください）。\n上記の対処法は、インターネットが繋がっている時に筆者がローカルドライブで試し、成功した対処法です。\n詳細については、こちら（ https://ciser.cornell.edu/rmarkdown-knit-to-html-word-pdf/ ）をご覧ください。\n\nPandoc Error 83 が表示された\n対象のファイルが見つからなかった時に表示されるエラーです。 例）can't find file...rmarkdown...lua...\n解決法については、こちら（ https://stackoverflow.com/questions/58830927/rmarkdown-unable-to-locate-lua-filter-when-knitting-to-word ）をご覧ください。\n原因としては、以下の 3 つが考えられます。\n\nRmarkdown パッケージがインストールされていない\nRmarkdown パッケージが見つからない\n管理者権限に何かしら問題がある\n\nR が rmarkdown パッケージファイルを見つけられないことが原因でエラーが発生している可能性があるので、rmarkdown パッケージがどのライブラリにインストールされているか確認してください（前述の「便利なコマンド」セクションのコードを参照ください）。アクセスできないライブラリにパッケージがインストールされている場合（例：「\\\\」で始まるライブラリ）は、パッケージを手動で C: ドライブまたは他の名前付きドライブのライブラリに移すことをおすすめします。rmarkdown パッケージは TinyTex インストールに接続する必要があるため、ネットワークドライブ上のライブラリには置かないでください。\nPandoc Error 61 が表示された\n例）Error: pandoc document conversion failed with error 61 または Could not fetch...\n\nRStudio を管理者として実行してください。（RStudio アイコンを右クリックし、「管理者として実行」を選択してください。詳細は、前述の「管理者として RStudio を実行する」セクションをご覧ください。)\nアクセスできないライブラリにインストールされたパッケージは、C: ドライブ内のライブラリに移動してください。\n\nLaTex に関するエラー\n例）! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' not found: using draft setting. または Error: LaTeX failed to compile file_name.tex.\n\n対処法については、こちら（ https://yihui.org/tinytex/r/#debugging ）をご覧ください。\n\nfile_name.log ファイルを確認してください。\n\nPandoc Error 127 が表示された\nRAM（パソコンのメインメモリ）に関するエラーの可能性があります。実行中の R セッションをリスタート（re-start）してください。\nネットワークドライブの割り当てに関するエラー\nネットワークドライブの割り当て（マッピング）は、重大な問題を引き起こす場合があります。割り当てが必要な場合は、割り当てる前に情報システムを担当する部署に相談してください。\n割り当て済のネットワークドライブにあるファイルを開く際にヒントになり得る Stack Overflow フォーラムのコメント を下記に引用します。\n質問「割当済みのネットワークドライブにあるファイルを開く方法をおしえてください」に対する回答\n\nまず、アクセスしようとしているネットワークドライブのロケーション（ネットワークアドレス）を確認します。\n次に、Windows のエクスプローラーを開き、左パネルにある「PC」を右クリックし、「ネットワークドライブの割当」を選択します。\n表示されたダイアログボックスで、先程確認したロケーション（ネットワークアドレス）をドライブレター付きのドライブとして設定します。\nロケーション（ネットワークアドレス）を直接指定し、ファイルを開く方法と、ドライブレター付きのネットワークドライブからファイルを開く方法の 2 通りの方法が準備できました。ドライブレター付きのネットワークドライブが機能します。\n\ninstall.packages() に関するエラー\n例）Error in install.packages : ERROR: failed to lock directory...\nエラーメッセージに「lock directory」が含まれている場合、パッケージが保存されたライブラリを開き、ライブラリに「00LOCK」と名付けられたフォルダーがあるか確認してください。「00LOCK」フォルダーがあった場合の対処法は、以下の通りです。\n\n「00LOCK」フォルダーをライブラリから削除し、インストールに失敗したパッケージを再度インストールする。\npacman::p_unlock() を実行し、再度パッケージをインストールする。複数回の実行を必要とするかもしれない（pacman::p_unlock() を Rprofile に追加すると、R プロジェクトを開くたびに実行される）。\n管理者として RStudio を開き、1 つずつパッケージをインストールする。\n上記の 3 つの対処法のいづれも成功しなかった場合、インストールしたいパッケージを別のライブラリやフォルダー（Temp など）にインストールし、インストール後にパッケージが保存されたフォルダーを R がアクセスするライブラリに移す。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>ネットワークドライブで R を使用する場合</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html",
    "href": "new_pages/data_table.jp.html",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "",
    "text": "50.1 データテーブルの概要\nデータテーブル（data table）は、データフレームのような 2 次元のデータ構造であり、複雑なグルーピング操作を実行できます。data.table 構文は、行、列、およびグループに対して操作を実行できるように構成されています。\ndata.table 構文は DT[i, j, by] と表記され、i、j、by という 3 つの部品で構成されています。 i 引数を使用すると、必要な行をサブセット化できます。j 引数を使用すると、列を操作できます。by 引数を使用すると、グループごとに列を操作できます。\nこの章では、以下のトピックについて説明します。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#データテーブルの概要",
    "href": "new_pages/data_table.jp.html#データテーブルの概要",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "",
    "text": "データのインポートと fread() および fwrite() の使用\ni 引数を使用した行の選択とフィルタリング\nヘルパー関数 %like%、%chin%,、%between% の使用\nj 引数を使用した列の選択と計算\nby 引数を使用したグループごとの計算\n:= を使用してデータテーブルにデータを追加および更新する",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#パッケージの読み込みとデータのインポート",
    "href": "new_pages/data_table.jp.html#パッケージの読み込みとデータのインポート",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "50.2 パッケージの読み込みとデータのインポート",
    "text": "50.2 パッケージの読み込みとデータのインポート\n\nパッケージの読み込み\npacman パッケージの p_load() 関数を使用して、この分析に必要なパッケージを読み込み（および必要に応じてインストールし）ます。\n\npacman::p_load(\n  rio,        # データのインポート\n  data.table, # データのグループ化\n  tidyverse,  # この章でパイプ（%&gt;%）関数を使用可にする\n  here \n  ) \n\n\n\nデータのインポート\nこの章では、ハンドブック全体で参照されている症例ラインリストを使用して、data.table パッケージのコア機能のいくつかを説明します。\nエボラ出血熱の流行をシミュレートしたデータセットをインポートします。お手元の環境でこの章の内容を実行したい方は、クリックして「前処理された」ラインリスト（linelist）データをダウンロードしてください&gt;（.rds 形式で取得できます）。データは rio パッケージの import() を利用してインポートしましょう（rio パッケージは、.xlsx、.csv、.rds など様々な種類のファイルを取り扱うことができます。詳細は、インポートとエクスポート の章をご覧ください。）data.table() を使用してデータフレームをデータテーブルに変換します。\n\nlinelist &lt;- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %&gt;% data.table()\n\nfread() 関数は、.csv ファイルなどの普通の区切り付きファイルをデータテーブルに直接インポートするために使用されます。この関数と対を成す fwrite() は、普通の区切り付きファイルへデータテーブルを書き込むために使用されます。これらの関数は、大規模なデータベースにとって非常に高速で計算効率の高い選択肢です。\nlinelist の最初の 20 行を表示します。\nデータフレームに使用される dim() などの R の base パッケージ（以下、base R）のコマンドは、データテーブルにも使用できます。\n\ndim(linelist) #データテーブルの行と列の数を示す\n\n[1] 5888   30",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#i-引数-行の選択とフィルタリング",
    "href": "new_pages/data_table.jp.html#i-引数-行の選択とフィルタリング",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "50.3 i 引数： 行の選択とフィルタリング",
    "text": "50.3 i 引数： 行の選択とフィルタリング\n先ほど説明した DT[i, j, by] data.table 構文を使い、行番号または論理式のいずれかを使用して行をフィルタリングできます。i 引数は構文における最初の引数です。 したがって、DT[i] または DT[i,] 構文を使用できます。\n以下の 1 つ目の例ではデータテーブルの最初の 5 行を取得し、2 つ目の例では 18 歳以上の症例をサブセット化し、3 つ目の例では 18 歳以上であるが Central Hospital で診断されていない症例をサブセット化します。\n\nlinelist[1:5] #1 行目から 5 行目を取得\nlinelist[age &gt;= 18] #18 歳以上をサブセット化\nlinelist[age &gt;= 18 & hospital != \"Central Hospital\"] #18 歳以上であるが、Central Hospital で診断されていない症例のサブセット\n\ni 引数に .N を使用すると、データテーブルの行の総数を表示します。 この書式は、行番号によるサブセット化に使用できます。\n\nlinelist[.N] #最後の行を取得\nlinelist[15:.N] #15 行目から最後の行を取得\n\n\nヘルパー関数を使用したフィルタリング\ndata.table 構文では、行のサブセット化を容易にするヘルパー関数を使用します。%like% 関数は列内をパターンマッチングで比較するために使用され、%chin% は特定の文字が含まれるか比較するために使用され、%between% 関数は事前に用意した範囲に数字型の列を抽出するために使用されます。\n以下では、3 点を例示します。\n\nhospital 列に文字列「Hospital」が含まれる行をフィルタリングする\n予後が「回復」または「死」である行をフィルタリングする\n年齢の範囲が 40〜60 歳の行をフィルタリングする\n\n\nlinelist[hospital %like% \"Hospital\"] #hospital 列に文字列「Hospital」が含まれる行をフィルタリングする\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #予後が「回復」または「死」である行をフィルタリングする\nlinelist[age %between% c(40, 60)] #年齢の範囲が 40〜60 歳の行をフィルタリングする\n\n#%between% を使う際は長さ 2 のベクトルが必要だが、%chin% を使う場合は長さ 1 以上のベクトルが使用できる。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#j-引数列の選択と計算",
    "href": "new_pages/data_table.jp.html#j-引数列の選択と計算",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "50.4 j 引数：列の選択と計算",
    "text": "50.4 j 引数：列の選択と計算\nDT[i, j, by] data.table 構文を使用すると、数値または名前を使用して列を選択できます。j 引数は構文における 2 番目の引数です。 したがって、DT[, j] 構文が使用されます。j 引数の計算を容易にするために、選択する列は list() または .() のいずれかを使用してまとめます。\n\n列の選択\n以下の 1 つ目の例では、データテーブルの 1 番目、3 番目、5 番目の列を取得し、2 つ目の例では、身長、体重、性別の列を除くすべての列を選択します。3 つ目の例では、.() を使用して、case_id 列とoutcome 列を選択します。\n\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)]でも可\n\n\n\n列内の計算\ni 引数と j 引数を組み合わせることにより、行をフィルタリングして列内の計算が可能です。 j 引数に .N を使用すると、データテーブルの行の総数を表し、行フィルタリング後に行数を取得するのに役立ちます。\n以下では、3 点を例示します。\n\n入院 7 日以上の症例数をカウント\n“Military” を病院名に含む病院で死亡した症例の平均年齢\nCentral Hospital で回復した症例の年齢の標準偏差、中央値、平均\n\n\nlinelist[days_onset_hosp &gt; 7 , .N]\n\n[1] 189\n\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T は N/A 値を除外します\n\n        V1\n     &lt;num&gt;\n1: 15.9084\n\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #この構文はヘルパー関数を使用しないが、使用する場合と同様に機能する\n\n   mean_age median_age   sd_age\n      &lt;num&gt;      &lt;num&gt;    &lt;num&gt;\n1: 16.85185         14 12.93857\n\n\nj 引数において .() 構文を使用すると、計算が容易になり、データテーブルを戻り値と返し、列に名前を付けることができます。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#by-引数グルーピングを用いた計算",
    "href": "new_pages/data_table.jp.html#by-引数グルーピングを用いた計算",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "50.5 by 引数：グルーピングを用いた計算",
    "text": "50.5 by 引数：グルーピングを用いた計算\nby 引数は、DT[i, j, by] data.table 構文の 3 番目の引数です。 by 引数には、文字型ベクトルと list() 構文または .() 構文を使用できます。 by 引数に .() 構文を使用すると、列名をその場で変更できます。\n以下では、3 点を例示します。\n\n症例数を病院ごとにグルーピング\n18 歳以上の症例を、性別や回復したか死亡したかによってグルーピングし、身長と体重の平均を計算\n7 日間以上入院したグループで、入院した月と入院した病院に応じて症例数を集計\n\n\nlinelist[, .N, .(hospital)] #病院別の症例数\n\n                               hospital     N\n                                 &lt;char&gt; &lt;int&gt;\n1:                                Other   885\n2:                              Missing  1469\n3: St. Mark's Maternity Hospital (SMMH)   422\n4:                        Port Hospital  1762\n5:                    Military Hospital   896\n6:                     Central Hospital   454\n\nlinelist[age &gt; 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NA は、データが欠測しているカテゴリを表す\n\n   gender outcome  mean_wt  mean_ht\n   &lt;char&gt;  &lt;char&gt;    &lt;num&gt;    &lt;num&gt;\n1:      m Recover 71.90227 178.1977\n2:      f   Death 63.27273 159.9448\n3:      m   Death 71.61770 175.4726\n4:      f    &lt;NA&gt; 64.49375 162.7875\n5:      m    &lt;NA&gt; 72.65505 176.9686\n6:      f Recover 62.86498 159.2996\n7:   &lt;NA&gt; Recover 67.21429 175.2143\n8:   &lt;NA&gt;   Death 69.16667 170.7917\n9:   &lt;NA&gt;    &lt;NA&gt; 70.25000 175.5000\n\nlinelist[days_onset_hosp &gt; 7, .N, .(month = month(date_hospitalisation), hospital)]\n\n    month                             hospital     N\n    &lt;num&gt;                               &lt;char&gt; &lt;int&gt;\n 1:     5                    Military Hospital     3\n 2:     6                        Port Hospital     4\n 3:     7                        Port Hospital     8\n 4:     8 St. Mark's Maternity Hospital (SMMH)     5\n 5:     8                    Military Hospital     9\n 6:     8                                Other    10\n 7:     8                        Port Hospital    10\n 8:     9                        Port Hospital    28\n 9:     9                              Missing    27\n10:     9                     Central Hospital    10\n11:     9 St. Mark's Maternity Hospital (SMMH)     6\n12:    10                              Missing     2\n13:    10                    Military Hospital     3\n14:     3                        Port Hospital     1\n15:     4                    Military Hospital     1\n16:     5                                Other     2\n17:     5                     Central Hospital     1\n18:     5                              Missing     1\n19:     6                              Missing     7\n20:     6 St. Mark's Maternity Hospital (SMMH)     2\n21:     6                    Military Hospital     1\n22:     7                    Military Hospital     3\n23:     7                                Other     1\n24:     7                              Missing     2\n25:     7 St. Mark's Maternity Hospital (SMMH)     1\n26:     8                     Central Hospital     2\n27:     8                              Missing     6\n28:     9                                Other     9\n29:     9                    Military Hospital    11\n30:    10                        Port Hospital     3\n31:    10                                Other     4\n32:    10 St. Mark's Maternity Hospital (SMMH)     1\n33:    10                     Central Hospital     1\n34:    11                              Missing     2\n35:    11                        Port Hospital     1\n36:    12                        Port Hospital     1\n    month                             hospital     N\n\n\ndata.table 構文では、次のように式を組み合わせることもできます。\n\nlinelist[, .N, .(hospital)][order(-N)][1:3] #1 番目の構文は病院ごとにすべての症例を選択し、2 番目の構文は症例を降順で並べ替え、3 番目の構文は症例数上位 3 つの病院をサブセット化する\n\n            hospital     N\n              &lt;char&gt; &lt;int&gt;\n1:     Port Hospital  1762\n2:           Missing  1469\n3: Military Hospital   896\n\n\n前述の例では、データテーブルの行は新しい症例に相当するという仮定に従っているため、.N を使用してデータテーブルの行数を表すことができます。個別の症例数を表すもう 1 つの便利な関数は、uniqueN() です。この関数は、与えられた入力から、重複のない個別の総数を取得できます。 以下のように実行します。\n\nlinelist[, .(uniqueN(gender))] # j 引数の .() はデータテーブルを戻り値として返すことを覚えておいてください\n\n      V1\n   &lt;int&gt;\n1:     3\n\n\n性別の列に含まれる個別の値は m、f、および N/A であるため、戻り値は 3 になります。 与えられた入力の個別の値すべてを取得する base R 関数 unique() と比較してください。\n\nlinelist[, .(unique(gender))]\n\n       V1\n   &lt;char&gt;\n1:      m\n2:      f\n3:   &lt;NA&gt;\n\n\n特定の月における個別の症例数を取得するには、以下のように記述します。\n\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]\n\n    month    V1\n    &lt;num&gt; &lt;int&gt;\n 1:     5    62\n 2:     6   100\n 3:     7   198\n 4:     8   509\n 5:     9  1170\n 6:    10  1228\n 7:    11   813\n 8:    12   576\n 9:     1   434\n10:     2   310\n11:     3   290\n12:     4   198",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#データテーブルへのデータの追加と更新",
    "href": "new_pages/data_table.jp.html#データテーブルへのデータの追加と更新",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "50.6 データテーブルへのデータの追加と更新",
    "text": "50.6 データテーブルへのデータの追加と更新\n:= 演算子は、データテーブルへデータを追加または更新するために使用されます。 データテーブルへの列の追加は、以下の方法で実行できます。\n\nlinelist[, adult := age &gt;= 18] # 1 列追加\nlinelist[, c(\"child\", \"wt_lbs\") := .(age &lt; 18, wt_kg*2.204)] #複数の列を追加するには、c(\"\") と list() または .() 構文が必要\nlinelist[, `:=` (bmi_in_range = (bmi &gt; 16 & bmi &lt; 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #この方法では、関数演算子 `:=` として := を使用\nlinelist[, adult := NULL] #列の削除\n\nより複雑な集計は、入門の範囲を超えています。本章ではデータのグルーピングと整理のために、一般的で実行可能な dplyr パッケージの代替手段を提供することを目的としています。data.table パッケージは、読みやすいコードを可能にする優れたパッケージです。",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.jp.html#参考資料",
    "href": "new_pages/data_table.jp.html#参考資料",
    "title": "50  data.table パッケージを使用したデータ処理",
    "section": "50.7 参考資料",
    "text": "50.7 参考資料\n詳細については、以下の資料をご覧ください。 * https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html * https://github.com/Rdatatable/data.table * https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf * https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/ * https://www.datacamp.com/community/tutorials/data-table-r-tutorial\nグルーピングされたデータに対して任意の要約機能を実行できます。 詳細については、こちらのチートシートをご参照ください。 https://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf",
    "crumbs": [
      "その他",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>data.table パッケージを使用したデータ処理</span>"
    ]
  }
]