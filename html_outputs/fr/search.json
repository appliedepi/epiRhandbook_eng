[
  {
    "objectID": "index.fr.html",
    "href": "index.fr.html",
    "title": "Le Epi R Handbook",
    "section": "",
    "text": "Bienvenue",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "index.fr.html#r-pour-lépidémiologie-appliquée-et-la-santé-publique",
    "href": "index.fr.html#r-pour-lépidémiologie-appliquée-et-la-santé-publique",
    "title": "Le Epi R Handbook",
    "section": "R pour l’épidémiologie appliquée et la santé publique",
    "text": "R pour l’épidémiologie appliquée et la santé publique\nUtilisation : Ce manuel a été utilisé plus d’un million de fois par 400 000 personnes dans le monde entier.\nObjectif: Servir de manuel de référence rapide du code R (en ligne et hors line) avec des exemples centrés sur la tâche qui traitent des problèmes épidémiologiques courants.\nEssayez nos tutoriels interactifs gratuits ou notre cours d’introduction synchrone et virtuel utilisé par les CDC américains, l’OMS et plus de 130 autres agences de santé et programmes de formation à l’épidémiologie sur le terrain dans le monde entier.\nLangues: Anglais (English), Espagnol (Español), Vietnamien (Tiếng Việt), Japonais (日本), Turc (Türkçe), Francais, Portugais (Português), Russe\n Rédigé par des épidémiologistes, pour des épidémiologistes\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\nApplied Epi est une organisation à but non lucratif et un mouvement d’épis de première ligne du monde entier. Nous écrivons pendant notre temps libre pour offrir cette ressource à la communauté. Vos encouragements et vos commentaires sont les bienvenus :\n\nVisitez notre site web et rejoignez notre liste de contacts.\n\ncontact@appliedepi.org, tweeter @appliedepi, ou LinkedIn\n\nSoumettre des problèmes à notre dépôt Github\n\nNous proposons des formations R en direct dispensées par des formateurs ayant des décennies d’expérience en épidémiologie appliquée - envoyez-nous un courriel pour en discuter.",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "index.fr.html#comment-utiliser-ce-manuel",
    "href": "index.fr.html#comment-utiliser-ce-manuel",
    "title": "Le Epi R Handbook",
    "section": "Comment utiliser ce manuel",
    "text": "Comment utiliser ce manuel\n\nParcourez les pages de la table des matières ou utilisez la boîte de recherche.\nCliquez sur les icônes “copier” pour copier le code.\n\nVous pouvez suivre avec les données d’exemple de le chapitre.\n\nVersion hors ligne\nVoir les instructions de la page Télécharger le manuel et les données.",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "index.fr.html#remmerciements",
    "href": "index.fr.html#remmerciements",
    "title": "Le Epi R Handbook",
    "section": "Remmerciements",
    "text": "Remmerciements\nCet ouvrage est le fruit du travail d’une équipe internationale d’épidémiologistes, qui se sont appuyés sur leur expérience auprès d’organisations telles que les agences sanitaires locales, régionales, provinciales et nationales de divers pays, l’Organisation mondiale de la santé (OMS), Médecins Sans Frontières (MSF), les systèmes hospitaliers et les institutions universitaires.\nCe guide n’est pas un produit approuvé par une organisation spécifique. Bien que nous nous soyons efforcés à être précis, nous ne pouvons fournir aucune garantie quant au contenu de ce livre.\n\nAuteurs et contributeurs\nEditeur: Neale Batra\nCommité éditorial Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay Campbell\nAuteurs et autrices: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin, Olivia Boyd\nRelecture: Pat Keating, Annick Lenglet, Margot Charette, Danielly Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga\nIllustrations: Calder Fong\nTraduction: Aminata Ndiaye, Olivia Boyd, Anais Legrand, Marie-Amelie Degail-Chabrat, Yves Amevoin, Laura Downham, Lise Grout, Margot Charette, Mathilde Mousset, Noe Guincko, Mor Ndiaye, Elysée Junior, Nerisson Joseph, Bryan Tegomoh, Marcel Woung, Amy Mikhail, Lucie Fournier, Paul-Evans Ehouman, Kelly McCain\n\n\n\n\n\n\nFinancements\nLe manuel a reçu un financement de soutien via une subvention d’urgence COVID-19 pour le renforcement des capacités de la part de TEPHINET, le réseau mondial des programmes de formation en épidémiologie de terrain (FETP).\nLe réseau des anciens d’EPIET (EAN) a fourni un soutien administratif (Annika Wendland en particulier). EPIET est le programme européen de formation en épidémiologie d’intervention.\nNous remercions tout particulièrement le Centre Opérationnel d’Amsterdam de Médecins Sans Frontières (MSF OCA) pour son soutien lors de l’élaboration de ce manuel.\nCette publication a été soutenue par l’accord de coopération numéro NU2GGH001873, financé par les Centers for Disease Control and Prevention par le biais de TEPHINET, un programme de “The Task Force for Global Health”. Son contenu relève de la seule responsabilité des auteurs et ne reflète pas les opinions officielles des Centers for Disease Control and Prevention, du Department of Health and Human Services, de The Task Force for Global Health, Inc. ou de TEPHINET.\n\n\nInspirations\nNous nous sommes inspiré de multiples tutoriels, livres et vignettes développés par la communauté pour développer ce manuel. Ces ressources, sont crédités dans les chapitres respectifs, mais nous souhaitons citer quelques sources d’inspiration générales que nous utilisons de manière récurrente :\nThe “R4Epis” project (une collaboration entre MSF et RECON)\nR Epidemics Consortium (RECON)\nR for Data Science book (R4DS)\nbookdown: Authoring Books and Technical Documents with R Markdown\nNetlify qui héberge ce site",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "index.fr.html#conditions-dutilisation-et-contribution",
    "href": "index.fr.html#conditions-dutilisation-et-contribution",
    "title": "Le Epi R Handbook",
    "section": "Conditions d’utilisation et contribution",
    "text": "Conditions d’utilisation et contribution\n\nLicense\nCe document est mis à disposition selon les termes de lalicence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International (CC BY-NC-SA 4.0) .\nN’hésitez pas à utiliser les contenus de ce manuel dans vos cours et formations en épidémiologie, ou à le conseiller à vos étudiants. Si vous avez des questions sur l’utilisation que vous souhaitez en faire, envoyez un courriel à contact@appliedepi.org.\n\n\nCitation\nBatra, Neale, et al. The Epidemiologist R Handbook. 2021. \n\n\nContribuer\nSi vous souhaitez contribuer à cet ouvrage, veuillez d’abord nous contacter via les tickets (issues) Github ou par courriel. Nous sommes en train de développer un calendrier de mise à jour et un guide du contributeur.\nVeuillez noter que le projet epiRhandbook est publié avec un code de conduite du contributeur. En contribuant à ce projet, vous acceptez de vous conformer à ses conditions.",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.fr.html",
    "href": "new_pages/editorial_style.fr.html",
    "title": "1  Notes techniques et choix éditoriaux",
    "section": "",
    "text": "1.1 Approche et style\nLe public visé par ce manuel est large. Nous espérons qu’il sera utile aux épidémiologistes novices en R, mais aussi aux utilisateurs expérimentés à la recherche de bonnes pratiques et d’astuces. L’ouvrage doit donc être à la fois accessible et succinct. Notre cherchons à fournir juste assez d’explications textuelles pour qu’une personne débutante en R puisse appliquer le code et comprendre ce qu’il fait.\nEn conséquences de quoi, ce guide est :",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes techniques et choix éditoriaux</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.fr.html#approche-et-style",
    "href": "new_pages/editorial_style.fr.html#approche-et-style",
    "title": "1  Notes techniques et choix éditoriaux",
    "section": "",
    "text": "un ouvrage de référence de code, accompagné d’exemples relativement brefs, et non un manuel complet sur R ou la science des données\n\nun guide R à utiliser dans le cadre de l’épidémiologie appliquée, et non un manuel sur les méthodes ou la science de l’épidémiologie appliquée\n\nun document évolutif : les paquets R optimaux pour une tâche donnée changent souvent et nous sommes ouverts à toute discussion sur les paquets à privilégier dans ce manuel.\n\n\nPaquets R\nTellement de possibilités…\nUn aspect difficile de l’apprentissage de R est de savoir quel paquet R utiliser pour une tâche donnée. Il n’est pas rare que l’on se décarcasse à écrire vingt (cent ?) lignes de code, pour se rendre compte plus tard qu’il existe un paquet R qui donne le même résultat recheré en une seule ligne de commande !\nDans ce guide, nous essayons de vous proposer au moins deux façons de réaliser chaque tâche : une méthode éprouvée (probablement dans R de base ou utilisant le tidyverse) et un paquet R spécialement conçu à cet effet. Nous voulons que vous ayez les deux options, au cas où vous ne pourriez pas télécharger un paquet donné ou si celui-ci ne vous convient pas.\nPour choisir les paquets à utiliser, nous avons donné la priorité aux paquets R et aux approches qui ont été testés et approuvés par la communauté, qui minimisent le nombre de paquets utilisés dans une session de travail typique, qui sont stables (ne changent pas très souvent) et qui accomplissent la tâche simplement et proprement.\nCe manuel donne généralement la priorité aux paquets et fonctions R du méta-paquet tidyverse. Tidyverse est une collection de paquets R conçus pour la science des données, et qui partagent une grammaire et des structures de données sous-jacentes. Tous les paquets du Tidyverse peuvent être installés ou chargés séparément, ou en masse via le paquet tidyverse. Pour en savoir plus, consultez le site Web du tidyverse.\nNous proposons également souvent des options de code utilisant R de base (les paquets et fonctions fournis avec R à l’installation). En effet, nous sommes conscients que certains lecteurs de ce livre ne disposent pas d’un accès Internet fiable pour télécharger des paquets supplémentaires.\nExpliciter quelle fonction appartient à quel paquet\nIl est souvent frustrant lorsque l’on suit un tutoriel R de ne pas savoir de quel paquet provient une fonction (et donc de ne pas pouvoir l’utiliser immédiatement dans notre code) !\nDans ce guide, les noms des paquets seront écrits en gras (par exemple dplyr) et les fonctions sont écrites comme ceci : mutate(). Nous nous efforçons d’être explicites quant au paquet dont provient une fonction, soit en faisant référence au paquet dans le texte voisin, soit en spécifiant le paquet explicitement dans le code, comme ceci : dplyr::mutate(). Cela alourdit un petit peu le code, mais rend plus facile la réutilisation du code chez vous.\nConsultez la page sur les Bases de R pour en savoir plus sur les paquets et les fonctions.\n\n\nChoix d’yn style de code\nDans le manuel, nous allons fréquemment à la ligne, ce qui rend notre code “long”. Nous faisons cela pour plusieurs raisons :\n\ncela permet d’écrire des commentaires explicatifs avec # adjacents à la commande qu’ils décrivent,\n\ngénéralement, un code plus long (vertical) est plus facile à lire,\n\nil est plus facile à lire sur un écran étroit (pas de défilement latéral nécessaire),\n\nil est plus facile de savoir quels arguments appartiennent à quelle fonction grâce aux indentations.\n\nPar conséquent, un bout de code code qui pourrait être écrit comme ceci :\n\nlinelist %&gt;% group_by(hospital) %&gt;%  # groupe les lignes par hopital\n  slice_max(date, n = 1, with_ties = F) # s'il y a égalité de date, prendre la première\n\n…est écrit comme cela :\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% # groupe les lignes par hopital\n  slice_max(\n    date,                # Garde les lignes avec la date maximun à l'intérieur de chaque groupe\n    n = 1,               # Ne garder que la date maximum\n    with_ties = F)       # S'il y a égalité de date, prendre la première\n\nLe code R n’est généralement pas affecté par les nouvelles lignes ou les indentations. Lorsque vous écrivez dans Rstudio (ou un éditeur décent), l’indentation se fera automatiquement lorsque vous allez à la ligne après une virgule.\nNous utilisons beaucoup d’espaces (par exemple n = 1 au lieu de n=1) parce que c’est plus facile à lire pour beaucoup de personnes. Pensez aux gens qui lisent votre code !\n\n\nNomenclature\nDans ce manuel, nous faisons généralement référence aux “colonnes” et aux “lignes” plutôt qu’aux “variables” et “observations”. Comme l’explique cette introduction aux “données ordonnées”, la plupart des jeux de données statistiques épidémiologiques se composent structurellement de lignes, de colonnes et de valeurs.\nLes variables contiennent les valeurs qui mesurent le même attribut sous-jacent (comme le groupe d’âge, le résultat ou la date d’apparition des symptomes). Les observations contiennent toutes les valeurs mesurées sur la même unité (par exemple, une personne, un site ou un échantillon de laboratoire). Ces aspects peuvent donc être plus difficiles à définir de manière tangible.\nDans les ensembles de données “ordonnés” (tidy data en anglais), chaque colonne est une variable, chaque ligne est une observation et chaque cellule est une valeur unique. Cependant, certains jeux de données que vous rencontrerez ne correspondront pas à ce modèle - un ensemble de données au format “large” peut avoir une variable répartie sur plusieurs colonnes (voir un exemple à la page Transformation long-large). De même, les observations peuvent être réparties sur plusieurs lignes.\nLa majeure partie de ce manuel porte sur le nettoyage et la transformation des données, et il est donc plus pertinent de se référer aux structures de données concrètes que sont les lignes et les colonnes qu’aux observations et aux variables plus abstraites. Les exceptions se produisent principalement dans les pages sur l’analyse des données, où vous verrez davantage de références aux “variables” et aux “observations”.\n\n\nNotes\nVoici les types de notations utilisées dans le guide :\nNOTE: Ceci est une note\nTIP: Ceci est un conseil ou une astuce.\nCAUTION: Ceci vous invite à bien prêter attention.\nDANGER: Ceci est un avertissement.",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes techniques et choix éditoriaux</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.fr.html#choix-techniques",
    "href": "new_pages/editorial_style.fr.html#choix-techniques",
    "title": "1  Notes techniques et choix éditoriaux",
    "section": "1.2 Choix techniques",
    "text": "1.2 Choix techniques\nCi-dessous, nous décrivons les principales décisions concernant le choix des paquets et des fonctions. Si vous n’êtes pas d’accord ou si vous souhaitez proposer un nouvel outil à examiner, veuillez rejoindre/démarrer une conversation sur notre page Github.\nTableau des paquets, fonction et autres choix techniques\n\n\n\n\n\n\n\n\n\nSujet\nConsidéré\nChoisi\nExplication brève\n\n\n\n\nApproche générale\ntidyverse, data.table, base\ntidyverse, avec un chapitre sur data.table, et mentions d’alternatives en R de base pour les lecteurs avec une connexion Internet faible\nlisibilité accrue, universel, paquets très répandus\n\n\nImportation des paquets\nlibrary(),install.packages(), require(), pacman\npacman\nSimplification et code plus court pour les cas avec de nombreux paquets à installer puis importer\n\n\nImport et export de données\nrio, de nombreux paquets spécialisés\nrio\nGère un grand nombre de format de jeux de données\n\n\nRésumer des données agrégées\ndplyr group_by(), stats aggregate()\ndplyr group_by()\nReste cohérent avec nos choix d’utiliser le tidyverse\n\n\nTransformation long-large\ntidyr (fonctions pivot_XXX), reshape2 (melt/cast), tidyr (spread/gather)\ntidyr (fonctions pivot_XXX)\nreshape2 est en fin de vie (recommandations officielles d’utiliser tidyr), tidyr utilise les fonctions pivot_XXX dès la versions v1.0.0\n\n\nNettoyer les noms des colonnes\nmatchmaker, janitor\njanitor\nJanitor est utilisé pour plusieus tâches dans le guide (optimisation des paquets)\n\n\nSemaines epi\nlubridate, aweek, tsibble, zoo\nlubridate en général, avec utilisation ponctuelle d’autres paquets pour des cas spécifiques\nLa grande flexibilité de lubridate, la cohérence avec le tidyverse, une meilleure maintenance future (?)\n\n\nLabels ggplot\nlabs(), ggtitle()/ylab()/xlab()\nlabs()\nSimplicité, tous les labels dans la même commande\n\n\nConversion en facteur\nfactor(), forcats\nforcats\ndifférentes fonctions pour transformer les facteurs dans la même commande\n\n\nCourbes épidémiques\nincidence, ggplot2, EpiCurve\nincidence2 pour le plus rapide, ggplot2 pour les détails\nfiabilité\n\n\nConcaténation\npaste(), paste0(), str_glue(), glue()\nstr_glue()\nsyntaxe plus simple que paste(); dans stringr",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes techniques et choix éditoriaux</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.fr.html#révisions-majeures",
    "href": "new_pages/editorial_style.fr.html#révisions-majeures",
    "title": "1  Notes techniques et choix éditoriaux",
    "section": "1.3 Révisions majeures",
    "text": "1.3 Révisions majeures\n\n\n\nDate\nChangements majeurs\n\n\n\n\n10 Mai 2021\nPublication de la version 1.0.0\n\n\n20 Nov 2022\nPublication de la version 1.0.1\n\n\n\nNEWS Avec la version 1.0.1, les changements suivants ont été mis en œuvre :\n\nMise à jour vers la version 4.2 de R\n\nNettoyage des données : remplacement de {linelist} par {matchmaker}, suppression d’une ligne inutile dans l’exemple case_when().\n\nDates : remplacement de {linelist} guess_date() par {parsedate} parse_date().\nPivot : légère mise à jour de pivot_wider()id_cols=`.\n\nAnalyse d’enquête : remplacement de plot_age_pyramid() par age_pyramid(), légère modification du code du tracé alluvial.\n\nGraphiques de chaleur : ajout de ungroup() au chunk agg_weeks.\n\nGraphiques interactifs : ajout de ungroup() au chunk qui fait agg_weeks pour que expand() fonctionne comme prévu.\n\nSéries temporelles : ajout de data.frame() autour des objets dans toutes les commandes trending::fit() et predict().\n\nAnalyse des combinaisons : Remplacer case_when() par ifelse() et ajouter le code optionnel across() pour préparer les données.",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes techniques et choix éditoriaux</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.fr.html#information-de-session-r-rstudio-paquets",
    "href": "new_pages/editorial_style.fr.html#information-de-session-r-rstudio-paquets",
    "title": "1  Notes techniques et choix éditoriaux",
    "section": "1.4 Information de session (R, RStudio, paquets)",
    "text": "1.4 Information de session (R, RStudio, paquets)\nVous trouverez ci-dessous les informations sur les versions de R, RStudio et les paquets R utilisés lors de la compilation du guide.\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31 ucrt)\n os       Windows 11 x64 (build 22621)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       Europe/Stockholm\n date     2024-05-08\n pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.2   2023-12-11 [2] CRAN (R 4.3.2)\n digest        0.6.35  2024-03-11 [1] CRAN (R 4.3.3)\n evaluate      0.23    2023-11-01 [2] CRAN (R 4.3.2)\n fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.3.2)\n htmltools     0.5.8   2024-03-25 [1] CRAN (R 4.3.3)\n htmlwidgets   1.6.4   2023-12-06 [2] CRAN (R 4.3.2)\n jsonlite      1.8.8   2023-12-04 [2] CRAN (R 4.3.2)\n knitr         1.45    2023-10-30 [2] CRAN (R 4.3.2)\n rlang         1.1.3   2024-01-10 [2] CRAN (R 4.3.2)\n rmarkdown     2.26    2024-03-05 [1] CRAN (R 4.3.3)\n rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.3.2)\n sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.3.2)\n xfun          0.43    2024-03-25 [1] CRAN (R 4.3.3)\n\n [1] C:/Users/ngulu864/AppData/Local/R/win-library/4.3\n [2] C:/Program Files/R/R-4.3.2/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes techniques et choix éditoriaux</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.fr.html",
    "href": "new_pages/data_used.fr.html",
    "title": "2  Télécharger le manuel et les données",
    "section": "",
    "text": "2.1 Télécharger le manuel hors-ligne\nVous pouvez télécharger la version hors-ligne de ce manuel en tant que fichier HTML afin de pouvoir le visualiser dans votre navigateur Web même si vous n’avez plus accès à Internet. Si vous envisagez d’utiliser le manuel Epi R hors ligne, voici quelques éléments à prendre en compte :\nIl y a deux façons de télécharger le manuel :",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Télécharger le manuel et les données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.fr.html#download_offline",
    "href": "new_pages/data_used.fr.html#download_offline",
    "title": "2  Télécharger le manuel et les données",
    "section": "",
    "text": "Lorsque vous ouvrez le fichier, le chargement des images et de la table des matières peut prendre une minute ou deux.\n\nLe manuel hors ligne a une mise en page légèrement différente : une très longue page avec la table des matières à gauche. Pour rechercher des termes spécifiques, utilisez Ctrl + F (Cmd + F).\n\nConsultez la page Paquets conseillés pour vous aider à installer les paquets R appropriés avant de perdre votre connexion à Internet.\n\nInstallez notre paquet R epirhandbook qui contient toutes les données utilisées dans les exemples (le processus d’installation est décrit ci-dessous).\n\n\n\nUtiliser le lien de téléchargement\nPour un accès rapide, cliquez à droite ce lien et sélectionnez “Enregistrer le lien sous”.\nSi vous êtes sur un Mac, utilisez Cmd + clic. Si vous êtes sur un téléphone portable, appuyez sur le lien et maintenez-le enfoncé, puis sélectionnez “Enregistrer le lien”. Le manuel sera téléchargé sur votre appareil. Si un écran contenant un code HTML brut apparaît, assurez-vous d’avoir suivi les instructions ci-dessus ou essayez l’option 2.\n\n\nUtiliser notre paquet R\nNous avons développé un paquet R appelé epirhandbook. Il comprend une fonction download_book() qui télécharge le fichier du guide depuis notre dépôt Github sur votre ordinateur.\nCe package contient également une fonction get_data() qui télécharge toutes les données utilisées dans les chapitres sur votre ordinateur.\nExécutez le code suivant pour installer notre paquet R epirhandbook à partir du dépôt Github appliedepi. Ce paquet n’est pas sur le CRAN, donc utilisez la fonction spéciale p_install_gh() du paquet pacman pour l’installer depuis Github.\n\n# installer la dernière version du paquet epirhandbook\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nMaintenant, importer le paquet pour l’utiliser dans votre session R actuelle :\n\n# Importer le paquet pour pouvoir l'utiliser dans la session ouverte\npacman::p_load(epirhandbook)\n\nEnsuite, exécutez la fonction du paquet download_book() (avec des parenthèses vides) pour télécharger le manuel sur votre ordinateur. En supposant que vous êtes dans RStudio, une fenêtre apparaîtra pour vous permettre de sélectionner un emplacement de sauvegarde.\n\n# télécharger la version html du manuel localement\ndownload_book()",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Télécharger le manuel et les données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.fr.html#télécharger-les-données",
    "href": "new_pages/data_used.fr.html#télécharger-les-données",
    "title": "2  Télécharger le manuel et les données",
    "section": "2.2 Télécharger les données",
    "text": "2.2 Télécharger les données\nPour pouvoir reproduire les exemples au fur et à mesure sur votre ordinateur, vous pouvez télécharger les données et les fichiers générés.\n\nUtiliser notre paquet R\nUne fois le paquet téléchargé et importé dans votre session R (voir section au-dessus) utilisez la fonction get_data() du paquet pour obtenir les données d’exemple sur votre ordinateur. Exécutez get_data(\"all\") pour obtenir toutes les données d’exemple, ou fournissez un nom de fichier spécifique et une extension entre guillemets pour récupérer un seul fichier.\nTechniquement, toutes les données ont déjà été téléchargées avec le paquet, et doivent simplement être transférées dans un dossier de votre ordinateur. Une fenêtre pop-up apparaîtra, vous permettant de sélectionner un emplacement de dossier de sauvegarde. Nous vous suggérons de créer un nouveau dossier “data” car il y a environ 30 fichiers (y compris les données d’exemple et les sorties générées par les exemples).\n\n# enregistrer toutes les données dans un dossier sur votre ordinateur\nget_data(\"all\")\n\n# enregistrer les données linelist dans un dossiet sur votre ordinateur\nget_data(file = \"linelist_cleaned.rds\")\n\nUne fois que vous avez utilisé get_data() pour enregistrer un fichier sur votre ordinateur, vous devrez encore l’importer dans R. Voir la page Importer et exporter des données pour plus de détails.\nSi vous le souhaitez, vous pouvez consulter toutes les données utilisées dans ce manuel dans le “dossier données” de notre dépôt Github.\n\n\nTéléchargement manuel\nVous pouvez télécharger les données fichier par fichier à partir de notre dépôt Github via un lien ou une commande R spécifique au fichier. Certains types de fichiers ont un bouton de téléchargement, tandis que d’autres peuvent être téléchargés via une commande R.\n\nListe de cas (linelist)\nIl s’agit d’une linelist pour une épidémie d’Ebola fictive, développée par notre équipe à partir du jeu de données d’exemple ebola_sim du paquet outbreaks.\n\nCliquer pour télécharger les données brutes (.xlsx). La liste de cas “brute” est une feuille de calcul Excel contenant des données désordonnées. Utilisez-la pour suivre la page Nettoyer les données et fonctions essentielles.\nCliquer pour télécharger la linelist nettoyée (.rds). Utilisez ce fichier pour toutes les autres pages de ce manuel qui utilisent la linelist. Un fichier .rds est un type de fichier spécifique à R qui préserve les classes de colonnes. Cela garantit que vous n’aurez qu’un nettoyage minimal à faire après avoir importé les données dans R.\n\nAutres fichiers linelist :\n\nCliquer pour télécharger la version nettoyée de la linelist sous format Excel\nUne partie de la page sur le nettoyage des données utilise un “dictionnaire de nettoyage” (fichier .csv). Vous pouvez le charger directement dans R en exécutant les commandes suivantes :\n\n\npacman::p_load(rio) # installer/importer le paquet **rio**\n\n# importer le fichier directement depuis github\ncleaning_dict &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/case_linelists/cleaning_dict.csv\")\n\n\n\nCas de paludisme\nCes données sont des comptages fictifs de cas de paludisme par groupe d’âge, établissement et jour. Un fichier .rds est un type de fichier spécifique à R qui préserve les classes de colonnes. Cela garantit que vous n’aurez qu’un nettoyage minimal à faire après avoir importé les données dans R.\n Click to download les comptages de de cas de paludisme (.rds file) \n\n\nDonnées sur l’échelle de Likert\nIl s’agit de données fictives issues d’une enquête de type Likert, utilisées dans la page Pyramides démographiques et échelles de Likert. Vous pouvez charger ces données directement dans R en exécutant les commandes suivantes :\n\npacman::p_load(rio)  # installer/importer le paquet **rio**\n\n# importer le fichier directement depuis github\nlikert_data &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/likert_data.csv\")\n\n\n\nFlexdashboard\nVous trouverez ci-dessous des liens vers le fichier associé à la page Tableaux de bord avec R Markdown:\n\nPour télécharger le fichier RMarkdown (.Rmd) du tableau de bord sur les épidémies, faites un clic droit sur ce lien (Cmd+clic pour Mac) et sélectionnez “Enregistrer le lien sous”.\n\nPour télécharger le tableau de bord HTML, cliquez avec le bouton droit de la souris sur ce lien. (Cmd + clic pour Mac) et sélectionnez “Enregistrer le lien sous”.\n\n\n\nrecherche des contacts\nLa page Recherche des contacts présente une analyse des données de recherche des contacts, à l’aide d’exemples de données provenant de Go.Data. Les données utilisées dans cette page peuvent être téléchargées sous forme de fichiers .rds en cliquant sur les liens suivants :\n Cliquer pour télécharger les données d’investigation des cas (.rds file) \n Cliquer pour télécharger les données d’enregistrement des contacts (.rds file) \n Cliquer pour télécharger les données de suivi des contacts (.rds file) \nNOTE: Les données structurées de recherche des contacts provenant d’autres logiciels (par exemple KoBo, DHIS2 Tracker, CommCare) peuvent être organisées differement. Si vous souhaitez contribuer à l’élaboration d’un échantillon de données ou d’un contenu alternatif pour cette page, veuillez nous contacter.\nTIP: Si vous déployez Go.Data et souhaitez vous connecter à l’API de votre instance, consultez la page Importation et exportation, (section API) et la Communauté de pratique Go.Data.\n\n\nSIG\nLes fichiers Shapefiles comportent de nombreux sous-fichiers, chacun avec une extension de fichier différente. Un fichier aura l’extension “.shp”, mais d’autres peuvent avoir “.dbf”, “.prj”, etc.\nLa page Notions de base sur les SIG fournit des liens vers le site Web Humanitarian Data Exchange où vous pouvez télécharger les fichiers de forme directement sous forme de fichiers zippés.\nPar exemple, les données des locations des établissements de santé peuvent être téléchargées ici. Téléchargez “hotosm_sierra_leone_health_facilities_points_shp.zip”. Une fois enregistré sur votre ordinateur, décompressez le dossier. Vous verrez plusieurs fichiers avec des extensions différentes (par exemple, “.shp”, “.prj”, “.shx”); tous ces fichiers doivent être enregistrés dans le même dossier sur votre ordinateur. Ensuite, pour importer dans R, fournissez le chemin et le nom du fichier “.shp” à st_read() du paquet sf (comme décrit dans la page Notions de base sur les SIG).\nSi vous suivez l’option 1 pour télécharger toutes les données de l’exemple (via notre paquet R epirhandbook), tous les shapefiles sont inclus.\nVous pouvez également télécharger les fichiers Shapefile à partir du dossier “data” du manuel R sur Github (voir le sous-dossier “gis”). Cependant, sachez que vous devrez télécharger chaque sous-fichier individuellement sur votre ordinateur. Dans Github, cliquez sur chaque fichier et téléchargez-les en cliquant sur le bouton “Télécharger”. Ci-dessous, vous pouvez voir comment le fichier de forme “sle_adm3” se compose de plusieurs fichiers, chacun devant être téléchargé depuis Github.\n\n\n\n\n\n\n\n\n\n\n\nArbres phylogénétiques\nLa page sur les arbres phylogénétiques utilise un fichier Newick pour l’arbre phylogénétique construit à partir du séquençage du génome entier de 299 échantillons de Shigella sonnei et des données d’échantillons correspondantes (converties en fichier texte). Les échantillons belges et les données résultantes sont aimablement fournis par le CNR belge pour Salmonella et Shigella dans le cadre d’un projet mené par un boursier EUPHEM de l’ECDC, et seront également publiés dans un manuscrit. Les données internationales sont disponibles sur des bases de données publiques (ncbi) et ont déjà été publiées.\n\nPour télécharger le fichier de l’arbre phylogénétique “Shigella_tree.txt”, cliquez avec le bouton droit de la souris sur ce lien (Cmd+click for Mac) et sélectionnez “Enregistrer le lien sous”.\nPour télécharger le fichier “sample_data_Shigella_tree.csv” contenant des informations supplémentaires sur chaque échantillon, cliquez avec le bouton droit de la souris sur ce lien (Cmd+clic pour Mac) et sélectionnez “Enregistrer le lien sous”.\n\nPour voir le nouveau sous-arbre créé, cliquez avec le bouton droit de la souris sur ce lien (Cmd+clic pour Mac) et sélectionnez “Enregistrer le lien sous”. Le fichier .txt sera téléchargé sur votre ordinateur.\n\nVous pouvez ensuite importer les fichiers .txt avec read.tree() du paquet ape, comme expliqué dans le chapitre concerné.\n\nape::read.tree(\"Shigella_tree.txt\")\n\n\n\nStandardization\nPour la page sur la standardisation des données, vous pouvez charger les données directement depuis notre dépôt Github sur internet dans votre session R avec les commandes suivantes :\n\n# installer/importer le paquet **rio**\npacman::p_load(rio) \n\n##############\n# Pays A\n##############\n# import des données démographiques du pays depuis github\nA_demo &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/country_demographics.csv\")\n\n# import des données de mortalité du pays depuis github\nA_deaths &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/deaths_countryA.csv\")\n\n\n\n##############\n# Pays B\n##############\n# import des données démographiques du pays depuis github\nB_demo &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/country_demographics_2.csv\")\n\n# import des données de mortalité du pays depuis github\nB_deaths &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Population de référence\n###############\n# import depuis Github\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/world_standard_population_by_sex.csv\")\n\n\n\nSéries temporelles et détection des épidémies\nVoir la page sur les séries temporelles et la détection des épidémies. Nous utilisons les cas de campylobacter rapportés en Allemagne de 2002 à 2011, tels que disponibles dans le paquet R surveillance. (note cet ensemble de données a été adapté de l’original, en ce sens que 3 mois de données ont été supprimés à partir de la fin de 2011 à des fins de démonstration).\n Cliquer pour télécharger  Campylobacter en Allemagne (.xlsx) \nNous utilisons également les données climatiques de l’Allemagne entre 2002 et 2011 (température en degrés Celsius et précipitations en millimètres). Ces données ont été téléchargées à partir d’un jeu de données dérivé des données produites par le satellite Copernicus (UE) à l’aide du paquet ecmwfr. Vous devrez télécharger toutes ces données et les importer avec stars::read_stars() comme expliqué dans la page sur les séries temporelles.\n Cliquer pour télécharger  Climat Allemagne 2002 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2003 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2004 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2005 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2006 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2007 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2008 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2009 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2010 (.nc file) \n Cliquer pour télécharger  Climat Allemagne 2011 (.nc file) \n\n\nAnalyse d’enquêtes\nPour la page analyse d’enquête, nous utilisons des données d’enquêtes de mortalité fictives basées sur les modèles d’enquête MSF OCA. Ces données fictives ont été générées dans le cadre du projet “R4Epis”.\n Cliquer pour télécharger  Données d’enquête fictives (.xlsx) \n Cliquer pour télécharger  Données d’enquête fictives (dictionnaire) (.xlsx) \n Cliquer pour télécharger  Données d’enquête fictives (données de population) (.xlsx) \n\n\nShiny\nLa page sur les tableaux de bord avec Shiny illustre la construction d’une application simple pour afficher les données sur le paludisme.\nPour télécharger les fichiers R qui produisent l’app Shiny :\nVous pouvez  cliquer ici pour télécharger le fichier app.R qui contient à la fois le code de l’interface utilisateur et du serveur pour l’application Shiny..\nVous pouvez  cliquer ici pour télécharger le fichier facility_count_data.rds qui contient les données sur le paludisme pour l’application Shiny. Notez que vous devrez peut-être l’enregistrer dans un dossier “data” pour que les chemins de fichier here() fonctionnent correctement.\nVous pouvez  cliquer ici pour télécharger le fichier global.R qui doit être exécuté avant l’ouverture de l’app, comme expliqué dans la page.\nVous pouvez  cliquer ici pour télécharger le fichier plot_epicurve.R dont l’exécution est lancée par le script global.R. Notez que vous devrez peut-être le stocker dans un dossier “funcs” pour que les chemins de fichier here() fonctionnent correctement.",
    "crumbs": [
      "À propos de ce livre",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Télécharger le manuel et les données</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html",
    "href": "new_pages/basics.fr.html",
    "title": "3  R - les bases",
    "section": "",
    "text": "3.1 Pourquoi utiliser R ?\nComme indiqué sur le site Web du projet R, R est un langage de programmation et un environnement pour le calcul statistique et les graphiques. Il est très polyvalent, extensible et axé sur la communauté.\nCoût\nL’utilisation de R est gratuite ! Il existe une forte éthique dans la communauté du matériel gratuit et open-source.\nReproductibilité\nLa gestion et l’analyse de vos données par le biais d’un langage de programmation (par rapport à Excel ou à un autre outil essentiellement manuel) améliore la reproductibilité, facilite la détection des erreurs et allège votre charge de travail.\nCommunauté\nLa communauté des utilisateurs de R est énorme et collaborative. De nouveaux paquets et outils destinés à résoudre des problèmes concrets sont développés quotidiennement et approuvés par la communauté des utilisateurs. À titre d’exemple, R-Ladies est une organisation mondiale dont la mission est de promouvoir la diversité des genres dans la communauté R, et c’est l’une des plus grandes organisations d’utilisateurs de R. Elle a probablement un chapitre près de chez vous !",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#termes-clés",
    "href": "new_pages/basics.fr.html#termes-clés",
    "title": "3  R - les bases",
    "section": "3.2 Termes clés",
    "text": "3.2 Termes clés\nRStudio - RStudio est une interface utilisateur graphique (GUI) qui facilite l’utilisation de R. Pour en savoir plus, consultez la section RStudio.\nObjets - Tout ce que vous stockez dans R - les jeu de données, les variables, une liste de noms de villages, un population total d’habitants, et même les résultats tels que les graphiques - sont des objets auxquels on attribue un nom et qui peuvent être référencés dans des commandes ultérieures. Pour en savoir plus, consultez la section Objets.\nFonctions - Une fonction est une opération de code qui accepte des entrées et renvoie une sortie transformée. Pour en savoir plus, consultez la section Fonctions.\nPaquets - Un paquet R est un ensemble de fonctions partageables. Pour en savoir plus, consultez la section Packages.\nScripts - Un script est le fichier document qui contient vos commandes. Pour en savoir plus, consultez la section Scripts",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#learning",
    "href": "new_pages/basics.fr.html#learning",
    "title": "3  R - les bases",
    "section": "3.3 Ressources pour l’apprentissage",
    "text": "3.3 Ressources pour l’apprentissage\n\nRessources au sein de RStudio\nDocumentation d’aide\nRecherchez dans l’onglet “Aide” de RStudio la documentation sur les paquets R et les fonctions spécifiques. Cet onglet se trouve dans le volet qui contient également les fichiers, les graphiques et les paquets (généralement dans le volet inférieur à droit). Comme raccourci, vous pouvez également taper le nom d’un paquet ou d’une fonction dans la console R après un point d’interrogation pour ouvrir la page d’aide correspondante. N’incluez pas les parenthèses.\nPar exemple : ?filter ou ?diagrammeR.\nTutoriels interactifs\nIl existe plusieurs façons d’apprendre R de manière interactive dans RStudio.\nRStudio lui-même offre un volet Tutoriel qui est alimenté par le paquet R learnr. Il suffit d’installer ce paquet et d’ouvrir un tutoriel via le nouvel onglet “Tutorial” dans le volet supérieur droit de RStudio (qui contient également les onglets Environnement et Historique).\nLe paquet R swirl propose des cours interactifs dans la console R. Installez et chargez ce paquet, puis lancez la commande swirl() (parenthèses vides) dans la console R. Vous verrez apparaître des invites dans la console. Répondez en tapant dans la console. Elle vous guidera à travers un cours de votre choix.\n\n\nFiches d’aide-mémoire\nIl existe de nombreuses fiches d’aide-mémoire au format PDF disponibles sur le site Web de RStudio, par exemple :\n\nFacteurs avec le paquet forcats\nDates et heures avec le paquet lubridate\nChaînes de caractères avec le paquet stringr\nOpérations itératives avec le paquet purrr\nImportation de données\nAide-mémoire pour la transformation des données avec le paquet dplyr\nR Markdown (pour créer des documents comme PDF, Word, Powerpoint…)\nShiny (pour créer des applications Web interactives)\nVisualisation de données avec le paquet ggplot2\nCartographie (SIG)\nPaquet leaflet (cartes interactives)\nPython avec R (paquet reticulate)\n\nIl existe également une ressource R en ligne spécialement destinée aux utilisateurs d’Excel.\n\n\nTwitter\nR possède une communauté Twitter dynamique où vous pouvez apprendre des astuces, des raccourcis et des nouvelles - suivez ces comptes :\n\nSuivez-nous ! @epiRhandbook\nR Function A Day @rfuntionaday est une ressource incroyable\nR pour la science des données @rstats4ds\nRStudio @RStudio\nConseils sur RStudio@rstudiotips\nR-Bloggers @Rbloggers\nR-ladies @RLadiesGlobal\nHadley Wickham @hadleywickham\n\nAussi :\n#epitwitter et #rstats\n\n\nRessources gratuites en ligne\nUn texte définitif est le livre R for Data Science de Garrett Grolemund et Hadley Wickham.\nLe site Web du projet R4Epis vise à “développer des outils standardisés de nettoyage, d’analyse et de rapport des données pour couvrir les types courants d’épidémies et d’enquêtes auprès de la population qui seraient menées dans le cadre d’une réponse d’urgence de MSF”. Vous y trouverez des supports de formation aux bases de R, des modèles de rapports RMarkdown sur les épidémies et les enquêtes, ainsi que des tutoriels pour vous aider à les configurer.\n\n\nLangues autres que l’anglais\nMateriales de RStudio en Español\nIntroduction à R et au tidyverse (Francais)",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#installation",
    "href": "new_pages/basics.fr.html#installation",
    "title": "3  R - les bases",
    "section": "3.4 Installation",
    "text": "3.4 Installation\n\nR et RStudio\nComment installer R\nVisitez ce site Web https://www.r-project.org/ et téléchargez la dernière version de R adaptée à votre ordinateur.\nComment installer RStudio\nVisitez ce site Web https://rstudio.com/products/rstudio/download/ et téléchargez la dernière version de bureau gratuite de RStudio adaptée à votre ordinateur.\nAutorisations requises\nNotez que vous devez installer R et RStudio sur un lecteur sur lequel vous avez des droits de lecture et d’écriture. Sinon, votre capacité à installer des paquets R (ce qui arrive fréquemment) sera affectée. Si vous rencontrez des problèmes, essayez d’ouvrir RStudio en faisant un clic droit sur l’icône et en sélectionnant “Exécuter en tant qu’administrateur”. Vous trouverez d’autres conseils sur la page R sur les lecteurs réseau.\nComment mettre à jour R et RStudio\nVotre version de R est imprimée dans la Console R au démarrage. Vous pouvez également exécuter sessionInfo().\nPour mettre à jour R, allez sur le site web mentionné ci-dessus et réinstallez R. Alternativement, vous pouvez utiliser le paquet installr (sous Windows) en exécutant installr::updateR(). Cela ouvrira des boîtes de dialogue pour vous aider à télécharger la dernière version de R et à mettre à jour vos paquets vers la nouvelle version de R. Plus de détails peuvent être trouvés dans la documentation de installr.\nSachez que l’ancienne version de R existera toujours sur votre ordinateur. Vous pouvez temporairement exécuter une ancienne version (ancienne “installation”) de R en cliquant sur “Outils” -&gt; “Options globales” dans RStudio et en choisissant une version de R. Cela peut être utile si vous voulez utiliser un paquet qui n’a pas été mis à jour pour fonctionner sur la version la plus récente de R.\nPour mettre à jour RStudio, vous pouvez aller sur le site Web ci-dessus et retélécharger RStudio. Une autre option consiste à cliquer sur “Aide” -&gt; “Vérifier les mises à jour” dans RStudio, mais cela peut ne pas montrer les toutes dernières mises à jour.\nPour savoir quelles versions de R, RStudio ou des paquets ont été utilisées lors de la réalisation de ce manuel, consultez la page sur Notes techniques et choix éditoriaux.\n\n\nAutres logiciels que vous pourriez avoir besoin d’installer\n\nTinyTeX (pour la compilation d’un document RMarkdown au format PDF)\nPandoc (pour compiler des documents RMarkdown)\nRTools (pour construire des paquets pour R)\nphantomjs (pour enregistrer des images fixes de réseaux animés, tels que des chaînes de transmission)\n\n\nTinyTex\nTinyTex est une distribution LaTeX personnalisée, utile lorsqu’on essaie de produire des PDF à partir de R. Voir https://yihui.org/tinytex/ pour plus d’informations.\nPour installer TinyTex à partir de R :\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n\n# pour désinstaller TinyTeX, lancez tinytex::uninstall_tinytex()\n\n\n\nPandoc\nPandoc est un convertisseur de document, un logiciel séparé de R. Il est fourni avec RStudio et ne devrait pas avoir besoin d’être téléchargé. Il aide le processus de conversion de documents Rmarkdown à des formats comme .pdf et ajoute des fonctionnalités complexes.\n\n\nRTools\nRTools est une collection de logiciels permettant de construire des paquets pour R.\nInstaller à partir de ce site web : https://cran.r-project.org/bin/windows/Rtools/\n\n\nphantomjs\nCet outil est souvent utilisé pour faire des “captures d’écran” despages web. Par exemple, lorsque vous faites une chaîne de transmission avec le paquet epicontacts, un fichier HTML interactif et dynamique est produit. Si vous voulez une image statique, il peut être utile d’utiliser le paquet webshot pour automatiser ce processus. Cela nécessite le programme externe “phantomjs”. Vous pouvez installer phantomjs via le paquet webshot avec la commande webshot::install_phantomjs().\n\n\n\n\n3.4.1 RStudio\n\n\nOrientation de RStudio\nD’abord, ouvrez RStudio. Comme leurs icônes peuvent être très similaires, assurez-vous que vous ouvrez bien RStudio et non pas R.\nPour que RStudio fonctionne, vous devez également avoir R installé sur l’ordinateur (voir ci-dessus pour les instructions d’installation).\nRStudio est une interface (GUI) pour une utilisation plus facile de R. Vous pouvez considérer R comme le moteur d’un véhicule, qui effectue le travail crucial, et RStudio comme le corps du véhicule (avec les sièges, les accessoires, etc.) qui vous aide à utiliser le moteur pour avancer ! Vous pouvez consulter la fiche technique complète de l’interface utilisateur de RStudio (PDF) ici\nPar défaut, RStudio affiche quatre volets rectangulaires.\n\n\n\n\n\n\n\n\n\nTIP: Si votre RStudio n’affiche qu’un seul volet gauche, c’est parce que vous n’avez pas encore de scripts ouverts.\nLe volet source\nCe volet, par défaut en haut à gauche, est un espace pour éditer, exécuter et enregistrer vos scripts. Les scripts contiennent les commandes que vous souhaitez exécuter. Ce volet peut également afficher des ensembles de données (cadres de données) pour les visualiser.\nPour les utilisateurs de Stata, ce volet est similaire aux fenêtres Do-file et Data Editor.\nLe volet Console R\nLa console R, qui est par défaut le volet gauche ou inférieur gauche de R Studio, est le siège du “moteur” R. C’est là que les commandes sont réellement exécutées et que les sorties non graphiques et les messages d’erreur/d’avertissement apparaissent. Vous pouvez saisir et exécuter directement des commandes dans la console R, mais sachez que ces commandes ne sont pas enregistrées comme c’est le cas lorsque vous exécutez des commandes à partir d’un script.\nSi vous êtes familier avec Stata, la console R ressemble à la fenêtre de commande et à la fenêtre des résultats.\nLe volet Environnement\nCe volet, situé par défaut en haut à droite, est le plus souvent utilisé pour afficher de brefs résumés des objets de l’environnement R dans la session en cours. Ces objets peuvent inclure des ensembles de données importés, modifiés ou créés, des paramètres que vous avez définis (par exemple, une semaine épi spécifique pour l’analyse), ou des vecteurs ou des listes que vous avez définis pendant l’analyse (par exemple, les noms des régions). Vous pouvez cliquer sur la flèche à côté du nom d’un cadre de données pour voir ses variables.\nDans Stata, cette fenêtre est très similaire à celle du gestionnaire de variables.\nCe volet contient également l’onglet “Historique” où vous pouvez voir les commandes que vous avez exécutées précédemment. Il comporte également un onglet “Tutoriel” où vous pouvez suivre des tutoriels R interactifs si vous avez installé le paquet learnr. En outre, il existe un volet “Connexions” pour les connexions aux bases de données externes. Si vous avez lié le répertoire actif à un dépôt sur Github, il y aura également un volet “Git”.\nVolets Graphiques, visionneuse, paquets et aide\nLe volet inférieur droit comprend plusieurs onglets importants. Les graphiques de tracé typiques, y compris les cartes, s’affichent dans le volet Tracé. Les sorties interactives ou HTML s’affichent dans le volet Visionneuse. Le volet Aide permet d’afficher la documentation et les fichiers d’aide. Le volet Fichiers est un navigateur qui peut être utilisé pour ouvrir ou supprimer des fichiers. Le volet Paquets vous permet de voir, d’installer, de mettre à jour, de supprimer, de charger/décharger des paquets R et de voir quelle version du paquet vous avez. Pour en savoir plus sur les paquets, consultez la section paquets ci-dessous.\nCe volet contient les équivalents Stata des fenêtres Plots Manager et Project Manager.\n\n\nParamètres RStudio\nModifiez les paramètres et l’apparence de RStudio dans le menu déroulant Outiles, en sélectionnant Options globales. Vous pouvez y modifier les paramètres par défaut, y compris l’apparence/couleur de fond.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRedémarrage\nSi votre R se fige, vous pouvez redémarrer R en allant dans le menu Session et en cliquant sur “Redémarrer R”. Cela vous évite de devoir fermer et ouvrir RStudio. Tout ce qui se trouve dans votre environnement R sera supprimé lorsque vous ferez cela.\n\n\nRaccourcis clavier\nVous trouverez ci-dessous quelques raccourcis clavier très utiles. Vous trouverez tous les raccourcis clavier pour Windows, Max et Linux sur la deuxième page de ce fichier technique par RStudio.\n\n\n\n\n\n\n\n\nWindows/Linux\nMac\nAction\n\n\n\n\nEsc\nEsc\nInterrompre la commande en cours (utile si vous avez accidentellement lancé une commande incomplète et que vous ne pouvez pas éviter de voir “+” dans la console R)\n\n\nCtrl+s\nCmd+s\nSauvegarder (script)\n\n\nTab\nTab\nAutocomplétion\n\n\nCtrl + Enter\nCmd + Enter\nExécuter la ou les ligne(s) courante(s)/sélection(s) de code\n\n\nCtrl + Shift + C\nCmd + Shift + c\ncommenter/dé-commenter les lignes souslignées\n\n\nAlt + -\nOption +\nInsérer &lt;-\n\n\nCtrl + Shift + m\nCmd + Shift + m\nInsérer %&gt;%\n\n\nCtrl + l\nCmd + l\nEffacer le contenu de la console R\n\n\nCtrl + Alt + b\nCmd + Option + b\nExécuter du début à la ligne courante\n\n\nCtrl + Alt + t\nCmd + Option + t\nExécuter la section de code actuelle (R Markdown)\n\n\nCtrl + Alt + i\nCmd + Shift + r\nInsérer un morceau de code (en R Markdown)\n\n\nCtrl + Alt + c\nCmd + Option + c\nExécuter le morceau de code actuel (en R Markdown)\n\n\nFlèches haut/bas dans la console R\nIdem\nBasculer entre les commandes récemment exécutées\n\n\nShift + flèches haut/bas dans le script\nIdem\nSélectionner plusieurs lignes de code\n\n\nCtrl + f\nCmd + f\nRechercher et remplacer dans le script actuel\n\n\nCtrl + Shift + f\nCmd + Shift + f\nRechercher dans les dossiers (rechercher/remplacer dans plusieurs scripts)\n\n\nAlt + l\nCmd + Option + l\nPlier le code sélectionné\n\n\nShift + Alt + l\nCmd + Shift + Option+l\nDéplier le code sélectionné\n\n\n\nTIP: Utilisez votre touche de tabulation lorsque vous tapez pour activer la fonctionnalité de complétion automatique de RStudio. Cela peut éviter les fautes d’orthographe. Appuyez sur la touche Tab pendant la saisie pour produire un menu déroulant de fonctions et d’objets probables, en fonction de ce que vous avez tapé jusqu’à présent.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#functions",
    "href": "new_pages/basics.fr.html#functions",
    "title": "3  R - les bases",
    "section": "3.5 Fonctions",
    "text": "3.5 Fonctions\nLes fonctions sont au cœur de l’utilisation de R. Les fonctions vous permettent d’effectuer des tâches et des opérations. De nombreuses fonctions sont installées avec R, beaucoup d’autres sont disponibles à télécharger dans des paquets (expliqués dans la section paquets), et vous pouvez même écrire vos propres fonctions personnalisées !\nCette section de base sur les fonctions explique :\n\nCe qu’est une fonction et comment elle fonctionne\nCe que sont les paramètres des fonctions\nComment obtenir de l’aide pour comprendre une fonction\n\nUne note rapide sur la syntaxe : Dans ce manuel, les fonctions sont écrites en code-texte avec des parenthèses vides, comme ceci : filter(). Comme expliqué dans la section paquets, les fonctions sont téléchargées dans des paquets. Dans ce manuel, les noms de paquets sont écrits en gras, comme dplyr. Parfois, dans le code d’exemple, vous pouvez voir le nom de la fonction lié explicitement au nom de son paquet avec deux points de suspension (::) comme ceci : dplyr::filter(). Le but de ce lien est expliqué dans la section sur les paquets.\n\n\nFonctions simples\nUne fonction est comme une machine qui reçoit des entrées, effectue une action avec ces entrées, et produit une sortie. La nature de la sortie dépend de la fonction.\nLes fonctions opèrent généralement sur un objet placé entre les parenthèses de la fonction. Par exemple, la fonction sqrt() calcule la racine carrée d’un nombre :\n\nsqrt(49)\n\n[1] 7\n\n\nL’objet fourni à une fonction peut également être une colonne dans un jeu de données (voir la section Objets pour plus de détails sur tous les types d’objets). Comme R peut stocker plusieurs jeux de données, vous devrez spécifier à la fois le jeu de données et la colonne. Une façon de le faire est d’utiliser la notation $ pour lier le nom du jeu de données et le nom de la colonne (dataset$column). Dans l’exemple ci-dessous, la fonction summary() est appliquée à la colonne numérique age du jeu de données linelist, et la sortie est un résumé des valeurs numériques et manquantes de la colonne.\n\n# Imprimez les statistiques sommaires de la colonne 'age' dans le jeu de données 'linelist'.\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n\nNOTE: En coulisses, une fonction représente un code supplémentaire complexe qui a été regroupé pour l’utilisateur dans une seule commande simple.\n\n\n\nFonctions à paramètres multiples\nLes fonctions demandent souvent plusieurs entrées, appelées paramètres, situées entre les parenthèses de la fonction, généralement séparées par des virgules.\n\nCertains paramètres sont obligatoires pour que la fonction fonctionne correctement, d’autres sont facultatifs\n\nLes paramètres facultatifs ont des valeurs par défaut\n\nLes paramètres peuvent prendre des entrées de type caractère, numérique, logique (VRAI/FAUX) et autres.\n\nVoici une fonction fictive amusante, appelée oven_bake() (cuisson au four), comme exemple d’une fonction typique. Elle prend un objet comme entrée (par exemple un jeu de données, ou dans cet exemple “pâte”) et effectue des opérations sur celui-ci comme spécifié par des paramètres supplémentaires (minutes = et température =). La sortie peut être imprimée sur la console, ou sauvegardée comme un objet en utilisant l’opérateur d’affectation &lt;-.\n\n\n\n\n\n\n\n\n\nDans un exemple plus réaliste, la commande age_pyramid() ci-dessous produit un graphique de pyramide des âges basé sur des groupes d’âge définis et une colonne de division binaire, comme le genre gender. La fonction reçoit trois paramètres entre parenthèses, séparés par des virgules. Les valeurs fournies aux paramètres établissent linelist comme le cadre de données à utiliser, age_cat5 comme la colonne à compter, et gender comme la colonne binaire à utiliser pour diviser la pyramide par couleur.\n\n# Créer une pyramide des âges\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n\n\n\n\n\n\n\n\nLa commande ci-dessus peut être écrite de manière équivalente comme ci-dessous, dans un style plus long avec une nouvelle ligne pour chaque argument. Ce style peut être plus facile à lire, et plus facile d’écrire des “commentaires” avec # pour expliquer chaque partie (commenter abondamment est une bonne pratique !). Pour exécuter cette commande plus longue, vous pouvez souligner la commande entière et cliquer sur “Run”, ou simplement placer votre curseur sur la première ligne et appuyer simultanément sur les touches Ctrl et Enter.\n\n# Créer une pyramide des âges\nage_pyramid(\n  data = linelist,        # utiliser la liste linéaire des cas\n  age_group = \"age_cat5\", # fournir une colonne de groupe d'âge\n  split_by = \"gender\"     # utiliser la colonne genre pour les deux côtés de la pyramide\n  )\n\n\n\n\n\n\n\n\nLa première moitié d’une affectation de paramètre (par exemple data =) n’a pas besoin d’être spécifiée si les paramètres sont écrits dans un ordre spécifique (spécifié dans la documentation de la fonction). Le code ci-dessous produit exactement la même pyramide que ci-dessus, parce que la fonction attend l’ordre des paramètres : cadre de données, le variable age_group, puis le variable split_by.\n\n# Cette commande produira exactement le même graphique que ci-dessus\nage_pyramid(linelist, \"age_cat5\", \"gender\")\n\nUne commande age_pyramid() plus complexe pourrait inclure les paramètres optionnels pour :\n\nAfficher les proportions au lieu des nombres (définissez proportional = TRUE (vrai) quand la valeur par défaut est FALSE (faux))\nSpécifier les deux couleurs à utiliser (pal = est l’abréviation de “palette” et est fourni avec un vecteur de deux noms de couleurs. Voir la page objets pour savoir comment la fonction c() fabrique un vecteur).\n\nNOTE: Pour les paramètres que vous spécifiez avec les deux parties du paramètre (par exemple proportional = TRUE), leur ordre parmi tous les paramètres n’a pas d’importance.\n\nage_pyramid(\n  linelist,                    # utiliser la liste linéaire des cas\n  \"age_cat5\",                  # colonne de groupe d'âge\n  \"gender\",                    # répartition par genre\n  proportional = TRUE,         # pourcentage au lieu du nombre\n  pal = c(\"orange\", \"purple\")  # couleurs\n  )\n\n\n\n\n\n\n\n\n\n\n\nEcrire des fonctions\nR est un langage orienté autour des fonctions, vous devez donc vous sentir capable d’écrire vos propres fonctions. La création de fonctions présente plusieurs avantages :\n\nFaciliter la programmation modulaire - la séparation du code en morceaux indépendants et gérables\nRemplacer le copier-coller répétitif, qui peut être source d’erreurs\nDonner des noms mémorisables aux morceaux de code\n\nL’écriture d’une fonction est traitée en détail à la page Écriture de fonctions.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#packages",
    "href": "new_pages/basics.fr.html#packages",
    "title": "3  R - les bases",
    "section": "3.6 Paquets",
    "text": "3.6 Paquets\nLes paquets contiennent des fonctions.\nUn paquet en R est un ensemble partageable de code et de documentation qui contient des fonctions prédéfinies. Les utilisateurs de la communauté R développent en permanence des packages répondant à des problèmes spécifiques; donc il est probable que l’un d’entre eux puisse vous aider dans votre travail ! Vous allez installer et utiliser des centaines de paquets dans votre utilisation de R.\nÀ l’installation, R contient des paquets et des fonctions “de base” qui effectuent des tâches élémentaires communes. Mais de nombreux utilisateurs de R créent des fonctions spécialisées, qui sont vérifiées par la communauté R et que vous pouvez télécharger en tant que paquet pour votre propre usage. Dans ce manuel, les noms des paquets sont écrits en gras. L’un des aspects les plus difficiles de R est qu’il existe souvent de nombreuses fonctions ou paquets parmi lesquels on peut choisir pour effectuer une tâche donnée.\n\nInstaller et charger\nLes fonctions sont contenues dans des paquets qui peuvent être téléchargés (“installés”) sur votre ordinateur à partir d’Internet. Une fois qu’un paquet est téléchargé, il est stocké dans votre “bibliothèque”. Vous pouvez alors accéder aux fonctions qu’il contient pendant votre séance R actuelle en “chargeant” le paquet.\nPensez à R comme votre bibliothèque personnelle : Lorsque vous téléchargez un paquet, votre bibliothèque gagne un nouveau livre de fonctions, mais chaque fois que vous voulez utiliser une fonction de ce livre, vous devez emprunter (“charger”) ce livre dans votre bibliothèque.\nEn résumé : pour utiliser les fonctions disponibles dans un paquet R, deux étapes doivent être mises en œuvre :\n\nLe paquet doit être installé (une fois), et\nLe paquet doit être chargé (à chaque séance R)\n\n\nVotre bibliothèque\nVotre “bibliothèque” est en fait un dossier sur votre ordinateur, contenant un dossier pour chaque paquet qui a été installé. Déterminez où R est installé sur votre ordinateur, et cherchez un dossier appelé “win-library”. Par exemple : R\\win-library\\4.0 (4.0 est la version de R). Notez que vous aurez une bibliothèque différente pour chaque version de R que vous avez téléchargée.\nVous pouvez imprimer le chemin d’accès à votre bibliothèque en entrant.libPaths() (parenthèses vides). Ceci devient particulièrement important si vous travaillez avec R sur des lecteurs réseau.\n\n\nInstaller à partir du CRAN\nLe plus souvent, les utilisateurs de R téléchargent des paquets depuis CRAN. CRAN (Comprehensive R Archive Network) est un entrepôt public en ligne de paquets R qui ont été publiés par des membres de la communauté R.\nVous vous inquiétez des virus et de la sécurité lorsque vous téléchargez un paquet depuis CRAN ? Lisez cet article à ce sujet.\n\n\nComment installer et charger\nDans ce manuel, nous suggérons d’utiliser le paquet pacman (abréviation de “package manager” en anglais). Il offre une fonction pratique p_load() qui installera un paquet si nécessaire et le chargera pour l’utiliser dans la séance R actuelle.\nLa syntaxe est assez simple. Il suffit de lister les noms des paquets entre les parenthèses de p_load(), séparés par des virgules.\nLa commande ci-dessous installera les paquets rio, tidyverse, et here s’ils ne sont pas encore installés, et les chargera pour les utiliser. Cela rend l’approche p_load() pratique et concise si vous partagez des scripts avec d’autres personnes. Notez que les noms des paquets sont sensibles à la casse.\n\n# Installer (si nécessaire) et charger les paquets pour l'utilisation\npacman::p_load(rio, tidyverse, here)\n\nNotez que nous avons utilisé la syntaxe pacman::p_load() qui écrit explicitement le nom du paquet (pacman) avant le nom de la fonction (p_load()), reliés par deux deux points ::. Cette syntaxe est utile car elle charge également le paquet pacman (en supposant qu’il soit déjà installé).\nIl existe d’autres fonctions R de base que vous verrez souvent. La fonction R de base pour installer un paquet est install.packages(). Le nom du paquet à installer doit être fourni entre les parenthèses et entre guillemets. Si vous voulez installer plusieurs paquets en une seule commande, ils doivent être listés dans un vecteur de caractères c().\nRemarque : cette commande installe un paquet, mais ne le charge pas pour l’utiliser dans la séance en cours.\n\n# Installer un seul paquet avec la base R\ninstall.packages(\"tidyverse\")\n\n# Installer plusieurs paquets avec la base R\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n\nL’installation peut également être effectuée par pointer-cliquer en allant dans le panneau “Packages” de RStudio, en cliquant sur “Installer” et en recherchant le nom du paquet souhaité.\nLa fonction base de R pour charger un paquet à utiliser (après qu’il ait été installé) est library(). Elle ne peut charger qu’un seul paquet à la fois (une autre raison d’utiliser p_load()). Vous pouvez fournir le nom du paquet avec ou sans guillemets.\n\n# Charger des paquets à utiliser, avec la base R\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n\nPour vérifier si un paquet est installé et/ou chargé, vous pouvez afficher le panneau des paquets dans RStudio. Si le paquet est installé, il est affiché avec son numéro de version. Si sa case est cochée, il est chargé pour la séance en cours.\nInstallation depuis Github\nParfois, vous avez besoin d’installer un paquet qui n’est pas encore disponible sur CRAN. Ou peut-être que le paquet est disponible sur CRAN mais que vous voulez la version de développement avec de nouvelles fonctionnalités qui ne sont pas encore proposées dans la version CRAN publiée, plus stable. Ces versions sont souvent hébergées sur le site Web github.com dans un “dépôt” de code libre et public. Pour en savoir plus sur Github, consultez la page du manuel intitulée Version control et collaboration avec GitHub.\nPour télécharger des paquets R depuis Github, vous pouvez utiliser la fonction p_load_gh() de pacman, qui installera le paquet si nécessaire, et le chargera pour l’utiliser dans votre séance R actuelle. Les alternatives à l’installation incluent l’utilisation des paquets remotes ou devtools. Pour en savoir plus sur toutes les fonctions de pacman, consultez la documentation du paquet.\nPour installer à partir de Github, vous devez fournir plus d’informations. Vous devez fournir :\n\nL’ID Github (nom d’utilisateur) du propriétaire du dépôt.\nLe nom du dépôt qui contient le paquet.\n(facultatif) Le nom de la “branche” (version de développement spécifique) que vous souhaitez télécharger.\n\nDans les exemples ci-dessous, le premier mot entre guillemets est l’ID Github du propriétaire du dépôt. Après la barre oblique est le nom du dépôt (typiquement le nom du paquet).\n\n# Installer/charger le paquet epicontacts depuis son dépôt Github\np_load_gh(\"reconhub/epicontacts\")\n\nSi vous voulez installer à partir d’une “branche” (version) autre que la branche principale, ajoutez le nom de la branche après un “@”, après le nom du dépôt.\n\n# Installer la branche \"timeline\" du paquet epicontacts depuis Github\np_load_gh(\"reconhub/epicontacts@timeline\")\n\nS’il n’y a pas de différence entre la version Github et la version sur votre ordinateur, aucune action ne sera entreprise. Vous pouvez “forcer” une réinstallation en utilisant p_load_current_gh() avec le paramètre update = TRUE. Lisez plus sur pacman dans cette vignette en ligne\nInstallation à partir d’un ZIP ou d’un TAR\nVous pouvez installer le paquet à partir d’une URL :\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos = NULL, type = \"source\")\n\nOu bien, le télécharger sur votre ordinateur dans un fichier zippé :\nOption 1 : utiliser install_local() du paquet remotes.\n\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\n\nOption 2 : en utilisant install.packages() du R de base, en fournissant le chemin d’accès au fichier ZIP et en définissant type = \"source\" et repos = NULL.\n\ninstall.packages(\"~/Downloads/dplyr-master.zip\", \n                 type = \"source\", \n                 repos = NULL)\n\n\n\n\nSyntaxe du code\nPour plus de clarté dans ce manuel, les fonctions sont parfois précédées du nom de leur paquet en utilisant le symbole :: de la manière suivante : nom_du_paquet::nom_de_la_fonction().\nUne fois qu’un paquet est chargé pour une séance, ce style explicite n’est plus nécessaire. On peut simplement utiliser nom_de_la_fonction(). Cependant, écrire le nom du paquet est utile lorsqu’un nom de fonction est commun et peut exister dans plusieurs paquets (par exemple, plot()). L’écriture du nom du paquet chargera également le paquet s’il n’est pas déjà chargé.\n\n# Cette commande utilise le paquet \"rio\" et sa fonction \"import()\" pour importer un jeu de données\nlinelist &lt;- rio::import(\"linelist.xlsx\", which = \"Sheet1\")\n\n\n\nAide sur les fonctions\nPour en savoir plus sur une fonction, vous pouvez la rechercher dans l’onglet Aide du RStudio en bas à droite. Vous pouvez également lancer une commande comme ?thefunctionname (mettez le nom de la fonction après un point d’interrogation) et la page d’aide apparaîtra dans le volet d’aide. Enfin, essayez de rechercher des ressources en ligne.\n\n\nMettre à jour les paquets\nVous pouvez mettre à jour les paquets en les réinstallant. Vous pouvez également cliquer sur le bouton vert “Update” dans votre panneau “RStudio Packages” pour voir quels paquets ont de nouvelles versions à installer. Sachez que votre ancien code peut avoir besoin d’être mis à jour s’il y a une révision majeure du fonctionnement d’une fonction !\n\n\nSupprimer des paquets\nUtilisez p_delete() de pacman, ou remove.packages() de base R. Alternativement, allez chercher le dossier qui contient votre bibliothèque et supprimez manuellement le dossier.\n\n\nDépendances\nLes paquets dépendent souvent d’autres paquets pour fonctionner. Ceux-ci sont appelés dépendances. Si une dépendance ne s’installe pas, le paquet qui en dépend peut également ne pas s’installer.\nVoir les dépendances d’un paquet avec p_depends(), et voir quels paquets en dépendent avec p_depends_reverse().\n\n\nFonctions masquées\nIl n’est pas rare que deux paquets ou plus contiennent le même nom de fonction. Par exemple, le paquet dplyr possède une fonction filter(), mais le paquet stats aussi. La fonction filter() par défaut dépend de l’ordre dans lequel ces paquets sont chargés pour la première fois dans la séance R - le dernier sera la fonction par défaut de la commande filter().\nVous pouvez vérifier l’ordre dans votre panneau Environnement de R Studio - cliquez sur la liste déroulante pour “Global Environment” et voyez l’ordre des paquets. Les fonctions des paquets inférieurs dans cette liste déroulante masqueront les fonctions du même nom dans les paquets qui apparaissent plus haut dans la liste déroulante. Lors du premier chargement d’un paquet, R vous avertira dans la console si le masquage se produit, mais il est facile de ne pas le voir.\n\n\n\n\n\n\n\n\n\nVoici comment vous pouvez corriger le masquage :\n\nSpécifiez le nom du paquet dans la commande. Par exemple, utilisez dplyr::filter()\nRéorganisez l’ordre dans lequel les paquets sont chargés (par exemple, dans p_load()), et démarrez une nouvelle séance R.\n\n\n\nDétacher / décharger\nPour détacher (décharger) un paquet, utilisez cette commande, avec le nom correct du paquet et un seul deux-points. Notez que cela peut ne pas résoudre le masquage.\n\ndetach(package:NOM_DU_PAQUET_ICI, unload = TRUE)\n\n\n\nInstaller une ancienne version\nConsultez ce guide pour installer une ancienne version d’un paquet particulier.\n\n\nPaquets suggérés\nVoir la page Paquets suggérés pour une liste de paquets que nous recommandons pour l’épidémiologie quotidienne.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#scripts",
    "href": "new_pages/basics.fr.html#scripts",
    "title": "3  R - les bases",
    "section": "3.7 Scripts",
    "text": "3.7 Scripts\nLes scripts sont une partie fondamentale de la programmation. Ce sont des documents qui contiennent vos commandes (par exemple, des fonctions pour créer et modifier des jeux de données, imprimer des visualisations, etc). Vous pouvez sauvegarder un script et l’exécuter à nouveau ultérieurement. Le stockage et l’exécution de vos commandes à partir d’un script présentent de nombreux avantages (par rapport à la saisie des commandes une par une dans la “ligne de commande” de la console R) :\n\nPortabilité : vous pouvez partager votre travail avec d’autres personnes en leur envoyant vos scripts\nReproductibilité : pour que vous et les autres sachiez exactement ce que vous avez fait\nContrôle de version : pour que vous puissiez suivre les modifications apportées par vous-même ou par vos collègues\nCommentaire/annotation : pour expliquer à vos collègues ce que vous avez fait\n\n\nCommentaire\nDans un script, vous pouvez également annoter (“commenter”) votre code R. Les commentaires sont utiles pour expliquer à vous-même et aux autres lecteurs ce que vous faites. Vous pouvez ajouter un commentaire en tapant le symbole dièse (#) et en écrivant votre commentaire après. Le texte commenté apparaîtra dans une couleur différente de celle du code R.\nTout code écrit après le # ne sera pas exécuté. Par conséquent, placer un # avant le code est également un moyen utile de bloquer temporairement une ligne de code (“commenter”) si vous ne souhaitez pas la supprimer). Vous pouvez mettre en commentaire plusieurs lignes à la fois en les soulignant et en appuyant sur Ctrl+Shift+c (Cmd+Shift+c sur Mac).\n\n# Un commentaire peut être sur une ligne par lui-même, ex.:\n# Importer des données:\nlinelist &lt;- import(\"linelist_raw.xlsx\") %&gt;% # un commentaire peut aussi venir après le code\n     # filter(age &gt; 50)\n     # Il peut aussi être utilisé pour désactiver une ligne de code\ncount()\n\nVous trouverez ci-dessous quelques conseils essentiels pour commenter et annoter votre code :\n\nCommentez ce que vous faites et pourquoi vous le faites\nDécoupez votre code en sections logiques\nAccompagnez votre code d’une description textuelle étape par étape de ce que vous faites (par exemple, des étapes numérotées).\n\n\n\nStyle\nIl est important d’être conscient de votre style de codage, surtout si vous travaillez en équipe. Nous préconisons le tidyverse guide de style. Il existe également des paquets tels que styler et lintr qui vous aident à vous conformer à ce style.\nQuelques points très basiques pour rendre votre code lisible pour les autres:\n\nLorsque vous nommez des objets, n’utilisez que des lettres minuscules, des chiffres et des traits de soulignement _, par exemple mes_donnees\nUtilisez fréquemment des espaces, y compris autour des opérateurs, par exemple n = 1 et age_nouveau &lt;- age_vieillesse + 3.\n\n\n\nExemple de script\nVous trouverez ci-dessous un exemple d’un court script R. N’oubliez pas que plus vous expliquerez succinctement votre code dans les commentaires, plus vos collègues vous apprécieront !\n\n\n\n\n\n\n\n\n\n\n\n\nR markdown\nUn script R markdown est un type de script R dans lequel le script lui-même devient un document de sortie (PDF, Word, HTML, Powerpoint, etc.). Ce sont des outils incroyablement utiles et polyvalents, souvent utilisés pour créer des rapports dynamiques et automatisés. Même ce site Web et ce manuel sont produits à l’aide de scripts R markdown !\nIl convient de noter que les utilisateurs débutants de R peuvent également utiliser R Markdown - ne vous laissez pas intimider !Pour en savoir plus, consultez la page du manuel consacrée aux rapports avec R Markdown.\n\n\n\nCarnets de notes R\nIl n’y a pas de différence entre écrire dans un Rmarkdown et un R notebook. Cependant, l’exécution du document diffère légèrement. Voir ce site pour plus de détails.\n\n\n\nShiny\nLes applications/sites web Shiny sont contenus dans un script, qui doit être nommé app.R. Ce fichier comporte trois éléments :\n\nUne interface utilisateur (ui)\nUne fonction serveur\nUn appel à la fonction shinyApp\n\nConsultez la page du manuel sur les teableaux de bord avec Shiny, ou ce tutoriel en ligne : Tutoriel Shiny\nAuparavant, le fichier ci-dessus était divisé en deux fichiers (ui.R et server.R).\n\n\nRepli du code\nVous pouvez replier des portions de code pour rendre votre script plus facile à lire.\nPour ce faire, créez un en-tête de texte avec #, écrivez votre en-tête, et faites-le suivre d’au moins 4 tirets (-), hachages (#) ou égaux (=). Lorsque vous aurez fait cela, une petite flèche apparaîtra dans la “gouttière” à gauche (près du numéro de ligne). Vous pouvez cliquer sur cette flèche et sur le code situé en dessous jusqu’à ce que l’en-tête suivant se réduise et qu’une icône à double flèche apparaisse à sa place.\nPour développer le code, cliquez à nouveau sur la flèche dans la gouttière ou sur l’icône à double flèche. Il existe également des raccourcis clavier, comme expliqué dans la section RStudio de cette page.\nEn créant des en-têtes avec #, vous activerez également la table des matières au bas de votre script (voir ci-dessous) que vous pouvez utiliser pour naviguer dans votre script. Vous pouvez créer des sous-titres en ajoutant d’autres symboles, par exemple # pour les titres primaires, ## pour les titres secondaires et ### pour les titres tertiaires.\nVous trouverez ci-dessous deux versions d’un exemple de script. À gauche, l’original avec des en-têtes commentés. À droite, quatre tirets ont été écrits après chaque en-tête, les rendant ainsi repliables. Deux d’entre eux ont été réduits, et vous pouvez voir que la table des matières en bas de page affiche maintenant chaque section.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD’autres zones de code qui sont automatiquement éligibles pour le pliage incluent les régions “accolées” avec des parenthèses { } telles que les définitions de fonctions ou les blocs conditionnels (instructions “if else”). Vous pouvez en savoir plus sur le pliage du code sur le site RStudio.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#répertoire-de-travail",
    "href": "new_pages/basics.fr.html#répertoire-de-travail",
    "title": "3  R - les bases",
    "section": "3.8 Répertoire de travail",
    "text": "3.8 Répertoire de travail\nLe répertoire de travail est l’emplacement du dossier racine utilisé par R pour votre travail - où R recherche et enregistre les fichiers par défaut. Par défaut, il enregistrera de nouveaux fichiers et sorties à cet emplacement et recherchera ici des fichiers (par exemple, des ensembles de données).\nLe répertoire de travail apparaît dans le texte gris en haut du volet de la console RStudio. Vous pouvez également imprimer le répertoire de travail actuel en exécutant getwd() (laissez les parenthèses vides).\n\n\n\n\n\n\n\n\n\n\nApproche recommandée\nVoir la page sur projets R pour plus de détails sur notre approche recommandée pour gérer votre répertoire de travail.\nUn moyen commun, efficace et sans problème de gérer votre répertoire de travail et vos chemins de fichier consiste à combiner ces trois éléments dans un flux de travail du projets R orienté comme expliqué ci-dessous:\n\nUn projet R pour stocker tous vos fichiers (voir page sur projets R)\nLe paquet here pour localiser les fichiers (voir page sur importer et exporter)\nLe paquet rio pour importer ou exporter des fichiers (voir page sur importer et exporter)\n\n\n\n\nDéfinir le répertoire de travail par commande\nJusqu’à récemment, de nombreuses personnes apprenant R ont appris à commencer leurs scripts avec une commande setwd(). Veuillez plutôt envisager d’utiliser un flux de travail orienté par projets R et lire les raisons de ne pas utiliser setwd().\nEn bref, votre travail devient spécifique à votre ordinateur, les chemins de fichier utilisés pour importer et exporter des fichiers deviennent “cassants”, ce qui entrave gravement la collaboration et l’utilisation de votre code sur tout autre ordinateur. Heureusement il existe des alternatives faciles!\nComme indiqué ci-dessus, bien que nous ne recommandons pas cette approche dans la plupart des cas, vous pouvez utiliser la commande setwd() avec le chemin du fichier de dossier souhaité dans les citations, par exemple:\n\nsetwd(\"C:/Documents/R Files/My analysis\")\n\nDANGER: Définition d’un répertoire de travail avec setwd() peut être “cassant” si le chemin de fichier est spécifique à un ordinateur. Au lieu de cela, utilisez des chemins de fichier par rapport à un répertoire racine du projet R (avec le paquet here).\n\n\n\nDéfinir manuellement le répertoire de travail\nPour définir le répertoire de travail manuellement (l’équivalent graphique du setwd()), cliquez sur le menu déroulant “Session” et accédez à “Set Working Directory”, puis “Choose Directory”. Cela définira le répertoire de travail pour cette scéance spécifique de R. Remarque: Si vous utilisez cette approche, vous devrez le faire manuellement chaque fois que vous ouvrez Rstudio.\n\n\n\nDéfinir le répertoire de travail dans un projet R\nSi vous utilisez un projet R, le répertoire de travail sera par défaut dans le dossier racine du projet R qui contient le fichier .rproj. Cela s’appliquera si vous ouvrez RStudio en cliquant sur le projet R (le fichier avec l’extension .rproj).\n\n\n\n3.8.1 Répertoire de travail dans un script R Markdown\nDans un script R Markdown, le répertoire de travail par défaut est le dossier ou le fichier RMarkdown (.rmd) est enregistré. Si vous utilisez un projet R et le paquet here, cela ne s’applique pas et le répertoire de travail sera here(), comme expliqué dans la page projets R.\nSi vous souhaitez modifier le répertoire de travail d’une dossier RMarkdown autonome (qui ne fait pas partie d’un projet R), et vous utilisez setwd(), cela ne s’appliquera qu’à ce morceau de code spécifique. Pour modifier tous les morceaux de code dans une dossier RMarkdown, modifiez le morceau de configuration pour ajouter le paramètre root.dir =, comme ci-dessous:\n\nknitr::opts_knit$set(root.dir = 'desired/directorypath')\n\nIl est beaucoup plus facile d’utiliser simplement le script RMarkdown dans un projet R et d’utiliser le paquet here.\n\n\n\nFournir des chemins de fichier\nLa source de frustration la plus commune pour un débutant R (au moins sur un ordinateur avec Windows) est de saisir un chemin de fichier pour importer ou exporter des données. Il existe une explication approfondie sur la meilleure façon de saisir les chemins de fichier de saisie dans la page importer et exporter, mais voici quelques points clés:\nChemins cassés\nVous trouverez ci-dessous un exemple de chemin de fichier “absolute” avec un “adresse complète”. Ceux-ci se casseront probablement s’ils sont utilisés par un autre ordinateur. Une exception est si vous utilisez un dossier sur un réseau partagé.\nC:/Utilisateurs/Nom/Document/Logiciels analytiques/R/Projets/Analyse2019/data/mars2019.csv\nDirection de la barre oblique\nSi vous saisissez un chemin de fichier, soyez conscient de la direction des barres obliques. Utilisez des barres obliques vers l’avant (/) pour séparer les composants, par exemple Data/Provincial.csv. Le défaut pour les ordinateurs avec Windows est de séparer les composants du chemin avec des barres obliques en arrière (\\\\). Vous devrez donc modifier la direction de chaque barre oblique. Si vous utilisez le paquet here comme décrit dans la page projets R, la direction des barres obliques n’est pas un problème.\nChemins de fichiers relatifs\nNous recommandons généralement de utiliser des fichiers avec chemins “relatifs” - c’est-à-dire le chemin par rapport à la racine de votre projet R. Vous pouvez le faire en utilisant le paquet here comme expliqué dans la page projets R. Un chemin de fichiers relatif peut ressembler à ceci:\n\n# Importer csv Linelist à partir de données/listes linéare/propres/sous-dossiers d'un projet R\n\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))\n\nMême si vous utilisez des chemins de fichiers relatifs dans un projet R, vous pouvez toujours utiliser des chemins absolus pour importer/exporter des données en dehors de votre projet R.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#objets",
    "href": "new_pages/basics.fr.html#objets",
    "title": "3  R - les bases",
    "section": "3.9 Objets",
    "text": "3.9 Objets\nTout dans R est un objet, et R est une langue “orienté sur l’objet”. Les sections suivantes expliquent:\n\nComment créer des objets (&lt;-)\nTypes d’objets (par exemple, trames de données, vecteurs ..)\nComment accéder à des sous-parties d’objets (par exemple, des variables dans un jeu de données)\n\nClasses d’objets (ex. numérique, logique, nombres entieres, double, caractère, facteur)\n\n\n\nTout est un objet\nCette section est adaptée du projet R4Epis.Tout ce que vous stockez dans R - des ensembles de données, des variables, une liste de noms de villages, un nombre total de population, même des sorties telles que des graphiques - sont des objets qui sont attribués à un nom et peuvent être référencés dans les commandes ultérieures.\nUn objet existe lorsque vous lui avez attribué une valeur (voir la section d’attribution ci-dessous). Lorsqu’une valeur lui est attribuée, l’objet apparaît dans l’environnement (voir le volet supérieur droit de RStudio). Il peut alors être exploité, manipulé, modifié et redéfini.\n\n\n\nDéfinir des objets (&lt;-)\nCréez des objets en leur attribuant une valeur avec l’opérateur &lt;-. Vous pouvez considérer l’opérateur d’affectation&lt;- comme les mots “est défini comme”. Les commandes d’affectation suivent généralement un ordre standard:\nnom_objet &lt;- valeur (ou processus/calcul qui produit une valeur)\nPar exemple, vous souhaiterez peut-être enregistrer la semaine de rapport épidémiologique en cours en tant qu’objet de référence dans le code ultérieur. Dans cet exemple, l’objet semaine_en_cours est créé lorsqu’il reçoit la valeur \"2018-W10\" (les guillemets en font une valeur de caractère). L’objet semaine_en_cours apparaîtra alors dans le volet Environnement de RStudio (en haut à droite) et pourra être référencé dans les commandes ultérieures.\nVoir les commandes R et leur sortie dans les cases ci-dessous.\n\n# Créer l'objet semaine_en_cours en lui attribuant une valeur:\nsemaine_en_cours &lt;- \"2018-W10\"   \n\n# Imprime la valeur actuelle de l'objet semaine_en_cours dans la console:\nsemaine_en_cours\n\n[1] \"2018-W10\"\n\n\nNOTE: Notez que le [1] dans la sortie de la console R indique simplement que vous visualisez le premier élément de la sortie\nATTENTION: La valeur d’un objet peut être écrasée à tout moment en exécutant une commande d’affectation pour redéfinir sa valeur. Ainsi, l’ordre d’exécution des commandes est très important.\nLa commande suivante redéfinira la valeur de semaine_en_cours:\n\n# Attribuer une NOUVELLE valeur à l'objet semaine_en_cours:\nsemaine_en_cours &lt;- \"2018-W51\"\n\n# Afficher la valeur actuelle de semaine_en_cours dans la console:\nsemaine_en_cours\n\n[1] \"2018-W51\"\n\n\nSigne égal =\nVous verrez également des signes égal dans le code R:\n\nUn double signe égal == entre deux objets ou valeurs pose une question logique: “est-ce égal à cela?”.\nVous verrez également des signes égal dans les fonctions utilisées pour spécifier les valeurs des arguments d’un fonction (lisez-les dans les sections ci-dessous), par exemple max(age, na.rm = TRUE).\nVous pouvez utiliser un seul signe égal = à la place de &lt;- pour créer et définir des objets, mais cela est déconseillé. Vous pouvez lire pourquoi cela est déconseillé ici.\n\nEnsembles de données\nLes ensembles de données sont également des objets (généralement des «dataframes») et doivent recevoir des noms lors de leur importation. Dans le code ci-dessous, l’objet linelist est créé et reçoit la valeur d’un fichier CSV importé avec le paquet rio et sa fonction import().\n\n# &lt;&lt;linelist&gt;&gt; est créée et reçoit la valeur du fichier CSV importé:\nlinelist &lt;- import(\"my_linelist.csv\")\n\nVous pouvez en savoir plus sur l’importation et l’exportation d’ensembles de données dans la section sur importer et exporter.\nATTENTION: Une note rapide sur la dénomination des objets:\n\nLes noms d’objets ne doivent pas contenir d’espaces, mais vous devez utiliser un trait de soulignement (_) ou un point (.) au lieu d’un espace.\nLes noms d’objets sont sensibles à la casse (lettres majuscules et minuscules; ce qui signifie que Dataset_A est différent de dataset_A).\nLes noms d’objets doivent commencer par une lettre (ne peuvent pas commencer par un chiffre comme 1, 2 ou 3).\n\nLes sorties\nLes sorties telles que les tableaux et les tracés fournissent un exemple de la façon dont les sorties peuvent être enregistrées en tant qu’objets ou simplement imprimées sans être enregistrées. Un tableau croisé du sexe et du résultat à l’aide de la fonction R base table() peut être imprimé directement sur la console R (sans être enregistré).\n\n# Imprimé sur la console R uniquement:\ntable(linelist$gender, linelist$outcome)\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nLa même table peut également être enregistrée en tant qu’objet nommé. Ensuite, éventuellement, il peut être imprimé.\n\n# Enregistrer:\ngen_out_table &lt;- table(linelist$gender, linelist$outcome)\n\n# Imprimer:\ngen_out_table\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nColonnes\nLes colonnes d’un ensemble de données sont également des objets et peuvent être définies, écrasées et créées comme décrit ci-dessous dansla section sur les colonnes.\nVous pouvez utiliser l’opérateur d’affectation de base R pour créer une nouvelle colonne. Ci-dessous, la nouvelle colonne bmi (indice de masse corporelle) est créée, et pour chaque ligne la nouvelle valeur est le résultat d’une opération mathématique sur la valeur de la ligne dans les colonnes wt_kg et ht_cm.\n\n# Créer une nouvelle colonne \"bmi\" en utilisant la syntaxe de base R:\nlinelist$bmi &lt;- linelist$wt_kg / (linelist$ht_cm/100)^2\n\nCependant, dans ce manuel, nous mettons l’accent sur une approche différente de la définition des colonnes, qui utilise la fonction mutate() du package dplyr et piping avec l’opérateur pipe (%&gt;%). La syntaxe est plus facile à lire et il y a d’autres avantages expliqués dans la page nettoyage de donnees et fonctions essentielles.\nVous pouvez lire plus sur piping dans la section “Piping” ci-dessous.\n\n# Créer une nouvelle colonne \"bmi\" en utilisant la syntaxe dplyr:\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\n\n\n\nStructure d’objet\nLes objets peuvent être une seule donnée (par exemple, “mon_numéro &lt;-24”), ou ils peuvent être constitués de données structurées.\nLe graphique ci-dessous est emprunté à ce tutoriel R en ligne. Il montre certaines structures de données courantes et leurs noms. Les données spatiales ne sont pas incluses dans cette image, qui sont abordées dans la page bases de GIS.\n\n\n\n\n\n\n\n\n\nEn épidémiologie (et en particulier en épidémiologie de terrain), vous rencontrerez le plus souvent des trames de données et des vecteurs:\n\n\n\n\n\n\n\n\nStructure commune\nExplication\nExemple\n\n\n\n\nVecteurs\nUn conteneur pour une séquence d’objets singuliers, tous de la même classe (par exemple numérique, caractère).\nLes “variables” (colonnes) dans les blocs de données sont des vecteurs (par exemple, la colonne age_years).\n\n\nTrames de données\nVecteurs (par exemple, des colonnes) qui sont liés ensemble et qui ont tous le même nombre de lignes.\nlinelist est une trame de données.\n\n\n\nNotez que pour créer un vecteur “autonome” (ne faisant pas partie d’un bloc de données), la fonction c() est utilisée pour combiner les différents éléments. Par exemple, si vous créez un vecteur de couleurs à appliquer à l’échelle de couleurs d’un tracé:\nvector_of_colors &lt;- c(\"blue\", \"red2\", \"orange\", \"grey\")\n\n\n\nClasses d’objets\nTous les objets stockés dans R ont une classe qui indique à R comment gérer l’objet. Il existe de nombreuses classes possibles, mais les plus courantes incluent:\n\n\n\nClasse\nExplication\nExemples\n\n\nCaractère\nCe sont des textes/mots/phrases “entre guillemets”. Les mathématiques ne peuvent pas être effectuées sur ces objets.\n“Les objets caractères sont entre guillemets”\n\n\nEntier\nNombres entiers uniquement (pas de décimales)\n-5, 14 ou 2000\n\n\nNumérique\nCe sont des nombres et peuvent inclure des décimales. S’ils sont entre guillemets, ils seront considérés comme une classe de caractères.\n23.1 ou 14\n\n\nFacteur\nCe sont des vecteurs qui ont un ordre spécifié ou une hiérarchie de valeurs\nUne variable de statut économique à valeurs ordonnées\n\n\nDes dates\nUne fois que R est informé que certaines données sont des dates, ces données peuvent être manipulées et affichées de manière spéciale. Voir la page sur manipuler les dates pour plus d’informations.\n2018-04-12 15/3/1954 mer, 4 janv, 1980\n\n\nLogique\nLes valeurs doivent être l’une des deux valeurs spéciales TRUE ou FALSE (notez qu’elles ne sont pas “TRUE” et “FALSE” entre guillemets)\nTRUE ou FALSE\n\n\ndata.frame a.frame\nUne trame de données est la façon dont R stocke un ensemble de données typiques. Il se compose de vecteurs (colonnes) de données liés entre eux, qui ont tous le même nombre d’observations (lignes).\nL’exemple de jeu de données AJS nommé linelist_raw contient 68 variables avec 300 observations (lignes) chaque.\n\n\ntibble\nLes tibbles sont une variante du cadre de données; la principale différence opérationnelle étant qu’ils s’impriment mieux sur la console (affichent les 10 premières lignes et uniquement les colonnes qui tiennent sur l’écran)\nTout cadre de données, liste ou matrice peut être converti en tibble avec as_tibble()\n\n\nliste\nUne liste est comme un vecteur, mais contient d’autres objets qui peuvent être d’autres classes différentes\n\n\n\n\nVous pouvez tester la classe d’un objet en fournissant son nom à la fonction class(). Remarque : vous pouvez référencer une colonne spécifique dans un jeu de données en utilisant la notation «$» pour séparer le nom du jeu de données et le nom de la colonne.\n\n# La classe doit être une trame de données ou un tibble:\nclass(linelist)         \n\n[1] \"data.frame\"\n\n# La classe doit être numérique:\nclass(linelist$age)\n\n[1] \"numeric\"\n\n# La classe doit être caractère:\nclass(linelist$gender)\n\n[1] \"character\"\n\n\nParfois, une colonne sera automatiquement convertie dans une classe différente par R. Attention à cela ! Par exemple, si vous avez un vecteur ou une colonne de nombres, mais qu’une valeur de caractère est insérée; toute la colonne deviendra un caractère de classe.\n\n# Définir le vecteur avec des numéros:\nnum_vector &lt;- c(1,2,3,4,5) \n\n# Le vecteur est de classe \"numérique\":\nclass(num_vector)          \n\n[1] \"numeric\"\n\n# Convertir le troisième élément en caractère:\nnum_vector[3] &lt;- \"three\"   \n\n# Le vecteur est maintenant de classe \"caractère\"\nclass(num_vector)          \n\n[1] \"character\"\n\n\nUn exemple courant de ceci est lors de la manipulation d’un bloc de données afin d’imprimer un tableau. Si vous faites une ligne totale et essayez de coller/coller ensemble des pourcentages dans la même cellule que des nombres (par exemple 23 (40%)), le toute la colonne numérique ci-dessus sera convertie en caractère et ne pourra plus être utilisée pour des calculs mathématiques. Parfois, vous devrez convertir des objets ou des colonnes dans une autre classe.\n\n\n\nFonction\nAction\n\n\nas.character()\nConvertit en classe “caractère”\n\n\nas.numeric()\nConvertit en classe “numérique”\n\n\nas.integer()\nConvertit en classe “entière”\n\n\nas.Date()\nConvertit en classe “Date” Remarque: voir le chapitre sur les dates pour plus de détails\n\n\nfactor()\nConvertit en classe “facteur”\nRemarque: la redéfinition de l’ordre des niveaux de valeur nécessite des arguments supplémentaires\n\n\n\nDe même, il existe des fonctions base R pour vérifier si un objet EST d’une classe spécifique, comme is.numeric(), is.character(), is.double(), is .facteur(), is.integer()\nVoici plus de matériel en ligne sur les classes et les structures de données dans R.\n\n\n\nColonnes/Variables ($)\nUne colonne dans un bloc de données est techniquement un “vecteur” (voir tableau ci-dessus) - une série de valeurs qui doivent toutes être de la même classe (caractère, numérique, logique, etc.).\nUn vecteur peut exister indépendamment d’un bloc de données, par exemple un vecteur de noms de colonnes que vous souhaitez inclure en tant que variables explicatives dans un modèle. Pour créer un vecteur “autonome”, utilisez la fonction c() comme ci-dessous:\n\n# Définir le vecteur autonome des valeurs de classe caractère:\nvar_explicatives &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# Affiche les valeurs dans ce vecteur nommé:\nvar_explicatives\n\n[1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\" \n\n\nLes colonnes d’un bloc de données sont également des vecteurs et peuvent être appelées, référencées, extraites ou créées à l’aide du symbole $. Le symbole $ relie le nom de la colonne au nom de son bloc de données. Dans ce manuel, nous essayons d’utiliser le mot “colonne” au lieu de “variable”.\n\n# Récupérer la longueur du vecteur age:\nlength(linelist$age) # (l'âge est une colonne dans le bloc de données nomé \"linelist\")\n\nEn tapant le nom de la trame de données suivi de $, vous verrez également un menu déroulant de toutes les colonnes de la trame de données. Vous pouvez les faire défiler à l’aide de votre touche fléchée, en sélectionner une avec votre touche Entrée et éviter les fautes d’orthographe !\n\n\n\n\n\n\n\n\n\nCONSEIL AVANCÉ: Certains objets plus complexes (par exemple, une liste ou un objet epicontacts) peuvent avoir plusieurs niveaux accessibles via plusieurs signes dollar. Par exemple epicontacts$linelist$date_onset\n\n\n\nAccès/index avec crochets ([ ])\nVous devrez peut-être afficher des parties d’objets, également appelées “indexation”, ce qui se fait souvent à l’aide des crochets [ ]. L’utilisation de $ sur une trame de données pour accéder à une colonne est également un type d’indexation.\n\n# Définir le vecteur:\nmon_vecteur &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")\n\n# Imprimer le 5ème élément:\nmon_vecteur[5]\n\n[1] \"e\"\n\n\nLes crochets fonctionnent également pour renvoyer des parties spécifiques d’une sortie renvoyée, comme la sortie d’une fonction summary():\n\n# Tout le résumé\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n# Juste le deuxième élément du résumé, avec le nom (en utilisant uniquement des crochets simples)\nsummary(linelist$age)[2]\n\n1st Qu. \n      6 \n\n# Juste le deuxième élément, sans nom (en utilisant des doubles crochets)\nsummary(linelist$age)[[2]]\n\n[1] 6\n\n# Extraire un élément par son nom, sans afficher le nom\nsummary(linelist$age)[[\"Median\"]]\n\n[1] 13\n\n\nLes crochets fonctionnent également sur les blocs de données pour afficher des lignes et des colonnes spécifiques. Vous pouvez le faire en utilisant la syntaxe dataframe[lignes, colonnes]:\n\n# Afficher une ligne spécifique (2) du jeu de données, avec toutes les colonnes \n# (n'oubliez pas la virgule!)\nlinelist[2,]\n\n# Afficher toutes les lignes, mais une seule colonne:\nlinelist[, \"date_onset\"]\n\n# Afficher les valeurs de la ligne 2 et des colonnes 5 à 10:\nlinelist[2, 5:10]\n\n# Afficher les valeurs de la ligne 2 et des colonnes 5 à 10 et 18:\nlinelist[2, c(5:10, 18)]\n\n# Afficher les lignes 2 à 20 et des colonnes spécifiques:\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# Afficher les lignes et les colonnes en fonction de critères\n# *** Notez que le dataframe doit toujours être nommé dans les critères!\nlinelist[linelist$age &gt; 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Utilisez View() pour voir les sorties dans le volet RStudio Viewer (plus facile à lire)\n# *** Notez le \"V\" majuscule dans la fonction View()\nView(linelist[2:20, \"date_onset\"])\n\n# Enregistrer en tant que nouvel objet:\nnew_table &lt;- linelist[2:20, c(\"date_onset\")]\n\nNotez que vous pouvez également réaliser l’indexation des lignes/colonnes ci-dessus sur les blocs de données et les tibbles en utilisant la syntaxe dplyr (fonctions filter() pour les lignes et select() pour les colonnes). Pour en savoir plus sur ces fonctions principales, consultez la page sur le nettoyage de deonnees et fonctions essentielles.\nPour filtrer en fonction du “numéro de ligne”, vous pouvez utiliser la fonction dplyr row_number() avec des parenthèses ouvertes dans le cadre d’une instruction de filtrage logique. Vous utiliserez souvent l’opérateur %in% et une plage de nombres dans le cadre de cette instruction logique, comme indiqué ci-dessous. Pour voir les premières N lignes, vous pouvez également utiliser la fonction spéciale dplyr head().\n\n# Afficher les 100 premières lignes:\nlinelist %&gt;% \n     head(100)\n\n# Afficher la ligne 5 uniquement:\nlinelist %&gt;% \n     filter(row_number() == 5)\n\n# Afficher les lignes 2 à 20 et trois colonnes spécifiques \n# (notez qu'aucun guillemet n'est nécessaire sur les noms de colonne)\nlinelist %&gt;% \n     filter(row_number() %in% 2:20) %&gt;% \n     select(date_onset, issue, age)\n\nLors de l’indexation d’un objet de classe list, les crochets simplesretournent toujours avec la classe list, même si un seul objet est retourné. Les crochets doubles, cependant, peuvent être utilisés pour accéder à un seul élément et renvoyer une classe différente de la liste.Les parenthèses peuvent également être écrites les unes après les autres, comme illustré ci-dessous.\nCette explication visuelle de l’indexation des listes, avec des poivrières est humoristique et utile.\n\n# définir la liste des démos\nma_liste &lt;- list(\n   # Le premier élément de la liste est un vecteur de caractères:\n   hopitaux = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n   # Le deuxième élément de la liste est une trame de données d'adresses:\n   adresses = data.frame(\n     rue = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n     ville = c(\"Andover\", \"Hamilton\", \"El Paso\")\n     )\n   )\n\nVoici à quoi ressemble la liste lorsqu’elle est imprimée sur la console. Voyez comment il y a deux éléments nommés:\n\nhôpitaux, un vecteur de caractères\nadresses, une trame de données d’adresses\n\n\nma_liste\n\n$hopitaux\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n$adresses\n              rue    ville\n1 145 Medical Way  Andover\n2  1048 Brown Ave Hamilton\n3   999 El Camino  El Paso\n\n\nMaintenant, nous extrayons, en utilisant diverses méthodes:\n\n# Cela renvoie l'élément dans la classe \"list\" - le nom de l'élément est toujours affiché:\nma_liste[1] \n\n$hopitaux\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n# Cela ne renvoie que le vecteur de caractères (sans nom):\nma_liste[[1]]\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n# Vous pouvez également indexer par le nom de l'élément de la liste:\nma_liste[[\"hopitaux\"]]\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n# Cela renvoie le troisième élément du vecteur de caractères \"hôpitaux\":\nma_liste[[1]][3] \n\n[1] \"Santa Anna\"\n\n# Cela renvoie la première colonne (\"rue\") de la trame de données d'adresse:\nma_liste[[2]][1]\n\n              rue\n1 145 Medical Way\n2  1048 Brown Ave\n3   999 El Camino\n\n\n\n\n\nSupprimer des objets\nVous pouvez supprimer des objets individuels de votre environnement R en mettant le nom dans la fonction rm() (sans guillemets):\n\nrm(nom_objet)\n\nVous pouvez supprimer tous les objets (vider votre espace de travail) en exécutant:\n\nrm(list = ls(all = TRUE))",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#tuyauterie-piping",
    "href": "new_pages/basics.fr.html#tuyauterie-piping",
    "title": "3  R - les bases",
    "section": "3.10 Tuyauterie / “Piping” (%>%)",
    "text": "3.10 Tuyauterie / “Piping” (%&gt;%)\nDeux approches générales pour travailler avec des objets sont:\n\nPipes/tidyverse - les tuyaux envoient un objet d’une fonction à l’autre - l’accent est mis sur l’action, pas sur l’objet\nDéfinir les objets intermédiaires - un objet est redéfini encore et encore - l’accent est mis sur l’objet\n\n\n\nTuyaux / Pipes\nExpliqué simplement, l’opérateur pipe (%&gt;%) passe une sortie intermédiaire d’une fonction à la suivante.  Vous pouvez penser que cela signifie “alors”. De nombreuses fonctions peuvent être liées avec %&gt;%.\n\nLe tuyau met l’accent sur une séquence d’actions, et non sur l’objet sur lequel les actions sont effectuées\nLes tuyaux sont plus efficaces lorsqu’une séquence d’actions doit être effectuée sur un objet\nLes tuyaux proviennent du paquet magrittr, qui est automatiquement inclus dans les paquets dplyr et tidyverse\nLes tuyaux peuvent rendre le code plus propre et plus facile à lire, plus intuitif\n\nEn savoir plus sur cette approche dans le tidyverse guide de style\nVoici un faux exemple de comparaison, utilisant des fonctions fictives pour “faire un gâteau”. Tout d’abord, la méthode du tuyau:\n\n# Un faux exemple de comment faire cuire un gâteau en utilisant la syntaxe de tuyauterie:\n\ngateau &lt;- farine %&gt;% # pour définir le gâteau, commencez par la farine, puis...\n     # ajouter des oeufs\n     add(oeufs) %&gt;% \n     # ajouter de l'huile\n     add(huile) %&gt;% \n     # ajouter de l'eau\n     add(eau) %&gt;% \n     # mélanger ensemble avec cuillère pour 2 minutes:\n     mix_together(\n          ustensil = \"spoon\",\n          minutes = 2) %&gt;%\n     # cuire à 200 degrés centigrade pour 35 minutes:\n     bake(\n          degrees = 200, \n          system = \"centigrade\",\n          minute = 35) %&gt;%\n     # laissez-le refroidir\n     let_cool() \n\nVoici un autre lien décrivant l’utilitaire de tuyaux.\nLa tuyauterie n’est pas une fonction de base en R. Pour utiliser la tuyauterie, le paquet magrittr doit être installé et chargé (cela se fait généralement en chargeant le paquet tidyverse ou dplyr qui l’inclut). Vous pouvez en savoir plus sur la tuyauterie dans la documentation de magrittr.\nNotez que, tout comme les autres commandes R, les tuyaux peuvent être utilisés pour afficher simplement le résultat ou pour enregistrer/réenregistrer un objet, selon que l’opérateur d’affectation &lt;- est impliqué ou non. Voir les deux exemplaires ci-dessous:\n\n# Créer ou écraser un objet, en le définissant sous \n# forme de nombres agrégés par catégorie d'âge (non imprimé)\nlinelist_summary &lt;- linelist %&gt;% \n  count(age_cat)\n\n\n# Imprimez le tableau des comptes dans la console, mais ne l'enregistrez pas:\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\n%&lt;&gt;% Il s’agit d’un “tuyau d’affectation” du paquet magrittr, qui transmet un objet en avant et redéfinit également l’objet. Il doit être le premier opérateur pipe de la chaîne. C’est un raccourci. Les deux commandes ci-dessous sont équivalentes:\n\n# Utilisez l'opérateur d'affectation:\nlinelist &lt;- linelist %&gt;%\n  filter(age &gt; 50)\n\n# Utilisez le tuyau d'affectation:\nlinelist %&lt;&gt;% filter(age &gt; 50)\n\n\n\n\nDéfinir les objets intermédiaires\nCette approche de modification des objets ou trammes de données peut être meilleure si:\n\nVous devez manipuler plusieurs objets\nIl y a des étapes intermédiaires qui sont significatives et méritent des noms d’objets séparés\n\nDes risques:\n\nCréer de nouveaux objets pour chaque étape signifie créer beaucoup d’objets. Si vous utilisez le mauvais, vous ne vous en rendrez peut-être pas compte!\nNommer tous les objets peut prêter à confusion\nLes erreurs peuvent ne pas être facilement détectables\n\nSoit nommer chaque objet intermédiaire, soit écraser l’original, soit combiner toutes les fonctions ensemble. Tous viennent avec leurs propres risques.\nVous trouverez ci-dessous le même exemple de faux “gâteau” que ci-dessus, mais en utilisant ce style:\n\n# un faux exemple de comment faire un gâteau en utilisant cette méthode \n# (définissant des objets intermédiaires):\n\n# Ajouter le farine et les oeufs:\npate_1 &lt;- left_join(farine, oeufs)\n\n# Ajouter l'huile:\npate_2 &lt;- left_join (pate_1, huile)\n\n# Ajouter l'eau:\npate_3 &lt;- left_join(pate_2, eau)\n\n# Melange tous ensemble:\npate_4 &lt;- mix_together(object = pate_3, \n                       ustensil = \"spoon\", \n                       minutes = 2)\n\n# Cuire le gâteau dans le four:\ngateau &lt;-bake(object = pate_4, \n              degrees = 200, \n              system = \"centigrade\", \n              minutes = 35)\n\n# Laissez-le à refroidir:\ngateau &lt;- laisse_refroidir(gateau)\n\nCombinez toutes les fonctions ensemble - c’est difficile à lire :\n\n# Un exemple de combinaison/imbrication de plusieurs fonctions - difficile à lire:\ngateau &lt;- let_cool(bake(mix_together(pate_3, \n                                     utensil = \"spoon\", \n                                     minutes = 2), \n                        degrees = 200, \n                        system = \"centigrade\",\n                        minutes = 35))",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#operators",
    "href": "new_pages/basics.fr.html#operators",
    "title": "3  R - les bases",
    "section": "3.11 Opérateurs clés et fonctions",
    "text": "3.11 Opérateurs clés et fonctions\nCette section détaille les opérateurs dans R, tels que:\n\nOpérateurs définitionnels\nOpérateurs relationnels (inférieur à, égal aussi..)\nOpérateurs logiques (et, ou…)\nGestion des valeurs manquantes\nOpérateurs et fonctions mathématiques (+/-, &gt;, sum(), median(), …)\nL’opérateur %in%\n\n\n\nOpérateurs d’affectation\n&lt;-\nL’opérateur d’affectation de base dans R est &lt;-. Tel que nom_objet &lt;- valeur. Cet opérateur d’affectation peut également être écrit comme =. Nous vous conseillons d’utiliser &lt;- pour une utilisation générale de R.Nous conseillons également d’entourer ces opérateurs d’espaces, pour plus de lisibilité.\n&lt;&lt;-\nSi Fonctions d’écriture, ou si vous utilisez R de manière interactive avec des scripts sourcés, vous devrez peut-être utiliser cet opérateur d’affectation &lt;&lt;- (de base R). Cet opérateur est utilisé pour définir un objet dans un environnement R « parent » supérieur. Voir ceci référence en ligne.\n%&lt;&gt;%\nIl s’agit d’un “tuyau d’affectation” du paquet magrittr, qui dirige un objet vers l’avant et redéfinit également l’objet. Il doit être le premier opérateur pipe de la chaîne. Il s’agit d’un raccourci.\n%&lt;+%\nCeci est utilisé pour ajouter des données aux arbres phylogénétiques avec le package ggtree. Voir la page sur les arbres phylogénétiques ou ce livre de ressources en ligne.\n\n\n\nOpérateurs relationnels et logiques\nLes opérateurs relationnels comparent les valeurs et sont souvent utilisés lors de la définition de nouvelles variables et de sous-ensembles des blocs de données. Voici les opérateurs relationnels courants dans R:\n\n\n\nSens\n\nOpérateur\n\nExemple\nExemple de résultat\n\n\nÉgal à\n\n==\n\n\" A\" = =  \"a\"\nFALSE (parce que R est sensible à la casse)\nNotez que == (double égal) est différent de = (simple égal), qui agit comme l’opérateur d’affectation &lt;-\n\n\nNon égal à\n\n!=\n\n2 != 0\nTRUE\n\n\nSupérieur a\n\n&gt;\n\n4 &gt; 2\nTRUE\n\n\nMoins de\n\n&lt;\n\n4 &lt; 2\nFALSE\n\n\nSupérieur ou égal à\n\n&gt;=\n\n6 &gt;= 4\nTRUE\n\n\nInférieur ou égal à\n\n&lt;=\n\n6 &lt;= 4\nFALSE\n\n\nValeur manquante\n\nis.na()\n\nis.na(7)\nFALSE\nvoir page sur valeur manquante\n\n\nValeur ne | !is.na() manque pas |\n\n\n\n!is.na(7) | TRUE |\n\n\n\n\nLes opérateurs logiques, tels que ET et OU, sont souvent utilisés pour connecter des opérateurs relationnels et créer des critères plus complexes. Les instructions complexes peuvent nécessiter des parenthèses ( ) pour le regroupement et l’ordre d’application.\n\n\n\n\n\n\n\nSens\nOpérateur\n\n\n\n\nET\n&\n\n\nOU\n| (barre verticale)\n\n\nParenthèses\n( ) Utilisé pour regrouper les critères et clarifier l’ordre des opérations\n\n\n\nPar exemple, ci-dessous, nous avons une liste linéaire avec deux variables que nous voulons utiliser pour créer notre définition de cas, resultat_tdr, un résultat d’un test rapide, et autres_cas_menage, qui nous dira s’il y a d’autres cas dans le ménage. La commande ci-dessous utilise la fonction case_when() pour créer la nouvelle variable case_def telle que:\n\nlinelist_propre &lt;- linelist %&gt;%\n  mutate(case_def = case_when(\n    is.na(resultat_tdr) & is.na(autres_cas_menage)             ~ NA_character_,\n    resultat_tdr == \"Positive\"                                 ~ \"Confirmé\",\n    resultat_tdr != \"Positive\" & other_cases_in_home == \"Oui\"  ~ \"Probable\",\n    TRUE                                                       ~ \"Suspect\"\n  ))\n\n\n\n\n\n\n\n\nCritères dans l’exemple ci-dessus\nValeur dans “case_def”\n\n\n\n\nSi la valeur des variables resultat_tdr et autres_cas_menage est manquante\nNA (manquante)\n\n\nSi la valeur dans resultat_tdr est “Positive”\n“Confirmé”\n\n\nSi la valeur dans resultat_tdr n’est pas “Positive” ET la valeur dans autres_cas_menage est “Oui”\n“Probable”\n\n\nSi l’un des critères ci-dessus n’est pas rempli\n“Suspect”\n\n\n\nNotez que R est sensible à la casse, donc “Positif” est différent de “positif”…\n\n\n\nValeurs manquantes\nDans R, les valeurs manquantes sont représentées par la valeur spéciale NA (une valeur “réservée”) (lettres majuscules N et A - pas entre guillemets). Si vous importez des données qui enregistrent des données manquantes d’une autre manière (par exemple, 99, “Missing” ou .), vous pouvez recoder ces valeurs en “NA”. La procédure à suivre est expliquée dans la page importer et exporter.\nPour tester si une valeur est NA, utilisez la fonction spéciale is.na(), qui renvoie TRUE ou FALSE.\n\n# 2 cas positives, un suspect et un inconnu:\nresultat_tdr &lt;- c(\"Positive\", \"Suspect\", \"Positive\", NA)   \n\n# Verifier si il y' a des valeurs manquantes:\nis.na(resultat_tdr)\n\n[1] FALSE FALSE FALSE  TRUE\n\n\nEn savoir plus sur les valeurs manquantes, infinies, NULL et impossibles dans la page sur les valeur manquantes. Découvrez comment convertir les valeurs manquantes lors de l’importation de données dans la page sur importer et exporter.\n\n\n\nMathématiques et statistiques\nTous les opérateurs et fonctions de cette page sont automatiquement disponibles en utilisant base R.\n\nOpérateurs mathématiques\nCeux-ci sont souvent utilisés pour effectuer des additions, des divisions, pour créer de nouvelles colonnes, etc. Vous trouverez ci-dessous des opérateurs mathématiques courants dans R. Que vous mettiez des espaces autour des opérateurs n’est pas important.\n\n\n\nObjectif\nExemple en R\n\n\n\n\naddition\n2 + 3\n\n\nsoustraction\n2 - 3\n\n\nmultiplication\n2 * 3\n\n\ndivision\n30 / 5\n\n\nexposant\n2^3\n\n\nordre des opérations\n( )\n\n\n\n\n\nFonctions mathématiques\n\n\n\n\n\n\n\nObjectif\nFonction\n\n\n\n\narrondir\nround(x, digits = n)\n\n\narrondir\njanitor::round_half_up(x, digits = n)\n\n\nplafond (arrondi)\nceiling(x)\n\n\nétage (arrondir à l’inférieur)\nfloor(x)\n\n\nvaleur absolue\nabs(x)\n\n\nracine carrée\nsqrt(x)\n\n\nexposant\nexponent(x)\n\n\nun algorithme naturel\nlog(x)\n\n\nlog à la base 10\nlog10(x)\n\n\nlog à la base 2\nlog2(x)\n\n\n\nRemarque: pour round(), les digits = spécifient le nombre de décimales placées. Utilisez signif() pour arrondir à un nombre de chiffres significatifs.\n\n\nNotation scientifique\nLa probabilité d’utilisation de la notation scientifique dépend de la valeur de l’option “scipen”.\nD’après la documentation de ?options: scipen est une pénalité à appliquer lors de la décision d’imprimer des valeurs numériques en notation fixe ou exponentielle. Les valeurs positives tendent vers la notation fixe et négatives vers la notation scientifique: la notation fixe sera préférée à moins qu’elle ne soit plus large de plus de ‘scipen’.\nS’il est réglé sur un nombre faible (par exemple 0), il sera toujours “allumé”. Pour “désactiver” la notation scientifique dans votre session R, définissez-la sur un nombre très élevé, par exemple:\n\n# Désactiver la notation scientifique\noptions(scipen = 999)\n\n\n\nArrondi\nDANGER: round() utilise “l’arrondi du banquier” qui arrondit à partir de 0,5 uniquement si le nombre supérieur est pair. Utilisez round_half_up() de janitor pour arrondir systématiquement les moitiés au nombre entier le plus proche. Voir cette explication\n\n# Fonction d'arrondi avec R de base:\nround(c(2.5, 3.5))\n\n[1] 2 4\n\n# Fonction d'arrondi du paquet \"janitor\":\njanitor::round_half_up(c(2.5, 3.5))\n\n[1] 3 4\n\n\n\n\nFonctions statistiques\nATTENTION: Les fonctions ci-dessous incluront par défaut les valeurs manquantes dans les calculs. Les valeurs manquantes entraîneront une sortie de NA, sauf si l’argument na.rm = TRUE est spécifié. Cela peut être écrit en raccourci comme na.rm = T.\n\n\n\nObjective\nFonction\n\n\n\n\nmoyen\nmean(x, na.rm=T)\n\n\nmédian\nmedian(x, na.rm=T)\n\n\nécart-type\nsd(x, na.rm=T)\n\n\nquantiles\nquantile(x, probs)\n\n\nsomme\nsum(x, na.rm=T)\n\n\nvaleur minimum\nmin(x, na.rm=T)\n\n\nvaleur maximum\nmax(x, na.rm=T)\n\n\nplage de valeurs numériques\nrange(x, na.rm=T)\n\n\nsommaire\nsummary(x)\n\n\n\nRemarques:\n\n*quantile(): x est le vecteur numérique à examiner et probs = est un vecteur numérique avec des probabilités comprises entre 0 et 1,0, par exemple c(0,5, 0,8, 0,85)\n**summary(): donne un résumé sur un vecteur numérique comprenant la moyenne, la médiane et les centiles communs\n\nDANGER: Si vous fournissez un vecteur de nombres à l’une des fonctions ci-dessus, assurez-vous d’envelopper les nombres dans c().\n\n# Si vous fournissez des nombres bruts à une fonction, \n# enveloppez-les dans c():\n\n# !!! ERREUR !!!\nmean(1, 6, 12, 10, 5, 0)      \n\n[1] 1\n\n# CORRECT\nmean(c(1, 6, 12, 10, 5, 0)) \n\n[1] 5.666667\n\n\n\n\nAutres fonctions utiles\n\n\n\n\n\n\n\n\nObjectif\nFonction\nExemple\n\n\n\n\ncréer une séquence\nseq(from, to, by)\nseq(1, 10, 2)\n\n\nrépéter x, n fois\nrep(x, ntimes)\nrep(1:3, 2) or rep(c(\"a\", \"b\", \"c\"), 3)\n\n\nsubdiviser un vecteur numérique\ncut(x, n)\ncut(linelist$age, 5)\n\n\nprendre un échantillon au hasard\nsample(x, size)\nsample(linelist$i d , size = 5, replace = TRUE)\n\n\n\n\n\n\n\n%in%\nUn opérateur très utile pour faire correspondre les valeurs et pour évaluer rapidement si une valeur se trouve dans un vecteur ou une trame de données:\n\nmon_vecteur &lt;- c(\"a\", \"b\", \"c\", \"d\")\n\n\n\"a\" %in% mon_vecteur\n\n[1] TRUE\n\n\"h\" %in% mon_vecteur\n\n[1] FALSE\n\n\nPour demander si une valeur n’est pas %in% un vecteur, placez un point d’exclamation (!) devant l’instruction logique:\n\n# Pour nier, mettre une exclamation devant:\n!\"a\" %in% mon_vecteur\n\n[1] FALSE\n\n!\"h\" %in% mon_vecteur\n\n[1] TRUE\n\n\n%in% est très utile lors de l’utilisation de la fonction dplyr case_when(). Vous pouvez définir un vecteur précédemment, puis le référencer ultérieurement. Par exemple:\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist &lt;- linelist %&gt;% \n  mutate(enfant_hospitalise = case_when(\n    hospitalise %in% affirmative & age &lt; 18 ~ \"Hospitalized Child\",\n    TRUE                                    ~ \"Not\"))\n\nRemarque: Si vous souhaitez détecter une chaîne partielle, en utilisant peut-être str_detect() de stringr, il n’acceptera pas un vecteur de caractères tel que c(\"1\", \"Oui\", \"oui\", \"y \"). Au lieu de cela, il doit recevoir une expression régulière - une chaîne condensée avec des barres OU, telle que “1|Oui|oui|y”. Par exemple, str_detect(hospitalisé, \"1|Oui|oui|y\"). Voir la page sur les caractères et les chaîne de caractères pour plus d’informations.\nVous pouvez convertir un vecteur de caractères en une expression régulière nommée avec cette commande:\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative\n\n[1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\" \n\n# Condenser à: \naffirmative_str_search &lt;- paste0(affirmative, collapse = \"|\")  # option avec R de base\naffirmative_str_search &lt;- str_c(affirmative, collapse = \"|\")   # option avec le paquet stringr\n\naffirmative_str_search\n\n[1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\"",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.fr.html#erreurs-et-avertissements",
    "href": "new_pages/basics.fr.html#erreurs-et-avertissements",
    "title": "3  R - les bases",
    "section": "3.12 Erreurs et avertissements",
    "text": "3.12 Erreurs et avertissements\nCette section explique :\n\nLa différence entre les erreurs et les avertissements\n\nConseils généraux de syntaxe pour l’écriture de code R\n\nAides au code\n\nLes erreurs et avertissements courants ainsi que des conseils de dépannage sont disponibles sur la page erreurs frequentes.\n\n\nErreur contre avertissement\nLorsqu’une commande est exécutée, la console R peut afficher des messages d’avertissement ou d’erreur en texte rouge.\n\nUn avertissement signifie que R a terminé votre commande, mais a dû prendre des mesures supplémentaires ou a produit une sortie inhabituelle dont vous devez être conscient.\nUne erreur signifie que R n’a pas pu terminer votre commande.\n\nCherchez des indices:\n\nLe message d’erreur/d’avertissement inclura souvent un numéro de ligne pour le problème.\nSi un objet “est inconnu” ou “introuvable”, vous l’avez peut-être mal orthographié, vous avez oublié d’appeler un package avec library() ou vous avez oublié de relancer votre script après avoir apporté des modifications.\n\nSi tout le reste échoue, copiez le message d’erreur dans Google avec quelques termes clés - il y a de fortes chances que quelqu’un d’autre ait déjà travaillé dessus!\n\n\n\nConseils généraux sur la syntaxe\nQuelques points à retenir lors de l’écriture de commandes dans R, pour éviter les erreurs et les avertissements:\n\nFermez toujours les parenthèses - astuce: comptez le nombre de “(” et de parenthèses fermantes “)” pour chaque bloc de code\nÉvitez les espaces dans les noms de colonnes et d’objets. Utilisez le trait de soulignement ( _ ) ou les points ( . ) à la place\nGardez une trace et n’oubliez pas de séparer les arguments d’une fonction par des virgules\nR est sensible à la casse, ce qui signifie que Variable_A est différent de Variable_a\n\n\n\n\nAides au code\nN’importe quel script (RMarkdown ou autre) donnera des indices lorsque vous avez fait une erreur. Par exemple, si vous avez oublié d’écrire une virgule là où c’est nécessaire, ou de fermer une parenthèse, RStudio lèvera un drapeau sur cette ligne, sur le côté droit du script, pour vous avertir.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R - les bases</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.fr.html",
    "href": "new_pages/transition_to_R.fr.html",
    "title": "4  Transition vers R",
    "section": "",
    "text": "4.1 De Excel\nPasser directement d’Excel à R est un objectif tout à fait réalisable. Cela peut sembler décourageant, mais vous pouvez le faire!\nIl est vrai qu’une personne ayant de solides compétences en Excel peut effectuer des activités très avancées dans Excel seul - même en utilisant des outils de script comme VBA. Excel est utilisé dans le monde entier et constitue un outil essentiel pour un épidémiologiste. Cependant, le compléter avec R peut améliorer et étendre considérablement vos méthodes de travail.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition vers R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.fr.html#de-excel",
    "href": "new_pages/transition_to_R.fr.html#de-excel",
    "title": "4  Transition vers R",
    "section": "",
    "text": "Bénéfices\nVous constaterez que l’utilisation de R offre d’immenses avantages en termes de gain de temps, d’analyses plus cohérentes et plus précises, de reproductibilité, de partage et de correction plus rapide des erreurs. Comme tout nouveau logiciel, il y a une “courbe” d’apprentissage dans laquelle vous devez investir du temps pour vous familiariser. Les bénéfices seront significatifs et un immense champ de nouvelles possibilités s’ouvrira à vous avec R.\nExcel est un logiciel bien connu qui peut être facile à utiliser pour un débutant afin de produire des analyses et des visualisations simples par “pointer-cliquer”. En comparaison, il faut parfois quelques semaines pour se familiariser avec les fonctions et l’interface de R. Cependant, R a évolué au cours des dernières années pour devenir beaucoup plus facile à utiliser pour les débutants.\nDe nombreux flux de travail Excel reposent sur la mémoire et la répétition - les risques d’erreur sont donc nombreux. En outre, le nettoyage des données, la méthodologie d’analyse et les équations utilisées sont généralement cachés. Un nouveau collègue peut avoir besoin de beaucoup de temps pour apprendre ce que fait un classeur Excel et comment le réparer. Avec R, toutes les étapes sont explicitement écrites dans le script et peuvent être facilement visualisées, modifiées, corrigées et appliquées à d’autres ensembles de données.\nPour commencer votre transition d’Excel à R, vous devez adapter votre état d’esprit sur quelques points importants:\n\n\nDonnées ordonnées (“Tidy” data)\nUtilisez des données “ordonnées” lisibles par une machine plutôt que des données désordonnées “lisibles par l’homme”. Il existe trois exigences principales pour les données “ordonnées”, comme l’explique ce tutoriel “tidy” data avec R:\n\nChaque variable doit avoir sa propre colonne\n\nChaque observation doit avoir sa propre ligne\n\nChaque valeur doit avoir sa propre cellule\n\nAux utilisateurs d’Excel - pensez au rôle que les tableaux Excel jouent pour normaliser les données et rendre le format plus compréhensible.\nUn exemple de données “ordonnées” serait la liste linéaire (linelist) utilisée dans ce manuel - chaque variable est contenue dans une colonne, chaque observation (un cas) a sa propre ligne, et chaque valeur est dans une seule cellule. Ci-dessous, vous pouvez visualiser les 50 premières lignes de la liste linéaire.:\n\n\n\n\n\n\nLa principale raison pour laquelle on rencontre des données non ordonnées est que de nombreuses feuilles de calcul Excel sont conçues pour être lues facilement par des humains et non par des machines/logiciels.\nPour vous aider à voir la différence, voici quelques exemples fictifs de données non ordonnées qui privilégient la lisibilité humaine à la lisibilité machine.:\n\n\n\n\n\n\n\n\n\nProblèmes: Dans la feuille de calcul ci-dessus, il y a des cellules fusionnées qui ne sont pas facilement digérées par R. La ligne qui doit être considérée comme “l’en-tête” n’est pas claire. Un dictionnaire basé sur les couleurs se trouve à droite et les valeurs des cellules sont représentées par des couleurs - ce qui n’est pas non plus facilement interprété par R (ni par les humains atteints de daltonisme !). En outre, différents éléments d’information sont combinés dans une seule cellule (plusieurs organisations partenaires travaillant dans un même domaine, ou le statut ” à confirmer ” dans la même cellule que ” partenaire D “).\n\n\n\n\n\n\n\n\n\nProblèmes: Dans la feuille de calcul ci-dessus, il y a de nombreuses lignes et colonnes vides supplémentaires dans l’ensemble de données - cela causera des problèmes de nettoyage dans R. De plus, les coordonnées GPS sont réparties sur deux lignes pour un centre de traitement donné. Par ailleurs, les coordonnées GPS sont dans deux formats différents!\nLes ensembles de données “ordonnées” ne sont peut-être pas aussi lisibles à l’œil nu, mais ils facilitent grandement le nettoyage et l’analyse des données ! Les données ordonnées peuvent être stockées sous différents formats, par exemple “long” ou “large” (voir la page sur les Données pivotées), mais les principes ci-dessus sont toujours respectés.\n\n\nFunctions\nLe mot “fonction” en R est peut-être nouveau, mais le concept existe aussi dans Excel sous la forme de formules. Les formules dans Excel requièrent également une syntaxe précise (par exemple, le placement des points-virgules et des parenthèses). Tout ce que vous avez à faire est d’apprendre quelques nouvelles fonctions et comment elles fonctionnent ensemble dans R.\n\n\nScripts\nAu lieu de cliquer sur des boutons et de faire glisser des cellules, vous allez écrire chaque étape et procédure dans un “script”. Les utilisateurs d’Excel connaissent peut-être les “macros VBA” qui utilisent également une approche de script.\nLe script R est constitué d’instructions étape par étape, ce qui permet à tout collègue de lire le script et de voir facilement les étapes que vous avez suivies. Cela permet également de corriger les erreurs ou les calculs imprécis. Voir la section Bases de R sur les scripts pour des exemples.\nVoici un exemple de script R:\n\n\n\n\n\n\n\n\n\n\n\nRessources Excel à R\nVoici quelques liens vers des tutoriels pour vous aider à passer d’Excel à R:\n\nR vs. Excel\n\nCours RStudio en R pour les utilisateurs d’Excel\n\n\n\nIntéraction R-Excel\nR dispose de moyens robustes pour importer des classeurs Excel, travailler avec les données, exporter/enregistrer des fichiers Excel et travailler avec les nuances des feuilles Excel.\nIl est vrai que certaines des mises en forme Excel les plus esthétiques peuvent se perdre dans la traduction (par exemple, l’italique, le texte latéral, etc.). Si votre flux de travail nécessite le passage de documents entre R et Excel tout en conservant le formatage Excel original, essayez des packages comme openxlsx.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition vers R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.fr.html#de-stata",
    "href": "new_pages/transition_to_R.fr.html#de-stata",
    "title": "4  Transition vers R",
    "section": "4.2 De Stata",
    "text": "4.2 De Stata\n\nPasser de Stata à R\nDe nombreux épidémiologistes apprennent d’abord à utiliser Stata, et le passage à R peut sembler intimidant. Cependant, si vous êtes un utilisateur de Stata à l’aise, le passage à R est certainement plus facile à gérer que vous ne le pensez. Bien qu’il existe quelques différences essentielles entre Stata et R dans la façon dont les données peuvent être créées et modifiées, ainsi que dans la façon dont les fonctions d’analyse sont mises en œuvre - après avoir appris ces différences clés, vous serez en mesure de traduire vos compétences.\nVous trouverez ci-dessous quelques traductions clés entre Stata et R, qui pourront vous être utiles lors de la lecture de ce guide.\nNotes générales\n\n\n\nSTATA\nR\n\n\n\n\nVous ne pouvez visualiser et manipuler qu’un seul ensemble de données à la fois\nVous pouvez visualiser et manipuler plusieurs ensembles de données en même temps, vous devrez donc fréquemment spécifier votre ensemble de données dans le code\n\n\nCommunauté en ligne disponible via https://www.statalist.org/\nCommunauté en ligne disponible via RStudio, StackOverFlow, et R-bloggers\n\n\nFonctionnalité “pointer et cliquer” en option\nFonctionnalité minimale de type “pointer-cliquer”\n\n\nAide pour les commandes disponibles avec help [command]\nAide disponible avec [function]? ou effectuer une recherche dans le volet d’aide (Help)\n\n\nCommenter le code avec * ou /// ou /* TEXTE */\nCommenter le code avec #\n\n\nPresque toutes les commandes sont intégrées à Stata. Les fonctions nouvelles/écrites par l’utilisateur peuvent être installées en tant que fichiers ado en utilisant ssc install[package]\nR s’installe avec les fonctions de base, mais l’utilisation typique implique l’installation d’autres packages à partir de CRAN (voir la page sur les bases de R).\n\n\nL’analyse est généralement écrite dans un fichier do\nAnalyse écrite dans un script R dans le panneau source de RStudio. Les scripts R markdown sont une alternative.\n\n\n\nLe fichier d’accès au travail\n\n\n\nSTATA\nR\n\n\n\n\nLes répertoires d’un travail impliquent des chemins d’accès aux fichiers absolus (e.x. “C:/utilisateur/documents/projets/data/”)\nLes répertoires d’un travail peuvent être soit absolus, soit relatifs au dossier racine du projet en utilisant le package here (voir Import et export)\n\n\nVoir le répertoire où se trouve le travail actuel avec pwd\nUtilisez getwd() ou here() (si vous utilisez le package here), avec des parenthèses vides\n\n\nDéfinir le répertoire de travail avec cd “emplacement du dossier”\nUtilisez setwd(“emplacement du dossier”), ou set_here(\"emplacement du dossier) (si le package here est utilisé)\n\n\n\nImportation et visualisation des données\n\n\n\nSTATA\nR\n\n\n\n\nCommandes spécifiques par type de fichier\nUtilisez import() du package rio pour presque tous les types de fichiers. Des fonctions spécifiques existent comme alternatives (voir Import et export)\n\n\nLa lecture des fichiers csv se fait par import delimited “nomdufichier.csv”\nUtilisez import(\"nomdufichier.csv\")\n\n\nLa lecture des fichiers xslx se fait par import excel “nomdufichier.xlsx”\nUtilisez import(\"nomdufichier.xlsx\")\n\n\nParcourez vos données dans une nouvelle fenêtre en utilisant la commande browse\nVisualisez un ensemble de données dans le volet source de RStudio en utilisant View(dataset). Vous devez spécifier le nom de votre ensemble de données à la fonction dans R car plusieurs ensembles de données peuvent être maintenus en même temps. Notez le “V” majuscule dans cette fonction\n\n\nObtenez une vue d’ensemble de votre ensemble de données à l’aide de summarize, qui fournit les noms des variables et les informations de base\nObtenez une vue d’ensemble de votre ensemble de données à l’aide de summary(dataset)\n\n\n\nManipulation de données de base\n\n\n\nSTATA\nR\n\n\n\n\nLes colonnes des ensembles de données sont fréquemment appelées “variables”\nPlus souvent appelés “colonnes” ou parfois “vecteurs” ou “variables”\n\n\nIl n’est pas nécessaire de spécifier l’ensemble de données\nDans chacune des commandes ci-dessous, vous devez spécifier l’ensemble de données - voir la page Nettoyage des données et des fonctions de base pour des exemples\n\n\nLes nouvelles variables sont créées à l’aide de la commande generate varname =\nGénérez de nouvelles variables en utilisant la fonction mutate(varname = ). Voir la page Nettoyage des données et des fonctions de base pour des détails sur les fonctions dplyr.\n\n\nLes variables sont renommées en utilisant rename nouveau_nom ancien_nom\nLes colonnes peuvent être renommées à l’aide de la fonction rename(nouveau_nom = ancien_nom)\n\n\nLes variables sont supprimées en utilisant drop nom_variable\nLes colonnes peuvent être supprimées en utilisant la fonction select() avec le nom de la colonne dans les parenthèses suivant un signe moins\n\n\nLes variables factorielles peuvent être étiquetées en utilisant une série de commandes telles que label define\nL’étiquetage des valeurs peut se faire en convertissant la colonne en classe de facteurs et en spécifiant des niveaux. Voir la page sur Facteurs. Les noms de colonnes ne sont pas typiquement étiquetés comme ils le sont dans Stata.\n\n\n\nAnalyse descriptive\n\n\n\nSTATA\nR\n\n\n\n\nMettre en tableau les effectifs d’une variable en utilisant tab nom_variable\nFournissez l’ensemble de données et le nom de la colonne à table() tel que table(ensemble_de_données$nomcolonne). Vous pouvez également utiliser count(nom_variable) du package dplyr, comme expliqué dans Regroupement des données.\n\n\nLe tableau croisé de deux variables dans un tableau 2x2 se fait avec tab nom_variable1 nom_variable2\nUtilisez table(ensemble_de_données$nom_variable1, ensemble_de_données$nom_variable2 ou count(nom_variable1, nom_variable2)\n\n\n\nBien que cette liste donne un aperçu des bases de la conversion des commandes Stata en R, elle n’est pas complète. Il existe de nombreuses autres ressources intéressantes pour les utilisateurs de Stata qui passent à R:\n\nhttps://dss.princeton.edu/training/RStata.pdf\n\nhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.html\n\nhttp://r4stats.com/books/r4stata/",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition vers R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.fr.html#de-sas",
    "href": "new_pages/transition_to_R.fr.html#de-sas",
    "title": "4  Transition vers R",
    "section": "4.3 De SAS",
    "text": "4.3 De SAS\n\nPasser de SAS à R\nSAS est couramment utilisé dans les agences de santé publique et les domaines de recherche universitaires. Bien que la transition vers une nouvelle langue soit rarement un processus simple, la compréhension des principales différences entre SAS et R peut vous aider à commencer à naviguer dans cette nouvelle langue en utilisant votre langue maternelle. Vous trouverez ci-dessous les principales traductions en matière de gestion des données et d’analyse descriptive entre SAS et R.\nNotes générales\n\n\n\nSAS\nR\n\n\n\n\nCommunauté en ligne disponible via SAS Support à la clientèle\nCommunauté en ligne disponible via RStudio, StackOverFlow et R-bloggers\n\n\nAide pour les commandes disponibles par help [command]\nAide disponible avec [function]? ou effectuer une recherche dans le volet d’aide\n\n\nCommenter le code en utilisant * TEXTE ; ou /* TEXTE */\nCommenter le code en utilisant #\n\n\nPresque toutes les commandes sont intégrées. Les utilisateurs peuvent écrire de nouvelles fonctions en utilisant les macros SAS, SAS/IML, SAS Component Language (SCL) et, plus récemment, les procédures Proc Fcmp et Proc Proto\nR s’installe avec les fonctions base, mais l’utilisation typique implique l’installation d’autres packages de CRAN (voir page Les bases de R)\n\n\nL’analyse est généralement effectuée en écrivant un programme SAS dans la fenêtre de l’éditeur.\nAnalyse écrite dans un script R dans le volet source de RStudio. Les scripts R markdown constituent une alternative.\n\n\n\nLe fichier d’accès au travail\n\n\n\nSAS\nR\n\n\n\n\nLes répertoires de travail peuvent être soit absolus, soit relatifs au dossier racine d’un projet en définissant le dossier racine à l’aide de %let rootdir=/chemin d'accès; %include “&cheminracine/nomsousdossier/nomfichier”\nLes répertoires de travail peuvent être soit absolus, soit relatifs au dossier racine du projet en utilisant le package here (voir Import et export)\n\n\nVoir le répertoire de travail actuel avec %put %sysfunc(getoption(work));\nUtilisez getwd() ou here() (si vous utilisez le package here), avec des parenthèses vides\n\n\nDéfinir le répertoire de travail avec libname “emplacement du dossier”\nUtilisez setwd(“emplacement du dossier”), ou set_here(\"emplacement du dossier) si vous utilisez le package here\n\n\n\nImportation et visualisation des données\n\n\n\nSAS\nR\n\n\n\n\nUtilisez la procédure Proc Import ou l’instruction Data Step Infile.\nUtilisez import() du package rio pour presque tous les types de fichiers. Des fonctions spécifiques existent comme alternatives (voir Import et export)\n\n\nLa lecture des fichiers csv se fait à l’aide de la fonction Proc Import datafile=”nom_fichier.csv” out=travail.nom_fichier dbms=CSV; run; OU en utilisant L’instruction Data Step Infile\nUtilisez import(\"nom_fichier.csv\")\n\n\nLa lecture des fichiers xlsx se fait à l’aide de la fonction Proc Import datafile=”nom_fichier.xlsx” out=travail.nom_fichier dbms=xlsx; run; OU en utilisant L’instruction Data Step Infile\nUtilisez import(“nom_fichier.xlsx”)\n\n\nParcourez vos données dans une nouvelle fenêtre en ouvrant la fenêtre de l’Explorateur et sélectionnez la bibliothèque souhaitée et l’ensemble de données\nVisualiser un ensemble de données dans le panneau source de RStudio en utilisant View(dataset). Vous devez spécifier le nom de votre ensemble de données à la fonction dans R car plusieurs ensembles de données peuvent être conservés en même temps. Notez le “V” majuscule dans cette fonction\n\n\n\nManipulation de données de base\n\n\n\nSAS\nR\n\n\n\n\nLes colonnes de l’ensemble de données sont souvent appelées “variables”\nOn parle plus souvent de “colonnes” ou parfois de “vecteurs” ou de “variables”\n\n\nAucune procédure spéciale n’est nécessaire pour créer une variable.Les nouvelles variables sont créées simplement en tapant le nom de la nouvelle variable, suivi d’un signe égal, puis d’une expression pour la valeur.\nGénérez de nouvelles variables en utilisant la fonction mutate(). Voir la page Nettoyage des données et fonctions de base pour plus de détails sur toutes les fonctions dplyr ci-dessous.\n\n\nLes variables sont renommées en utilisant rename *ancien_nom=nouveau_nom*\nLes colonnes peuvent être renommées à l’aide de la fonction rename(nouveau_nom = ancien_nom)\n\n\nLes variables sont conservées en utilisant **keep**=nom_variable\nLes colonnes peuvent être sélectionnées en utilisant la fonction select() avec le nom de la colonne entre parenthèses.\n\n\nLes variables sont supprimées à l’aide de la fonction **drop**=nom_variable\nLes colonnes peuvent être supprimées à l’aide de la fonction select() avec le nom de la colonne entre parenthèses après le signe moins.\n\n\nLes variables factorielles peuvent être étiquetées dans l’étape de données (Data Step) en utilisant l’instruction Label.\nL’étiquetage des valeurs peut être fait en convertissant la colonne en classe factorielle et en spécifiant les niveaux. Voir la page sur les Facteurs. Les noms de colonnes ne sont généralement pas étiquetés.\n\n\nLes enregistrements sont sélectionnés à l’aide des instructions Where ou If dans l’étape de données (Data Step).\nLes enregistrements sont sélectionnés à l’aide de la fonction filter() avec plusieurs conditions de sélection séparées soit par l’opérateur pour ET (en anglais AND,&), soit par une virgule.\n\n\nLes ensembles de données sont combinés en utilisant l’instruction Merge dans l’étape Data Step. Les jeux de données à fusionner doivent d’abord être triés à l’aide de la procédure Proc Sort.\nLe package `dplyr offre quelques fonctions pour fusionner les jeux de données. Voir la page Joindre des données pour plus de détails.\n\n\n\nAnalyse descriptive\n\n\n\nSAS\nR\n\n\n\n\nObtenez un aperçu de votre ensemble de données en utilisant la procédure Proc Summary, qui fournit les noms des variables et les statistiques descriptives\nObtenez un aperçu de votre ensemble de données en utilisant summary(dataset) ou skim(dataset) du package skimr\n\n\nMettre en tableau les effectifs d’une variable en utilisant proc freq data=Dataset; Tables nom_variable; Run;\nVoir la page sur les Tableaux descriptifsLes options incluent table() de R de base, et tabyl() du package janitor, entre autres. Notez que vous devrez spécifier le jeu de données et le nom de la colonne, car R contient plusieurs jeux de données.\n\n\nLe tableau croisé de deux variables dans un tableau 2x2 est fait avec proc freq data=Dataset ; Tables rowvar*colvar ; Run;\nAussi, vous pouvez utiliser table(), tabyl() ou d’autres options comme décrit dans la page Tableaux descriptifs.\n\n\n\nQuelques ressources utiles:\nR for SAS and SPSS Users (2011)\nSAS and R, Second Edition (2014)",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition vers R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.fr.html#interopérabilité-des-données",
    "href": "new_pages/transition_to_R.fr.html#interopérabilité-des-données",
    "title": "4  Transition vers R",
    "section": "4.4 Interopérabilité des données",
    "text": "4.4 Interopérabilité des données\n\nVoir la page Import et export pour des détails sur comment le package rio peut importer et experter des fichiers tels que des fichiers STATA .dta, des fichiers SAS .xpt et.sas7bdat, des fichiers SPSS .por et.sav, et plusieurs autres.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition vers R</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.fr.html",
    "href": "new_pages/packages_suggested.fr.html",
    "title": "5  Paquets conseillés",
    "section": "",
    "text": "5.1 Paquets disponibles sur le CRAN\n##############################################\n# Liste de paquets R utiles en épidémiologie #\n##############################################\n\n# Ce script utilise la fonction p_load() du paquet **pacman**, \n# qui installe le paquet si ce dernier n'est pas encore installé sur\n# l'ordinateur, et l'importe dans la session active pour l'utiliser \n# s'il est déjà installé.\n\n\n# S'assure de l'installation du paquet \"pacman\".\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n#  Paquets du CRAN\n##############################\npacman::p_load(\n     \n     # Apprendre R\n     ############\n     learnr,   # tutos interactifs dans le volet tutos de RStudio\n     swirl,    # tutoriels interactifs dans la console R\n        \n     # Gestion des projets et des dossiers\n     #############################\n     here,     # chemins de fichiers relatifs au dossier racine du projet R\n     rio,      # import/export de nombreux types de données\n     openxlsx, # import/export de classeurs Excel à feuilles multiples \n     \n     # Installation et gestion des paquets\n     ################################\n     pacman,   # installation et importation des paquets\n     renv,     # gérer les versions des paquets lors de collaborations\n     remotes,  # installer des paquets provenant de Github\n     \n     # Paquets généralistes pour gérer les données\n     #########################\n     tidyverse,    # méta-paquet qui comprend de nombreux paquets pour le traitement et la présentation des données.\n          # dplyr : gestion des données\n          # tidyr : gestion des données\n          # ggplot2 : visualisation de données\n          # stringr : travailler avec des chaînes de caractères et des caractères\n          # forcats : travailler avec des facteurs \n          # lubridate : travailler avec des dates\n          # purrr : itération et travail avec des listes\n\n     linelist,     # nettoyage de linelists\n     naniar,       # évaluation des données manquantes\n     \n     # Statistiques\n     ############\n     janitor,      # nettoyage des données\n     gtsummary,    # création de tableaux descriptifs et statistiques\n     rstatix,      # exécution rapide de tests et de résumés statistiques\n     broom,        # nettoyage des résultats des régressions\n     lmtest,       # likelihood-ratio tests\n     easystats,\n          # parameters, # alternative pour ordonner les résultats des régressions\n          # see,        # alternative pour visualiser les forest plots\n     \n     # modélisation épidémiologique\n     ###################\n     epicontacts,    # Analyse des réseaux de transmission\n     EpiNow2,        # Estimation de Rt\n     EpiEstim,       # Estimation Rt\n     projections,    # Projections d'incidence\n     incidence2,     # Création d'épicurves et traitement des données d'incidence\n     i2extras,       # Fonctions supplémentaires pour le paquet incidence2\n     epitrix,        # Fonctions epi utiles\n     distcrete,      # Distributions discrètes de délais\n     \n     \n     # graphiques - general\n     #################\n     #ggplot2,     # inclus dans tidyverse\n     cowplot,      # combinaison de graphiques  \n     patchwork,  # combinaison de graphiques (alternative à cowplot)     \n     RColorBrewer, # échelles de couleurs\n     ggnewscale,   # pour ajouter des couches supplémentaires de schémas de couleurs\n\n     # graphiques - types spécifiques\n     ########################\n     DiagrammeR,  # diagrammes utilisant le langage DOT\n     incidence2,  # courbes épidémiques\n     gghighlight, # mettre en évidence un sous-ensemble\n     ggrepel,     # étiquettes intelligentes\n     plotly,      # graphiques interactifs\n     gganimate,   # graphiques animés \n     \n\n     # SIG\n     ######\n     sf,            # pour gérer les données spatiales en utilisant un format Simple Feature\n     tmap,          # pour produire des cartes simples, fonctionne à la fois pour les cartes interactives et statiques\n     OpenStreetMap, # pour ajouter la carte de base OSM dans la carte ggplot\n     spdep,         # statistiques spatiales \n     \n     # Rapports automatisés\n     #################\n     rmarkdown,     # produit des PDFs, des documents Word, des Powerpoints, et des fichiers HTML\n     reportfactory, # auto-organisation des sorties R Markdown\n     officer,       # création de documents word et powerpoints (alternative à Rmarkdown)\n     \n     # Tableaux de bord\n     ############\n     flexdashboard, # création de tableaux de bord (syntaxe Rmarkdown)\n     shiny,         # applications web interactives\n     \n     # Créer des tableaux pour présenter des résultats\n     #########################\n     knitr,       # Génération de rapports R Markdown et tableaux html\n     flextable,   # Tableaux HTML\n     # DT,        # Tableaux HTML (alternative)\n     # gt,        # Tableaux HTML (alternative)\n     # huxtable,  # Tableaux HTML (alternative) \n     \n     # Phylogenetique\n     ###############\n     ggtree,  # visualisation et annotation d'arbres phylogénétiques\n     ape,     # analyse phylogénétique et évolutive\n     treeio,  # visualision des fichiers phylogénétiques\n \n)",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Paquets conseillés</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.fr.html#paquets-hébergés-sur-github",
    "href": "new_pages/packages_suggested.fr.html#paquets-hébergés-sur-github",
    "title": "5  Paquets conseillés",
    "section": "5.2 Paquets hébergés sur Github",
    "text": "5.2 Paquets hébergés sur Github\nVous trouverez ci-dessous les commandes pour installer des paquets directement depuis leur répertoire sur Github.\n\nLa version de développement de epicontacts contient la possibilité de faire des arbres de transmission avec un axe x temporel.\n\nLe paquet epirhandbook contient toutes les données d’exemple pour ce manuel et peut être utilisé pour télécharger la version hors ligne du manuel.\n\n\n# Paquets à télécharger depuis Github (non disponibles sur CRAN)\n##########################################################\n\n# Version de développement d'epicontacts (pour les chaînes de transmission avec un axe x temporel)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# Le paquet pour ce manuel, qui comprend toutes les données d'exemple \npacman::p_install_gh(\"appliedepi/epirhandbook\")",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Paquets conseillés</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.fr.html",
    "href": "new_pages/r_projects.fr.html",
    "title": "6  Projets R",
    "section": "",
    "text": "6.1 Utilisation suggérée\nUne façon courante, efficace et sans probléme d’utiliser R consiste à combiner ces 3 éléments. Un projet de travail discret est hébergélé dans un projet R. Chaque élément est décrit dans les sections ci-dessous.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projets R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.fr.html#utilisation-suggérée",
    "href": "new_pages/r_projects.fr.html#utilisation-suggérée",
    "title": "6  Projets R",
    "section": "",
    "text": "Un projet R\n\nUn environnement de travail autonome avec des dossiers pour les données, les scripts, les résultats, etc.\n\n\nLe paquet here pour les chemins de fichiers relatifs\n\nLes chemins de fichiers sont écrits par rapport au dossier racine du projet R - voir Importation et exportation pour plus d’informations.\n\n\nLe paquet rio pour les importations/exportations\n\nimport() et export() traitent tout type de fichier par son extension (par exemple .csv, .xlsx, .png).",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projets R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.fr.html#créer-un-projet-r",
    "href": "new_pages/r_projects.fr.html#créer-un-projet-r",
    "title": "6  Projets R",
    "section": "6.2 Créer un projet R",
    "text": "6.2 Créer un projet R\nPour créer un projet R, sélectionnez “Nouveau projet” dans le menu Fichier.\n\nSi vous voulez créer un nouveau dossier pour le projet, sélectionnez “Nouveau répertoire” et indiquez où vous voulez qu’il soit créé.\n\nSi vous voulez créer le projet dans un dossier existant, cliquez sur “Répertoire existant” et indiquez le dossier.\n\nSi vous voulez cloner un dépôt Github, sélectionnez la troisiéme option “Version Control” et ensuite “Git”. Voir la page contrôle de version et collaboration avec Git et Github pour plus de détails.\n\n\n\n\n\n\n\n\n\n\nLe projet R que vous créez se présente sous la forme d’un dossier contenant un fichier .Rproj. Ce fichier est un raccourci et probablement la principale façon d’ouvrir votre projet. Vous pouvez également ouvrir un projet en sélectionnant “Ouvrir un projet” dans le menu Fichier. Alternativement, sur le côté supérieur droit de RStudio, vous verrez une icône de projet R et un menu déroulant des projets R disponibles.\nPour quitter un projet R, vous pouvez soit ouvrir un nouveau projet, soit fermer le projet (Fichier - Fermer le projet).\n\nChanger de projet\nPour passer d’un projet à l’autre, cliquez sur l’icône et le menu déroulant du projet R tout en haut à droite de RStudio. Vous verrez les options Fermer le projet, Ouvrir le projet, et une liste de projets récents.\n\n\n\n\n\n\n\n\n\n\n\nParamétres\nIl est généralement conseillé de démarrer RStudio à chaque fois avec une “ardoise propre” - c’est-à-dire avec votre espace de travail non préservé de votre session précédente. Cela signifie que vos objets et résultats ne persisteront pas d’une session à l’autre (vous devrez les recréer en exécutant vos scripts). C’est une bonne chose, car cela vous obligera à écrire de meilleurs scripts et à éviter les erreurs à long terme.\nPour configurer RStudio de maniére à ce qu’il fasse “table rase” à chaque démarrage :\n\nSélectionnez “Options du projet” dans le menu Outils.\n\nDans l’onglet “Général”, configurez RStudio pour ne pas restaurer les .RData dans l’espace de travail au démarrage, et pour ne pas sauvegarder l’espace de travail en .RData à la sortie.\n\n\n\nOrganisation\nIl est courant d’avoir des sous-dossiers dans votre projet. Pensez à avoir des dossiers tels que “données”, “scripts”, “figures”, “présentations”. Vous pouvez ajouter des dossiers de la même maniére que vous ajouteriez un nouveau dossier sur votre ordinateur. Vous pouvez également consulter la page sur les Interactions avec les répertoires pour apprendre à créer de nouveaux dossiers à l’aide de commandes R.\n\n\nContrôle de version\nPensez à un systéme de contrôle de version. Cela pourrait étre quelque chose d’aussi simple que d’avoir des dates sur les noms des scripts (par exemple “transmission_analysis_2020-10-03.R”) et un dossier “archive”. Vous pouvez également envisager d’avoir un texte d’en-téte commenté en haut de chaque script avec une description, des balises, des auteurs et un journal des modifications.\nUne méthode plus complexe consisterait à utiliser Github ou une plateforme similaire pour le contrôle de version. Voir la page contrôle de version et collaboration avec Git et Github.\nUne astuce : vous pouvez effectuer une recherche dans l’ensemble d’un projet ou d’un dossier à l’aide de l’outil “Rechercher dans les fichiers” (menu édition). Il peut rechercher et même remplacer des chaînes de caractères dans plusieurs fichiers.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projets R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.fr.html#exemples",
    "href": "new_pages/r_projects.fr.html#exemples",
    "title": "6  Projets R",
    "section": "6.3 Exemples",
    "text": "6.3 Exemples\nVoici quelques exemples d’importation/exportation/sauvegarde utilisant here() à partir d’un projet R. Pour en savoir plus sur l’utilisation du paquet here, consultez la page Import and export.\nImporter linelist_raw.xlsx du dossier “data” de votre projet R\n\nlinelist &lt;- import(here(\"data\", \"linelist_raw.xlsx\"))\n\nExportation de l’objet R linelist en tant que “my_linelist.rds” dans le dossier “clean” du dossier “data” de votre projet R.\n\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\n\nEnregistrement du tracé le plus récemment imprimé sous le nom de “epicurve_2021-02-15.png” dans le dossier “epicurves” du dossier “outputs” de votre projet R.\n\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projets R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.fr.html#ressources",
    "href": "new_pages/r_projects.fr.html#ressources",
    "title": "6  Projets R",
    "section": "6.4 Ressources",
    "text": "6.4 Ressources\nPage web de RStudio sur l’utilisation de projets R",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Projets R</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html",
    "href": "new_pages/importing.fr.html",
    "title": "7  Importer et exporter des données",
    "section": "",
    "text": "7.1 Aperçu\nLorsque vous importez un “jeu de données” dans R, vous créez généralement un nouvel objet appelé data frame dans votre environnement R et vous le définissez comme un fichier importé (par exemple Excel, CSV, TSV, RDS) qui se trouve dans votre répertoire de dossiers à un certain chemin d’accès au fichier.\nVous pouvez importer/exporter de nombreux types de fichiers, y compris ceux créés par d’autres programmes statistiques (SAS, STATA, SPSS). Vous pouvez également vous connecter à des bases de données relationnelles.\nR a même ses propres formats de données :",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#aperçu",
    "href": "new_pages/importing.fr.html#aperçu",
    "title": "7  Importer et exporter des données",
    "section": "",
    "text": "Un fichier RDS (.rds) stocke un seul objet R tel qu’un dataframe. Ils sont utiles pour stocker des données nettoyées, car ils conservent les classes de colonnes R. Pour en savoir plus, consultez cette section.\nUn fichier RData (.Rdata) peut être utilisé pour stocker plusieurs objets, voire un espace de travail R complet. Pour en savoir plus, consultez cette section.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#le-package-rio",
    "href": "new_pages/importing.fr.html#le-package-rio",
    "title": "7  Importer et exporter des données",
    "section": "7.2 Le package rio",
    "text": "7.2 Le package rio\nLe paquet R que nous recommandons est : rio. Le nom “rio” est une abréviation de “R I/O” (input/output).\nSes fonctions import() et export() peuvent traiter de nombreux types de fichiers différents (par exemple .xlsx, .csv, .rds, .tsv). Lorsque vous fournissez un chemin d’accès au fichier à l’une de ces fonctions (y compris l’extension de fichier comme “.csv”), rio lira l’extension et utilisera le bon outil pour importer ou exporter le fichier.\nL’alternative à l’utilisation de rio est d’utiliser les fonctions de nombreux autres packages, chacun d’entre eux étant spécifique à un type de fichier. Par exemple, read.csv() (base R), read.xlsx() (openxlsx package), et write_csv() (readr pacakge), etc. Ces alternatives peuvent être difficiles à mémoriser, alors qu’utiliser import() et export() de rio est facile.\nLes fonctions import() et export() de rio utilisent le package et la fonction appropriés pour un fichier donné, en se basant sur son extension. Consultez la fin de cette page pour un tableau complet des paquets/fonctions que rio utilise en arrière-plan. Il peut également être utilisé pour importer des fichiers STATA, SAS, et SPSS, parmi des dizaines d’autres types de fichiers.\nL’importation/exportation de shapefile nécessite d’autres packages, tel que détaillé dans la page sur Introduction aux SIG.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#here",
    "href": "new_pages/importing.fr.html#here",
    "title": "7  Importer et exporter des données",
    "section": "7.3 Le package here",
    "text": "7.3 Le package here\nLe package here et sa fonction here() permettent d’indiquer facilement à R où trouver et enregistrer vos fichiers - en fait, il construit les chemins d’accès aux fichiers.\nUtilisé en conjonction avec un projet R, here vous permet de décrire l’emplacement des fichiers dans votre projet R par rapport au répertoire racine du projet R (le dossier de niveau supérieur). Cela est utile lorsque le projet R peut être partagé ou accessible par plusieurs personnes/ordinateurs. Cela évite les complications dues aux chemins d’accès aux fichiers uniques sur différents ordinateurs (par exemple \"C:/Users/Laura/Documents...\" en “commençant” le chemin d’accès à un endroit commun pour tous les utilisateurs (la racine du projet R).\nVoici comment here() fonctionne dans un projet R :\n\nLorsque le package here est chargé pour la première fois dans le projet R, il place un petit fichier appelé “.here” dans le dossier racine de votre projet R comme “repère” ou “ancre”.\n\nDans vos scripts, pour référencer un fichier dans les sous-dossiers du projet R, vous utilisez la fonction here() pour construire le chemin d’accès au fichier en relation avec cette ancre\nPour construire le chemin d’accès au fichier, écrivez les noms des dossiers au-delà de la racine, entre guillemets, séparés par des virgules, et terminez par le nom du fichier et son extension, comme indiqué ci-dessous.\n\nLes chemins d’accès here() peuvent être utilisés à la fois pour l’importation et l’exportation.\n\nPar exemple, ci-dessous, la fonction import() reçoit un chemin d’accès construit avec here().\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\nLa commande here(\"data\", \"linelists\", \"ebola_linelist.xlsx\") fournit en fait le chemin d’accès complet au fichier qui est unique à l’ordinateur de l’utilisateur :\n\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\"\nL’avantage est que la commande R utilisant here() peut être exécutée avec succès sur n’importe quel ordinateur accédant au projet R.\nTIP: Si vous n’êtes pas certaine de l’emplacement de la racine “here”, exécutez la fonction here() avec des parenthèses vides.\nPlus d’informations sur le package ici en cliquant sur ce lien.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#chemins-daccès-aux-fichiers",
    "href": "new_pages/importing.fr.html#chemins-daccès-aux-fichiers",
    "title": "7  Importer et exporter des données",
    "section": "7.4 Chemins d’accès aux fichiers",
    "text": "7.4 Chemins d’accès aux fichiers\nLorsque vous importez ou exportez des données, vous devez fournir un chemin d’accès au fichier. Vous pouvez le faire de trois manières différentes:\n\nRecommandé: fournir un chemin d’accès “relatif” avec le package here\nFournir le chemin d’accès “complet” / “absolu”\nSélection manuelle des fichiers\n\n\nChemins d’accès “relatifs”\nDans R, les chemins d’accès “relatifs” consistent en un chemin d’accès relatif à la racine d’un projet R. Ils permettent d’obtenir des chemins d’accès plus simples qui peuvent fonctionner sur différents ordinateurs (par exemple, si le projet R se trouve sur un disque partagé ou est envoyé par courrier électronique). Comme décrit ci-dessus, les chemins de fichiers relatifs sont facilités par l’utilisation du package here.\nVoici un exemple de chemin d’accès relatif construit avec here(). Nous supposons que le travail se trouve dans un projet R qui contient un sous-dossier “data” et dans celui-ci un sous-dossier “linelists”, dans lequel se trouve le fichier .xlsx qui nous intéresse.\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\n\n\nChemins d’accès “absolus”\nLes chemins d’accès absolus ou “complets” peuvent être fournis à des fonctions comme import() mais ils sont “fragiles” car ils sont uniques à l’ordinateur spécifique de l’utilisateur et donc non recommandés.\nVous trouverez ci-dessous un exemple de chemin d’accès absolu à un fichier. Dans l’ordinateur de Laura, il existe un dossier “analysis”, un sous-dossier “data” et un sous-dossier “linelists”, dans lequel se trouve le fichier .xlsx en question.\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")\n\nQuelques points à noter concernant les chemins d’accès absolus aux fichiers:\n\nÉvitez les chemins d’accès absolus parce qu’ils vont interrompre le script si ils sont utilisés sur un autre ordinateur différent\nUtilisez des barres obliques (/), comme dans l’exemple ci-dessus (remarque : ce n’est PAS l’option par défaut pour les chemins d’accès aux fichiers de Windows).\nLes chemins de fichiers qui commencent par des doubles barres obliques (par exemple, “//…”) ne seront probablement pas reconnus par R et produiront une erreur. Pensez à déplacer votre travail sur un lecteur “nommé” ou “lettré” qui commence par une lettre (par exemple “J :” ou “C :”). Voir la page sur les Interactions avec les répertoires pour plus de détails sur cette question.\n\nUn scénario dans lequel les chemins de fichier absolus peuvent être appropriés est celui où vous voulez importer un fichier d’un lecteur partagé qui a le même chemin d’accès complet pour tous les utilisateurs.\nTIP: Pour convertir rapidement tous les \\ à /, surlignez le code d’intérêt, utilisez Ctrl+f (avec Windows), sélectionnez l’option “Dans la sélection”, et ensuite utilisez la fonction remplacement pour les convertir.\n\n\n\nSélectionner les fichier manuellement\nVous pouvez importer des données de façon manuelle via une de ces méthodes:\n\nDans le volet Environnement de RStudio, cliquez sur “Import Dataset”, et sélectionnez le type de données\nCliquez sur File / Import Dataset / (sélectionnez le type de données)\n\nPour une sélection manuelle complète, utilisez la commande file.choose() de la base R (en laissant les parenthèses vides) pour d’éclencher l’apparition d’une fenêtre pop-up qui permet à l’utilisateur de sélectionner manuellement le fichier sur son ordinateur. Par exemple :\n\n\n# Sélection manuelle d'un fichier. Lorsque cette commande est exécutée, une fenêtre POP-UP apparaîtra.\n\n# Le chemin du fichier sélectionné sera fourni à la commande import().\n\nmy_data &lt;- import(file.choose())\n\nTIP: Il est possible que la fenêtre pop-up apparaisse DERRIÈRE votre fenêtre de RStudio.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#importer-des-données",
    "href": "new_pages/importing.fr.html#importer-des-données",
    "title": "7  Importer et exporter des données",
    "section": "7.5 Importer des données",
    "text": "7.5 Importer des données\nIl est assez simple d’utiliser import() pour importer un ensemble des données. Il suffit de fournir le chemin d’accès au fichier (y compris le nom et l’extension du fichier) entre guillemets. Si vous utilisez here() pour construire le chemin d’accès au fichier, suivez les insTIPtions ci-dessus. Voici quelques exemples:\nImportation d’un fichier csv situé dans votre “répertoire de travail” ou dans le dossier racine du projet R:\n\nlinelist &lt;- import(\"linelist_cleaned.csv\")\n\nImportation de la première feuille d’un Excel qui se trouve dans les sous-dossiers “data” et “linelists” du projet R (le chemin du fichier construit à l’aide de here()):\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\n\nImporting d’un data frame (un fichier .rds) à l’aide d’un chemin d’accès absolu:\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")\n\n\nFeuilles spécifiques d’Excel\nPar défaut, si vous fournissez un fichier Excel (.xlsx) à import(), la première feuille du fichier sera importée. Si vous voulez importer une feuille spécifique, incluez le nom de la feuille dans l’argument which =. Par exemple:\n\nmy_data &lt;- import(\"my_excel_file.xlsx\", which = \"Sheetname\")\n\nSi vous utilisez la méthode here() pour fournir un chemin d’accès relatif à import(), vous pouvez toujours indiquer une feuille spécifique en ajoutant l’argument which = après les parenthèses de fermeture de la fonction here().\n\n# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\nlinelist_raw &lt;- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  \n\nPour exporter un data frame à partir de R vers une feuille Excel spécifique tout en gardant inchangé le reste du fichier Excel, vous devrez importer, modifier et exporter avec un package alternatif spécifique pour cet objectif tel que openxlsx. Pour davantage d’information consultez la page Interactions avec les répertoires ou cette page github.\nSi votre fichier Excel est .xlsb (fichier Excel en format binaire) il est possible que vous ne puissiez pas l’importer en utilisant rio. Envisagez de le réenregistrer en format .xlsx, ou bien en utilisant un package tel que readxlsb qui fut conçu à cet effet.\n\n\n\nDonnées manquantes\nVous pouvez désigner la ou les valeurs de votre ensemble de données qui doivent être considérées comme manquantes. Comme expliqué dans la page Données manquantes, la valeur dans R pour les données manquantes est NA, mais peut-être que l’ensemble de données que vous voulez importer utilise 99, “Manquant”, ou juste un espace vide “” à la place.\nUtilisez l’argument na = avec import() et fournissez la ou les valeurs entre guillemets (même si ce sont des nombres). Vous pouvez spécifier plusieurs valeurs en les incluant dans un vecteur, en utilisant c() comme indiqué ci-dessous.\nIci, la valeur “99” dans le jeu de données est considéré comme manquant et converti à NA dans R.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\n\nIci, toutes les valeurs “Missing”, “” (cellule vide), ou ” ” (espace unique) dans l’ensemble de données importées sont converties en NA dans R.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))\n\n\n\n\nSauter des lignes\nParfois, vous pouvez vouloir éviter d’importer une ligne de données. Vous pouvez le faire avec l’argument skip = si vous utilisez import() de rio sur un fichier .xlsx ou .csv. Indiquez le nombre de lignes que vous souhaitez ignorer.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\", skip = 1)  # n'importe pas la ligne d'en-tête\n\nMalheureusement, skip = n’accepte qu’une seule valeur entière, pas une plage (par exemple, “2:10” ne fonctionne pas). Pour sauter l’importation de lignes spécifiques qui ne sont pas consécutives à partir du haut, pensez à importer plusieurs fois et à utiliser bind_rows() de dplyr. Voir l’exemple ci-dessous pour sauter seulement la ligne 2.\n\n\nGérer une deuxième ligne d’en-tête\nParfois, vos données peuvent avoir une deuxième ligne, par exemple s’il s’agit d’une ligne de “dictionnaire de données” comme indiqué ci-dessous. Cette situation peut être problématique car elle peut entraîner l’importation de toutes les colonnes en tant que classe “caractère”.\nVoici un exemple de ce type d’ensemble de données (la première ligne étant le dictionnaire de données).\n\n\n\n\n\n\n\nSupprimez la deuxième ligne d’en-tête\nPour supprimer la deuxième ligne d’en-tête, vous devrez probablement importer les données deux fois.\n\nImportez les données afin de stocker les bons noms des colonnes.\nImportez à nouveau les données, en sautant les deux premières lignes (en-tête et deuxième ligne).\nReliez les noms corrects sur le cadre de données réduit.\n\nL’argument exact utilisé pour relier les bons noms de colonnes dépend du type de fichier de données (.csv, .tsv, .xlsx, etc.). Ceci est dû au fait que rio utilise une fonction différente pour les différents types de fichiers (voir le tableau ci-dessus).\nPour les documents Excel: (col_names =)\n\n# importer pour la première fois; stocker les noms des colonnes\nlinelist_raw_names &lt;- import(\"linelist_raw.xlsx\") %&gt;% names()  # stocker les bons noms des colonnes\n\n# importer pour la deuxième fois; sauter la deuxième ligne, et assigner les noms des colonnes à l'argument col_names =\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n\nPour les fichiers CSV: (col.names =)\n\n# importer pour la première fois; stocker les noms des colonnes\nlinelist_raw_names &lt;- import(\"linelist_raw.csv\") %&gt;% names() # save true column names\n\n# notez que l'argument pour les fichiers CSV est 'col.names = '\nlinelist_raw &lt;- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n\nOption de secours - changer les noms des colonnes à l’aide d’une commande additionnelle\n\n# attribuer/supprimer des en-têtes en utilisant la fonction de base 'colnames()'\ncolnames(linelist_raw) &lt;- linelist_raw_names\n\n\n\nCréer un dictionnaire de données\nBonus! Si vous avez une deuxième ligne qui est un dictionnaire de données, vous pouvez facilement créer un dictionnaire de données approprié à partir de celle-ci. Cette astuce est adaptée de cet article.\n\ndict &lt;- linelist_2headers %&gt;%             # début: liste des case avec le dictionnaire en première ligne\n  head(1) %&gt;%                             # garder seulement les noms des colonnes et la premièere ligne étant le dictionnaire                \n  pivot_longer(cols = everything(),       # pivoter toutes les colonnes au format long\n               names_to = \"Column\",       # définir de nouveaux noms pour les colonnes\n               values_to = \"Description\")\n\n\n\n\n\n\n\n\n\nCombiner les deux lignes d’en-tête\nDans certains cas, lorsque votre ensemble de données brutes comporte deux lignes d’en-tête (ou plus précisément, la deuxième ligne de données est un en-tête secondaire), vous pouvez souhaiter les “combiner” ou ajouter les valeurs de la deuxième ligne d’en-tête à la première ligne d’en-tête.\nLa commande ci-dessous définit les noms des colonnes du cadre de données comme la combinaison (collage) des premiers en-têtes (vrais) avec la valeur située immédiatement en dessous (dans la première ligne).\n\nnames(my_data) &lt;- paste(names(my_data), my_data[1, ], sep = \"_\")\n\n\n\n\n\nFeuille de calcul Google\nVous pouvez importer des données à partir d’une feuille de calcul Google en ligne avec le paquet googlesheet4 et en authentifiant votre accès à la feuille de calcul.\n\npacman::p_load(\"googlesheets4\")\n\nCi-dessous, une feuille de calcul Google de démonstration est importée et sauvegardée. Cette commande peut vous demander de confirmer l’authentification de votre compte Google. Suivez les insTIPtions et les fenêtres contextuelles de votre navigateur Internet pour accorder aux packages API Tidyverse les autorisations de modifier, créer et supprimer vos feuilles de calcul dans Google Drive.\nLa feuille ci-dessous est “consultable par toute personne ayant le lien” et vous pouvez essayer de l’importer.\n\nGsheets_demo &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\n\nLa feuille ci-dessous est “consultable par toute personne ayant le lien” et vous pouvez essayer de l’importer.\n\nGsheets_demo &lt;- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")\n\nUn autre package, googledrive, propose des fonctions utiles pour écrire, modifier et supprimer des feuilles Google. Par exemple, en utilisant les fonctions gs4_create() et sheet_write() trouvées dans ce package.\nVoici d’autres tutoriels en ligne utiles:\nTutoriel de base sur l’importation de feuilles de calcul Google sheets\ntutoriel plus détaillé\nintéraction entre googlesheets4 et tidyverse",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#fichiers-multiples---importation-exportation-fractionnement-combinaison",
    "href": "new_pages/importing.fr.html#fichiers-multiples---importation-exportation-fractionnement-combinaison",
    "title": "7  Importer et exporter des données",
    "section": "7.6 Fichiers multiples - importation, exportation, fractionnement, combinaison",
    "text": "7.6 Fichiers multiples - importation, exportation, fractionnement, combinaison\nConsultez la page Itération, boucles et listes pour obtenir des exemples sur la manière d’importer et de combiner plusieurs fichiers, ou plusieurs fichiers de classeur Excel. Cette page contient également des exemples sur la façon de diviser un cadre de données en plusieurs parties et d’exporter chacune d’entre elles séparément, ou en tant que feuilles nommées dans un classeur Excel.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#import_github",
    "href": "new_pages/importing.fr.html#import_github",
    "title": "7  Importer et exporter des données",
    "section": "7.7 Importer de Github",
    "text": "7.7 Importer de Github\nL’importation de données directement de Github dans R peut être très facile ou nécessiter quelques étapes, selon le type de fichier. Voici quelques approches:\n\nFichiers CSV\nIl peut être facile d’importer un fichier .csv directement de Github dans R avec une commande R.\n\nAllez sur le repo Github, localisez le fichier qui vous intéresse et cliquez dessus.\n\nCliquez sur le bouton “Raw” (vous verrez alors les données csv “brutes”, comme indiqué ci-dessous)\n\nCopiez l’adresse URL\n\nPlacez l’URL entre guillemets dans la commande R import()\n\n\n\n\n\n\n\n\n\n\n\n\nFichiers XLSX\nIl se peut que vous ne puissiez pas visualiser les données “brutes” pour certains fichiers (e.x. .xlsx, .rds, .nwk, .shp)\n\nAllez sur le repo Github, localisez le fichier qui vous intéresse et cliquez dessus.\n\nCliquez sur le bouton “Download”, comme indiqué ci-dessous\n\nSauvegardez le fichier sur votre ordinateur, et importez-le dans R\n\n\n\n\n\n\n\n\n\n\n\n\nShapefiles\nLes fichiers Shapefiles comportent de nombreux sous-fichiers, chacun avec une extension de fichier différente. Un fichier aura l’extension “.shp”, mais d’autres peuvent avoir “.dbf”, “.prj”, etc. Pour télécharger un shapefile à partir de Github, vous devrez télécharger chacun des fichiers de sous-composants individuellement, et les enregistrer dans le même dossier sur votre ordinateur. Dans Github, cliquez sur chaque fichier individuellement et téléchargez-les en cliquant sur le bouton ” Download “.\nUne fois enregistré sur votre ordinateur, vous pouvez importer le shapefile comme indiqué sur la page Bases de SIG st_read() du paquet sf. Il vous suffit de fournir le chemin d’accès et le nom du fichier ” .shp “, à condition que les fichiers associés se trouvent dans le même dossier sur votre ordinateur.\nCi-dessous, vous pouvez voir comment le shapefile “sle_adm3” se compose de plusieurs fichiers, chacun devant être téléchargé depuis Github.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#entrée-de-données-de-façon-manuelle",
    "href": "new_pages/importing.fr.html#entrée-de-données-de-façon-manuelle",
    "title": "7  Importer et exporter des données",
    "section": "7.8 Entrée de données de façon manuelle",
    "text": "7.8 Entrée de données de façon manuelle\n\nEntrée par lignes\nUtilisez la fonction tribble du paquet tibble du tidyverse, ici un référence tibble en ligne\nNotez que les en-têtes de colonne commencent par une tilde (~). Notez également que chaque colonne ne doit contenir qu’une seule classe de données (caractère, numérique, etc.). Vous pouvez utiliser des tabulations, des espaces et de nouvelles lignes pour rendre la saisie des données plus intuitive et plus lisible. Les espaces ne comptent pas entre les valeurs, mais chaque ligne est représentée par une nouvelle ligne de code. Par exemple:\n\n# create the dataset manually by row\nmanual_entry_rows &lt;- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )\n\nEt maintenant nous affichons le nouveau jeu de données:\n\n\n\n\n\n\n\n\nEntrée par colonnes\nÉtant donné qu’un cadre de données est constitué de vecteurs (colonnes verticales), l’approche de base de la création manuelle de cadres de données dans R prévoit que vous définissiez chaque colonne, puis que vous les reliiez entre elles. Cela peut être contre-intuitif en épidémiologie, car nous pensons généralement à nos données en lignes (comme ci-dessus).\n\n# define each vector (vertical column) separately, each with its own name\nPatientID &lt;- c(235, 452, 778, 111)\nTreatment &lt;- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     &lt;- c(1, 0, 1, 0)\n\nATTENTION: Tous les vecteurs doivent avoir la même longueur (même nombre de valeurs).\nLes vecteurs peuvent ensuite être liés entre eux à l’aide de la fonction data.frame():\n\n# combiner les colonnes dans un cadre de données, en référençant les noms de vecteurs\nmanual_entry_cols &lt;- data.frame(PatientID, Treatment, Death)\n\nEt maintenant nous affichons le nouveau jeu de données:\n\n\n\n\n\n\n\n\nCollage à partir du presse-papiers\nSi vous copiez des données d’un autre endroit et que vous les avez dans votre presse-papiers, vous pouvez essayer l’une des deux méthodes ci-dessous :\nA partir du package clipr, vous pouvez utiliser read_clip_tbl() pour importer comme un cadre de données, ou simplement read_clip() pour importer comme un vecteur de caractères. Dans les deux cas, laissez les parenthèses vides.\n\nlinelist &lt;- clipr::read_clip_tbl()  # importe le presse-papiers actuel comme cadre de données\nlinelist &lt;- clipr::read_clip()      # importations en tant que vecteur de caractères\n\nVous pouvez aussi facilement exporter vers le presse-papiers de votre système avec clipr. Voir la section ci-dessous sur l’Exportation.\nAlternativement, vous pouvez utiliser la fonction read.table() de base R avec file = \"clipboard\") pour importer comme un cadre de données:\n\ndf_from_clipboard &lt;- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#importer-le-fichier-le-plus-récent",
    "href": "new_pages/importing.fr.html#importer-le-fichier-le-plus-récent",
    "title": "7  Importer et exporter des données",
    "section": "7.9 Importer le fichier le plus récent",
    "text": "7.9 Importer le fichier le plus récent\nIl arrive souvent que vous receviez des mises à jour quotidiennes de vos ensembles de données. Dans ce cas, vous voudrez écrire un code qui importe le fichier le plus récent. Nous présentons ci-dessous deux façons d’aborder cette question:\n\nSélection du fichier en fonction de la date figurant dans le nom du fichier\n\nSélection du fichier sur la base des métadonnées du fichier (dernière modification)\n\n\nDates dans le nom du fichier\nCette approche repose sur trois prémisses:\n\nVous faites confiance aux dates dans les noms de fichiers\n\nLes dates sont numériques et apparaissent généralement dans le même format (par exemple, année, mois, jour)\n\nIl n’y a pas d’autres chiffres dans le nom du fichier\n\nNous vous expliquerons chaque étape, puis nous vous les montrerons combinées à la fin.\nTout d’abord, utilisez dir() de base R pour extraire uniquement les noms de fichiers pour chaque fichier dans le dossier qui vous intéresse. Pour plus de détails sur dir(), consultez la page sur Interactions avec les répertoires. Dans cet exemple, le dossier concerné est le dossier ” linelists ” situé dans le dossier ” example ” situé dans ” data ” au sein du projet R.\n\nlinelist_filenames &lt;- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print\n\n[1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n[3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n[5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n[7] \"case_linelist20201006.csv\"    \n\n\nUne fois que vous avez ce vecteur de noms, vous pouvez en extraire les dates en appliquant str_extract() de stringr en utilisant cette expression régulière. Elle extrait tous les nombres dans le nom de fichier (y compris tout autre caractère au milieu comme les tirets ou les barres obliques). Vous pouvez en savoir plus sur stringr à la page Caractères et chaînes de caractères.\n\nlinelist_dates_raw &lt;- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print\n\n[1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"20201006\"  \n\n\nEn supposant que les dates sont généralement écrites dans le même format (par exemple, Année puis Mois puis Jour) et que les années ont 4 chiffres, vous pouvez utiliser les fonctions de conversion flexibles de lubridate (ymd(), dmy(), ou mdy()) pour les convertir en dates. Pour ces fonctions, les tirets, les espaces ou les barres obliques n’ont pas d’importance, seul l’ordre des chiffres compte. Pour en savoir plus, consultez la page Manipuler les dates.\n\nlinelist_dates_clean &lt;- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean\n\n[1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"2020-10-06\"\n\n\nLa fonction R base which.max() peut alors être utilisée pour retourner la position de l’index (par exemple, 1ère, 2ème, 3ème, …) de la valeur maximale de la date. Le dernier fichier est correctement identifié comme étant le 6ème fichier - “case_linelist_2020-10-08.xlsx”.\n\nindex_latest_file &lt;- which.max(linelist_dates_clean)\nindex_latest_file\n\n[1] 6\n\n\nSi nous condensons toutes ces commandes, le code complet pourrait ressembler à ce qui suit. Notez que le . de la dernière ligne est un caractère de remplacement pour l’objet pipé à ce point de la séquence de pipelines. A ce stade, la valeur est simplement le nombre 6. Celui-ci est placé entre doubles crochets pour extraire le 6ème élément du vecteur de noms de fichiers produit par dir().\n\n# Charger les packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extraire le nom de fichier du dernier fichier\nlatest_file &lt;- dir(here(\"data\", \"example\", \"linelists\")) %&gt;%  # noms du fichier du sous-dossier \"linelists\"          \n  str_extract(\"[0-9].*[0-9]\") %&gt;%                  # extraire les dates (nombres)\n  ymd() %&gt;%                                        # convertir les nombres en dates (assumant le format année-mois-jour)\n  which.max() %&gt;%                                  # obtenir l'index de la date maximale (dernier fichier)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # retourne le nom de fichier de la dernière liste de diffusion\n\nlatest_file  # imprimer le nom du dernier fichier\n\n[1] \"case_linelist_2020-10-08.xlsx\"\n\n\nVous pouvez maintenant utiliser ce nom pour terminer le chemin de fichier relatif, avec here():\n\nhere(\"data\", \"example\", \"linelists\", latest_file) \n\nEt vous pouvez maintenant importer le dernier fichier:\n\n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import \n\n\n\nUtiliser l’information du fichier\nSi vos fichiers n’ont pas de date dans leur nom (ou si vous ne faites pas confiance à ces dates), vous pouvez essayer d’extraire la date de dernière modification à partir des métadonnées du fichier. Utilisez les fonctions du paquet fs pour examiner les informations des métadonnées de chaque fichier, qui comprennent l’heure de dernière modification et le chemin d’accès au fichier.\nCi-dessous, nous fournissons le dossier d’intérêt à la fonction dir_info() de fs. Dans ce cas, le dossier d’intérêt se trouve dans le projet R dans le dossier “data”, le sous-dossier “example”, et son sous-dossier “linelists”. Le résultat est un cadre de données avec une ligne par fichier et des colonnes pour modification_time, path, etc. Vous pouvez voir un exemple visuel de ceci dans la page sur Interactions avec les répertoires.\nNous pouvons trier ce cadre de données de fichiers par la colonne modification_time, et ensuite ne garder que la ligne (fichier) la plus haute/la plus récente avec la fonction base de R head(). Ensuite, nous pouvons extraire le chemin d’accès de ce dernier fichier uniquement avec la fonction dplyr pull() sur la colonne path. Enfin, nous pouvons passer ce chemin de fichier à import(). Le fichier importé est enregistré sous le nom de latest_file.\n\nlatest_file &lt;- dir_info(here(\"data\", \"example\", \"linelists\")) %&gt;%  # collecte des informations sur tous les fichiers du répertoire\n  arrange(desc(modification_time)) %&gt;%      # trier par temps de modification\n  head(1) %&gt;%                               # ne conserver que le fichier le plus récent\n  pull(path) %&gt;%                            # extraire uniquement le chemin du fichier\n  import()                                  # importer le fichier",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#import_api",
    "href": "new_pages/importing.fr.html#import_api",
    "title": "7  Importer et exporter des données",
    "section": "7.10 APIs",
    "text": "7.10 APIs\nUne “interface de programmation automatisée” (API) peut être utilisée pour demander directement des données à un site web. Les API sont un ensemble de règles qui permettent à une application logicielle d’interagir avec une autre. Le client (vous) envoie une “requête” et reçoit une “réponse” contenant du contenu. Les packages R httr et jsonlite peuvent faciliter ce processus.\nChaque site Web compatible avec l’API possède sa propre documentation et ses propres spécificités avec lesquelles il faut se familiariser. Certains sites sont accessibles au public et peuvent être consultés par n’importe qui. D’autres, comme les plates-formes avec des identifiants et des références d’utilisateur, nécessitent une authentification pour accéder à leurs données.\nIl va sans dire qu’il est nécessaire de disposer d’une connexion Internet pour importer des données via l’API. Nous donnerons brièvement des exemples d’utilisation des API pour importer des données, et nous vous renverrons à d’autres ressources.\nNote : rappelons que les données peuvent être affichées* sur un site web sans API, ce qui peut être plus facile à récupérer. Par exemple, un fichier CSV affiché peut être accessible simplement en fournissant l’URL du site à import() comme décrit dans la section sur importation de Github.*\n\nRequête HTTP\nL’échange d’API se fait le plus souvent par le biais d’une requête HTTP. HTTP, qui signifie Hypertext Transfer Protocol, est le format sous-jacent d’une demande/réponse entre un client et un serveur. Les données d’entrée et de sortie exactes peuvent varier en fonction du type d’API, mais le processus est le même : une “demande” (souvent une requête HTTP) de la part de l’utilisateur, contenant souvent une requête, suivie d’une “réponse”, contenant des informations d’état sur la demande et éventuellement le contenu demandé.\nVoici quelques éléments d’une requête HTTP:\n\nL’URL du point de terminaison de l’API\n\nLa “Méthode” (ou “Verbe”)\n\nEn-tête\n\nCorps\n\nLa “méthode” de la requête HTTP est l’action que vous voulez effectuer. Les deux méthodes HTTP les plus courantes sont GET et POST mais d’autres peuvent inclure PUT, DELETE, PATCH, etc. Lorsque vous importez des données dans R, il est très probable que vous utilisiez la méthode GET.\nAprès votre requête, votre ordinateur recevra une “réponse” dans un format similaire à celui que vous avez envoyé, comprenant l’URL, l’état HTTP (l’état 200 est ce que vous voulez !), le type de fichier, la taille et le contenu souhaité. Vous devrez ensuite analyser cette réponse et la transformer en un cadre de données exploitable dans votre environnement R.\n\n\nPackages\nLe package httr fonctionne bien pour traiter les requêtes HTTP dans R. Il nécessite peu de connaissances préalables sur les API Web et peut être utilisé par des personnes moins familières avec la terminologie du développement logiciel. En outre, si la réponse HTTP est un fichier .json, vous pouvez utiliser jsonlite pour analyser la réponse.\n\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)\n\n\n\nDonnées disponibles au public\nVoici un exemple de requête HTTP, emprunté à un tutoriel du site the Trafford Data Lab. Ce site propose plusieurs autres ressources pour apprendre et des exercices API.\nScénario : Nous souhaitons importer une liste des établissements de restauration rapide de la ville de Trafford, au Royaume-Uni. Les données sont accessibles à partir de l’API de la Food Standards Agency, qui fournit des données sur l’évaluation de l’hygiène alimentaire au Royaume-Uni.\nVoici les paramètres de notre requête :\n\nVerbe HTTP: GET\n\nURL du point d’accès à l’API: http://api.ratings.food.gov.uk/Establishments\n\nParamètres sélectionnés: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityId\n\nEn-tête: “x-api-version”, 2\n\nFormat(s) des données: JSON, XML\n\nDocumentation: http://api.ratings.food.gov.uk/help\n\nLe code R serait le suivant:\n\n# préparer la requête\npath &lt;- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest &lt;- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# Vérifier s'il y a une erreur de serveur (\"200\" est bon !)\nrequest$status_code\n\n# soumettre la requête, analyser la réponse et la convertir en un cadre de données\nresponse &lt;- content(request, as = \"text\", encoding = \"UTF-8\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%\n  pluck(\"establishments\") %&gt;%\n  as_tibble()\n\nVous pouvez maintenant nettoyer et utiliser le cadre de données response, qui contient une ligne par établissement de restauration rapide.\n\n\nAuthentification requise\nCertaines API nécessitent une authentification, c’est-à-dire que vous devez prouver votre identité pour pouvoir accéder à des données restreintes. Pour importer ces données, vous devrez peut-être d’abord utiliser une méthode POST pour fournir un nom d’utilisateur, un mot de passe ou un code. Vous obtiendrez alors un jeton d’accès, qui pourra être utilisé pour les demandes ultérieures par la méthode GET afin de récupérer les données souhaitées.\nVous trouverez ci-dessous un exemple d’interrogation de données à partir de Go.Data, qui est un outil d’investigation des épidémies. Go.Data utilise une API pour toutes les interactions entre le frontal web et les applications pour smartphones utilisées pour la collecte des données. Go.Data est utilisé dans le monde entier. Comme les données sur les épidémies sont sensibles et que vous ne devez pouvoir accéder qu’aux données concernant votre épidémie, une authentification est requise.\nVous trouverez ci-dessous un exemple de code R utilisant httr et jsonlite pour se connecter à l’API Go.Data afin d’importer des données sur le suivi des contacts de votre épidémie.\n\n# définir les informations d'identification pour l'autorisation\nurl &lt;- \"https://godatasampleURL.int/\"           # url d'instance valide de Go.Data\nusername &lt;- \"username\"                          # nom d'utilisateur valide Go.Data \npassword &lt;- \"password\"                          # mot de passe Go,Data valide \noutbreak_id &lt;- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # identifiant d'épidémie Go.Data valide\n\n# obtenir le jeton d'accès\nurl_request &lt;- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# préparer la requête\nresponse &lt;- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # utiliser le nom d'utilisateur et le mot de passe enregistrés ci-dessus pour l'autorisation                              \n    password = password),                                       \n    encode = \"json\")\n\n# exécuter la demande et analyser la réponse\ncontent &lt;-\n  content(response, as = \"text\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%          # aplatir les JSON imbriqués\n  glimpse()\n\n# Sauvegarder le jeton d'accès de la réponse\naccess_token &lt;- content$access_token    # sauvegarder le jeton d'accès pour permettre les appels API suivants\n\n# importer les contacts de l'épidémie\n# Utiliser le jeton d'accès \nresponse_contacts &lt;- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # obtenir (GET) la requête\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts &lt;- content(response_contacts, as = \"text\")         # convertir en texte JSON\n\ncontacts &lt;- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # aplatir JSON en tibble\n\nATTENTION: Si vous importez de grandes quantités de données à partir d’une API nécessitant une authentification, il se peut que le délai d’attente soit dépassé. Pour éviter cela, récupérez à nouveau l’access_token avant chaque requête GET de l’API et essayez d’utiliser des filtres ou des limites dans la requête.\nTIP: La fonction fromJSON() du package jsonlite ne désimbrique pas complètement la première fois qu’elle est exécutée, donc vous aurez probablement encore des éléments de liste dans votre tibble résultant. Vous aurez besoin de désimbriquer davantage certaines variables, en fonction de l’imbrication de votre fichier .json. Pour plus d’informations à ce sujet, consultez la documentation du package jsonlite, notamment la fonction flatten(). {style=“color: darkgreen;”}\nPour plus de détails, consultez la documentation sur LoopBack Explorer, la page Suivi des contacts ou les astuces API sur Go.Data Github repository\nVous pouvez en savoir plus sur le package httr here\nCette section a aussi été informée par ce tutoriel et ce tutoriel.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#exporter",
    "href": "new_pages/importing.fr.html#exporter",
    "title": "7  Importer et exporter des données",
    "section": "7.11 Exporter",
    "text": "7.11 Exporter\n\nAvec le package rio\nAvec rio, vous pouvez utiliser la fonction export() de manière très similaire à import(). Donnez d’abord le nom de l’objet R que vous voulez sauvegarder (par exemple linelist) et ensuite entre guillemets mettez le chemin du fichier où vous voulez sauvegarder le fichier, en incluant le nom de fichier désiré et l’extension de fichier. Par exemple :\nCette opération permet de sauvegarder le cadre de données linelist comme un classeur Excel dans le répertoire de travail/ dossier racine du projet :\n\nexport(linelist, \"my_linelist.xlsx\") # will save to working directory\n\nVous pouvez enregistrer le même cadre de données comme un fichier csv en changeant l’extension. Par exemple, nous l’enregistrons également dans un chemin de fichier construit avec here() :\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))\n\n\n\nVers le presse-papiers\nPour exporter un cadre de données vers le “presse-papiers” de votre ordinateur (pour ensuite le coller dans un autre logiciel comme Excel, Google Spreadsheets, etc.) vous pouvez utiliser write_clip() du paquet clipr.\n\n# exporter le cadre de données de la liste de cas vers le presse-papiers de votre système\nclipr::write_clip(linelist)",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#import_rds",
    "href": "new_pages/importing.fr.html#import_rds",
    "title": "7  Importer et exporter des données",
    "section": "7.12 Documents RDS",
    "text": "7.12 Documents RDS\nOutre les fichiers .csv, .xlsx, etc., vous pouvez également exporter/enregistrer des cadres de données R sous forme de fichiers .rds. Il s’agit d’un format de fichier spécifique à R, très utile si vous savez que vous allez retravailler les données exportées dans R.\nLes classes de colonnes sont stockées, de sorte que vous n’avez pas à refaire le nettoyage lors de l’importation (avec un fichier Excel ou même un fichier CSV, cela peut être un casse-tête !) C’est aussi un fichier plus petit, ce qui est utile pour l’exportation et l’importation si votre ensemble de données est grand.\nPar exemple, si vous travaillez dans une équipe d’épidémiologie et que vous devez envoyer des fichiers à une équipe SIG pour la cartographie, et qu’ils utilisent également R, envoyez-leur simplement le fichier .rds ! Toutes les classes de colonnes sont alors conservées et ils ont moins de travail à faire.\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#import_rdata",
    "href": "new_pages/importing.fr.html#import_rdata",
    "title": "7  Importer et exporter des données",
    "section": "7.13 Fichiers Rdata et listes",
    "text": "7.13 Fichiers Rdata et listes\nLes fichiers .Rdata peuvent stocker plusieurs objets R - par exemple plusieurs cadres de données, des résultats de modèles, des listes, etc. Cela peut être très utile pour consolider ou partager un grand nombre de vos données pour un projet donné.\nDans l’exemple ci-dessous, plusieurs objets R sont stockés dans le fichier exporté “my_objects.Rdata”:\n\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\n\nNote : si vous essayez d’importer une liste, utilisez import_list() de rio pour l’importer avec la sTIPture et le contenu originaux complets.\n\nrio::import_list(\"my_list.Rdata\")",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#sauvegarde-des-graphiques",
    "href": "new_pages/importing.fr.html#sauvegarde-des-graphiques",
    "title": "7  Importer et exporter des données",
    "section": "7.14 Sauvegarde des graphiques",
    "text": "7.14 Sauvegarde des graphiques\nLes insTIPtions sur la façon de sauvegarder les tracés, tels que ceux créés par ggplot(), sont discutées en profondeur dans la page bases de ggplot.\nEn bref, lancez ggsave(\"my_plot_filepath_and_name.png\") après avoir imprimé votre tracé. Vous pouvez soit fournir un objet de tracé sauvegardé à l’argument plot =, ou seulement spécifier le chemin du fichier de destination (avec l’extension du fichier) pour sauvegarder le tracé le plus récemment affiché. Vous pouvez aussi contrôler le width =, height =, units =, et dpi =.\nL’enregistrement d’un graphe de réseau, tel qu’un arbre de transmission, est abordé dans la page Chaînes de transmission.",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.fr.html#ressources",
    "href": "new_pages/importing.fr.html#ressources",
    "title": "7  Importer et exporter des données",
    "section": "7.15 Ressources",
    "text": "7.15 Ressources\nLe Manuel pour Importer/Exporter\nChapitre sur l’importaiton de données de R 4 Data Science\nDocumation pour ggsave()\nVoici un tableau tiré de la vignette en ligne de rio. Pour chaque type de données, il indique : l’extension de fichier attendue, le package que rio utilise pour importer ou exporter les données, et si cette fonctionnalité est incluse dans la version installée par défaut de rio.\n\n\n\n\n\n\n\n\n\n\nFormat\nExtension Typique\nPackage d’Importation\nPackage d’Exportation\nInstallé par Defaut\n\n\n\n\nComma-separated data\n.csv\ndata.table fread()\ndata.table\nOui\n\n\nPipe-separated data\n.psv\ndata.table fread()\ndata.table\nOui\n\n\nTab-separated data\n.tsv\ndata.table fread()\ndata.table\nOui\n\n\nSAS\n.sas7bdat\nhaven\nhaven\nOui\n\n\nSPSS\n.sav\nhaven\nhaven\nOui\n\n\nStata\n.dta\nhaven\nhaven\nOui\n\n\nSAS\nXPORT\n.xpt\nhaven\nOui\n\n\nSPSS Portable\n.por\nhaven\n\nOui\n\n\nExcel\n.xls\nreadxl\n\nOui\n\n\nExcel\n.xlsx\nreadxl\nopenxlsx\nOui\n\n\nR syntax\n.R\nbase\nbase\nOui\n\n\nSaved R objects\n.RData, .rda\nbase\nbase\nOui\n\n\nSerialized R objects\n.rds\nbase\nbase\nOui\n\n\nEpiinfo\n.rec\nforeign\n\nOui\n\n\nMinitab\n.mtp\nforeign\n\nOui\n\n\nSystat\n.syd\nforeign\n\nOui\n\n\n“XBASE”\ndatabase files\n.dbf\nforeign\nOui\n\n\nWeka Attribute-Relation File Format\n.arff\nforeign\nforeign\nOui\n\n\nData Interchange Format\n.dif\nutils\n\nOui\n\n\nFortran data\npas d’extension reconnue\nutils\n\nOui\n\n\nFixed-width format data\n.fwf\nutils\nutils\nOui\n\n\ngzip comma-separated data\n.csv.gz\nutils\nutils\nOui\n\n\nCSVY (CSV + YAML metadata header)\n.csvy\ncsvy\ncsvy\nNon\n\n\nEViews\n.wf1\nhexView\n\nNon\n\n\nFeather R/Python interchange format\n.feather\nfeather\nfeather\nNon\n\n\nFast Storage\n.fst\nfst\nfst\nNon\n\n\nJSON\n.json\njsonlite\njsonlite\nNon\n\n\nMatlab\n.mat\nrmatio\nrmatio\nNon\n\n\nOpenDocument Spreadsheet\n.ods\nreadODS\nreadODS\nNon\n\n\nHTML Tables\n.html\nxml2\nxml2\nNon\n\n\nShallow XML documents\n.xml\nxml2\nxml2\nNon\n\n\nYAML\n.yml\nyaml\nyaml\nNon\n\n\nClipboard default is tsv\n\nclipr\nclipr\nNon",
    "crumbs": [
      "Les bases de R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importer et exporter des données</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html",
    "href": "new_pages/cleaning.fr.html",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "",
    "text": "Fonctions principales\nCe manuel met l’accent sur l’utilisation des fonctions provenant du package tidyverse, appartenant à la famille des packages de R. L’essentiel des fonctions de R présentées dans cette page sont listées ci-dessous.\nBeaucoup de ces fonctions appartiennent au package R dplyr, qui fournit des fonctions “verbes” pour résoudre les problèmes de manipulation des données (le nom fait référence à un “dataframe”- plier. dplyr fait partie de la famille de packages R tidyverse (qui qui consiste de ggplot2, tidyr, stringr, tibble, purrr, magrittr, et forcats entre autres).\nSi vous souhaitez comparer ces fonctions aux commandes de Stata ou de SAS, consultez la page Transition vers R.\nVous pouvez rencontrer une méthode alternative de gestion des données à partir du package R data.table avec des opérateurs comme := et l’utilisation fréquente de crochets [ ]. Cette approche et cette syntaxe sont brièvement expliquées dans la page Data Table.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#méthodologie-de-nettoyage",
    "href": "new_pages/cleaning.fr.html#méthodologie-de-nettoyage",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.1 Méthodologie de nettoyage",
    "text": "8.1 Méthodologie de nettoyage\nCette page passe en revue les étapes importantes du nettoyage, en les ajoutant séquentiellement à une “chaîne de nettoyage”.\nDans l’analyse épidémiologique et le traitement des données, les étapes de nettoyage sont souvent effectuées de manière séquentielle, reliées entre elles. En R, cela se manifeste souvent sous la forme d’un “pipeline” de nettoyage, où le jeu de données brutes est passé ou “pipé” d’une étape de nettoyage à une autre.\nDe telles chaînes utilisent les fonctions “verbes” de dplyr et l’opérateur pipe %&gt;% de magrittr. Ce pipe commence avec les données “brutes” (“linelist_raw.xlsx”) et se termine avec un dataframe “propre” (linelist) qui peut être utilisé, enregistré, exporté, etc.\nDans un pipeline de nettoyage, l’ordre des étapes est important. Les étapes de nettoyage peuvent inclure :\n\nImportation des données\n\nNettoyage ou modification des noms de colonnes\n\nDéduplication\n\nCréation et transformation de colonnes (par exemple, recodage ou normalisation des valeurs).\n\nSélection ou ajout de lignes",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#charger-les-packages",
    "href": "new_pages/cleaning.fr.html#charger-les-packages",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.2 Charger les packages",
    "text": "8.2 Charger les packages\nCes lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,        # importation données  \n  here,       # chemins d'accès relatifs aux fichiers  \n  janitor,    # nettoyage des données et tables\n  lubridate,  # manipuler les dates\n  epikit,     # age_categories() fonction\n  matchmaker, # nettoyage basé sur un dictionnaire\n  tidyverse   # manipulation et visualisation  des donnees \n)",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#import-data",
    "href": "new_pages/cleaning.fr.html#import-data",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.3 Import data",
    "text": "8.3 Import data\n\nImport\nIci, nous importons le fichier Excel “brut” de cas linelist en utilisant la fonction import() du package rio. Cet dernier gère de manière flexible de nombreux types de fichiers (par exemple, .xlsx, .csv, .tsv, .rds). Importation et exportation des données pour plus d’informations et des conseils sur les situations inhabituelles (par exemple, sauter des lignes, définir des valeurs manquantes, importer des feuilles Google, etc.)\nPour reproduire les étapes, cliquer pour télécharger le jeu de données “brutes” linelist (comme fichier .xlsx).\nSi votre jeu de données est important et prend beaucoup de temps à s’importer, il peut valloir le coup de séparer la commande d’importation des étapes de nettoyage, pour que que la donnée “brute” soit enregistré dans un dataframe distinct. Cela permet également de comparer facilement les versions originales et nettoyées.\nCi-dessous, nous importons le fichier Excel brut et le sauvegardons dans le dataframe linelist_raw. Nous supposons que le fichier est situé dans votre répertoire de travail ou à la racine de votre projet R, et donc aucun sous-dossier n’est spécifié dans le chemin du fichier.\n\nlinelist_raw &lt;- import(\"linelist.xlsx\")\n\nVous pouvez visualiser les 50 premières lignes du dataframe ci-dessous. Remarque : la fonction de base de R head(n) vous permet de visualiser uniquement les n premières lignes dans la console R.\n\n\n\n\n\n\n\n\nVue d’ensemble\nVous pouvez utiliser la fonction skim() du package skimr pour obtenir une vue d’ensemble du dataframe (voir la page sur les Tableaux descriptifs pour plus d’informations). Les colonnes sont résumées par classe/type, telles que “chaîne de caractère”, “numérique”… Note : “POSIXct” est un type de classe de date brute (voir Working with dates).\n\nskimr::skim(linelist_raw)\n\n\n\n\nData summary\n\n\nName\nlinelist_raw\n\n\nNumber of rows\n6611\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n17\n\n\nnumeric\n8\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n137\n0.98\n6\n6\n0\n5888\n0\n\n\ndate onset\n293\n0.96\n10\n10\n0\n580\n0\n\n\noutcome\n1500\n0.77\n5\n7\n0\n2\n0\n\n\ngender\n324\n0.95\n1\n1\n0\n2\n0\n\n\nhospital\n1512\n0.77\n5\n36\n0\n13\n0\n\n\ninfector\n2323\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2323\n0.65\n5\n7\n0\n2\n0\n\n\nage\n107\n0.98\n1\n2\n0\n75\n0\n\n\nage_unit\n7\n1.00\n5\n6\n0\n2\n0\n\n\nfever\n258\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n258\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n258\n0.96\n2\n3\n0\n2\n0\n\n\naches\n258\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n258\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n844\n0.87\n5\n5\n0\n1091\n0\n\n\nmerged_header\n0\n1.00\n1\n1\n0\n1\n0\n\n\n…28\n0\n1.00\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n7\n1.00\n16.60\n5.71\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nlon\n7\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n7\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nrow_num\n0\n1.00\n3240.91\n1857.83\n1.00\n1647.50\n3241.00\n4836.50\n6481.00\n\n\nwt_kg\n7\n1.00\n52.69\n18.59\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n7\n1.00\n125.25\n49.57\n4.00\n91.00\n130.00\n159.00\n295.00\n\n\nct_blood\n7\n1.00\n21.26\n1.67\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n158\n0.98\n38.60\n0.95\n35.20\n38.30\n38.80\n39.20\n40.80\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ninfection date\n2322\n0.65\n2012-04-09\n2015-04-27\n2014-10-04\n538\n\n\nhosp date\n7\n1.00\n2012-04-20\n2015-04-30\n2014-10-15\n570\n\n\ndate_of_outcome\n1068\n0.84\n2012-05-14\n2015-06-04\n2014-10-26\n575",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#noms-de-colonnes",
    "href": "new_pages/cleaning.fr.html#noms-de-colonnes",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.4 Noms de colonnes",
    "text": "8.4 Noms de colonnes\nEn R, les noms de colonnes sont la valeur “d’en-tête” ou la “première cellule” d’une colonne. Ils sont utilisés pour faire référence aux colonnes dans le code et servent de labels par défaut dans les figures.\nD’autres logiciels statistiques tels que SAS et STATA utilisent des “labels” qui représentent un format plus long et détaillé des noms de colonnes plus courts existants. Bien que R offre la possibilité d’ajouter des étiquettes de colonne aux données, cela n’est pas mis en avant en pratique. Pour rendre les noms de colonne explicites et descriptifs pour les figures, on ajuste généralement leur affichage dans les commandes de qui créent les graphiques (par exemple, les titres des axes ou des légendes d’une graphique, ou les en-têtes de colonne dans un tableau imprimé - voir la section section échelles de la page Astuces de ggplot et les pages Tableaux pour la présentation). Si vous souhaitez attribuer des étiquettes de colonne dans les données, lisez la suite en ligne ici et ici.\nComme les noms de colonnes sur R sont utilisés très souvent, ils doivent avoir une syntaxe “propre”. Nous suggérons ce qui suit :\n\nNoms courts\n\nPas d’espaces (remplacez-les par des traits de soulignement _ )\n\nPas de caractères inhabituels (&, #, &lt;, &gt;, …)\n\nNomenclature homogène (par exemple, toutes les colonnes de date nommées comme date_apparition, date_rapport, date_mort…)\n\nLes noms des colonnes de linelist_raw sont affichés ci-dessous en utilisant la fonction names() de base R. On peut voir qu’initialement :\n\nCertains noms contiennent des espaces (par exemple date d'infection)\n\nDes motifs de noms différents sont utilisés pour les dates (date onset vs. infection date).\n\nIl doit y avoir un même nom attribué pour les deux dernières colonnes du fichier .xlsx. Nous le savons parce que le nom de deux colonnes fusionnées (“merged_header”) a été attribué par R à la première colonne, et que la deuxième colonne s’est vue attribuer un nom fictif “…28” (puisqu’elle était alors vide et qu’il s’agit de la 28ième colonne).\n\n\nnames(linelist_raw)\n\n [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\"          \n\n\nREMARQUE: Pour faire référence à un nom de colonne qui comprend des espaces, entourez le nom de contre-tirets, par exemple : linelist$`'\\x60infection date\\x60'`. Notez que sur votre clavier, le contre-tiret (`) est différent du guillemet simple (’).\n\nLabels\nD’autres logiciels statistiques tels que SAS ont des labels de variables.\n\n\nNettoyage automatique\nLa fonction clean_names() du package janitor normalise les noms de colonnes et les rend uniques en effectuant les opérations suivantes :\n\nConvertit tous les noms pour qu’ils ne soient composés que de underscores (sous-tiret/tiret “bas”/tiret 8), de chiffres et de lettres.\n\nLes caractères accentués sont translittérés en ASCII (par exemple, le o allemand avec tréma devient “o”, le “enye” espagnol devient “n”).\n\nLa préférence de capitalisation pour les nouveaux noms de colonnes peut être spécifiée en utilisant l’argument case = (“snake” est le défaut, les alternatives incluent “phrase”, “title”, “small_camel”…)\n\nVous pouvez spécifier des remplacements de noms spécifiques en fournissant un vecteur à l’argument replace = (par exemple, replace = c(onset = \"date_of_onset\"))\n\nPour en savoir plus, voici la vignette en ligne. .\nCi-dessous, le pipeline de nettoyage commence par utiliser clean_names() sur le dataframe contenant les données brutes.\n\n# pipe le jeu de données brutes à travers clean_names(), puis assigne le resultat à un nouveau dataframe, \"linelist\"  \nlinelist &lt;- linelist_raw %&gt;% \n  janitor::clean_names()\n\n# voir les nouveaux noms de colonnes\nnames(linelist)\n\n [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\"            \n\n\nNOTE: le dernier nom de colonne “…28” est changé pour devenir “x28”.\n\n\nNettoyage manuel des noms\nIl est souvent nécessaire de renommer les colonnes manuellement, même après l’étape de normalisation ci-dessus. Ci-dessous, le changement de nom est effectué en utilisant la fonction rename() du package dplyr, dans une chaine de commandes pipées. rename() utilise le style NEW = OLD - le nouveau nom de colonne est donné avant l’ancien nom de colonne.\nCi-dessous, une commande de re-nommage est ajoutée au pipeline de nettoyage. Des espaces ont été ajoutés stratégiquement pour aligner le code afin de faciliter la lecture.\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et suivi de  pipes avec les commandes pour le nettoyage)\n##################################################################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardiser la syntaxe des noms de colonnes \n    janitor::clean_names() %&gt;% \n    \n    # renommer manuellement les noms de colonnes\n           # Nouveau noms             # Ancien noms\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)\n\nVous pouvez maintenant voir que les noms des colonnes ont été modifiés :\n\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nRenommer par la position des colonnes\nVous pouvez également renommer par position de colonne, au lieu du nom de colonne, par exemple :\n\n#rename(newNameForFirstColumn  = 1,\n       #newNameForSecondColumn = 2)\n\n\n\nRenommer via select() et summarise()\nComme raccourci, vous pouvez aussi renommer les colonnes dans les fonctions dplyr select() et summarise(). select() est utilisé pour ne garder que certaines colonnes (et est couvert plus loin dans cette page). La fonction summarise() est traitée dans les pages Regroupement des données et Tableaux descriptifs. Ces fonctions utilisent également le format nouveau_nom = ancien_nom. Voici un exemple :\n\nlinelist_raw %&gt;% \n  select(# NOUVEAU nom             # ANCIEN nom\n         date_infection       = `infection date`,    # renommer and CONSEVER  que  ces colonnes\n         date_hospitalisation = `hosp date`)\n\n\n\n\nAutres challenges\n\nfichiers excels sans noms de colonnes\nR ne peut pas travailler sur des jeux de données qui n’ont pas de noms de colonne (en-têtes). Ainsi, si vous importez un jeu de données Excel contenant des données mais pas d’en-tête de colonne, R remplira les en-têtes avec des noms tels que “…1” ou “…2”. Le chiffre représente le numéro de la colonne (par exemple, si la quatrième colonne de l’ensemble de données n’a pas d’en-tête, R la nommera “…4”).\nVous pouvez nettoyer ces noms manuellement en faisant référence à leur numéro de position (voir l’exemple ci-dessus), ou au nom qui leur est attribué (linelist_raw$...1).\n\n\nFusion des noms de colonnes et de cellules sur Excel\nLa fusion de cellules dans un fichier Excel est un phénomène courant lors de la réception de données. Comme expliqué dans Transition vers R, les cellules fusionnées peuvent être agréables pour la lecture humaine des données, mais ne sont pas des “tidy data” et posent de nombreux problèmes pour la lecture automatique des données. R ne peut pas prendre en compte les cellules fusionnées.\nRappelez aux personnes chargées de la saisie des données que les données lisibles par l’homme ne sont pas les mêmes que celles lisibles par la machine. Efforcez-vous de former les utilisateurs aux principes des [Tidy Data] (https://r4ds.had.co.nz/tidy-data.html). Dans la mesure du possible, essayez de modifier les procédures pour que les données arrivent dans un format tidy, sans cellules fusionnées.\n\nChaque variable doit avoir sa propre colonne.\n\nChaque observation doit avoir sa propre ligne.\n\nChaque valeur doit avoir sa propre cellule.\n\nLorsque vous utilisez la fonction import() de rio, la valeur d’une cellule fusionnée sera assignée à la première cellule et les cellules suivantes seront vides.\nUne solution pour gérer les cellules fusionnées est d’importer les données avec la fonction readWorkbook() du package openxlsx. Définissez l’argument fillMergedCells = TRUE. Cela donne la valeur d’une cellule fusionnée à toutes les cellules de la plage de fusion.\n\nlinelist_raw &lt;- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)\n\nDANGERS: Si les noms de colonnes sont fusionnés avec readWorkbook(), vous vous retrouverez avec des noms de colonnes en double, que vous devrez corriger manuellement - R ne fonctionne pas bien avec des noms de colonnes en double ! Vous pouvez les renommer en faisant référence à leur position (par exemple colonne 5), comme expliqué dans la section sur le nettoyage manuel des noms de colonnes.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#sélectionner-ou-réorganiser-les-colonnes",
    "href": "new_pages/cleaning.fr.html#sélectionner-ou-réorganiser-les-colonnes",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.5 Sélectionner ou réorganiser les colonnes",
    "text": "8.5 Sélectionner ou réorganiser les colonnes\nUtilisez select() de dplyr pour sélectionner les colonnes que vous voulez conserver, et pour spécifier leur ordre dans le cadre de données.\nAvertissement: Dans les exemples ci-dessous, le dataframe linelist est modifié avec select() et affiché, mais pas enregistré. Ceci est pour les besoins de la démonstration. Les noms de colonnes modifiés sont renvoyés en passant (pipe)le dataframe dans names().\nVoici TOUS les noms de colonnes dans la liste de lignes à ce stade de la chaîne de nettoyage :.\n\nnames(linelist)\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nConserver des colonnes\nSelectionner uniquement les colonnes que vous voulez conserver\nMettez leurs noms dans la commande select(), sans guillemets. Elles apparaîtront dans le dataframe dans l’ordre que vous avez indiqué. Notez que si vous incluez une colonne qui n’existe pas, R retournera une erreur (voir l’utilisation de any_of() ci-dessous si vous ne voulez pas d’erreur dans cette situation).\n\n# jeu de donnée linelist est pipé  à travers la commande select() et names() affiche les noms de colones\nlinelist %&gt;% \n  select(case_id, date_onset, date_hospitalisation, fever) %&gt;% \n  names()  # affiche le nom des colonnes\n\n[1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n[4] \"fever\"               \n\n\n\n\nfonction d’aide “tidyselect”\nCes fonctions d’aide existent pour faciliter la spécification des colonnes à conserver, à éliminer ou à transformer. Elles sont issues du package tidyselect, qui est inclus dans tidyverse et qui sous-tend la façon dont les colonnes sont sélectionnées dans les fonctions dplyr.\nPar exemple, si vous voulez réordonner les colonnes, everything() est une fonction utile qui correspond à “toutes les autres colonnes non encore mentionnées”. La commande ci-dessous déplace les colonnes date_onset et date_hospitalisation au début (à gauche) du jeu de donnée, mais conserve toutes les autres colonnes par la suite. Notez que everything() est écrit avec des parenthèses vides :\n\n# deplacer les colonnes data_onset et date_hospilisation au debut du jeu de donnée\nlinelist %&gt;% \n  select(date_onset, date_hospitalisation, everything()) %&gt;% \n  names()\n\n [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\nVoici d’autres fonctions d’aide “tidyselect” qui fonctionnent également dans les fonctions dplyr comme select(), across(), et summarise() :\n\neverything() - toutes les autres colonnes non mentionnées\n\nlast_col() - la dernière colonne\n\nwhere() - applique une fonction à toutes les colonnes et sélectionne celles qui sont VRAIES.\n\ncontains() - colonnes contenant une chaîne de caractères.\n\nExemple : select(contains(\"time\")).\n\n\nstarts_with() - correspond à un préfixe spécifié.\n\nExemple : select(starts_with(\"date_\")).\n\n\nends_with() - correspond à un suffixe spécifié.\n\nexemple : select(ends_with(\"_post\"))\n\n\nmatches() - pour appliquer une expression régulière (regex)\n\nexemple : select(matches(\"[pt]al\"))\n\n\nnum_range() - une plage numérique comme x01, x02, x03\n\nany_of() - correspond si la colonne existe mais ne renvoie pas d’erreur si elle n’est pas trouvée.\n\nExemple : select(any_of(date_onset, date_death, cardiac_arrest)).\n\n\nDe plus, utilisez des opérateurs normaux tels que c() pour lister plusieurs colonnes, : pour des colonnes consécutives, ! pour l’opposé, & pour AND, et | pour OR.\nUtilisez where() pour spécifier des critères logiques pour les colonnes. Si vous fournissez une fonction dans where(), n’incluez pas les parenthèses vides de la fonction. La commande ci-dessous sélectionne les colonnes de la classe Numeric.\n\n# selectionner les colonnes de classe Numeric\nlinelist %&gt;% \n  select(where(is.numeric)) %&gt;% \n  names()\n\n[1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"     \n[6] \"ht_cm\"      \"ct_blood\"   \"temp\"      \n\n\nUtilisez contains() pour ne sélectionner que les colonnes dont le nom contient une chaîne de caractères donnée. ends_with() et starts_with() apportent plus de nuances.\n\n# Selectionner des colonnes qui contiennent une caractere defini\nlinelist %&gt;% \n  select(contains(\"date\")) %&gt;% \n  names()\n\n[1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n[4] \"date_outcome\"        \n\n\nLa fonction matches() fonctionne de la même manière que contains() mais on peut lui fournir une expression régulière (voir la page sur les Caractères et chaînes de caractères), comme plusieurs chaînes de caractères séparées par des barres OR à l’intérieur des parenthèses :\n\n# searched for multiple character matches\n#  rechercher plusieurs caracteres \nlinelist %&gt;% \n  select(matches(\"onset|hosp|fev\")) %&gt;%   # noter le symbole de OR  \"|\"\n  names()\n\n[1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n[4] \"fever\"               \n\n\nAVERTISSEMENT: Si un nom de colonne que vous fournissez spécifiquement n’existe pas dans les données, il peut retourner une erreur et arrêter votre code. Pensez à utiliser any_of() pour citer des colonnes qui peuvent ou non exister, particulièrement utile dans les sélections négatives (enlever).\nUne seule de ces colonnes existe, mais aucune erreur n’est produite et le code continue sans arrêter votre chaîne de nettoyage.\n\nlinelist %&gt;% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %&gt;% \n  names()\n\n[1] \"date_onset\"\n\n\n\n\nSupprimer colonnes\nIndiquez les colonnes à supprimer en plaçant un symbole moins “-” devant le nom de la colonne (par exemple, select(-outcome)), ou un vecteur de noms de colonnes (comme ci-dessous). Toutes les autres colonnes seront conservées.\n\nlinelist %&gt;% \n  select(-c(date_onset, fever:vomit)) %&gt;% #supprimer la colonne date_onset et tout les colonnes allant de fever à vomit\n  names()\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n [7] \"gender\"               \"hospital\"             \"lon\"                 \n[10] \"lat\"                  \"infector\"             \"source\"              \n[13] \"age\"                  \"age_unit\"             \"row_num\"             \n[16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n[19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[22] \"x28\"                 \n\n\nVous pouvez également supprimer une colonne en utilisant la syntaxe R base, en la définissant comme NULL. Par exemple :\n\nlinelist$date_onset &lt;- NULL   \n# supprimer colonne avec la syntaxe native de R\n\n\n\nAutres\nselect() peut aussi être utilisé comme une commande indépendante (pas dans une chaîne de tuyaux). Dans ce cas, le premier argument est le dataframe original sur lequel on veut travailler.\n\n# creer un nouvelle donnée linelist avec des colonnes  id et age-related\nlinelist_age &lt;- select(linelist, case_id, contains(\"age\"))\n\n# afficher les noms de colonnes\nnames(linelist_age)\n\n[1] \"case_id\"  \"age\"      \"age_unit\"\n\n\n\najouter à la chaine de commande pipé\nDans la linelist_raw, il y a quelques colonnes dont nous n’avons pas besoin : row_num, merged_header, et x28. Nous les supprimons avec une commande select() dans la chaîne de nettoyage :\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipes avec les commandes pour le nettoyage)\n##################################################################################\n\n\n# Debuter le processus de Nettoyage pipé \n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n     # standardiser le syntaxe des noms de colonnes\n    janitor::clean_names() %&gt;% \n    \n    \n     # renommer manuellement les colonnes\n           # NOUVEAU nom            # ANCIEN nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    \n     # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT \n    #####################################################\n\n    # supprimer des colonnes\n    select(-c(row_num, merged_header, x28))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#deduplication",
    "href": "new_pages/cleaning.fr.html#deduplication",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.6 Deduplication",
    "text": "8.6 Deduplication\nVoir la page du manuel sur la déduplication pour de nombreuses options sur la façon de dédupliquer les données. Seul un exemple très simple de déduplication de lignes est présenté ici.\nLe package dplyr offre la fonction distinct(). Cette fonction examine chaque ligne et réduit le dataframe à seulement les lignes uniques. C’est-à-dire qu’elle supprime les lignes qui sont à 100% des doublons.\nLors de l’évaluation des lignes dupliquées, elle prend en compte un eventail de colonnes defini - par défaut, elle considère toutes les colonnes. Comme le montre la page dediée à la déduplication, vous pouvez ajuster cet eventail de colonnes afin que l’unicité des lignes ne soit évaluée que par rapport à certaines colonnes.\nDans cet exemple simple, nous ajoutons simplement la commande vide distinct() à la chaîne de commande pipé. Cela permet de s’assurer qu’il n’y a pas de lignes qui sont des doublons à 100% d’autres lignes (évaluées sur toutes les colonnes).\nNous commençons avec nrow(linelist) lignes dans linelist.\n\nlinelist &lt;- linelist %&gt;% \n  distinct()\n\nAprès la déduplication, il y a nrow(linelist) lignes. Toutes les lignes supprimées auraient été des doublons à 100% d’autres lignes.\nCi-dessous, la commande distinct() est ajoutée à la chaîne de nettoyage :\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipe avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le processus de Nettoyage pipé \n\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardiser le syntaxe des noms de colonnes\n    janitor::clean_names() %&gt;% \n    \n    # Renommer manuellement les noms de colonnes\n           # Nouveau nom             # Ancien nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # supprimer les colonnes\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT \n    #####################################################\n    \n    # Supprimer les doublons\n    distinct()",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#creation-et-transformation-de-colonne",
    "href": "new_pages/cleaning.fr.html#creation-et-transformation-de-colonne",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.7 Creation et transformation de colonne",
    "text": "8.7 Creation et transformation de colonne\nNous recommandons d’utiliser la fonction mutate() du package dplyr pour ajouter une nouvelle colonne, ou pour modifier une colonne existante.\nVous trouverez ci-dessous un exemple de création d’une nouvelle colonne avec mutate(). La syntaxe est la suivante : mutate(nouveau_nom_de_colonne = valeur ou transformation).\nDans Stata, ceci est similaire à la commande generate, mais la fonction mutate() de R peut également être utilisée pour modifier une colonne existante.\n\nNouvelles colonnes\nLa commande mutate() la plus basique pour créer une nouvelle colonne peut ressembler à ceci. Elle crée une nouvelle colonne new_col dont la valeur dans chaque ligne est 10.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(new_col = 10)\n\nVous pouvez également référencer des valeurs dans d’autres colonnes, pour effectuer des calculs. Ci-dessous, une nouvelle colonne bmi est créée pour contenir l’indice de masse corporelle (IMC) pour chaque cas - tel que calculé en utilisant la formule IMC = kg/m^2, en utilisant la colonne ht_cm et la colonne wt_kg.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\nSi vous créez plusieurs nouvelles colonnes, séparez-les par une virgule et une nouvelle ligne. Vous trouverez ci-dessous des exemples de nouvelles colonnes, y compris celles qui sont constituées de valeurs provenant d’autres colonnes combinées à l’aide de str_glue() du package stringr (voir la page sur Caractères et chaînes de caractères.\n\nnew_col_demo &lt;- linelist %&gt;%                       \n  mutate(\n    new_var_dup    = case_id,             \n    # nouveau colonne= dupliquer ou copier une autre colonne existante\n    new_var_static = 7,                   # nouveau colonne = meme valeur sur toute les lignes\n    new_var_static = new_var_static + 5,  \n    # On peut ecraser une colonne et le recreer par un calcul  utilisant d'autres variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # nouveau colonne = pasting together values from other columns\n    # regrouper les valeurs de differentes  colonnes\n    ) %&gt;% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        \n# montrer seulement les nouveaux colonnes  pour besoin de demonstration\n\nExaminez les nouvelles colonnes. À des fins de démonstration, seules les nouvelles colonnes et les colonnes utilisées pour les créer sont affichées :\n\n\n\n\n\n\nCONSEILS: Une variante de mutate() est la fonction transmute(). Cette fonction ajoute une nouvelle colonne comme mutate(), mais supprime également toutes les autres colonnes que vous ne mentionnez pas entre ses parenthèses..\n\n# CACHER POUR LECTEUR\n# Supprimer les nouveaux colonnes demo créees en haut\n# linelist &lt;- linelist %&gt;% \n#   select(-contains(\"new_var\"))\n\n\n\nConvertir la classe des colonnes\nLes colonnes contenant des valeurs qui sont des dates, des nombres ou des valeurs logiques (VRAI/FAUX) ne se comporteront comme prévu que si elles sont dans la classe appropriée. Il y a une différence entre “2” de classe caractère et 2 de classe numérique !\nIl existe des moyens de définir la classe des colonnes avec les commandes d’importation, mais cela est souvent fastidieux. Consultez la section Bases de R sur les classes d’objets pour en savoir plus sur la conversion de la classe des objets et des colonnes.\nTout d’abord, effectuons quelques vérifications sur les colonnes importantes pour voir si elles sont de la bonne classe. Nous avons également vu cela au début lorsque nous avons lancé skim().\nActuellement, la classe de la colonne age est un caractère. Pour effectuer des analyses quantitatives, nous avons besoin que ces nombres soient reconnus comme numériques !\n\nclass(linelist$age)\n\n[1] \"character\"\n\n\nLa classe de la colonne date_onset est aussi un caractère ! Pour effectuer des analyses, ces dates doivent être reconnues comme des dates!\n\nclass(linelist$date_onset)\n\n[1] \"character\"\n\n\nPour résoudre ce problème, utilisez la capacité de mutate() pour redéfinir une colonne avec une transformation. Nous définissons la colonne comme elle-même, mais convertie en une classe différente. Voici un exemple de base, convertissons ou assurerons nous que la colonne age est de classe Numeric :\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age = as.numeric(age))\n\nDe la même manière, vous pouvez utiliser as.character() et as.logical(). Pour convertir en classe Factor, vous pouvez utiliser factor() de base R ou as_factor() de forcats. Pour en savoir plus, consultez la page Facteurs.\nVous devez faire attention lorsque vous convertissez en classe Date. Plusieurs méthodes sont expliquées sur la page Manipuler les dates. En général, les valeurs brutes de la date doivent toutes être dans le même format pour que la conversion fonctionne correctement (par exemple “MM/JJ/AAAA”, ou “JJ MM AAAA”). Après la conversion en classe Date, vérifiez vos données pour confirmer que chaque valeur a été convertie correctement.\n\n\nDonnées groupées\nSi votre dataframe est déjà groupée (voir la page sur Travailler sur des données groupées), mutate() peut se comporter différemment que si la base de données n’est pas groupée. Toutes les fonctions de résumé, comme mean(), median(), max(), etc. seront calculées par groupe, et non par toutes les lignes.\n\n# Normalisation de l'age en fonction la moyenne\nlinelist %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n\n# Normalisation de l'age en fonction de la moyenne du jeu donne groupe  à partir de la colonne hospital\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\nPour en savoir plus sur l’utilisation de mutate () sur des blocs de données groupés, consultez la documentation tidyverse mutate.\n\n\nTransformer plusieurs colonnes\nSouvent, pour écrire un code concis, vous voulez appliquer la même transformation à plusieurs colonnes à la fois. Une transformation peut être appliquée à plusieurs colonnes à la fois en utilisant la fonction across() du package dplyr (également contenu dans le package tidyverse). across() peut être utilisé avec n’importe quelle fonction dplyr, mais est couramment utilisé dans select(), mutate(), filter(), ou summarise(). Voir comment il est appliqué à summarise() dans la page sur les Tableaux descriptifs.\nSpécifiez les colonnes à l’argument .cols = et la ou les fonctions à appliquer à .fns =. Tout argument supplémentaire à fournir à la fonction .fns peut être inclus après une virgule, toujours dans across().\n\nacross() selection de colonne\nSpécifiez les colonnes à l’argument .cols =. Vous pouvez les nommer individuellement, ou utiliser les fonctions d’aide “tidyselect”. Spécifiez la fonction en argument .fns =. Notez qu’en utilisant le mode fonction démontré ci-dessous, la fonction est écrite sans ses parenthèses ( ).\nIci, la transformation as.character() est appliquée à des colonnes spécifiques nommées dans across().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n\nLes fonctions d’aide “tidyselect” sont disponibles pour vous aider à spécifier les colonnes. Elles sont détaillées ci-dessus dans la section sur la sélection et le réordonnancement des colonnes, et elles incluent : everything(), last_col(), where(), starts_with(), ends_with(), contains(), matches(), num_range() et any_of().\nVoici un exemple de la façon dont on peut changer toutes les colonnes en classe de caractères :\n\n# Changer toutes les colonnes en classe caractère\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = everything(), .fns = as.character))\n\nConvertissez en caractères toutes les colonnes dont le nom contient la chaîne “date” (notez le placement des virgules et des parenthèses) :\n\n# Changer toutes les colonnes en classe caractère\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\n\nCi-dessous, un exemple de mutation des colonnes qui sont actuellement de classe POSIXct (une classe de date brute qui montre les timestamps) - en d’autres termes, où la fonction is.POSIXct() évalue à TRUE. Ensuite, nous voulons appliquer la fonction as.Date() à ces colonnes pour les convertir en une classe normale de Date.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))\n\n\nNotez que dans across(), nous utilisons également la fonction where() car is.POSIXct est évalué à TRUE ou FALSE.\n\nNotez que is.POSIXct() fait partie du paquet lubridate. D’autres fonctions “is” similaires comme is.character(), is.numeric(), et is.logical() sont issues de base R.\n\n\n\nfonction across()\nVous pouvez lire la documentation avec ?across pour des détails sur la façon de fournir des fonctions à across(). Quelques points récapitulatifs : il y a plusieurs façons de spécifier la ou les fonctions à exécuter sur une colonne et vous pouvez même définir vos propres fonctions :\n\nVous pouvez fournir le nom de la fonction seul (par exemple mean ou as.character)\n\nVous pouvez fournir la fonction dans le style purrr (par exemple ~ mean(.x, na.rm = TRUE)) (voir [cette page][#iteration])\n\nVous pouvez spécifier plusieurs fonctions en fournissant une liste (par exemple, list(mean = mean, n_miss = ~ sum(is.na(.x))).\n\nSi vous fournissez plusieurs fonctions, plusieurs colonnes transformées seront retournées par colonne d’entrée, avec des noms uniques dans le format col_fn. Vous pouvez ajuster la façon dont les nouvelles colonnes sont nommées avec l’argument .names = en utilisant la syntaxe glue (voir la page sur Caractères et chaînes de caractères) où {.col} et {.fn} sont des raccourcis pour la colonne d’entrée et la fonction.\n\n\nVoici quelques ressources en ligne sur l’utilisation de across() : creator Hadley Wickham’s thoughts/rationale\n\n\n\ncoalesce()\nCette fonction dplyr trouve la première valeur non manquante à chaque position. Elle “remplit” les valeurs manquantes avec la première valeur disponible dans l’ordre que vous spécifiez.\nVoici un exemple En dehors du contexte de dataframe : Disons que vous avez deux vecteurs, l’un contenant le village de détection du patient et l’autre contenant le village de résidence du patient. Vous pouvez utiliser coalesce pour choisir la première valeur non manquante pour chaque indice :\n\nvillage_detection &lt;- c(\"a\", \"b\", NA,  NA)\nvillage_residence &lt;- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage &lt;- coalesce(village_detection, village_residence)\nvillage    # print\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\nCela fonctionne de la même manière si vous fournissez des colonnes de cadre de données : pour chaque ligne, la fonction attribuera la nouvelle valeur de la colonne avec la première valeur non manquante dans les colonnes que vous avez fournies (dans l’ordre fourni).\n\nlinelist &lt;- linelist %&gt;% \n  mutate(village = coalesce(village_detection, village_residence))\n\nIl s’agit d’un exemple d’opération “ligne par ligne”. Pour des calculs par rangée plus complexes, voir la section ci-dessous sur les calculs par rangée.\n\n\nmathématique cumulative\nSi vous voulez qu’une colonne reflète somme/moy/min/max cumulée etc. pour les differntes observations du dataframe, utilisez les fonctions suivantes :\ncumsum() renvoie la somme cumulée, comme indiqué ci-dessous :\n\nsum(c(2,4,15,10))     # retourne un nombre unique\n\n[1] 31\n\ncumsum(c(2,4,15,10))  # renvoie la somme cumulé a chaque élémenet parcouru du vecteur \n\n[1]  2  6 21 31\n\n\nCeci peut être utilisé dans un dataframe lors de la création d’une nouvelle colonne. Par exemple, pour calculer le nombre cumulé de cas par jour dans une épidémie, envisagez un code comme celui-ci :\n\ncumulative_case_counts &lt;- linelist %&gt;%  # Commencons avec la donnne linelist \n  count(date_onset) %&gt;%                 # Creons une colonne 'n' qui totalise le nombre de ligne par jour   \n  mutate(cumulative_cases = cumsum(n))  #  nouveau colonne representant la somme cumulée par ligne\n\nVoici les 10 premières rangées :\n\nhead(cumulative_case_counts, 10)\n\n   date_onset n cumulative_cases\n1  2012-04-15 1                1\n2  2012-05-05 1                2\n3  2012-05-08 1                3\n4  2012-05-31 1                4\n5  2012-06-02 1                5\n6  2012-06-07 1                6\n7  2012-06-14 1                7\n8  2012-06-21 1                8\n9  2012-06-24 1                9\n10 2012-06-25 1               10\n\n\nVoir la page sur les [Courbes épidémiques] pour savoir comment tracer l’incidence cumulée avec l’épicurve.\nVoir aussi :\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall().\n\n\nUtiliser les fonctions base de R\nPour définir une nouvelle colonne (ou redéfinir une colonne) en utilisant base R, écrivez le nom du cadre de données, relié par $, à la nouvelle colonne (ou à la colonne à modifier). Utilisez l’opérateur d’affectation &lt;- pour définir la ou les nouvelles valeurs. N’oubliez pas que lorsque vous utilisez base R, vous devez à chaque fois spécifier le nom du dataframe avant le nom de la colonne (par exemple, dataframe$column). Voici un exemple de création de la colonne bmi en utilisant base R :\n\nlinelist$bmi = linelist$wt_kg / \n     (linelist$ht_cm /100) ^ 2\n\n\n\nAjouter à la chaine de commande pipé\nAu-dessous, une nouvelle colonne est ajoutée à la chaîne de tuyaux et certaines classes sont converties.\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipes avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le processus de Nettoyage pipé\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardiser le syntaxe des noms de colonnes\n    janitor::clean_names() %&gt;% \n    \n    # renommer manuellement les noms de colonnes\n           # Nouveau nom             # ANCIEN nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # supprimer colonne\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # supprimer les doublons\n    distinct() %&gt;% \n  \n    \n    # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT \n    ###################################################\n    # ajouter un nouveau colonne\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;% \n  \n    # convertir les classes des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#re-coder-les-valeurs",
    "href": "new_pages/cleaning.fr.html#re-coder-les-valeurs",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.8 Re-coder les valeurs",
    "text": "8.8 Re-coder les valeurs\nVoici quelques situations dans lesquelles vous devez recoder (modifier) des valeurs :\n\npour modifier une valeur spécifique (par exemple, une date dont l’année ou le format est incorrect)\n\npour uniformiser des valeurs dont l’orthographe n’est pas la même\npour créer une nouvelle colonne de valeurs catégorielles\n\npour créer une nouvelle colonne de catégories numériques (par exemple, des catégories d’âge).\n\n\nValeurs spécifiques\nPour modifier les valeurs manuellement, vous pouvez utiliser la fonction recode() au sein de la fonction mutate().\nImaginez qu’il y ait une date érronée dans les données (par exemple “2014-14-15”) : vous pouvez corriger la date manuellement dans les données brutes, ou vous pouvez operer le changement dans le pipeline de nettoyage via mutate() et recode(). Cette dernière solution est plus transparente et reproductible pour toute autre personne cherchant à comprendre ou à répéter votre analyse.\n\n# Corriger  les valeurs erronnées                   # ancienne valeur        # nouvelle valeur\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\n\nLa ligne mutate() ci-dessus peut être lue comme : “muter la colonne date_onset pour qu’elle soit égale à la colonne date_onset recodée de façon à ce que l’ancienne Valeur soit changée en Nouvelle Valeur”. Notez que ce modèle (Ancienne = Nouvelle) pour recode() est l’opposé de la plupart des modèles R (new = old). La communauté de développement de R travaille à la révision de ce modèle.\nVoici un autre exemple de recodage de plusieurs valeurs dans une même colonne.\nDans linelist, les valeurs de la colonne “hospital” doivent être nettoyées. Il y a plusieurs orthographes différentes et de nombreuses valeurs manquantes.\n\ntable(linelist$hospital, useNA = \"always\")  \n\n\n                     Central Hopital                     Central Hospital \n                                  11                                  457 \n                          Hospital A                           Hospital B \n                                 290                                  289 \n                    Military Hopital                    Military Hospital \n                                  32                                  798 \n                    Mitylira Hopital                    Mitylira Hospital \n                                   1                                   79 \n                               Other                         Port Hopital \n                                 907                                   48 \n                       Port Hospital St. Mark's Maternity Hospital (SMMH) \n                                1756                                  417 \n  St. Marks Maternity Hopital (SMMH)                                 &lt;NA&gt; \n                                  11                                 1512 \n\n# Afficher un tableau avec toutes les valeurs uniques y compris les les valeurs manquantes\n\nLa commande recode() ci-dessous redéfinit la colonne “hospital” comme la colonne actuelle “hospital”, mais avec les changements de recode spécifiés. N’oubliez pas les virgules après chacun d’eux !\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital,\n                # Pour reference: ANCIEN =NOUVEAU\n                      \"Mitylira Hopital\"  =\"Military Hospital\",\n                      \"Mitylira Hospital\" =\"Military Hospital\",\n                      \"Military Hopital\"  =\"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\n\nNous voyons maintenant que les orthographes de la colonne hospital ont été corrigées et consolidées :\n\ntable(linelist$hospital, useNA = \"always\")\n\n\n                    Central Hospital                           Hospital A \n                                 468                                  290 \n                          Hospital B                    Military Hospital \n                                 289                                  910 \n                               Other                        Port Hospital \n                                 907                                 1804 \nSt. Mark's Maternity Hospital (SMMH)                                 &lt;NA&gt; \n                                 428                                 1512 \n\n\nCONSEIL: Le nombre d’espaces avant et après un signe égal n’a pas d’importance. Rendez votre code plus facile à lire en alignant le signe = pour toutes ou la plupart des lignes. En outre, envisagez d’ajouter une ligne de commentaires afin de clarifier pour les futurs lecteurs quel côté est l’ANCIEN et quel côté est le NOUVEAU. \nCONSEIL: Parfois, une valeur de caractère vide existe dans un jeu de donnée (non reconnue comme la valeur de R pour les manquants - NA). Vous pouvez référencer cette valeur avec deux guillemets sans espace entre eux (““).\n\n\npar logique\nNous démontrons ci-dessous comment recoder les valeurs d’une colonne en utilisant la logique et les conditions :\n\nUtiliser replace(), ifelse() et if_else() pour une logique simple.\nUtilisation de case_when() pour une logique plus complexe.\n\n\n\nLogique simple\n\nreplace()\nPour recoder avec des critères logiques simples, vous pouvez utiliser replace() dans mutate(). replace() est une fonction de base R. Utilisez une condition logique pour spécifier les lignes à changer . La syntaxe générale est la suivante :\nmutate(col_a_change = replace(col_a_changer, condition sur les lignes, nouvelle valeur)).\nUne situation courante pour utiliser replace() est la modification d’une seule valeur dans une ligne, en utilisant un identifiant propre à une ligne . Ci-dessous, le sexe est changé en “Female” dans la ligne où la colonne case_id est “2195”.\n\n# Exemple : Changer en \"Female\" le genre pour une observation definie\nlinelist &lt;- linelist %&gt;% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\n\nLa commande équivalente utilisant la syntaxe base R et les crochets d’indexation [ ] est presenté ci-dessous. Elle se lit comme suit : “Changez la valeur de la colonne gender du dataframe linelist (pour les lignes où la colonne case_id de linelist a la valeur ‘2195’) en ‘Female’”.\n\nlinelist$gender[linelist$case_id == \"2195\"] &lt;- \"Female\"\n\n\n\nifelse() et if_else()\nUne autre fonction pour la logique simple est ifelse() et son partenaire if_else(). Cependant, dans la plupart des cas de recodage, il est plus clair d’utiliser case_when() (détaillé ci-dessous). Ces commandes “if else” sont des versions simplifiées d’une instruction de programmation if et else. La syntaxe générale est la suivante :\nifelse(condition, valeur à renvoyer si la condition vaut VRAI, valeur à renvoyer si la condition vaut FAUX).\nCi-dessous, la colonne source_known est définie. Sa valeur dans une ligne donnée est définie comme “connue” si la valeur de la colonne source de cette ligne n’est pas manquante. Si la valeur de la colonne source est manquante, alors la valeur de la colonne source_known est définie comme “inconnue”.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n\nif_else() est une version spéciale de dplyr qui gère les dates. Notez que si la valeur “true” est une date, la valeur “false” doit aussi être une date, d’où l’utilisation de la valeur spéciale “NA_real_” au lieu de “NA”.\n\n# Creer une colonne nommé date of death qui a comme valeur NA si le patient n'est pas mort\nlinelist &lt;- linelist %&gt;% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))\n\nÉvitez d’enchaîner les commandes ifelse… utilisez plutôt case_when()! case_when() est beaucoup plus facile à lire et vous ferez moins d’erreurs.\n\n\n\n\n\n\n\n\n\nEn dehors du contexte d’un dataframe, si vous voulez qu’un objet utilisé dans votre code change de valeur, pensez à utiliser switch() une fonction base de R.\n\n\n\nLogique complexe\nUtilisez la fonction case_when() de dplyr si vous effectuez un recodage dans de nombreux nouveaux groupes, ou si vous devez utiliser des instructions logiques complexes pour recoder des valeurs. Cette fonction évalue chaque ligne du cadre de données, détermine si les lignes répondent aux critères spécifiés et attribue la nouvelle valeur correcte.\nLes commandes case_when() sont des instructions qui ont un côté droit (CD) et un côté gauche (CG) séparés par un “tilde” ~. Les critères logiques se trouvent dans la partie gauche et les valeurs d’application dans la partie droite de chaque instruction. Les déclarations sont séparées par des virgules.\nPar exemple, ici nous utilisons les colonnes age et age_unit pour créer une colonne age_years :\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # Si l'age est donné en années\n            age_unit == \"months\" ~ age/12,    # si l'age est donnée en mois, divise par 12\n            is.na(age_unit)      ~ age))      # Si l'unite d'age est une valeur maquante, garde comme années\n                                              # toute valeur non prise en compte par ces conditions seront consideres commme valeur NA (manquante)\n\nLorsque chaque ligne des données est évaluée, les critères sont appliqués/évalués dans l’ordre où les instructions case_when() sont écrites - de haut en bas. Si le premier critère est évalué à TRUE pour une ligne donnée, la valeur CD est attribuée, et les autres critères ne sont même pas testés pour cette ligne. Il est donc préférable d’écrire les critères les plus restrictifs en premier, et les plus généraux en dernier. Une ligne de données qui ne répond à aucun des critères de droite se verra attribuer la valeur “NA” (manquante).\nParfois, vous pouvez écrire une instruction finale qui attribue une valeur pour tous les autres scénarios non décrits par l’une des lignes précédentes. Pour faire cela, placez TRUE sur le côté gauche, ce qui permettra de capturer toute ligne qui ne répond à aucun des critères précédents. Le côté droit de cette déclaration pourrait se voir attribuer une valeur comme “vérifiez-moi !” ou manquante.\nVoici un autre exemple de case_when() utilisé pour créer une nouvelle colonne avec la classification du patient, selon une définition de cas pour les cas confirmés et suspectés :\n\nlinelist &lt;- linelist %&gt;% \n     mutate(case_status = case_when(\n          \n          # si le patient a fait un test de laboratoire et le test est positif,\n          # il est marqué comme un cas confirmé \n          ct_blood &lt; 20                   ~ \"Confirmed\",\n          \n          # étant donné qu'un patient n'a pas de résultat de laboratoire positif,\n          # si le patient a une \"source\" (lien épidémiologique) ET a de la fièvre, \n          # alors il est considéré comme un cas suspect\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # tout autre patient non traité ci-dessus \n          # est marqué pour un suivi\n          TRUE                            ~ \"To investigate\"))\n\nDANGER: Les valeurs du côté droit doivent toutes être de la même classe - soit numérique, caractère, date, logique, etc. Pour attribuer des valeurs manquantes (NA), Il est dnas certaine situation important d’utiliser des variantes spéciales de NA telles que NA_character_, NA_real_ (pour les numériques ou POSIX), et as.Date(NA). Pour en savoir plus, lisez Manipuler les dates.\n\n\nValeurs manquantes\nVous trouverez ci-dessous des fonctions spéciales pour le traitement des valeurs manquantes dans le cadre du nettoyage des données.\nVoir la page sur les [Données manquantes] pour des conseils plus détaillés sur l’identification et la gestion des valeurs manquantes. Par exemple, la fonction is.na() qui teste logiquement l’absence de données.\nreplace_na()\nPour changer les valeurs manquantes (NA) en une valeur spécifique, telle que “Missing”, utilisez la fonction dplyr replace_na() dans mutate(). Notez que cette fonction est utilisée de la même manière que recode ci-dessus - le nom de la variable doit être mentionnée dans replace_na().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\n\nfct_explicit_na()\nC’est une fonction du package forcats qui permet de manipuler les colonnes de la classe Factor. Les facteurs constitue la facon dont R gère les valeurs ordonnées telles que c(\"Premier\", \"Deuxieme\", \"Troisieme\") ou pour définir l’ordre dans lequel les valeurs (par exemple les hôpitaux) apparaissent dans les tableaux et les graphiques. Voir la page sur les Facteurs.\nSi vos données sont de la classe Factor et que vous essayez de convertir NA en “Missing” en utilisant replace_na(), vous obtiendrez cette erreur : invalid factor level, NA generated. Vous avez essayé d’ajouter “Missing” comme valeur, alors qu’il n’était pas défini comme un niveau possible du facteur, et il a été rejeté.\nLa façon la plus simple de résoudre ce problème est d’utiliser la fonction fct_explicit_na() du package forcats qui convertit une colonne en classe facteur , et convertit les valeurs NA en caractère “(Missing)”.\n\nlinelist %&gt;% \n  mutate(hospital = fct_explicit_na(hospital))\n\nUne alternative plus lente serait d’ajouter le niveau du facteur en utilisant fct_expand() et ensuite de convertir les valeurs manquantes.\nna_if()\nPour convertir une valeur spécifique en NA, utilisez la fonction na_if() de dplyr. La commande ci-dessous effectue l’opération inverse de replace_na(). Dans l’exemple ci-dessous, toutes les valeurs de “Missing” dans la colonne hospital sont converties en NA.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n\nRemarque : na_if() ne peut pas être utilisé pour des critères logiques (par exemple “toutes les valeurs &gt; 99”) - utilisez replace() ou case_when() pour cela :\n\n# remplacer les temperature superieure à 40 par NA\nlinelist &lt;- linelist %&gt;% \n  mutate(temp = replace(temp, temp &gt; 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\n# Convertir en valeur manquante toutes dates d'appartion  avant le 1 Jan 2000 \nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = replace(date_onset, date_onset &gt; as.Date(\"2000-01-01\"), NA))\n\n\n\nDictionnaire contenant les parametres de nettoyage\nUtilisez le package matchmaker et sa fonction match_df() pour nettoyer un dataframe avec un dictionnaire de nettoyage.\n\nCréez un dictionnaire de nettoyage avec 3 colonnes :\n\nUne colonne “from” (la valeur incorrecte)\n\nUne colonne “to” (la valeur correcte)\n\nUne colonne spécifiant la colonne pour laquelle les changements doivent être appliqués (ou “.global” pour appliquer à toutes les colonnes).\n\n\nRemarque : les entrées du dictionnaire .global seront remplacées par les entrées du dictionnaire spécifiques à la colonne.\n\n\n\n\n\n\n\n\n\n\nImportez le fichier du dictionnaire dans R. Cet exemple peut être téléchargé via les instructions de la page Télécharger le manuel et les données.\n\n\ncleaning_dict &lt;- rio::import(\"cleaning_dict.csv\")\n\n\nPipez le jeu de donnée brute linelist à match_df(), en spécifiant à dictionary = le dataframe du dictionnaire de nettoyage.L’argument from = doit être le nom de la colonne du dictionnaire qui contient les “anciennes” valeurs, l’argument by = doit être la colonne du dictionnaire qui contient les “nouvelles” valeurs correspondantes, et la troisième colonne indique la colonne dans laquelle effectuer le changement. Utilisez .global dans la colonne by = pour appliquer un changement à toutes les colonnes. Une quatrième colonne de dictionnaire order peut être utilisée pour spécifier l’ordre des facteurs des nouvelles valeurs.\nVous trouverez plus de détails dans la documentation du package en exécutant ?match_df. Notez que l’exécution de cette fonction peut prendre beaucoup de temps pour un grand jeu de données.\n\n\nlinelist &lt;- linelist %&gt;% # fournissez ou pipez votre jeu de données\n     matchmaker::match_df(\n          dictionary = cleaning_dict, # nom de votre dictionnaire\n          from = \"from\", # colonne avec les valeurs à remplacer (par défaut, col 1)\n          to = \"to\", # colonne avec les valeurs finales (par défaut col 2)\n          by = \"col\", # colonne avec les noms de colonnes (par défaut col 3)\n  )\n\nMaintenant, faites défiler vers la droite pour voir comment les valeurs ont changé - en particulier le genre(de minuscule à majuscule), et toutes les colonnes de symptômes ont été transformées de oui/non à 1/0.\n\n\n\n\n\n\nNotez que les noms de vos colonnes dans le dictionnaire de nettoyage doivent correspondre aux noms à ce stade dans votre script de nettoyage. Voir cette référence en ligne pour le package linelist pour plus de détails.\n\nAjouter à la chaine de commande pipé\nCi dessous quelques nouveaux colonnes et des transformations operes sur les colonnes existantes sont implementés dans la chaine pipé.\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipe avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le processus de Nettoyage pipé\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardiser la syntaxe des noms de colonnes\n    janitor::clean_names() %&gt;% \n    \n    # renommer manuellement les noms de colonnes\n           # Nouveau nom             # Ancien nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # supprimer colonne\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # supprimer les doublon\n    distinct() %&gt;% \n  \n    # ajouter colonne\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convertir les classes des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # ajout colonnes: Delai de l'apparition de la maladie et  l'hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n   # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT\n   ###################################################\n\n    # Nettoyer les  valeurs de la colonne hospital \n    mutate(hospital = recode(hospital,\n                      # ANCIEN = NOUVEAU\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # creer une colonne  age_years  (à partir des solonnes  age et age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#num_cats",
    "href": "new_pages/cleaning.fr.html#num_cats",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.9 Classes numeriques",
    "text": "8.9 Classes numeriques\nNous décrivons ici quelques approches spéciales pour créer des catégories à partir de colonnes numériques. Les exemples les plus courants sont les catégories d’âge, les groupes de valeurs de laboratoire, etc. Nous discuterons ici :\n\nage_categories(), du paquet epikit.\n\ncut(), du package base R\n\ncase_when()\n\nLes ruptures quantiles avec quantile() et ntile().\n\n\nRevoir la distribution\nPour cet exemple, nous allons créer une colonne age_cat en utilisant la colonne age_years.\n\n# Verifions la class de la colonne age_years\nclass(linelist$age_years)\n\n[1] \"numeric\"\n\n\nTout d’abord, examinez la distribution de vos données, afin de définir limites appropriés. Voir la page sur les bases de ggplot.\n\n# examine the distribution\nhist(linelist$age_years)\n\n\n\n\n\n\n\n\n\nsummary(linelist$age_years, na.rm=T)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.04   23.00   84.00     107 \n\n\nATTENTION: Parfois, les variables numériques sont importées en tant que classe “character”. Cela se produit s’il y a des caractères non numériques dans certaines des valeurs, par exemple une entrée de “2 mois” pour l’âge, ou (en fonction des paramètres par defaut de R) si une virgule est utilisée à la place des décimales (par exemple “4,5” pour signifier quatre ans et demi)..\n\n\n\nage_categories()\nAvec le packagge epikit, vous pouvez utiliser la fonction age_categories() pour catégoriser et étiqueter facilement les colonnes numériques (noté que cette fonction peut aussi être appliquée à des variables non numériques d’âge). En guise de bonus, la colonne de sortie est automatiquement une variable categorielle ordonnée.\nVoici les entrées requises :\n\nUn tableau numérique (colonne)\n\nL’argument breakers = - fournit un vecteur numérique de points de rupture pour les nouveaux groupes.\n\nTout d’abord, l’exemple le plus simple :\n\n# Exemple basique\n################\npacman::p_load(epikit)                    # chargerle  package\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(             # creer un nouveau colonne\n      age_years,                            # colonne numerique pour  concevoir des groupes\n      breakers = c(0, 5, 10, 15, 20,        # les  bornes\n                   30, 40, 50, 60, 70)))\n\n# afficher le tableau\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    27     7   107 \n\n\nLes valeurs de bornes que vous spécifiez sont par défaut les limites inférieures - c’est-à-dire qu’elles sont incluses dans le groupe “supérieur” / les groupes sont “ouverts” du côté inférieur/gauche. Comme indiqué ci-dessous, vous pouvez ajouter 1 à chaque valeur de rupture pour obtenir des groupes ouverts en haut/à droite.\n\n# Inclure les bornes superieures pour les memes classes\n############################################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# afficher le tableau\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  &lt;NA&gt; \n 1469  1195  1040   770  1149   547   231    70    24     6   107 \n\n\nVous pouvez ajuster la façon dont les étiquettes sont affichées avec separator =. La valeur par défaut est “-”.\nVous pouvez ajuster la façon dont les numéros supérieurs sont traités, avec l’argument ceiling =. Pour définir une coupure supérieure, mettez ceiling = TRUE. Dans cette utilisation, la valeur de rupture la plus élevée fournie est un “plafond” et une catégorie “XX+” n’est pas créée. Toutes les valeurs supérieures à la valeur de rupture la plus élevée (ou à upper =, s’il est défini) sont classées dans la catégorie NA. Voici un exemple avec ceiling = TRUE, de sorte qu’il n’y a pas de catégorie XX+ et que les valeurs supérieures à 70 (la valeur de rupture la plus élevée) sont classées comme NA.\n\n# Avec l'argument ceiling definit comme  TRUE\n##########################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is le plafond, toute valeur au dela  devient  NA\n\n# afficher le tableau\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    28   113 \n\n\nAlternativement, au lieu de breakers =, vous pouvez fournir tous les lower =, upper =, et by = :\n\nlower = Le nombre le plus bas que vous voulez prendre en compte - la valeur par défaut est 0\n\nupper = Le nombre le plus élevé que vous voulez considérer\n\nby = Le nombre d’années entre les groupes\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# afficher tableau\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  &lt;NA&gt; \n 2450  1875  1216   597   251    78    27     6     1     0     0   107 \n\n\nConsultez la page d’aide de la fonction pour plus de détails (entrez ?age_categories dans la console R).\n\n\n\ncut()\ncut() est une alternative à age_categories() présente dans les packages de base de R , vous verrez pourquoi age_categories() a été développé pour simplifier ce processus. Quelques différences notoires avec age_categories() sont :\n\nVous n’avez pas besoin d’installer/charger un autre package\n\nVous pouvez spécifier si les groupes sont ouverts/fermés à droite/à gauche.\n\nVous devez fournir vous-même des étiquettes précises\n\nSi vous voulez que 0 soit inclus dans le groupe le plus bas, vous devez le spécifier.\n\nLa syntaxe de base de cut() est de fournir d’abord la colonne numérique à découper (age_years), puis l’argument breaks, qui est un vecteur numérique c() de points de rupture. En utilisant cut(), la colonne résultante est un facteur ordonné.\nPar défaut, la catégorisation se produit de sorte que le côté droit/supérieur est “ouvert” et inclusif (et le côté gauche/inférieur est “fermé” ou exclusif). C’est le comportement opposé de la fonction age_categories(). Les étiquettes par défaut utilisent la notation “(A, B]”, ce qui signifie que A n’est pas inclus mais que B l’est. **Inversez ce comportement en fournissant l’argument right = TRUE.\nAinsi, par défaut, les valeurs “0” sont exclues du groupe le plus bas, et catégorisées comme NA ! Les valeurs “0” pourraient être des nourrissons codés comme ayant l’âge 0, alors faites attention ! Pour changer cela, ajoutez l’argument include.lowest = TRUE pour que toutes les valeurs “0” soient incluses dans le groupe le plus bas. L’étiquette générée automatiquement pour la catégorie la plus basse sera alors “[A],B]”. Notez que si vous incluez l’argument include.lowest = TRUE et right = TRUE, l’inclusion extrême s’appliquera maintenant à la valeur et à la catégorie du point de rupture haut, et non à la plus basse.\nVous pouvez fournir un vecteur d’étiquettes personnalisées en utilisant l’argument labels =. Comme ils sont écrits manuellement, faites très attention à ce qu’ils soient exacts ! Vérifiez votre travail en utilisant des tableaux croisés, comme décrit ci-dessous.\nVoici un exemple de cut() appliqué à age_years pour créer la nouvelle variable age_cat :\n\n# Creons une nouvelle variable en decoupant par interval la variable numerique age\n\n#La valeur de la borne inferieure est exclu mais la borne superieu est inclue dans chaque groupe\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # inclu le 0 dans le premier interval crée\n      ))\n\n# Representer dans un tableau les nombres d'observations en fonction des categories créee\ntable(linelist$age_cat, useNA = \"always\")\n\n\n   [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100] \n    1469     1195     1040      770     1149      778       94        6 \n    &lt;NA&gt; \n     107 \n\n\n**Vérifiez que chaque valeur d’âge a été affectée à la bonne catégorie en croisant les colonnes numériques et de catégorie. Examinez l’attribution des valeurs limites (par exemple 15, si les catégories voisines sont 10-15 et 16-20).\n\n# Cross tabulation of the numeric and category columns. \n# tableau croisé entre les colonnes numeriques et categorielles\ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        \n\n                    Categories\nNumeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70]\n  0                    136      0       0       0       0       0       0\n  0.0833333333333333     1      0       0       0       0       0       0\n  0.25                   2      0       0       0       0       0       0\n  0.333333333333333      6      0       0       0       0       0       0\n  0.416666666666667      1      0       0       0       0       0       0\n  0.5                    6      0       0       0       0       0       0\n  0.583333333333333      3      0       0       0       0       0       0\n  0.666666666666667      3      0       0       0       0       0       0\n  0.75                   3      0       0       0       0       0       0\n  0.833333333333333      1      0       0       0       0       0       0\n  0.916666666666667      1      0       0       0       0       0       0\n  1                    275      0       0       0       0       0       0\n  1.5                    2      0       0       0       0       0       0\n  2                    308      0       0       0       0       0       0\n  3                    246      0       0       0       0       0       0\n  4                    233      0       0       0       0       0       0\n  5                    242      0       0       0       0       0       0\n  6                      0    241       0       0       0       0       0\n  7                      0    256       0       0       0       0       0\n  8                      0    239       0       0       0       0       0\n  9                      0    245       0       0       0       0       0\n  10                     0    214       0       0       0       0       0\n  11                     0      0     220       0       0       0       0\n  12                     0      0     224       0       0       0       0\n  13                     0      0     191       0       0       0       0\n  14                     0      0     199       0       0       0       0\n  15                     0      0     206       0       0       0       0\n  16                     0      0       0     186       0       0       0\n  17                     0      0       0     164       0       0       0\n  18                     0      0       0     141       0       0       0\n  19                     0      0       0     130       0       0       0\n  20                     0      0       0     149       0       0       0\n  21                     0      0       0       0     158       0       0\n  22                     0      0       0       0     149       0       0\n  23                     0      0       0       0     125       0       0\n  24                     0      0       0       0     144       0       0\n  25                     0      0       0       0     107       0       0\n  26                     0      0       0       0     100       0       0\n  27                     0      0       0       0     117       0       0\n  28                     0      0       0       0      85       0       0\n  29                     0      0       0       0      82       0       0\n  30                     0      0       0       0      82       0       0\n  31                     0      0       0       0       0      68       0\n  32                     0      0       0       0       0      84       0\n  33                     0      0       0       0       0      78       0\n  34                     0      0       0       0       0      58       0\n  35                     0      0       0       0       0      58       0\n  36                     0      0       0       0       0      33       0\n  37                     0      0       0       0       0      46       0\n  38                     0      0       0       0       0      45       0\n  39                     0      0       0       0       0      45       0\n  40                     0      0       0       0       0      32       0\n  41                     0      0       0       0       0      34       0\n  42                     0      0       0       0       0      26       0\n  43                     0      0       0       0       0      31       0\n  44                     0      0       0       0       0      24       0\n  45                     0      0       0       0       0      27       0\n  46                     0      0       0       0       0      25       0\n  47                     0      0       0       0       0      16       0\n  48                     0      0       0       0       0      21       0\n  49                     0      0       0       0       0      15       0\n  50                     0      0       0       0       0      12       0\n  51                     0      0       0       0       0       0      13\n  52                     0      0       0       0       0       0       7\n  53                     0      0       0       0       0       0       4\n  54                     0      0       0       0       0       0       6\n  55                     0      0       0       0       0       0       9\n  56                     0      0       0       0       0       0       7\n  57                     0      0       0       0       0       0       9\n  58                     0      0       0       0       0       0       6\n  59                     0      0       0       0       0       0       5\n  60                     0      0       0       0       0       0       4\n  61                     0      0       0       0       0       0       2\n  62                     0      0       0       0       0       0       1\n  63                     0      0       0       0       0       0       5\n  64                     0      0       0       0       0       0       1\n  65                     0      0       0       0       0       0       5\n  66                     0      0       0       0       0       0       3\n  67                     0      0       0       0       0       0       2\n  68                     0      0       0       0       0       0       1\n  69                     0      0       0       0       0       0       3\n  70                     0      0       0       0       0       0       1\n  72                     0      0       0       0       0       0       0\n  73                     0      0       0       0       0       0       0\n  76                     0      0       0       0       0       0       0\n  84                     0      0       0       0       0       0       0\n  &lt;NA&gt;                   0      0       0       0       0       0       0\n                    Categories\nNumeric Values       (70,100] &lt;NA&gt;\n  0                         0    0\n  0.0833333333333333        0    0\n  0.25                      0    0\n  0.333333333333333         0    0\n  0.416666666666667         0    0\n  0.5                       0    0\n  0.583333333333333         0    0\n  0.666666666666667         0    0\n  0.75                      0    0\n  0.833333333333333         0    0\n  0.916666666666667         0    0\n  1                         0    0\n  1.5                       0    0\n  2                         0    0\n  3                         0    0\n  4                         0    0\n  5                         0    0\n  6                         0    0\n  7                         0    0\n  8                         0    0\n  9                         0    0\n  10                        0    0\n  11                        0    0\n  12                        0    0\n  13                        0    0\n  14                        0    0\n  15                        0    0\n  16                        0    0\n  17                        0    0\n  18                        0    0\n  19                        0    0\n  20                        0    0\n  21                        0    0\n  22                        0    0\n  23                        0    0\n  24                        0    0\n  25                        0    0\n  26                        0    0\n  27                        0    0\n  28                        0    0\n  29                        0    0\n  30                        0    0\n  31                        0    0\n  32                        0    0\n  33                        0    0\n  34                        0    0\n  35                        0    0\n  36                        0    0\n  37                        0    0\n  38                        0    0\n  39                        0    0\n  40                        0    0\n  41                        0    0\n  42                        0    0\n  43                        0    0\n  44                        0    0\n  45                        0    0\n  46                        0    0\n  47                        0    0\n  48                        0    0\n  49                        0    0\n  50                        0    0\n  51                        0    0\n  52                        0    0\n  53                        0    0\n  54                        0    0\n  55                        0    0\n  56                        0    0\n  57                        0    0\n  58                        0    0\n  59                        0    0\n  60                        0    0\n  61                        0    0\n  62                        0    0\n  63                        0    0\n  64                        0    0\n  65                        0    0\n  66                        0    0\n  67                        0    0\n  68                        0    0\n  69                        0    0\n  70                        0    0\n  72                        1    0\n  73                        3    0\n  76                        1    0\n  84                        1    0\n  &lt;NA&gt;                      0  107\n\n# N'oublier pas d'examiner les valeurs NA\n\nRéétiquetage des valeurs NA .\nVous pouvez vouloir attribuer aux valeurs NA une étiquette telle que “Missing”. Comme la nouvelle colonne est de la classe Factor (valeurs restreintes), vous ne pouvez pas simplement la muter avec replace_na(), car cette valeur sera rejetée. A la place, utilisez fct_explicit_na() de forcats comme expliqué dans la page Facteurs.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # cut() creates age_cat, automatically of class Factor      \n     # cut() crée  automatique une colonne dénommée age_cat avec des valeurs categorielles \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n   \n    # nommer explicitemment les valeurs manquantes\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n    # on peut specifier les etiquettes\n  )    \n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat = fct_explicit_na(age_cat, na_level = \"Missing age\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n# tableau pour voir les effectifs\ntable(linelist$age_cat, useNA = \"always\")\n\n\n        0-4         5-9       10-14       15-19       20-29       30-49 \n       1227        1223        1048         827        1216         848 \n      50-69      70-100 Missing age        &lt;NA&gt; \n        105           7         107           0 \n\n\nCréer des seuils de rupture et des étiquettes\nPour une manière rapide de faire des pauses et de labelliser des vecteurs, utilisez quelque chose comme ci-dessous. Voir la page Bases de R pour les références sur seq() et rep().\n\n# Make break points from 0 to 90 by 5\n# Crée un vecteur allant de 0 à 90 avec des pas de 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\n# Créé des etiquettes pour les categories concues ci dessus avec les parametres de defaut de cut() \nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\n# Montrons que que les deux vecteurs sont de meme longueurs\nlength(age_seq) == length(age_labels)\n\nLisez plus sur cut() dans sa page d’aide en entrant ?cut dans la console R.\n\n\nSeuil de rupture par le Quantile\nDans le langage courant, les “quantiles” ou “percentiles” font généralement référence à une valeur en dessous de laquelle se situe une proportion de valeurs. Par exemple, le 95ème percentile des âges dans linelist serait l’âge en dessous duquel 95% de l’âge tombe.\nCependant, dans le langage courant, les “quartiles” et les “déciles” peuvent également faire référence aux groupes de données divisés de manière égale en 4 ou 10 groupes (notez qu’il y aura un point de rupture de plus que le groupe).\nPour obtenir les points de rupture des quantiles, vous pouvez utiliser quantile() du paquet stats de base R. Vous fournissez un vecteur numérique (par exemple une colonne dans un ensemble de données) et un vecteur de valeurs numériques de probabilité allant de 0 à 1,0. Les points de rupture sont renvoyés sous la forme d’un vecteur numérique. Explorez les détails des méthodologies statistiques en entrant ?quantile.\n\nSi votre tableau numérique d’entrée a des valeurs manquantes, il est préférable de définir na.rm = TRUE.\n\nDéfinissez names = FALSE pour obtenir un tableau numérique sans nom.\n\n\nquantile(linelist$age_years,              #specifier le vecteur numerique sur lequel on travaille\n         \n  probs = c(0, .25, .50, .75, .90, .95),  #specifier les centiles qui vous interesse\n  na.rm = TRUE)                            # ignorer les valeurs manquantes \n\n 0% 25% 50% 75% 90% 95% \n  0   6  13  23  33  41 \n\n\nVous pouvez utiliser les résultats de quantile() comme points de rupture dans age_categories() ou cut(). Ci-dessous, nous créons une nouvelle colonne déciles en utilisant cut() où les ruptures sont définies en utilisant quantiles() sur age_years. Ci-dessous, nous affichons les résultats en utilisant tabyl() de janitor pour que vous puissiez voir les pourcentages (voir la page Tableaux descriptifs). Notez comment ils ne sont pas exactement 10% dans chaque groupe.\n\nlinelist %&gt;%                              #commencer avec la donnéé linelist\n  mutate(deciles = cut(age_years,           # creer un nouveau colonne decile qui represente des classes issues de l'application de cut() sur age_years \n    breaks = quantile(                      #definir les seuils  de la fonction cut en utilisant quantile()\n      age_years,                               # utiliser  la colonne age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 à 1.0 pas de  0.1\n      na.rm = TRUE),                           # ignorer les valeurs manquantes\n    include.lowest = TRUE)) %&gt;%             #Pour cut() inclure age 0\n  janitor::tabyl(deciles)                   # piper pour obtenir un tableau à afficher\n\n deciles   n    percent valid_percent\n   [0,2] 748 0.11319613    0.11505922\n   (2,5] 721 0.10911017    0.11090601\n   (5,7] 497 0.07521186    0.07644978\n  (7,10] 698 0.10562954    0.10736810\n (10,13] 635 0.09609564    0.09767728\n (13,17] 755 0.11425545    0.11613598\n (17,21] 578 0.08746973    0.08890940\n (21,26] 625 0.09458232    0.09613906\n (26,33] 596 0.09019370    0.09167820\n (33,84] 648 0.09806295    0.09967697\n    &lt;NA&gt; 107 0.01619249            NA\n\n\n\n\nGroupes de taille égale\nUn autre outil pour créer des groupes numériques est la fonction dplyr ntile(), qui tente de diviser vos données en n groupes de taille égale - mais sachez que contrairement à quantile(), la même valeur peut apparaître dans plus d’un groupe. Fournissez le tableau numérique et ensuite le nombre de groupes. Les valeurs dans la nouvelle colonne créée sont juste des “numéros” de groupe (par exemple 1 à 10), et non la plage de valeurs elle-même comme lors de l’utilisation de cut().\n\n# créer des classes avec ntile()\nntile_data &lt;- linelist %&gt;% \n  mutate(even_groups = ntile(age_years, 10))\n\n# créer un tableau avec les effectifs et les frequences des classes\nntile_table &lt;- ntile_data %&gt;% \n  janitor::tabyl(even_groups)\n  \n\n# ajouter les valeurs min/max pour voir l'etendu des classe\nntile_ranges &lt;- ntile_data %&gt;% \n  group_by(even_groups) %&gt;% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `min = min(age_years, na.rm = T)`.\nℹ In group 11: `even_groups = NA`.\nCaused by warning in `min()`:\n! no non-missing arguments to min; returning Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# combine and print - note that values are present in multiple groups\n#\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")\n\n even_groups   n    percent valid_percent min  max\n           1 651 0.09851695    0.10013844   0    2\n           2 650 0.09836562    0.09998462   2    5\n           3 650 0.09836562    0.09998462   5    7\n           4 650 0.09836562    0.09998462   7   10\n           5 650 0.09836562    0.09998462  10   13\n           6 650 0.09836562    0.09998462  13   17\n           7 650 0.09836562    0.09998462  17   21\n           8 650 0.09836562    0.09998462  21   26\n           9 650 0.09836562    0.09998462  26   33\n          10 650 0.09836562    0.09998462  33   84\n          NA 107 0.01619249            NA Inf -Inf\n\n\n\n\n\ncase_when()\nIl est possible d’utiliser la fonction dplyr case_when() pour créer des classes à partir d’une colonne numérique, mais il est plus facile d’utiliser age_categories() de epikit ou cut() car ceux-ci créeront un facteur ordonné automatiquement.\nSi vous utilisez case_when(), veuillez revoir l’utilisation correcte comme décrit précédemment dans la section Re-coder les valeurs de cette page. Sachez également que toutes les valeurs du côté droit doivent être de la même classe. Ainsi, si vous voulez que NA figure à droite, vous devez soit écrire “Missing”, soit utiliser la valeur spéciale NA, NA_character_.\n\n\nAjouter à la chaine de commande pipé\nCi-dessous, le code pour créer deux colonnes d’âge catégorique est ajouté à la chaîne de nettoyage :\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et suivi de  pipe avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le nettoyage de la chaine de commande pipé\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardiser la syntaxe des noms de colonnes\n    janitor::clean_names() %&gt;% \n    \n    # renommons manuellement les noms de colonnes\n           # Nouveau nom             # Ancien nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # supprimer colonne\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # supplimer les doublons\n    distinct() %&gt;% \n\n    # ajouter colonnes\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convertir la classe des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # creer colonne: retard d'hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # rendre propre les valeurs contenu dans la colonne hospitalisation\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # creons la colonne age_years column (à partir des colonnes age et age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT\n    ###################################################   \n    mutate(\n          # age classe: difinition\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age classe: 0 à 85 par pas de 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#ajouter-des-lignes",
    "href": "new_pages/cleaning.fr.html#ajouter-des-lignes",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.10 Ajouter des lignes",
    "text": "8.10 Ajouter des lignes\n\nune à une\nAjouter des lignes une par une manuellement est fastidieux mais peut être fait avec add_row() de dplyr. Rappelez-vous que chaque colonne doit contenir des valeurs d’une seule classe (soit caractère, numérique, logique, etc.). Ainsi, l’ajout d’une ligne nécessite de la nuance pour maintenir cela.\n\nlinelist &lt;- linelist %&gt;% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)\n\nUtilisez .before et .after. pour spécifier le placement de la ligne que vous voulez ajouter. .before = 3 placera la nouvelle ligne avant la 3ème ligne actuelle. Le comportement par défaut est d’ajouter la ligne à la fin. Les colonnes non spécifiées seront laissées vides (NA).\nLe nouveau numéro de ligne peut sembler étrange (“…23”) mais les numéros de ligne dans les lignes préexistantes ont changé. Donc, si vous utilisez la commande deux fois, examinez/testez soigneusement l’insertion.\nSi une classe que vous avez fournie est incorrecte, vous verrez une erreur comme celle-ci :\nError: Can't combine ..1$infection date &lt;date&gt; and ..2$infection date &lt;character&gt;.\n(lorsque vous insérez une ligne avec une valeur de date, n’oubliez pas d’envelopper la date dans la fonction as.Date() comme as.Date(\"2020-10-10\").\n\n\ncoller des lignes\nPour combiner des ensembles de données ensemble en liant les lignes d’un cadre de données au bas d’un autre cadre de données, vous pouvez utiliser bind_rows() de dplyr. Ceci est expliqué plus en détail dans la page Joindre des données.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#filtrer-les-lignes",
    "href": "new_pages/cleaning.fr.html#filtrer-les-lignes",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.11 Filtrer les lignes",
    "text": "8.11 Filtrer les lignes\nUne étape typique de nettoyage après avoir nettoyé les colonnes et recodé les valeurs est de filtrer le cadre de données pour des lignes spécifiques en utilisant le verbe dplyr filter().\nDans filter(), spécifiez la logique qui doit être TRUE pour qu’une ligne de l’ensemble de données soit conservée. Nous montrons ci-dessous comment filtrer des lignes sur la base de conditions logiques simples et complexes.\n\n\nFiltre simple\nCet exemple simple redéfinit le dataframe linelist comme lui-même, après avoir filtré les lignes pour répondre à une condition logique. **Seules les lignes où l’énoncé logique entre parenthèses est évalué à “VRAI” sont conservées.\nDans cet exemple, l’instruction logique est gender == \"f\", qui demande si la valeur de la colonne gender est égale à “f” (sensible à la casse).\nAvant que le filtre ne soit appliqué, le nombre de lignes dans linelist est nrow(linelist).\n\nlinelist &lt;- linelist %&gt;% \n  filter(gender == \"f\")   # garder unique les lignes ou le est egale à \"f\"\n\nUne fois le filtre appliqué, le nombre de lignes dans linelist est linelist %&gt;% filter(gender == \"f\") %&gt;% nrow().\n\n\nFiltrer les valeurs manquantes\nIl est assez courant de vouloir filtrer les lignes qui ont des valeurs manquantes. Résistez à l’envie d’écrire filter(!is.na(column) & !is.na(column)) et utilisez plutôt la fonction tidyr qui est spécialement conçue à cet effet : drop_na(). Si elle est exécutée avec des parenthèses vides, elle supprime les lignes avec toutes les valeurs manquantes. Alternativement, vous pouvez fournir des noms de colonnes spécifiques à évaluer pour les valeurs manquantes, ou utiliser les fonctions d’aide “tidyselect” décrites ci-dessus.\n\nlinelist %&gt;% \n  drop_na(case_id, age_years)  # enlever les lignes avec des valeurs manquantes pour les colonnes case_id ou age_years\n\nVoir la page sur les [Données manquantes] pour de nombreuses techniques d’analyse et de gestion des données manquantes dans vos données.\n\n\nFiltrer par numéro de ligne\nDans un cadre de données ou un tibble, chaque ligne aura généralement un “numéro de ligne” qui (vu dans R Viewer) apparaît à gauche de la première colonne. Ce n’est pas en soi une vraie colonne dans les données, mais il peut être utilisé dans une instruction filter().\nPour filtrer sur la base du “numéro de ligne”, vous pouvez utiliser la fonction dplyr row_number() avec des parenthèses ouvertes dans le cadre d’une instruction de filtrage logique. Souvent, vous utiliserez l’opérateur %in% et une plage de nombres dans le cadre de cette instruction logique, comme indiqué ci-dessous. Pour voir les premières N lignes, vous pouvez également utiliser la fonction spéciale dplyr head().\n\n# montrer les 100 premiere lignes\nlinelist %&gt;% head(100)     # ou utiliser tail() pour voir les n derniers lignes \n\n# afficher uniquement la cinquieme ligne\nlinelist %&gt;% filter(row_number() == 5)\n\n# voir la 2ème à la 20ème ligne et 3 colonnes specifiques\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nVous pouvez également convertir les numéros de ligne en une vraie colonne en passant votre cadre de données à la fonction tibble rownames_to_column() (ne mettez rien entre les parenthèses).\n\n\n\nFiltre complexe\nDes instructions logiques plus complexes peuvent être construites en utilisant les opérateurs parenthèses ( ), OR |, négation !, %in%, et AND &. Un exemple est donné ci-dessous :\nRemarque : Vous pouvez utiliser l’opérateur ! devant un critère logique pour le nier. Par exemple, !is.na(column) est évalué à true si la valeur de la colonne n’est pas manquante. De même, !column %in% c(\"a\", \"b\", \"c\") est évalué comme vrai si la valeur de la colonne n’est pas dans le vecteur.\n\nExaminer la donnée\nVous trouverez ci-dessous une commande simple en une ligne pour créer un histogramme des dates d’apparition. Notez qu’une deuxième épidémie plus petite, datant de 2012-2013, est également incluse dans cet ensemble de données brutes. **Pour nos analyses, nous voulons supprimer les entrées de cette épidémie antérieure.\n\nhist(linelist$date_onset, breaks = 50)\n\n\n\n\n\n\n\n\n\n\nComment les filtres traitent les valeurs numériques et les dates manquantes\nPeut-on simplement filtrer par date_onset les lignes après Juin 2013 ? Attention ! L’application du code filter(date_onset &gt; as.Date(\"2013-06-01\"))) supprimerait toutes les lignes de la dernière épidémie avec une date d’apparition manquante!.\nDANGERS: Le fait de filtrer sur une date ou un nombre supérieur (&gt;) ou inférieur (&lt;) peut supprimer toutes les lignes contenant des valeurs manquantes (NA) ! En effet, NA est considéré comme infiniment grand et petit.\n(Voir la page Manipuler les dates pour plus d’informations sur le travail avec des dates et le paquet lubridate).\n\n\nConcevoir le filtre\nExaminez un tableau croisé pour vous assurer que nous excluons uniquement les bonnes lignes :\n\ntable(Hospital  = linelist$hospital,                     # nom d'hopital\n      YearOnset = lubridate::year(linelist$date_onset),  # annee des dates d'apparition \n      useNA     = \"always\")                              # montrer les valeurs manquantes\n\n                                      YearOnset\nHospital                               2012 2013 2014 2015 &lt;NA&gt;\n  Central Hospital                        0    0  351   99   18\n  Hospital A                            229   46    0    0   15\n  Hospital B                            227   47    0    0   15\n  Military Hospital                       0    0  676  200   34\n  Missing                                 0    0 1117  318   77\n  Other                                   0    0  684  177   46\n  Port Hospital                           9    1 1372  347   75\n  St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n  &lt;NA&gt;                                    0    0    0    0    0\n\n\nQuels autres critères pouvons-nous filtrer pour éliminer la première épidémie (en 2012 et 2013) de l’ensemble de données ? Nous constatons que :\n\nLa première épidémie en 2012 & 2013 a eu lieu à l’hôpital A, à l’hôpital B, et qu’il y avait aussi 10 cas à l’hôpital du Port.\n\nLes hôpitaux A et B n’ont pas eu de cas lors de la deuxième épidémie, mais l’hôpital du Port en a eu.\n\nNous voulons exclure :\n\nLes nrow(linelist %&gt;% filter(hospital %in% c(\"Hospital A\", \"Hospital B\") | date_onset &lt; as.Date(\"2013-06-01\"))) lignes avec une apparition en 2012 et 2013 à l’hôpital A, B ou Port :\n\nExclure nrow(linelist %&gt;% filter(date_onset &lt; as.Date(\"2013-06-01\"))) les lignes dont l’apparition s’est produite en 2012 et 2013.\nExclure nrow(linelist %&gt;% filter(hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) les lignes des hôpitaux A et B avec des dates de début manquantes.\n\nNe pas exclure nrow(linelist %&gt;% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) d’autres lignes avec des dates de début manquantes.\n\n\nNous commençons avec une linelist de `nrow(linelist). Voici notre déclaration de filtre :\n\nlinelist &lt;- linelist %&gt;% \n  \n # conserver les lignes où le début de la maladie est postérieur 1 June 2013 OU où le début de la maladie n'a pas de valeur renseignée et où il s'agissait d'un hôpital AUTRE que l'hôpital A ou B.\n  filter(date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)\n\n[1] 6019\n\n\nLorsque nous refaisons le tableau croisé, nous constatons que les hôpitaux A et B sont complètement retirés, ainsi que les 10 cas de l’hôpital du Port de 2012 et 2013, et que toutes les autres valeurs sont les mêmes - exactement comme nous le voulions.\n\ntable(Hospital  = linelist$hospital,                     # nom de l'hopital\n      YearOnset = lubridate::year(linelist$date_onset),   # année d'apparition de la maladie\n      useNA     = \"always\")                              # montrer les valeurs manquantes\n\n                                      YearOnset\nHospital                               2014 2015 &lt;NA&gt;\n  Central Hospital                      351   99   18\n  Military Hospital                     676  200   34\n  Missing                              1117  318   77\n  Other                                 684  177   46\n  Port Hospital                        1372  347   75\n  St. Mark's Maternity Hospital (SMMH)  322   93   13\n  &lt;NA&gt;                                    0    0    0\n\n\nPlusieurs déclarations peuvent être incluses dans une commande de filtre (séparées par des virgules), ou vous pouvez toujours utiliser une commande filter() séparée pour plus de clarté.\nNote : certains lecteurs peuvent remarquer qu’il serait plus facile de filtrer simplement par date_hospitalisation parce qu’il est 100% complet, sans valeurs manquantes. Ceci est vrai. Mais date_onset est utilisé dans le but de démontrer un filtre complexe.\n\n\n\nAutres complements\nLe filtrage peut également être effectué comme une commande autonome (ne faisant pas partie d’une chaîne de tuyaux). Comme les autres verbes dplyr, dans ce cas, le premier argument doit être le jeu de données lui-même.\n\n# dataframe &lt;- filter(dataframe, condition(s)pour les lignes à garder)\n\nlinelist &lt;- filter(linelist, !is.na(case_id))\n\nVous pouvez également utiliser base R pour effectuer un sous-ensemble en utilisant des crochets qui reflètent les [lignes, colonnes] que vous souhaitez conserver.\n\n# dataframe &lt;- dataframe[lignes conditions, colonnes conditions] (vide signifie garder tous les colonnes ou lignes)\n\nlinelist &lt;- linelist[!is.na(case_id), ]\n\n\n\nExaminer rapidement la donnée\nSouvent, vous voulez examiner rapidement quelques enregistrements, pour seulement quelques colonnes. La fonction R base View() imprimera un cadre de données pour le visualiser dans votre RStudio.\nVisualisez la liste des lignes dans RStudio :\n\nView(linelist)\n\nVoici deux exemples d’affichage de cellules spécifiques (lignes spécifiques et colonnes spécifiques) :\nAvec les fonctions dplyr filter() et select():\nDans View(), passez le jeu de données dans filter() pour conserver certaines lignes, puis dans select() pour conserver certaines colonnes. Par exemple, pour examiner les dates de début et d’hospitalisation de 3 cas spécifiques :\n\nView(linelist %&gt;%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %&gt;%\n       select(date_onset, date_hospitalisation))\n\nVous pouvez faire la même chose avec la syntaxe base de R, en utilisant les crochets `[ ]`` pour le sous-ensemble que vous voulez voir.\n\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\n\n\nAjouter à la chaine de commande pipé to pipé\n\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipes avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter la chaine de commande pipé pour le nettoyage \n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardiser la syntaxe des noms de colonnes\n    janitor::clean_names() %&gt;% \n    \n    # manuallement renommer le noms des colonnes\n           # Nouveau nom             # Ancienne nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # supprimer les colonnes\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # supprimer les doublons\n    distinct() %&gt;% \n\n    # ajouter colonne\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convertir la classe des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # ajout de colonne: retard d'hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # Nettoyer les valeurs de la colonne hospitalisation\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # creer la colonne age_years (à partir de age et age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    mutate(\n          # age classe: definition\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age classes: 0 à 85 par pas de 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %&gt;% \n    \n     # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT\n    ###################################################\n    filter(\n          # conserver uniquement les lignes ou les valeurs  case_id ne sont pas  manquantes\n          !is.na(case_id),  \n          \n          # egalement filtrons pour garder uniquement la deuxieme pandemie\n          date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#calculs-par-rangée",
    "href": "new_pages/cleaning.fr.html#calculs-par-rangée",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.12 Calculs par rangée",
    "text": "8.12 Calculs par rangée\nSi vous voulez effectuer un calcul dans une ligne, vous pouvez utiliser rowwise() de dplyr. Voir cette vignette en ligne sur calculs par ligne.\nPar exemple, ce code applique rowwise() et crée une nouvelle colonne qui additionne le nombre de colonnes de symptômes spécifiées qui ont la valeur “yes”, pour chaque ligne de la linelist. Les colonnes sont spécifiées dans sum() par leur nom dans un vecteur c(). rowwise() est essentiellement un type spécial de group_by(), il est donc préférable d’utiliser ungroup() lorsque vous avez terminé (page sur Travailler sur des données groupées).\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %&gt;% \n  ungroup() %&gt;% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # pour affichage\n\n# A tibble: 5,888 × 6\n   fever chills cough aches vomit num_symptoms\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;\n 1 no    no     yes   no    yes              2\n 2 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 3 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 4 no    no     no    no    no               0\n 5 no    no     yes   no    yes              2\n 6 no    no     yes   no    yes              2\n 7 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 8 no    no     yes   no    yes              2\n 9 no    no     yes   no    yes              2\n10 no    no     yes   no    no               1\n# ℹ 5,878 more rows\n\n\nLorsque vous spécifiez la colonne à évaluer, vous pouvez utiliser les fonctions d’aide “tidyselect” décrites dans la section select() de cette page. Vous devez juste faire un ajustement (parce que vous ne les utilisez pas dans une fonction dplyr comme select() ou summarise()).\nPlacez les critères de spécification des colonnes dans la fonction dplyr c_across(). Ceci marche parce que c_across ( documentation) est conçue pour fonctionner avec rowwise() spécifiquement. Par exemple, le code suivant :\n\nApplique rowwise() pour que l’opération suivante (sum()) soit appliquée à chaque ligne (sans additionner des colonnes entières)\n\nCrée la nouvelle colonne num_NA_dates, définie pour chaque ligne comme le nombre de colonnes (dont le nom contient “date”) pour lesquelles is.na() a donné la valeur TRUE (ce sont des données manquantes).\n\nungroup() pour supprimer les effets de rowwise() pour les étapes suivantes.\n\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %&gt;% \n  ungroup() %&gt;% \n  select(num_NA_dates, contains(\"date\")) # pour affichage\n\n# A tibble: 5,888 × 5\n   num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n          &lt;int&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n 2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n 3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n 4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n 5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n\n\nVous pouvez également fournir d’autres fonctions, telles que max() pour obtenir la dernière ou la plus récente date pour chaque ligne :\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %&gt;% \n  ungroup() %&gt;% \n  select(latest_date, contains(\"date\"))  # pour affichage \n\n# A tibble: 5,888 × 5\n   latest_date date_infection date_onset date_hospitalisation date_outcome\n   &lt;date&gt;      &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n 2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n 3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n 4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n 5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.fr.html#arranger-et-trier",
    "href": "new_pages/cleaning.fr.html#arranger-et-trier",
    "title": "8  Nettoyage de données et fonctions essentielles",
    "section": "8.13 Arranger et trier",
    "text": "8.13 Arranger et trier\nUtilisez la fonction dplyr arrange() pour trier ou ordonner les lignes par les valeurs des colonnes.\nListez simplement les colonnes dans l’ordre où elles doivent être triées. Spécifiez .by_group = TRUE si vous voulez que le tri se fasse d’abord par tout groupement appliqué aux données (voir la page sur Travailler sur des données groupées).\nPar défaut, les colonnes seront triées dans l’ordre “ascendant” (ce qui s’applique aux colonnes numériques et aussi aux colonnes de caractères). Vous pouvez trier une variable dans l’ordre “descendant” en l’entourant de desc().\nLe tri des données avec arrange() est particulièrement utile lorsque vous créez des Tableaux de présentation, lorsque vous utilisez slice() pour prendre les lignes “supérieures” par groupe, ou lorsque vous définissez l’ordre des niveaux de facteurs par ordre d’apparition.\nPar exemple, pour trier les lignes de notre linelist par hospital, puis par date_onset en ordre décroissant, nous utiliserons :\n\nlinelist %&gt;% \n   arrange(hospital, desc(date_onset))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nettoyage de données et fonctions essentielles</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html",
    "href": "new_pages/dates.fr.html",
    "title": "9  Manipuler les dates",
    "section": "",
    "text": "9.1 étapes préliminaires",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#étapes-préliminaires",
    "href": "new_pages/dates.fr.html#étapes-préliminaires",
    "title": "9  Manipuler les dates",
    "section": "",
    "text": "Importation des paquets\nCes lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\n# Vérifie si le paquet est installé, l'installe si nécessaire, et charge le paquet pour la session en cours.\n\npacman::p_load(\n  lubridate,  # paquet général pour la manipulation et la conversion des dates \n  parsedate,   # a une fonction pour \"deviner\" les dates désordonnées\n  aweek,      # une autre option pour convertir les dates en semaines, et les semaines en dates\n  zoo,        # fonctions supplémentaires de date et d'heure\n  here,       # gestion de fichiers\n  tidyverse,  # gestion et visualisation des données  \n  rio)        # import des fichiers\n\n\n\nImportation des données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour suivre le processus étape par étape, consultez les instructions de la page télécharger le manuel et les données. Pour ce script, nous supposons que le fichier se trouve dans le répertoire de travail de la session R. Aucun sous-dossier n’est donc spécifié dans ce chemin de fichier.\n\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#date-actuelle",
    "href": "new_pages/dates.fr.html#date-actuelle",
    "title": "9  Manipuler les dates",
    "section": "9.2 Date actuelle",
    "text": "9.2 Date actuelle\nVous pouvez obtenir la date ou l’heure “système” actuelle de votre ordinateur en effectuant les opérations suivantes avec base R.\n\n# obtenir la date du système - il s'agit d'une classe DATE\nSys.Date()\n\n[1] \"2024-05-08\"\n\n# obtenir l'heure du système - il s'agit d'une classe DATETIME\nSys.time()\n\n[1] \"2024-05-08 11:03:33 CEST\"\n\n\nAvec le paquet lubridate, la date et l’heure du système peuvent aussi être retournées avec today() et now(), respectivement. date() renvoie la date et l’heure actuelles avec les noms des jours de la semaine et du mois.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#convertir-en-date",
    "href": "new_pages/dates.fr.html#convertir-en-date",
    "title": "9  Manipuler les dates",
    "section": "9.3 Convertir en Date",
    "text": "9.3 Convertir en Date\nAprès avoir importé un ensemble de données dans R, les valeurs des colonnes de date peuvent ressembler à “1989/12/30”, “05/06/2014” ou “13 Jan 2020”. Dans ces cas, R traite probablement encore ces valeurs comme des valeurs de caractères. Il faut dire à R que ces valeurs sont des dates… et quel est le format de la date (quelle partie est le jour, le mois, l’année, etc.).\nUne fois informé, R convertit ces valeurs en classe Date. En arriére-plan de l’interface, R stockera les dates sous forme de nombres (le nombre de jours depuis sa date “d’origine”, le 1er janvier 1970). Vous n’utiliserez pas souvent le nombre de dates, mais cela permet à R de traiter les dates comme des variables continues. Cela permet également à R d’autoriser des opérations spéciales pour les objets Date, comme le calcul de la distance entre les dates.\nPar défaut, les valeurs de la classe Date dans R sont affichées sous la forme YYYY-MM-DD. Plus tard dans cette section, nous verrons comment modifier l’affichage des valeurs de date.\nNous présentons ci-dessous deux approches pour convertir une colonne de valeurs de caractères en classe Date.\n**__CONSEIL:_** Vous pouvez vérifier la classe actuelle d’une colonne avec la fonction R base class(), comme class(linelist$date_onset).\n\nbase R\nas.Date() est la fonction standard de base R pour convertir un objet ou une colonne en classe Date (notez la majuscule de “D”).\nL’utilisation de as.Date() nécessite que :\n\nVous spécifiez le format existant de la date brute en caractères ou la date d’origine si vous fournissez des dates en forme de nombres (voir la section sur les dates Excel).\n\nSi vous l’utilisez sur une colonne de caractères, toutes les valeurs de date doivent avoir le même format exact (si ce n’est pas le cas, essayez parse_date() du paquet parsedate)\n\nProcessus d’utilisation de as.Date() :\nPremiérement, vérifiez la classe de votre colonne avec class() de base R. Si vous n’étiez pas sûr de la classe ou sommes confus au sujet de la classe de vos données (par exemple, vous voyez “POSIXct”, etc.), il peut être plus facile de convertir d’abord la colonne en classe Character avec as.character(), et ensuite de la convertir en classe Date.\nDeuxiémement, dans la fonction as.Date(), utilisez l’argument format = pour indiquer à R le format actuel de la chaîne de caractères de la date - quels caractères font référence au mois, au jour et à l’année, et comment ils sont séparés. Si vos valeurs sont déjà dans un des formats de date standard de R (“YYYY-MM-DD” ou “YYYY/MM/DD”) l’argument format = n’est pas nécessaire.\nPour format =, fournissez une chaîne de caractères (entre guillemets) qui représente le format de date actuel en utilisant les abréviations spéciales “strptime” ci-dessous. Par exemple, si les dates de vos caractères sont actuellement au format “DD/MM/YYYY”, comme “24/04/1968”, vous utiliserez format = \"%d/%m/%Y\" pour convertir les valeurs en dates. Il est nécessaire de mettre le format entre guillemets. Et n’oubliez pas les barres obliques ou les tirets!\n\n# Convertir en classe de date\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))\n\nLa plupart des abréviations de strptime sont listées ci-dessous. Vous pouvez voir la liste compléte en exécutant ?strptime.\n%d = numéro du jour du mois (5, 17, 28, etc.)\n%j = numéro du jour de l’année (Jour 001-366)\n%a = Jour de la semaine abrégé (Lun, Mar, Mer, etc.)\n%A = Jour de la semaine (Lundi, Mardi, etc.) %w = numéro du jour de la semaine (0-6, le dimanche est 0)\n%u = numéro du jour de la semaine (1-7, le lundi est 1)\n%W = numéro de semaine(00-53, le lundi est le début de la semaine)\n%U = numéro de semaine (01-53, le dimanche est le début de la semaine)\n%m = numéro du mois (e.g. 01, 02, 03, 04)\n%b = Mois abrégé (jan, févr, etc.)\n%B = Mois complet (janvier, février, etc.)\n%y = année à 2 chiffres (par example 89)\n%Y = année à 4 chiffres (par example 1989)\n%h = heures (horloge de 24 heures)\n%m = minutes\n%s = secondes %z = décalage par rapport à GMT\n%Z = Fuseau horaire (caractère)\nCONSEIL: L’argument format = de la fonction as.Date() n’indique pas à R le format que vous voulez donner aux dates, mais plutôt comment identifier les parties de la date telles qu’elles sont avant que vous lanciez la commande.\nCONSEIL: Assurez-vous que dans l’argument format = vous utilisez le séparateur de partie de date (par exemple /, -, ou espace) qui est présent dans vos dates.\nUne fois que les valeurs sont dans la classe Date, R les affichera par défaut dans le format standard, qui est AAAA-MM-JJ.\n\n\nlubridate\nLa conversion d’objets caractères en dates peut être plus facile en utilisant le paquet lubridate. lubridate est un paquet tidyverse créé pour rendre le travail avec les dates et les heures plus simple et plus cohérent que dans base R. Pour ces raisons, lubridate est souvent considéré comme le paquet de référence pour les dates et les heures, et il est recommandé de travailler avec des variables de date ou d’heure.\nLe paquet lubridate fournit plusieurs fonctions d’aide différentes créées pour convertir les objets caractères en dates de maniére intuitive, et plus facile que de spécifier le format dans as.Date(). Ces fonctions sont spécifiques au format de date brut, mais permettent une variété de séparateurs et de synonymes pour les dates (par exemple 01 vs Jan vs Janvier) - les synonymes sont nommés d’après les abréviations des formats de date.\n\n# installez/chargez lubridate\npacman::p_load(lubridate)\n\nLa fonction ymd() convertit de maniére flexible les valeurs de date fournies sous la forme année, mois, jour. Cette fonction fonctionne avec n’importe quel séparateur utilisé dans les variables.\n\n# lire la date au format année-mois-jour\nymd(\"2020-10-11\")\n\n[1] \"2020-10-11\"\n\nymd(\"20201011\")\n\n[1] \"2020-10-11\"\n\n\nLa fonction mdy() convertit de maniére flexible les valeurs de date fournies sous la forme mois, jour, année.\n\n# lire la date au format mois-jour-année\nmdy(\"10/11/2020\")\n\n[1] \"2020-10-11\"\n\nmdy(\"Oct 11 20\")\n\n[1] \"2020-10-11\"\n\n\nLa fonction dmy() convertit de maniére flexible les valeurs de date fournies sous la forme jour, mois, année.\n\n# lire la date au format jour-mois-année\ndmy(\"11 10 2020\")\n\n[1] \"2020-10-11\"\n\ndmy(\"11 October 2020\")\n\n[1] \"2020-10-11\"\n\n\n\n\n\n\nSi vous utilisez le piping, la conversion d’une colonne de caractères en dates avec lubridate pourrait ressembler à ceci :\n\nlinelist &lt;- linelist %&gt;%\n  mutate(date_onset = lubridate::dmy(date_onset))\n\nUne fois terminé, vous pouvez exécuter class() pour vérifier la classe de la colonne\n\n#Vérifiez la classe de la colonne\nclass(linelist$date_onset)  \n\nUne fois que les valeurs sont dans la classe Date, R les affichera par défaut dans le format standard, qui est AAAA-MM-JJ.\nNotez que les fonctions ci-dessus fonctionnent mieux avec des années à 4 chiffres. Les années à 2 chiffres peuvent produire des résultats inattendus, car lubridate va deviner le siècle.\nPour convertir une année à 2 chiffres en une année à 4 chiffres (toutes dans le même siècle), vous pouvez convertir en caractères de classe, puis combiner les chiffres existants avec un préfixe en utilisant str_glue() du paquet stringr (voir la page Caractères et chaînes de caractères). Vous pouvez ensuite convertir la colonne en date.\n\ntwo_digit_years &lt;- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")\n\n2015\n2015\n2016\n2017\n\n\n\n\nCombine columns\nVous pouvez utiliser les fonctions lubridate make_date() et make_datetime() pour combiner plusieurs colonnes numériques en une seule colonne de date. Par exemple, si vous avez les colonnes numériques onset_day, onset_month, et onset_year dans le cadre de données linelist :\n\nlinelist &lt;- linelist %&gt;% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#dates-en-excel",
    "href": "new_pages/dates.fr.html#dates-en-excel",
    "title": "9  Manipuler les dates",
    "section": "9.4 Dates en Excel",
    "text": "9.4 Dates en Excel\nEn arriére-plan, la plupart des logiciels stockent les dates sous forme de nombres. R stocke les dates à partir du 1er janvier 1970. Ainsi, si vous exécutez as.numeric(as.Date(\"1970-01-01)) vous obtiendrez 0.\nMicrosoft Excel enregistre les dates à partir du 30 décembre 1899 (Windows) ou du 1er janvier 1904 (Mac), selon votre système d’exploitation. Consultez ce guide Microsoft pour plus d’informations.\nLes dates d’Excel sont souvent importées dans R sous la forme de ces valeurs numériques plutôt que sous la forme de caractères. Si le jeu de données que vous avez importé d’Excel montre des dates sous forme de nombres ou de caractères comme “41369”… utilisez la fonction as.Date() (ou la fonction as_date() de lubridate) pour convertir, mais au lieu de fournir un “format” comme ci-dessus, fournissez la date d’origine Excel à l’argument origin = dans la fonction.\nCela ne fonctionnera pas si la date Excel est stockée dans R comme un type de caractère, donc assurez-vous que le nombre est de classe Numérique!\nNOTE: Vous devez fournir la date d’origine dans le format de date par défaut de R (“YYYY-MM-DD”).\n\n# Un exemple de fourniture de la \"date d'origine\" d'Excel lors de la conversion de dates numériques d'Excel.\ndata_cleaned &lt;- data %&gt;% \n  mutate(date_onset = as.numeric(date_onset)) %&gt;%   # ensure class is numeric\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convert to date using Excel origin",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#dates-désordonnées",
    "href": "new_pages/dates.fr.html#dates-désordonnées",
    "title": "9  Manipuler les dates",
    "section": "9.5 Dates désordonnées",
    "text": "9.5 Dates désordonnées\nVous pouvez utiliser la fonction parse_date() du paquet parsedate pour lire une colonne de date “désordonnée” qui contient des dates dans de nombreux formats différents et convertir les dates dans un format standard. Vous pouvez en savoir plus en ligne sur parse_date().\nPar exemple, parse_date lira un vecteur des dates en caractères suivantes : “03 Jan 2018”, “07/03/1982”, et “08/20/85” et les convertira en classe Date sous la forme de : 2018-01-03, 1982-03-07, et 1985-08-20.\n\nparsedate::parse_date(c(\"03 January 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))\n\n[1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n\n\n\n# Un exemple d'utilisation de parse_date() sur la colonne date_onset\nlinelist &lt;- linelist %&gt;%                 # le dataframe s'appelle linelist, à ne pas confondre avec le paquet \"linelist\"\n  mutate(\n    date_onset = parse_date(date_onset))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#travailler-avec-la-classe-date-heure",
    "href": "new_pages/dates.fr.html#travailler-avec-la-classe-date-heure",
    "title": "9  Manipuler les dates",
    "section": "9.6 Travailler avec la classe date-heure",
    "text": "9.6 Travailler avec la classe date-heure\nComme nous l’avons déjà mentionné, R supporte également une classe datetime - une colonne qui contient des informations de date et d’heure. Comme pour la classe Date, il faut souvent convertir les objets caracter en objets datetime.\n\nConvertir des dates avec des heures\nUn objet datetime standard est formaté avec la date en premier, qui est suivie par une entrée de temps - par exemple 01 Jan 2020, 16:30. Comme pour les dates, il existe de nombreuses façons de formater cet objet. Il existe de nombreux niveaux de précision (heures, minutes, secondes) qui peuvent être fournis à un objet “datetime”.\nIl existe des fonctions du paquet lubridate pour aider à convertir ces chaînes en objets datetime. Ces fonctions sont des extensions des fonctions d’aide de date, avec _h (seulement les heures fournies), _hm (heures et minutes fournies), ou _hms (heures, minutes et secondes fournies) ajoutées à la fin (par exemple, dmy_hms()). Ils peuvent être utilisês comme indiqué :\nConvertir une date avec seulement des heures en objet datetime\n\nymd_h(\"2020-01-01 16hrs\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\nymd_h(\"2020-01-01 4PM\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\n\nConverter une date avec des heures et des minutes en objet datetime.\n\ndmy_hm(\"01 Janvier 2020 16:20\")\n\nWarning: All formats failed to parse. No formats found.\n\n\n[1] NA\n\n\nConverrtir une date avec des heures, des minutes et des secondes en un objet de type datetime.\n\nmdy_hms(\"01 Janvier 2020, 16:20:40\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nVous pouvez fournir le fuseau horaire mais il est ignoré par la fonction. Allez à la section plus bas dans le chapitre pour en savoir plus sur les fuseaux horaires dans R.\n\nmdy_hms(\"01 Janvier 2020, 16:20:40 PST\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nAvec un dataframe chargé dans R, les colonnes d’heure et de date peuvent être combinées pour créer une colonne de date en utilisant la fonction str_glue() du paquet stringr et la fonction appropriée du paquet lubridate, selon le format de date et d’heure dans le dataframe. Voir la page caractères et chaînes de caractères pour plus de détails sur stringr.\nDans cet exemple, le dataframe linelist a une colonne au format “heures:minutes”. Pour la convertir en date, nous suivons quelques étapes :\n\nVous créez une colonne de temps d’admission “propre” avec les valeurs manquantes remplies avec la médiane de la colonne. Nous faisons cela parce que lubridate ne fonctionne pas sur les valeurs manquantes. Combinez la nouvelle colonne avec la colonne date_hospitalisation, puis utilisez la fonction ymd_hm() pour convertir en objet datetime.\n\n\n# packages\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission est une colonne en heures:minutes\nlinelist &lt;- linelist %&gt;%\n  \n#si l'heure d'admission n'est pas donnée, attribuez l'heure d'admission médiane.\n\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # si l'heure est manquante\n      median(time_admission),          # assigner la médiane\n      time_admission                   # si elle n'est pas manquante, la garder telle quelle\n  ) %&gt;%\n  \n    # Utilisez str_glue() pour combiner les colonnes de date et d'heure afin de créer une colonne de caractères.\n    # puis utiliser ymd_hm() pour la convertir en classe datetime\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %&gt;% \n      ymd_hm()\n  )\n\n\n\nConvertir uniquement les temps\nSi vos données ne contiennent qu’un caractère temps (heures et minutes), vous pouvez les convertir et les manipuler comme des temps en utilisant la fonction strptime() de base R. Par exemple, pour obtenir la différence entre deux temps :\n\n# temps comme objets de caractère\ntime1 &lt;- \"13:45\" \ntime2 &lt;- \"15:20\"\n\n# temps converties en une classe de datetime\ntime1_clean &lt;- strptime(time1, format = \"%H:%M\")\ntime2_clean &lt;- strptime(time2, format = \"%H:%M\")\n\n# La différence est de classe \"difftime\" par défaut, ici convertie en heures numériques. \nas.numeric(time2_clean - time1_clean)   # différence en heures\n\n[1] 1.583333\n\n\nNotez cependant que si aucune valeur de date n’est fournie, la fonction suppose que la date est aujourd’hui. Pour combiner une chaîne de date et une chaîne d’heure, voyez comment utiliser stringr dans la section juste au-dessus. Pour en savoir plus sur strptime() ici.\nPour convertir des nombres à un chiffre en nombres à deux chiffres (par exemple, pour ajouter des zéros aux heures ou aux minutes afin d’obtenir deux chiffres), consultez la section “Longueur des caractères” de la page caractères et chaînes de caractères.\n\n\nExtraction d’éléments du temps\nVous pouvez extraire des éléments du temps avec hour(), minute(), ou second() du paquet lubridate.\nVoici un exemple d’extraction de l’heure, puis de classement par partie de la journée. Nous commençons par la colonne time_admission, qui est dans la classe Character au format “HH:MM”. D’abord, la fonction strptime() est utilisêe comme décrit ci-dessus pour convertir les caractères en classe datetime. Ensuite, l’heure est extraite avec hour(), retournant un nombre de 0-24. Enfin, une colonne time_period est crée en utilisant la logique de case_when() pour classer les lignes en Matin/Après-midi/Soir/Nuit en fonction de leur heure d’admission.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %&gt;%\n  mutate(time_period = case_when(\n    hour_admit &gt; 06 & hour_admit &lt; 12 ~ \"Matin\",\n    hour_admit &gt;= 12 & hour_admit &lt; 17 ~ \"Après-midi\",\n    hour_admit &gt;= 17 & hour_admit &lt; 21 ~ \"Soir\",\n    hour_admit &gt;=21 | hour_admit &lt;= 6 ~ \"Nuit\"))\n\nPour en savoir plus sur la fonction case_when(), consultez la page Nettoyage des données et des fonctions de base.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#travailler-avec-des-dates",
    "href": "new_pages/dates.fr.html#travailler-avec-des-dates",
    "title": "9  Manipuler les dates",
    "section": "9.7 Travailler avec des dates",
    "text": "9.7 Travailler avec des dates\nLe paquet lubridate peut également être utilisê pour une variété d’autres fonctions, telles que l’extraction d’aspects d’une date/heure, l’exécution d’arithmétique pour les dates, ou le calcul d’intervalles de dates.\nNous définissons ici une date à utiliser dans les exemples :\n\n# créer un objet de la classe Date\nexample_date &lt;- ymd(\"2020-03-01\")\n\n\nExtraire les composants de la date\nVous pouvez extraire des aspects communs commes le mois, le jour, le jour de la semaine :\n\nmonth(example_date) # numéro du mois\n\n[1] 3\n\nday(example_date) # jour (numéro) du mois\n\n[1] 1\n\nwday(example_date) # numéro du jour de la semaine (1-7)\n\n[1] 1\n\n\nVous pouvez également extraire les composants temporels d’un objet ou d’une colonne en classe datetime. Cela peut être utile si vous voulez visualiser la distribution des temps d’admission.\n\nexample_datetime &lt;- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime) # extraire l'heure\nminute(example_datetime) # extrait la minute\nsecond(example_datetime) # extrait les secondes\n\nIl existe plusieurs options pour récupérer les semaines. Lisez la section sur les semaines épidémiologiques ci-dessous pour en savoir plus.\nNotez que si vous cherchez à afficher une date d’une certaine maniére (par exemple “Jan 2020” ou “Jeudi 20 mars” ou “Semaine 20, 1977”), vous pouvez le faire assez facilement en utilisant les méthodes décrites dans la section sur l’affichage des dates.\n\n\nMathématiques de dates\nVous pouvez ajouter certains nombres de jours ou de semaines en utilisant leur fonction respective du paquet lubridate.\n\n# ajouter 3 jours à cette date\nexample_date + days(3)\n\n[1] \"2020-03-04\"\n\n# ajoute 7 semaines et soustrait deux jours à cette date\nexample_date + weeks(7) - days(2)\n\n[1] \"2020-04-17\"\n\n\n\n\nIntervalles entre les dates\nLa différence entre les dates peut être calculée par :\n\nAssurez-vous que les deux dates sont de la classe Date\n\nUtilisez la soustraction pour obtenir la différence “difftime” entre les deux dates.\n\nSi nécessaire, convertissez le résultat en classe numérique pour effectuer les calculs mathématiques suivants.\n\nCi-dessous, l’intervalle entre deux dates est calculé et affiché. Vous pouvez trouver des intervalles en utilisant le symbole “moins” de la soustraction sur des valeurs de la classe Date. Notez que la classe de la valeur retournée est “difftime” comme affiché ci-dessous, et doit être convertie en classe numérique.\n\n# trouver l'intervalle entre example_date et le 20 février 2020 \noutput &lt;- example_date - ymd(\"2020-02-20\")\noutput    # imprimer\n\nTime difference of 10 days\n\nclass(output)\n\n[1] \"difftime\"\n\n\nPour effectuer d’autres opérations sur un objet de classe “difftime”, convertissez-le en numérique avec la fonction as.numeric().\nTout ceci peut être rassemblé pour travailler avec des données - par exemple :\n\npacman::p_load(lubridate, tidyverse) # charger les paquets\n\nlinelist &lt;- linelist %&gt;% # conversion de la date d'apparition en caractères\n  \n  # convertir la date d'apparition de objets caractères en objets date en spécifiant le format dmy\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %&gt;%\n  \n  # filtre tous les cas dont la date d'apparition n'est pas en mars\n  filter(month(date_onset) == 3) %&gt;% # filtrer tous les cas sans apparition en mars\n    \n  # trouver la différence en jours entre l'apparition et l'hospitalisation pour tous les cas\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n\nDans le dataframe, si l’une des dates ci-dessus est manquante, l’opération échouera pour cette ligne. Il en résultera un NA au lieu d’une valeur numérique. Lorsque vous utilisez cette colonne pour des calculs, assurez-vous de mettre l’argument na.rm = à TRUE (vrai). Par exemple :\n\n# Calculez le nombre médian de jours d'hospitalisation pour tous les cas pour lesquels des données sont disponibles.\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#affichage-des-dates",
    "href": "new_pages/dates.fr.html#affichage-des-dates",
    "title": "9  Manipuler les dates",
    "section": "9.8 Affichage des dates",
    "text": "9.8 Affichage des dates\nUne fois que les dates ont la bonne classe, vous voudrez peut-être qu’elles s’affichent différemment, par exemple qu’elles s’affichent comme “Lundi 05 Janvier” au lieu de “2018-01-05”. Vous pouvez aussi vouloir ajuster l’affichage afin de regrouper ensuite les lignes en fonction des éléments de date affichés - par exemple pour regrouper par mois-année.\n\nformat()\nAjustez l’affichage de la date avec la fonction format() de base R. Cette fonction accepte une chaîne de caractères (entre guillemets) spécifiant le format final souhaité dans les abréviations “%” strptime (la même syntaxe que celle utilisêe dans la fonction as.Date()). Vous trouverez ci-dessous la plupart des abréviations courantes.\nNOTE: l’’utilisation de format() convertira les valeurs dans la classe Character, donc cette fonction est généralement utilisêe vers la fin d’une analyse ou uniquement pour l’affichage ! Vous pouvez voir la liste complète en exécutant ?strptime.\n%d = numéro du jour du mois (5, 17, 28, etc.)\n%j = numéro du jour de l’année (Jday 001-366)\n%a = Jour de la semaine abrégé (lun, mar, mer, etc.)\n%A = Jour de la semaine complet (lundi, mardi, etc.)\n%w = numéro du jour de la semaine (0-6, le dimanche est 0)\n%u = numéro du jour de la semaine (1-7, le lundi est 1)\n%W = numéro de la semaine (00-53, le lundi est le début de la semaine)\n%U = numéro de la semaine (01-53, le dimanche est le début de la semaine)\n%m = numéro du mois (par exemple 01, 02, 03, 04)\n%b = Mois abrégé (Jan, Feb, etc.)\n%B = Mois complet (janvier, février, etc.)\n%y = année à 2 chiffres (ex. 89)\n%Y = année à 4 chiffres (ex. 1989)\n%h = heures (horloge de 24 heures)\n%m = minutes\n%s = secondes\n%z = décalage par rapport à GMT\n%Z = Fuseau horaire (caractère)\nUn exemple de formatage de la date du jour:\n\n# date du jour, avec formatage\nformat(Sys.Date(), format = \"%d %B %Y\")\n\n[1] \"08 May 2024\"\n\n# moyen simple d'obtenir la date et l'heure complètes (formatage par défaut)\ndate()\n\n[1] \"Wed May  8 11:03:35 2024\"\n\n# formatage de la date, de l'heure et du fuseau horaire combinés ensemble avec la fonction str_glue()\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")\n\nWednesday, May 08 2024, +0000 UTC, 11:03:35\n\n#Utilisation du formatage pour afficher les semaines\nformat(Sys.Date(), \"%Y Week %W\")\n\n[1] \"2024 Week 19\"\n\n\nNotez que si vous utilisez la fonction str_glue(), sachez qu’à l’intérieur des guillemets doubles ” vous ne devez utiliser que des guillemets simples (comme ci-dessus).\n\n\nMois-année\nPour convertir une colonne de date au format mois-année, nous vous suggérons d’utiliser la fonction as.yearmon() du paquet zoo. Cette fonction convertit la date en classe “yearmon” et conserve l’ordre correct. En revanche, l’utilisation de la fonction format(colonne, \"%Y %B\") convertira la date en classe caractère et classera les valeurs par ordre alphabétique (de maniére incorrecte).\nCi-dessous, une nouvelle colonne yearmonth est créée à partir de la colonne date_onset, en utilisant la fonction as.yearmon(). L’ordre par défaut (correct) des valeurs résultantes est indiqué dans le tableau.\n\n# créer une nouvelle colonne \ntest_zoo &lt;- linelist %&gt;% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# imprimer le tableau\ntable(test_zoo$yearmon)\n\n\nApr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 \n       7       64      100      226      528     1070     1112      763 \nDec 2014 Jan 2015 Feb 2015 Mar 2015 Apr 2015 \n     562      431      306      277      186 \n\n\nEn revanche, vous pouvez voir comment la seule utilisation de format() permet d’obtenir le format d’affichage souhaité, mais pas l’ordre correct.\n\n# créer une nouvelle colonne\ntest_format &lt;- linelist %&gt;% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# imprimer le tableau\ntable(test_format$yearmon)\n\n\nApr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 \n       7      186      528      562      306      431      226      100 \nMar 2015 May 2014 Nov 2014 Oct 2014 Sep 2014 \n     277       64      763     1112     1070 \n\n\nNote : si vous travaillez dans un ggplot() et vous voulez ajuster la façon dont les dates sont affichées uniquement, il peut être suffisant de fournir un format strptime à l’argument date_labels = dans scale_x_date() - vous pouvez utiliser \"%b %Y\" ou \"%Y %b\". Consultez la page Astuces de ggplot pour une explication plus approfondie.\nAlternativement, le paquet zoo posséde la fonction as.yearqtr(), et vous pouvez utiliser scale_x_yearmon() lorsque vous utilisez ggplot() pour ajuster la façon dont les dates sont affichées sur le graphique.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#dates_epi_wks",
    "href": "new_pages/dates.fr.html#dates_epi_wks",
    "title": "9  Manipuler les dates",
    "section": "9.9 Semaines épidémiologiques",
    "text": "9.9 Semaines épidémiologiques\n\nlubridate\nConsultez la page Regroupement de données pour des exemples plus complets de regroupement de données par date. Ci-dessous, nous décrivons briévement le regroupement des données par semaine.\nNous recommandons généralement d’utiliser la fonction floor_date() du package lubridate, avec l’argument unit = \"week\". Cela arrondit la date au “début” de la semaine, comme défini par l’argument week_start =. Le début de semaine par défaut est 1 (pour les lundis) mais vous pouvez spécifier n’importe quel jour de la semaine comme début (par exemple 7 pour les dimanches). floor_date() est polyvalent et peut être utilisê pour arrondir à d’autres unités de temps en définissant unit = à “seconde”, “minute”, “heure”, “jour”, “mois” ou “année”.\nLa valeur retournée est la date de début de la semaine, dans la classe Date. La classe Date est utile pour tracer les données, car elle est ordonnée correctement et elle sera facilement reconnue par ggplot().\nSi vous êtes seulement intéressé par l’ajustement des dates pour afficher par semaine dans un graphique, voyez la section de ce chapitre sur l’affichage des dates. Par exemple, lorsque vous tracez une épicurve, vous pouvez formater l’affichage de la date en fournissant la nomenclature strptime “%” désirée. Par exemple, utilisez “%Y-%W” ou “%Y-%U” pour spécifier l’année et le numéro de semaine (respectivement le lundi ou le dimanche en début de semaine).\n\n\nComptages hebdomadaires\nAllez à la page Regroupement des données pour une explication détaillée du regroupement des données avec count(), group_by(), et summarise(). Voici un bref exemple.\n\ncréez une nouvelle colonne ‘semaine’ avec mutate(), en utilisant floor_date() avec unit = \"week\".\n\nObtenez le nombre de lignes (cas) par semaine avec count() ; filtrez les cas dont la date est manquante.\n\nTerminez avec complete() du paquet tidyr pour vous assurer que toutes les semaines apparaissent dans les données - même celles qui n’ont pas de lignes/cas. Par défaut, les valeurs de comptage pour toutes les “nouvelles” lignes sont NA, mais vous pouvez les rendre 0 avec l’argument fill =, qui attend une liste nommée (ci-dessous, n est le nom de la colonne de comptage).\n\n\n# créez un jeu de données agrégé des comptes hebdomadaires de cas.\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%             # Suppression des cas pour lesquels il manque la date de début de la maladie\n  mutate(weekly_cases = floor_date(   # créer une nouvelle colonne, semaine d'apparition du cas\n    date_onset,\n    unit = \"week\")) %&gt;%            \n  count(weekly_cases) %&gt;%           # grouper les données par semaine et compter les lignes par groupe (crée la colonne 'n')\n  tidyr::complete(                  # Assurez-vous que toutes les semaines sont présentes, même celles où aucun cas n'a été observé.\n    weekly_cases = seq.Date(          # definir la colonne \"weekly_cases\" comme une séquence complète\n      from = min(weekly_cases),       # à partir de la date minimum\n      to = max(weekly_cases),         # jusqu'à la date maximale\n      by = \"week\"),                   # agrégé par semaines\n    fill = list(n = 0))             # Remplir les NA dans la colonne des comptes n avec 0\n\nVoici les premiéres lignes du jeu de données résultant :\n\n\n\n\n\n\n\n\ndifférentes méthodes pour les epiweeks\nNotez que le paquet lubridate posséde des fonctions alternatives week(), epiweek(), et isoweek(), dont chacune a des dates de début légérement différentes et d’autres nuances. De maniére générale, floor_date() devrait suffire à vos besoins. Pour en savoir plus sur ces fonctions, entrez ?week dans la console ou lisez la documentation ici.\nVous pouvez également utiliser le paquet aweek pour définir les semaines épidémiologiques. Vous pouvez en savoir plus sur le paquet aweek sur le site de RECON. aweek contient les fonctions date2week() et week2date() dans lesquelles vous pouvez définir le jour de début de semaine avec week_start = \"Monday\". aweek est le plus simple si vous voulez spécifier vos dates sous forme de numéro de semaine (par exemple “2020-W12”). Un autre avantage du package aweek est que lorsque date2week() est appliqué à une colonne de date, la colonne retournée (format de semaine) est automatiquement de la classe Factor et inclut les niveaux de toutes les semaines de l’intervalle de temps (cela évite l’étape supplémentaire de complete() décrite ci-dessus). Cependant, aweek n’a pas la fonctionnalité d’arrondir les dates à d’autres unités de temps comme les mois, les années, etc.\nUne autre alternative pour les séries temporelles qui fonctionne également bien pour afficher un format “semaine” (“2020 W12”) est yearweek() du paquet tsibble, comme démontré dans la page sur Série temporelle et détection des épidémies.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#conversion-des-datesfuseaux-horaires",
    "href": "new_pages/dates.fr.html#conversion-des-datesfuseaux-horaires",
    "title": "9  Manipuler les dates",
    "section": "9.10 Conversion des dates/fuseaux horaires",
    "text": "9.10 Conversion des dates/fuseaux horaires\nLorsque des données sont présentes dans différents fuseaux horaires, il peut souvent être important de standardiser ces données dans un fuseau horaire unifié. Cela peut présenter un défi supplémentaire, car la l’élément fuseau horaire des données doit être codée manuellement dans la plupart des cas.\nDans R, chaque objet datetime posséde un élément fuseau horaire. Par défaut, tous les objets datetime portent le fuseau horaire local de l’ordinateur utilisê - ce fuseau est généralement spécifique à une localisation plutôt qu’à un fuseau horaire nommé, car les fuseaux horaires changent souvent en fonction de l’heure d’été. Il n’est pas possible de compenser avec précision les fuseaux horaires sans la composante temporelle d’une date, car l’événement que représente une colonne de date ne peut être attribué à une heure spécifique, et les décalages horaires mesurés en heures ne peuvent donc pas être raisonnablement pris en compte.\nPour définir des fuseaux horaires différents, il existe un certain nombre de fonctions dans le paquet lubridate qui peuvent être utilisêes pour changer le fuseau horaire d’un objet datetime du fuseau horaire local à un fuseau horaire différent. Les fuseaux horaires sont définis en attribuant un fuseau horaire valide de la base de données tz à l’objet datetime. Une liste de ces fuseaux est disponible ici - si le lieu dont vous utilisez les données ne figure pas sur cette liste, les grandes villes voisines dans le fuseau horaire sont disponibles et servent le même objectif.\nhttps://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n\n# Assignez l'heure actuelle à une colonne \ntime_now &lt;- Sys.time()\ntime_now\n\n[1] \"2024-05-08 11:03:35 CEST\"\n\n# utilisez with_tz() pour affecter un nouveau fuseau horaire à la colonne, tout en CHANGEANT l'heure de l'horloge\ntime_london_real &lt;- with_tz(time_now, \"Europe/London\")\n\n# Utilisez force_tz() pour assigner un nouveau fuseau horaire à la colonne, tout en conservant l'heure de l'horloge.\ntime_london_local &lt;- force_tz(time_now, \"Europe/London\")\n\n\n# notez que tant que l'ordinateur qui a été utilisê pour exécuter ce code n'est PAS réglé sur l'heure de Londres,\n# il y aura une différence dans les heures \n# (le nombre d'heures de différence entre le fuseau horaire de l'ordinateur et l'heure de Londres)\ntime_london_real - time_london_local\n\nTime difference of -1 hours\n\n\nCela peut sembler largement abstrait, et n’est souvent pas nécessaire si l’utilisateur ne travaille pas sur plusieurs fuseaux horaires.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#calculs-de-décalage-et-davance",
    "href": "new_pages/dates.fr.html#calculs-de-décalage-et-davance",
    "title": "9  Manipuler les dates",
    "section": "9.11 Calculs de décalage et d’avance",
    "text": "9.11 Calculs de décalage et d’avance\nlead() et lag() sont des fonctions du paquet dplyr qui aident à trouver les valeurs précédentes (décalées) ou suivantes (en avance) dans un vecteur - généralement pour un vecteur numérique ou de date. Ces fonctions sont utiles pour calculer les changements/différences entre les unités de temps.\nSupposons que vous vouliez calculer la différence de cas entre la semaine en cours et la semaine précédente. Les données sont initialement fournies en nombre de cas hebdomadaires, comme indiqué ci-dessous.\n\n\n\n\n\n\nLorsque vous utilisez lag() ou lead(), l’ordre des lignes dans le dataframe est très important ! - Faites attention à ce que vos dates/chiffres soient ascendants ou descendants.\nLa premiére étape consiste à créer une nouvelle colonne contenant la valeur de la semaine précédente (décalée).\n\nContrôlez le nombre d’unités en arriére/en avant avec n = (doit être un integer non-négatif)\n\nUtilisez default = pour définir la valeur placée dans les lignes inexistantes (par exemple, la premiére ligne pour laquelle il n’y a pas de valeur décalée). Par défaut, c’est NA.\n\nUtilisez order_by = TRUE si vos lignes ne sont pas ordonnées par votre colonne de référence.\n\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\n\n\n\n\n\n\n\nL’étape suivante consiste à créer une nouvelle colonne qui est la différence entre les deux colonnes de cas :\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)\n\n\n\n\n\n\n\nVous pouvez en savoir plus sur lead() et lag() dans la documentation ici ou en entrant ?lag dans votre console.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.fr.html#ressources",
    "href": "new_pages/dates.fr.html#ressources",
    "title": "9  Manipuler les dates",
    "section": "9.12 Ressources",
    "text": "9.12 Ressources\nlubridate tidyverse page\nlubridate RStudio cheatsheet\nR for Data Science page on dates and times\nOnline tutorial Date formats",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Manipuler les dates</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html",
    "href": "new_pages/characters_strings.fr.html",
    "title": "10  Caractères et chaînes de caractères",
    "section": "",
    "text": "10.1 Preparation",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#preparation",
    "href": "new_pages/characters_strings.fr.html#preparation",
    "title": "10  Caractères et chaînes de caractères",
    "section": "",
    "text": "Charger les paquets\nInstallez ou chargez le paquet stringr et d’autres paquets de tidyverse.\n\n# installer/charger les paquets\npacman::p_load(\n  stringr,    # de nombreuses fonctions pour la manipulation des chaînes de caractères\n  tidyverse,  # pour diverses options de manipulation des données \n  tools)      # alternative pour la conversion en majuscules\n\n\n\nImportation de données\nDans cette page, il y aura parfois des références à la linelist (liste de cas ou liste linéaire) nettoyée des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre les exemples dans votre propre script, cliquez ici pour télécharger la “linelist” nettoyée (as .rds file). Importez les données avec la fonction import() du paquet rio (la fonction import() peut être utilisée pour importer plusieurs types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# importez la linelist de cas\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premiéres lignes de la linelist (liste linéaire ou liste de cas) sont affichées ci-dessous.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#unir-séparer-et-arranger",
    "href": "new_pages/characters_strings.fr.html#unir-séparer-et-arranger",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.2 Unir, séparer et arranger",
    "text": "10.2 Unir, séparer et arranger\nCette section couvre :\n\nUtilisation de str_c(), str_glue() et unite() pour combiner des chaînes de caractères.\n\nUtiliser str_order() pour organiser des chaînes de caractères.\n\nUtiliser str_split() et separate() pour séparer des chaînes de caractères.\n\n\n\nCombiner des chaînes de caractères\nPour combiner ou concaténer plusieurs chaînes de caractères en une seule chaîne, nous suggérons d’utiliser la fonction str_c() du paquet stringr. Si vous avez des valeurs de caractères distinctes à combiner, fournissez-les simplement comme arguments uniques, séparés par des virgules.\n\nstr_c(\"String1\", \"String2\", \"String3\")\n\n[1] \"String1String2String3\"\n\n\nL’argument sep = insére une valeur de caractère entre chacun des arguments que vous avez fournis (par exemple, fournir une virgule, un espace ou une nouvelle ligne insérerait ce caractère entre chaque argument \"\\n\")\n\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")\n\n[1] \"String1, String2, String3\"\n\n\nL’argument collapse = est pertinent si vous mettez plusieurs vecteurs comme arguments à str_c(). L’argument collapse = est utilisé pour séparer les éléments inclus dans le vecteur produit par str_c(), où le vecteur produit est un long vecteur de type caractère.\nL’exemple ci-dessous montre la combinaison de deux vecteurs en un seul vecteur (prénoms et noms de famille). Un autre exemple similaire pourrait être montré avec des régions et le nombre de cas dans chaque région. Dans cet exemple :\n\nLa valeur sep = apparaît entre chaque prénom et chaque nom.\n\nLa valeur collapse = apparaît entre chaque personne.\n\n\nfirst_names &lt;- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  &lt;- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep s'affiche entre les chaînes de caractères d'entrée respectives, tandis que collapse s'affiche entre les éléments produits\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")\n\n[1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n\n\nRemarque: Selon le contexte d’affichage souhaité, lorsque vous imprimez une telle chaîne combinée avec des nouvelles lignes, vous devrez peut-être envelopper la phrase entière dans cat() pour que les nouvelles lignes s’impriment correctement:\n\n# Pour que les nouvelles lignes s'impriment correctement, il peut être nécessaire d'envelopper la phrase dans cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))\n\nabdul hussein;\nfahruk akinleye;\njanice okeke\n\n\n\n\n\nChaînes de caractères dynamiques\nUtilisez la fonction str_glue() pour insérer du code R dynamique dans une chaîne de caractères. C’est une fonction trés utile pour créer des légendes de graphiques dynamiques, comme démontré ci-dessous.\n\nTout le contenu est placé entre guillemets doubles comme ceci str_glue(\"\").\n\nTout code dynamique ou référence à des valeurs prédéfinies est placé entre des accolades {} à l’intérieur des guillemets doubles. Il peut y avoir plusieurs accolades dans la même commande de str_glue().\n\nPour afficher les guillemets de caractères ’’, utilisez des guillemets simples entre les guillemets doubles (par exemple, pour le format de date - voir l’exemple ci-dessous).\n\nConseil : Vous pouvez utiliser \\n pour forcer une nouvelle ligne.\n\nConseil : Vous pouvez utiliser format() pour ajuster l’affichage de la date, et utiliser Sys.Date() pour afficher la date actuelle.\n\nUn exemple simple, d’une légende d’un graphique dynamique :\n\nstr_glue(\"Les données incluent {nrow(linelist)} cas et sont actuelles à {format(Sys.Date(), '%d %b %Y')}.\")\n\nLes données incluent 5888 cas et sont actuelles à 08 May 2024.\n\n\nUn format alternatif consiste à utiliser des caractères de remplacement à l’intérieur des parenthèses et à définir le code dans des arguments séparés à la fin de la fonction str_glue(), comme ci-dessous. Cela peut améliorer la lisibilité du code si le texte est long.\n\nstr_glue(\"Linelist à la {current_date}.\\nDernier cas hospitalisé à l'hôpital {last_hospital}.\\n{n_missing_onset} cas n'ont pas de date d'apparition et ne sont pas représentés.\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %&gt;% filter(is.na(date_onset)))\n         )\n\nLinelist à la 08 May 2024.\nDernier cas hospitalisé à l'hôpital 30 Apr 2015.\n256 cas n'ont pas de date d'apparition et ne sont pas représentés.\n\n\nExtraction d’un dataframe\nIl est parfois utile d’extraire des données d’un dataframe et de les coller ensemble en séquence.Vous trouverez ci-dessous un exemple de dataframe comprenant la juridiction (zone), les nouvelles affaires et les affaires totales. Nous allons l’utiliser pour faire une description résumée du nombre de nouveaux cas et du nombre total de cas par juridiction.\n\n# créer un dataframe de cas\ncase_table &lt;- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\n\n\n\n\n\n\n\nUtilisez la fonction str_glue_data(), qui est spécifiquement utilisée pour prendre des données à partir des lignes du dataframe:\n\ncase_table %&gt;% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")\n\nZone 1: 3 (40 total cases)\nZone 2: 0 (4 total cases)\nZone 3: 7 (25 total cases)\nZone 4: 0 (10 total cases)\nZone 5: 15 (103 total cases)\n\n\nCombinaison des chaînes de caractères entre les lignes\nSi vous essayez “d’enrouler” des valeurs dans une colonne d’un dataframe, c’est-à-dire de combiner des valeurs de plusieurs lignes en une seule ligne en les collant ensemble avec un séparateur. Consultez la section de la page Deduplication sur les valeurs “enroulées”.\nDataframe combiné en une seule ligne\nVous pouvez faire apparaêtre la description résumée sur une seule ligne en utilisant str_c() (en spécifiant le dataframe et les noms des colonnes), et en fournissant les arguments sep = et collapse =.\n\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")\n\n[1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\nVous pouvez ajouter le pré-fixe “New Cases :” (nouveaux cas en français) au début de la description en l’entourant d’une str_c() distincte (si “New Cases :” se trouvait dans la `str_c()``, il apparaîtrait plusieurs fois).\n\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))\n\n[1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\n\n\nUnir les colonnes\nDans un cadre de données, le regroupement des valeurs de caractères de plusieurs colonnes peut être réalisé avec la fonction unite() du paquet tidyr. C’est l’inverse de la fonction separate().\nVous devez fournir le nom de la nouvelle colonne unie et ensuite fournir les noms des colonnes que vous souhaitez unir.\n\nPar défaut, le séparateur utilisé dans la colonne unie est le caractère de soulignement _, mais cela peut être changé avec l’argument sep =.\n\nL’argument remove = supprime les colonnes qui seront unies du dataframe (VRAI par défaut).\n\nL’argument na.rm = supprime les valeurs manquantes lors de l’unification (FAUX par défaut)\n\nCi-dessous, nous définissons un mini dataframe pour la démonstration:\n\ndf &lt;- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # patient 1\n                \"chills, aches, pains\",        # patient 2 \n                \"fever\",                       # patient 3\n                \"vomiting, diarrhoea\",         # patient 4\n                \"bleeding from gums, fever\",   # patient 5\n                \"rapid pulse, headache\"),      # patient 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\n\n\ndf_split &lt;- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")\n\nWarning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\n\n\nVoici l’exemple avec le dataframe dessus:\n\n\n\n\n\n\nCi-dessous, nous réunissons les trois colonnes de symptômes:\n\ndf_split %&gt;% \n  unite(\n    col = \"all_symptoms\", # nom de la nouvelle colonne unie\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # colonnes à unir\n    sep = \", \", # séparateur à utiliser dans la colonne unie\n    remove = TRUE, # si TRUE (VRAI), supprime les colonnes d'entrée du dataframe\n    na.rm = TRUE # Si TRUE (VRAI), les valeurs manquantes sont supprimées avant l'unification.\n  )\n\n  case_ID                all_symptoms outcome\n1       1     jaundice, fever, chills Recover\n2       2        chills, aches, pains   Death\n3       3                       fever   Death\n4       4         vomiting, diarrhoea Recover\n5       5 bleeding, from, gums, fever Recover\n6       6      rapid, pulse, headache Recover\n\n\n\n\n\nséparer\nPour diviser une chaîne de caractères en fonction d’un motif, utilisez la fonction str_split(). Cette fonction évalue la (ou les) chaîne(s) de caractères et renvoie une liste de vecteurs de caractères constituée des valeurs nouvellement séparées.\nL’exemple simple ci-dessous évalue une chaîne de caractères et la divise en trois. Par défaut, il retourne un objet de la classe list avec un élément (un vecteur de caractères) pour chaque chaîne initialement fournie. Si simplify = TRUE, (en français VRAI), il retourne une matrice de caractères.\nDans cet exemple, une chaîne de caractères est fournie, et la fonction renvoie une liste avec un élément - un vecteur de caractères avec trois valeurs.\n\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n\nSi les valeurs séparées sont enregistrées dans un objet, vous pouvez alors accéder à la n-iéme valeur séparée avec la syntaxe des crochets. Pour accéder à une valeur spécifique, vous pouvez utiliser une syntaxe comme celle-ci : nouveau_objet[[1]][2], qui accéderait à la deuxiéme valeur de la premiére chaîne évaluée (“fever”, ou fiévre en français, dans le dataframe de l’exemple). Consultez la page Bases de R pour plus de détails sur l’accés aux éléments.\n\npt1_symptoms &lt;- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extrait la 2éme valeur du 1er (et dans ce cas unique) élément de la liste\n\n[1] \" fever\"\n\n\nSi plusieurs chaînes de caractères sont fournies par str_split(), il y aura plus d’un élément dans la liste retournée.\n\nsymptoms &lt;- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n[[2]]\n[1] \"chills\" \" aches\" \" pains\"\n\n[[3]]\n[1] \"fever\"\n\n[[4]]\n[1] \"vomiting\"   \" diarrhoea\"\n\n[[5]]\n[1] \"bleeding from gums\" \" fever\"            \n\n[[6]]\n[1] \"rapid pulse\" \" headache\"  \n\n\nPour retourner une “matrice de caractères” à la place, ce qui peut être utile pour créer des colonnes dans votre dataframe, définissez l’argument simplify = TRUE comme indiqué ci-dessous :\n\nstr_split(symptoms, \",\", simplify = TRUE) #simplify = VRAI\n\n     [,1]                 [,2]         [,3]     \n[1,] \"jaundice\"           \" fever\"     \" chills\"\n[2,] \"chills\"             \" aches\"     \" pains\" \n[3,] \"fever\"              \"\"           \"\"       \n[4,] \"vomiting\"           \" diarrhoea\" \"\"       \n[5,] \"bleeding from gums\" \" fever\"     \"\"       \n[6,] \"rapid pulse\"        \" headache\"  \"\"       \n\n\nVous pouvez également ajuster le nombre de séparations à créer avec l’argument n =. Par exemple, l’exemple ci-dessous limite le nombre de séparations à deux. Toutes les autres virgules restent dans les deuxiémes valeurs.\n\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)\n\n     [,1]                 [,2]            \n[1,] \"jaundice\"           \" fever, chills\"\n[2,] \"chills\"             \" aches, pains\" \n[3,] \"fever\"              \"\"              \n[4,] \"vomiting\"           \" diarrhoea\"    \n[5,] \"bleeding from gums\" \" fever\"        \n[6,] \"rapid pulse\"        \" headache\"     \n\n\nNote - les mêmes résultats peuvent être obtenus avec str_split_fixed(), dans lequel vous ne donnez pas l’argument simplify, mais devez à la place désigner le nombre de colonnes (n).\n\nstr_split_fixed(symptoms, \",\", n = 2)\n\n\n\nSéparer les colonnes\nSi vous essayez de séparer une colonne dans un dataframe, il est préférable d’utiliser la fonction separate() de dplyr. Cette fonction est utilisée pour séparer une colonne de caractères en d’autres colonnes.\nDisons que nous avons un simple dataframe df (défini et uni dans la section unite) contenant une colonne case_ID, une colonne de caractères avec plusieurs symptômes, et une colonne de résultats. Notre objectif est de séparer la colonne symptoms en plusieurs colonnes, chacune contenant un symptôme.\n\n\n\n\n\n\nEn supposant que les données sont passées (‘pipe’, en utilisant %&gt;%) dans separate(), vous devez d’abord fournir la colonne à séparer dans la fonction seperate(). Ensuite, fournissez into = comme un vecteur c( ) contenant les noms des nouvelles colonnes, comme indiqué ci-dessous.\n\nsep = le séparateur, peut être un caractère, ou un nombre (interprété comme la position du caractère à séparer)\nremove = FAUX par défaut, supprime la colonne sélectionnée du dataframe une fois séparée.\n\nconvert = FALSE par défaut, si TRUE, les “NA” de la chaîne deviendront des NA.\n\nextra = ce contréle ce qui se passe s’il y a plus de valeurs créées par la séparation de la colonne que de nouveaux noms de colonnes fournis.\n\nextra = \"warn\" signifie que vous verrez un avertissement mais que les valeurs excédentaires seront supprimées (par défaut).\n\nextra = \"drop\", signifie que les valeurs excédentaires seront abandonnées sans avertissement.\n**extra = \"merge\" ne fractionnera que le nombre de nouvelles colonnes listées dans into - *cette configuration préservera toutes vos données**.\n\n\nVoici un exemple avec extra = \"merge\" - Deux nouvelles colonnes sont définies mais tous les troisiémes symptômes ou plus sont combinés dans la deuxiéme colonne:\n\n# troisiémes symptômes combinés dans la deuxiéme nouvelle colonne\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1          sym_2 outcome\n1       1           jaundice  fever, chills Recover\n2       2             chills   aches, pains   Death\n3       3              fever           &lt;NA&gt;   Death\n4       4           vomiting      diarrhoea Recover\n5       5 bleeding from gums          fever Recover\n6       6        rapid pulse       headache Recover\n\n\nLorsque l’option par défaut est utilisée ci-dessous, R retourne un avertissement mais les troisiémes symptômes sont perdus:\n\n# les troisiémes symptômes sont perdus\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")\n\nWarning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].\n\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1      sym_2 outcome\n1       1           jaundice      fever Recover\n2       2             chills      aches   Death\n3       3              fever       &lt;NA&gt;   Death\n4       4           vomiting  diarrhoea Recover\n5       5 bleeding from gums      fever Recover\n6       6        rapid pulse   headache Recover\n\n\nCAUTION: Si vous ne fournissez pas suffisamment de valeurs into pour les nouvelles colonnes, vos données peuvent être tronquées.\n\n\n\nClasser par ordre alphabétique\nVous pouvez trier plusieurs chaînes de caractères par ordre alphabétique. str_order() renvoie l’ordre (numérique), tandis que str_sort() renvoie les chaînes de caractères dans l’ordre alphabétique.\n\n# chaînes de caractères\nhealth_zones &lt;- c(\"Alba\", \"Takota\", \"Delta\")\n\n# renvoie l'ordre alphabétique\nstr_order(health_zones)\n\n[1] 1 3 2\n\n# retourne les chaînes de caractères par ordre alphabétique\nstr_sort(health_zones)\n\n[1] \"Alba\"   \"Delta\"  \"Takota\"\n\n\nPour utiliser un alphabet différent, ajoutez l’argument locale =. Voir la liste complète des locales en entrant stringi::stri_locale_list() dans la console R.\n\n\n\nFonctions de la base R\nIl est courant de voir les fonctions base R paste() et paste0(), qui concaténent des vecteurs aprés avoir converti toutes les parties en caractères. Ces fonctions agissent de manière similaire à str_c() mais la syntaxe est sans doute plus compliquée - dans les parenthèses, chaque partie est séparée par une virgule. Les parties sont soit du texte en caractères (entre guillemets), soit des objets de code prédéfinis (sans guillemets). Par exemple:\n\nn_beds &lt;- 10\nn_masks &lt;- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")\n\n[1] \"Regional hospital needs 10 beds and 20 masks.\"\n\n\nLes arguments sep = et collapse = peuvent être spécifiés. paste() est simplement paste0() avec un sep = \" \" (un espace) par défaut.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#nettoyer-et-standardiser",
    "href": "new_pages/characters_strings.fr.html#nettoyer-et-standardiser",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.3 Nettoyer et standardiser",
    "text": "10.3 Nettoyer et standardiser\n\n\nChanger la casse\nSouvent, on doit modifier la casse/capitalisation d’une valeur de chaîne de caractères, par exemple les noms des jursidictions. Utilisez str_to_upper(), str_to_lower(), et str_to_title(), de stringr, comme indiqué ci-dessous :\n\nstr_to_upper(\"California\")\n\n[1] \"CALIFORNIA\"\n\nstr_to_lower(\"California\")\n\n[1] \"california\"\n\n\nEn utilisant *base** R, l’exemple ci-dessus peut également être réalisé avec toupper() ou tolower().\nMots en majuscules\nLa transformation de la chaîne pour que chaque mot soit en majuscule peut être réalisée avec str_to_title():\n\nstr_to_title(\"go to the US state of california \")\n\n[1] \"Go To The Us State Of California \"\n\n\nUtilisez la fonction toTitleCase() du paquet tools pour ne mettre en majuscules que certains mots (les mots comme “to”, “the” et “of” ne sont pas mis en majuscules).\n\ntools::toTitleCase(\"This is the US state of california\")\n\n[1] \"This is the US State of California\"\n\n\nVous pouvez également utiliser la fonction str_to_sentence(), qui ne met en majuscule que la premiére lettre de la chaîne.\n\nstr_to_sentence(\"the patient must be transported\")\n\n[1] \"The patient must be transported\"\n\n\n\n\nLongueur du bloc\nUtilisez la fonction str_pad() pour ajouter des caractères à une chaîne, jusqu’à une longueur minimale. Par défaut, des espaces sont ajoutés, mais vous pouvez également ajouter d’autres caractères en utilisant l’argument pad =.\n\n# Codes ICD de longueur différente\nICD_codes &lt;- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# Les codes ICD sont complétés à 7 caractères sur la droite\nstr_pad(ICD_codes, 7, \"right\")\n\n[1] \"R10.13 \" \"R10.819\" \"R17    \"\n\n# Remplir avec des points au lieu d'espaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")\n\n[1] \"R10.13.\" \"R10.819\" \"R17....\"\n\n\nPar exemple, pour complèter des nombres avec des zéros en tête (comme pour les heures ou les minutes), vous pouvez complèter le nombre à une longueur minimale de 2 avec pad = \"0\".\n\n# Ajoutez des zéros à deux chiffres (par exemple, pour les minutes/heures)\nstr_pad(\"4\", 2, pad = \"0\") \n\n[1] \"04\"\n\n# Exemple utilisant une colonne numérique nommée \"heures\" (hours en Anglais)\n# hours &lt;- str_pad(hours, 2, pad = \"0\")\n\n\n\nTronquer\nLa fonction str_trunc() définit une longueur maximale pour chaque chaîne. Si une chaîne dépasse cette longueur, elle est tronquée (raccourcie) et une ellipse (…) est incluse pour indiquer que la chaîne était auparavant plus longue. Notez que l’ellipse est comptée dans la longueur. Les caractères d’ellipses peuvent être changés avec l’argument ellipsis =. L’argument optionnel side = spécifie où l’ellipse apparaîtra dans la chaîne tronquée (“gauche”, “droite”, ou “centre”).\n\noriginal &lt;- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")\n\n[1] \"Symp...ing\"\n\n\n\n\nNormaliser la longueur\nUtilisez la fonction str_trunc() pour définir une longueur maximale, puis utilisez str_pad() pour étendre les chaînes trés courtes à cette longueur tronquée. Dans l’exemple ci-dessous, 6 est défini comme longueur maximale (une valeur est tronquée), puis une valeur trés courte est ajoutée pour atteindre la longueur de 6.\n\n# Codes CIM de longueur différente\nICD_codes   &lt;- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# tronquer à la longueur maximale de 6\nICD_codes_2 &lt;- str_trunc(ICD_codes, 6)\nICD_codes_2\n\n[1] \"R10.13\" \"R10...\" \"R17\"   \n\n# étendre à une longueur minimale de 6\nICD_codes_3 &lt;- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3\n\n[1] \"R10.13\" \"R10...\" \"R17   \"\n\n\n\n\nSupprimer les espaces avant/aprés les chaînes de caractères\nUtilisez la fonction str_trim() pour supprimer les espaces, les nouvelles lignes (\\n) ou les tabulations (\\t) sur les côtés d’une entrée de chaîne de caractères. Ajoutez \"right\" (en français droite), \"left\" (en français gauche) ou \"both\" (en français les deux) à la commande pour spécifier le côté à découper (par exemple, str_trim(x, \"right\").\n\n# Numéros d'identification avec espaces excédentaires à droite\nIDs &lt;- c(\"provA_1852  \", # deux espaces excédentaires\n         \"provA_2345\",   # zero espace excédentaire\n         \"provA_9460 \")  # un espace excédentaire\n\n#  les identifiants sont coupés pour supprimer les espaces excédentaires du côté droit uniquement\nstr_trim(IDs)\n\n[1] \"provA_1852\" \"provA_2345\" \"provA_9460\"\n\n\n\n\nSupprimer les espaces répétés dans les chaînes de caractères\nUtilisez la fonction str_squish() pour supprimer les espaces répétés qui apparaissent à l’intérieur d’une chaîne. Par exemple, pour convertir les espaces doubles en espaces simples. Elle supprime également les espaces, les retours à la ligne ou les tabulations à l’extérieur de la chaîne, comme str_trim().\n\n# L'original contient des espaces supplémentaires dans la chaîne\nstr_squish(\"  Pt requires   IV saline\\n\") \n\n[1] \"Pt requires IV saline\"\n\n\nEntrez ?str_trim, ?str_pad dans votre console R pour voir plus de détails.\n\n\nTransformer en paragraphes\nUtilisez str_wrap() pour transformer un long texte non structuré en un paragraphe structuré avec une longueur de ligne fixe. Fournissez la longueur idéale de caractères pour chaque ligne, et la fonction applique un algorithme pour insérer des nouvelles lignes (\\n) dans le paragraphe, comme dans l’exemple ci-dessous.\n\npt_course &lt;- \"Début des symptômes 1/4/2020 : vomissements, frissons, fièvre. Le patient a vu un guérisseur traditionnel dans son village natal le 2/4/2020. Le 5/4/2020, les symptômes du patient se sont aggravés et il a été admis à la clinique Lumta. Un échantillon a été prélevé et le patient a été transporté à l'hôpital régional le 6/4/2020. Le patient est décédé à l'hôpital régional le 7/4/2020.\"\n\nstr_wrap(pt_course, 40)\n\n[1] \"Début des symptômes 1/4/2020 :\\nvomissements, frissons, fièvre. Le\\npatient a vu un guérisseur traditionnel\\ndans son village natal le 2/4/2020. Le\\n5/4/2020, les symptômes du patient se\\nsont aggravés et il a été admis à la\\nclinique Lumta. Un échantillon a été\\nprélevé et le patient a été transporté\\nà l'hôpital régional le 6/4/2020. Le\\npatient est décédé à l'hôpital régional\\nle 7/4/2020.\"\n\n\nLa fonction de base R cat()` peut être enroulée autour de la commande ci-dessus afin d’imprimer le résultat dans la console R.\n\ncat(str_wrap(pt_course, 40))\n\nDébut des symptômes 1/4/2020 :\nvomissements, frissons, fièvre. Le\npatient a vu un guérisseur traditionnel\ndans son village natal le 2/4/2020. Le\n5/4/2020, les symptômes du patient se\nsont aggravés et il a été admis à la\nclinique Lumta. Un échantillon a été\nprélevé et le patient a été transporté\nà l'hôpital régional le 6/4/2020. Le\npatient est décédé à l'hôpital régional\nle 7/4/2020.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#gérer-par-position",
    "href": "new_pages/characters_strings.fr.html#gérer-par-position",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.4 Gérer par position",
    "text": "10.4 Gérer par position\n\nExtraire par position de caractère\nUtilisez la fonction str_sub() pour retourner seulement une partie d’une chaîne de caractères. La fonction prend trois arguments principaux :\n\nle(s) vecteur(s) de caractères\n\nla position de départ dans le vecteur\nla position finale dans le vecteur\n\nQuelques remarques sur les numéros de position :\n\nSi le numéro de position est positif, la position est comptée à partir de l’extrémité gauche de la chaîne.\n\nSi le numéro de position est négatif, il est compté à partir de l’extrémité droite de la chaîne.\n\nLes numéros de position sont inclusifs.\n\nLes positions qui dépassent la chaîne de caractères seront tronquées (supprimées).\n\nVoici quelques exemples appliqués à la chaîne “pneumonie” :\n\n# position de départ et position finale troisiéme en partant de la gauche (3éme lettre en partant de la gauche)\nstr_sub(\"pneumonia\", 3, 3)\n\n[1] \"e\"\n\n# 0 n'est pas présent, donc cela renvoie \"\"\nstr_sub(\"pneumonia\", 0, 0)\n\n[1] \"\"\n\n# # 6éme en partant de la gauche, jusqu'à  la 1ére en partant de la droite\nstr_sub(\"pneumonia\", 6, -1)\n\n[1] \"onia\"\n\n# 5éme de la droite, vers le 2éme de la droite\nstr_sub(\"pneumonia\", -5, -2)\n\n[1] \"moni\"\n\n# 4éme en partant de la gauche, jusqu'à  une position en dehors de la chaîne de caractères\nstr_sub(\"pneumonia\", 4, 15)\n\n[1] \"umonia\"\n\n\n\n\nExtraire par position de mot\nPour extraire le niéme “mot”, utilisez la fonction word(), du paquet stringr. Fournissez la ou les chaînes de caractères, puis la premiére position du mot à extraire, et la dernière position du mot à extraire.\nPar défaut, le séparateur entre les mots est supposé être un espace, sauf indication contraire avec sep = (par exemple, sep = \"_\" où les mots sont séparés par des caractères de soulignement).\n\n# chaînes de caractères à évaluer\nchief_complaints &lt;- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")\n\n[1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\" \n\n\n\n\nRemplacer par la position du caractère\nstr_sub() apparié avec l’opérateur d’affectation (&lt;-) peut être utilisé pour modifier une partie d’une chaîne :\n\nword &lt;- \"pneumonia\"\n\n# convertissez les troisiéme et quatriéme caractères en X \nstr_sub(word, 3, 4) &lt;- \"XX\"\n\n# imprimer\nword\n\n[1] \"pnXXmonia\"\n\n\nVoici ci-dessus Un exemple appliqué à plusieurs chaînes de caractères (par exemple, un vecteur de mots ou une colonne). Notez l’expansion en longueur de “HIV”.\n\nwords &lt;- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convertissez les troisiéme et quatriéme caractères en X \nstr_sub(words, 3, 4) &lt;- \"XX\"\n\nwords\n\n[1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\"        \n\n\n\n\nEvaluer la longueur\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nAlternativement, utilisez la fonction nchar() de base R.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#motifs",
    "href": "new_pages/characters_strings.fr.html#motifs",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.5 Motifs",
    "text": "10.5 Motifs\nDe nombreuses fonctions du paquet stringr fonctionnent pour détecter, localiser, extraire, correspondre, remplacer et séparer en fonction d’un motif spécifié.\n\n\ndétecter un motif\nUtilisez la fonction str_detect() comme ci-dessous pour détecter la présence/absence d’un motif dans une chaîne de caractères. Fournissez d’abord la chaîne ou le vecteur à rechercher (string =), puis le motif à rechercher (pattern =). Notez que par défaut, la recherche est sensible à la casse!\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")\n\n[1] TRUE\n\n\nL’argument negate = peut être inclus et mis à TRUE (en français VRAI) si vous voulez savoir si le motif n’est PAS présent.\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)\n\n[1] FALSE\n\n\nPour ignorer les majuscules et les minuscules, intégrez le motif dans regex(), et dans regex() ajoutez l’argument ignore_case = TRUE (ou T en raccourci).\n\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))\n\n[1] TRUE\n\n\nLorsque str_detect() est appliqué à un vecteur de caractères ou à une colonne de dataframe, il renvoie TRUE (en français VRAI) ou FALSE (en français FAUX) pour chacune des valeurs.\n\n# un vecteur/colonne de professions \noccupations &lt;- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# détecter la présence du motif \"teach\" dans chaque chaîne - la valeur retournée est un vecteur de VRAI/FAUX\nstr_detect(occupations, \"teach\")\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nSi vous avez besoin de compter les TRUEs, utilisez la fonction sum() sur les valeurs ou le vecteur retourné(es). Ceci compte le nombre de TRUE (VRAI) dans les valeurs ou le vecteur retourné(es).\n\nsum(str_detect(occupations, \"teach\"))\n\n[1] 1\n\n\nPour effectuer une recherche incluant plusieurs termes, incluez-les séparés par des barres OR (|) dans l’argument pattern =, comme indiqué ci-dessous:\n\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))\n\n[1] 3\n\n\nSi vous avez besoin de construire une longue liste de termes de recherche, vous pouvez les combiner en utilisant str_c() et sep = |, et assigner ceci à un objet. Vous pouvez ensuite référencer le vecteur par le nom de l’objet. L’exemple ci-dessous combine les termes de recherche d’une occupation possible en un seul objet.\n\n# termes de recherche\noccupation_med_frontline &lt;- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline\n\n[1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\n\n\nCette commande renvoie le nombre de professions qui contiennent l’un des termes de recherche pour les praticiens médicaux (occupation_med_frontline):\n\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))\n\n[1] 2\n\n\nFonctions de recherche de chaînes de caractères de base R\nLa fonction de R base grepl() fonctionne de manière similaire à str_detect(), dans le sens qu’elle recherche les correspondances avec un motif et retourne un vecteur logique. La syntaxe de base est grepl(pattern, strings_to_search, ignore.case = FALSE, ...). Un avantage est que l’argument ignore.case est plus facile à écrire (il n’y a pas besoin d’impliquer la fonction regex()).\nLes fonctions sub() et gsub() de base R agissent de manière similaire à str_replace(). Leur syntaxe générale suit ce format : gsub(motif, remplacement, chaînes_a_rechercher, ignore.case = FALSE). sub() remplacera seulement la premiére instance du motif, alors que gsub() remplacera toutes les instances du motif.\n\nConvertir les virgules en points\nVoici un exemple d’utilisation de gsub() pour convertir des virgules en points dans un vecteur de nombres. Cela peut être utile si vos données proviennent de différents endroits dans le monde avec une syntaxe de langue différente.\nL’exemple ci-dessous utilise deux applications de gsub. L’application interne gsub(), qui agit en premier sur l’objet lengths, convertit tous les points en “” sans espace. Le caractère point “.” doit être “spécifié” avec deux slashs pour signifier réellement un point, parce que “.” en regex sans deux slashs signifie ” n’importe quel caractère”. Ensuite, le résultat (avec seulement des virgules) est passé à la fonction externe gsub() dans laquelle les virgules sont remplacées par des points.\n\nlengths &lt;- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # trouver les virgules    \n                replacement = \".\",            # remplacer par des points\n                x = gsub(\"\\\\.\", \"\", lengths)  # vecteur avec d'autres points supprimés \n                )\n           )                                  # convertir le résultat en numérique\n\n\n\n\nRemplacer tous les éléments\nUtilisez la fonction str_replace_all() comme un outil de “recherche et remplacement”. Vous fournissez d’abord les chaînes à évaluer à string =, puis le motif à remplacer à pattern =, et enfin la valeur de remplacement à replacement =. L’exemple ci-dessous remplace toutes les occurrences de “dead” (en français mort) par “deceased” (en français décédés). Notez que cette opération est sensible à la casse.\n\noutcome &lt;- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")\n\n[1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\"\n\n\nRemarques :\n\nPour remplacer un motif par NA, utilisez str_replace_na().\n\nLa fonction str_replace() remplace uniquement la premiére instance du motif dans chaque chaîne évaluée.\n\n\n\n\ndétecter en utilisant des instructions logiques\nA l’intérieur de case_when()\nstr_detect() est souvent utilisé dans case_when() (du paquet dplyr). Disons que occupations est une colonne de la linelist (liste linéaire ou liste de cas). La fonction mutate() ci-dessous crée une nouvelle colonne appelée is_educator en utilisant la logique conditionnelle via case_when(). Consultez la page sur le nettoyage des données pour en savoir plus sur la méthode case_when().\n\ndf &lt;- df %&gt;% \n  mutate(is_educator = case_when(\n    #  recherche de termes dans la profession, non sensible à la casse\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))\n\nPar ailleurs, il peut être important d’ajouter des critéres d’exclusion à la logique conditionnelle (negate = F) :\n\ndf &lt;- df %&gt;% \n  # la valeur de la nouvelle colonne is_educator est basée sur la logique conditionnelle\n  mutate(is_educator = case_when(\n    \n    # la colonne occupation doit répondre à 2 critéres pour se voir attribuer \"Educateur\" :\n    # elle doit avoir un terme de recherche ET PAS de terme d'exclusion\n    \n    #  Doit avoir un terme de recherche\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # AND ne doit PAS avoir de terme d'exclusion\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # Toutes les lignes ne répondant pas aux critéres ci-dessus\n    TRUE                                            ~ \"Not an educator\"))\n\n\n\n\nLocaliser la position du motif\nPour localiser la premiére position d’un motif, utilisez la fonction str_locate(). Elle produit une position de début et de fin.\n\nstr_locate(\"I wish\", \"sh\")\n\n     start end\n[1,]     5   6\n\n\nComme les autres fonctions de la famille str, il existe une version “_all” (str_locate_all()) qui renvoie les positions de toutes les instances du motif dans chaque chaîne. Cette fonction renvoie les valeurs sous forme de liste.\n\nphrases &lt;- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" ) # position de la *premiére* instance du motif\n\n     start end\n[1,]     6   6\n[2,]     3   3\n[3,]     1   1\n[4,]     4   4\n\nstr_locate_all(phrases, \"h\" ) # position de *chaque* instance du motif\n\n[[1]]\n     start end\n[1,]     6   6\n\n[[2]]\n     start end\n[1,]     3   3\n\n[[3]]\n     start end\n[1,]     1   1\n[2,]     4   4\n\n[[4]]\n     start end\n[1,]     4   4\n\n\n\n\n\nExtraire une correspondance\nstr_extract_all() retourne les motifs de correspondance eux-mêmes, ce qui est trés utile lorsque vous avez proposé plusieurs motifs via des conditions “OR” (en français OU). Par exemple, si vous cherchez dans le vecteur de chaînes de professions (voir l’exemple précédent) soit “teach”, “prof”, ou “tutor”.\nstr_extract_all() renvoie une liste qui contient toutes les correspondances pour chaque chaîne évaluée. Voyez ci-dessous comment l’occupation 3 contient deux correspondances de motifs.\n\nstr_extract_all(occupations, \"teach|prof|tutor\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\n[1] \"prof\"\n\n[[3]]\n[1] \"teach\" \"tutor\"\n\n[[4]]\n[1] \"tutor\"\n\n[[5]]\ncharacter(0)\n\n[[6]]\ncharacter(0)\n\n[[7]]\ncharacter(0)\n\n[[8]]\ncharacter(0)\n\n[[9]]\ncharacter(0)\n\n[[10]]\ncharacter(0)\n\n\nstr_extract() extrait seulement la premiére correspondance dans chaque chaîne évaluée, produisant un vecteur de caractères avec un élément pour chaque chaîne évaluée. Elle retourne NA lorsqu’il n’y a pas de correspondance. Les NAs peuvent être supprimés en enveloppant le vecteur retourné avec na.exclude(). Notez que la deuxiéme correspondance de l’occupation 3 n’est pas affichée.\n\nstr_extract(occupations, \"teach|prof|tutor\")\n\n [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA     \n[10] NA     \n\n\n\n\n\nSous-ensemble et comptage\nLes fonctions alignées comprennent str_subset() et str_count().\nstr_subset() renvoie les valeurs réelles qui contiennent le motif :\n\nstr_subset(occupations, \"teach|prof|tutor\")\n\n[1] \"university professor\"           \"primary school teacher & tutor\"\n[3] \"tutor\"                         \n\n\nstr_count() renvoie un vecteur de nombres : le nombre de fois qu’un terme de recherche apparaît dans chaque valeur évaluée.\n\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))\n\n [1] 0 1 2 1 0 0 0 0 0 0\n\n\n\n\n\nGroupes de regex\nEN CONSTRUCTION",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#caractères-spéciaux",
    "href": "new_pages/characters_strings.fr.html#caractères-spéciaux",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.6 caractères spéciaux",
    "text": "10.6 caractères spéciaux\nSlash arriére \\ comme échappement\nLa barre oblique inverse \\ est utilisée pour “échapper” à la signification du caractère suivant. Ainsi, une barre oblique inversée peut être utilisée pour afficher un guillemet dans d’autres guillemets (\\\") - le guillemet central ne “cassera” pas les guillemets environnants.\nNote - Si vous voulez afficher une barre oblique inverse, vous devez échapper à sa signification avec une autre barre oblique inverse. Ainsi, vous devez écrire deux barres obliques inversées \\\\ pour en afficher une.\nCaractères spéciaux\n\n\n\nCaractère spécial\nReprésentation\n\n\n\n\n\"\\\\\"\nbarre oblique inversée\n\n\n\"\\n\"\nune nouvelle ligne (newline)\n\n\n\"\\\"\"\nguillemets doubles entre guillemets doubles\n\n\n'\\''\nguillemets simples entre guillemets simples\n\n\n\"\\`\"\naccent grave\n\n\n\"\\r\"\nretour chariot\n\n\n\"\\t\"\ntabulation\n\n\n\"\\v\"\ntabulation verticale\n\n\n\"\\b\"\nretour arriére\n\n\n\nExécutez ?\"'\" dans la console R pour afficher la liste complète de ces caractères spéciaux (elle apparaîtra dans le volet d’aide de RStudio).",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#expressions-régulières-regex",
    "href": "new_pages/characters_strings.fr.html#expressions-régulières-regex",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.7 Expressions régulières (regex)",
    "text": "10.7 Expressions régulières (regex)",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#regex-et-caractères-spéciaux",
    "href": "new_pages/characters_strings.fr.html#regex-et-caractères-spéciaux",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.8 Regex et caractères spéciaux",
    "text": "10.8 Regex et caractères spéciaux\nLes expressions régulières, ou “regex”, sont un langage concis pour décrire des motifs dans des chaînes de caractères. Si vous n’étes pas familier avec ce langage, une expression régulière peut ressembler à une langue étrangére. Nous allons essayer de démystifier un peu ce langage.\nUne grande partie de cette section est adaptée de ce tutoriel et de cette cheatsheet. Nous adaptons ici de manière sélective, sachant que ce manuel pourrait être consulté par des personnes n’ayant pas d’accés à l’Internet pour consulter les autres tutoriels.\nUne expression régulière est souvent utilisée pour extraire des motifs spécifiques d’un texte “non structuré”, par exemple des notes médicales, des plaintes principales, des antécédents du patient ou d’autres colonnes de texte libre dans un dataframe.\nIl existe quatre outils de base que l’on peut utiliser pour créer une expression régulière de base :\n\nJeux de caractères\n\nMéta-caractères\n\nQuantificateurs\n\nGroupes\n\nJeux de caractères\nLes jeux de caractères sont une façon d’exprimer les options de liste pour une correspondance de caractères, entre parenthèses. Ainsi, une correspondance sera déclenchée si l’un des caractères entre parenthèses est trouvé dans la chaîne. Par exemple, pour rechercher des voyelles, on peut utiliser ce jeu de caractères: “[aeiou]”. Voici d’autres jeux de caractères courants:\n\n\n\n\n\n\n\nJeu de caractères\nCorrespond à\n\n\n\n\n\"[A-Z]\"\ntoute lettre majuscule unique\n\n\n\"[a-z]\"\ntoute lettre minuscule unique\n\n\n\"[0-9]\"\nn’importe quel chiffre\n\n\n[:alnum:]\ntout caractère alphanumérique\n\n\n[:digit:]\ntout chiffre numérique\n\n\n[:alpha:]\ntoute lettre (majuscule ou minuscule)\n\n\n[:upper:]\ntoute lettre majuscule\n\n\n[:lower:]\ntoute lettre minuscule\n\n\n\nLes jeux de caractères peuvent être combinés à l’intérieur d’une même parenthèse (sans espace !), par exemple \"[A-Za-z]\" (toute lettre majuscule OU minuscule), ou un autre exemple \"[t-z0-5]\" (minuscules de t à z OU nombre de 0 à 5).\nMeta characters\nLes métacaractères sont des raccourcis pour les jeux de caractères. Certains des plus importants sont énumérés ci-dessous :\n\n\n\n\n\n\n\ncaractère méta\nReprésentation\n\n\n\n\n\"\\\\s\"\nun seul espace\n\n\n\"\\\\w\"\nun seul caractère alphanumérique (A-Z, a-z, ou 0-9)\n\n\n\"\\\\d\"\nun seul chiffre (0-9)\n\n\n\nQuantificateurs\nEn général, vous ne souhaitez pas rechercher une correspondance sur un seul caractère. Les quantificateurs vous permettent de désigner la longueur des lettres/chiffres pour permettre une correspondance plus spécifique.\nLes quantificateurs sont des nombres écrits entre accolades { } aprés le caractère qu’ils quantifient, par exemple:\n\n\"A{2}\" renverra les instances de deux lettres majuscules A.\n\n\"A{2,4}\" renverra les instances de deux à quatre lettres majuscules A (ne mettez pas d’espace !).\n\n\"A{2,}\" renverra les instances de deux lettres A majuscules ou plus.\n\n\"A+\" renverra les instances de une ou plusieurs lettres majuscules A (groupe étendu jusqu’à ce qu’un caractère différent soit rencontré).\n\nFaites précéder d’un astérisque * pour obtenir zéro ou plus de correspondances (utile si vous n’étes pas sûr que le motif soit présent).\n\nEn utilisant le symbole plus + comme quantificateur, la correspondance se fera jusqu’à ce qu’un caractère différent soit rencontré. Par exemple, cette expression retournera tous les mots (caractères alpha : \"[A-Za-z]+\").\n\n# chaîne de caractères pour tester les quantificateurs\ntest &lt;- \"A-AA-AAA-AAAA\"\n\nLorsqu’un quantificateur de {2} est utilisé, seules les paires de A consécutifs sont renvoyées. Deux paires sont identifiées dans AAAA.\n\nstr_extract_all(test, \"A{2}\")\n\n[[1]]\n[1] \"AA\" \"AA\" \"AA\" \"AA\"\n\n\nLorsqu’un quantificateur de {2,4} est utilisé, les groupes de A consécutifs d’une longueur de deux à quatre sont renvoyés.\n\nstr_extract_all(test, \"A{2,4}\")\n\n[[1]]\n[1] \"AA\"   \"AAA\"  \"AAAA\"\n\n\nAvec le quantificateur +, les groupes de un ou plus sont renvoyés :\n\nstr_extract_all(test, \"A+\")\n\n[[1]]\n[1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\n\n\nRelative position\nIl existe des exigences spécifiques pour ce qui précéde ou suit un motif. Par exemple, pour extraire des phrases, “deux chiffres qui sont suivis d’un point” (\"\"). (?&lt;=\\.)\\s(?=[A-Z])\n\nstr_extract_all(test, \"\")\n\n[[1]]\n [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\n\n\n\n\n\n\n\n\n\ndéclaration de position\nCorrespond à\n\n\n\n\n\"(?&lt;=b)a\"\nUn “a” qui est précédé d’un “b”.\n\n\n\"(?&lt;!b)a\"\n“a” qui n’est PAS précédé par un “b”\n\n\n\"a(?=b)\"\n“a” qui est suivi par un “b”\n\n\n\"a(?!b)\"\n“a” qui n’est PAS suivi d’un “b”.\n\n\n\nGroupes\nLa capture de groupes dans votre expression régulière est un moyen d’obtenir des valeurs plus organisées lors de l’extraction.\nExemples de regex\nVous trouverez ci-dessous un texte libre pour les exemples. Nous allons essayer d’en extraire des informations utiles en utilisant un terme de recherche par expression régulière.\n\npt_note &lt;- \"Le patient est arrivé aux urgences de l'hôpital Broward à 18h00 le 6/12/2005. Le patient s'est présenté avec une douleur abdominale irradiant du quadrant LR. La peau du patient était pâle, fraîche et moite. Sa température était de 99,8 degrés Farinheit. Le pouls du patient était de 100 bpm et filant. La fréquence respiratoire était de 29 par minute.\"\n\nCette expression correspond à tous les mots (tout caractère jusqu’à la frappe d’un non-caractère tel qu’un espace):\n\nstr_extract_all(pt_note, \"[A-Za-z]+\")\n\n[[1]]\n [1] \"Le\"           \"patient\"      \"est\"          \"arriv\"        \"aux\"         \n [6] \"urgences\"     \"de\"           \"l\"            \"h\"            \"pital\"       \n[11] \"Broward\"      \"h\"            \"le\"           \"Le\"           \"patient\"     \n[16] \"s\"            \"est\"          \"pr\"           \"sent\"         \"avec\"        \n[21] \"une\"          \"douleur\"      \"abdominale\"   \"irradiant\"    \"du\"          \n[26] \"quadrant\"     \"LR\"           \"La\"           \"peau\"         \"du\"          \n[31] \"patient\"      \"tait\"         \"p\"            \"le\"           \"fra\"         \n[36] \"che\"          \"et\"           \"moite\"        \"Sa\"           \"temp\"        \n[41] \"rature\"       \"tait\"         \"de\"           \"degr\"         \"s\"           \n[46] \"Farinheit\"    \"Le\"           \"pouls\"        \"du\"           \"patient\"     \n[51] \"tait\"         \"de\"           \"bpm\"          \"et\"           \"filant\"      \n[56] \"La\"           \"fr\"           \"quence\"       \"respiratoire\" \"tait\"        \n[61] \"de\"           \"par\"          \"minute\"      \n\n\nL’expression \"[0-9]{1,2}\" correspond à des nombres consécutifs de 1 ou 2 chiffres. On pourrait aussi l’écrire \"\\d{1,2}\", ou \"[:digit:]{1,2}\".\n\nstr_extract_all(pt_note, \"[0-9]{1,2}\")\n\n[[1]]\n [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\"\n\n\n\n\n\n\nVous pouvez consulter une liste utile d’expressions regex et de conseils à la page 2 de cette cheatsheet.\nVoir également ce tutoriel.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.fr.html#resources",
    "href": "new_pages/characters_strings.fr.html#resources",
    "title": "10  Caractères et chaînes de caractères",
    "section": "10.9 Resources",
    "text": "10.9 Resources\nUne fiche de référence pour les fonctions du paquet stringr peut être trouvée ici\nUne vignette sur stringr peut être trouvée ici.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caractères et chaînes de caractères</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html",
    "href": "new_pages/factors.fr.html",
    "title": "11  Facteurs",
    "section": "",
    "text": "11.1 Preparation",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#preparation",
    "href": "new_pages/factors.fr.html#preparation",
    "title": "11  Facteurs",
    "section": "",
    "text": "Chargement des paquets\nCe morceau de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur R basics pour plus d’informations sur les packages R.\n\npacman::p_load(\n  rio,           # importer/exporter\n  here,          # chemin des fichiers\n  lubridate,     # travailler avec les dates\n  forcats,       # facteurs\n  aweek,         # creer epiweeks avec les niveaux des facteurs\n  janitor,       # tableau\n  tidyverse      # données management et visualisation\n  )\n\n\n\nImporter données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, , cliquer pour telecharger le jeu de données “nettoyé” linelist (as .rds file). Importez vos données avec la fonction import() du package rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation pour plus de détails).\n\n# importer ton jeu de donnée\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n\n\n11.1.1 Nouveau variable qualitative {#fct_newcat .unnumbered}\nPour la démonstration dans cette page, nous utiliserons un scénario commun - la création d’une nouvelle variable catégorielle.\nNotez que si vous convertissez une colonne numérique en facteur de classe, vous ne serez pas en mesure de calculer des statistiques numériques sur celle-ci.\n\nCreation de colonnes\nNous utilisons la colonne existante days_onset_hosp (jours entre l’apparition des symptômes et l’admission à l’hôpital) et créons une nouvelle colonne delay_cat en classant chaque ligne dans l’une de plusieurs catégories. Nous faisons cela avec la fonction dplyr case_when(), qui applique séquentiellement des critères logiques (côté droit) à chaque ligne et renvoie la valeur correspondante côté gauche pour la nouvelle colonne delay_cat. Vous trouverez plus d’informations sur la fonction case_when() dans Nettoyage des données et des fonctions de base.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = case_when(\n    # critere                                 # nouveau valeur si vrai\n    days_onset_hosp &lt; 2                        ~ \"&lt;2 days\",\n    days_onset_hosp &gt;= 2 & days_onset_hosp &lt; 5 ~ \"2-5 days\",\n    days_onset_hosp &gt;= 5                       ~ \"&gt;5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  \n\n\n\nOrdre des valeurs par defaut\nTelle que créée avec case_when(), la nouvelle colonne delay_cat est une colonne catégorielle de la classe Character - pas encore un facteur. Ainsi, dans un tableau de fréquence, nous voyons que les valeurs uniques apparaissent dans un ordre alphanumérique par défaut - un ordre qui n’a pas beaucoup de sens intuitif :\n\ntable(linelist$delay_cat, useNA = \"always\")\n\n\n &lt;2 days  &gt;5 days 2-5 days     &lt;NA&gt; \n    2990      602     2040      256 \n\n\nDe même, si nous réalisons un diagramme à barres, les valeurs apparaissent également dans cet ordre sur l’axe des x (voir la page sur les bases de ggplot pour en savoir plus sur ggplot2 - le package de visualisation le plus courant dans R).\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#convertir-en-facteur",
    "href": "new_pages/factors.fr.html#convertir-en-facteur",
    "title": "11  Facteurs",
    "section": "11.2 Convertir en facteur",
    "text": "11.2 Convertir en facteur\nPour convertir une colonne de caractères ou de chiffres en facteur de classe, vous pouvez utiliser n’importe quelle fonction du package forcats (plusieurs sont détaillées ci-dessous). Elles convertiront en facteur de classe et effectueront ou permettront un certain ordre des niveaux - par exemple, l’utilisation de fct_relevel() vous permet de spécifier manuellement l’ordre des niveaux. La fonction as_factor() convertit simplement la classe sans autres capacités.\nLa fonction R base factor() convertit une colonne en facteur et vous permet de spécifier manuellement l’ordre des niveaux, comme un vecteur de caractères à son argument levels =.\nCi-dessous, nous utilisons mutate() et fct_relevel() pour convertir la colonne delay_cat de la classe caractère à la classe facteur. La colonne delay_cat est créée dans la section Préparation ci-dessus.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat))\n\nLes “valeurs” uniques de cette colonne sont maintenant considérées comme des “niveaux” du facteur. Les niveaux ont un ordre, qui peut être affiché avec la fonction base R levels(), ou alternativement visualisé dans un tableau de comptage via table() de base R ou tabyl() de janitor. Par défaut, l’ordre des niveaux sera alpha-numérique, comme auparavant. Notez que NA n’est pas un niveau de facteur.\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"&gt;5 days\"  \"2-5 days\"\n\n\nLa fonction fct_relevel() a l’utilité supplémentaire de vous permettre de spécifier manuellement l’ordre des niveaux. Il suffit d’écrire les valeurs des niveaux dans l’ordre, entre guillemets, séparés par des virgules, comme indiqué ci-dessous. Notez que l’orthographe doit correspondre exactement aux valeurs. Si vous voulez créer des niveaux qui n’existent pas dans les données, utilisez plutôt fct_expand()).\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))\n\nNous pouvons maintenant voir que les niveaux sont ordonnés, comme spécifié dans la commande précédente, dans un ordre raisonnable.\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nMaintenant, l’ordre de l’intrigue a aussi un sens plus intuitif.\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#ajouter-ou-enlever-des-niveaux",
    "href": "new_pages/factors.fr.html#ajouter-ou-enlever-des-niveaux",
    "title": "11  Facteurs",
    "section": "11.3 Ajouter ou enlever des niveaux",
    "text": "11.3 Ajouter ou enlever des niveaux\n\n11.3.1 Ajouter {#fct_add .unnumbered}\nSi vous devez ajouter des niveaux à un facteur, vous pouvez le faire avec fct_expand(). Il suffit d’écrire le nom de la colonne suivi des nouveaux niveaux (séparés par des virgules). En tabulant les valeurs, nous pouvons voir les nouveaux niveaux et le nombre de zéros. Vous pouvez utiliser table() de base R, ou tabyl() de janitor :\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %&gt;% \n  tabyl(delay_cat)   # afficher le tableau\n\n                      delay_cat    n    percent valid_percent\n                        &lt;2 days 2990 0.50781250     0.5308949\n                       2-5 days 2040 0.34646739     0.3622159\n                        &gt;5 days  602 0.10224185     0.1068892\n       Not admitted to hospital    0 0.00000000     0.0000000\n Transfer to other jurisdiction    0 0.00000000     0.0000000\n                           &lt;NA&gt;  256 0.04347826            NA\n\n\nNote : il existe une fonction spéciale forcats pour ajouter facilement les valeurs manquantes (NA) comme niveau. Voir la section sur les Valeurs manquantes ci-dessous.\n\n\nEnlever\nSi vous utilisez fct_drop(), les niveaux “inutilisés” avec des comptes nuls seront supprimés de l’ensemble des niveaux. Les niveaux que nous avons ajoutés ci-dessus (“Non admis à l’hôpital”) existent en tant que niveau mais aucune ligne n’a réellement ces valeurs. Ils seront donc supprimés en appliquant fct_drop() à notre colonne de facteurs :\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_drop(delay_cat)) %&gt;% \n  tabyl(delay_cat)\n\n delay_cat    n    percent valid_percent\n   &lt;2 days 2990 0.50781250     0.5308949\n  2-5 days 2040 0.34646739     0.3622159\n   &gt;5 days  602 0.10224185     0.1068892\n      &lt;NA&gt;  256 0.04347826            NA",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#ajuster-lordre-des-niveaux-fct_adjust",
    "href": "new_pages/factors.fr.html#ajuster-lordre-des-niveaux-fct_adjust",
    "title": "11  Facteurs",
    "section": "11.4 Ajuster l’ordre des niveaux {#fct_adjust}",
    "text": "11.4 Ajuster l’ordre des niveaux {#fct_adjust}\nLe package forcats offre des fonctions utiles pour ajuster facilement l’ordre des niveaux d’un facteur (après qu’une colonne ait été définie comme facteur de classe) :\nCes fonctions peuvent être appliquées à une colonne de facteurs dans deux contextes :\n\nA la colonne dans le dataframe, comme d’habitude, afin que la transformation soit disponible pour toute utilisation ultérieure des données.\nÀ l’intérieur d’un graphique, de sorte que la modification soit appliquée uniquement à l’intérieur du graphique.\n\n\nManuellement\nCette fonction est utilisée pour ordonner manuellement les niveaux des facteurs. Si elle est utilisée sur une colonne sans facteur, la colonne sera d’abord convertie en facteur de classe.\nEntre les parenthèses, fournissez d’abord le nom de la colonne de facteur, puis fournissez soit :\n\nTous les niveaux dans l’ordre désiré (comme un vecteur de caractères c()), ou bien\nUn niveau et son placement corrigé en utilisant l’argument after =.\n\nVoici un exemple de redéfinition de la colonne delay_cat (qui est déjà de la classe Factor) et de spécification de tous les niveaux dans l’ordre souhaité.\n\n# re-define level order\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\")))\n\nSi vous voulez seulement déplacer un niveau, vous pouvez le spécifier à fct_relevel() seul et donner un nombre à l’argument after = pour indiquer où dans l’ordre il doit être. Par exemple, la commande ci-dessous déplace “&lt;2 jours” en deuxième position :\n\n# re-define level order\nlinelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", after = 1)) %&gt;% \n  tabyl(delay_cat)\n\n\n\nDans un graphe\nLes commandes forcats peuvent être utilisées pour définir l’ordre des niveaux dans le dataframe, ou seulement dans un graphique. En utilisant la commande pour “envelopper” le nom de la colonne dans la commande de traçage ggplot(), vous pouvez inverser/niveler/etc. la transformation ne s’appliquera que dans ce tracé.\nCi-dessous, deux tracés sont créés avec ggplot() (voir la page les bases de ggplot). Dans le premier, la colonne delay_cat est mise en correspondance avec l’axe des x du graphique, avec son ordre de niveau par défaut comme dans les données linelist. Dans le second exemple, elle est enveloppée dans fct_relevel() et l’ordre est modifié dans le graphe.\n\n# Ordre alphanumerique par defaut - pas d'ajustement dans ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Ordonner des niveaux de facteurs dans ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotez que le titre par défaut de l’axe des x est maintenant assez compliqué - vous pouvez changer ce titre avec l’argument ggplot2 labs().\n\n\nInverser\nIl est assez fréquent que vous vouliez inverser l’ordre des niveaux. Enveloppez simplement le facteur avec fct_rev().\nNotez que si vous voulez inverser seulement la légende du graphique mais pas les niveaux réels du facteur, vous pouvez le faire avec guides() (voir la page Astuces avec ggplot)).\n\n\nPar fréquence\nPour ordonner par fréquence que la valeur apparaît dans les données, utilisez fct_infreq(). Toute valeur manquante (NA) sera automatiquement incluse à la fin, à moins qu’elle ne soit convertie en un niveau explicite (voir cette section). Vous pouvez inverser l’ordre en enveloppant davantage avec fct_rev().\nCette fonction peut être utilisée dans un ggplot(), comme indiqué ci-dessous.\n\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# fréquence inversée\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPar apparence\nUtilisez fct_inorder() pour définir l’ordre des niveaux afin de correspondre à l’ordre d’apparition dans les données, en commençant par la première ligne. Cela peut être utile si vous avez d’abord soigneusement arrange() les données dans le cadre de données, et ensuite l’utiliser pour définir l’ordre des facteurs.\nParce que je me suis un peu éloigné des configurations du livre original, j’ai renommé le métapackage. r4ds que nous utilisons pour installer les dépendances du livre en r4dses et j’ai fait un peu de ménage dans le DESCRIPTION, .Rbuildignore et j’ai supprimé certains fichiers qui n’étaient plus nécessaires. Le résultat a été d’obtenir zéro erreur, avertissement et note lors de l’exécution de devtools::check().\nIl est important de mentionner que le dépôt de livres est, en partie, un paquetage R, et que la commande devtools::install_github(\"cienciadedatos/r4ds\") installera les dépendances du livre en en lisant le fichier DESCRIPTION qui s’y trouve.\n\n\nPar la statistique sommaire d’une autre colonne\nVous pouvez utiliser fct_reorder() pour ordonner les niveaux d’une colonne par une statistique sommaire d’une autre colonne. Visuellement, cela peut donner des graphiques agréables où les barres/points montent ou descendent régulièrement sur le graphique.\nDans les exemples ci-dessous, l’axe des x est delay_cat, et l’axe des y est la colonne numérique ct_blood (valeur du seuil de cycle). Les box plots montrent la distribution des valeurs CT par groupe delay_cat. Nous voulons ordonner les box plots dans l’ordre croissant de la valeur médiane du groupe.\nDans le premier exemple ci-dessous, l’ordre par défaut alpha-numérique est utilisé. Vous pouvez voir que les hauteurs des box plots sont mélangées et ne sont pas dans un ordre particulier. Dans le deuxième exemple, la colonne delay_cat (mappée sur l’axe des x) a été enveloppée dans fct_reorder(), la colonne ct_blood est donnée comme deuxième argument, et “median” est donné comme troisième argument (vous pourriez aussi utiliser “max”, “mean”, “min”, etc). Ainsi, l’ordre des niveaux de delay_cat reflètera maintenant les valeurs médianes croissantes de la valeur médiane de CT de chaque groupe delay_cat. Ceci est reflété dans le deuxième graphique - les box plots ont été réarrangés pour être ascendants. Notez comment NA (manquant) apparaîtra à la fin, à moins d’être converti en un niveau explicite.\n\n# boxplots ordonnés par les niveaux des facteurs initiaux\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Délai d'apparition à l'admission (jours)\",\n       title = \"Classé par niveaux alphanumériques originaux\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordonner par la mediane des valeurs de CT \nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Délai d'apparition à l'admission (jours)\",\n       title = \"Classé par valeur médiane de CT dans par groupe\" )+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotez que dans l’exemple ci-dessus, aucune étape n’est nécessaire avant l’appel à ggplot() - le regroupement et les calculs sont tous effectués en interne par la commande ggplot.\n\n\nPar la valeur “end”\nUtilisez fct_reorder2() pour des tracés de lignes groupées. Il ordonne les niveaux (et donc le légende) pour s’aligner avec l’ordre vertical des lignes à la “fin” du tracé. Techniquement parlant, il “ordonne par les valeurs y associées aux plus grandes valeurs x”.\nPar exemple, si vous avez des lignes montrant le nombre de cas par hôpital au fil du temps, vous pouvez appliquer fct_reorder2() à l’argument color = dans aes(), de sorte que l’ordre vertical des hôpitaux apparaissant dans la légende s’aligne sur l’ordre des lignes à l’extrémité du tracé. Pour en savoir plus, consultez la documentation en ligne.\n\nepidemic_data &lt;- linelist %&gt;%         # commencer avec linelist  \n    filter(date_onset &lt; as.Date(\"2014-09-21\")) %&gt;%    # point de coupure  la date, pour une meilleur visualisation\n    count(                                            # obtenir le nombre de cas par semaine et par hôpital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # debut pour representaton graphique\n  geom_line(                                        # faire des lignes\n    aes(\n      x = epiweek,                                  # l'axe x est epiweek\n      y = n,                                        # l'axe y est le nombre de cas par semaine\n      color = fct_reorder2(hospital, epiweek, n)))+ # données regroupées et colorées par hôpital, avec un ordre des facteurs par hauteur à la fin du graphique\n  labs(title = \"Niveaux des facteurs (et affichage de la légende) par hauteur de ligne à la fin du grahpique\",\n       color = \"Hôpital\")                          # changer le titre de la legende",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#valeurs-manquantes-fct_missing",
    "href": "new_pages/factors.fr.html#valeurs-manquantes-fct_missing",
    "title": "11  Facteurs",
    "section": "11.5 Valeurs manquantes {#fct_missing}",
    "text": "11.5 Valeurs manquantes {#fct_missing}\nSi vous avez des valeurs NA dans votre colonne de facteurs, vous pouvez facilement les convertir en un niveau nommé tel que “Missing” avec fct_explicit_na(). Les valeurs NA sont converties en “(Missing)” à la fin de l’ordre des niveaux par défaut. Vous pouvez ajuster le nom du niveau avec l’argument na_level =.\nCi-dessous, cette opération est effectuée sur la colonne delay_cat et un tableau est imprimé avec tabyl() avec NA converti en “Missing delay”.\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %&gt;% \n  tabyl(delay_cat)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing\n  delay\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\n     delay_cat    n    percent\n      2-5 days 2040 0.34646739\n       &lt;2 days 2990 0.50781250\n       &gt;5 days  602 0.10224185\n Missing delay  256 0.04347826\n\n\n\n11.5.1 Combiner les niveaux\n\n\nManuellement\nVous pouvez ajuster l’affichage des niveaux manuellement avec fct_recode(). C’est comme la fonction dplyr recode() (voir Nettoyage des données et fonctions de base), mais elle permet la création de nouveaux niveaux de facteurs. Si vous utilisez le simple recode() sur un facteur, les nouvelles valeurs recodées seront rejetées à moins qu’elles n’aient déjà été définies comme des niveaux admissibles.\nCet outil peut aussi être utilisé pour “combiner” des niveaux, en assignant à plusieurs niveaux la même valeur re-codée. Veillez simplement à ne pas perdre d’informations ! Pensez à effectuer ces étapes de combinaison dans une nouvelle colonne (sans écraser la colonne existante).\nfct_recode() a une syntaxe différente de celle de recode(). recode() utilise OLD = NEW, alors que fct_recode() utilise NEW = OLD.\nLes niveaux actuels de delay_cat sont :\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nLes nouveaux niveaux sont créés à l’aide de la syntaxe fct_recode(colonne, \"nouveau\" = \"ancien\", \"nouveau\" = \"ancien\", \"nouveau\" = \"ancien\") et imprimés :\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"&lt;2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 2 days 2990 0.50781250     0.5308949\n      2 to 5 days 2040 0.34646739     0.3622159\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\nIci, ils sont combinés manuellement avec fct_recode(). Notez qu’aucune erreur n’est soulevée lors de la création d’un nouveau niveau “Moins de 5 jours”.\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"&lt;2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 5 days 5030 0.85427989     0.8931108\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\n\n\nRéduire en “Autre”\nVous pouvez utiliser fct_other() pour assigner manuellement des niveaux de facteurs à un niveau “Autre”. Ci-dessous, tous les niveaux de la colonne hospital, à part “Port Hospital” et “Central Hospital”, sont combinés dans “Other”. Vous pouvez fournir un vecteur pour soit maintenir =, soit drop =. Vous pouvez modifier l’affichage du niveau “Autre” avec other_level =.\n\nlinelist %&gt;%    \n  mutate(hospital = fct_other(                      # ajuster niveaux\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # garder  ceux ci separer\n    other_level = \"Other Hospital\")) %&gt;%            # Considerer tout autre niveau comme  \"Other Hospital\"\n  tabyl(hospital)                                   # afficher tableau\n\n         hospital    n    percent\n Central Hospital  454 0.07710598\n    Port Hospital 1762 0.29925272\n   Other Hospital 3672 0.62364130\n\n\n\n\nRéduire par fréquence\nVous pouvez combiner automatiquement les niveaux de facteurs les moins fréquents en utilisant fct_lump().\nPour “regrouper” plusieurs niveaux à basse fréquence dans un groupe “Autre”, faites l’une des choses suivantes :\n\nDéfinissez n = comme le nombre de groupes que vous voulez garder. Les n niveaux les plus fréquents seront conservés, et tous les autres seront regroupés dans “Autres”.\nDéfinissez prop = comme étant la proportion de fréquence seuil pour les niveaux au-dessus desquels vous voulez garder. Toutes les autres valeurs seront regroupées dans “Autres”.\n\nVous pouvez modifier l’affichage du niveau “Autre” avec other_level =. Ci-dessous, tous les hôpitaux sauf les deux les plus fréquents sont combinés dans “Autre hôpital”.\n\nlinelist %&gt;%    \n  mutate(hospital = fct_lump(                      # ajuster niveaux\n    hospital,\n    n = 2,                                          # garder les  2 premiers  niveaux\n    other_level = \"Other Hospital\")) %&gt;%            #  Considerer tout autre niveau comme  \"Other Hospital\"\n  tabyl(hospital)                                   # afficher tableau\n\n       hospital    n   percent\n        Missing 1469 0.2494905\n  Port Hospital 1762 0.2992527\n Other Hospital 2657 0.4512568",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#afficher-tous-les-niveaux",
    "href": "new_pages/factors.fr.html#afficher-tous-les-niveaux",
    "title": "11  Facteurs",
    "section": "11.6 Afficher tous les niveaux",
    "text": "11.6 Afficher tous les niveaux\nL’un des avantages de l’utilisation des facteurs est de standardiser l’apparence des légendes et des tableaux des graphiques, quelles que soient les valeurs réellement présentes dans un ensemble de données.\nSi vous préparez de nombreuses figures (par exemple, pour plusieurs juridictions), vous voudrez que les légendes et les tableaux apparaissent de manière identique, même si les niveaux de complétion ou de composition des données varient.\n\nDans les graphiques\nDans une figure ggplot(), ajoutez simplement l’argument drop = FALSE dans la fonction scale_xxxx() concernée. Tous les niveaux de facteurs seront affichés, qu’ils soient présents ou non dans les données. Si les niveaux de vos colonnes de facteurs sont affichés en utilisant fill =, alors dans scale_fill_discrete() vous incluez drop = FALSE, comme indiqué ci-dessous. Si vos niveaux sont affichés avec x = (sur l’axe des x) color = ou size =, vous devez le fournir à scale_color_discrete() ou scale_size_discrete() en conséquence.\nCet exemple est un diagramme à barres empilées de la catégorie d’âge, par hôpital. L’ajout de scale_fill_discrete(drop = FALSE) garantit que tous les groupes d’âge apparaissent dans la légende, même s’ils ne sont pas présents dans les données.\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # montrer tous les groupes d'âge dans la légende, même ceux qui ne sont pas présents\n  labs(\n    title = \"Tous les groupes d'âge apparaissent dans la légende, même s'ils ne sont pas présents dans les données\")\n\n\n\n\n\n\n\n\n\n\nDans les tableaux\nTant le base R table() que tabyl() de janitor montreront tous les niveaux de facteurs (même les niveaux non utilisés).\nSi vous utilisez count() ou summarise() de dplyr pour faire une table, ajoutez l’argument .drop = FALSE pour inclure les comptes pour tous les niveaux de facteurs, même ceux qui ne sont pas utilisés.\nPour en savoir plus, consultez la page Descriptive tables, ou la documentation scale_discrete, ou la documentation count(). Vous pouvez voir un autre exemple à la page Suivi des contacts.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#epiweeks",
    "href": "new_pages/factors.fr.html#epiweeks",
    "title": "11  Facteurs",
    "section": "11.7 Epiweeks",
    "text": "11.7 Epiweeks\nVeuillez consulter la discussion approfondie sur la création de semaines épidémiologiques à la page Regroupement des données.\nVeuillez également consulter la page Travailler avec des dates pour obtenir des conseils sur la façon de créer et de formater des semaines épidémiologiques.\n\nSemaines épidémiologiques dans un graphique\nSi votre objectif est de créer des semaines épidémiologiques à afficher dans un graphique, vous pouvez le faire simplement avec la fonction floor_date() de lubridate, comme expliqué dans la page Regroupement de données. Les valeurs retournées seront de la classe Date avec le format AAAA-MM-JJ. Si vous utilisez cette colonne dans un graphique, les dates seront naturellement ordonnées correctement, et vous n’aurez pas à vous soucier des niveaux ou de la conversion en classe Facteur. Voir l’histogramme ggplot() des dates d’apparition ci-dessous.\nDans cette approche, vous pouvez ajuster l’affichage des dates sur un axe avec scale_x_date(). Voir la page sur les Courbes épidémiques pour plus d’informations. Vous pouvez spécifier un format d’affichage “strptime” à l’argument date_labels = de scale_x_date(). Ces formats utilisent des caractères de remplacement “%” et sont traités dans la page Manipuler les dates. Utilisez “%Y” pour représenter une année à 4 chiffres, et “%W” ou “%U” pour représenter le numéro de la semaine (semaines du lundi ou du dimanche respectivement).\n\nlinelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %&gt;%  # créer une colonne semaine\n  ggplot()+                                                  # commencer ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogramme de la date d'apparition\n  scale_x_date(date_labels = \"%Y-W%W\")                       # ajuster la répartition des dates pour qu'elle soit YYYY-WWw\n\n\n\n\n\n\n\n\n\n\nEpiweeks dans les données\nCependant, si le but de la factorisation n’est pas de tracer, vous pouvez l’aborder de deux façons :\n\n\nPour un contrôle précis de l’affichage, convertissez la colonne lubridée des épihebdomadaires (AAAA-MM-JJ) au format d’affichage souhaité (AAAA-WWW) dans le cadre de données lui-même, puis convertissez-la en classe Factor.\n\n\nTout d’abord, utilisez format() de base R pour convertir l’affichage de la date de YYYY-MM-DD en YYYY-Www (voir la page Manipuler les dates). Dans ce processus, la classe sera convertie en caractère. Ensuite, convertissez le caractère en classe Factor avec factor().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # creer epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convertir pour afficher (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convertir un facteur\n\n# Afficher les niveaux\nlevels(linelist$epiweek_formatted)\n\n [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\"\n [7] \"2014-W19\" \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\"\n[13] \"2014-W25\" \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\"\n[19] \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\" \"2014-W35\" \"2014-W36\"\n[25] \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\" \"2014-W41\" \"2014-W42\"\n[31] \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\" \"2014-W48\"\n[37] \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\"\n[43] \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\"\n[49] \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\"\n[55] \"2015-W15\" \"2015-W16\"\n\n\nDANGERS: Si vous placez les semaines avant les années (“Www-YYYY”) (“%W-%Y”), l’ordre par défaut des niveaux alphanumériques sera incorrect (par exemple, 01-2015 sera avant 35-2014). Vous pourriez avoir besoin d’ajuster manuellement l’ordre, ce qui serait un processus long et difficile..\n\nPour un affichage rapide par défaut, utilisez le package aweek et sa fonction date2week(). Vous pouvez définir le jour week_start =, et si vous définissez factor = TRUE alors la colonne de sortie est un facteur ordonné. En prime, le facteur inclut des niveaux pour toutes les semaines possibles dans l’intervalle - même s’il n’y a pas de cas cette semaine-là.\n\n\ndf &lt;- linelist %&gt;% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)\n\nVoir la page Manipuler les dates pour plus d’informations sur aweek. Il propose également la fonction inverse week2date().",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.fr.html#ressources",
    "href": "new_pages/factors.fr.html#ressources",
    "title": "11  Facteurs",
    "section": "11.8 Ressources",
    "text": "11.8 Ressources\nR for Data Science page on factors\naweek package vignette",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Facteurs</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.fr.html",
    "href": "new_pages/pivoting.fr.html",
    "title": "12  Restructurer les données",
    "section": "",
    "text": "12.1 Étapes préliminaires",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Restructurer les données</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.fr.html#pivot_prep_data",
    "href": "new_pages/pivoting.fr.html#pivot_prep_data",
    "title": "12  Restructurer les données",
    "section": "",
    "text": "Importation des paquets\nCes lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,          # import des fichiers\n  here,         # gestion des chemins d'accès\n  kableExtra,\n  tidyverse)    # gestion des données + graphiques (ggplot2)\n\n\n\nImportation des données\n\n\nCas de Malaria\nDans ce chapitre, nous utiliserons un jeu de données fictif de cas quotidiens de paludisme, par établissement et par groupe d’âge. Pour reproduire les étapes, cliquez ici pour télécharger les données (en tant que fichier .rds). Ou importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation des données pour plus de détails).\n\n# Importation des données\ncount_data &lt;- import(\"malaria_facility_count_data.rds\")\n\nLes premières cinquantes lignes sont affichées ci-dessous.\n\n\n\n\n\n\n\n\nLinelist des cas\nA la fin de ce chapitre, nous utiliserons également une liste des cas d’une épidémie d’Ebola simulée. Pour reproduire les étapes, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation des données pour plus de détails).\n\n# Importer la linelist\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Restructurer les données</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.fr.html#transformation-du-format-large-vers-long",
    "href": "new_pages/pivoting.fr.html#transformation-du-format-large-vers-long",
    "title": "12  Restructurer les données",
    "section": "12.2 Transformation du format large vers long",
    "text": "12.2 Transformation du format large vers long\n\n\n\n\n\n\n\n\n\n\n\nLe format “large”\nLes données sont souvent saisies et stockées dans un format “large” (ou “étendu”), où les caractéristiques ou les réponses d’un sujet/d’un item sont entrées dans une même ligne. Cette structure de données est utile pour la saisie et la présentation des données, mais elle n’est pas appropriée pour de nombreuses analyses.\nPar exemple, dans le jeu de données count_data importé auparavant, chaque ligne représente un établissement à une date donnée. Les nombres de cas sont contenus dans les colonnes les plus à droites, avec une colonne par classe d’age, et une colonne pour le nombre total de cas ce jour là dans cet établissement. L’information “nombre de cas” est donc contenues sur plusieurs colonnes, au lieu d’une seule, d’où la structure dite “large”.\n\n\n\n\n\n\nPlus précisément, chaque ligne dans ce tableau contient le nombre de cas de paludisme dans l’un des 65 établissements à une date donnée, dans la période allant de count_data$data_date %&gt;% min() à count_data$data_date %&gt;% max(). Ces établissements sont situés dans une province (Nord) et quatre districts (Spring, Bolo, Dingo, et Barnard). Le dataframe contient les totaux des cas de paludisme, globaux et pour chaque classe d’age (&lt;4 ans, 5-14 ans, et 15 ans et plus).\nLes données sous format “large” comme celle-ci ne respectent pas les normes de “données rangées”, car les en-têtes de colonne ne représentent pas réellement des “variables”: ils contiennent les valeurs d’une hypothétique variable “groupe d’âge”.\nCe format est utile pour présenter les informations dans un tableau, ou pour saisir des données (dans Excel par exemple) à partir de formulaires de notification des cas. Cependant, au stade de l’analyse, ces données doivent généralement être restructurées et rangées en un format plus long. Le paquet de visualisations ggplot2, fonctionne également mieux lorsque les données sont dans un format “long”.\nLa visualisation du nombre total de cas de paludisme dans le temps ne pose aucun problème avec les données dans leur format actuel :\n\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)\n\n\n\n\n\n\n\n\nCependant, les choses se compliquent si l’on veut visualiser les contributions relatives de chaque groupe d’âge au total des cas ? Nous devons alors nous assurer que la variable d’intérêt (le groupe d’âge) ait sa propre colonne dans le dataframe, colonne qui peut être passée à l’argument “mapping aesthetics” aes() de {ggplot2}.\n\n\n\npivot_longer()\nLa fonction pivot_longer() de tidyr transforme un jeu de données au format “large” en un jeu de données “plus long”. tidyr fait partie du méta-paquet tidyverse.\nElle accepte une ou plusieurs colonnes à transformer (argument cols =), ce qui donne un contrôle fin sur les colonnes à restructurer. Par exemple, pour les données sur le paludisme, nous ne voulons faire pivoter que les colonnes contenant des nombre de cas.\nSuite à ce processus, nous obtenons deux “nouvelles” colonnes: l’une contenant les catégories (anciennement sotckées dans les noms de colonnes), et l’autre avec les valeurs correspondantes (ici, le nombre de cas). Nous pouvons accepter les noms par défaut pour ces nouvelles colonnes, ou spécifier de nouveaux noms dans names_to = et values_to = respectivement.\nVoyons comment utiliser pivot_longer()…\n\n\nTransformation simple\nNous utilisons la fonction pivot_longer() de tidyr pour convertir les données d’un format “large” à un format “long”. Plus précisément, il s’agit de convertir les quatre colonnes numériques contenant des nombre de cas de paludisme en deux nouvelles colonnes : une qui contient les groupes d’âge et une qui contient les valeurs correspondantes.\n\ndf_long &lt;- count_data %&gt;% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, \n             `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n\nNotons que le dataframe nouvellement crée (df_long) a plus de lignes (12 152 contre 3 038) : il est devenu plus long. Pour être précis, il est quatre fois plus long, car chaque ligne du tableau d’origine a donné quatre lignes dans `df_long``, une pour chacun des colonnes restructurées (&lt;4 ans, 5-14 ans, 15 ans et plus, et total).\nLe nouveau tableau a également moins de colonnes (8 contre 10), car les données précédemment stockées dans quatre colonnes (celles qui commencent par le préfixe malaria_) sont maintenant stockées dans deux colonnes.\nNote : puisque les noms de quatre colonnes transformées commencent tous par le préfixe malaria_, nous aurions pu sélectionner les colonnes à transformer en utilisant la fonction starts_with() pour obtenir le même résultat (voir la page sur le nettoyage des données et les fonctions de base pour plus de ces fonctions d’aide de type “tidyselect”).\n\n# choisir les colonnes avec l'aide d'une fonction \"tidyselect\"\ncount_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid name    value\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    11\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    12\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    23\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    46\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    11\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    10\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…     5\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    26\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     8\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     5\n# ℹ 12,142 more rows\n\n\nou par position :\n\n# Choisir les colonnes à partir de leur position dans le tableau\ncount_data %&gt;% \n  pivot_longer(\n    cols = 6:9\n  )\n\nou dans le cas de colonnes consécutives, avec la première et la dernière colonne :\n\n# Choisir les colonnes avec un \"intervalle\"\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\n\nLes deux nouvelles colonnes crées lors de la restructuration reçoivent les noms par défaut de name et value, mais nous pouvons remplacer ces valeurs par défaut par des noms qui décrivent mieux le contenu des colonnes en utilisant les arguments names_to et values_to. Par exemple, si nous voulons renommer les colonnes age_group et counts :\n\ndf_long &lt;- count_data %&gt;% \n  pivot_longer(\n    cols      = starts_with(\"malaria_\"),\n    names_to  = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid age_group    \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;        \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot  \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot  \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n# ℹ 12,142 more rows\n# ℹ 1 more variable: counts &lt;int&gt;\n\n\nNous pouvons maintenant passer ce nouveau jeu de données à {ggplot2}, et placer la nouvelle colonne count dans l’axe des y et colorer les barres en fonction des valeurs de la colonne age_group grâce à l’argument fill =. Nous obtenons alors un diagramme en bâtons des cas de paludisme par groupe d’âge :\n\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date,\n                  y = counts, \n                  fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nExaminez ce nouveau tracé et comparez-le avec le tracé que nous avons créé précédemment : qu’est-ce qui cloche ?\nNous fait une erreur classique du traitement des données de surveillance et inclus le nombre de cas totaux de la colonne malaria_tot. La conséquence est que chaque barre du graphique est deux fois plus élevée qu’elle ne devrait l’être.\nNous pouvons résoudre ce problème de plusieurs façons. Tout d’abord nous pouvons simplement filtrer les données avant de les passer à ggplot() :\n\ndf_long %&gt;% \n  filter(age_group != \"malaria_tot\") %&gt;% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, \n        y = counts, \n        fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nAutrement, nous aurions pu exclure cette variable lors du pivot_longer(), la conservant comme une variable séparée dans le tableau :\n\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\n# A tibble: 9,114 × 9\n   location_name data_date  submitted_date Province District malaria_tot newid\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4\n# ℹ 9,104 more rows\n# ℹ 2 more variables: age_group &lt;chr&gt;, counts &lt;int&gt;\n\n\nLes valeurs sont alors répétées dans les lignes des groupes d’age.\n\n\nTransformer les données de plusieurs classes\nL’exemple ci-dessus fonctionne bien dans les situations où toutes les colonnes que l’on veut faire pivoter sont de la même classe (chaîne de caractère, numérique, logique…).\nCependant, en tant qu’épidémiologiste de terrain, vous serez amené à travailler avec des données qui ont été préparées par des non-spécialistes, appliquant leur propre logique. Cela aboutit parfois à des jeux de données non-standard, voire totalement désorganisés. Comme Hadley Wickham l’a noté (en faisant référence à Tolstoï) dans son article séminal sur les principes des données rangées, organisées (tidy data) :\n\nComme les familles, les tableaux de données rangés et organisés se ressemblent tous, mais chaque fichier de données désorganisé / mal rangé l’est à sa manière.\n\nUn problème particulièrement courant est la nécessité de restructurer des colonnes qui contiennent différentes types de données. Cette transformation aurait pour conséquence de stocker différents types de données dans une seule colonne, ce qui est déconseillé. Il y a plusieurs manière de gérer les problèmes associés à ce type de données mais la restructuration avec pivot_longer() est une étape importante.\nImaginons cette situation : une série d’observations a été effectuée à différents pas de temps pour chacun des trois éléments A, B et C. Il peut s’agir d’individus (par exemple, les contacts d’un cas d’Ebola sont suivis chaque jour pendant 21 jours) ou de postes de santé de villages éloignés qui sont contrôlés une fois par an pour s’assurer qu’ils sont toujours fonctionnels. Reprenons l’exemple de la recherche des contacts. Imaginons que les données soient stockées comme suit :\n\n\n\n\n\n\nLe format de ces données est un peu plus compliqué que dans l’exemple précédent : chaque ligne stocke des informations sur un élément, et des paires de colonnes contiennent des séries d’observations à différentes dates. Le fichier s’allonge avec de nouvelles colonnes à droite au fur et à mesure des observations. Les classes de colonnes alternent entre dates et chaînes de caractères.\nPour la petite histoire, un des pires exemples de ce type de données qu’il m’ait été donné de rencontrer concernait des données de surveillance du choléra, dans lesquelles 8 nouvelles colonnes d’observations étaient ajoutées chaque jour, pendant 4 ans. L’ouverture du fichier Excel sur mon ordinateur portable a pris plus de dix minutes…\nPour travailler avec ces données, nous devons les transformer en format “long” tout en gardant la séparation entre une colonne date et une colonne caractère (statut), pour chaque observation pour chaque élément. Ceci afin d’éviter de nous retrouver avec un mélange de types de variables dans une seule colonne, une situation que vous devrez chercher à éviter à tout prix dans votre gestion de données, en particulier avec des données ordonnées.\nC’est malheureusement ce qui se produit si l’on effectue une transformation simple :\n\ndf %&gt;% \n  pivot_longer(\n    cols     = -id,\n    names_to = c(\"observation\")\n  )\n\n# A tibble: 18 × 3\n   id    observation value     \n   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;     \n 1 A     obs1_date   2021-04-23\n 2 A     obs1_status Healthy   \n 3 A     obs2_date   2021-04-24\n 4 A     obs2_status Healthy   \n 5 A     obs3_date   2021-04-25\n 6 A     obs3_status Unwell    \n 7 B     obs1_date   2021-04-23\n 8 B     obs1_status Healthy   \n 9 B     obs2_date   2021-04-24\n10 B     obs2_status Healthy   \n11 B     obs3_date   2021-04-25\n12 B     obs3_status Healthy   \n13 C     obs1_date   2021-04-23\n14 C     obs1_status Missing   \n15 C     obs2_date   2021-04-24\n16 C     obs2_status Healthy   \n17 C     obs3_date   2021-04-25\n18 C     obs3_status Healthy   \n\n\nCi-dessus, notre restructuration a fusionné dates et caractères en une seule colonne valeur. Face à deux colonnes de classes différentes, la fonction convertit par défaut la colonne entière en chaîne de caractères.\nPour éviter cette situation, nous pouvons tirer parti de la structure des noms de colonnes dans le tableau original, qui respectent le même format : le numéro de l’observation, un “_” puis soit “statut” soit “date”.\nPour cela, il nous faut :\n\nfournir un vecteur de chaîne de caractères un peu spécial à l’argument names_to =. Dans ce vecteur, le second élément est \".value\", ce terme spécial indiquant que les colonnes restructurées seront divisées sur la base d’un mot dans le nom des colonnes.\nfournir le caractère utilisé comme séparateur à l’argument names_sep = . Dans le cas présent, il s’agit du tiret-bas “_“.\n\nAinsi, le nommage et la division des nouvelles colonnes sont basés sur le “_” dans les noms des variables existantes.\n\ndf_long &lt;- \n  df %&gt;% \n  pivot_longer(\n    cols      = -id,\n    names_to  = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  \n1 A     obs1        2021-04-23 Healthy\n2 A     obs2        2021-04-24 Healthy\n3 A     obs3        2021-04-25 Unwell \n4 B     obs1        2021-04-23 Healthy\n5 B     obs2        2021-04-24 Healthy\n6 B     obs3        2021-04-25 Healthy\n7 C     obs1        2021-04-23 Missing\n8 C     obs2        2021-04-24 Healthy\n9 C     obs3        2021-04-25 Healthy\n\n\nDerniers détails :\nLa colonne date est actuellement sous la forme d’une chaîne de caractères mais nous pouvons facilement la convertir en classe date en utilisant les fonctions mutate() et as_date() décrites dans la page travailler avec des dates.\nNous pouvons aussi améliorer la colonne observation en supprimant le préfixe “obs” et en la convertissant en format numérique. Nous pouvons le faire avec str_remove_all() du paquet stringr (voir la page sur les chaînes de caractères).\n\ndf_long &lt;- \n  df_long %&gt;% \n  mutate(\n    date = date %&gt;% lubridate::as_date(),\n    observation = \n      observation %&gt;% \n      str_remove_all(\"obs\") %&gt;% \n      as.numeric()\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;  \n1 A               1 2021-04-23 Healthy\n2 A               2 2021-04-24 Healthy\n3 A               3 2021-04-25 Unwell \n4 B               1 2021-04-23 Healthy\n5 B               2 2021-04-24 Healthy\n6 B               3 2021-04-25 Healthy\n7 C               1 2021-04-23 Missing\n8 C               2 2021-04-24 Healthy\n9 C               3 2021-04-25 Healthy\n\n\nNous pouvons maintenant travailler avec les données dans ce format allongé. par exemple, en créant une carte de chaleur :\n\nggplot(data = df_long, \n       mapping = aes(x = date, \n                     y = id, \n                     fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\"  = \"red\", \n        \"Missing\" = \"orange\")\n  )",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Restructurer les données</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.fr.html#transformation-du-format-long-en-large",
    "href": "new_pages/pivoting.fr.html#transformation-du-format-long-en-large",
    "title": "12  Restructurer les données",
    "section": "12.3 Transformation du format long en large",
    "text": "12.3 Transformation du format long en large\n\n\n\n\n\n\n\n\n\nIl peut être utile de transformer un jeu de données d’un format “long” en un format plus large à l’aide de la fonction pivot_wider().\nUn cas d’utilisation typique est lorsque qu’il faut transformer les résultats d’une analyse dans un format plus digeste pour le lecteur, tel qu’un tableau résumé. En général, il s’agit de transformer un dataframe dans lequel les informations relatives à un sujet sont réparties sur plusieurs lignes en un format dans lequel ces informations sont stockées sur une seule ligne.\n\nDonnées utilisées\nPour cette section nous utiliserons la liste des cas (voir la section Etapes préliminaires), qui contient une ligne par cas.\nVoici les 50 premières lignes :\n\n\n\n\n\n\nImaginons que nous voulions voir les nombres d’individus dans les différentes classes d’age, par genre :\n\ndf_wide &lt;- \n  linelist %&gt;% \n  count(age_cat, gender)\n\ndf_wide\n\n   age_cat gender   n\n1      0-4      f 640\n2      0-4      m 416\n3      0-4   &lt;NA&gt;  39\n4      5-9      f 641\n5      5-9      m 412\n6      5-9   &lt;NA&gt;  42\n7    10-14      f 518\n8    10-14      m 383\n9    10-14   &lt;NA&gt;  40\n10   15-19      f 359\n11   15-19      m 364\n12   15-19   &lt;NA&gt;  20\n13   20-29      f 468\n14   20-29      m 575\n15   20-29   &lt;NA&gt;  30\n16   30-49      f 179\n17   30-49      m 557\n18   30-49   &lt;NA&gt;  18\n19   50-69      f   2\n20   50-69      m  91\n21   50-69   &lt;NA&gt;   2\n22     70+      m   5\n23     70+   &lt;NA&gt;   1\n24    &lt;NA&gt;   &lt;NA&gt;  86\n\n\nCette commande renvoi un dataframe en format long, qui est très adapté à la création de graphiques avec ggplot2, mais moins idéal pour un tableau résumé dans un rapport :\n\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))\n\n\n\n\n\n\n\n\nNous pouvons utiliser la fonction pivot_wider() pour restructurer les données dans un format plus lisible par un lecteur humain.\n\n\npivot_wider()\nL’argument names_from spécifie la colonne depuis laquelle générer les nouveaux noms de colonne, tandis que l’argument values_from spécifie la colonne depuis laquelle prendre les valeurs pour remplir les cellules. L’argument id_cols = est facultatif, mais peut servir à fournir un vecteur de noms de colonnes qui ne doivent pas être pivotées, et qui serviront d’identifiant pour chaque ligne.\n\ntable_wide &lt;- \n  df_wide %&gt;% \n  pivot_wider(\n    id_cols     = age_cat,\n    names_from  = gender,\n    values_from = n\n  )\n\ntable_wide\n\n# A tibble: 9 × 4\n  age_cat     f     m  `NA`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 0-4       640   416    39\n2 5-9       641   412    42\n3 10-14     518   383    40\n4 15-19     359   364    20\n5 20-29     468   575    30\n6 30-49     179   557    18\n7 50-69       2    91     2\n8 70+        NA     5     1\n9 &lt;NA&gt;       NA    NA    86\n\n\nCe tableau est beaucoup plus facile à lire, et est une base pour créer des tableaux résumés dans des rapports et articles. Nous pouvons améliorer son apparence à l’aide de paquets tels que flextable et knitr (voir la page Tableaux pour la présentation.\n\ntable_wide %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% # adds row and column totals\n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 10, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nage_cat\nf\nm\nNA\nTotal\n\n\n\n\n0-4\n640\n416\n39\n1095\n\n\n5-9\n641\n412\n42\n1095\n\n\n10-14\n518\n383\n40\n941\n\n\n15-19\n359\n364\n20\n743\n\n\n20-29\n468\n575\n30\n1073\n\n\n30-49\n179\n557\n18\n754\n\n\n50-69\n2\n91\n2\n95\n\n\n70+\nNA\n5\n1\n6\n\n\nNA\nNA\nNA\n86\n86\n\n\nTotal\n2807\n2803\n278\n5888",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Restructurer les données</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.fr.html#remplissage-des-colonnes",
    "href": "new_pages/pivoting.fr.html#remplissage-des-colonnes",
    "title": "12  Restructurer les données",
    "section": "12.4 Remplissage des colonnes",
    "text": "12.4 Remplissage des colonnes\nParfois, après un pivot, ou plus fréquemment après un bind, nous nous retrouvons avec des vides dans certaines cellules que nous aimerions remplir.\n\n\nDonnées\nPar exemple, prenons deux jeux de données qui contiennent tout deux des observations pour le numéro de mesure, le nom de l’établissement et le nombre de cas à ce moment-là. En plus de cela, le deuxième jeu de données a également une variable Year.\n\ndf1 &lt;- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 \n\n# A tibble: 9 × 3\n  Measurement Facility Cases\n        &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1           1 Hosp 1      66\n2           2 Hosp 1      26\n3           3 Hosp 1       8\n4           1 Hosp 2      71\n5           2 Hosp 2      62\n6           3 Hosp 2      70\n7           1 Hosp 3      47\n8           2 Hosp 3      70\n9           3 Hosp 3      38\n\ndf2 &lt;- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2\n\n# A tibble: 3 × 4\n   Year Measurement Facility Cases\n  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1  2000           1 Hosp 4      82\n2  2001           2 Hosp 4      87\n3  2002           3 Hosp 4      46\n\n\nLorsque nous effectuons une liaison avec bind_rows() pour joindre les deux ensembles de données ensemble, la variable Year est remplie avec de NA pour les lignes où il n’y avait pas d’information préalable (c’est-à-dire le premier ensemble de données) :\n\ndf_combined &lt;- \n  bind_rows(df1, df2) %&gt;% \n  arrange(Measurement, Facility)\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66    NA\n 2           1 Hosp 2      71    NA\n 3           1 Hosp 3      47    NA\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26    NA\n 6           2 Hosp 2      62    NA\n 7           2 Hosp 3      70    NA\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8    NA\n10           3 Hosp 2      70    NA\n11           3 Hosp 3      38    NA\n12           3 Hosp 4      46  2002\n\n\n\n\n\nfill()\nDans ce cas, Year est une variable utile à inclure si nous souhaitons explorer les tendances temporelle. Nous pouvons utiliser fill() pour remplir les cellules vides, en spécifiant la colonne à remplir et la direction (dans ce cas up) :\n\ndf_combined %&gt;% \n  fill(Year, .direction = \"up\")\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66  2000\n 2           1 Hosp 2      71  2000\n 3           1 Hosp 3      47  2000\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26  2001\n 6           2 Hosp 2      62  2001\n 7           2 Hosp 3      70  2001\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8  2002\n10           3 Hosp 2      70  2002\n11           3 Hosp 3      38  2002\n12           3 Hosp 4      46  2002\n\n\nAlternativement, nous pouvons réordonner les données pour remplir vers le bas :\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  arrange(Measurement, desc(Facility))\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47    NA\n 3           1 Hosp 2      71    NA\n 4           1 Hosp 1      66    NA\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70    NA\n 7           2 Hosp 2      62    NA\n 8           2 Hosp 1      26    NA\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38    NA\n11           3 Hosp 2      70    NA\n12           3 Hosp 1       8    NA\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  fill(Year, .direction = \"down\")\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47  2000\n 3           1 Hosp 2      71  2000\n 4           1 Hosp 1      66  2000\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70  2001\n 7           2 Hosp 2      62  2001\n 8           2 Hosp 1      26  2001\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38  2002\n11           3 Hosp 2      70  2002\n12           3 Hosp 1       8  2002\n\n\nNous avons à présent un jeu de données facilement visualisable à l’aide de ggplot2 :\n\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\n\n\n\n\n\n\n\n\nMais ce jeu de données est peu lisible si présenté tel quel dans un rapport. Nous pouvons appliquer pivot_larger() pour le transformer en un format plus large :\n\ndf_combined %&gt;% \n  pivot_wider(\n    id_cols     = c(Measurement, Facility),\n    names_from  = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  arrange(Facility) %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% \n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 5, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\nTotal\n\n\n\n\n1\nHosp 1\n66\nNA\nNA\n66\n\n\n2\nHosp 1\nNA\n26\nNA\n26\n\n\n3\nHosp 1\nNA\nNA\n8\n8\n\n\n1\nHosp 2\n71\nNA\nNA\n71\n\n\n2\nHosp 2\nNA\n62\nNA\n62\n\n\n3\nHosp 2\nNA\nNA\n70\n70\n\n\n1\nHosp 3\n47\nNA\nNA\n47\n\n\n2\nHosp 3\nNA\n70\nNA\n70\n\n\n3\nHosp 3\nNA\nNA\n38\n38\n\n\n1\nHosp 4\n82\nNA\nNA\n82\n\n\n2\nHosp 4\nNA\n87\nNA\n87\n\n\n3\nHosp 4\nNA\nNA\n46\n46\n\n\nTotal\n-\n266\n245\n162\n673\n\n\n\n\n\n\n\n\nNote : dans ce cas, nous avons dû spécifier de n’inclure que les trois variables Facility, Year, et Cases car la variable supplémentaire Measurement interférait avec la création de la table :\n\ndf_combined %&gt;% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  knitr::kable()\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\n\n\n\n\n1\nHosp 4\n82\nNA\nNA\n\n\n1\nHosp 3\n47\nNA\nNA\n\n\n1\nHosp 2\n71\nNA\nNA\n\n\n1\nHosp 1\n66\nNA\nNA\n\n\n2\nHosp 4\nNA\n87\nNA\n\n\n2\nHosp 3\nNA\n70\nNA\n\n\n2\nHosp 2\nNA\n62\nNA\n\n\n2\nHosp 1\nNA\n26\nNA\n\n\n3\nHosp 4\nNA\nNA\n46\n\n\n3\nHosp 3\nNA\nNA\n38\n\n\n3\nHosp 2\nNA\nNA\n70\n\n\n3\nHosp 1\nNA\nNA\n8",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Restructurer les données</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.fr.html#resources",
    "href": "new_pages/pivoting.fr.html#resources",
    "title": "12  Restructurer les données",
    "section": "12.5 Resources",
    "text": "12.5 Resources\nVoici un tutoriel utilel",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Restructurer les données</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html",
    "href": "new_pages/grouping.fr.html",
    "title": "13  Travailler sur des données groupées",
    "section": "",
    "text": "13.1 Étapes préliminaires",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#étapes-préliminaires",
    "href": "new_pages/grouping.fr.html#étapes-préliminaires",
    "title": "13  Travailler sur des données groupées",
    "section": "",
    "text": "Importation des paquets\nCes lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,       # import des fichiers\n  here,      # gestion des chemins d'accès\n  tidyverse, # gestion des données + graphiques (inclus dplyr)\n  janitor)   # ajout de totaux aux lignes et colonnes\n\n\n\nImport des données\nDans ce chapitre, nous utiliserons un jeu de données fictif pour une épidémie d’Ebola. Pour reproduire les étapes, cliquez pour télécharger la liste “nettoyée” (sous forme de fichier .rds). Le jeu de données est importé à l’aide de la fonction import() du paquet rio. voir la page Importation et exportation des données pour plus de détails).\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes premières cinquante lignes de la linelist :",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#grouper-des-données",
    "href": "new_pages/grouping.fr.html#grouper-des-données",
    "title": "13  Travailler sur des données groupées",
    "section": "13.2 Grouper des données",
    "text": "13.2 Grouper des données\nLa fonction group_by() de dplyr permet de définir des groupes de lignes à partir des valeurs d’une ou de plusieurs colonnes. Chaque valeur unique (ou combinaison de valeurs unique, dans le cas où plusieurs colonnes sont spécifiées) constitue un groupe. Une fois les données groupées, de nombreuses fonctions utilisées pour le nettoyage ou des analyses descriptives seront appliquées à chaque groupe.\nPar exemple, le code ci-dessous groupe la linelist en fonction des valeurs uniques de la colonne outcome. La ou les colonnes selon lesquelles grouper les données sont placées entre parenthèses dans la fonction group_by(). La fonction génère un nouveau tableau de données, que nous nommons ll_by_outcome.\n\nll_by_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\nNotez que les données elles mêmes n’ont pas été modifiées après avoir exécuté group_by(). Le fait que le dataframe soit “groupé” se verra lorsqu’une autre fonction du paquet dplyr tel que mutate(), summarise(), ou arrange() sera appliquée sur le dataframe “groupé”.\nVous pouvez cependant savoir qu’un dataframe est groupé en l’imprimant dans la console. Vous verrez alors qu’il a été transformé en un objet de classe tibble qui, lorsqu’il est affiché, indique les groupements présents et le nombre de groupes qu’il y a juste au-dessus de la ligne d’en-tête.\n\n# Faire afficher pour voir le schéma de groupement\nll_by_outcome\n\n# A tibble: 5,888 × 30\n# Groups:   outcome [3]\n   case_id generation date_infection date_onset date_hospitalisation\n   &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;              \n 1 5fe599           4 2014-05-08     2014-05-13 2014-05-15          \n 2 8689b7           4 NA             2014-05-13 2014-05-14          \n 3 11f8ea           2 NA             2014-05-16 2014-05-18          \n 4 b8812a           3 2014-05-04     2014-05-18 2014-05-20          \n 5 893f25           3 2014-05-18     2014-05-21 2014-05-22          \n 6 be99c8           3 2014-05-03     2014-05-22 2014-05-23          \n 7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29          \n 8 369449           4 2014-05-28     2014-06-02 2014-06-03          \n 9 f393b4           4 NA             2014-06-05 2014-06-06          \n10 1389ca           4 NA             2014-06-05 2014-06-07          \n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_outcome &lt;date&gt;, outcome &lt;chr&gt;, gender &lt;chr&gt;,\n#   age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;,\n#   hospital &lt;chr&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;,\n#   wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;,\n#   cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;,\n#   bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\nGroupes distincts\nLes groupes sont basés sur les combinaisons uniques de valeurs dans les colonnes de groupement.\nPour afficher les groupes et le nombre de lignes de chaque groupe, passez les données groupées à la fonction tally(). Pour afficher les groupes présents mais pas le nombre de lignes, passez les données à la fonction group_keys().\nDans l’exemple ci-dessous, il y a trois valeurs uniques dans la colonne de groupement outcome : “Death”, “Recover”, et “NA”. Vous voyez qu’il y avait nrow(linelist %&gt;% filter(outcome == \"Death\")) morts, nrow(linelist %&gt;% filter(outcome == \"Recover\")) guéris, et nrow(linelist %&gt;% filter(is.na(outcome))) individus sans information renseignée.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally()\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\nVous pouvez regrouper par plus d’une colonne. Ci-dessous, nous groupons le dataframe par outcome et gender, puis comptons le nombre de lignes dans chaque groupe. Chaque combinaison unique de outcome et gender crée un groupe différent, y compris les valeurs manquantes pour chaque colonne.\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally()\n\n# A tibble: 9 × 3\n# Groups:   outcome [3]\n  outcome gender     n\n  &lt;chr&gt;   &lt;chr&gt;  &lt;int&gt;\n1 Death   f       1227\n2 Death   m       1228\n3 Death   &lt;NA&gt;     127\n4 Recover f        953\n5 Recover m        950\n6 Recover &lt;NA&gt;      80\n7 &lt;NA&gt;    f        627\n8 &lt;NA&gt;    m        625\n9 &lt;NA&gt;    &lt;NA&gt;      71\n\n\n\n\nNouvelle colonne\nVous pouvez également grouper selon une colonne crée directement dans la fonction group_by(). Cela revient à appeler mutate() avant le group_by(). Cela peut être intéressant pour créer de petites tables descriptives rapidement, mais dans d’autres cas, il sera plus lisible de créer la nouvelle colonne avec la fonction mutate() avant de passer le tableau à group_by().\n\n# grouper les données sur la base d'une colonne crée dans la commande group_by()\nlinelist %&gt;% \n  group_by(\n    age_class = ifelse(age &gt;= 18, \"adult\", \"child\")) %&gt;% \n  tally(sort = TRUE)\n\n# A tibble: 3 × 2\n  age_class     n\n  &lt;chr&gt;     &lt;int&gt;\n1 child      3618\n2 adult      2184\n3 &lt;NA&gt;         86\n\n\n\n\nGrouper selon plus ou moins de colonnes\nPar défaut, si vous exécutez group_by() sur des données déjà groupées, les anciens groupes seront supprimés et le ou les nouveaux groupes s’appliqueront. Si vous voulez ajouter de nouveaux groupes à ceux qui existent déjà, incluez l’argument .add = TRUE.\n\n# Grouper par  outcome\nby_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\n# Ajouter gender aux définition de groupe (grouper par une combinaison\n# de gender et outcome)\nby_outcome_gender &lt;- by_outcome %&gt;% \n  group_by(gender, .add = TRUE)\n\n\n\nConserver tous les groupes\nSi vous groupez les données sur la base d’une colonne de type “facteur”, il se peut que certains niveaux du facteur ne soient pas présents dans le jeu de données dans son état actuel. Dans ce cas, ces niveaux non représentés seront abandonnés par défaut et n’apparaîtront pas dans les groupes. Pour éviter ce comportement et prendre en compte tous les niveaux du facteur, y compris lorsqu’ils ne contiennent pas de données, utilisez l’argument .drop = FALSE dans votre commande group_by().",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#dégrouper-les-données",
    "href": "new_pages/grouping.fr.html#dégrouper-les-données",
    "title": "13  Travailler sur des données groupées",
    "section": "13.3 Dégrouper les données",
    "text": "13.3 Dégrouper les données\nLes dataframes qui ont été groupés le resteront jusqu’à ce qu’ils soient spécifiquement dégroupés grâce à la fonction ungroup().\nAttention à ne pas oublier de dégrouper les données avant de passer aux étapes qui nécessitent le jeu de données complet et non groupé.\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nOn peut également dégrouper seulement certaines colonnes, en passant le nom de la colonne à ungroup().\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup(gender) # dégroupe gender, mais garde le groupement par outcome\n\nNOTE: Le verbe count() dégroupe automatiquement les données après avoir compté les lignes.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#group_summarise",
    "href": "new_pages/grouping.fr.html#group_summarise",
    "title": "13  Travailler sur des données groupées",
    "section": "13.4 Résumer les données par groupe",
    "text": "13.4 Résumer les données par groupe\nVoir la section dplyr du chapitre sur les Tableaux descriptifs pour une explication détaillée sur comment produire des tableaux récapitulatifs à l’aide de la fonction summarise(). Ici, nous décrivons le comportement de summarise() lorsque la fonction est appliquée à des données groupées.\nLa fonction de dplyr summarise() (ou summarize()) prend un dataframe en entrée et le convertit en un nouveau dataframe contenant des statistiques de synthèse définies par l’utilisateur. Sur un tableau non groupé, le calcul de synthèse est effectuée sur toutes les lignes. Sur un tableau groupé, le calcul est effectué pour chaque groupe.\nPlus précisement, la syntaxe de la fonction summarise() est du type : “NOM_NOUVELLE_COLONNE = fonction résumé d’une ou plusieurs colonnes des données source”. Dans la fonction statistique, indiquez la colonne à traiter et tout argument pertinent (par exemple, na.rm = TRUE). Les fonctions régulièrement utilisées incluent par exemple mean(), min(), max(), median(), ou sd(), mais on peut également utiliser sum() pour compter le nombre de lignes qui répondent à un critère logique (avec l’opérateur ==).\nVous trouverez ci-dessous un premier où summarise() est appliquée sur des données non groupées : les statistiques retournées sont produites à partir de l’ensemble des données.\n\n# statistiques résumées appliquées sur le jeu de données complet\nlinelist %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm = T),\n    max_age  = max(age_years,  na.rm = T),\n    min_age  = min(age_years,  na.rm = T),\n    n_males  = sum(gender == \"m\", na.rm = T))\n\n  n_cases mean_age max_age min_age n_males\n1    5888 16.01831      84       0    2803\n\n\nMaintenant, la même commande est appliquée sur la linelist groupée, ce qui génère les résumés statistique pour chaque groupe. Notez que les colonnes utilisées pour définir les groupes sont gardées dans le tableau agrégé généré par summarise().\n\n# statistiques résumées appliquées sur le jeu de données complet \n# mais groupé par outcome\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm = T),\n    max_age  = max(age_years,  na.rm = T),\n    min_age  = min(age_years,  na.rm = T),\n    n_males  = sum(gender == \"m\", na.rm = T))\n\n# A tibble: 3 × 6\n  outcome n_cases mean_age max_age min_age n_males\n  &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;\n1 Death      2582     15.9      76       0    1228\n2 Recover    1983     16.1      84       0     950\n3 &lt;NA&gt;       1323     16.2      69       0     625\n\n\nNote: il est possible d’appeler la fonction en utilisant l’orthographe britannique et américaine : summarise() et summarize() sont équivalentes.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#comptes-et-additions",
    "href": "new_pages/grouping.fr.html#comptes-et-additions",
    "title": "13  Travailler sur des données groupées",
    "section": "13.5 Comptes et additions",
    "text": "13.5 Comptes et additions\nLes fonctions count() et tally() fournissent des fonctionnalités similaires mais légèrement différentes. Pour plus de détails sur la distinction entre les deux, voir ici.\n\ntally()\ntally() est un raccourci pour summarise(n = n()), et ne groupe pas les données d’elle même. Ainsi, pour obtenir des totaux groupés, il faut d’abord exécuter la commande group_by() avant la commande tally(). On peut ajouter sort = TRUE pour voir les plus grands groupes en premier.\nExemple sans grouper les données :\n\nlinelist %&gt;% \n  tally()\n\n     n\n1 5888\n\n\nEn groupant les données avant d’applique la fonction tally() :\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally(sort = TRUE)\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\n\n\ncount()\nEn revanche, la fonction count() effectue les actions suivantes :\n\napplique group_by() sur la ou les colonnes spécifiées\n\napplique summarise() et retourne la colonne n avec le nombre de lignes par groupe\n\npuis applique la fonction ungroup().\n\n\nlinelist %&gt;% \n  count(outcome)\n\n  outcome    n\n1   Death 2582\n2 Recover 1983\n3    &lt;NA&gt; 1323\n\n\nTout comme avec group_by() il est possible de créer une nouvelle colonne directement dans la commande count() :\n\nlinelist %&gt;% \n  count(age_class = ifelse(age &gt;= 18, \"adult\", \"child\"), \n        sort = T)\n\n  age_class    n\n1     child 3618\n2     adult 2184\n3      &lt;NA&gt;   86\n\n\ncount() peut être utilisée plusieurs fois à la suite pour résumer des données de manière plus en plus compacte. Par exemple, pour résumer le nombre d’hôpitaux présents pour chaque sexe, exécutez ce qui suit. Notez que le nom de la dernière colonne est changé de la valeur par défaut “n” pour plus de clarté (avec name =).\n\nlinelist %&gt;% \n  # compte le nombre de lignes pour chaque combinaison gender x hospital\n  count(gender, hospital) %&gt;% \n  # en utilisant le jeu de données agrégées, compte le nombre d’hôpitaux pour chaque genre.\n  count(gender, name = \"hospitals per gender\" ) \n\n  gender hospitals per gender\n1      f                    6\n2      m                    6\n3   &lt;NA&gt;                    6\n\n\n\n\nAjouter des colonnes contenant les décomptes\nConstruites sur des principes similaires à count() et tally(), vous pouvez utiliser les fonctions add_count() et add_tally() pour ajouter une nouvelle colonne n avec le nombre de lignes par groupe tout en conservant toutes les autres colonnes du dataframe. Cela signifie que le nombre de lignes total d’un groupe est ajouté pour chaque ligne du groupe dans une nouvelle colonne n.\nDans l’exemple suivant, nous ajoutons cette colonne et ré-arrangeons ensuite les colonnes pour une lecture plus aisée du tableau. Pour un autre exemple, voir la section plus bas sur comment filtrer sur la taille du groupe.\n\nlinelist %&gt;% \n  as_tibble() %&gt;%  # conversion en tibble pour un meilleur affichage\n  add_count(hospital) %&gt;%  # ajoute la colonne n avec les totaux par hôpitaux\n  select(hospital, n, everything()) # trie les colonnes\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\nAjouter les totaux\nPour facilement ajouter les totaux par lignes ou colonnes d’un tableau après avoir utilisé tally() ou count(), consultez la section janitor de la page sur les tables descriptives. Ce paquet offre des fonctions telles que adorn_totals() et adorn_percentages() pour ajouter des totaux et pourcentages. Par exemple :\n\nlinelist %&gt;%                                  \n  tabyl(age_cat, gender) %&gt;%                  # décomptes croisés de deux colonnes\n  adorn_totals(where = \"row\") %&gt;%             # ajoute ligne de totaux\n  adorn_percentages(denominator = \"col\") %&gt;%  # ajoute proportions (dénominateur colonne)\n  adorn_pct_formatting() %&gt;%                  # formate en %\n  adorn_ns(position = \"front\") %&gt;%            # formate en : \"N (%)\"\n  adorn_title(                                # ajuste les titres\n    row_name = \"Catégorie d'âge\",\n    col_name = \"Sexe\")\n\n                           Sexe                            \n Catégorie d'âge              f              m          NA_\n             0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n             5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n           10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n           15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n           20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n           30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n           50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n             70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n            &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n           Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\nPour ajouter des lignes de totaux plus complexes qui impliquent des statistiques récapitulatives autres que des sommes, voir cette section de la page Tables descriptives.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#grouper-par-date",
    "href": "new_pages/grouping.fr.html#grouper-par-date",
    "title": "13  Travailler sur des données groupées",
    "section": "13.6 Grouper par date",
    "text": "13.6 Grouper par date\nPour grouper des données par date, il faut avoir, ou créer une colonne contenant l’unité de temps qui vous intéresse (par exemple : “jour”, “semaine épidémiologique”, “mois”, etc). Vous pouvez créer cette colonne en utilisant floor_date() du paquet lubridate, tel qu’expliqué dans la section sur les Semaines épidémiologiques du chapitre sur les dates. Cette colonne peut être simplement passée à group_by() ou count() de dplyr pour grouper les lignes par les valeurs uniques de date ou obtenir le nombre de lignes par date.\nUn besoin spécifique à la gestion et l’analyse de données par date consiste à compléter les dates de la séquence qui ne sont pas présentes dans les données. Pour cela, on peut utiliser complete() du paquet tidyr pour que la série de dates agrégées comprenne toutes les unités de dates possibles dans la plage. Sans cette étape, une semaine où aucun cas n’a été signalé n’apparaîtrait pas dans les données…\nLa fonction complete(), redéfinit la colonne contenant les dates comme une séquence de dates (en passant seq.Date() du minimum au maximum comme argument). Par défaut, les valeurs du nombre de cas (et autres colonnes) dans les nouvelles lignes “développées” contient des “NA”, mais l’on peut modifier ce comportement. Par exemple, on peut mettre le nombre de cas à 0 en utilisant l’argument fill = de complete(), qui prend en entrée une liste nommée (si votre colonne de nombre de cas est nommée n, fournissez fill = list(n = 0). Voir ?complete pour plus de détails et la page Manipuler les dates pour un exemple.\n\nGrouper par jours (linelist)\nVoici un exemple où l’on va grouper le nombre de cas de la linelist par jour, sans utiliser la fonction complete(). Note : la première ligne permet d’ignorer les cas où il n’y a pas eu de date de rentrée.\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%        # Exclut les cas où date_onset est vide\n  count(date_onset)              # Compte le nombre de lignes par date\n\n\n\n\n\n\n\nMaintenant, le même exemple en utilisant la commande complete() pour s’assurer que tous les jours dans la fourchette temporelle seront représentés dans les données.\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%     # Exclut les cas où date_onset est vide\n  count(date_onset) %&gt;%       # Compte le nombre de lignes par jour\n  complete(                   # Ajoute les jours manquants (sans cas)\n    date_onset = seq.Date(    # redéfinit la colonne comme une séquence de dates\n      from = min(date_onset, na.rm=T), \n      to   = max(date_onset, na.rm=T),\n      by   = \"day\"),\n    fill   = list(n = 0))     # remplit les nouvelles dates ajoutées de 0 (aurait été des NA par défaut) \n\n\n\n\n\n\n\n\n\nGrouper par semaines (linelist)\nLe même principe peut être appliqué au groupement par semaine. Dans cet exemple, on va d’abord créer une nouvelle colonne contenant la semaine à l’aide de la fonction floor_date() du package lubridate (avec unit = \"week\"). Cela arrondit chaque date au premier jour de la semaine correspondante. Ensuite, on utilise la fonction count() pour obtenir le nombre de cas hebdomadaires. On termine enfin avec un complete() pour compléter toutes les semaines dans le jeu de données agrégées, même il n’y a pas eu de cas cette semaine là.\n\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%        # Exclut les cas où date_onset est vide\n  mutate(week = lubridate::floor_date(date_onset, \n                                      unit = \"week\")) %&gt;%  # Crée colonne avec la date de début des symptomes\n  count(week) %&gt;%                # Compte le nombre de lignes par semaine\n  complete(                      # Ajoute les semaines non représentées (sans cas)\n    week = seq.Date(             # redéfinit la colonne comme une séquence de dates\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))          # remplit les nouvelles dates ajoutées de 0 (aurait été des NA par \n\nVoici les 50 premières lignes du jeu de données créé :\n\n\n\n\n\n\n\n\nGrouper par mois (linelist)\nPour agréger les cas par mois, nous utiliserons à nouveau floor_date(), avec l’argument unit = \"months\". Cette commande arrondit chaque date au 1er de son mois. La sortie sera donc de la classe Date. Notez que dans l’étape complete(), nous utilisons également by = \"months\".\n\nmonthly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;% \n  mutate(month = lubridate::floor_date(date_onset, \n                                       unit = \"months\")) %&gt;%  # nouvelle colonne, 1st du mois de début des symptomes\n  count(month) %&gt;%             # Compte le nombre de cas par mois\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # Ajoute les mois non représentées (sans cas)\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))\n\n\n\n\n\n\n\n\n\nComptes journaliers en semaines (données agrégées)\nPour agréger les nombres de cas quotidiens (données déjà agrégées par jour, donc) en nombre de cas hebdomadaires, utilisez floor_date() de la même manière que dans les exemples précédents. Cependant, il faut ensuite utiliser les fonctions group_by() et summarize() au lieu de count() car il faut faire la somme des nombres de cas quotidiens au lieu de simplement compter le nombre de lignes par semaine.\n\nComptes journaliers en mois (données agrégées)\nPour agréger les nombres de cas journaliers par mois, utilisez floor_date() de la même manière que dans les exemples précédents (avec unit = \"month\"). Cependant, il faut ensuite utiliser les fonctions group_by() et summarize() au lieu de count() car il faut additionner le nombre de cas quotidiens au lieu de simplement compter le nombre de lignes par mois.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#trier-les-données-groupées",
    "href": "new_pages/grouping.fr.html#trier-les-données-groupées",
    "title": "13  Travailler sur des données groupées",
    "section": "13.7 Trier les données groupées",
    "text": "13.7 Trier les données groupées\nLa fonction arrange() de dplyr qui permet d’ordonner les lignes d’un dataframe se comporte de la même manière lorsque les données sont groupées, sauf si vous définissez l’argument .by_group = TRUE. Dans ce cas, les lignes sont d’abord ordonnées par les colonnes de regroupement, puis par toutes les autres colonnes que vous spécifiez à arrange().",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#filtrer-les-données-groupées",
    "href": "new_pages/grouping.fr.html#filtrer-les-données-groupées",
    "title": "13  Travailler sur des données groupées",
    "section": "13.8 Filtrer les données groupées",
    "text": "13.8 Filtrer les données groupées\n\nfilter()\nLorsque l’on utilise la fonction filter en conjonction avec des fonctions qui évaluent le dataframe (max(), min() ou mean() par exemple), la commande est désormais appliquée à chaque groupe indépendamment. Par exemple, pour filtrer et conserver les lignes où les patients ont un âge supérieur à l’âge médian, le filtre s’appliquera désormais à l’intérieur de chaque groupe, pour pour conserver les lignes où l’age des patients est supérieur à l’âge médian du groupe.\n\n\nslice()\nLa fonction dplyr slice(), qui filtre les lignes en fonction de leur position dans les données, peut également être appliquée par groupe. N’oubliez pas de trier les données au sein de chaque groupe pour obtenir la “tranche” souhaitée.\nPar exemple, pour extraire uniquement les 5 dernières admissions de chaque hôpital :\n\nGroupez les données de la linelist par la colonne hospital.\n\nTriez les enregistrements du plus récent au plus ancien grâce à la colonne date_hospitalisation dans chaque groupe d’hôpitaux.\n\nTranchez pour récupérer les 5 premières lignes de chaque hôpital\n\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  arrange(hospital, date_hospitalisation) %&gt;%\n  slice_head(n = 5) %&gt;% \n  arrange(hospital) %&gt;%                            # (pour l'affichage)\n  select(case_id, hospital, date_hospitalisation)  # (pour l'affichage)\n\n# A tibble: 30 × 3\n# Groups:   hospital [6]\n   case_id hospital          date_hospitalisation\n   &lt;chr&gt;   &lt;chr&gt;             &lt;date&gt;              \n 1 20b688  Central Hospital  2014-05-06          \n 2 d58402  Central Hospital  2014-05-10          \n 3 b8f2fd  Central Hospital  2014-05-13          \n 4 acf422  Central Hospital  2014-05-28          \n 5 275cc7  Central Hospital  2014-05-28          \n 6 d1fafd  Military Hospital 2014-04-17          \n 7 974bc1  Military Hospital 2014-05-13          \n 8 6a9004  Military Hospital 2014-05-13          \n 9 09e386  Military Hospital 2014-05-14          \n10 865581  Military Hospital 2014-05-15          \n# ℹ 20 more rows\n\n\nslice_head() : sélectionne les n premières lignes (“par le haut”)\nslice_tail() : sélectionne les n dernières lignes (“par le bas”)\nslice_sample() : sélectionne n lignes aléatoirement. Utiliser replace = TRUE pour un échantillonnage avec remplacement\nslice_min() : sélectionne les n lignes avec les plus petites valeurs dans une colonne donnée (argument order_by =). Utiliser with_ties = TRUE pour garder les ex-æquo\nslice_max() : sélectionne les n lignes avec les plus grandes valeurs dans une colonne donnée (argument order_by =)\nVoir le chapitre sur la dé-duplication pour plus d’exemples et de détails sur la fonction slice().\n\n\nFiltrer sur la taille des groupes\nLa fonction add_count() ajoute une colonne n aux données originales, ajoutant ainsi, pour chaque ligne, le nombre de lignes du groupe auquel cette ligne appartient.\nDans l’exemple ci-dessous, add_count() est appliqué à la colonne hospital, de sorte que les valeurs de la nouvelle colonne n reflètent le nombre de lignes dans le groupe hospitalier de cette ligne. Bien sûr, cela veut dire que la valeur de la colonne “n” est répétée pour chaque ligne du groupe.\nDans l’exemple ci-dessous, le nom de la colonne n pourrait être modifié en utilisant name = dans add_count().\n\nlinelist %&gt;% \n  as_tibble() %&gt;% \n  add_count(hospital) %&gt;%          # ajoute le nombre de patients admis dans cette hôpital, pour chaque groupe\n  select(hospital, n, everything()) # Pour un meilleur affichage\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\nIl est alors facile de filtrer les lignes de cas qui ont été hospitalisés dans un “petit” hôpital. Par exemple un hôpital qui a admis moins de 500 patients :\n\nlinelist %&gt;% \n  add_count(hospital) %&gt;% \n  filter(n &lt; 500)",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#mutate",
    "href": "new_pages/grouping.fr.html#mutate",
    "title": "13  Travailler sur des données groupées",
    "section": "13.9 mutate()",
    "text": "13.9 mutate()\nPour conserver toutes les colonnes et lignes (sans les résumer) et ajouter une nouvelle colonne contenant des statistiques de groupe, utilisez mutate() après group_by() au lieu de summarise().\nCeci est utile si vous voulez les statistiques de groupe dans le jeu de données original avec toutes les autres colonnes présentes - par exemple pour les calculs qui comparent une ligne à son groupe.\nPar exemple, le code ci-dessous calcule la différence entre le délai d’admission d’une ligne et le délai d’admission médian pour son hôpital. Les étapes sont les suivantes :\n\nGroupez les données par hôpital\n\nUtilisez la colonne days_onset_hosp (délai à l’hospitalisation) pour créer une nouvelle colonne contenant le délai moyen de l’hôpital pour chaque patient de cet hôpital\n\nCalculez la différence entre les deux colonnes\n\n\nlinelist %&gt;% \n  # grouper les données par hôpital\n  group_by(hospital) %&gt;% \n  \n  # Ajoute de nouvelles colonnes (conserve toutes lies lignes)\n  mutate(\n    # Délai moyen d'admission pour chaque hôpital (arrondi à la 1re décimale)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm = T), 1),\n    \n    # Différence entre le délai de chaque patient et le délai moyen de son hôpital\n    diff_to_group = round(days_onset_hosp - group_delay_admit, 1)) %&gt;%\n  \n  # Sélectionne colonnes (pour l'affichage)\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)\n\n# A tibble: 5,888 × 5\n# Groups:   hospital [6]\n   case_id hospital              days_onset_hosp group_delay_admit diff_to_group\n   &lt;chr&gt;   &lt;chr&gt;                           &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 5fe599  Other                               2               2             0  \n 2 8689b7  Missing                             1               2.1          -1.1\n 3 11f8ea  St. Mark's Maternity…               2               2.1          -0.1\n 4 b8812a  Port Hospital                       2               2.1          -0.1\n 5 893f25  Military Hospital                   1               2.1          -1.1\n 6 be99c8  Port Hospital                       1               2.1          -1.1\n 7 07e3e8  Missing                             2               2.1          -0.1\n 8 369449  Missing                             1               2.1          -1.1\n 9 f393b4  Missing                             1               2.1          -1.1\n10 1389ca  Missing                             2               2.1          -0.1\n# ℹ 5,878 more rows",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#select-sur-les-données-groupées",
    "href": "new_pages/grouping.fr.html#select-sur-les-données-groupées",
    "title": "13  Travailler sur des données groupées",
    "section": "13.10 select() sur les données groupées",
    "text": "13.10 select() sur les données groupées\nLa fonction select() fonctionne sur les données groupées, à ce détail près que les colonnes utilisées pour les groupes sont toujours inclues, même si elles n’ont pas été mentionnées dans les colonnes à conserver. Pour se débarrasser de ces colonnes, il faut utiliser ungroup() avant de dégrouper.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.fr.html#resources",
    "href": "new_pages/grouping.fr.html#resources",
    "title": "13  Travailler sur des données groupées",
    "section": "13.11 Resources",
    "text": "13.11 Resources\nPour plus d’information, voici quelques ressources utiles :\nVous pouvez utiliser n’importe quelle fonction agrégeant sur des données groupées ; Voir l’antisèche sur la transformation des données avec Rstudio\nLa page de The Data Carpentry sur dplyr\nLa page de référence de l’aide du tidyverse sur group_by() et grouping\nCette page sur la manipulation des données\nRésummer les données avec des conditions avec dplyr",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Travailler sur des données groupées</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.fr.html",
    "href": "new_pages/joining_matching.fr.html",
    "title": "14  Joindre des données",
    "section": "",
    "text": "14.1 Étapes préliminaires",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joindre des données</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.fr.html#étapes-préliminaires",
    "href": "new_pages/joining_matching.fr.html#étapes-préliminaires",
    "title": "14  Joindre des données",
    "section": "",
    "text": "Importation des paquets\nCes lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,            # import des fichiers\n  here,           # chemins d'accès\n  tidyverse,      # gestion des données + graphiques (ggplot2)\n  RecordLinkage,  # correspondances probabilistes\n  fastLink        # correspondances probabilistes\n)\n\n\n\nImportation des données\nNous importons un jeu de données de cas d’une épidémie d’ébola fictive. Pour reproduire les étapes, cliquez pour télécharger la linelist “propre” (as .rds file). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation des données pour plus de détails).\n\n# importer la linelist dans R\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes cinquantes premières lignes sont affichées ci-dessous :\n\n\n\n\n\n\n\n\n\nJeux de données simplifiés\nDans les exemples ci-dessous, nous utiliserons des jeux de données simplifiés pour mieux voir ce qui se passe :\n\nUne version “miniature” de la linelist (liste des cas), contenant seulement les colonnes case_id, date_onset, et hospital, et seulement les 10 premières lignes.\n\nUne table nommée hosp_info, qui contient des détails sur chaque hôpital.\n\nDans la section sur l’appariement probabiliste, nous utiliserons deux petits ensembles de données différents. Le code pour créer ces jeux de données sera donné dans cette section.\n\nLinelist miniature\nNous générons ici la linelist miniature des cas, qui contient seulement 10 lignes et seulement les colonnes case_id, date_onset, et hospital.\n\nlinelist_mini &lt;- linelist %&gt;%                 \n  select(case_id, date_onset, hospital) %&gt;%   # sélectionne les colonnes\n  head(10)                                    # garde les 10 premières lignes\n\n\n\n\n\n\n\n\n\nJeu de données des hôpitaux\nLe code ci-dessous permet de créer un jeu de données contenant des informations supplémentaires sur sept hôpitaux (la population desservie et le niveau de soins disponible). Notez que le nom “Hôpital militaire” appartient à deux hôpitaux différents, l’un de niveau primaire desservant 10000 résidents et l’autre de niveau secondaire desservant 50280 résidents.\n\n# Crée des informations sur les hôpitaux : \nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \n                    \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, \n                    12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\",\n                    \"Secondary\", \"Primary\", \"Primary\")\n)\n\nVoici le tableau ainsi produit :\n\n\n\n\n\n\n\n\n\n\nNettoyage préliminaire\nLes jointures “traditionnelles” (i.e. non-probabilistes) sont sensibles à la casse et nécessitent des correspondances exactes entre les valeurs des colonnes utilisées comme clef/identifiant. Pour démontrer certaines des étapes de nettoyage que vous pourriez avoir besoin de faire avant de joindre vos données, nous allons commencer par nettoyer et aligner les dataframe linelist_mini et hosp_info.\nIdentifier les différences\nLe nom de l’hôpital étant notre identifiant/clef commun aux deux jeux de données, nous avons besoin que les valeurs de la colonne hosp_name dans le tableau hosp_info correspondent aux valeurs de la colonne hospital dans le tableau linelist_mini.\nVoici le dataframe linelist_mini, affiché avec la fonction base R unique() :\n\nunique(linelist_mini$hospital)\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n\n\n… et voici les valeurs dans le dataframe hosp_info :\n\nunique(hosp_info$hosp_name)\n\n[1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"      \n[5] \"ignace\"           \"sisters\"         \n\n\nIl est clair que si certains hôpitaux sont présents dans les deux dataframes, leurs noms ne sont pas toujours orthographiés de la même manière.\nAligner les valeurs\nNettoyons les valeurs du jeu de données hosp_info. Comme expliqué dans le chapitre sur le Nettoyage de données et fonctions essentielles, il est possible de recoder les valeurs à partir de critères logiques en utilisant la fonction case_when() de dplyr. Pour les quatre hôpitaux communs dans les deux dataframes, nous modifions les noms pour les aligner avec les noms dans le tableau linelist_mini (en ne touchant pas aux noms des autres hôpitaux grâce à l’argument TRUE ~ hosp_name).\nATTENTION: Normalement on devrait créer une nouvelle colonne pour ce type de nettoyage (hosp_name_clean par exemple), mais pour mieux comprendre ce qui se passe lors des étapes suivantes, nous modifions directement la colonne contenant les données “brutes”\n\nhosp_info &lt;- hosp_info %&gt;% \n  mutate(\n    hosp_name = case_when(\n      # critère                          # nouvelles valeur\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\n\nLes noms des hôpitaux qui apparaissent dans les deux bases de données sont désormais identiques. Il y a deux hôpitaux dans hosp_info qui ne sont pas présents dans linelist_mini, nous les traiterons plus tard, lors de la jointure.\n\nunique(hosp_info$hosp_name)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Port Hospital\"                       \n[4] \"St. Mark's Maternity Hospital (SMMH)\"\n[5] \"ignace\"                              \n[6] \"sisters\"                             \n\n\nAvant une jointure, il est souvent rassurant de convertir une colonne tout en minuscules ou majuscules. Pour cela, on peut utiliser mutate() et une des colonnes de stringr (voir le chapitre sur les chaînes de caractères):\nstr_to_upper()\nstr_to_lower()\nstr_to_title()",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joindre des données</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.fr.html#jointures-à-laide-de-dplyr",
    "href": "new_pages/joining_matching.fr.html#jointures-à-laide-de-dplyr",
    "title": "14  Joindre des données",
    "section": "14.2 Jointures à l’aide de dplyr",
    "text": "14.2 Jointures à l’aide de dplyr\nLe package dplyr offre plusieurs fonctions qui permettent d’effectuer des jointures différentes. dplyr est inclus dans le paquet tidyverse.\nUn grand merci à https://github.com/gadenbuie pour les gifs informatifs !\n\n\nSyntaxe générale\nLes fonctions de jointure peuvent s’utiliser seules pour unir deux dataframes et créer un nouveau dataframe, mais aussi au sein d’un enchaînement de commandes (pipe avec %&gt;%) pour fusionner un dataframe dans un autre à la volée.\nDans l’exemple ci-dessous, la fonction left_join() est utilisée de manière autonome pour créer un nouveau jeu de données (joined_data). Les arguments à l’entrée sont les dataframes à unir/fusionner/joindre (df1 et df2). Le premier dataframe listé est le dataframe de base, et le deuxième dataframe listé est joint à celui-ci.\nLe troisième argument by = précise quelle(s) colonne(s) sera utilisée pour faire la correspondance entre les lignes des deux dataframes (la clef). Si les noms de ces colonnes sont différents, fournissez-les dans un vecteur c() comme dans l’exemple ci-dessous, les identifiants communs sont dans la colonne ID dans df1 et dans la colonne identifier dans df2.\n\n# Jointure basée sur les valeurs communes dans la colonne ID (df1) et la colonne \"identifier\" (df2)\njoined_data &lt;- left_join(df1, df2, \n                         by = c(\"ID\" = \"identifier\"))\n\nSi la ou les colonnes “clef” à le même nom dans les deux tableaux, alors leur nom peut juste être fourni directement, avec des guillemets :\n\n# Jointure basée sur les valeurs communes dans la colonne ID présente dans df1 et df2\njoined_data &lt;- left_join(df1, df2, \n                         by = \"ID\")\n\nS’il y a besoin de plusieurs colonnes pour identifier de manière unique les observations (i.e. créer une clef primaire), on peut lister plusieurs colonnes dans un vecteur et le passer à by. Dans cet exemple, les lignes des deux dataframes sont unies si les valeurs sont identiques dans les trois colonnes.\n\n# Jointure basée sur le prénom, le nom de famille et l'age : les lignes sont fusionnées si les valeurs sont alignées exactement\njoined_data &lt;- left_join(df1, df2, \n                         by = c(\"name\"    = \"firstname\", \n                                \"surname\" = \"lastname\", \n                                \"Age\"     = \"age\"))\n\nLes fonctions de jointure peuvent également être exécutées dans un enchaînement d’instructions (ou pipe). Cela modifiera le jeu de données qui est passée dans le pipe.\nDans l’exemple ci-dessous, df1 est pipé, df2 lui est joint, et df1 est ainsi modifié et redéfini.\n\ndf1 &lt;- df1 %&gt;%\n  filter(date_onset &lt; as.Date(\"2020-03-05\")) %&gt;%  # nettoyage divers\n  left_join(df2, by = c(\"ID\" = \"identifier\"))     # jointure de df2 à df1\n\nATTENTION: Les jointures respectent les majuscules/minuscules ! Il peut donc être utile de convertir les colonnes utilisées comme clefs en minuscules ou majuscules. Voir le chapitre sur les chaînes de caractères\n\n\n\nJointures à gauche et droite\nUne jointure à gauche ou droite est une opération très couramment utilisée pour ajouter des informations à un dataframe, en particulier dans les analyses épidémiologiques. Les nouvelles informations sont ajoutées uniquement aux lignes qui existaient déjà dans le dataframe de “référence”.\nEn utilisant ces jointures, l’ordre d’écriture des dataframes dans la commande est important.\n\nDans une jointure à gauche, le premier dataframe écrit est utilisé comme “référence” à laquelle on adjoint les informations venant de l’autre table.\n\nDans une jointure à droite, le second dataframe est la référence à laquelle on rajoute les informations venant du premier dataframe.\n\nPlus précisement :\n* Toutes les lignes présentes dans le dataframe de référence sont conservées. Les informations contenues dans le dataframe secondaire sont adjointes au dataframe de référence uniquement s’il existe une correspondance via la ou les colonnes d’identification/clefs.\n\nLes lignes du dataframe secondaire qui ne correspondent pas sont abandonnées.\nSi plusieurs lignes du dataframe utilisé comme référence correspondent à une ligne dans le dataframe secondaire (many-to-one), les informations du dataframe secondaire sont ajoutées à chaque ligne du dataframe de référence correspondantes.\nSi une ligne du dataframe de référence correspond à plusieurs lignes dans le dataframe secondaire (one-to-many), toutes les combinaisons sont données, ce qui signifie que de nouvelles lignes sont ajoutées au dataframe de référence !.\n\nExemples animés de jointures gauche et droite (source de l’image)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemple\nVoici le résultat d’un left_join() de hosp_info (dataframe secondaire, voir ici) dans/vers linelist_mini (dataframe de référence, voir ici). La linelist_mini originale a nrow(linelist_mini) lignes. La linelist_mini modifiée est affichée. On constate que :\n\nDeux nouvelles colonnes, catchment_pop et level ont été ajoutées sur le côté gauche de linelist_mini.\nToutes les lignes originales du dataframe de référence linelist_mini ont été conservées.\nToutes les lignes originales de linelist_mini pour “Military Hospital” ont été dupliquées car elles correspondaient à deux lignes dans le dataframe secondaire, et donc les deux combinaisons ont été retournées.\nLa colonne d’identifiant/clef de jointure du dataframe secondaire (hosp_name) a disparu car elle est redondante avec la colonne d’identifiant du dataframe de référence (hospital)\nLorsqu’une ligne du dataframe de gauche ne correspond à aucune du dataframe de droite (par exemple, lorsque hospital est “Autre” ou “Manquant”), les observations renvoyées dans les colonnes venant du dataframe de droite sont NA.\nLes lignes du dataframe de droite qui ne correspondent pas au dataframe gauche (hôpitaux “sisters” et “ignace”) ont été abandonnées.\n\n\nlinelist_mini %&gt;% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in left_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\nJointure à gauche ou jointure à droite ?\nPour répondre à la question, il faut décider quel dataframe doit conserver toutes ses lignes, et l’utiliser comme dataframe de référence. Une jonction à gauche conserve toutes les lignes du premier dataframe écrit dans la commande, tandis qu’une jonction à droite conserve toutes les lignes du second dataframe.\nLes deux instructions ci-dessous retournent le même résultat : 10 lignes de hosp_info jointes dans un dataframe linelist_mini, mais elles utilisent des jointures différentes. Le résultat est que l’ordre des colonnes sera différent selon que hosp_info arrive “par la droite” (dans la jointure à gauche) ou arrive “par la gauche” (dans la jointure à droite). L’ordre des lignes peut également changer en conséquence. Néanmoins ces deux conséquences peuvent être traitées ultérieurement, en utilisant select() pour réordonner les colonnes ou arrange() pour trier les lignes.\n\n# On obtient le même jeu de données, mais avec l'ordre des colonnes et des lignes différent\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\nVoici le résultat d’une fusion de hosp_info dans linelist_mini par une jointure à gauche (nouvelles colonnes ajoutées par la droite) :\n\n\nWarning in left_join(linelist_mini, hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nVoici le résultat de la fusion de hosp_info dans linelist_mini par une jointure à droite (nouvelles colonnes ajoutées par la gauche) :\n\n\nWarning in right_join(hosp_info, linelist_mini, by = c(hosp_name = \"hospital\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 4 of `x` matches multiple rows in `y`.\nℹ Row 5 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nUne autre chose à considérer est si la jointure est réalisée au sein d’une chaîne d’instructions pipées (%&gt;%). Si le dataframe transmis par le pipe doit être utilisé comme référence, utilisez une jointure à gauche pour lui adjoindre de nouvelles données.\n\n\n\n\nJointure complète\nLa jointure complète est la plus inclusive des jointures, elle renvoie toutes les lignes des deux dataframes fusionnés.\nSi des lignes ne sont présentes que dans l’un des dataframes fusionnés (i.e aucune correspondance n’est trouvée), elles seront inclues dans le dataframe final (qui s’allonge donc), avec des NA pour combler les vides.\nLorsque vous effectuez une jointure, surveillez attentivement le nombre de colonnes et de lignes pour vérifier le nombre de lignes des dataframes en entrée, et du dataframe fusionné. Cela vous permettra notamment de détecter des problèmes de correspondance dus à la sensibilité à la casse ou à des correspondances inexactes.\nLe dataframe de référence utilisé comme base est celui qui est écrit en premier dans la commande. Dans une jointure complète, Lequel des deux dataframes est écrit en premier n’affecte que l’ordre des lignes, l’ordre des colonnes et le nom des colonnes clef retenues.\n\n\n\n\n\n\n\n\n\nExemple animé d’une jointure complète (image source)\nExemple\nVoici la sortie d’une jointure complète du dataframe hosp_info (originellement nrow(hosp_info) lignes, voir ici) avec linelist_mini (originellement nrow(linelist_mini) lignes, voir ici). On constate que :\n\nToutes les lignes du dataframe de référence sont conservées (linelist_mini).\nLes lignes du second dataframe qui n’ont pas de correspondance avec le premier dataframe sont conservées (“ignace” et “sisters”), et les valeurs des colonnes apportées par le dataframe de référence, case_id et onset, sont complétées par des valeurs manquantes.\nDe même, les lignes du dataframe de référence qui ne correspondent pas à la ligne secondaire (“Autre” et “Manquant”) sont conservées, les colonnes secondaires catchment_pop et level étant remplies de valeurs manquantes.\nDans le cas d’une correspondance un-à-plusieurs ou plusieurs-à-un (par exemple, des lignes pour “Hôpital militaire”), toutes les combinaisons possibles sont retournées (ce qui allonge le dataframe final).\nSeule la colonne d’identification du dataframe de référence est conservée (hospital).\n\n\nlinelist_mini %&gt;% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in full_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nJointure interne\nLa jointure interne est la plus restrictive des jointures : elle renvoie uniquement les lignes avec des correspondances dans les deux dataframes.\nLe nombre de lignes dans le dataframe de référence peut ainsi diminuer. Le choix du dataframe à passer en premier à la fonction n’aura pas d’impact sur les lignes conservées, mais affectera l’ordre des colonnes, l’ordre des lignes et clefs d’identification retenues.\n\n\n\n\n\n\n\n\n\nExemple animé d’une jointure complète : (image source)\nExemple\nVoici la sortie d’un inner_join() de la linelist_mini (référence) avec hosp_info (secondaire). On constate que :\n\nLes lignes du dataframe de référence sans correspondance dans le second dataframe sont supprimées (lignes où hospital est “Missing” ou “Other”).\n\nDe même, les lignes du dataframe secondaires qui n’ont pas de correspondance dans le dataframe de référence (lignes où hosp_name est “sisters” ou “ignace”) sont supprimées.\n\nSeule la colonne clef du dataframe de référence est conservée (hospital).\n\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, \n             by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nSemi jointure\nLes semi jointures sont des jointures dites “filtrantes”, qui utilisent la correspondance avec un second dataframe pour filtrer le dataframe de référence.\nLa semi jointure garde toutes les observations du dataframe de référence qui ont une correspondance dans le dataframe secondaire. Mais les colonnes du dataframe secondaire ne sont pas ajoutées et les lignes du dataframe de référence ne sont pas dupliquées s’il y a des correspondances multiples.\nPlus d’explications sur les semi-jointures ici.\n\n\n\n\n\n\n\n\n\nExemple animé d’une semi jointure (image source)\nVoici un exemple qui retourne les lignes du dataframe hosp_info qui ont une correspondance dans le dataframe linelist_mini en utilisant le nom de l’hôpital comme clé de jointure/identifiant.\n\nhosp_info %&gt;% \n  semi_join(linelist_mini, \n            by = c(\"hosp_name\" = \"hospital\"))\n\n                             hosp_name catchment_pop     level\n1                    Military Hospital         40500 Secondary\n2                    Military Hospital         10000   Primary\n3                        Port Hospital         50280 Secondary\n4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary\n\n\n\n\n\nAnti-jointure anti_join()\nL’anti-jointure est une autre type de jointure filtrante, qui, à l’opposé du semi-join, ne renvoie que les lignes du dataframe de référence qui n’ont PAS de correspondance dans le dataframe secondaire.\nPlus de détails sur les jointures filtrantes ici.\nVoici quelques cas d’usage de l’anti-jointure : identifier les observations non présentes dans un autre dataframe, identifier les typos qui compliquent une jointure (se focaliser sur les observations qui auraient du correspondre), examiner les observations qui ont été exclues d’une jointure etc.\nComme pour les jointures à droite (right_join()) et à gauche (left_join()), l’ordre dans lequel sont passés les dataframe a de l’importance. Dans les joins filtrants, on ne renvoie que les lignes présentes dans le dataframe de référence (écrit en premier), comme on peut le voir dans l’animation ci-dessous (la ligne 4, violette, du dataframe secondaire n’est pas retournée, alors qu’elle ne matche avec aucune ligne du dataframe de référence).\n\n\n\n\n\n\n\n\n\nExemple animé d’une anti-jointure (image source)\n\nExemple simple d’anti-jointure\nUn cas d’utilisation simple est de rechercher les hôpitaux dans le tableau hosp_info qui n’ont pas de cas présents dans le tableau linelist_mini. Nous rentrons hosp_info en premier, comme dataframe de référence, puis linelist_mini, la seconde table à comparer pour trouver les hôpitaux qui n’y sont pas présents.\n\nhosp_info %&gt;% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n\n\n\n\n\n\n\n\nExemple d’anti-jointure plus complexe\nImaginons cette fois-ci que nous avons exécuté une jointure interne (inner_join()) entre les dataframes linelist_mini et hosp_info. Cette opération ne retourne qu’un sous-ensemble des lignes originales de linelist_mini, car certains hôpitaux ne sont pas présents dans hosp_info.\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nNous pouvons utiliser une anti jointure pour inspecter les éléments de linelist_mini qui ont été exclus lors de la jointure interne, avec les mêmes paramètres (linelist_mini comme dataframe de référence).\n\nlinelist_mini %&gt;% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\n\n\n\n\nPour voir les lignes d’hosp_info exclues lors de la jointure interne, nous pourrions aussi exécuter une anti-jointure en utilisant hosp_info comme table de référence.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joindre des données</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.fr.html#apparienement-probabiliste",
    "href": "new_pages/joining_matching.fr.html#apparienement-probabiliste",
    "title": "14  Joindre des données",
    "section": "14.3 Apparienement probabiliste",
    "text": "14.3 Apparienement probabiliste\nSi l’on ne dispose pas d’un identifiant unique commun à tous les dataframes sur lequel se baser, il est possible d’utiliser un algorithme de correspondance probabiliste. Cet algorithme cherche des correspondances entre les observations sur la base de la similarité (par exemple, la distance entre les chaînes de caractères Jaro-Winkler ou la distance numérique). Nous illustrons ce concept ci-dessous à l’aide du paquet fastLink.\nCharger les paquets\n\npacman::p_load(\n  tidyverse,      # manipulation de données et visualisation\n  fastLink        # appariement d'observations\n  )\n\nNous créons d’abord deux petits jeux de données d’exemple que nous utiliserons pour démontrer l’appariement/la correspondance probabiliste (cases et test_results) :\n\n# Création des jeux de données\n\ncases &lt;- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults &lt;- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )\n\nLe dataframe cases a 9 observations de patients attendant les résultats de leur test.\n\n\n\n\n\n\nLe dataframe test_results a 14 observations et contient la colonne result, qui contient des informations que nous voudrions rapatrier dans le jeu de données cases en utilisant un algorithme probabiliste pour faire correspondre les observations.\n\n\n\n\n\n\n\nAppariement probabiliste\nLa fonction fastLink() du paquet fastLink peut être utilisée pour appliquer un algorithme probabiliste de correspondance. Voici quelques informations basiques, mais vous pouvez en savoir plus en tapant ?fastLink dans la console.\n\nDéfinir les deux dataframes à comparer grâce aux arguments dfA = et dfB =.\n\nDans varnames =, indiquer les noms de toutes les colonnes à utiliser pour la comparaison. Ces colonnes doivent exister à la fois dans dfA et dfB.\n\nDans stringdist.match =, donner les colonnes sur lesquelles effectuer le calcul de la distance de similarité entre les chaînes de caractère (ce ou ces colonnes doivent être présentes dans varnames).\n\nDans numeric.match =, donner les colonnes sur lesquelles calculer une mesure de distance numérique (ce ou ces colonnes doivent être présentes dans varnames).\n\nLes valeurs manquantes sont ignorées.\n\nPar défaut, chaque ligne de l’un des deux dataframes est comparée à une ligne au maximum de l’autre dataframe. Si vous voulez voir toutes les correspondances évaluées, choisissez dedupe.matches = FALSE. La dé-duplication est faite en utilisant la technique de programmation linéaire de Winkler.\n\nAstuce : divisez une colonne de date en trois colonnes numériques distinctes en utilisant day(), month(), et year() du package lubridate.\nLe seuil par défaut pour les correspondances est de 0.94 (threshold.match =) mais il peut être ajusté. Un seuil plus élevé peut produire plus de faux négatifs (des lignes qui ne correspondent pas alors qu’elles devraient correspondre) et un seuil plus bas peut produire plus de faux positifs.\nCi-dessous, les données sont comparées sur la base de la distance de similarité entre les chaînes de caractères dans les colonnes du nom et du district, et sur la base de la distance numérique pour l’année, le mois et le jour de naissance. Un seuil de correspondance de 95% de probabilité est fixé.\n\nfl_output &lt;- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nDeduping the estimated matches.\nGetting the match patterns for each estimated match.\n\n\nVérification des correspondance\nL’objet fl_output contient la sortie de la fonction fastLink(). Cet objet est une liste (classe list) qui contient plusieurs dataframes détaillant les résultats de l’analyse des correspondances. Le dataframe matches contient les correspondances les plus probables entre cases et results. On peut y accéder avec la commande fl_output$matches. Ci-dessous, nous l’enregistrons sous le nom de my_matches pour faciliter son accès ultérieur.\nLe dataframe my_matches contient deux colonnes contenant les numéros de lignes/indices (aussi appelés “rownames”) de cases (“inds.a”) et de results (“inds.b”), représentant les meilleures correspondances. Si un numéro de ligne d’un dataframe est manquant, alors aucune correspondance n’a été trouvée dans l’autre dataframe au seuil de correspondance spécifié.\n\n# print matches\nmy_matches &lt;- fl_output$matches\nmy_matches\n\n  inds.a inds.b\n1      1      1\n2      2      2\n3      3      3\n4      4      4\n5      8      8\n6      7      9\n7      6     10\n8      5     12\n\n\nOn observe que :\n\nLes correspondances ont été trouvées malgré les légères différences dans l’orthographe des noms et les dates de naissance, c’est la beauté de ce type d’approche :\n\n“Tony B. Smith” correspond à “Anthony B. Smith”.\n\n“Maria Rodriguez” correspond à “Marialisa Rodrigues”.\n\n“Betty Chase” correspond à “Elizabeth Chase”.\n\n“Olivier Laurent De Bordeaux” correspond à “Oliver Laurent De Bordow” (date de naissance manquante ignorée).\n\n\nUne ligne de cases (pour “Blessing Adebayo”, ligne 9) n’avait pas de bonne correspondance dans results, elle n’est donc pas présente dans my_matches.\n\nJointure basée sur les correspondances probabilistes.\nPour utiliser ces correspondances afin de joindre les results aux cases, une stratégie consiste à :\n\nUtiliser left_join() pour joindre my_matches à cases (en faisant correspondre les rownames dans cases à “inds.a” dans my_matches)\n\nUtiliser ensuite un autre left_join() pour joindre results à cases (en faisant correspondre les “inds.b” nouvellement acquis dans cases aux noms de domaine dans results).\n\nAvant les jointures, nous devons nettoyer les trois dataframes :\n\nLes numéros de ligne (“rowname”) de dfA et dfB doivent être convertis en une colonne.\n\nLes deux colonnes de my_matches sont converties en chaînes de caractères, donc elles peuvent être jointes aux caractères rownames.\n\n\n# Préparation des dataframes avant la jointure\n#############################\n\n# Covertir les numéros de lignes en colonne\ncases_clean   &lt;- cases %&gt;% rownames_to_column()\nresults_clean &lt;- results %&gt;% rownames_to_column()  \n\n# Convertir toutes les colonnes du dataframe des correspondances en texte pour pouvoire les joindre aux numéros de ligne\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n\n\n# Joindre `clean_matches` à dfA, puis ajouer dfB\n###################################\n# la colonne \"inds.b\" est ajoutée à dfA\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# les colonnes de dfB sont rappatriées \ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\nLe dataframe complete ainsi crée contient toutes les colonnes de cases et de results. Beaucoup d’entre elles se retrouvent ajoutées avec les suffixes “.x” et “.y”, parce que les noms des colonnes seraient dupliqués sinon.\n\n\n\n\n\n\nPour obtenir seulement les 9 observations “originales” dans cases avec la ou les nouvelles colonnes de results, utiliser select() sur results avant les jointures, de sorte que e dataframe ne contienne que les rownames et les colonnes que vous voulez ajouter à cases (par exemple la colonne result).\n\ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\nresults_clean &lt;- results %&gt;%\n  rownames_to_column() %&gt;% \n  select(rowname, result)    # Sélectionner certaines colonnes\n\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n# jointure\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\n\n\n\n\n\n\nSi vous voulez ne garder que les lignes qui avec des correspondances dans l’un ou l’autre des des dataframe, vous pouvez utiliser les codes ci-dessous :\n\ncases_matched &lt;- cases[my_matches$inds.a,]  # Lignes de  `cases` qui matchent une ligne dans 'results'\nresults_matched &lt;- results[my_matches$inds.b,]  # Lignes de 'results qui matchent une ligne dans `cases`\n\nOu pour ne voir que les lignes sans correspondances :\n\ncases_not_matched &lt;- cases[!rownames(cases) %in% my_matches$inds.a,]  # Lignes dans `cases` sans matchs dans `results`\nresults_not_matched &lt;- results[!rownames(results) %in% my_matches$inds.b,]  # Lignes dans  `results` sans matchs dans `cases`\n\n\n\nDéduplication probabiliste\nLa correspondance probabiliste peut également être utilisée pour dé-dupliquer un jeu de données. Voir la page sur la dé-duplication pour d’autres méthodes de dé-duplication.\nIci, nous modifions le tableau cases, en ajoutant des lignes supplémentaires qui peuvent être des doublons de lignes existantes, et l’appelons cases_dup; voir “Tony” avec “Anthony”, et “Marialisa Rodrigues” avec “Maria Rodriguez”.\n\n\n\n\n\n\nOn peut désormais utiliser la fonction fastLink() comme précédemment, mais en comparant le jeu de données cases_dup à lui-même. Lorsque les dataframes fournis en argument sont identiques, la fonction suppose que vous voulez dé-dupliquer.\nNotez que nous ne spécifions pas stringdist.match = ou numeric.match = comme nous le faisions précédemment.\n\n## Utiliser fastLink sur le même jeu de données\ndedupe_output &lt;- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\ndfA and dfB are identical, assuming deduplication of a single data set.\nSetting return.all to FALSE.\n\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nCalculating the posterior for each pair of matched observations.\nGetting the match patterns for each estimated match.\n\n\nLa fonction getMatches() permet d’examiner la sortie de fastLink pour rechercher les doublons potentiels. Il faut fournir le dataframe d’origine à dfA = et dfB =, ainsi que la sortie de fastLink() à fl.out =.\nNote : fl.out doit nécessairement être de la classe fastLink.dedupe, ou en d’autres termes, le résultat de fastLink().\n\n## Executer getMatches()\ncases_dedupe &lt;- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\n\nLa colonne la plus à droite indique les identifiants des doublons. Ici les deux dernières lignes sont identifiées comme étant des doublons probables des lignes 2 et 3.\n\n\n\n\n\n\nPour obtenir les numéros de ligne des lignes qui sont potentiellement des doublons, il suffit de compter le nombre de lignes par valeur unique dans la colonne dedupe.ids, puis de filtrer pour ne garder que celles qui ont plus d’une ligne. Dans ce cas, nous obtenons laisse les lignes 2 et 3.\n\ncases_dedupe %&gt;% \n  count(dedupe.ids) %&gt;% \n  filter(n &gt; 1)\n\n  dedupe.ids n\n1          2 2\n2          3 2\n\n\nPour inspecter les doublons, on peut utiliser le numéro de ligne pour obtenir la ligne complète :\n\n# Afficher la ligne 2 et ses duplicats probables\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   \n\n   gender   first middle  last   yr mon day district dedupe.ids\n2       M Anthony     B. Smith 1970   9  19    River          2\n10      M    Tony     B. Smith 1970   9  19    River          2",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joindre des données</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.fr.html#assembler-et-aligner-des-dataframes",
    "href": "new_pages/joining_matching.fr.html#assembler-et-aligner-des-dataframes",
    "title": "14  Joindre des données",
    "section": "14.4 Assembler et aligner des dataframes",
    "text": "14.4 Assembler et aligner des dataframes\nUne autre manière de combiner deux dataframes consiste à les assembler/concaténer/coller/aligner. On peut également considérer cette méthode comme un ajout de lignes ou de colonnes.\nCette section explique également comment “aligner” l’ordre des lignes d’un dataframe sur celui d’un autre dataframe. Ce sujet est abordé ci-dessous dans la section consacrée à la liaison des colonnes.\n\nAssembler verticallement\nLa fonction bind_rows() de dplyr permet de coller les lignes d’un dataframe à la suite d’un autre dataframe (verticalement, donc). Elle est très inclusive : toute colonne présente dans l’un ou l’autre des dataframes sera incluse dans la sortie.\nQuelques notes :\n\nContrairement à la version base de R row.bind(), dplyr’s bind_rows() n’exige pas que l’ordre des colonnes soit le même dans les deux dataframes à assembler. Du moment que les noms des colonnes sont orthographiés de manière identique, la fonction les alignera correctement.\nIl est possible de fournir une chaîne de caractères à l’argument .id = pour produire une nouvelle colonne qui servira à identifier de quel dataframe chaque ligne provient à l’origine.\nIl est possible d’utiliser bind_rows() sur une liste de dataframes possédant la même structure pour les combiner en un seul. Vous trouverez un exemple de cette action dans la page Itération, boucles et listes qui importe plusieurs linelists avec le paquet purrr.\n\nUn exemple classique d’assemblage de dataframes est d’ajouter une ligne “total” à un tableau descriptif créé avec la fonction summarise() de dplyr. Ci-dessous, nous créons un tableau des nombres de cas et des valeurs médianes de CT par hôpital et y ajoutons une ligne de total.\nLa fonction summarise() est utilisée sur des données groupées par hôpital pour retourner un dataframe récapitulatif par hôpital. Malheureusement, elle ne produit pas automatiquement une ligne de “totaux”, donc nous devons la rajouter nous même. Nous l’obtenons en résumant à nouveau ces données, mais sans grouper par hôpital. Cela produit un deuxième dataframe d’une seule ligne, que nous concaténons ensuite au premier pour obtenir le tableau final.\nVous trouverez d’autres exemples de ce type dans les pages Tableaux descriptifs et Tableaux de présentation.\n\n# Créer la table de base\n###################\nhosp_summary &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;%      # grouper les données par hôpital\n  summarise(                  # Créer résumé :\n    cases = n(),               # NNombre de lignes par hôpital\n    ct_value_med = median(ct_blood, na.rm=T))     # Médiane du CT par hôpital\n\nVoici à quoi ressemble hosp_summary :\n\n\n\n\n\n\nMaintenant nous créons un dataframe d’une seule ligne contenant les statistiques pour tous les hôpitaux (données non groupées) :\n\n# Créer la ligne de totaux\n###############\ntotals &lt;- linelist %&gt;% \n  summarise(\n    cases = n(),                               # Nb lignes dataframe entier\n    ct_value_med = median(ct_blood, na.rm=T))  # Médiane du CT\n\nCi-dessous, le dataframe totals. Remarquez qu’il n’y a que deux colonnes alors que hosp_summary en contenant trois. Ce n’est pas un problème.\n\n\n\n\n\n\nNous utilisons à présent bind_rows() pour assembler les deux dataframes :\n\n# Combiner les deux dataframes ensemble\ncombined &lt;- bind_rows(hosp_summary, totals)\n\nPour le résultat ci-dessous. Dans la dernière ligne, une valeur vide NA a été automatiquement insérée dans la colonne hospital, qui n’était pas dans hosp_summary. Comme expliqué dans la page Tableaux de présentation, il est possible de “remplir” cette cellule avec “Total” en utilisant replace_na().\n\n\n\n\n\n\n\n\nAssembler des colonnes latéralement\nDe manière assez similaire, il existe une fonction bind_cols() dans dplyr qui combine deux dataframes latéralement. En revanche, contrairement aux jointures, les lignes sont alignées les unes aux autres par position : la ligne X du dataframe 1 sera alignée à la ligne X du dataframe 2.\nPar exemple, nous allons assembler plusieurs tableaux récapitulatifs. Nous montrerons au passage comment réarranger l’ordre des lignes d’un dataframe pour qu’il corresponde à l’ordre dans un autre dataframe, à l’aide de la fonction match().\nIci, nous définissons case_info comme un dataframe récapitulatif des cas de la liste linéaire, par hôpital, avec le nombre de cas et le nombre de décès.\n\n# Information sur les cas \ncase_info &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\n\n\n\n\n\n\n\nNous définissons également contact_fu, un autre dataframe contenant des informations sur le pourcentage de contacts exposés ayant fait l’objet d’une enquête et d’un “suivi”, toujours par hôpital.\n\ncontact_fu &lt;- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)\n\n\n\n\n\n\n\nNotez que les hôpitaux sont les mêmes, mais dans un ordre différent dans les deux dataframes. La solution la plus simple serait d’utiliser un left_join() sur la colonne hospital, mais il est aussi possible d’utiliser bind_cols() avec une étape supplémentaire.\n\nUtiliser match() pour homogénéiser l’ordre des lignes\nComme l’ordre des lignes est différent, un simple bind_cols() entraînerait une mauvaise correspondance des données. Pour résoudre ce problème, nous pouvons utiliser la fonction match() de base R pour aligner les lignes d’un dataframes dans le même ordre que dans un autre. Pour cette approche, nous supposons qu’il n’y a pas de doublons dans les dataframes.\nLorsque nous utilisons match(), la syntaxe est match(vecteur/colonne dans l'ordre désiré, colonne de dataframe à ordonner), où le premier argument est l’ordre souhaité (soit un vecteur autonome, soit une colonne d’un dataframe), et le second argument est la colonne du dataframe qui sera réordonnée. La sortie de match() est un vecteur de nombres représentant l’ordre correct des positions. Vous pouvez en savoir plus avec ?match.\n\nmatch(case_info$hospital, contact_fu$hospital)\n\n[1] 4 2 3 6 5 1\n\n\nOn peut utiliser ce vecteur numérique pour réorganiser le dataframe : placez-le entre des crochets [ ] avant la virgule. Pour en savoir plus sur la syntaxe des crochets pour séléctionner les lignes et/ou colonnes d’un dataframe en base R, consultez la page Bases de R. La commande ci-dessous crée un nouveau dataframe, défini comme l’ancien dataframe dans lequel les lignes sont ordonnées selon le tableau numérique ci-dessus.\n\ncontact_fu_aligned &lt;- contact_fu[match(case_info$hospital, contact_fu$hospital),]\n\n\n\n\n\n\n\nMaintenant nous pouvons lier les colonnes du dataframe ensemble, avec l’ordre correct des lignes respecté. Notez que certaines colonnes sont dupliquées et devront être nettoyées avec rename(). Pour en savoir plus sur bind_rows(), rendez-vous ici.\n\nbind_cols(case_info, contact_fu)\n\nNew names:\n• `hospital` -&gt; `hospital...1`\n• `hospital` -&gt; `hospital...4`\n\n\n# A tibble: 6 × 6\n  hospital...1                     cases deaths hospital...4 investigated per_fu\n  &lt;chr&gt;                            &lt;int&gt;  &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt; \n1 Central Hospital                   454    193 St. Mark's … 80%          60%   \n2 Military Hospital                  896    399 Military Ho… 82%          25%   \n3 Missing                           1469    611 Missing      &lt;NA&gt;         &lt;NA&gt;  \n4 Other                              885    395 Central Hos… 78%          20%   \n5 Port Hospital                     1762    785 Port Hospit… 64%          75%   \n6 St. Mark's Maternity Hospital (…   422    199 Other        55%          80%   \n\n\nUne alternative base R à bind_cols est cbind(), qui effectue la même opération.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joindre des données</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.fr.html#resources",
    "href": "new_pages/joining_matching.fr.html#resources",
    "title": "14  Joindre des données",
    "section": "14.5 Resources",
    "text": "14.5 Resources\nLa page du tidyverse sur les jointures\nLe chapitre sur les données relationelles dans R for Data Science\nLa page de dplyr sur bind on binding\nUne vignette surfastLink sur la page Github du paquet\nPublication décrivant la méthodologie de fastLink\nPublication décrivant le paquetRecordLinkage",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Joindre des données</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html",
    "href": "new_pages/deduplication.fr.html",
    "title": "15  De-duplication",
    "section": "",
    "text": "15.1 Préparation",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html#préparation",
    "href": "new_pages/deduplication.fr.html#préparation",
    "title": "15  De-duplication",
    "section": "",
    "text": "Importation des packages\nCes lignes de code importe les packages necessaire pour l’analyse. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages en R.\n\npacman::p_load(\n  tidyverse,   # fonctions de déduplication, de regroupement et de slicing\n  janitor,     # fonction de gestion des doublons \n  stringr)     # pour la recherche des caractères, peut être utilisé ensembler les valeurs\n\n\n\nImporter les données\nPour la démonstration, nous allons utiliser un ensemble de données exemplaire qui a été créé avec le code R ci-dessous.\nLes données sont des enregistrements des appels téléphoniques sur le COVID-19, y compris les appels avec des contacts et des cas. Les colonnes comprennent recordID (généré par ordinateur), personID, name, date de la rencontre, time de la rencontre, le purpose de la rencontre (soit pour un interview en tant que cas ou en tant que contact), et symptoms_ever (si la personne dans cette appel a déclaré avoir jamais eu des symptômes).\nVoici le code pour créer la base de données obs :\n\nobs &lt;- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %&gt;% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))\n\n\nVoici le tableau de données\nUtilisez les boîtes de filtre au-dessous pour examiner les rencontres pour chaque personne.\n\n\n\n\n\n\nQuelques éléments à noter lors de l’examen des données :\n\nLes deux premiers enregistrements sont des doublons complets à 100%, y compris le recordID ( cela doit être un problème informatique !).\n\nLes deux secondes lignes sont des doublons, dans toutes les colonnes, sauf pour le recordID.\n\nPlusieurs personnes ont été contactées plusieurs fois par téléphone, à des dates et horaires différents, et en tant que contacts et/ou cas.\n\nA chaque rencontre, il a été demandé à la personne si elle avait jamais eu des symptômes, et certaines de ces informations sont manquantes.\n\nEt voici un résumé de ces personnes et la raison de leurs rencontres, en utilisant tabyl() de janitor :\n\nobs %&gt;% \n  tabyl(name, purpose)\n\n    name case contact\n    adam    1       2\n  amrish    1       3\n   brian    1       2\n  mariah    1       2\n natalie    1       0\n  nikhil    0       2\n  raquel    0       2\n   smita    0       1",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html#deduplication",
    "href": "new_pages/deduplication.fr.html#deduplication",
    "title": "15  De-duplication",
    "section": "15.2 Deduplication",
    "text": "15.2 Deduplication\nCette section décrit comment examiner et supprimer les doublons dans un tableau de données. Elle montre également comment traiter les éléments dupliqués dans un vecteur.\n\n\nExaminer les lignes dupliquées\nPour rapidement examiner les lignes qui ont été dupliquées, vous pouvez utiliser get_dupes() du package janitor. Par défaut, toutes les colonnes sont prises en compte lors de l’évaluation des duplications - les lignes retournées par la fonction sont des doublons à 100% en considérant les valeurs de toutes les colonnes.\nDans le tableau de données obs, les deux premières lignes sont 100% dupliquées - elles ont la même valeur dans chaque colonne (y compris la colonne recordID, qui est supposée être unique - cela doit être un problème informatique). Le tableau de données obtenu inclut automatiquement une nouvelle colonne dupe_count sur le côté droit, montrant le nombre de lignes avec cette combinaison de valeurs en double.\n\n# 100% duplicates across all columns\nobs %&gt;% \n  janitor::get_dupes()\n\n\n\n\n\n\n\nVoir les données originales\nCependant, si nous décidons d’ignorer le recordID, les 3e et 4e lignes sont également des doublons entre eux. C’est-à-dire qu’elles ont les mêmes valeurs dans toutes les colonnes sauf pour recordID. Vous pouvez spécifier des colonnes spécifiques à ignorer dans la fonction en utilisant le symbole moins -.\n\n# Duplications lorsque la colonne recordID est exclue. \nobs %&gt;% \n  janitor::get_dupes(-recordID)         # si multiples colonnes, les inclure dans c()\n\n\n\n\n\n\n\nVous pouvez également spécifier les colonnes à considérer. Ci-dessous, seules les lignes qui ont les mêmes valeurs dans les colonnes name et purpose sont retournées. Notez comment “amrish” a maintenant un dupe_count égal à 3 pour correspondre à ses trois rencontres “contact”.\n*Défiler vers la gauche pour plus de lignes**\n\n# duplications basées sur les colonnes name et purpose uniquement\nobs %&gt;% \n  janitor::get_dupes(name, purpose)\n\n\n\n\n\n\n\nVoir les données originales\nVoir ?get_dupes pour plus de details, ou consulter ceci référence en ligne\n\n\n\nGarder seulement les lignes uniques\nPour garder que les lignes uniques d’un tableau de données, utilisez distinct() de dplyr (comme démontré dans la page CNettoyage de données et fonctions essentielles). Les lignes qui sont dupliquées sont enlevées de sorte que seule la première ligne est retenue. Par défaut, la première ligne correspond au plus grand rownumber (ordre des lignes de haut en bas). Seules les lignes uniques sont retenues.\nDans l’exemple ci-dessous, nous utilisons distinct() tel que la colonne recordID est exclue - ainsi deux lignes dupliquées sont enlevées. La première ligne (pour “adam”) était dupliquée à 100% et a été enlevée. Par ailleurs, la troisième ligne (pour “amrish”) était dupliquée dans chaque colonne sauf recordID (qui n’est pas considéré) donc a été supprimée. Le tableau de données obs est maintenant nrow(obs)-2, et non nrow(obs) lignes).\nDéfilez vers la gauche pour voir le tableau de données complet\n\n# ajouté à une chaîne de pipes (par exemple, nettoyage de données)\nobs %&gt;% \n  distinct(across(-recordID), # réduit le tableau de données à seulement des lignes uniques (retient la première ligne de toute duplication)\n           .keep_all = TRUE) \n\n# si en dehors des pipes, inclure les données comme premier argument  \n# distinct(obs)\n\n\n\n\n\n\n\nCAUTION: Si vous utilisez distinct() sur des données groupées, la fonction s’appliquera à chaque groupe. \nDéduplication basée sur des colonnes spécifiques\nVous pouvez également spécifier des colonnes qui seront la base de la déduplication. Ainsi, la déduplication ne s’applique qu’aux lignes qui sont des duplications dans les colonnes spécifiées. A moins que vous ne définissiez .keep_all = TRUE, toutes les colonnes non mentionnées seront ignorées.\nDans l’exemple ci-dessous, la déduplication ne s’applique qu’aux lignes qui ont des valeurs identiques pour les colonnes name et purpose. Ainsi, “brian” a seulement 2 lignes au lieu de 3 - son premier “contact” et son unique “case”. Pour ajuster afin que la dernière rencontre de brian pour chaque “purpose” soit retenue, voir l’onglet “Slicing within groups”.\nDéfilez vers la gauche pour voir le tableau de données complet\n\n# ajouté à une chaîne de pipes (par exemple, nettoyage de données)\nobs %&gt;% \n  distinct(name, purpose, .keep_all = TRUE) %&gt;%  # garder les lignes uniques par 'name' et par 'purpose', retient toutes les colonnes\n  arrange(name)                                  # arranger pour faciliter la visualisation\n\n\n\n\n\n\n\nVoir données originales.\n\n\n\nDédupliquer les éléments d’un vecteur\nLa fonction duplicated() de base R va évaluer un vecteur (colonne) et renvoie un vecteur logique de même longueur (TRUE/FALSE). La première fois qu’une valeur apparaît, elle renvoie FALSE (pas de duplication), et les fois suivantes, elle renvoie VRAI. Notez que NA est traité de la même façon que toute autre valeur.\n\nx &lt;- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)\n\n [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nPour ne retourner que les éléments dupliqués, vous pouvez utiliser des parenthèses pour sous-titrer le vecteur original :\n\nx[duplicated(x)]\n\n[1]  1 NA  4  4  1  2\n\n\nPour ne renvoyer que les éléments uniques, utilisez unique() de base R. Pour supprimer les NA de la sortie, mettez na.omit() dans unique().\n\nunique(x)           # alternativement, utilisez x[!duplicated(x)]\n\n[1]  1  2 NA  4  5\n\nunique(na.omit(x))  # supprimez les NA \n\n[1] 1 2 4 5\n\n\n\n\n\nUtilisant base R\nPour retourner les lignes dupliquées\nDans base R, vous pouvez également voir quelles lignes sont dupliquées à 100% dans un tableau de données df avec la commande duplicated(df) ( retourne un vecteur logique des lignes).\nAinsi, vous pouvez également utiliser le sous-groupe de base [ ] sur le tableau de données pour voir les lignes dupliquées avec df[duplicated(df),] (n’oubliez pas la virgule, qui signifie que vous voulez voir toutes les colonnes !)\nPour retourner les lignes uniques\nVoir les notes ci-dessus. Pour voir les lignes uniques, ajoutez le négateur logique ! devant la fonction duplicated() :\ndf[!duplicated(df),]\nPour retourner les lignes qui sont des duplications de certaines colonnes seulement.\nSous-ensembler le df qui se trouve *dans la parenthèse de duplicated(), afin que cette fonction ne traite que certaines colonnes du df.\nPour spécifier les colonnes, fournissez les numéros ou les noms des colonnes après une virgule (rappelez-vous, tout ceci est dans la fonction duplicated()).\nAssurez-vous de garder la virgule , à l’extérieur après la fonction duplicated() également !\nPar exemple, pour évaluer seulement les colonnes 2 à 5 pour les doublons : df[!duplicated(df[, 2:5]),]``   Pour évaluer seulement les colonnesnameetpurposepour les doublons :df[!duplicated(df[, c(“name”, “purpose)]),]`",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html#slicing",
    "href": "new_pages/deduplication.fr.html#slicing",
    "title": "15  De-duplication",
    "section": "15.3 Slicing",
    "text": "15.3 Slicing\nPour “slice” un tableau de données pour pouvoir appliquer un filtre sur les lignes par numéro/position de ligne. Cette fonction devient particulièrement utile si vous avez plusieurs lignes par groupe fonctionnel (par exemple, par “person”) et que vous ne voulez retenir qu’une ou quelques-unes d’entre elles.\nLa fonction de base slice() accepte des numéros et retourne les lignes dans ces positions. Si les numéros fournis sont positifs, seuls ceux-ci sont retournés. S’ils sont négatifs, ces lignes ne sont pas retournées. Les nombres doivent être soit tous positifs, soit tous négatifs.\n\nobs %&gt;% slice(4)  # retourne la 4e ligne\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n\n\nobs %&gt;% slice(c(2,4))  # retourne les lignes 2 et 4\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        1        1   adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n#obs %&gt;% slice(c(2:4))  # retourne les lignes 2 à 4\n\nVoir données originales.\nIl existe plusieurs variations : Celles-ci doivent être fournies avec une colonne et le nombre de lignes à retourner (à n =).\n\nslice_min() et slice_max() ne gardent que la ou les lignes avec la ou les valeurs minimales ou maximales de la colonne spécifiée. Cela permet également de retourner le “min” et le “max” de facteurs ordonnés.\nslice_head() et slice_tail() - Retient que la ou les premières ou dernières lignes.\n\nslice_sample() - ne retenir qu’un échantillon aléatoire des lignes.\n\n\nobs %&gt;% slice_max(encounter, n = 1)  # Retourne les lignes avec le plus grand nombre de \"encounter\" \n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n2       13        3 mariah 2020-01-06 08:32         3 contact            No\n3       16        5  brian 2020-01-07 07:59         3    case            No\n\n\nUtilisez les arguments n = ou prop = pour spécifier le nombre ou la proportion de lignes à retenir. Si vous n’utilisez pas la fonction dans un pipe, fournissez d’abord l’argument data (par exemple, slice(data, n = 2)). Voir ?slice pour plus d’informations.\nAutres arguments :\n.order_by = utilisé dans slice_min() et slice_max() ceci est une colonne à ordonner par avant de “slice”.\nwith_ties = TRUE par défaut, ce qui signifie que les liens sont retenus.\n.preserve = FALSE par défaut. Si TRUE, alors la structure de regroupement est recalculée après le slicing.\nweight_by = Optionnel, colonne numérique pour pondérer par ( un plus grand chiffre est plus probable d’être échantillonné).\nAussi, replace = pour savoir si l’échantillonnage est fait avec/sans remplacement.\nTIP: En utilisant slice_max() et slice_min(), assurez-vous de spécifier/d’écrire n = (e.g. n = 2, pas seulement 2). Sinon, vous risquez d’obtenir une erreur: Error:…is not empty. \nNOTE: Vous pouvez rencontrer la fonction top_n(), qui a été remplacées par les fonctions slice.\n\n\nSlice avec les groupes\nLes fonctions slice_*() peuvent être très utiles si elles sont appliquées à un tableau de données groupées, puisque l’opération de slice est effectuée sur chaque groupe séparément. Utilisez la fonction group_by() en conjonction avec slice() pour regrouper les données et prendre une tranche de chaque groupe.\nCeci est utile pour la déduplication si vous avez plusieurs lignes par personne mais que vous ne voulez retenir qu’une seule d’entre elles. Vous utilisez d’abord group_by() avec des colonnes clés qui sont les mêmes pour chaque personne, puis vous utilisez une fonction slice sur une colonne qui sera différente parmi les lignes groupées.\nDans l’exemple ci-dessous, pour ne garder que la dernière rencontre par personne, nous regroupons les lignes par name et ensuite nous utilisons slice_max() avec n = 1 sur la colonne date. Mais attention ! Pour appliquer une fonction comme slice_max() sur des dates, la colonne date doit être de la classe Date.\nPar défaut, les “liens” (par exemple la même date dans ce scénario) sont retenus, et nous aurions toujours plusieurs lignes pour certaines personnes (par exemple adam). Pour éviter cela, nous mettons with_ties = FALSE. Nous ne récupérons qu’une seule ligne par personne.\nCAUTION: Si utilisant arrange(), specifier .by_group = TRUE pour que les données soient organisées dans chaque groupe.\nDANGER: Si with_ties = FALSE, la première ligne d’une même égalité est conservée. Cela peut être déceptive. Voyez comment pour Mariah, elle a deux rencontres à sa dernière date (6 Jan) et la première (la plus ancienne) a été gardée. Il est probable que nous voulions garder la dernière rencontre de ce jour-là. Voyez comment ” séparer ” ces liens dans l’exemple suivant. \n\nobs %&gt;% \n  group_by(name) %&gt;%       # regroupe les lignes par 'name'\n  slice_max(date,          # retenir une ligne par groupe avec la valeur maximale de la date \n            n = 1,         # ne retenir que la ligne la plus élevée \n            with_ties = F) # s'il y a une égalité (de date), prenez le premier ligne\n\n\n\n\n\n\n\nCi-dessus, par exemple, nous pouvons voir que seule la ligne d’Amrish du 5 janvier a été retenue, et que seule la ligne de Brian du 7 janvier a été retenue. Voir les données originales.\nSéparation des égalités\nMultiples lignes de slice peuvent être exécutées pour ” séparer les égalités”. Dans ce cas, si une personne a plusieurs rencontres à leur dernière date, la rencontre avec la dernière heure est retenue (lubridate::hm() est utilisé pour convertir les heures des caractères en une classe de temps triable).\nNotez comment maintenant, la seule ligne conservée pour “Mariah” le 6 janvier est la rencontre 3 de 08:32, et non la rencontre 2 de 07:25.\n\n# Exemple de multiple lignes de slice exécutées pour \" séparer les égalités\"\nobs %&gt;%\n  group_by(name) %&gt;%\n  \n  # PREMIEREMENT - slice par la dernière date\n  slice_max(date, n = 1, with_ties = TRUE) %&gt;% \n  \n  # DEUXIÈMEMENT - s'il y a une égalité, sélectionner la ligne avec l'heure la plus tardive ; égalité interdite\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)\n\n\n\n\n\n\n\nDans l’exemple ci-dessus, il aurait également été possible de slice par le numéro de encounter, mais nous avons montré le slice sur date et time pour illustration.\nTIP: Pour utiliser slice_max() ou slice_min() sur une colonne e de “caractères”, mutez-la en une classe de facteurs ordonnée !.\nVoir données originales.\n\n\n\nRetenir tous les lignes mais les marquer\nSi vous voulez retenir tous les evenements mais n’en marquer que certains pour l’analyse, envisagez une approche en deux étapes en utilisant un numéro unique de recordID/encounter :\n\nReduire/slice le tableau de données original pour n’avoir que les lignes à analyser. Sauvegardez/retenir ce tableau de données réduit.\n\nDans le tableau de données original, marquez les lignes avec case_when(), selon que leur identifiant unique d’enregistrement (recordID dans cet exemple) est présent ou non dans le tableau de données réduit.\n\n\n# 1. Definir les lignes de tableau de données à retenir pour l'analyse\nobs_keep &lt;- obs %&gt;%\n  group_by(name) %&gt;%\n  slice_max(encounter, n = 1, with_ties = FALSE) # ne garder que la dernière rencontre par personne\n\n\n# 2. Marquer le tableau de données original\nobs_marked &lt;- obs %&gt;%\n\n  # Créer une nouvelle colonne dup_record\n  mutate(dup_record = case_when(\n    \n    # si record est dans le tableau de données obs_keep\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    #tout le reste est marqué comme \"Ignore\" pour l'analyse\n    TRUE                            ~ \"Ignore\"))\n\n# imprimer\nobs_marked\n\n   recordID personID    name       date  time encounter purpose symptoms_ever\n1         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n3         2        2  amrish 2020-01-02 14:20         1 contact            No\n4         3        2  amrish 2020-01-02 14:20         1 contact            No\n5         4        3  mariah 2020-01-05 12:00         1    case            No\n6         5        2  amrish 2020-01-05 16:10         3    case           Yes\n7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes\n8         7        5   brian 2020-01-05 15:20         1 contact            No\n9         8        6   smita 2020-01-05 14:20         1 contact           Yes\n10        9        7  raquel 2020-01-05 12:30         1 contact          &lt;NA&gt;\n11       10        2  amrish 2020-01-02 10:24         2 contact           Yes\n12       11        1    adam 2020-01-05 09:40         2    case            No\n13       12        3  mariah 2020-01-06 07:25         2 contact            No\n14       13        3  mariah 2020-01-06 08:32         3 contact            No\n15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes\n16       15        5   brian 2020-01-06 15:31         2 contact           Yes\n17       16        5   brian 2020-01-07 07:59         3    case            No\n18       17        7  raquel 2020-01-07 11:13         2 contact            No\n19       18        8 natalie 2020-01-07 17:12         1    case            No\n     dup_record\n1        Ignore\n2        Ignore\n3        Ignore\n4        Ignore\n5        Ignore\n6  For analysis\n7        Ignore\n8        Ignore\n9  For analysis\n10       Ignore\n11       Ignore\n12 For analysis\n13       Ignore\n14 For analysis\n15 For analysis\n16       Ignore\n17 For analysis\n18 For analysis\n19 For analysis\n\n\n\n\n\n\n\n\nVoir données originales.\n\n\n\nCalcul de la complétude des lignes\nCréez une colonne qui contient une métrique pour la complétude des lignes (pas de valeurs manquantes). Cela peut être utile pour décider des lignes à prioriser par rapport aux autres lors de la déduplication.\nDans cet exemple, les colonnes “clés” sur lesquelles vous voulez mesurer la complétude sont sauvegardées dans un vecteur de noms de colonnes.\nEnsuite, la nouvelle colonne key_completeness est créée avec mutate(). La nouvelle valeur dans chaque ligne est définie comme une fraction calculée : le nombre de valeurs non manquantes dans cette ligne parmi les colonnes clés, divisé par le nombre de colonnes clés.\nCela fait appel à la fonction rowSums() de base R. On utilise également ., qui, dans le cadre d’un pipe, fait référence au tableau de données à ce point du pipe (dans ce cas, il est sous-ensemble avec les crochets []).\nDéfiler vers la droite pour voir plus de lignes.\n\n# créer une colonne \"complétude des variables clés\".\n# il s'agit de la *proportion* des colonnes désignées comme \"key_cols\" qui ont des valeurs non manquantes.\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %&gt;% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) \n\n\n\n\n\n\n\nVoir données originales.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html#str_rollup",
    "href": "new_pages/deduplication.fr.html#str_rollup",
    "title": "15  De-duplication",
    "section": "15.4 Réunir les valeurs de plusieurs lignes",
    "text": "15.4 Réunir les valeurs de plusieurs lignes\nCette section décrit :\n\nComment “réunir” les valeurs de plusieurs lignes en une seule ligne, avec quelques variations.\n\nUne fois les valeurs sont “réunit”, comment remplacer/prioriser les valeurs dans chaque cellule.\n\nCet onglet utilise le jeu de données d’exemple de l’onglet Préparation.\n\n\nRéunir les valeurs en une seule ligne\nL’exemple de code ci-dessous utilise group_by() et summarise() pour regrouper les lignes par personne, puis rassembler toutes les valeurs uniques dans les lignes groupées. Ainsi, vous obtenez un résumé de ligne par personne. Quelques notes :\n* Un suffixe est ajouté à toutes les nouvelles colonnes (“_roll” dans cet exemple).\n* Si vous ne voulez afficher que les valeurs uniques par cellule, enveloppez le na.omit() avec unique().\n* na.omit() supprime les valeurs NA, mais si cela n’est pas souhaité, il peut être supprimé paste0(.x) …\n\n# Réunir les valeurs en une seule ligne par groupe (par \"personID\") \ncases_rolled &lt;- obs %&gt;% \n  \n  # créer des groupes par nom\n  group_by(personID) %&gt;% \n  \n  # ordonner les lignes à l'intérieur de chaque groupe (par exemple par date)\n  arrange(date, .by_group = TRUE) %&gt;% \n  \n  # Pour chaque colonne, rassemblez toutes les valeurs des lignes groupées, en les séparant par \" ;\".\n  summarise(\n    across(everything(),                           # appliquer à toutes les colonnes\n           ~paste0(na.omit(.x), collapse = \"; \"))) # on définit une fonction qui combine les valeurs non-NA \n\nLe résultat est une ligne par groupe (ID), avec des entrées classées par date et assemblées. Défiler vers la gauche pour voir plus de lignes\n\n\n\n\n\n\nVoir données originales.\nCette variation ne présente que des valeurs uniques:\n\n# Cette variation ne présente que des valeurs uniques \ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                                   # appliquer à toutes les colonnes\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # on définit une fonction qui combine les valeurs non-NA \n\n\n\n\n\n\n\nCette variation ajoute un suffixe à chaque colonne.\nDans ce cas, “_roll” pour signifier qu’elle a été roulée :\n\n# Cette variation ajoute un suffixe à chaque colonne\ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll est ajouté aux noms des colonnes\n\n\n\n\n\n\n\n\n\n\nRemplacer les valeurs/hiérarchie\nSi vous voulez ensuite évaluer toutes les valeurs reunit, et ne garder qu’une valeur spécifique (par exemple la “meilleure” ou la “valeur maximale”), vous pouvez utiliser mutate() sur les colonnes souhaitées, pour implémenter case_when(), qui utilise str_detect() du package stringr pour rechercher séquentiellement des séquences de caractères et remplacer le contenu de la cellule.\n\n# CLEAN CASES\n#############\ncases_clean &lt;- cases_rolled %&gt;% \n    \n    # nettoie les variables Yes-No-Unknown : remplace le texte par la valeur \"la plus élevée\" présente dans la séquence des caracteres\n    mutate(across(c(contains(\"symptoms_ever\")),                     # fonctionne sur les colonnes spécifiées (Y/N/U)\n             list(mod = ~case_when(                                 # ajoute le suffixe \"_mod\" aux nouvelles cols ; implémente case_when() \n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # si \"Yes\" est détecté, alors la valeur de la cellule est convertie en Yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # # alors, si \"No\" est détecté, la valeur de la cellule est convertie en No\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # alors, si \"Unknown\" est détecté, la valeur de la cellule est convertie en Unknown \n               TRUE                        ~ as.character(.x)))),   # alors, si quelque chose d'autre est retenu comme tel\n      .keep = \"unused\")                                             # anciennes colonnes enlevées, ne laissant que des colonnes _mod\n\nMaintenant vous pouvez voir dans la colonne symptoms_ever que si la personne a JAMAIS dit “Oui” aux symptômes, alors seul “Oui” est affiché.\n\n\n\n\n\n\nVoir données originales.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html#déduplication-probabiliste",
    "href": "new_pages/deduplication.fr.html#déduplication-probabiliste",
    "title": "15  De-duplication",
    "section": "15.5 Déduplication probabiliste",
    "text": "15.5 Déduplication probabiliste\nParfois, vous souhaitez identifier les doublons “probables” en vous basant sur la similarité (par exemple, la sequence des caractères “distance”) entre plusieurs colonnes telles que le nom, l’âge, le sexe, la date de naissance, etc. Vous pouvez appliquer un algorithme de correspondance probabiliste pour identifier les doublons probables.\nVoir la page Joindre des données pour une explication de cette méthode. La section sur l’Appariement Probabiliste contient un exemple d’application de ces algorithmes pour comparer un tableau de données à soi-même, effectuant ainsi une déduplication probabiliste.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.fr.html#ressources",
    "href": "new_pages/deduplication.fr.html#ressources",
    "title": "15  De-duplication",
    "section": "15.6 Ressources",
    "text": "15.6 Ressources\nLa plupart des informations contenues dans cette page sont adaptées de ces ressources et des vignettes en ligne :\ndatanovia\ndplyr tidyverse reference\ncran janitor vignette",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplication</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.fr.html",
    "href": "new_pages/iteration.fr.html",
    "title": "16  Itération, boucles et listes",
    "section": "",
    "text": "16.1 Préparation",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Itération, boucles et listes</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.fr.html#préparation",
    "href": "new_pages/iteration.fr.html#préparation",
    "title": "16  Itération, boucles et listes",
    "section": "",
    "text": "Chargement des paquets\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n     rio, # import/export\n     here, # localisateur de fichiers\n     purrr, # itération\n     tidyverse, # gestion et visualisation des données\n     grates\n)\n\n\n\nImporter des données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre le mouvement, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# Importez la liste de cas\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la linelist sont affichées ci-dessous.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Itération, boucles et listes</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.fr.html#for-loops",
    "href": "new_pages/iteration.fr.html#for-loops",
    "title": "16  Itération, boucles et listes",
    "section": "16.2 for loops",
    "text": "16.2 for loops\n\nfor loops en R\nLes for loops ne sont pas mis en avant dans R, mais sont courants dans d’autres langages de programmation. En tant que débutant, elles peuvent être utiles à l’apprentissage et à la pratique car elles sont plus faciles à “explorer”, à “déboguer” et à comprendre exactement ce qui se passe à chaque itération, en particulier lorsque vous n’êtes pas encore à l’aise pour écrire vos propres fonctions.\nVous pouvez passer rapidement des boucles for à l’itération avec des fonctions mappées avec purrr (voir section ci-dessous).\n\n\nComposants principaux\nUne boucle for comporte trois éléments essentiels :\n\nla séquence d’éléments à parcourir par itération\n\nLes opérations à effectuer pour chaque élément de la séquence.\n\nle contenu des résultats (facultatif).\n\nLa syntaxe de base est la suivante : pour (élément dans la séquence) {faire des opérations avec l'élément}. Notez les parenthèses et les accolades. Les résultats peuvent être imprimés sur la console, ou stockés dans un objet R conteneur.\nVoici un exemple simple de boucle for.\n\nfor (num in c(1,2,3,4,5)) { # la SEQUENCE est définie (numéros 1 à 5) et la boucle est ouverte avec \"{\"\n  print(num + 2) # Les OPERATIONS (ajouter deux à chaque numéro de séquence et imprimer)\n}                            # La boucle est fermée avec \"}\"                            \n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n\n                             # Il n'y a pas de \"conteneur\" dans cet exemple.\n\n\n\n16.2.1 Séquence {.unnumbered} (sans numéro)\nIl s’agit de la partie “for” d’une boucle for - les opérations seront exécutées “pour” chaque élément de la séquence. La séquence peut être une série de valeurs (par exemple, des noms de juridictions, de maladies, des noms de colonnes, des éléments de listes, etc), ou bien une série de nombres consécutifs (par exemple, 1,2,3,4,5). Chaque approche a ses propres utilitaires, décrits ci-dessous.\nLa structure de base d’une déclaration de séquence est item in vector.\n\nVous pouvez écrire n’importe quel caractère ou mot à la place de “item” (par exemple “i”, “num”, “hosp”, “district”, etc.). La valeur de cet “item” change à chaque itération de la boucle, en passant par chaque valeur du vecteur.\n\nLe vecteur peut être constitué de valeurs de caractères, de noms de colonnes, ou peut-être d’une séquence de nombres - ce sont les valeurs qui changeront à chaque itération. Vous pouvez les utiliser dans les opérations for loop en utilisant le terme “item”.\n\nExemple : séquence de valeurs de caractères\nDans cet exemple, une boucle est exécutée pour chaque valeur d’un vecteur de caractères prédéfini de noms d’hôpitaux.\n\n# faire un vecteur des noms d'hôpitaux\nhospital_names &lt;- unique(linelist$hospital)\nhospital_names # print\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n[6] \"Central Hospital\"                    \n\n\nNous avons choisi le terme hosp pour représenter les valeurs du vecteur hospital_names. Pour la première itération de la boucle, la valeur de hosp sera hospital_names[[1]]. Pour la deuxième boucle, elle sera noms_hospitaliers[[2]]. Et ainsi de suite…\n\n# une 'boucle for' avec une séquence de caractères\n\nfor (hosp in hospital_names){ # séquence\n  \n       # OPÉRATIONS ICI\n  }\n\nExemple : séquence de noms de colonnes\nIl s’agit d’une variation de la séquence de caractères ci-dessus, dans laquelle les noms d’un objet R existant sont extraits et deviennent le vecteur. Par exemple, les noms des colonnes d’un cadre de données. De façon pratique, dans le code d’opérations de la boucle for, les noms de colonnes peuvent être utilisés pour indexer (sous-ensemble) leur cadre de données original.\nCi-dessous, la séquence est constituée des names() (noms des colonnes) du cadre de données linelist. Notre nom d’“élément” est col, qui représentera chaque nom de colonne au fur et à mesure que les boucles se déroulent.\nPour les besoins de l’exemple, nous incluons le code des opérations à l’intérieur de la boucle for, qui est exécutée pour chaque valeur de la séquence. Dans ce code, les valeurs de la séquence (noms de colonnes) sont utilisées pour indexer (sous-ensemble) linelist, une par une. Comme enseigné dans la page bases de R, les doubles branchements [[ ]] sont utilisés pour sous-indexer. La colonne résultante est passée à is.na(), puis à sum() pour produire le nombre de valeurs manquantes dans la colonne. Le résultat est imprimé sur la console - un nombre pour chaque colonne.\nUne remarque sur l’indexation avec les noms de colonnes - lorsque vous faites référence à la colonne elle-même, ne vous contentez pas d’écrire “col”! col ne représente que le nom de la colonne en caractères! Pour faire référence à la colonne entière, vous devez utiliser le nom de la colonne comme index sur linelist via linelist[[col]].\n\nfor (col in names(linelist)){ # La boucle est exécutée pour chaque colonne de la linelist ; le nom de la colonne est représenté par \"col\". \n  \n  # Exemple de code d'opérations - impression du nombre de valeurs manquantes dans la colonne\n  print(sum(is.na(linelist[[col]])))  # La linelist est indexée par la valeur actuelle de \"col\".\n     \n}\n\n[1] 0\n[1] 0\n[1] 2087\n[1] 256\n[1] 0\n[1] 936\n[1] 1323\n[1] 278\n[1] 86\n[1] 0\n[1] 86\n[1] 86\n[1] 86\n[1] 0\n[1] 0\n[1] 0\n[1] 2088\n[1] 2088\n[1] 0\n[1] 0\n[1] 0\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 149\n[1] 765\n[1] 0\n[1] 256\n\n\nSéquence de nombres\nDans cette approche, la séquence est une série de nombres consécutifs. Ainsi, la valeur de l’“item” n’est pas une valeur de caractère (par exemple, “Central Hospital” ou “date_onset”) mais un nombre. Ceci est utile pour boucler des cadres de données, car vous pouvez utiliser le numéro de “item” dans la boucle for pour indexer le cadre de données par numéro de ligne.\nPar exemple, disons que vous souhaitez parcourir chaque ligne de votre cadre de données et extraire certaines informations. Vos “éléments” seraient des numéros de ligne numériques. Dans ce cas, les “éléments” sont souvent écrits sous la forme i.\nLe processus for loop pourrait s’expliquer par la phrase suivante: “pour chaque élément d’une séquence de nombres allant de 1 au nombre total de lignes de mon cadre de données, faire X”. Pour la première itération de la boucle, la valeur de l’“élément” i sera 1. Pour la deuxième itération, i sera 2, etc.\nVoici à quoi ressemble la séquence en code: for (i in 1:nrow(linelist)) {CODE DES OPERATIONS} où i représente l’“élément” et 1:nrow(linelist) produit une séquence de nombres consécutifs allant de 1 au nombre de lignes de linelist.\n\nfor (i in 1:nrow(linelist)) { # utilisation sur un cadre de données\n  # OPÉRATIONS ICI\n}  \n\nSi vous voulez que la séquence soit des nombres, mais que vous partez d’un vecteur (et non d’un cadre de données), utilisez le raccourci seq_along() pour retourner une séquence de nombres pour chaque élément du vecteur. Par exemple, for (i in seq_along(hospital_names) {CODE D'OPÉRATIONS}.\nLe code ci-dessous renvoie en fait des nombres, qui deviendront la valeur de i dans leur boucle respective.\n\nseq_along(hospital_names) # utilisation sur un vecteur nommé\n\n[1] 1 2 3 4 5 6\n\n\nUn avantage de l’utilisation de nombres dans la séquence est qu’il est facile d’utiliser le nombre i pour indexer un conteneur qui stocke les sorties de la boucle. Il y a un exemple de ceci dans la section Opérations ci-dessous.\n\n\nOpérations\nC’est le code entre les crochets { } de la boucle for. Vous voulez que ce code soit exécuté pour chaque “élément” de la séquence. Par conséquent, faites attention à ce que chaque partie de votre code qui change en fonction de l’“item” soit correctement codée pour qu’elle change réellement ! Par exemple, n’oubliez pas d’utiliser [[ ]] pour l’indexation.\nDans l’exemple ci-dessous, nous itérons à travers chaque ligne de la linelist. Les valeurs gender et age de chaque ligne sont collées ensemble et stockées dans le vecteur de caractères conteneur cases_demographics. Notez comment nous utilisons également l’indexation [[i]] pour enregistrer la sortie de la boucle à la bonne position dans le vecteur “conteneur”.\n\n# créer un conteneur pour stocker les résultats - un vecteur de caractères\ncases_demographics &lt;- vector(mode = \"character\", length = nrow(linelist))\n\n# la boucle for\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extraire les valeurs de la linelist pour la ligne i, en utilisant les parenthèses pour l'indexation.\n  row_gender &lt;- linelist$gender[[i]]\n  row_age &lt;- linelist$age_years[[i]]    # n'oubliez pas d'indexer!\n     \n  # combinez sexe-âge et stockez dans un vecteur conteneur à l'emplacement indexé\n  cases_demographics[[i]] &lt;- str_c(row_gender, row_age, sep = \",\") \n\n}  # fin de la boucle for\n\n\n# affiche les 10 premières lignes du conteneur\nhead(cases_demographics, 10)\n\n [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\"\n\n\n\n\nConteneur\nParfois, les résultats de votre boucle for seront imprimés sur la console ou dans le panneau Plots de RStudio. D’autres fois, vous voudrez stocker les résultats dans un “conteneur” pour une utilisation ultérieure. Ce conteneur peut être un vecteur, un cadre de données ou même une liste.\nIl est plus efficace de créer le conteneur pour les résultats avant même de commencer la boucle for. En pratique, cela signifie créer un vecteur, un cadre de données ou une liste vide. On peut les créer avec les fonctions vector() pour les vecteurs ou les listes, ou avec matrix() et data.frame() pour un cadre de données.\nVecteur vide\nUtilisez vector() et spécifiez le mode = en fonction de la classe attendue des objets que vous allez insérer - soit “double” (pour contenir des nombres), “caractère”, ou “logique”. Vous devez également définir la valeur length = à l’avance. Il s’agit de la longueur de votre séquence for loop.\nDisons que vous voulez stocker le délai médian d’admission pour chaque hôpital. Vous utiliserez “double” et définirez la longueur comme étant le nombre de sorties attendues (le nombre d’hôpitaux uniques dans l’ensemble de données).\n\ndelays &lt;- vector(\n  mode = \"double\", # nous nous attendons à stocker des nombres\n  length = length(unique(linelist$hospital))) # le nombre d'hôpitaux uniques dans l'ensemble de données\n\n**Cadre de données vide\nVous pouvez créer un cadre de données vide en spécifiant le nombre de lignes et de colonnes comme ceci :\n\ndelays &lt;- data.frame(matrix(ncol = 2, nrow = 3))\n\nListe vide\nVous pouvez vouloir stocker certains graphiques créés par une boucle for dans une liste. Une liste est comme un vecteur, mais elle contient d’autres objets R qui peuvent être de différentes classes. Les éléments d’une liste peuvent être un nombre unique, un cadre de données, un vecteur et même une autre liste.\nVous pouvez initialiser une liste vide en utilisant la même commande vector() que ci-dessus, mais avec mode = \"list\". Spécifiez la longueur comme vous le souhaitez.\n\nplots &lt;- vector(mode = \"list\", length = 16)\n\n\n\nImpression\nNotez que pour imprimer à partir d’une boucle for, vous aurez probablement besoin d’envelopper explicitement avec la fonction print().\nDans l’exemple ci-dessous, la séquence est un vecteur de caractères explicite, qui est utilisé pour sous-titrer la linelist par hôpital. Les résultats ne sont pas stockés dans un conteneur, mais sont imprimés sur la console avec la fonction print().\n\nfor (hosp in hospital_names){ \n     hospital_cases &lt;- linelist %&gt;% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}\n\n[1] 885\n[1] 1469\n[1] 422\n[1] 1762\n[1] 896\n[1] 454\n\n\n\n\nTester votre boucle for\nPour tester votre boucle, vous pouvez lancer une commande pour effectuer une affectation temporaire de l’“élément”, comme i &lt;- 10 ou hosp &lt;- \"Central Hospital\". Faites cela en dehors de la boucle, puis exécutez votre code d’opérations uniquement (le code entre les accolades) pour voir si les résultats attendus sont produits.\n\n\nPlots de bouclage\nPour rassembler les trois composants (conteneur, séquence et opérations), essayons de tracer une épicurve pour chaque hôpital (voir la page sur les Courbes épidémiques).\nNous pouvons faire une belle épicurve de tous les cas par sexe en utilisant le paquet incidence2 comme ci-dessous:\n\n# créer un objet 'incidence\noutbreak &lt;- incidence2::incidence(   \n     x = linelist, # dataframe - linelist complet\n     date_index = \"date_onset\", # colonne de date\n     interval = \"week\", # aggregate counts weekly\n     groups = \"gender\") # regroupe les valeurs par sexe\n     #na_as_group = TRUE , deprecated incidence version 2.0.0\n\n# tracer la courbe d'épidémie\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # couleur des barres par sexe\n       color = \"black\"      # couleur de contour des barres\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n\n\n\n\n\n\n\n\nPour produire un graphique distinct pour les cas de chaque hôpital, nous pouvons placer ce code épicurve dans une boucle for.\nTout d’abord, nous enregistrons un vecteur nommé des noms uniques des hôpitaux, hospital_names. La boucle for sera exécutée une fois pour chacun de ces noms : for (hosp in hospital_names). A chaque itération de la boucle for, le nom de l’hôpital actuel du vecteur sera représenté par hosp pour être utilisé dans la boucle.\nDans les opérations de la boucle, vous pouvez écrire du code R comme d’habitude, mais utiliser l’“élément” (hosp dans ce cas) en sachant que sa valeur va changer. Dans cette boucle :\n\nUn filter() est appliqué à linelist, de telle sorte que la colonne hospital doit être égale à la valeur actuelle de hosp.\n\nL’objet incidence est créé sur la liste de lignes filtrée.\n\nLe graphique de l’hôpital actuel est créé, avec un titre auto-ajustable qui utilise hosp.\n\nLe graphique de l’hôpital actuel est temporairement sauvegardé puis imprimé.\n\nLa boucle se répète ensuite avec l’hôpital suivant dans hospital_names.\n\n\n# fabrique un vecteur des noms d'hôpitaux\nhospital_names &lt;- unique(linelist$hospital)\n\n# pour chaque nom (\"hosp\") dans hospital_names, créer et imprimer la courbe épi\nfor (hosp in hospital_names) {\n     \n     # créer un objet d'incidence spécifique à l'hôpital actuel\n     outbreak_hosp &lt;- incidence2::incidence(\n          x = linelist %&gt;% filter(hospital == hosp), # linelist est filtré sur l'hôpital actuel\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\",\n          #na_as_group = TRUE , deprecated incidence version 2.0.0\n     )\n     \n     \n     # tracer la courbe d'épidémie\n\n     plot_hosp &lt;- ggplot(outbreak_hosp, # nom de l'objet d'incidence\n                         aes(x = date_index, #aesthetiques et axes\n                             y = count, \n                             fill = gender), # couleur des barres par sexe\n                         color = \"black\"      # couleur de contour des barres\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #titre\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # Créez et enregistrez le graphique. Le titre s'ajuste automatiquement à l'hôpital actuel\n    # plot_hosp &lt;- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     # imprimer le graphique pour l'hôpital actuel\n     print(plot_hosp)\n     \n} # terminez la boucle for lorsqu'elle a été exécutée pour chaque hôpital dans hospital_names \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuivi de la progression d’une boucle\nUne boucle comportant de nombreuses itérations peut s’exécuter pendant plusieurs minutes, voire plusieurs heures. Ainsi, il peut être utile d’imprimer la progression dans la console R. L’instruction if ci-dessous peut être placée dans les opérations de la boucle pour imprimer chaque 100ème nombre. Il suffit de l’ajuster pour que i soit l’“élément” de votre boucle.\n\n# boucle avec code pour imprimer la progression toutes les 100 itérations\nfor (i in seq_len(nrow(linelist))){\n\n  # imprimer la progression\n  if(i %% 100==0){ # L'opérateur %% est le restant\n    print(i)\n\n}",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Itération, boucles et listes</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.fr.html#iter_purrr",
    "href": "new_pages/iteration.fr.html#iter_purrr",
    "title": "16  Itération, boucles et listes",
    "section": "16.3 purrr et listes",
    "text": "16.3 purrr et listes\nUne autre approche des opérations itératives est le paquet purrr - c’est l’approche tidyverse de l’itération.\nSi vous devez effectuer la même tâche plusieurs fois, il est probablement utile de créer une solution généralisée que vous pouvez utiliser sur plusieurs entrées. Par exemple, produire des tracés pour plusieurs juridictions, ou importer et combiner de nombreux fichiers.\nIl y a aussi quelques autres avantages à purrr - vous pouvez l’utiliser avec des tubes %&gt;%, il gère mieux les erreurs que les boucles for normales, et la syntaxe est assez propre et simple ! Si vous utilisez une boucle for, vous pouvez probablement le faire plus clairement et succinctement avec purrr !\nGardez à l’esprit que purrr est un outil de programmation fonctionnel. C’est-à-dire que les opérations qui doivent être appliquées de manière itérative sont regroupées dans des fonctions. Consultez la page Écrire des fonctions pour apprendre à écrire vos propres fonctions.\npurrr est également presque entièrement basé sur des listes et des vecteurs - pensez-y comme si vous appliquiez une fonction à chaque élément de cette liste/ce vecteur !\n\nChargement des paquets\npurrr fait partie de tidyverse, il n’y a donc pas besoin d’installer/charger un paquet séparé.\n\npacman::p_load(\n     rio, # import/export\n     here, # chemins de fichiers relatifs\n     tidyverse, # gestion et visualisation des données\n     writexl, # écriture d'un fichier Excel à feuilles multiples\n     readxl # importer Excel avec plusieurs feuilles\n)\n\n\n\nmap()\nUne fonction essentielle de purrr est map(), qui “mappe” (applique) une fonction à chaque élément d’entrée d’une liste/vecteur que vous fournissez.\nLa syntaxe de base est map(.x = SEQUENCE, .f = FONCTION, AUTRES ARGUMENTS). Un peu plus en détail :\n\n.x = sont les entrées sur lesquelles la fonction .f sera appliquée de manière itérative - par exemple un vecteur de noms de juridiction, des colonnes dans un cadre de données, ou une liste de cadres de données.\n\n.f = est la fonction à appliquer à chaque élément de l’entrée .x - cela peut être une fonction comme print() qui existe déjà, ou une fonction personnalisée que vous définissez. La fonction est souvent écrite après un tilde ~ (détails ci-dessous).\n\nQuelques notes supplémentaires sur la syntaxe :\n\nSi la fonction n’a pas besoin de spécifier d’autres arguments, elle peut être écrite sans parenthèses et sans tilde (par exemple, .f = mean). Pour fournir des arguments qui auront la même valeur à chaque itération, fournissez-les dans map() mais en dehors de l’argument .f =, comme le na.rm = T dans map(.x = ma_liste, .f = mean, na.rm=T).\n\nVous pouvez utiliser .x (ou simplement .) * à l’intérieur* de la fonction .f = comme substitut pour la valeur .x de cette itération.\n\nUtilisez la syntaxe du tilde (~) pour avoir un meilleur contrôle sur la fonction - écrivez la fonction normalement avec des parenthèses, par exemple : map(.x = ma_liste, .f = ~mean(., na.rm = T)). Utilisez cette syntaxe particulièrement si la valeur d’un argument change à chaque itération, ou si c’est la valeur .x elle-même (voir les exemples ci-dessous)\n\nLe résultat de l’utilisation de map() est une liste  - une liste est une classe d’objets comme un vecteur mais dont les éléments peuvent être de classes différentes. Ainsi, une liste produite par map() peut contenir de nombreux cadres de données, ou de nombreux vecteurs, de nombreuses valeurs individuelles, ou même de nombreuses listes ! Il existe des versions alternatives de map() expliquées ci-dessous qui produisent d’autres types de sorties (par exemple, map_dfr() pour produire un cadre de données, map_chr() pour produire des vecteurs de caractères, et map_dbl() pour produire des vecteurs numériques).\n\nExemple - Importer et combiner des feuilles Excel\nDémontrons avec une tâche courante d’épidémiologiste: - *Vous voulez importer un classeur Excel avec des données de cas, mais les données sont réparties sur différentes feuilles nommées dans le classeur. Comment importer et combiner efficacement les feuilles en un seul cadre de données ?\nImaginons que l’on nous envoie le classeur Excel ci-dessous. Chaque feuille contient les cas d’un hôpital donné.\n\n\n\n\n\n\n\n\n\nVoici une approche qui utilise map() :\n\nmap() la fonction import() pour qu’elle s’exécute pour chaque feuille Excel.\n\nCombinez les cadres de données importés en un seul en utilisant bind_rows().\n\nEn cours de route, conservez le nom de la feuille originale pour chaque ligne, en stockant cette information dans une nouvelle colonne du cadre de données final.\n\nTout d’abord, nous devons extraire les noms des feuilles et les enregistrer. Nous fournissons le chemin du fichier du classeur Excel à la fonction excel_sheets() du package readxl, qui extrait les noms des feuilles. Nous les stockons dans un vecteur de caractères appelé sheet_names.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\nVoici les noms :\n\nsheet_names\n\n[1] \"Central Hospital\"              \"Military Hospital\"            \n[3] \"Missing\"                       \"Other\"                        \n[5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\n\n\nMaintenant que nous avons ce vecteur de noms, map() peut les fournir un par un à la fonction import(). Dans cet exemple, les sheet_names sont .x et import() est la fonction .f.\nRappelez-vous de la page Importation et exportation que lorsqu’il est utilisé sur des classeurs Excel, import() peut accepter l’argument which = spécifiant la feuille à importer. Dans la fonction .f import(), nous fournissons which = .x, dont la valeur changera à chaque itération dans le vecteur sheet_names - d’abord “Central Hospital”, puis “Military Hospital”, etc.\nA noter - parce que nous avons utilisé map(), les données de chaque feuille Excel seront enregistrées comme un cadre de données séparé dans une liste. Nous voulons que chacun de ces éléments de liste (cadres de données) ait un nom, donc avant de passer sheet_names à map(), nous le passons à travers set_names() de purrr, ce qui garantit que chaque élément de liste reçoit le nom approprié.\nNous enregistrons la liste de sortie comme combined (combiné en francais).\n\ncombined &lt;- sheet_names %&gt;% \n  purrr::set_names() %&gt;% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\n\nLorsque nous inspectons la sortie, nous voyons que les données de chaque feuille Excel sont enregistrées dans la liste avec un nom. C’est bien, mais nous n’avons pas tout à fait terminé.\n\n\n\n\n\n\n\n\n\nEnfin, nous utilisons la fonction bind_rows() (de dplyr) qui accepte la liste des cadres de données structurés de manière similaire et les combine en un seul cadre de données. Pour créer une nouvelle colonne à partir de l’élément de liste names, nous utilisons l’argument .id = et lui fournissons le nom souhaité pour la nouvelle colonne.\nVoici la séquence complète des commandes :\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\") # extrait les noms des feuilles\n \ncombined &lt;- sheet_names %&gt;% # commence avec les noms de feuilles\n  purrr::set_names() %&gt;% # définit leurs noms\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %&gt;% # itère, importe, sauvegarde dans la liste\n  bind_rows(.id = \"origin_sheet\") # combine la liste des cadres de données, en préservant l'origine dans une nouvelle colonne  \n\nEt maintenant nous avons un cadre de données avec une colonne contenant la feuille d’origine !\n\n\n\n\n\n\n\n\n\nIl existe des variantes de map() que vous devez connaître. Par exemple, map_dfr() renvoie un cadre de données, et non une liste. Ainsi, nous aurions pu l’utiliser pour la tâche ci-dessus et ne pas avoir à lier les rangées. Mais alors nous n’aurions pas été en mesure de capturer de quelle feuille (hôpital) chaque cas provenait.\nD’autres variations incluent map_chr(), map_dbl(). Ces fonctions sont très utiles pour deux raisons. Premièrement, elles convertissent automatiquement la sortie d’une fonction itérative en un vecteur (et non en une liste). Deuxièmement, elles peuvent contrôler explicitement la classe dans laquelle les données reviennent - vous vous assurez que vos données reviennent sous forme de vecteur de caractères avec map_chr(), ou de vecteur numérique avec map_dbl(). Nous y reviendrons plus tard dans cette section !\nLes fonctions map_at() et map_if() sont aussi très utiles pour l’itération - elles vous permettent de spécifier quels éléments d’une liste vous devez itérer ! Elles fonctionnent en appliquant simplement un vecteur d’index/noms (dans le cas de map_at()) ou un test logique (dans le cas de map_if()).\nPrenons un exemple où nous ne voulons pas lire la première feuille de données de l’hôpital. Nous utilisons map_at() au lieu de map(), et spécifions l’argument .at = à c(-1) ce qui signifie ne pas utiliser le premier élément de .x. Alternativement, vous pouvez fournir un vecteur de nombres positifs, ou de noms, à .at = pour spécifier les éléments à utiliser.\n\nsheet-names &lt;- readxl::excel_sheets(\"hospital_linelinest.xlsx\")\n\ncombined &lt;- sheet_names %&gt;% \n     purrr::set_names() %&gt;% \n     # exclure la première feuille\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))\n\nNotez que le nom de la première feuille apparaîtra toujours comme un élément de la liste de sortie - mais ce n’est qu’un nom à un seul caractère (pas un cadre de données). Vous devrez supprimer cet élément avant de lier les lignes. Nous verrons comment supprimer et modifier des éléments de liste dans une section ultérieure.\n\n\n\nDiviser l’ensemble de données et exporter\nCi-dessous, nous donnons un exemple de la façon de diviser un jeu de données en plusieurs parties, puis d’utiliser l’itération map() pour exporter chaque partie comme une feuille Excel séparée, ou comme un fichier CSV séparé.\n\nDiviser l’ensemble de données\nDisons que nous avons le cas complet linelist en tant que cadre de données, et que nous voulons maintenant créer une linelist séparée pour chaque hôpital et l’exporter comme un fichier CSV séparé. Ci-dessous, nous effectuons les étapes suivantes :\nUtilisez group_split() (de dplyr) pour diviser le cadre de données linelist par des valeurs uniques dans la colonne hospital. La sortie est une liste contenant un cadre de données par sous-ensemble hospitalier.\n\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital)\n\nNous pouvons exécuter View(linelist_split) et voir que cette liste contient 6 cadres de données (“tibbles”), chacun représentant les cas d’un hôpital.\n\n\n\n\n\n\n\n\n\nCependant, notez que les cadres de données de la liste n’ont pas de nom par défaut ! Nous voulons que chacun d’eux ait un nom, et que ce nom soit utilisé lors de l’enregistrement du fichier CSV.\nUne approche pour extraire les noms est d’utiliser pull() (de dplyr) pour extraire la colonne hospital de chaque cadre de données dans la liste. Ensuite, pour être sûr, nous convertissons les valeurs en caractères et utilisons ensuite unique() pour obtenir le nom de ce cadre de données particulier. Toutes ces étapes sont appliquées à chaque cadre de données via map().\n\nnames(linelist_split) &lt;- linelist_split %&gt;% # Affectation aux noms des blocs de données listés \n     # Extrayez les noms en effectuant ce qui suit pour chaque cadre de données : \n     map(.f = ~pull(.x, hospital)) %&gt;% # Extraire la colonne hôpital\n     map(.f = ~as.character(.x)) %&gt;% # Convertir en caractères, juste au cas où\n     map(.f = ~unique(.x))                    # Prendre le nom unique de l'hôpital\n\nNous pouvons maintenant voir que chacun des éléments de la liste a un nom. On peut accéder à ces noms via `names(linelist_split)``.\n\n\n\n\n\n\n\n\n\n\nnames(linelist_split)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Missing\"                             \n[4] \"Other\"                               \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\n\nPlus d’une colonne group_split()\nSi vous souhaitez diviser la linelist par plusieurs colonnes de regroupement, par exemple pour produire un sous-ensemble linelist par intersection de l’hôpital ET du sexe, vous aurez besoin d’une approche différente pour nommer les éléments de la liste. Cela implique de collecter les “clés de groupe” uniques en utilisant group_keys() de dplyr - elles sont retournées comme un cadre de données. Vous pouvez ensuite combiner les clés de groupe en valeurs avec unite() comme indiqué ci-dessous, et attribuer ces noms de conglomérat à linelist_split.\n\n# divise la linelist par les combinaisons uniques hôpital-sexe\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital, gender)\n\n# extraire group_keys() sous forme de dataframe\ngroupings &lt;- linelist %&gt;% \n     group_by(hospital, gender) %&gt;%       \n     group_keys()\n\ngroupings # montre les groupements uniques \n\n# A tibble: 18 × 2\n   hospital                             gender\n   &lt;chr&gt;                                &lt;chr&gt; \n 1 Central Hospital                     f     \n 2 Central Hospital                     m     \n 3 Central Hospital                     &lt;NA&gt;  \n 4 Military Hospital                    f     \n 5 Military Hospital                    m     \n 6 Military Hospital                    &lt;NA&gt;  \n 7 Missing                              f     \n 8 Missing                              m     \n 9 Missing                              &lt;NA&gt;  \n10 Other                                f     \n11 Other                                m     \n12 Other                                &lt;NA&gt;  \n13 Port Hospital                        f     \n14 Port Hospital                        m     \n15 Port Hospital                        &lt;NA&gt;  \n16 St. Mark's Maternity Hospital (SMMH) f     \n17 St. Mark's Maternity Hospital (SMMH) m     \n18 St. Mark's Maternity Hospital (SMMH) &lt;NA&gt;  \n\n\nMaintenant nous combinons les groupements ensemble, séparés par des tirets, et nous les assignons comme noms des éléments de la liste dans linelist_split. Cela prend quelques lignes supplémentaires car nous remplaçons NA par “Missing”, nous utilisons unite() de dplyr pour combiner les valeurs des colonnes ensemble (séparées par des tirets), puis nous les convertissons en un vecteur sans nom pour qu’il puisse être utilisé comme noms de linelist_split.\n\n# Combinez en une seule valeur de nom \nnames(linelist_split) &lt;- groupings %&gt;% \n     mutate(across(everything(), replace_na, \"Missing\")) %&gt;% # Remplacer NA par \"Missing\" dans toutes les colonnes\n     unite(\"combined\", sep = \"-\") %&gt;% # Réunit toutes les valeurs des colonnes en une seule\n     setNames(NULL) %&gt;% # d'unification de toutes les valeurs de colonnes en une seule \n     as_vector() %&gt;% \n     as.list()\n\n\n\n\nExporter en tant que feuilles Excel\nPour exporter les listes de lignes de l’hôpital comme un classeur Excel avec une liste de lignes par feuille, nous pouvons simplement fournir la liste nommée linelist_split à la fonction write_xlsx() du paquet writexl. Cela permet d’enregistrer un classeur Excel avec plusieurs feuilles. Les noms des éléments de la liste sont automatiquement appliqués comme noms de feuilles.\n\nlinelist_split %&gt;% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))\n\nVous pouvez maintenant ouvrir le fichier Excel et voir que chaque hôpital a sa propre feuille.\n\n\n\n\n\n\n\n\n\n\n\nExportation en fichiers CSV\nC’est une commande un peu plus complexe, mais vous pouvez également exporter chaque liste de lignes spécifique à un hôpital sous forme de fichier CSV distinct, avec un nom de fichier spécifique à l’hôpital.\nEncore une fois, nous utilisons map() : nous prenons le vecteur des noms des éléments de la liste (montré ci-dessus) et utilisons map() pour les parcourir, en appliquant export() (du paquet rio, voir la page Importation et exportation) sur le cadre de données dans la liste linelist_split qui a ce nom. Nous utilisons également le nom pour créer un nom de fichier unique. Voici comment cela fonctionne :\n\nNous commençons avec le vecteur de noms de caractères, passé à map() sous la forme .x.\n\nLa fonction .f est export(), qui requiert un cadre de données et un chemin de fichier pour l’écriture.\n\nL’entrée .x (le nom de l’hôpital) est utilisée *dans .f pour extraire/indexer cet élément spécifique de la liste linelist_split. Il en résulte qu’un seul cadre de données à la fois est fourni à export().\n\nPar exemple, lorsque map() cherche “Military Hospital”, alors linelist_split[[.x]] est en fait linelist_split[[\"Military Hospital\"]], retournant ainsi le deuxième élément de linelist_split - qui est tous les cas de Military Hospital.\n\nLe chemin du fichier fourni à export() est dynamique grâce à l’utilisation de str_glue() (voir la page Caractères et chaînes de caractères) :\n\nhere() est utilisé pour obtenir la base du chemin du fichier et spécifier le dossier “data” (notez les guillemets simples pour ne pas interrompre les guillemets doubles de str_glue()).\n\n\nPuis une barre oblique /, et encore le .x qui imprime le nom de l’hôpital actuel pour rendre le fichier identifiable\n\nEnfin, l’extension “.csv” que export() utilise pour créer un fichier CSV.\n\n\nnames(linelist_split) %&gt;%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))\n\nMaintenant vous pouvez voir que chaque fichier est enregistré dans le dossier “data” du projet R “Epi_R_handbook” !\n\n\n\n\n\n\n\n\n\n\n\n\nFonctions personnalisées\nVous pouvez créer votre propre fonction à fournir à map().\nDisons que nous voulons créer des courbes épidémiques pour les cas de chaque hôpital. Pour faire cela en utilisant purrr, notre fonction .f peut être ggplot() et les extensions avec + comme d’habitude. Comme la sortie de map() est toujours une liste, les graphiques sont stockés dans une liste. Comme ce sont des tracés, ils peuvent être extraits et tracés avec la fonction ggarrange() du paquet ggpubr ( documentation).\n\n# charger le paquetage pour tracer les éléments d'une liste\npacman::p_load(ggpubr)\n\n# cartographier le vecteur des 6 \"noms\" d'hôpitaux (créé précédemment)\n# utiliser la fonction ggplot spécifiée\n# la sortie est une liste avec 6 ggplots\n\nhospital_names &lt;- unique(linelist$hospital)\n\nmy_plots &lt;- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %&gt;% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# imprimer les ggplots (ils sont stockés dans une liste)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\nSi ce code map() vous semble trop compliqué, vous pouvez obtenir le même résultat en enregistrant votre commande ggplot() spécifique comme une fonction personnalisée définie par l’utilisateur, par exemple nous pouvons la nommer make_epicurve()). Cette fonction est ensuite utilisée dans la fonction map(). .x sera itérativement remplacé par le nom de l’hôpital, et utilisé comme hosp_name dans la fonction make_epicurve(). Voir la page sur les Fonctions d’écriture.\n\n# Créer une fonction\nmake_epicurve &lt;- function(hosp_name){\n  \n  ggplot(data = linelist %&gt;% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n\n\n# cartographie\nmy_plots &lt;- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# imprimer les ggplots (ils sont stockés dans une liste)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\nMappage d’une fonction sur plusieurs colonnes\nUn autre cas d’utilisation courant est de mapper une fonction sur plusieurs colonnes. Ci-dessous, nous mappons() la fonction t.test() sur les colonnes numériques du cadre de données linelist, en comparant les valeurs numériques par sexe.\nRappelez-vous de la page sur les Tests statistiques simples que t.test() peut prendre des entrées dans un format de formule, comme t.test(colonne numérique ~ colonne binaire). Dans cet exemple, nous faisons ce qui suit :\n\nLes colonnes numériques intéressantes sont sélectionnées dans linelist - elles deviennent les entrées .x de map().\n\nLa fonction t.test() est fournie comme fonction .f, qui est appliquée à chaque colonne numérique.\n\nDans les parenthèses de t.test():\n\nle premier ~ précède la fonction .f que map() va itérer sur .x\n\nLe .x représente la colonne courante fournie à la fonction t.test().\n\nLe deuxième ~ fait partie de l’équation du test t décrit ci-dessus.\n\nLa fonction t.test() attend une colonne binaire du côté droit de l’équation. Nous fournissons le vecteur linelist$gender indépendamment et statiquement (notez qu’il n’est pas inclus dans select()).\n\n\nmap() retourne une liste, donc la sortie est une liste de résultats de tests t - un élément de liste pour chaque colonne numérique analysée.\n\n# Les résultats sont enregistrés sous forme de liste\nt.test_results &lt;- linelist %&gt;% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %&gt;% # Ne garder que certaines colonnes numériques pour les mapper entre elles\n  map(.f = ~t.test(.x ~ linelist$gender))        # fonction t.test, avec équation NUMERIC ~ CATEGORICAL\n\nVoici à quoi ressemble la liste t.test_results lorsqu’elle est ouverte (visualisée) dans RStudio. Nous avons mis en évidence les parties qui sont importantes pour les exemples de cette page.\n\nVous pouvez voir en haut que la liste entière est nommée t.test_results et a cinq éléments. Ces cinq éléments sont nommés age, wt_km, ht_cm, ct_blood, temp après chaque variable qui a été utilisée dans un test t avec gender de la linelist.\n\nChacun de ces cinq éléments sont eux-mêmes des listes, avec des éléments à l’intérieur comme p.value et conf.int. Certains de ces éléments, comme p.value, sont des nombres simples, tandis que d’autres, comme estimate, sont composés de deux éléments ou plus (mean in group f et mean in group m).\n\n\n\n\n\n\n\n\n\n\nRemarque : N’oubliez pas que si vous voulez appliquer une fonction à certaines colonnes seulement d’un cadre de données, vous pouvez aussi utiliser simplement mutate() et across(), comme expliqué dans la page Nettoyage des données et fonctions de base. Vous trouverez ci-dessous un exemple d’application de as.character() aux seules colonnes “age”. Notez l’emplacement des parenthèses et des virgules.\n\n# convertit les colonnes dont le nom contient \"age\" en classe Character\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  \n\n\n\nExtraire des listes\nComme map() produit une sortie de la classe List, nous allons passer un peu de temps à discuter de la façon d’extraire des données de listes en utilisant les fonctions purrr qui les accompagnent. Pour le démontrer, nous allons utiliser la liste t.test_results de la section précédente. C’est une liste de 5 listes - chacune des 5 listes contient les résultats d’un test t entre une colonne du cadre de données linelist et sa colonne binaire gender. Voir l’image dans la section ci-dessus pour un visuel de la structure de la liste.\n\nNoms des éléments\nPour extraire les noms des éléments eux-mêmes, utilisez simplement names() de base R. Dans ce cas, nous utilisons names() sur t.test_results pour retourner les noms de chaque sous-liste, qui sont les noms des 5 variables qui ont eu des tests t effectués.\n\nnames(t.test_results)\n\n[1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\"    \n\n\n\n\nÉléments par nom ou par position\nPour extraire les éléments d’une liste par nom ou par position, vous pouvez utiliser des crochets “[[ ]]” comme décrit dans la page bases de R. Ci-dessous, nous utilisons des doubles crochets pour indexer la liste t.tests_results et afficher le premier élément qui est le résultat du test t sur age.\n\nt.test_results[[1]] # premier élément par position\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\nt.test_results[[1]][ \"p.value\"] # retourne l'élément nommé \"p.value\" à partir du premier élément  \n\n$p.value\n[1] 2.350374e-96\n\n\nCependant, nous allons démontrer ci-dessous l’utilisation des fonctions purrr simples et flexibles map() et pluck() pour obtenir les mêmes résultats.\n\n\npluck()\npluck() extrait les éléments par nom ou par position. Par exemple - pour extraire les résultats du test t pour l’âge, vous pouvez utiliser pluck() comme ceci :\n\nt.test_results %&gt;% \n  pluck(\"age\") # Ou bien, utilisez pluck(1)\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\n\nIndexez des niveaux plus profonds en spécifiant les autres niveaux avec des virgules. L’exemple ci-dessous extrait l’élément nommé “p.value” de la liste age dans la liste t.test_results. Vous pouvez également utiliser des nombres à la place des noms de caractères.\n\nt.test_results %&gt;% \n  pluck(\"age\", \"p.value\")\n\n[1] 2.350374e-96\n\n\nVous pouvez extraire ces éléments internes de tous les éléments de premier niveau en utilisant map() pour exécuter la fonction pluck() sur chaque élément de premier niveau. Par exemple, le code ci-dessous extrait les éléments “p.value” de toutes les listes de t.test_results. La liste des résultats du test t est le .x itéré, pluck() est la fonction .f itérée, et la valeur “p-value” est fournie à la fonction.\n\nt.test_results %&gt;%\n  map(pluck, \"p.value\") # renvoie chaque valeur p\n\n$age\n[1] 2.350374e-96\n\n$wt_kg\n[1] 2.664367e-182\n\n$ht_cm\n[1] 3.515713e-144\n\n$ct_blood\n[1] 0.4473498\n\n$temp\n[1] 0.5735923\n\n\nComme autre alternative, map() offre un raccourci qui vous permet d’écrire le nom de l’élément entre guillemets, et il le récupérera. Si vous utilisez map(), la sortie sera une liste, alors que si vous utilisez map_chr(), ce sera un tableau de caractères nommé et si vous utilisez map_dbl(), ce sera un tableau numérique nommé.\n\nt.test_results %&gt;% \n  map_dbl(\"p.value\") # renvoie les valeurs p sous la forme d'un tableau numérique nommé\n\n          age         wt_kg         ht_cm      ct_blood          temp \n 2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01 \n\n\nVous pouvez en savoir plus sur pluck() dans sa purrr documentation. Elle a une fonction sour chuck() qui retournera une erreur au lieu de NULL si un élément n’existe pas.\n\n\n\nConvertir une liste en cadre de données\nCeci est un sujet complexe - voir la section Ressources pour des tutoriels plus complets. Néanmoins, nous allons démontrer la conversion de la liste des résultats du test t en un cadre de données. Nous allons créer un cadre de données avec des colonnes pour la variable, sa valeur p, et les moyennes des deux groupes (hommes et femmes).\nVoici quelques-unes des nouvelles approches et fonctions qui seront utilisées :\n\nLa fonction tibble() sera utilisée pour créer un tibble (comme un cadre de données).\n\nNous entourons la fonction tibble() de crochets { } pour éviter que la totalité de t.test_results soit stockée dans la première colonne du tibble.\n\n\nDans tibble(), chaque colonne est créée explicitement, de façon similaire à la syntaxe de mutate() :\n\nLe . représente t.test_results\nPour créer une colonne avec les noms des variables t-test (les noms de chaque élément de la liste), nous utilisons names() comme décrit ci-dessus.\n\nPour créer une colonne avec les valeurs p, nous utilisons map_dbl() comme décrit ci-dessus pour extraire les éléments p.value et les convertir en un tableau numérique.\n\n\n\nt.test_results %&gt;% {\n  tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"))\n  }\n\n# A tibble: 5 × 2\n  variables         p\n  &lt;chr&gt;         &lt;dbl&gt;\n1 age       2.35e- 96\n2 wt_kg     2.66e-182\n3 ht_cm     3.52e-144\n4 ct_blood  4.47e-  1\n5 temp      5.74e-  1\n\n\nMais maintenant, ajoutons des colonnes contenant les moyennes pour chaque groupe (hommes et femmes).\nNous devrions extraire l’élément estimate, mais celui-ci contient en fait deux éléments (mean in group f et mean in group m). On ne peut donc pas le simplifier en vecteur avec map_chr() ou map_dbl(). A la place, nous utilisons map(), qui utilisé dans tibble() créera une colonne de liste de classe dans le tibble ! Oui, c’est possible !\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimation\"))}\n\n# A tibble: 5 × 3\n  variables         p means       \n  &lt;chr&gt;         &lt;dbl&gt; &lt;named list&gt;\n1 age       2.35e- 96 &lt;NULL&gt;      \n2 wt_kg     2.66e-182 &lt;NULL&gt;      \n3 ht_cm     3.52e-144 &lt;NULL&gt;      \n4 ct_blood  4.47e-  1 &lt;NULL&gt;      \n5 temp      5.74e-  1 &lt;NULL&gt;      \n\n\nUne fois que vous avez cette colonne de liste, il existe plusieurs fonctions tidyr (faisant partie de tidyverse) qui vous aident à “rectangler” ou à “désimbriquer” ces colonnes de “liste imbriquée”. Vous pouvez en savoir plus à leur sujet ici, ou en exécutant vignette(\"rectangle\"). En bref:\n\nunnest_wider() - donne à chaque élément d’une colonne de liste sa propre colonne.\n\nunnest_longer() - donne à chaque élément d’une liste-colonne sa propre ligne\nhoist() - agit comme unnest_wider() mais vous spécifiez les éléments à dépiler.\n\nCi-dessous, nous passons le tibble à unnest_wider() en spécifiant la colonne means du tibble (qui est une liste imbriquée). Le résultat est que means est remplacé par deux nouvelles colonnes, chacune reflétant les deux éléments qui étaient précédemment dans chaque cellule means.\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %&gt;% \n  unnest_wider(means)\n\n# A tibble: 5 × 4\n  variables         p `mean in group f` `mean in group m`\n  &lt;chr&gt;         &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 age       2.35e- 96              12.7              19.6\n2 wt_kg     2.66e-182              45.8              59.6\n3 ht_cm     3.52e-144             109.              142. \n4 ct_blood  4.47e-  1              21.2              21.2\n5 temp      5.74e-  1              38.6              38.6\n\n\n\n\nJeter, conserver et compacter les listes\nParce que le travail avec purrr implique si souvent des listes, nous allons explorer brièvement certaines fonctions purrr pour modifier les listes. Voir la section Ressources pour des tutoriels plus complets sur les fonctions purrr.\n\nlist_modify() a de nombreuses utilisations, dont l’une peut être de supprimer un élément de liste\n\nkeep() conserve les éléments spécifiés dans .p =, ou lorsqu’une fonction fournie dans .p = évalue VRAI.\n\ndiscard() supprime les éléments spécifiés dans .p, ou lorsqu’une fonction fournie à .p = vaut VRAI.\n\ncompact() supprime tous les éléments vides.\n\nVoici quelques exemples utilisant la liste combined créée dans la section ci-dessus sur l’utilisation de map() pour importer et combiner plusieurs fichiers (elle contient 6 cadres de données de listes de cas) :\nLes éléments peuvent être supprimés par leur nom avec list_modify() et en mettant le nom égal à NULL.\n\ncombined %&gt;% \n  list_modify(\"Central Hospital\" = NULL) # Suppression d'un élément de liste par son nom\n\nVous pouvez également supprimer des éléments par critère, en fournissant une équation “prédicat” à .p = (une équation qui évalue à VRAI ou FAUX). Placez un tilde ~ devant la fonction et utilisez .x pour représenter l’élément de la liste. En utilisant keep(), les éléments de la liste qui valent VRAI seront conservés. Inversement, si vous utilisez discard(), les éléments de la liste qui valent VRAI seront supprimés.\n\n# ne conserve que les éléments de liste de plus de 500 lignes\ncombined %&gt;% \n  keep(.p = ~nrow(.x) &gt; 500)  \n\nDans l’exemple ci-dessous, les éléments de liste sont éliminés si leur classe n’est pas un cadre de données.\n\n# Suppression des éléments de liste qui ne sont pas des cadres de données\ncombinws %&gt;% \n  discard(.p = ~class(.x) != \"data.frame\")\n\nVotre fonction prédicat peut également faire référence à des éléments/colonnes dans chaque élément de la liste. Par exemple, ci-dessous, les éléments de liste dont la moyenne de la colonne ct_blood est supérieure à 25 sont éliminés.\n\n# ne conserve que les éléments de liste dont la moyenne de la colonne ct_blood est supérieure à 25\ncombined %&gt;% \n  discard(.p = ~mean(.x$ct_blood) &gt; 25)  \n\nCette commande supprimerait tous les éléments de liste vides :\n\n# Supprime tous les éléments de liste vides\ncombined %&gt;% \n  compact()\n\n\n\npmap()\nCETTE SECTION EST EN CONSTRUCTION",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Itération, boucles et listes</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.fr.html#fonctions-dapplication",
    "href": "new_pages/iteration.fr.html#fonctions-dapplication",
    "title": "16  Itération, boucles et listes",
    "section": "16.4 Fonctions d’application",
    "text": "16.4 Fonctions d’application\nLa famille de fonctions “apply” est une alternative base R à purrr pour les opérations itératives. Vous pouvez en savoir plus à leur sujet ici.",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Itération, boucles et listes</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.fr.html#resources",
    "href": "new_pages/iteration.fr.html#resources",
    "title": "16  Itération, boucles et listes",
    "section": "16.5 Resources",
    "text": "16.5 Resources\nfor loops with Data Carpentry\nThe R for Data Science page on iteration\nVignette on write/read Excel files\nA purrr tutorial by jennybc\nAnother purrr tutorial by Rebecca Barter\nA purrr tutorial on map, pmap, and imap\npurrr cheatsheet\npurrr tips and tricks\nkeep and discard",
    "crumbs": [
      "Gestion des données",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Itération, boucles et listes</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html",
    "href": "new_pages/tables_descriptive.fr.html",
    "title": "17  Tableaux descriptifs",
    "section": "",
    "text": "17.1 Préparation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#préparation",
    "href": "new_pages/tables_descriptive.fr.html#préparation",
    "title": "17  Tableaux descriptifs",
    "section": "",
    "text": "Chargement des packages\nCe bloc de code montre le chargement des packages nécessaires pour les analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour utilisation. Vous pouvez également charger les packages installés avec library() de extension/package R base. Voir la page sur Bases de R pour plus d’informations sur les packages R.\n\npacman::p_load(\n  rio,          # importation de fichier\n  here,         # répertoire de fichiers\n  skimr,        # obtenir un aperçu des données\n  tidyverse,    # gestion de données + ggplot2 graphiques \n  gtsummary,    # sommaire des statistiques et tests\n  rstatix,      # sommaire des statistiques et tests statistiques\n  janitor,      # ajouter des totaux et des pourcentages à des tableaux\n  scales,       # convertir facilement les proportions en pourcentages  \n  flextable     # convertir les tableaux en belles images\n  )\n\n\n\nImporter les données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre,cliquez pour télécharger la linelist ” nettoyé “.(as .rds file). Importez vos données avec la fonction import() du package rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation pour plus de détails.\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nThe first 50 rows of the linelist are displayed below.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#explorer-les-données",
    "href": "new_pages/tables_descriptive.fr.html#explorer-les-données",
    "title": "17  Tableaux descriptifs",
    "section": "17.2 Explorer les données",
    "text": "17.2 Explorer les données\n\nskimr package\nEn utilisant le package skimr, vous pouvez obtenir un aperçu détaillé et esthétique de chacune des variables de votre ensemble de données. Pour en savoir plus sur skimr, consultez sa page github.\nCi-dessous, la fonction skim() est appliquée à l’ensemble du tableau de données linelist. Un aperçu du tableau de données et un résumé de chaque colonne (par classe) est produit.\n\n## obtenir des informations sur chaque variable d'un jeu de données\nskim(linelist)\n\n\n\n\nData summary\n\n\nName\nlinelist\n\n\nNumber of rows\n5888\n\n\nNumber of columns\n30\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n4\n\n\nfactor\n2\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n0\n1.00\n6\n6\n0\n5888\n0\n\n\noutcome\n1323\n0.78\n5\n7\n0\n2\n0\n\n\ngender\n278\n0.95\n1\n1\n0\n2\n0\n\n\nage_unit\n0\n1.00\n5\n6\n0\n2\n0\n\n\nhospital\n0\n1.00\n5\n36\n0\n6\n0\n\n\ninfector\n2088\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2088\n0.65\n5\n7\n0\n2\n0\n\n\nfever\n249\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n249\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n249\n0.96\n2\n3\n0\n2\n0\n\n\naches\n249\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n249\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n765\n0.87\n5\n5\n0\n1072\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_infection\n2087\n0.65\n2014-03-19\n2015-04-27\n2014-10-11\n359\n\n\ndate_onset\n256\n0.96\n2014-04-07\n2015-04-30\n2014-10-23\n367\n\n\ndate_hospitalisation\n0\n1.00\n2014-04-17\n2015-04-30\n2014-10-23\n363\n\n\ndate_outcome\n936\n0.84\n2014-04-19\n2015-06-04\n2014-11-01\n371\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nage_cat\n86\n0.99\nFALSE\n8\n0-4: 1095, 5-9: 1095, 20-: 1073, 10-: 941\n\n\nage_cat5\n86\n0.99\nFALSE\n17\n0-4: 1095, 5-9: 1095, 10-: 941, 15-: 743\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n0\n1.00\n16.56\n5.79\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nage\n86\n0.99\n16.07\n12.62\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nage_years\n86\n0.99\n16.02\n12.64\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nlon\n0\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n0\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nwt_kg\n0\n1.00\n52.64\n18.58\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n0\n1.00\n124.96\n49.52\n4.00\n91.00\n129.00\n159.00\n295.00\n\n\nct_blood\n0\n1.00\n21.21\n1.69\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n149\n0.97\n38.56\n0.98\n35.20\n38.20\n38.80\n39.20\n40.80\n\n\nbmi\n0\n1.00\n46.89\n55.39\n-1200.00\n24.56\n32.12\n50.01\n1250.00\n\n\ndays_onset_hosp\n256\n0.96\n2.06\n2.26\n0.00\n1.00\n1.00\n3.00\n22.00\n\n\n\n\n\nVous pouvez également utiliser la fonction summary()de extension/package R base, pour obtenir des informations sur un jeu de données entier, mais cette sortie peut être plus difficile à lire qu’en utilisant skimr. C’est pourquoi la sortie n’est pas montrée ci-dessous, afin de conserver de l’espace sur la page.\n\n## obtenir des informations sur chaque colonne d'un jeu de données\nsummary(linelist)\n\n\n\nStatistiques sommaires\nVous pouvez utiliser les fonctions extension/package R base pour renvoyer des synthèses statistiques sur une colonne numérique. Vous pouvez retourner la plupart des synthèses statistiques utiles pour une colonne numérique en utilisant summary(), comme ci-dessous. Notez que le nom du tableau de données doit également être spécifié comme indiqué ci-dessous.\n\nsummary(linelist$age_years)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.02   23.00   84.00      86 \n\n\nVous pouvez accéder à une partie spécifique et l’enregistrer avec les crochets d’indexation [ ] :\n\nsummary(linelist$age_years)[[2]]            # retourne uniquement le 2ème élément\n\n[1] 6\n\n# équivalent, alternative au précédent par nom d'élément\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \n\nVous pouvez renvoyer des statistiques individuelles avec des fonctions extension/package R base comme max(), min(), median(), mean(), quantile(), sd(), et range(). Consultez la page Bases de R pour obtenir une liste complète.\nCAUTION: Si vos données contiennent des valeurs manquantes, R veut que vous le sachiez et retournera donc NA, sauf si vous spécifiez aux fonctions mathématiques ci-dessus que vous voulez que R ignore les valeurs manquantes, via l’argument na.rm = TRUE.\nVous pouvez utiliser la fonction get_summary_stats() de rstatix pour retourner des synthèses statistiques dans un format de tableau de données. Cela peut être utile pour effectuer des opérations ultérieures ou des tracés sur les chiffres. Consultez la page Tests statistiques simples pour plus de détails sur le package rstatix et ses fonctions.\n\nlinelist %&gt;% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # colonnes à calculer pour\n    type = \"common\")                    # sommaire des statistiques à retourner\n\n# A tibble: 5 × 10\n  variable     n   min   max median   iqr  mean     sd    se    ci\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#tbl_janitor",
    "href": "new_pages/tables_descriptive.fr.html#tbl_janitor",
    "title": "17  Tableaux descriptifs",
    "section": "17.3 janitor package",
    "text": "17.3 janitor package\nLes packages janitor offrent la fonction tabyl() pour produire des tableaux et des tableaux croisés, qui peuvent être ” améliorés ” ou modifiés avec des fonctions d’aide pour afficher des pourcentages, des proportions, des comptes, etc.\nCi-dessous, nous envoyons le tableau de données linelist aux fonctions janitor et nous affichons le résultat. Si vous le souhaitez, vous pouvez également enregistrer les tableaux résultants avec l’opérateur d’affectation &lt;-.\n\nSimple tabyl\nL’utilisation par défaut de tabyl() sur une colonne spécifique produit les valeurs uniques, les nombres, et les “pourcentages” par colonne ( proportion en fait). Les proportions peuvent avoir plusieurs chiffres. Vous pouvez ajuster le nombre de décimales avec adorn_rounding() comme décrit ci-dessous.\n\nlinelist %&gt;% tabyl(age_cat)\n\n age_cat    n     percent valid_percent\n     0-4 1095 0.185971467   0.188728025\n     5-9 1095 0.185971467   0.188728025\n   10-14  941 0.159816576   0.162185453\n   15-19  743 0.126188859   0.128059290\n   20-29 1073 0.182235054   0.184936229\n   30-49  754 0.128057065   0.129955188\n   50-69   95 0.016134511   0.016373664\n     70+    6 0.001019022   0.001034126\n    &lt;NA&gt;   86 0.014605978            NA\n\n\nComme vous pouvez le voir ci-dessus, s’il y a des valeurs manquantes, elles s’affichent dans une ligne étiquetée &lt;NA&gt;. Vous pouvez les supprimer avec show_na = FALSE. S’il n’y a pas de valeurs manquantes, cette ligne n’apparaîtra pas. S’il y a des valeurs manquantes, toutes les proportions sont données à la fois brutes (dénominateur incluant les comptes NA) et “valide” (dénominateur excluant les comptes NA).\nSi la colonne est un facteur de classe et que seuls certains niveaux sont présents dans vos données, tous les niveaux apparaîtront quand même dans le tableau. Vous pouvez supprimer cette fonctionnalité en spécifiant show_missing_levels = FALSE. Pour en savoir plus, consultez la page Facteurs.\n\n\nTableau croisé\nLes chiffres des tableaux croisés sont obtenus en ajoutant une ou plusieurs colonnes supplémentaires dans tabyl(). Notez que maintenant, seuls les chiffres sont retournés - les proportions et les pourcentages peuvent être ajoutés avec les étapes supplémentaires montrées ci-dessous.\n\nlinelist %&gt;% tabyl(age_cat, gender)\n\n age_cat   f   m NA_\n     0-4 640 416  39\n     5-9 641 412  42\n   10-14 518 383  40\n   15-19 359 364  20\n   20-29 468 575  30\n   30-49 179 557  18\n   50-69   2  91   2\n     70+   0   5   1\n    &lt;NA&gt;   0   0  86\n\n\n\n\n“Habillage” du tabyl\nUtilisez les fonctions “adorn” de janitor pour ajouter des totaux ou convertir en proportions, en pourcentages, ou ajuster l’affichage. Souvent, vous ferez passer le tabyle par plusieurs de ces fonctions.\n\n\n\n\n\n\n\nFonction\nRésultat\n\n\n\n\nadorn_totals()\nAjoute les totaux (où = ” ligne “,” colonne “, ou” les deux “). Définissez nom = pour”Total”.\n\n\nadorn_percentages()\nConvertir les nombres en proportions, avec denominateur = ” ligne “,” colonne “, ou” tout “.\n\n\nadorn_pct_formatting()\nConvertit les proportions en pourcentages. Spécifiez digits =. Supprimez le symbole “%” avec affix_sign = FALSE.\n\n\nadorn_rounding()\nPour arrondir les proportions à des positions digits =. Pour arrondir les pourcentages, utilisez adorn_pct_formatting() with digits =.\n\n\nadorn_ns()\nAjoutez des nombres à un tableau de proportions ou de pourcentages. Indiquez position = “arrière” pour montrer les nombres entre parenthèses, ou “avant” pour mettre les pourcentages entre parenthèses.\n\n\nadorn_title()\nAjouter une chaîne via les arguments row_name = et/ou col_name =.\n\n\n\nFaites attention à l’ordre dans lequel vous appliquez les fonctions ci-dessus. Voici quelques exemples.\nUn simple tableau à sens unique avec des pourcentages au lieu des proportions par défaut.\n\nlinelist %&gt;%               # cas linelist\n  tabyl(age_cat) %&gt;%       # calculer les effectifs et les proportions par catégorie d'âge\n  adorn_pct_formatting()   # convertir les proportions en pourcentages\n\n age_cat    n percent valid_percent\n     0-4 1095   18.6%         18.9%\n     5-9 1095   18.6%         18.9%\n   10-14  941   16.0%         16.2%\n   15-19  743   12.6%         12.8%\n   20-29 1073   18.2%         18.5%\n   30-49  754   12.8%         13.0%\n   50-69   95    1.6%          1.6%\n     70+    6    0.1%          0.1%\n    &lt;NA&gt;   86    1.5%             -\n\n\nUn tableau croisé avec une ligne totale et des pourcentages de ligne.\n\nlinelist %&gt;%                                  \n  tabyl(age_cat, gender) %&gt;%                  # comptage par âge et par sexe\n  adorn_totals(where = \"row\") %&gt;%             # ajouter une ligne totale\n  adorn_percentages(denominator = \"row\") %&gt;%  # convertir les comptages en proportions\n  adorn_pct_formatting(digits = 1)            # convertir les proportions en pourcentages\n\n age_cat     f     m    NA_\n     0-4 58.4% 38.0%   3.6%\n     5-9 58.5% 37.6%   3.8%\n   10-14 55.0% 40.7%   4.3%\n   15-19 48.3% 49.0%   2.7%\n   20-29 43.6% 53.6%   2.8%\n   30-49 23.7% 73.9%   2.4%\n   50-69  2.1% 95.8%   2.1%\n     70+  0.0% 83.3%  16.7%\n    &lt;NA&gt;  0.0%  0.0% 100.0%\n   Total 47.7% 47.6%   4.7%\n\n\nUn tableau croisé ajusté de façon à ce que les nombres et les pourcentages soient affichés.\n\nlinelist %&gt;%                                  # cas linelist\n  tabyl(age_cat, gender) %&gt;%                  # croiser les comptages\n  adorn_totals(where = \"row\") %&gt;%             # ajouter une ligne de total\n  adorn_percentages(denominator = \"col\") %&gt;%  # convertir en proportions\n  adorn_pct_formatting() %&gt;%                  # convertir en pourcentages\n  adorn_ns(position = \"front\") %&gt;%            # afficher comme: \"count (percent)\"\n  adorn_title(                                # ajuster les titres\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\n\n\nImpression du tableau\nPar défaut, le tableau s’affichera brute sur votre console R.\nVous pouvez également passer le tableau à flextable ou à un package similaire pour qu’il s’imprime comme une “jolie” image dans la visionneuse RStudio, qui peut être exportée en .png, .jpeg, .html, etc. Ce sujet est abordé à la page Tableaux pour la présentation. Notez que si vous imprimez de cette manière en utilisant adorn_titles(), vous devez spécifier placement = \"combined\".\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% # c'est nécessaire pour afficher comme image\n  flextable::flextable() %&gt;%    # convertir en une belle image\n  flextable::autofit()          # format à une ligne par rangée \n\nAge Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1,095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1,095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%)941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%)743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1,073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%)754 (12.8%)50-692  (0.1%)91  (3.2%)2  (0.7%)95  (1.6%)70+0  (0.0%)5  (0.2%)1  (0.4%)6  (0.1%)0  (0.0%)0  (0.0%)86 (30.9%)86  (1.5%)\n\n\n\n\nUtiliser sur d’autres tables\nVous pouvez utiliser les fonctions adorn_*() de janitor sur d’autres tables, comme celles crées par summarise() et count() de dplyr, ou table() de extension/package R base. Il suffit de passer la table à la fonction janitor désirée. Par exemple :\n\nlinelist %&gt;% \n  count(hospital) %&gt;%   # dplyr fonction\n  adorn_totals()        # janitor fonction\n\n                             hospital    n\n                     Central Hospital  454\n                    Military Hospital  896\n                              Missing 1469\n                                Other  885\n                        Port Hospital 1762\n St. Mark's Maternity Hospital (SMMH)  422\n                                Total 5888\n\n\n\n\nEnregistrer le tableau\nSi vous convertissez le tableau en une ” jolie ” image avec un package comme flextable, vous pouvez l’enregistrer avec les fonctions de ce package - comme save_as_html(), save_as_word(), save_as_ppt(), et save_as_image() de flextable (comme discuté plus en détail dans la page Tableaux de présentation). Ci-dessous, le tableau est enregistré sous forme de document Word, dans lequel il peut être modifié manuellement.\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% \n  flextable::flextable() %&gt;%                     # convertir en image\n  flextable::autofit() %&gt;%                       # assurer une seule ligne par rangée\n  flextable::save_as_docx(path = \"tabyl.docx\")   # enregistrer en tant que document Word dans le chemin de fichier\n\n\n\n\n\n\n\n\n\n\n\n\nStatistiques\nVous pouvez appliquer des tests statistiques sur les tableaux, comme chisq.test() ou fisher.test() du package stats, comme indiqué ci-dessous. Notez que les valeurs manquantes ne sont pas autorisées, elles sont donc exclues du tableau avec show_na = FALSE\n\nage_by_outcome &lt;- linelist %&gt;% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)\n\n\n    Pearson's Chi-squared test\n\ndata:  age_by_outcome\nX-squared = 6.4931, df = 7, p-value = 0.4835\n\n\nConsultez la page sur les Tests statistiques simples pour obtenir plus de code et de conseils sur les statistiques.\n\n\nAutres conseils\n\nIncluez l’argument na.rm = TRUE pour exclure les valeurs manquantes de tous les calculs ci-dessus.\nSi vous appliquez des fonctions d’aide adorn_*() à des tables qui n’ont pas été crées par tabyl(), vous pouvez spécifier une ou plusieurs colonnes particulières auxquelles les appliquer comme adorn_percentage(,,,c(cas,décès)) (spécifiez-les au 4ème argument non nommé). La syntaxe n’est pas simple. Pensez à utiliser summarise() à la place.\nVous pouvez obtenir plus de détails dans le janitor page et ce tabyl vignette.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#dplyr-package",
    "href": "new_pages/tables_descriptive.fr.html#dplyr-package",
    "title": "17  Tableaux descriptifs",
    "section": "17.4 dplyr package",
    "text": "17.4 dplyr package\ndplyr fait partie des packages tidyverse et est un outil de gestion de données très courant. Créer des tableaux avec les fonctions dplyr summarise() et count() est une méthode très utile pour calculer des statistiques sommaires, résumer par groupe, ou passer des tableaux à ggplot().\nsummarise() crée un nouveau tableau de données récapitulatif. Si les données sont non groupées, il renvoie un tableau de données à une ligne avec les statistiques récapitulatives spécifiées pour l’ensemble du tableau de données. Si les données sont groupées, le nouveau tableau de données aura une ligne par groupe (voir la page Regroupement de données).\nEntre les parenthèses de summarise(), vous indiquez le nom de chaque nouvelle colonne du résumé, suivi d’un signe égal et d’une fonction statistique à appliquer.\nTIP: La fonction summarise fonctionne avec les orthographes britannique et américaine (summarise() et summarize()).\n\nObtenir des nombres\nLa fonction la plus simple à appliquer dans summarise() est n(). Laissez les parenthèses vides pour compter le nombre de lignes.\n\nlinelist %&gt;%                 # commencer par une liste de lignes\n  summarise(n_rows = n())    # retourne un nouveau tableau de données avec la colonne n_rows\n\n  n_rows\n1   5888\n\n\nCela devient plus intéressant si nous avons regroupé les données au préalable.\n\nlinelist %&gt;% \n  group_by(age_cat) %&gt;%     # regrouper les données par valeurs uniques dans une colonne age_cat\n  summarise(n_rows = n())   # retourne le nombre de lignes *per group*\n\n# A tibble: 9 × 2\n  age_cat n_rows\n  &lt;fct&gt;    &lt;int&gt;\n1 0-4       1095\n2 5-9       1095\n3 10-14      941\n4 15-19      743\n5 20-29     1073\n6 30-49      754\n7 50-69       95\n8 70+          6\n9 &lt;NA&gt;        86\n\n\nLa commande ci-dessus peut être réduite en utilisant la fonction count() à la place. La fonction count() effectue les opérations suivantes :\n\nRegroupe les données selon les colonnes qui lui sont fournies.\nLes résume avec n() (en créant la colonne n).\nDé-grouper les données\n\n\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\nVous pouvez changer le nom de la colonne des comptages de la valeur par défaut n à quelque chose d’autre en le spécifiant à name =.\nLes résultats de la mise en tableau de deux colonnes de regroupement ou plus sont toujours renvoyés au format “long”, avec les effectifs dans la colonne n. Consultez la page Pivoter les données pour en savoir plus sur les formats de données “long” et “large”.\n\nlinelist %&gt;% \n  count(age_cat, outcome)\n\n   age_cat outcome   n\n1      0-4   Death 471\n2      0-4 Recover 364\n3      0-4    &lt;NA&gt; 260\n4      5-9   Death 476\n5      5-9 Recover 391\n6      5-9    &lt;NA&gt; 228\n7    10-14   Death 438\n8    10-14 Recover 303\n9    10-14    &lt;NA&gt; 200\n10   15-19   Death 323\n11   15-19 Recover 251\n12   15-19    &lt;NA&gt; 169\n13   20-29   Death 477\n14   20-29 Recover 367\n15   20-29    &lt;NA&gt; 229\n16   30-49   Death 329\n17   30-49 Recover 238\n18   30-49    &lt;NA&gt; 187\n19   50-69   Death  33\n20   50-69 Recover  38\n21   50-69    &lt;NA&gt;  24\n22     70+   Death   3\n23     70+ Recover   3\n24    &lt;NA&gt;   Death  32\n25    &lt;NA&gt; Recover  28\n26    &lt;NA&gt;    &lt;NA&gt;  26\n\n\n\n\nVoir tous les niveaux\nSi vous mettez en tableau une colonne de classe facteur, vous pouvez vous assurer que tous les niveaux sont affichés (et pas seulement les niveaux avec des valeurs dans les données) en ajoutant .drop = FALSE dans la commande summarise() ou count().\nCette technique est utile pour standardiser vos tableaux/graphiques. Par exemple, si vous créez des chiffres pour plusieurs sous-groupes, ou si vous créez plusieurs fois le même chiffre pour des rapports de routine. Dans chacune de ces circonstances, la présence de valeurs dans les données peut fluctuer, mais vous pouvez définir des niveaux qui restent constants.\nConsultez la page sur les Facteurs pour plus d’informations.\n\n\nProportions\nLes proportions peuvent être ajoutées en passant le tableau à mutate() pour créer une nouvelle colonne. Définissez la nouvelle colonne comme la colonne des comptages (n par défaut) divisée par la sum() de la colonne des comptages (ceci retournera une proportion).\nNotez que dans ce cas, sum() dans la commande mutate() retournera la somme de la colonne entière n pour l’utiliser comme dénominateur de la proportion. Comme expliqué dans la page Regroupement des données, si sum() est utilisé dans des données groupées (par exemple, si la commande mutate() suit immédiatement une commande group_by()), il retournera les sommes par groupe. Comme indiqué juste au-dessus, count() termine ses actions en dégroupant. Ainsi, dans ce scénario, nous obtenons les proportions de la colonne entière.\nPour afficher facilement les pourcentages, vous pouvez inclure la proportion dans la fonction percent() du package scales (notez cette conversion en caractère de classe).\n\nage_summary &lt;- linelist %&gt;% \n  count(age_cat) %&gt;%                     # grouper et compter par sexe (produit la colonne \"n\")\n  mutate(                                # créer le pourcentage de la colonne - noter le dénominateur\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary\n\n  age_cat    n percent\n1     0-4 1095  18.60%\n2     5-9 1095  18.60%\n3   10-14  941  15.98%\n4   15-19  743  12.62%\n5   20-29 1073  18.22%\n6   30-49  754  12.81%\n7   50-69   95   1.61%\n8     70+    6   0.10%\n9    &lt;NA&gt;   86   1.46%\n\n\nVous trouverez ci-dessous une méthode permettant de calculer les proportions dans les groupes. Elle repose sur l’application et la suppression sélectives de différents niveaux de regroupement des données. Tout d’abord, les données sont regroupées en fonction du résultat via group_by(). Ensuite, la fonction count() est appliquée. Cette fonction regroupe à nouveau les données par age_cat et retourne les résultats pour chaque combinaison outcome-age-cat. Il est important de noter qu’en terminant son processus, count() a également dégroupé le regroupement par age_cat, de sorte que le seul regroupement de données restant est le regroupement original par outcome. Ainsi, l’étape finale du calcul des proportions (dénominateur sum(n)) est toujours groupée par outcome.\n\nage_by_outcome &lt;- linelist %&gt;%                  # commencer par la linelist\n  group_by(outcome) %&gt;%                         # groupe par résultats\n  count(age_cat) %&gt;%                            # regrouper et compter par age_cat, puis supprimer le regroupement age_cat\n  mutate(percent = scales::percent(n / sum(n))) # calculer le pourcentage - noter que le dénominateur est par groupe de résultats\n\n\n\n\n\n\n\n\n\nPlotting\nAfficher un tableau “long” comme celui ci-dessus avec ggplot() est relativement simple. Les données sont naturellement au format “long”, qui est naturellement accepté par ggplot(). Voir d’autres exemples dans les pages ggplot basics et Astuces de ggplot.\n\nlinelist %&gt;%                      # commencer par la linelist\n  count(age_cat, outcome) %&gt;%     # regrouper et présenter les comptages par deux colonnes\n  ggplot()+                       # passer le nouveau tableau de données à ggplot\n    geom_col(                     # créer un bar plot\n      mapping = aes(   \n        x = outcome,              # mappez le résultat sur l'axe des x\n        fill = age_cat,           # mappe age_cat au remplissage\n        y = n))                  # associer la colonne de comptage `n` à la hauteur\n\n\n\n\n\n\n\n\n\n\nSynthèse des statistiques\nUn avantage majeur de dplyr et de summarise() est la possibilité de retourner des résumés statistiques plus avancés comme median(), mean(), max(), min(), sd() (écart-type), et les percentiles. Vous pouvez également utiliser sum() pour retourner le nombre de lignes qui répondent à certains critères logiques. Comme ci-dessus, ces sorties peuvent être produites pour l’ensemble du cadre de données, ou par groupe.\nLa syntaxe est la même - entre les parenthèses de summarise(), vous fournissez les noms de chaque nouvelle colonne de résumé, suivis d’un signe égal et d’une fonction statistique à appliquer. Dans la fonction statistique, donnez la ou les colonnes sur lesquelles vous voulez travailler et tous les arguments pertinents (par exemple na.rm = TRUE pour la plupart des fonctions mathématiques).\nVous pouvez également utiliser sum() pour retourner le nombre de lignes qui répondent à un critère logique. L’expression qu’il contient est comptée si elle vaut TRUE. Par exemple :\n\nsum(age_years &lt; 18, na.rm=T)\nsum(gender == \"male\", na.rm=T)\nsum(response %in% c(\"Likely\", \"Very Likely\"))\n\nCi-dessous, les données linelist sont résumées pour décrire le délai en jours entre l’apparition des symptômes et l’admission à l’hôpital (colonne days_onset_hosp), par hôpital.\n\nsummary_table &lt;- linelist %&gt;%                                        # commencez avec la linelist, enregistrez comme un nouvel objet\n  group_by(hospital) %&gt;%                                             # regrouper tous les calculs par hopital\n  summarise(                                                         # seules les colonnes de résumé ci-dessous seront retournées\n    cases       = n(),                                                # nombre de lignes par groupe\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # délai max\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # délai moyen, arrondi\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # Déviation standard des délais, arrondie\n    delay_3     = sum(days_onset_hosp &gt;= 3, na.rm = T),               # nombre de lignes avec un délai de 3 jours ou plus\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convertir en pourcentage une colonne de délai précédemment définie\n  )\n\nsummary_table  # Afficher\n\n# A tibble: 6 × 7\n  hospital               cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n  &lt;chr&gt;                  &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;      \n1 Central Hospital         454        12        1.9      1.9     108 24%        \n2 Military Hospital        896        15        2.1      2.4     253 28%        \n3 Missing                 1469        22        2.1      2.3     399 27%        \n4 Other                    885        18        2        2.2     234 26%        \n5 Port Hospital           1762        16        2.1      2.2     470 27%        \n6 St. Mark's Maternity …   422        18        2.1      2.3     116 27%        \n\n\nQuelques conseils :\n\nUtilisez sum() avec une instruction logique pour “compter” les lignes qui répondent à certains critères (==).\nNotez l’utilisation de na.rm = TRUE dans les fonctions mathématiques comme sum(), sinon NA sera retourné s’il y a des valeurs manquantes.\nUtilisez la fonction percent() du package scales pour convertir facilement en pourcentages.\n\nDéfinissez accuracy = à 0,1 ou 0,01 pour garantir respectivement 1 ou 2 décimales.\n\nUtilisez la fonction round() de extension/package R base pour spécifier les décimales.\nPour calculer ces statistiques sur l’ensemble des données, utilisez summarise() sans group_by().\nVous pouvez créer des colonnes pour les besoins de calculs ultérieurs (par exemple, les dénominateurs) que vous supprimez éventuellement de votre cadre de données avec select().\n\n\n\nStatistiques conditionnelles\nVous pouvez souhaiter renvoyer des statistiques conditionnelles - par exemple, le maximum de lignes qui répondent à certains critères. Pour ce faire, il suffit de subdiviser la colonne avec des parenthèses [ ]. L’exemple ci-dessous renvoie la température maximale pour les patients classés comme ayant ou n’ayant pas de fièvre. Attention cependant - il peut être plus approprié d’ajouter une autre colonne à la commandegroup_by()etpivot_wider() (comme démontré ci-dessous).\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )\n\n# A tibble: 6 × 3\n  hospital                             max_temp_fvr max_temp_no\n  &lt;chr&gt;                                       &lt;dbl&gt;       &lt;dbl&gt;\n1 Central Hospital                             40.4        38  \n2 Military Hospital                            40.5        38  \n3 Missing                                      40.6        38  \n4 Other                                        40.8        37.9\n5 Port Hospital                                40.6        38  \n6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9\n\n\n\n\nColler ensemble\nLa fonction str_glue() de stringr est utile pour combiner les valeurs de plusieurs colonnes en une nouvelle colonne. Dans ce contexte, elle est généralement utilisée après la commande summarise().\nDans la page Caractères et chaînes de caractères, diverses options pour combiner des colonnes sont discutées, notamment unite(), et paste0(). Dans ce cas d’utilisation, nous préconisons str_glue() parce qu’il est plus flexible que unite() et a une syntaxe plus simple que paste0().\nCi-dessous, le tableau de données summary_table (créé plus haut) est modifié de telle sorte que les colonnes delay_mean et delay_sd sont combinées, la mise en forme entre parenthèses est ajoutée à la nouvelle colonne, et leurs anciennes colonnes respectives sont supprimées.\nEnsuite, pour rendre le tableau plus présentable, une ligne de total est ajoutée avec adorn_totals() de janitor (qui ignore les colonnes non-numériques). Enfin, nous utilisons select() de dplyr pour réordonner et renommer les colonnes avec des noms plus appropriés.\nMaintenant, vous pouvez passer à flextable et imprimer le tableau dans Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc. ! (voir la page Tableaux pour la présentation).\n\nsummary_table %&gt;% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %&gt;%  # fusionner et formater d'autres valeurs\n  select(-c(delay_mean, delay_sd)) %&gt;%                       # supprimer deux anciennes colonnes  \n  adorn_totals(where = \"row\") %&gt;%                            # ajouter la ligne totale\n  select(                                                    # ordonner et renommer les colonnes\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )\n\n                        Hospital Name Cases Max delay Mean (sd) Delay 3+ days\n                     Central Hospital   454        12 1.9 (1.9)           108\n                    Military Hospital   896        15 2.1 (2.4)           253\n                              Missing  1469        22 2.1 (2.3)           399\n                                Other   885        18   2 (2.2)           234\n                        Port Hospital  1762        16 2.1 (2.2)           470\n St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116\n                                Total  5888       101         -          1580\n % delay 3+ days\n             24%\n             28%\n             27%\n             26%\n             27%\n             27%\n               -\n\n\n\nPercentiles\nLes percentiles et les quantiles dans dplyr méritent une mention spéciale. Pour retourner les quantiles, utilisez quantile() avec les valeurs par défaut ou spécifiez la ou les valeurs que vous souhaitez avec probs =.\n\n# obtenir les valeurs percentile par défaut de l'âge (0%, 25%, 50%, 75%, 100%)\nlinelist %&gt;% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               0\n2               6\n3              13\n4              23\n5              84\n\n# obtenir des valeurs percentiles d'âge spécifiées manuellement (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               1\n2              13\n3              23\n4              48\n\n\nSi vous voulez retourner les quantiles par groupe, vous pouvez rencontrer des sorties longues et moins utiles si vous ajoutez simplement une autre colonne à group_by(). Donc, essayez plutôt cette approche - créez une colonne pour chaque niveau de quantile désiré.\n\n# obtenir des valeurs percentiles d'âge spécifiées manuellement (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )\n\n# A tibble: 6 × 5\n  hospital                               p05   p50   p75   p98\n  &lt;chr&gt;                                &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Central Hospital                         1    12    21  48  \n2 Military Hospital                        1    13    24  45  \n3 Missing                                  1    13    23  48.2\n4 Other                                    1    13    23  50  \n5 Port Hospital                            1    14    24  49  \n6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\n\n\nBien que dplyr summarise() offre certainement un contrôle plus précis, vous trouverez peut-être que toutes les synthèses statistiques dont vous avez besoin peuvent être produites avec get_summary_stat() du package rstatix. Si l’on opère sur des données groupées, if retournera 0%, 25%, 50%, 75%, et 100%. Si elle est appliquée à des données non groupées, vous pouvez spécifier les percentiles avec probs = c(.05, .5, .75, .98).\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 6 × 8\n  hospital                         variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;chr&gt;                            &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Central Hospital                 age        445     0     6    12    21     58\n2 Military Hospital                age        884     0     6    14    24     72\n3 Missing                          age       1441     0     6    13    23     76\n4 Other                            age        873     0     6    13    23     69\n5 Port Hospital                    age       1739     0     6    14    24     68\n6 St. Mark's Maternity Hospital (… age        420     0     7    12    22     84\n\n\n\nlinelist %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 1 × 7\n  variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 age       5802     0     6    13    23     84\n\n\n\n\n\nSynthèse des données agrégées\nSi vous commencez avec des données agrégées, l’utilisation de n() renvoie le nombre de lignes, et non la somme des comptes agrégés. Pour obtenir la somme, utilisez sum() sur la colonne des comptages des données.\nPar exemple, disons que vous commencez avec le tableau de données de comptage ci-dessous, appelé linelist_agg - il montre en format “long” le nombre de cas par résultat et par sexe.\nCi-dessous, nous créons cet exemple de tableau de données de comptage de linelist par résultat et par sexe (les valeurs manquantes sont supprimées pour plus de clarté).\n\nlinelist_agg &lt;- linelist %&gt;% \n  drop_na(gender, outcome) %&gt;% \n  count(outcome, gender)\n\nlinelist_agg\n\n  outcome gender    n\n1   Death      f 1227\n2   Death      m 1228\n3 Recover      f  953\n4 Recover      m  950\n\n\nPour additionner les valeurs (dans la colonne n) par groupe, vous pouvez utiliser summarise() mais définissez la nouvelle colonne égale à sum(n, na.rm=T). Pour ajouter un élément de condition à l’opération de somme, vous pouvez utiliser la syntaxe des sous-ensembles [ ] sur la colonne des comptages.\n\nlinelist_agg %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))\n\n# A tibble: 2 × 4\n  outcome total_cases male_cases female_cases\n  &lt;chr&gt;         &lt;int&gt;      &lt;int&gt;        &lt;int&gt;\n1 Death          2455       1228         1227\n2 Recover        1903        950          953\n\n\n\n\nacross() multiples colonnes\nVous pouvez utiliser summarise() sur plusieurs colonnes en utilisant across(). Cela vous facilite la tâche lorsque vous voulez calculer les mêmes statistiques pour plusieurs colonnes. Placez across() dans summarise() et spécifiez ce qui suit :\n\n.cols = comme un vecteur de noms de colonnes c() ou des fonctions d’aide “tidyselect” (expliquées ci-dessous)\n.fns = la fonction à exécuter (sans parenthèses) - vous pouvez en fournir plusieurs dans une list().\n\nCi-dessous, la fonction mean() est appliquée à plusieurs colonnes numériques. Un vecteur de colonnes est nommé explicitement dans .cols = et une seule fonction mean est spécifiée (sans parenthèses) dans .fns =. Tout argument supplémentaire pour la fonction (par exemple na.rm=TRUE) est fourni après .fns =, séparé par une virgule.\nIl peut être difficile de respecter l’ordre des parenthèses et des virgules lorsqu’on utilise across(). N’oubliez pas qu’à l’intérieur de across(), vous devez inclure les colonnes, les fonctions et tous les arguments supplémentaires nécessaires aux fonctions.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # colonnes\n                   .fns = mean,                               # fonction\n                   na.rm=T))                                  # arguments supplémentaires\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `outcome = \"Death\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 3 × 5\n  outcome age_years  temp wt_kg ht_cm\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Death        15.9  38.6  52.6  125.\n2 Recover      16.1  38.6  52.5  125.\n3 &lt;NA&gt;         16.2  38.6  53.0  125.\n\n\nPlusieurs fonctions peuvent être exécutées en même temps. Ci-dessous, les fonctions mean et sd sont fournies à .fns = dans une list(). Vous avez la possibilité de fournir des noms de caractères (par exemple “mean” et “sd”) qui sont ajoutés dans les nouveaux noms de colonnes.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # colonnes\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # fonctions multiples \n                   na.rm=T))                                 # arguments supplémentaires\n\n# A tibble: 3 × 9\n  outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 Death             15.9         12.3      38.6   0.962       52.6     18.4\n2 Recover           16.1         13.0      38.6   0.997       52.5     18.6\n3 &lt;NA&gt;              16.2         12.8      38.6   0.976       53.0     18.9\n# ℹ 2 more variables: ht_cm_mean &lt;dbl&gt;, ht_cm_sd &lt;dbl&gt;\n\n\nVoici les fonctions d’aide “tidyselect” que vous pouvez fournir à .cols = pour sélectionner des colonnes :\n\neverything() - toutes les autres colonnes non mentionnées\nlast_col() - la dernière colonne\nwhere() - applique une fonction à toutes les colonnes et sélectionne celles qui sont VRAIES\nstarts_with() - correspond à un préfixe spécifié. Exemple : starts_with(\"date\")\nends_with() - correspond à un suffixe spécifié. Exemple : `ends_with(“_end”)\ncontains() - colonnes contenant une chaîne de caractères. Exemple : contains(\"time\")\nmatches() - pour appliquer une expression régulière (regex). Exemple : contains(\"[pt]al\")\nnum_range() -\nany_of() - correspond si la colonne est nommée. Utile si le nom peut ne pas exister. Exemple : any_of(date_onset, date_death, cardiac_arrest)\n\nPar exemple, pour retourner la moyenne de chaque colonne numérique, utilisez where() et fournissez la fonction as.numeric() (sans parenthèses). Tout cela reste dans la commande across().\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(\n    .cols = where(is.numeric),  # toutes les colonnes numériques dans le tableau de données\n    .fns = mean,\n    na.rm=T))\n\n# A tibble: 3 × 12\n  outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6\n2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6\n3 &lt;NA&gt;          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6\n# ℹ 2 more variables: bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\nPivot élargi\nSi vous préférez votre tableau en format “large”, vous pouvez le transformer en utilisant la fonction tidyr pivot_wider(). Vous devrez probablement renommer les colonnes avec rename(). Pour plus d’informations, consultez la page sur le pivotement des données.\nL’exemple ci-dessous commence avec la table “longue” age_by_outcome de la section proportions. Nous le créons à nouveau et le présentons à l’impression, pour plus de clarté :\n\nage_by_outcome &lt;- linelist %&gt;%                  # commencez par la linelist\n  group_by(outcome) %&gt;%                         # groupe par outcome \n  count(age_cat) %&gt;%                            # regrouper et compter par age_cat, puis supprimer le regroupement age_cat\n  mutate(percent = scales::percent(n / sum(n))) # calculer le pourcentage - noter que le dénominateur est par groupe de outcome\n\n\n\n\n\n\n\nPour effectuer un pivot plus large, nous créons les nouvelles colonnes à partir des valeurs de la colonne existante age_cat (en définissant names_from = age_cat). Nous spécifions également que les nouvelles valeurs de la table proviendront de la colonne existante n, avec values_from = n. Les colonnes non mentionnées dans notre commande de pivotement (outcome) resteront inchangées à l’extrême gauche.\n\nage_by_outcome %&gt;% \n  select(-percent) %&gt;%   # maintenir seulement compte pour la simplicité\n  pivot_wider(names_from = age_cat, values_from = n)  \n\n# A tibble: 3 × 10\n# Groups:   outcome [3]\n  outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Death     471   476     438     323     477     329      33     3    32\n2 Recover   364   391     303     251     367     238      38     3    28\n3 &lt;NA&gt;      260   228     200     169     229     187      24    NA    26\n\n\n\n\nTotal de lignes\nLorsque summarise() opère sur des données groupées, il ne produit pas automatiquement des statistiques “totales”. Ci-dessous, deux approches pour ajouter une ligne de total sont présentées :\n\njanitor’s adorn_totals()\nSi votre table consiste uniquement en des nombres ou des proportions/pourcentages qui peuvent être additionnés en un total, alors vous pouvez ajouter des totaux sum en utilisant adorn_totals() de janitor comme décrit dans la section ci-dessus. Notez que cette fonction ne peut additionner que les colonnes numériques - si vous voulez calculer d’autres statistiques totales, voyez l’approche suivante avec dplyr.\nCi-dessous, linelist est groupé par sexe et résumé dans un tableau qui décrit le nombre de cas dont l’issue est connue, les décès et les guéris. En passant le tableau à adorn_totals(), on ajoute une ligne de total en bas reflétant la somme de chaque colonne. Les autres fonctions adorn_*() ajustent l’affichage comme indiqué dans le code.\n\nlinelist %&gt;% \n  group_by(gender) %&gt;%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Nombre de lignes dans le groupe où le outcome n'est pas manquant\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Nombre de lignes dans le groupe où outcome est égale a Death.\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Nombre de lignes dans le groupe où outcome est egale à Recovered.\n  ) %&gt;% \n  adorn_totals() %&gt;%                                # Adorn total ligne (somme de chaque colonne numérique)\n  adorn_percentages(\"col\") %&gt;%                      # Obtenir les proportions des colonnes\n  adorn_pct_formatting() %&gt;%                        # Convertir les proportions en pourcentages\n  adorn_ns(position = \"front\")                      # Afficher les % et les comptes (avec les comptes en avant)\n\n gender  known_outcome        n_death      n_recover\n      f 2,180  (47.8%) 1,227  (47.5%)   953  (48.1%)\n      m 2,178  (47.7%) 1,228  (47.6%)   950  (47.9%)\n   &lt;NA&gt;   207   (4.5%)   127   (4.9%)    80   (4.0%)\n  Total 4,565 (100.0%) 2,582 (100.0%) 1,983 (100.0%)\n\n\n\n\nsummarise() Sur “total” des données et ensuite bind_rows()\nSi votre tableau est composé de données de synthèse statistiques telles que median(), mean(), etc, l’approche adorn_totals() présentée ci-dessus ne sera pas suffisante. Pour obtenir des données de synthèse pour l’ensemble des données, vous devez les calculer avec une commande séparée summarise() et ensuite lier les résultats au tableau de synthèse original. Pour faire la liaison, vous pouvez utiliser bind_rows() de dplyr comme décrit dans la page Joining data. Vous trouverez ci-dessous un exemple :\nVous pouvez faire un tableau de synthèse des résultats par hôpital avec group_by() et summarise() comme ceci :\n\nby_hospital &lt;- linelist %&gt;% \n  filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%  # Supprimez les cas avec outcome ou  hôpital manquant\n  group_by(hospital, outcome) %&gt;%                      # Données du groupe\n  summarise(                                           # Créer de nouvelles colonnes de résumé des indicateurs intéressants\n    N = n(),                                            # Nombre de lignes par groupe d'hôpitaux et outcome     \n    ct_value = median(ct_blood, na.rm=T))               # Valeur médiane du CT par groupe\n  \nby_hospital # Afficher la table\n\n# A tibble: 10 × 4\n# Groups:   hospital [5]\n   hospital                             outcome     N ct_value\n   &lt;chr&gt;                                &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n 1 Central Hospital                     Death     193       22\n 2 Central Hospital                     Recover   165       22\n 3 Military Hospital                    Death     399       21\n 4 Military Hospital                    Recover   309       22\n 5 Other                                Death     395       22\n 6 Other                                Recover   290       21\n 7 Port Hospital                        Death     785       22\n 8 Port Hospital                        Recover   579       21\n 9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\n\n\nPour obtenir les totaux, exécutez la même commande summarise() mais regroupez les données uniquement par résultat (et non par hôpital), comme ceci :\n\ntotals &lt;- linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Regroupés uniquement par outcome, et non par hôpital    \n      summarise(\n        N = n(),                                       # Ces statistiques sont maintenant par outcome seulement     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table\n\n# A tibble: 2 × 3\n  outcome     N ct_value\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n1 Death    1971       22\n2 Recover  1469       22\n\n\nNous pouvons lier ces deux tableaux ensemble. Notez que by_hospital a 4 colonnes alors que totals a 3 colonnes. En utilisant bind_rows(), les colonnes sont combinées par nom, et tout espace supplémentaire est rempli avec NA (par exemple les valeurs de la colonne hospital pour les deux nouvelles lignes totals). Après avoir lié les lignes, nous convertissons ces espaces vides en “Total” en utilisant replace_na() (voir la page Nettoyage des données et des fonctions de base).\n\ntable_long &lt;- bind_rows(by_hospital, totals) %&gt;% \n  mutate(hospital = replace_na(hospital, \"Total\"))\n\nVoici le nouveau tableau avec les lignes “Total” en bas.\n\n\n\n\n\n\nCe tableau est dans un format “long”, ce qui peut correspondre à ce que vous souhaitez. En option, vous pouvez pivoter ce tableau plus large pour le rendre plus lisible. Consultez la section sur le pivotement plus large ci-dessus, ainsi que la page Pivoter les données. Vous pouvez également ajouter plus de colonnes, et les arranger joliment. Ce code se trouve ci-dessous.\n\ntable_long %&gt;% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Passer du long au large\n    values_from = c(ct_value, N),                       # les nouvelles valeurs proviennent des colonnes ct et count\n    names_from = outcome) %&gt;%                           # les nouveaux noms de colonnes proviennent des outcomes\n  mutate(                                              # Ajouter de nouvelles colonnes\n    N_Known = N_Death + N_Recover,                               # nombre avec résultat connu\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # Pourcentage des cas qui sont morts (à une décimale près)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # Pourcentage de guérison (à une décimale près)\n  select(                                              # Réorganiser les colonnes\n    hospital, N_Known,                                   # Introduction de colonnes\n    N_Recover, Pct_Recover, ct_value_Recover,            # Colonnes récupérées\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Colonnes de décès\n  arrange(N_Known)                                  # Ranger les rangées du plus bas au plus haut (rangée totale en bas)\n\n# A tibble: 6 × 8\n# Groups:   hospital [6]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n6 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;\n\n\nEt vous pouvez ensuite afficher ce tableau sous la forme d’une image. Vous trouverez ci-dessous le résultat imprimé avec flextable. Vous pouvez lire plus en détail cet exemple et la façon d’obtenir ce “joli” tableau sur la page Tableaux pour la présentation.\n\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#tbl_gt",
    "href": "new_pages/tables_descriptive.fr.html#tbl_gt",
    "title": "17  Tableaux descriptifs",
    "section": "17.5 gtsummary package",
    "text": "17.5 gtsummary package\nSi vous voulez afficher vos synthèses statistiques dans un joli graphique, vous pouvez utiliser le package gtsummary et sa fonction tbl_summary(). Le code peut sembler complexe au début, mais les résultats sont très jolis et apparaissent dans votre panneau de visualisation RStudio sous forme d’image HTML. Lire une vignette ici.\nVous pouvez également ajouter les résultats des tests statistiques aux tableaux gtsummary. Ce processus est décrit dans la section gtsummary de la page Tests statistiques simples.\nPour présenter tbl_summary(), nous allons d’abord montrer le comportement le plus basique, qui produit effectivement un grand et beau tableau. Ensuite, nous examinerons en détail comment faire des ajustements et des tableaux plus adaptés.\n\nTableau de synthèse\nLe comportement par défaut de tbl_summary() est assez incroyable - il prend les colonnes que vous fournissez et crée un tableau de synthèse en une seule commande. La fonction affiche les statistiques appropriées à la classe de la colonne : la médiane et l’écart inter-quartile (IQR) pour les colonnes numériques, et le nombre (%) pour les colonnes catégorielles. Les valeurs manquantes sont converties en “Inconnu”. Des notes de bas de page sont ajoutées en bas de page pour expliquer les statistiques, tandis que le N total est affiché en haut de page.\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;%  # ne gardez que les colonnes d'intérêt\n  tbl_summary()                                                  # defaut\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n13 (6, 23)\n\n\n    Unknown\n86\n\n\ngender\n\n\n\n\n    f\n2,807 (50%)\n\n\n    m\n2,803 (50%)\n\n\n    Unknown\n278\n\n\noutcome\n\n\n\n\n    Death\n2,582 (57%)\n\n\n    Recover\n1,983 (43%)\n\n\n    Unknown\n1,323\n\n\nfever\n4,549 (81%)\n\n\n    Unknown\n249\n\n\ntemp\n38.80 (38.20, 39.20)\n\n\n    Unknown\n149\n\n\nhospital\n\n\n\n\n    Central Hospital\n454 (7.7%)\n\n\n    Military Hospital\n896 (15%)\n\n\n    Missing\n1,469 (25%)\n\n\n    Other\n885 (15%)\n\n\n    Port Hospital\n1,762 (30%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n422 (7.2%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\nAjustements\nNous allons maintenant expliquer le fonctionnement de la fonction et la manière de procéder aux ajustements. Les principaux arguments sont détaillés ci-dessous :\nby = Vous pouvez stratifier votre tableau par une colonne (par exemple par outcome), créant ainsi un tableau à 2 dimensions.\nstatistic = Utilisez une équation pour spécifier les statistiques à afficher et comment les afficher. L’équation comporte deux côtés, séparés par un tilde ~. Sur le côté droit, entre guillemets, se trouve l’affichage statistique souhaité, et sur la gauche se trouvent les colonnes auxquelles cet affichage s’appliquera.\n\nLe côté droit de l’équation utilise la syntaxe de str_glue() de stringr (voir Caractères et chaînes de caractères), avec la chaîne d’affichage souhaitée entre guillemets et les statistiques elles-mêmes entre crochets. Vous pouvez inclure des statistiques comme “n” (pour les comptes), “N” (pour le dénominateur), “mean”, “median”, “sd”, “max”, “min”, les percentiles comme “p##” comme “p25”, ou le pourcentage du total comme “p”. Voir ?tbl_summary pour plus de détails.\nPour le côté gauche de l’équation, vous pouvez spécifier les colonnes par leur nom (par exemple, age ou c(age, gender)) ou en utilisant des aides telles que all_continuous(), all_categorical(), contains(), starts_with(), etc.\n\nUn exemple simple d’équation statistic = pourrait ressembler à ce qui suit, pour afficher uniquement la moyenne de la colonne age_years :\n\nlinelist %&gt;% \n  select(age_years) %&gt;%         #  Ne gardez que les colonnes d'intérêt \n  tbl_summary(                  #  créer un tableau récapitulatif\n    statistic = age_years ~ \"{mean}\") # Impression de la moyenne d'âge\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n16\n\n\n    Unknown\n86\n\n\n\n1 Mean\n\n\n\n\n\n\n\n\n\nUne équation un peu plus complexe pourrait ressembler à \"({min}, {max})\", incorporant les valeurs max et min entre parenthèses et séparées par une virgule :\n\nlinelist %&gt;% \n  select(age_years) %&gt;%                       #  Ne gardez que les colonnes d'intérêt \n  tbl_summary(                                # créer un tableau résumé\n    statistic = age_years ~ \"({min}, {max})\") # Impression des valeurs minimale et maximale de l'âge\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n(0, 84)\n\n\n    Unknown\n86\n\n\n\n1 (Range)\n\n\n\n\n\n\n\n\n\nVous pouvez également différencier la syntaxe pour des colonnes ou des types de colonnes distincts. Dans l’exemple plus complexe ci-dessous, la valeur fournie à statistc = est une liste indiquant que pour toutes les colonnes continues, le tableau doit afficher la moyenne avec l’écart-type entre parenthèses, tandis que pour toutes les colonnes catégorielles, il doit afficher le n, le dénominateur et le pourcentage.\ndigits = Ajuste les chiffres et les arrondis. En option, il est possible de spécifier que cela ne concerne que les colonnes continues (comme ci-dessous).\nlabel = Ajustez la façon dont le nom de la colonne doit être affiché. Fournissez le nom de la colonne et son étiquette souhaitée, séparés par un tilde. La valeur par défaut est le nom de la colonne.\nmissing_text = Ajustez la façon dont les valeurs manquantes sont affichées. La valeur par défaut est “Inconnu”.\ntype = Permet de régler le nombre de niveaux de statistiques à afficher. La syntaxe est similaire à statistic = en ce sens que vous fournissez une équation avec des colonnes à gauche et une valeur à droite. Voici deux scénarios courants :\n\ntype = all_categorical() ~ \"categorical\" Force les colonnes dichotomiques (par exemple, fièvre oui/non) à montrer tous les niveaux au lieu de ne montrer que la ligne “oui”\ntype = all_continuous() ~ \"continuous2\" Permet des statistiques multi-lignes par variable, comme indiqué dans une section ultérieure.\n\nDans l’exemple ci-dessous, chacun de ces arguments est utilisé pour modifier le tableau de synthèse original :\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;% #  Ne gardez que les colonnes d'intérêt \n  tbl_summary(     \n    by = outcome,                                               # stratifier le tableau entier par résultat\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats et format pour les colonnes continues\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats et format pour les colonnes catégorielles\n    digits = all_continuous() ~ 1,                              # arrondi pour les colonnes continues\n    type   = all_categorical() ~ \"categorical\",                 # force l'affichage de tous les niveaux catégoriels\n    label  = list(                                              # affichage des étiquettes pour les noms de colonnes\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # comment les valeurs manquantes doivent être affichées\n  )\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\n\n\n\n\nAge (years)\n15.9 (12.3)\n16.1 (13.0)\n\n\n    Missing\n32\n28\n\n\nGender\n\n\n\n\n\n\n    f\n1,227 / 2,455 (50%)\n953 / 1,903 (50%)\n\n\n    m\n1,228 / 2,455 (50%)\n950 / 1,903 (50%)\n\n\n    Missing\n127\n80\n\n\nfever\n\n\n\n\n\n\n    no\n458 / 2,460 (19%)\n361 / 1,904 (19%)\n\n\n    yes\n2,002 / 2,460 (81%)\n1,543 / 1,904 (81%)\n\n\n    Missing\n122\n79\n\n\nTemperature\n38.6 (1.0)\n38.6 (1.0)\n\n\n    Missing\n60\n55\n\n\nHospital\n\n\n\n\n\n\n    Central Hospital\n193 / 2,582 (7.5%)\n165 / 1,983 (8.3%)\n\n\n    Military Hospital\n399 / 2,582 (15%)\n309 / 1,983 (16%)\n\n\n    Missing\n611 / 2,582 (24%)\n514 / 1,983 (26%)\n\n\n    Other\n395 / 2,582 (15%)\n290 / 1,983 (15%)\n\n\n    Port Hospital\n785 / 2,582 (30%)\n579 / 1,983 (29%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n199 / 2,582 (7.7%)\n126 / 1,983 (6.4%)\n\n\n\n1 Mean (SD); n / N (%)\n\n\n\n\n\n\n\n\n\n\n\nStatistiques multi-lignes pour les variables continues\nSi vous souhaitez afficher plusieurs lignes statistiques pour des variables continues, vous pouvez l’indiquer en définissant le type = à “continuous2”. Vous pouvez combiner tous les éléments présentés précédemment dans un seul tableau en choisissant les statistiques que vous voulez afficher. Pour cela, vous devez indiquer à la fonction que vous voulez récupérer un tableau en entrant le type comme “continuous2”. Le nombre de valeurs manquantes est indiqué comme “Inconnu”.\n\nlinelist %&gt;% \n  select(age_years, temp) %&gt;%                      # Ne garder que les colonnes d'intérêt\n  tbl_summary(                                     # # créer un tableau résume\n    type = all_continuous() ~ \"continuous2\",       # indique que vous voulez imprimer plusieurs statistiques \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # ligne 1 : moyenne et SD\n      \"{median} ({p25}, {p75})\",                   # ligne 2 : médiane et IQR\n      \"{min}, {max}\")                              # ligne 3: min et max\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,888\n\n\n\n\nage_years\n\n\n\n\n    Mean (SD)\n16 (13)\n\n\n    Median (IQR)\n13 (6, 23)\n\n\n    Range\n0, 84\n\n\n    Unknown\n86\n\n\ntemp\n\n\n\n\n    Mean (SD)\n38.56 (0.98)\n\n\n    Median (IQR)\n38.80 (38.20, 39.20)\n\n\n    Range\n35.20, 40.80\n\n\n    Unknown\n149\n\n\n\n\n\n\n\n\nIl existe de nombreuses autres façons de modifier ces tableaux, notamment en ajoutant des valeurs p, en ajustant la couleur et les titres, etc. La plupart sont décrites dans la documentation (entrez ?tbl_summary dans Console), et certaines sont données dans la section sur les tests statistiques.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#extensionpackage-r-base",
    "href": "new_pages/tables_descriptive.fr.html#extensionpackage-r-base",
    "title": "17  Tableaux descriptifs",
    "section": "17.6 extension/package R base",
    "text": "17.6 extension/package R base\nVous pouvez utiliser la fonction table() pour faire des tableaux et des tableaux croisés de colonnes. Contrairement aux options ci-dessus, vous devez spécifier le tableau de données chaque fois que vous faites référence à un nom de colonne, comme indiqué ci-dessous.\nCAUTION: Les valeurs NA(manquantes) ne seront pas affichées en tableau, à moins que vous n’incluiez l’argument useNA = \"always\" (qui peut également être défini sur “no” ou “ifany”).\nTIP: Vous pouvez utiliser le %$% de magrittr pour supprimer la répétition des enregistrements de données du tableaux dans les fonctions base. Par exemple, on pourrait écrire linelist %$% table(outcome, useNA = \"always\").\n\ntable(linelist$outcome, useNA = \"always\")\n\n\n  Death Recover    &lt;NA&gt; \n   2582    1983    1323 \n\n\nPlusieurs colonnes peuvent être croisées en les listant l’une après l’autre, séparées par des virgules. En option, vous pouvez attribuer à chaque colonne un “nom” comme Outcome = linelist$outcome.\n\nage_by_outcome &lt;- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # sauvegarder le tableau comme objet\nage_by_outcome   # imprimer le tableau\n\n       \n        Death Recover &lt;NA&gt;\n  0-4     471     364  260\n  5-9     476     391  228\n  10-14   438     303  200\n  15-19   323     251  169\n  20-29   477     367  229\n  30-49   329     238  187\n  50-69    33      38   24\n  70+       3       3    0\n  &lt;NA&gt;     32      28   26\n\n\n\nProportions\nPour retourner les proportions, passez le tableau ci-dessus à la fonction prop.table(). Utilisez l’argument margins = pour spécifier si vous voulez que les proportions soient des lignes (1), des colonnes (2), ou du tableau entier (3). Pour plus de précisions, nous envoyons le tableau à la fonction round() de base R, en spécifiant 2 chiffres.\n\n# obtenir les proportions du tableau défini ci-dessus, par lignes, arrondies\nprop.table(age_by_outcome, 1) %&gt;% round(2)\n\n       \n        Death Recover &lt;NA&gt;\n  0-4    0.43    0.33 0.24\n  5-9    0.43    0.36 0.21\n  10-14  0.47    0.32 0.21\n  15-19  0.43    0.34 0.23\n  20-29  0.44    0.34 0.21\n  30-49  0.44    0.32 0.25\n  50-69  0.35    0.40 0.25\n  70+    0.50    0.50 0.00\n  &lt;NA&gt;   0.37    0.33 0.30\n\n\n\n\nTotals\nPour ajouter les totaux des lignes et des colonnes, passez le tableau à addmargins(). Cela fonctionne à la fois pour les nombres et les proportions.\n\naddmargins(age_by_outcome)\n\n       \n        Death Recover &lt;NA&gt;  Sum\n  0-4     471     364  260 1095\n  5-9     476     391  228 1095\n  10-14   438     303  200  941\n  15-19   323     251  169  743\n  20-29   477     367  229 1073\n  30-49   329     238  187  754\n  50-69    33      38   24   95\n  70+       3       3    0    6\n  &lt;NA&gt;     32      28   26   86\n  Sum    2582    1983 1323 5888\n\n\n\n\nConvertir en tableau de données\nConvertir un objet table() directement en tableau de données n’est pas simple. Une approche est démontrée ci-dessous :\n\nCréez la table, sans utiliser useNA = \"always\". A la place, convertissez les valeurs NA en “(Missing)” avec fct_explicit_na() de forcats.\nAjoutez les totaux (facultatif) en utilisant addmargins().\nPassez le tableau dans la fonction R base as.data.frame.matrix().\nPassez le tableau dans la fonction tibble rownames_to_column(), en spécifiant le nom de la première colonne.\nAffichez, visualisez ou exportez comme vous le souhaitez. Dans cet exemple, nous utilisons flextable() du package flextable comme décrit dans la page Tableaux pour la présentation. Cela permettra d’afficher dans le volet de visualisation de RStudio une jolie image HTML.\n\n\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %&gt;% \n  addmargins() %&gt;% \n  as.data.frame.matrix() %&gt;% \n  tibble::rownames_to_column(var = \"Age Category\") %&gt;% \n  flextable::flextable()\n\nAge CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.fr.html#ressources",
    "href": "new_pages/tables_descriptive.fr.html#ressources",
    "title": "17  Tableaux descriptifs",
    "section": "17.7 Ressources",
    "text": "17.7 Ressources\nLa plupart des informations contenues dans cette page sont issues de ces ressources et des sites Internet :\ngtsummary\ndplyr",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tableaux descriptifs</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html",
    "href": "new_pages/stat_tests.fr.html",
    "title": "18  Tests statistiques simples",
    "section": "",
    "text": "18.1 Préparation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html#préparation",
    "href": "new_pages/stat_tests.fr.html#préparation",
    "title": "18  Tests statistiques simples",
    "section": "",
    "text": "Importation des packages\nCe bloc de code montre l’importation des packages nécessaires pour les analyses. Dans ce manuel, nous soulignons la fonction p_load() de pacman, qui installe le package si nécessaire et l’importe pour utilisation. Vous pouvez aussi importer les packages déjà installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages R.\n\npacman::p_load(\n  rio,          # pour importation des fichiers\n  here,         # chemins de fichiers\n  skimr,        # obtenir un aperçu des données\n  tidyverse,    # gestion des données + graphiques ggplot2, \n  gtsummary,    # statistiques et tests sommaires\n  rstatix,      # statistiques\n  corrr,        # analyse de corrélation pour les variables numériques\n  janitor,      # ajouter des totaux et des pourcentages à des tableaux\n  flextable     # transformer les tableaux en HTML\n  )\n\n\n\nImportation des données\nNous importons les données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez suivre, cliquez pour télécharger le “clean” linelist (as .rds file). Importez les données avec la fonction import() du package rio (cette fonction supporte de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# importez linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la liste des lignes sont affichées ci-dessous.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html#base-r",
    "href": "new_pages/stat_tests.fr.html#base-r",
    "title": "18  Tests statistiques simples",
    "section": "18.2 Base R",
    "text": "18.2 Base R\nVous pouvez utiliser les fonctions de base R pour effectuer des tests statistiques. Les commandes sont relativement simples et les résultats sont affichés dans la Console R pour une visualisation simple. Cependant, les résultats sont généralement des listes et sont donc plus difficiles à manipuler si vous souhaitez utiliser les résultats dans des opérations ultérieures.\n\nTest T\nUn t-test, aussi appelé “test t de Student”, est généralement utilisé pour déterminer s’il existe une différence significative entre les moyennes d’une variable numérique entre deux groupes. Nous allons montrer ici quelle syntaxe utiliser pour effectuer ce test selon si les colonnes se trouvent dans le même tableau de données.\nSyntaxe 1: Voici la syntaxe à utiliser lorsque les colonnes numériques et catégorielles se trouvent dans le même tableau de données. Fournissez la colonne numérique sur la gauche de l’équation et la colonne catégorielle sur la droite. Précisez le tableau de données à data =. Optionnellement, définissezpaired = TRUE, et conf.level = (0.95 par défaut), et alternative = (soit “two.sided”, “less”, or “greater”). Entrez ?t.test pour plus de détails.\n\n## comparer l'âge moyen par groupe avec un test t.\nt.test(age_years ~ gender, data = linelist)\n\n\n    Welch Two Sample t-test\n\ndata:  age_years by gender\nt = -21.344, df = 4902.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.571920 -6.297975\nsample estimates:\nmean in group f mean in group m \n       12.60207        19.53701 \n\n\nSyntaxe 2: Vous pouvez comparer deux vecteurs numériques distincts en utilisant cette syntaxe alternative. Par exemple, si les deux colonnes se trouvent dans des tableau de données différents.\n\nt.test(df1$age_years, df2$age_years)\n\nVous pouvez aussi utiliser un test t pour déterminer si la moyenne d’un échantillon est significativement différente d’une valeur spécifique. Ici, nous effectuons un one-sample t-test avec une moyenne de population connue/hypothétique mu = :\n\nt.test(linelist$age_years, mu = 45)\n\n\n\nTest de Shapiro-Wilk\nLe Shapiro-Wilk test peut être utilisé pour déterminer si un échantillon provient d’une population normalement distribuée (une hypothèse de nombreux autres tests et analyses, tels que le test t). Cependant, il ne peut être utilisé que sur un échantillon de 3 à 5000 observations. Pour des échantillons plus importants, un quantile-quantile plot peut être utile.\n\nshapiro.test(linelist$age_years)\n\n\n\nTest de la somme des rangs de Wilcoxon\nLe test de la somme des rangs de Wilcoxon, aussi appelé test U de Mann-Whitney, est souvent utilisé pour déterminer si deux échantillons numériques proviennent de la même distribution lorsque leurs populations ne sont pas normalement distribuées ou présentent une variance inégale.\n\n## comparer la distribution des âges par groupe de résultats avec un test de Wilcox.\nwilcox.test(age_years ~ outcome, data = linelist)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age_years by outcome\nW = 2501868, p-value = 0.8308\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nTest de Kruskal-Wallis\nLe test de Kruskal-Wallis est une extension du test de la somme des rangs de Wilcoxon qui peut être utilisé pour tester les différences dans la distribution de plus de deux échantillons. Lorsque deux échantillons sont utilisés, ce test donne des résultats identiques à ceux du test de la somme des rangs de Wilcoxon.\n\n## comparer la distribution des âges par groupe de résultats avec un test de Kruskal-Wallis.\nkruskal.test(age_years ~ outcome, linelist)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  age_years by outcome\nKruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308\n\n\n\n\nTest du khi carré\nPearson’s Chi-squared test est utilisé pour tester des différences significatives entre des groupes catégorielles.\n\n## comparer les proportions dans chaque groupe avec un test de chi-carré\nchisq.test(linelist$gender, linelist$outcome)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  linelist$gender and linelist$outcome\nX-squared = 0.0011841, df = 1, p-value = 0.9725",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html#le-rstatix-package",
    "href": "new_pages/stat_tests.fr.html#le-rstatix-package",
    "title": "18  Tests statistiques simples",
    "section": "18.3 Le rstatix package",
    "text": "18.3 Le rstatix package\nLe package rstatix offre la possibilité d’exécuter des tests statistiques et de recueillir les résultats dans un cadre “pipe-friendly”. Les résultats sont automatiquement intégrés dans un tableau de données afin que vous puissiez effectuer des opérations ultérieures sur les résultats. Il est aussi facile de regrouper les données transmises dans les fonctions, afin que les statistiques soient exécutées pour chaque groupe.\n\nStatistiques sommaires\nLa fonction get_summary_stats() est un moyen rapide de retourner des statistiques sommaires. Il suffit de passer vos données à cette fonction et de préciser les colonnes à analyser. Si aucune colonne n’est précisée, les statistiques sont calculées pour toutes les colonnes.\nPar défaut, une gamme complète de statistiques sommaires est retournée : n, max, min, médiane, 25%ile, 75%ile, IQR, écart absolu médian (mad), moyenne, écart-type, erreur-type, et un intervalle de confiance de la moyenne.\n\nlinelist %&gt;%\n  rstatix::get_summary_stats(age, temp)\n\n# A tibble: 2 × 13\n  variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166\n2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\nVous pouvez préciser un sous-groupe de statistiques sommaires à retourner en fournissant l’une des valeurs suivantes à type = : “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.\nElle peut également être utilisée avec des données groupées, de sorte qu’une ligne est renvoyée pour chaque variable de groupement :\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  rstatix::get_summary_stats(age, temp, type = \"common\")\n\n# A tibble: 12 × 11\n   hospital     variable     n   min   max median   iqr  mean     sd    se    ci\n   &lt;chr&gt;        &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Central Hos… age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n 2 Central Hos… temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n 3 Military Ho… age        884   0    72     14    18    16.1 12.4   0.417 0.818\n 4 Military Ho… temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n 5 Missing      age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n 6 Missing      temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n 7 Other        age        873   0    69     13    17    16.0 12.5   0.422 0.828\n 8 Other        temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n 9 Port Hospit… age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n10 Port Hospit… temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n11 St. Mark's … age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n12 St. Mark's … temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095\n\n\nVous pouvez aussi utiliser rstatix pour effectuer des tests statistiques :\n\n\nTest T\nUtilisez une syntaxe de formule pour préciser les colonnes numériques et catégorielles :\n\nlinelist %&gt;% \n  t_test(age_years ~ gender)\n\n# A tibble: 1 × 10\n  .y.   group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_… f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****        \n\n\nOu utilisez ~ 1 et spécifiez mu = pour un one-sample T-test. Cela peut aussi être fait par groupe.\n\nlinelist %&gt;% \n  t_test(age_years ~ 1, mu = 30)\n\n# A tibble: 1 × 7\n  .y.       group1 group2         n statistic    df     p\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age_years 1      null model  5802     -84.2  5801     0\n\n\nSi applicable, les tests statistiques peuvent être effectués par groupe, comme illustré ci-dessous :\n\nlinelist %&gt;% \n  group_by(gender) %&gt;% \n  t_test(age_years ~ 1, mu = 18)\n\n# A tibble: 3 × 8\n  gender .y.       group1 group2         n statistic    df         p\n* &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n3 &lt;NA&gt;   age_years 1      null model   192     -3.80   191 1.96e-  4\n\n\n\n\nTest de Shapiro-Wilk\nComme indiqué précédemment, la taille de l’échantillon doit être entre 3 et 5000.\n\nlinelist %&gt;% \n  head(500) %&gt;%            # les 500 premières lignes du case linelist, pour illustration seulement \n  shapiro_test(age_years)\n\n# A tibble: 1 × 3\n  variable  statistic        p\n  &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 age_years     0.917 6.67e-16\n\n\n\n\nTest de la somme des rangs de Wilcoxon\n\nlinelist %&gt;% \n  wilcox_test(age_years ~ gender)\n\n# A tibble: 1 × 9\n  .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****        \n\n\n\n\nTest de Kruskal-Wallis\nAussi appelé le test U de Mann-Whitney.\n\nlinelist %&gt;% \n  kruskal_test(age_years ~ outcome)\n\n# A tibble: 1 × 6\n  .y.           n statistic    df     p method        \n* &lt;chr&gt;     &lt;int&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis\n\n\n\n\nTest du khi carré\nLa fonction de khi carré peut accepter un tableau, donc nous allons d’abord créer un tableau croisé. Il existe de plusieurs méthodes de créer un tableau croisé (voir Tableaux descriptifs) mais ici nous utilisons tabyl() de janitor et nous supprimons la colonne la plus à gauche des labels de valeur avant de passer à chisq_test().\n\nlinelist %&gt;% \n  tabyl(gender, outcome) %&gt;% \n  select(-1) %&gt;% \n  chisq_test()\n\n# A tibble: 1 × 6\n      n statistic     p    df method          p.signif\n* &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;   \n1  5888      3.53 0.473     4 Chi-square test ns      \n\n\nDe nombreuses autres fonctions et tests statistiques peuvent être exécutés avec les fonctions de rstatix. Consultez la documentation de rstatix online here ou en entrant ?rstatix.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html#stats_gt",
    "href": "new_pages/stat_tests.fr.html#stats_gt",
    "title": "18  Tests statistiques simples",
    "section": "18.4 Le gtsummary package",
    "text": "18.4 Le gtsummary package\nUtilisez gtsummary si vous cherchez à ajouter les résultats d’un test statistique à un beau tableau qui a été créé avec ce package (comme décrit dans la section gtsummary de la page Tableaux descriptifs).\nEffectuer des tests statistiques de comparaison avec tbl_summary se fait en ajoutant la fonction add_p à une table et en précisant le test à utiliser. Il est possible d’obtenir des valeurs p ajustées pour multiples tests en utilisant la fonction add_q. Exécutez ?tbl_summary pour plus de détails.\n\nTest du khi carré\nComparez les proportions d’une variable catégorielle dans deux groupes. Le test statistique par défaut pour add_p() lorsqu’il est appliqué à une variable catégorielle est d’effectuer un test d’indépendance du khi-carré avec correction de continuité, mais si le nombre d’appels attendus est inférieur à 5, alors un test exact de Fisher est utilisé.\n\nlinelist %&gt;% \n  select(gender, outcome) %&gt;%    # garder les variables d'intérêt\n  tbl_summary(by = outcome) %&gt;%  # produire un tableau sommaire et préciser la variable de groupement\n  add_p()                        # préciser le test à effectuer\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\ngender\n\n\n\n\n&gt;0.9\n\n\n    f\n1,227 (50%)\n953 (50%)\n\n\n\n\n    m\n1,228 (50%)\n950 (50%)\n\n\n\n\n    Unknown\n127\n80\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\nTest T\nComparez la différence de moyennes entre deux groupes de variables continues. Par exemple, comparez l’âge moyen selon le statut du patient.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%             # garder les variables d'intérêt\n  tbl_summary(                               # produire un tableau sommaire\n    statistic = age_years ~ \"{mean} ({sd})\", # préciser quel statistique a afficher\n    by = outcome) %&gt;%                        # préciser la variable de groupement\n  add_p(age_years ~ \"t.test\")                # préciser le test à effectuer\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n16 (12)\n16 (13)\n0.6\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n\n\n\n\n\n\n\n\n\nTest de la somme des rangs de Wilcoxon\nComparez la distribution d’une variable continue dans deux groupes. La méthode par défaut est d’utiliser le test de la somme des rangs de Wilcoxon et la médiane (IQR) pour comparer deux groupes. Cependant, pour les données de distribution non normale ou la comparaison de plusieurs groupes, le test de Kruskal-wallis est plus approprié.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # garder les variables d'intérêt\n  tbl_summary(                                         # produire un tableau sommaire\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # préciser quel statistique a afficher (ceci est par défaut et peut donc être supprimé)\n    by = outcome) %&gt;%                                  # préciser la variable de groupement\n  add_p(age_years ~ \"wilcox.test\")                     # préciser le test à effectuer\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\n\n\n\nTest de Kruskal-Wallis\nComparer la distribution d’une variable continue dans deux ou plusieurs groupes, peu importe si les données sont normalement distribuées ou pas.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # garder les variables d'intérêt\n  tbl_summary(                                         # produire un tableau sommaire\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # préciser quel statistique a afficher (ceci est par défaut et peut donc être supprimé)\n    by = outcome) %&gt;%                                  # préciser la variable de groupement\n  add_p(age_years ~ \"kruskal.test\")                    # préciser le test à effectuer\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Kruskal-Wallis rank sum test",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html#corrélations",
    "href": "new_pages/stat_tests.fr.html#corrélations",
    "title": "18  Tests statistiques simples",
    "section": "18.5 Corrélations",
    "text": "18.5 Corrélations\nLa corrélation entre les variables numériques peut être étudiée en utilisant le package tidyverse\ncorrr. Il vous permet de calculer les corrélations en utilisant Pearson, Kendall tau ou Spearman rho. Le package crée un tableau et dispose également d’une fonction pour pour tracer automatiquement les valeurs.\n\ncorrelation_tab &lt;- linelist %&gt;% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %&gt;%   # garder les variables numeriques d'intérêt\n  correlate()      # créer une table de corrélation (en utilisant le pearson par défaut)\n\ncorrelation_tab    # afficher\n\n# A tibble: 6 × 7\n  term            generation      age ct_blood days_onset_hosp    wt_kg    ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 generation        NA       -2.22e-2  0.179         -0.288    -0.0302  -0.00942\n2 age               -0.0222  NA        0.00849       -0.000635  0.833    0.877  \n3 ct_blood           0.179    8.49e-3 NA             -0.600    -0.00636  0.0181 \n4 days_onset_hosp   -0.288   -6.35e-4 -0.600         NA         0.0153  -0.00953\n5 wt_kg             -0.0302   8.33e-1 -0.00636        0.0153   NA        0.884  \n6 ht_cm             -0.00942  8.77e-1  0.0181        -0.00953   0.884   NA      \n\n## supprimer les entrées dupliquées (le tableau précédent est dupliqué) \ncorrelation_tab &lt;- correlation_tab %&gt;% \n  shave()\n\n## voir le tableau de corrélation\ncorrelation_tab\n\n# A tibble: 6 × 7\n  term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 generation        NA       NA        NA              NA       NA        NA\n2 age               -0.0222  NA        NA              NA       NA        NA\n3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n\n## graphique des corrélations \nrplot(correlation_tab)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.fr.html#ressources",
    "href": "new_pages/stat_tests.fr.html#ressources",
    "title": "18  Tests statistiques simples",
    "section": "18.6 Ressources",
    "text": "18.6 Ressources\nLa plupart des informations contenues dans cette page sont adaptées de ces ressources et vignettes disponibles en ligne :\ngtsummary dplyr corrr sthda correlation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests statistiques simples</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html",
    "href": "new_pages/regression.fr.html",
    "title": "19  Régression univariée et multivariable",
    "section": "",
    "text": "19.1 Preparation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html#preparation",
    "href": "new_pages/regression.fr.html#preparation",
    "title": "19  Régression univariée et multivariable",
    "section": "",
    "text": "Chargement des packages\nCe bout de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() du package pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur R basics pour plus d’informations sur les packages de R.\n\npacman::p_load(\n  rio, # Importation du fichier\n  here, # Localisation de fichiers\n  tidyverse, # gestion des données + graphiques ggplot2, \n  stringr, # manipuler des chaînes de texte \n  purrr, # boucle sur les objets d'une manière ordonnée\n  gtsummary, # statistiques et tests sommaires \n  broom, # met de l'ordre dans les résultats des régressions\n  lmtest, # tests du rapport de vraisemblance\n  parameters, # alternative pour mettre de l'ordre dans les résultats des régressions\n  see # alternative pour visualiser les parcelles forestières\n  )\n\n\n\nImportation de données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez continuer dans le processus d’acquisition de données suivait ce lien, cliquer pour téléchager le jeu de données linelist “propre” (as .rds file). Importez vos données avec la fonction import() du packages rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importer et exporter des données pour plus de détails)..\n\n# importer la liste de lignes\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de linelist sont affichées ci-dessous.\n\n\n\n\n\n\n\n\nNettoyer les données\n\nStocker les variables explicatives\nNous stockons les noms des colonnes explicatives sous la forme d’un vecteur de caractères. Il sera référencé plus tard.\n\n## definir les variables d'interet \nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n\n\n19.1.0.1 Convertir en 1 et 0 {.non numéroté}\nCi-dessous, nous convertissons les colonnes explicatives de “yes”/“no”, “m”/“f”, et “dead”/“alive” en 1 / 0, pour se conformer avec les attentes des modèles de régression logistique. Pour faire cela efficacement, nous avons utilisé across() de dplyr pour transformer plusieurs colonnes en une seule fois. La fonction que nous appliquons à chaque colonne est case_when() (également dplyr) qui applique une logique pour convertir les valeurs spécifiées en 1 et 0. Voir les sections sur across() et case_when() dans la page Nettoyage de données et fonctions essentielles).\nNote : le “.” ci-dessous représente la colonne qui est traitée par across() à ce moment-là.\n\n## convertir les  variables dichotomique   en  0/1 \nlinelist &lt;- linelist %&gt;%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## pour chaque colonne listée et \"résultat\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recoder male, yes et death en 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0)           ## female, no and recover en 0\n                                                     ## autre definir comme valeurs manquantes\n    )\n  )\n\n\n\nSupprimer les lignes avec des valeurs manquantes\nPour supprimer les lignes avec des valeurs manquantes, vous pouvez utiliser la fonction tidyr drop_na(). Cependant, nous ne voulons l’utiliser que pour les lignes qui ont des valeurs manquantes dans les colonnes qui nous intéressent.\nLa première chose que nous devons faire est de nous assurer que notre vecteur explanatory_vars exlu la colonne age (age aurait produit une erreur dans l’opération précédente case_when(), qui ne concernait que les variables dichotomiques). Ensuite, nous envoyons la liste de lignes à drop_na() pour enlever toutes les lignes avec des valeurs manquantes dans la colonne outcome ou dans l’une des colonnes explanatory_vars.\nAvant d’exécuter le code, le nombre de lignes dans la linelist est nrow(linelist).\n\n## ajout de la catégorie d'âge aux variables explicatives \nexplanatory_vars &lt;- c(explanatory_vars, \"age_cat\")\n\n## supprimer les lignes avec des informations manquantes pour les variables d'intérêt \nlinelist &lt;- linelist %&gt;% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))\n\nle nombre de lignes restant dans linelist est de nrow(linelist).",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html#univarié",
    "href": "new_pages/regression.fr.html#univarié",
    "title": "19  Régression univariée et multivariable",
    "section": "19.2 Univarié",
    "text": "19.2 Univarié\nTout comme dans la page sur les Tableaux descriptifs, votre cas d’utilisation déterminera le package R que vous utiliserez. Nous vous présentons deux options pour effectuer une analyse univariée :\n\nUtiliser les fonctions disponibles dans base R pour afficher rapidement les résultats sur la console. Utilisez le package broom pour mettre de l’ordre dans les résultats.\n\nUtilisez le package gtsummary pour modéliser et obtenir des résultats prêts à être publiés.\n\n\n\nbase R\n\nRégression linéaire\nLa fonction base R lm() effectue une régression linéaire, évaluant la relation entre une réponse numérique et des variables explicatives qui sont supposées avoir une relation linéaire.\nFournissez l’équation sous forme de formule, avec les noms des colonnes de réponse et d’explication séparés par un tilde ~. Spécifiez également l’ensemble de données à data =. Définissez les résultats du modèle comme un objet R, à utiliser ultérieurement.\n\nlm_results &lt;- lm(ht_cm ~ age, data = linelist)\n\nVous pouvez ensuite exécuter summary() sur les résultats du modèle pour voir les coefficients (Estimations), la valeur P, les résidus, et d’autres mesures.\n\nsummary(lm_results)\n\n\nCall:\nlm(formula = ht_cm ~ age, data = linelist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-128.579  -15.854    1.177   15.887  175.483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  69.9051     0.5979   116.9   &lt;2e-16 ***\nage           3.4354     0.0293   117.2   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.75 on 4165 degrees of freedom\nMultiple R-squared:  0.7675,    Adjusted R-squared:  0.7674 \nF-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: &lt; 2.2e-16\n\n\nVous pouvez également utiliser la fonction tidy() du package broom pour afficher les résultats dans un tableau. les résultats dans un tableau. Les résultats nous indiquent que pour chaque année de plus dans l’âge d’un individu, la taille augmente de de 3,5 cm, ce qui est statistiquement significatif.\n\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    69.9     0.598       117.       0\n2 age             3.44    0.0293      117.       0\n\n\nVous pouvez également utiliser cette régression pour l’ajouter à un ggplot. d’abord prendre les points des données observées et la colonne predite à partir de la ligne ajustée dans un dataframe en utilisant la fonction augment() de broom.\n\n## rassembler les points de régression et les données observées dans un seul ensemble de données\npoints &lt;- augment(lm_results)\n\n## creer un graphique  avec age comme   axe  des abscisses\nggplot(points, aes(x = age)) + \n  ## ajouter point pour l'ordonné\n  geom_point(aes(y = ht_cm)) + \n  ## ajouter de la droite de régression linéaire\n  geom_line(aes(y = .fitted), colour = \"red\")\n\n\n\n\n\n\n\n\nIl est également possible d’ajouter une droite de régression linéaire simple dans ggplot en utilisant la fonction geom_smooth().\n\n## ajoute ta donnée dans le graphe\n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## montrer les points\n  geom_point() + \n  ## ajouter une regression linéaire\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nConsultez la section Ressources à la fin de ce chapitre pour obtenir des didacticiels plus détaillés.\n\n\nRégression logistique\nLa fonction glm() du package stats (faisant partie de base R) est utilisée pour ajuster les modèles linéaires généralisés (GLM).\nglm() peut être utilisée pour la régression logistique univariée et multivariée (par exemple pour obtenir des Odds Ratios). Voici les parties principales :\n\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)\n\n\nformula = Le modèle est fourni à glm() sous forme d’équation, avec le résultat à gauche et les variables explicatives à droite d’un tilde ~.\n\nfamily = Ceci détermine le type de modèle à exécuter. Pour la régression logistique, utilisez famille = \"binomiale\", pour le poisson utilisez famille = \"poisson\". D’autres exemples sont dans le tableau ci-dessous.\n\ndata = Spécifiez votre dataframe\n\nSi nécessaire, vous pouvez également spécifier la fonction de lien via la syntaxe family = familytype(link = \"linkfunction\")). Vous pouvez en savoir plus dans la documentation sur les autres familles et les arguments optionnels tels que weights = et subset = (?glm).\n\n\n\nFamille\nFonction de liaison par défaut\n\n\n\n\n\"binomial\"\n(lien = \"logit\")\n\n\n\"gaussian\"\n(lien = \"identity\")\n\n\n\"Gamma\"\n(lien = \"inverse\")\n\n\n\"inverse.gaussian\"\n(link = \"1/mu^2\")\n\n\n\"poisson\"\n(lien = \"log\")\n\n\n\"quasi\"\n(lien = \"identity\", variance = \"constant\")\n\n\n\"quasibinomial\"\n(lien = \"logit\")\n\n\n\"quasipoisson\"\n(lien = \"log\")\n\n\n\nLorsque vous exécutez glm(), il est plus courant de sauvegarder les résultats comme un objet R nommé. Vous pouvez ensuite afficher les résultats sur votre console en utilisant summary() comme indiqué ci-dessous, ou effectuer d’autres opérations sur les résultats (par exemple, exponentiation).\nSi vous avez besoin d’exécuter une régression binomiale négative, vous pouvez utiliser le package MASS ; le glm.nb() utilise la même syntaxe que glm(). Pour une présentation des différentes régressions, consultez la UCLA stats page.\n\n\nUnivarié glm()\nDans cet exemple, nous évaluons la relation entre différentes catégories d’âge et le résultat du décès (codé 1 dans la section Préparation). Nous présentons ci-dessous un modèle univarié de outcome par age_cat. Nous enregistrons la sortie du modèle sous le nom de model et nous l’affichons ensuite avec summary() sur la console. Notez que les estimations fournies sont les log odds et que le niveau de base est le premier niveau du facteur age_cat (“0-4”).\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   0.233738   0.072805   3.210  0.00133 **\nage_cat5-9   -0.062898   0.101733  -0.618  0.53640   \nage_cat10-14  0.138204   0.107186   1.289  0.19726   \nage_cat15-19 -0.005565   0.113343  -0.049  0.96084   \nage_cat20-29  0.027511   0.102133   0.269  0.78765   \nage_cat30-49  0.063764   0.113771   0.560  0.57517   \nage_cat50-69 -0.387889   0.259240  -1.496  0.13459   \nage_cat70+   -0.639203   0.915770  -0.698  0.48518   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\nPour modifier le niveau de base d’une variable donnée, assurez-vous que la colonne est de classe facteur et déplacez le niveau désiré à la première position avec fct_relevel() (voir la page sur Factors). Par exemple, ci-dessous, nous prenons la colonne age_cat et définissons “20-29” comme niveau de base avant de passer le dataframe modifié dans glm().\n\nlinelist %&gt;%\n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %&gt;% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %&gt;% \n  summary()\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.26125    0.07163   3.647 0.000265 ***\nage_cat0-4   -0.02751    0.10213  -0.269 0.787652    \nage_cat5-9   -0.09041    0.10090  -0.896 0.370220    \nage_cat10-14  0.11069    0.10639   1.040 0.298133    \nage_cat15-19 -0.03308    0.11259  -0.294 0.768934    \nage_cat30-49  0.03625    0.11302   0.321 0.748390    \nage_cat50-69 -0.41540    0.25891  -1.604 0.108625    \nage_cat70+   -0.66671    0.91568  -0.728 0.466546    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nAffichage des résultats\nPour la plupart des utilisations, plusieurs modifications doivent être apportées aux sorties ci-dessus. La fonction tidy() du package broom est pratique pour rendre les résultats du modèle lisibles et comprehensibles.\nNous montrons ici comment combiner les sorties du modèle avec une table de comptage.\n\nObtenez les estimations du logarithm de l’odd ratio exponentiées et les intervalles de confiance en passant le modèle à tidy() et en définissant exponentiate = TRUE et conf.int = TRUE.\n\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %&gt;% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%        # exponentiée et  généré IC\n  mutate(across(where(is.numeric), round, digits = 2))  # arrondir tous les colonnes numeriques\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, digits = 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nVoici la sortie du tibble model :\n\n\n\n\n\n\n\nCombinez les résultats de ces modèles avec un tableau de comptage. Ci-dessous, nous créons un tableau de comptage croisé avec la fonction tabyl() de janitor, comme indiqué dans la page Tableaux descriptifs.\n\n\ncounts_table &lt;- linelist %&gt;% \n  janitor::tabyl(age_cat, outcome)\n\n\n\n\n\n\n\n\n\n\n\nVoici à quoi ressemble ce dataframe counts_table :\n\n\n\n\n\n\nMaintenant, nous pouvons lier les résultats de counts_table et de model ensemble horizontalement avec bind_cols() (dplyr). Rappelez-vous qu’avec bind_cols() les lignes des deux dataframes doivent être parfaitement alignées. Dans ce code, comme nous effectuons des liaisons dans une chaîne de commandes, nous utilisons . pour représenter l’objet counts_table lorsque nous le lions à model. Pour terminer le processus, nous utilisons select() pour choisir les colonnes souhaitées et leur ordre, et enfin nous appliquons la fonction base R round() sur toutes les colonnes numériques pour spécifier 2 décimales.\n\ncombined &lt;- counts_table %&gt;%           # debutons avec un tableau de comptage\n  bind_cols(., model) %&gt;%              # combiner avec les sorties de la regression\n  select(term, 2:3, estimate,          # selectionner and arranger les cols\n         conf.low, conf.high, p.value) %&gt;% \n  mutate(across(where(is.numeric), round, digits = 2)) ## arrondir à deux chiffres apres la virgule\n\nVoici à quoi ressemble le dataframe combiné, affiché joliment comme une image avec une fonction de flextable. La section Tableau pour la presentationn explique comment personnaliser de tels tableaux avec flextable, ou vous pouvez utiliser de nombreux autres packages tels que knitr ou GT.\n\ncombined &lt;- combined %&gt;% \n  flextable::qflextable()\n\n\n\nMettre en Boucle plusieurs modèles univariés\nNous présentons ci-dessous une méthode utilisant glm() et tidy() pour une approche plus simple, voir la section sur gtsummary.\nPour exécuter les modèles sur plusieurs variables d’explicative afin de produire des odds ratios univariés (c’est-à-dire sans contrôle des autres variables), vous pouvez utiliser l’approche ci-dessous. Elle utilise str_c() de stringr pour créer des formules univariées (voir Caractères et chaînes de caractères), exécute la régression glm() sur chaque formule, passe chaque sortie glm() à tidy() et enfin rassemble toutes les sorties du modèle avec bind_rows() de tidyr. Cette approche utilise map() du packages purrr pour itérer - voir la page sur [Iteration, loops, and lists] pour plus d’informations sur cet outil.\n\nCréez un vecteur de noms de colonnes des variables explicatives. Nous l’avons déjà en tant que explanatory_vars dans la section Préparation de cette page.\nUtilisez str_c() pour créer plusieurs formules de chaîne, avec outcome à gauche, et un nom de colonne de explanatory_vars à droite. Le point . remplace le nom de la colonne dans explanatory_vars.\n\n\nexplanatory_vars %&gt;% str_c(\"outcome ~ \", .)\n\n[1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\" \n[4] \"outcome ~ cough\"   \"outcome ~ aches\"   \"outcome ~ vomit\"  \n[7] \"outcome ~ age_cat\"\n\n\n\nPassez ces formules de chaîne à map() et définissez ~glm() comme la fonction à appliquer à chaque entrée. Dans glm(), définissez la formule de régression comme as.formula(.x) où .x sera remplacé par la formule de chaîne définie dans l’étape précédente. map() bouclera sur chacune des formules en format chaîne de caractères, en effectuant des régressions pour chacune d’entre elles.\nLes résultats de cette première map() sont passés à une seconde commande map(), qui applique tidy() aux résultats de la régression.\nFinalement, la sortie de la seconde commande map() (une liste de dataframe triés) est condensée avec bind_rows(), qui donne un dataframe avec tous les résultats univariés.\n\n\nmodels &lt;- explanatory_vars %&gt;%       # commencer avec les variables d'interets\n  str_c(\"outcome ~ \", .) %&gt;%         # combiner chaque variable dans une formule (\"outcome ~ variable of interest\")\n  \n  # itérer à travers chaque formule univariée\n  map(                               \n    .f = ~glm(                       # passer les formules une par une à glm()\n      formula = as.formula(.x),      # dans glm(), la formule de la chaîne de caractère est .x\n      family = \"binomial\",           # spécifier le type de glm (logistique)\n      data = linelist)) %&gt;%          # jeu de données\n  \n  # mettre en ordre chacun des résultats de la régression glm ci-dessus\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiation \n      conf.int = TRUE)) %&gt;%          # retourne les intervalles de confiance\n  \n  # réduire la liste des résultats de la régression en un seul dataframe\n  bind_rows() %&gt;% \n  \n  # arrondir tous les colonnes numeriques\n  mutate(across(where(is.numeric), round, digits = 2))\n\nCette fois, l’objet final models est plus long car il représente maintenant les résultats combinés de plusieurs régressions univariées. Cliquez pour voir toutes les lignes de model.\n\n\n\n\n\n\nComme précédemment, nous pouvons créer une table des effectifs à partir de la linelist pour chaque variable explicative, la lier à models, et faire une belle table. Nous commençons par les variables, et nous les parcourons avec map(). Nous itérons à travers une fonction définie par l’utilisateur qui implique la création d’une table d’effectifs avec les fonctions dplyr. Ensuite, les résultats sont combinés et liés aux résultats du modèle models.\n\n## pour chaque variable explicative\nuniv_tab_base &lt;- explanatory_vars %&gt;% \n  map(.f = \n    ~{linelist %&gt;%                ## debuter avec  linelist\n        group_by(outcome) %&gt;%     ## grouper le jeu de donnée par outcome\n        count(.data[[.x]]) %&gt;%    ## produire des comptages pour la variable d'intérêt\n        pivot_wider(              ## étendre à un format large (comme dans un tableau croisé)\n          names_from = outcome,\n          values_from = n) %&gt;% \n        drop_na(.data[[.x]]) %&gt;%         ## éliminer les lignes avec des valeurs manquantes\n        rename(\"variable\" = .x) %&gt;%      ## changer la colonne de la variable d'intérêt en \"variable\".\n        mutate(variable = as.character(variable))} ## convertir en caractères, sinon les variables non-dichotomiques (catégorielles) apparaissent comme des facteurs et ne peuvent pas être fusionnées.\n      ) %&gt;% \n  \n  ## Réduire la liste des sorties de comptage à un seul dataframe\n  bind_rows() %&gt;% \n  \n  ## fusionner avec les sorties de la régression \n  bind_cols(., models) %&gt;% \n  \n  ## ne garder que les colonnes intéressées \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %&gt;% \n  \n  ## arrondir les décimales\n  mutate(across(where(is.numeric), round, digits = 2))\n\nVoici à quoi ressemble le dataframe. Voir la page sur les Tableau pour la presentationn pour des idées sur la façon de convertir ce tableau en une jolie sortie HTML (par exemple avec flextable).\n\n\n\n\n\n\n\n\n\n\ngtsummary package\nNous présentons ci-dessous l’utilisation de tbl_uvregression() du package gtsummary. Tout comme dans la page sur les Tableaux descriptifs, les fonctions gtsummary font un bon travail pour exécuter des statistiques et produire des résultats à usage professionnel. Cette fonction produit un tableau des résultats d’une régression univariée.\nNous ne sélectionnons que les colonnes nécessaires de la linelist (les variables explicatives et la variable de résultat) et les introduisons dans tbl_uvregression(). Nous allons exécuter une régression univariée sur chacune des colonnes que nous avons définies comme explanatory_vars dans la section Préparation des données (sexe, fièvre, frissons, toux, courbatures, vomissements, et age_cat).\nDans la fonction elle-même, nous fournissons la method = comme glm (sans guillemets), la colonne y = outcome (outcome), nous spécifions à method.args = que nous voulons exécuter une régression logistique via family = binomial, et nous lui disons d’exponentiser les résultats.\nLa sortie est en HTML et contient les comptes\n\nuniv_tab &lt;- linelist %&gt;% \n  dplyr::select(explanatory_vars, outcome) %&gt;% ## selectionner variables d'interet\n\n  tbl_uvregression(                         ## produire un tableau univarié\n    method = glm,                           ## définir la régression que l'on veut exécuter (modèle linéaire généralisé)\n    y = outcome,                            ## définir la variable de résultat\n    method.args = list(family = binomial),  ## définir le type de glm que l'on veut exécuter (logistique)\n    exponentiate = TRUE                     ## exponentiez pour produire des odds ratios (plutôt que des odds logarithmiques)\n  )\n\n## visualiser le tableau des résultats univariés \nuniv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nVous pouvez apporter de nombreuses modifications à ce tableau, par exemple en ajustant les étiquettes de texte, en mettant en gras les lignes en fonction de leur valeur p, etc. Voir les didacticiels ici et ailleurs en ligne.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html#stratifié",
    "href": "new_pages/regression.fr.html#stratifié",
    "title": "19  Régression univariée et multivariable",
    "section": "19.3 Stratifié",
    "text": "19.3 Stratifié\nL’analyse stratifiée est actuellement en cours de développement pour gtsummary, cette page sera mise à jour en temps voulu.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html#multivariable",
    "href": "new_pages/regression.fr.html#multivariable",
    "title": "19  Régression univariée et multivariable",
    "section": "19.4 Multivariable",
    "text": "19.4 Multivariable\nPour l’analyse multivariable, nous présentons à nouveau deux approches :\n\nglm() et tidy().\n\npackage gtsummary.\n\nLa methodologie est similaire pour chacune d’entre elles et seule la dernière étape, celle de l’élaboration d’un tableau final, est différente.\n\nConduite multivariable\nIci, nous utilisons glm() mais ajoutons plus de variables au côté droit de l’équation, séparées par des symboles plus (+).\nPour exécuter le modèle avec toutes nos variables explicatives, nous devrions exécuter :\n\nmv_reg &lt;- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)\n\n\nCall:\nglm(formula = outcome ~ gender + fever + chills + cough + aches + \n    vomit + age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   0.069054   0.131726   0.524    0.600\ngender        0.002448   0.065133   0.038    0.970\nfever         0.004309   0.080522   0.054    0.957\nchills        0.034112   0.078924   0.432    0.666\ncough         0.138584   0.089909   1.541    0.123\naches        -0.070705   0.104078  -0.679    0.497\nvomit         0.086098   0.062618   1.375    0.169\nage_cat5-9   -0.063562   0.101851  -0.624    0.533\nage_cat10-14  0.136372   0.107275   1.271    0.204\nage_cat15-19 -0.011074   0.113640  -0.097    0.922\nage_cat20-29  0.026552   0.102780   0.258    0.796\nage_cat30-49  0.059569   0.116402   0.512    0.609\nage_cat50-69 -0.388964   0.262384  -1.482    0.138\nage_cat70+   -0.647443   0.917375  -0.706    0.480\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5700.2  on 4153  degrees of freedom\nAIC: 5728.2\n\nNumber of Fisher Scoring iterations: 4\n\n\nSi vous voulez inclure deux variables et une interaction entre elles, vous pouvez les séparer avec un astérisque * au lieu d’un +. Séparez-les par un deux-points : si vous ne spécifiez que l’interaction. Par exemple :\n\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n\nOptionnellement, vous pouvez utiliser ce code pour exploiter le vecteur prédéfini des noms de colonnes et recréer la commande ci-dessus en utilisant str_c(). Cela peut être utile si les noms de vos variables explicatives changent, ou si vous ne voulez pas les taper à nouveau.\n\n## effectuer une régression avec toutes les variables d'intérêt \nmv_reg &lt;- explanatory_vars %&gt;%  ## commencer par un vecteur de noms de colonnes explicatives\n  str_c(collapse = \"+\") %&gt;%     ## combiner tous les noms des variables d'intérêt séparés par un plus\n  str_c(\"outcome ~ \", .) %&gt;%    ## combiner les noms des variables d'intérêt avec le résultat dans le style d'une formule\n  glm(family = \"binomial\",      ## définir le type de glm comme logistique,\n      data = linelist)          ## définir votre jeu de données\n\n\nConstruire le modèle\nVous pouvez construire votre modèle étape par étape, en enregistrant plusieurs modèles qui incluent certaines variables explicatives. Vous pouvez comparer ces modèles avec des tests de rapport de vraisemblance en utilisant lrtest() du package lmtest, comme ci-dessous :\nNOTE: L’utilisation de base anova(model1, model2, test = \"Chisq) produit les mêmes résultats \n\nmodel1 &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 &lt;- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)\n\nLikelihood ratio test\n\nModel 1: outcome ~ age_cat\nModel 2: outcome ~ age_cat + gender\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)\n1   8 -2852.6                    \n2   9 -2852.6  1 2e-04     0.9883\n\n\nUne autre option consiste à prendre l’objet modèle et à appliquer la fonction step() du package stats. Spécifiez la direction de sélection des variables que vous souhaitez utiliser lors de la construction du modèle.\n\n## choisir un modèle en utilisant la sélection avant basée sur l'AIC\n## vous pouvez aussi faire \"backward\" ou \"both\" en ajustant la direction.\nfinal_mv_reg &lt;- mv_reg %&gt;%\n  step(direction = \"forward\", trace = FALSE)\n\nVous pouvez également désactiver la notation scientifique dans votre session R, pour plus de clarté :\n\noptions(scipen=999)\n\nComme décrit dans la section sur l’analyse univariée, nous passons la sortie du modèle à tidy() pour exponentialiser les probabilités logarithmiques et les IC. Enfin, nous arrondissons toutes les colonnes numériques à deux décimales. Faites défiler pour voir toutes les lignes.\n\nmv_tab_base &lt;- final_mv_reg %&gt;% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%  ## obtenir un tidy  dataframe d'estimations \n  mutate(across(where(is.numeric), round, digits = 2))          ## arrondir\n\nVoici à quoi ressemble le dataframe obtenu :\n\n\n\n\n\n\n\n\n\n\nCombiner univarié et multivariable\n\nCombinez avec gtsummary\nLe package gtsummary fournit la fonction tbl_regression(), qui prendra . les sorties d’une régression (glm() dans ce cas) et produira un joli tableau de synthèse. tableau récapitulatif.\n\n## montrer le tableau des résultats de la régression finale \nmv_tab &lt;- tbl_regression(final_mv_reg, exponentiate = TRUE)\n\nVoyons le tableau :\n\nmv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n1.15\n0.96, 1.37\n0.12\n\n\naches\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n\n\n\n\n\n\n\n\n    0-4\n—\n—\n\n\n\n\n    5-9\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nVous pouvez également combiner plusieurs tableaux de sortie différents produits par gtsummary avec la fonction tbl_merge(). Nous combinons maintenant les résultats multivariables avec les résultats univariés de gtsummary que nous avons créés ci-dessus:\n\n## combiner avec les résultats univariés \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combiner\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # definier les entetes des colonnes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nUnivariate\nMultivariable\n\n\nN\nOR1\n95% CI1\np-value\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n1.15\n0.96, 1.37\n0.12\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nCombiner avec dplyr\nUne autre façon de combiner les sorties univariées et multivariées de glm()/tidy() est d’utiliser les fonctions de jonction dplyr.\n\nfusionner les résultats univariés de tout à l’heure (univ_tab_base, qui contient les comptages) avec les résultats multivariables triés mv_tab_base.\n\nUtilisez select() pour ne garder que les colonnes que nous voulons, spécifier leur ordre, et les renommer.\n\nUtilisez round() avec deux décimales sur toutes les colonnes qui sont classe Double\n\n\n## combiner des tableaux univariés et multivariés \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %&gt;% \n  ##choisir les colonnes et les renommer\n  select( # nouveau nom = ancien nom\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %&gt;% \n  mutate(across(where(is.double), round, 2))   \n\n# A tibble: 20 × 11\n   characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval\n   &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          909  1168    1.28        1.18         1.4       0   \n 2 gender               916  1174    1           0.88         1.13      0.97\n 3 (Intercept)          340   436    1.28        1.11         1.48      0   \n 4 fever               1485  1906    1           0.85         1.17      0.99\n 5 (Intercept)         1472  1877    1.28        1.19         1.37      0   \n 6 chills               353   465    1.03        0.89         1.21      0.68\n 7 (Intercept)          272   309    1.14        0.97         1.34      0.13\n 8 cough               1553  2033    1.15        0.97         1.37      0.11\n 9 (Intercept)         1636  2114    1.29        1.21         1.38      0   \n10 aches                189   228    0.93        0.76         1.14      0.51\n11 (Intercept)          931  1144    1.23        1.13         1.34      0   \n12 vomit                894  1198    1.09        0.96         1.23      0.17\n13 (Intercept)          338   427    1.26        1.1          1.46      0   \n14 age_cat5-9           365   433    0.94        0.77         1.15      0.54\n15 age_cat10-14         273   396    1.15        0.93         1.42      0.2 \n16 age_cat15-19         238   299    0.99        0.8          1.24      0.96\n17 age_cat20-29         345   448    1.03        0.84         1.26      0.79\n18 age_cat30-49         228   307    1.07        0.85         1.33      0.58\n19 age_cat50-69          35    30    0.68        0.41         1.13      0.13\n20 age_cat70+             3     2    0.53        0.07         3.2       0.49\n# ℹ 4 more variables: mv_or &lt;dbl&gt;, mvv_ci_low &lt;dbl&gt;, mv_ci_high &lt;dbl&gt;,\n#   mv_pval &lt;dbl&gt;",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html#forest-plot",
    "href": "new_pages/regression.fr.html#forest-plot",
    "title": "19  Régression univariée et multivariable",
    "section": "19.5 Forest plot",
    "text": "19.5 Forest plot\nCette section montre comment produire un graphique avec les résultats de votre régression. Il y a deux options, vous pouvez construire un graphique vous-même en utilisant ggplot2 ou utiliser un méta-package appelé easystats (un package qui inclut plusieurs packages). méta-package appelé easystats (un package qui inclut plusieurs packages).\nConsultez la page sur Les bases de ggplot si vous n’êtes pas familier avec le package de traçage ggplot2.\n\n\nggplot2 package\nVous pouvez construire un graphique forest avec ggplot() en traçant les éléments des résultats de la régression multivariable. Ajoutez les couches des tracés en utilisant ces “geoms” :\n\nestimations avec geom_point()\n\nintervalles de confiance avec “geom_errorbar()`”.\n\nune ligne verticale à OR = 1 avec geom_vline().\n\nAvant de tracer un graphique, vous pouvez utiliser fct_relevel() du package forcats pour définir l’ordre des variables/niveaux sur l’axe des ordonnées. ggplot() peut les afficher dans l’ordre alpha-numérique, ce qui ne fonctionnerait pas bien pour ces valeurs de catégories d’âge (“30” apparaîtrait avant “5”). Voir la page sur les facteurs pour plus de détails.\n\n## enlever le terme intercept dans le resultats multivariables\nmv_tab_base %&gt;% \n  \n  #definir l'odre d'apparition des niveaux  le long de l'axe y \n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %&gt;%\n  \n  # supprimer la ligne denommé \"intercept\" dans le graphique\n  filter(term != \"(Intercept)\") %&gt;% \n  \n  ## concevoir un graphe avec la variable sur l'axe des y et l'estimation (OR) sur l'axe des x\n  \n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## montrer  estimate  comme un point\n  geom_point() + \n  \n  ## ajouter une barre d'erreur pour les intervalles de confiance\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## montrer où OR = 1 est pour référence comme une ligne pointillée\n  geom_vline(xintercept = 1, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nPackages easystats\nUne alternative, si vous ne voulez pas le bon niveau de contrôle que ggplot2 fournit, est d’utiliser une combinaison des packages easystats.\nLa fonction model_parameters() du package parameters fait l’équivalent de la fonction du package broom. de la fonction tidy() du package broom. Le package see accepte alors ces sorties et crée un graphique forest par défaut sous la forme d’un objet ggplot().\n\npacman::p_load(easystats)\n\n## supprimer le terme interception de vos résultats multivariables\nfinal_mv_reg %&gt;% \n  model_parameters(exponentiate = TRUE) %&gt;% \n  plot()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.fr.html#ressources",
    "href": "new_pages/regression.fr.html#ressources",
    "title": "19  Régression univariée et multivariable",
    "section": "19.6 Ressources",
    "text": "19.6 Ressources\nLe contenu de cette page a été alimenté par ces ressources et vignettes en ligne :\nLinear regression in R\ngtsummary\nUCLA stats page\nsthda stepwise regression",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Régression univariée et multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html",
    "href": "new_pages/missing_data.fr.html",
    "title": "20  Données manquantes",
    "section": "",
    "text": "20.1 Étapes préliminaires",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#étapes-préliminaires",
    "href": "new_pages/missing_data.fr.html#étapes-préliminaires",
    "title": "20  Données manquantes",
    "section": "",
    "text": "Importation des paquets\nCes lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,           # import des fichiers\n  tidyverse,     # gestion des données + graphiques (ggplot2)\n  naniar,        # bilan des données manquantes\n  mice           # imputation\n)\n\n\n\nImportation des données\nNous importons un jeu de données de cas d’une épidémie d’ébola fictive. Pour reproduire les étapes, cliquez pour télécharger la linelist “propre” (as .rds file). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation des données pour plus de détails).\n\n# importer la linelist dans R\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes cinquantes premières lignes sont affichées ci-dessous :\n\n\n\n\n\n\n\n\nConversion des données manquantes lors de l’import\nIl faut être particulièrement attentif aux valeurs qui doivent être classifiées comme “manquantes” lors de l’import des données. Des données manquantes peuvent par exemple être indiquées par 99, 999, “Manquant”, un espace vide (” “) ou des cellules vides (”“). Vous pouvez les convertir en NA via la fonction d’importation des données.\nPour plus de détails, consultez la page sur l’importation des Données manquantes, car la syntaxe exacte varie selon le type de fichier.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#valeurs-manquantes-dans-r",
    "href": "new_pages/missing_data.fr.html#valeurs-manquantes-dans-r",
    "title": "20  Données manquantes",
    "section": "20.2 Valeurs manquantes dans R",
    "text": "20.2 Valeurs manquantes dans R\nNous explorons ci-dessous les façons dont les données manquantes sont représentées et évaluées dans R.\n\nNA\nEn R, les valeurs manquantes sont représentées par un mot réservé (spécial) : NA (pour “Non available”). Notez que ce mot est tapé sans guillemets, et ne doit pas être confondu avec une chaîne de caractères “NA” (également une parole des Beatles de la chanson Hey Jude).\nLes données manquantes peuvent avoir été encodées de divers manières dans les données brutes, telles que “99”, “Manquant”, “Inconnu”, une valeur de caractère vide “” qui ressemble à un “blanc”, ou un espace simple ” “. Tenez-en compte et réfléchissez à l’opportunité de les convertir en NA pendant l’importation ou pendant le nettoyage des données avec na_if().\nA l’inverse, lors du nettoyage des données, il peut également être pertinent de convertir des NA en “Manquant” (ou autre) avec les fonctions replace_na() ou fct_explicit_na() dans le cas des facteurs.\n\n\nNA et ses dérivés\nLa plupart du temps, NA représente une valeur manquante et il n’y a pas besoin de se poser plus de questions que ça. Cependant, dans certaines circonstances, il peut y avoir besoin de variations de NA spécifiques à une classe d’objet (caractère, numérique, etc.). C’est rare, mais ça peut arriver.\nParmi ces cas rares, la création d’une nouvelle colonne avec la fonction dplyr case_when() est le plus commun. Comme décrit dans la page Nettoyage des données et fonctions de base, cette fonction évalue chaque ligne du dataframe, détermine si les lignes répondent à des critères logiques spécifiés (partie droite du code), et attribue la nouvelle valeur correcte (partie gauche du code). Important : toutes les valeurs du côté droit doivent être de la même classe.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # Créer une nouvelle colonne \"age_years\" à partir de la colonne \"age\"\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,    # si l'unité est années =&gt; garder la valeur originale\n    age_unit == \"months\" ~ age/12, # l'unité est en mois, diviser par 12\n    is.na(age_unit)      ~ age,    # si l'unité est manquante, supposer que l'age est en années\n    TRUE                 ~ NA_real_)) # sinon, définir age comme valeur manquante\n\nAfin que toutes les valeurs spécifiées du côté droit des équations aient le même type, il faut utiliser des dérivés de NA avec un type connu. Si les autres valeurs de droite sont des chaines de caractères, on peut utiliser NA_character_ ou envisager d’utiliser “Manquant” à la place. Si les valeurs sont toutes numériques, utiliser NA_real_. S’il s’agit de dates ou de valeurs logiques, on peut conserver NA.\n\nNA - à utiliser pour les dates ou les booléens VRAI/FAUX\n\nNA_character_ - à utiliser pour les chaines de caractères\n\nNA_real_ - pour les valeurs numériques\n\nEncore une fois, il est peu probable que vous rencontriez ces variations, hors utilisation de case_when() pour créer une nouvelle colonne. Consultez la documentation R sur NA pour plus d’informations.\n\n\nNULL\nNULL est un autre mot réservée en R. C’est la représentation logique d’une déclaration qui n’est ni vraie ni fausse. Elle est retournée par des expressions ou des fonctions dont les valeurs sont indéfinies. En général, n’assignez pas NULL comme valeur, à moins d’écrire des fonctions ou peut-être une shiny app pour retourner NULL dans des scénarios spécifiques.\nLa nullité peut être évaluée avec is.null() et la conversion peut être faite avec as.null().\nVoir cet article de blog sur la différence entre NULL et NA.\n\n\nNaN\nLes valeurs impossibles sont représentées par le mot spécial NaN. Par exemple, R renvoi NaN si vous lui demandez de diviser 0 par 0. NaN peut être évalué avec is.nan(). Il existe également des fonctions complémentaires comme is.infinite() et is.finite().\n\n\nInf\nInf représente une valeur infinie, telle que l’on peut par exemple obtenir en divisant un nombre par zéro.\n\n\nExemples\nPour comprendre comment ce type de valeurs peuvent affecter vos analyses, imaginons que vous avez un vecteur z qui contient ces valeurs : z &lt;- c(1, 22, NA, Inf, NaN, 5).\nSi vous voulez utiliser la fonction max() sur la colonne pour trouver la valeur la plus élevée, vous pouvez utiliser le na.rm = TRUE pour omettre le NA du calcul. Mais cela n’enlèvera pas les Inf et NaN, ce qui fait que le résultat retourné sera Inf. Pour résoudre ce problème, vous pouvez utiliser les crochets [ ] et is.finite() pour effectuer un sous-ensemble de sorte que seules les valeurs finies soient utilisées pour le calcul : max(z[is.finite(z)]).\n\nz &lt;- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # retourne NA\nmax(z, na.rm=T)                  # retourne Inf\nmax(z[is.finite(z)])             # retourne 22\n\n\n\n\n\n\n\n\nInstruction R\nSortie\n\n\n\n\n5 / 0\nInf\n\n\n0 / 0\nNaN\n\n\n5 / NA\nNA\n\n\n5 / Inf |0NA - 5|NAInf / 5|Infclass(NA)| \"logical\"class(NaN)| \"numeric\"class(Inf)| \"numeric\"class(NULL)`\n“NULL”\n\n\n\nUn message d’avertissement que vous rencontrerez certainement est “NAs introduits par coercition”. Cela peut se produire si vous tentez d’effectuer une conversion illégale, par exemple en insérant une chaîne caractères dans un vecteur qui contient des valeurs numériques.\n\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))\n\nWarning: NAs introduced by coercion\n\n\n[1] 10 20 NA 40\n\n\nNote : NULL est ignoré dans un vecteur.\n\nmy_vector &lt;- c(25, NA, 10, NULL)  # définit\nmy_vector                         # affiche\n\n[1] 25 NA 10\n\n\nNote : tenter de calculer la variance sur une valeur unique retourne également un NA.\n\nvar(22)\n\n[1] NA",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#fonctions-utiles",
    "href": "new_pages/missing_data.fr.html#fonctions-utiles",
    "title": "20  Données manquantes",
    "section": "20.3 Fonctions utiles",
    "text": "20.3 Fonctions utiles\nVoici quelques fonctions utiles en base R pour détecter et gérer les valeurs manquantes.\n\nis.na() et !is.na()\nis.na() permet d’identifier les valeurs manquantes. Pour identifier les valeurs non manquantes il suffit d’utiliser son opposé en ajoutant ! devant l’instruction. Ces deux méthodes retournent une valeur logique (TRUE ou FALSE). Pour rappel, il est possible de sommer le vecteur résultant avec sum() pour compter le nombre de TRUE. Par exemple : sum(is.na(linelist$date_outcome)).\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n\n!is.na(my_vector)\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\nsum(is.na(my_vector))\n\n[1] 2\n\n\n\n\nna.omit()\nAppliquée à un dataframe, cette fonction de base R supprimera les lignes dont toutes les valeurs sont manquantes. Appliquée à un vecteur, elle supprimera les valeurs NA de ce vecteur. Par exemple :\n\nna.omit(my_vector)\n\n[1]  1  4 56  5 22\nattr(,\"na.action\")\n[1] 4 6\nattr(,\"class\")\n[1] \"omit\"\n\n\n\n\ndrop_na()\nIl s’agit d’une fonction de tidyr utile pour nettoyer des données dans un pipeline. Si elle est exécutée sans argument, elle supprime également les lignes dont toutes les valeurs sont manquantes. Mais si des noms de colonnes sont spécifiés comme arguments, seules les lignes avec des valeurs manquantes dans ces colonnes seront supprimées.\nNote : on peut utiliser la syntaxe “tidyselect” pour spécifier les colonnes.\n\nlinelist %&gt;% \n  drop_na(case_id, date_onset, age) # omet les lignes contenant des valeurs manquantes dans une de ces colonnes au moins\n\n\n\nna.rm = TRUE\nLorsque vous exécutez une fonction mathématique telle que max(), min(), sum() ou mean(), la valeur retournée est NA si des valeurs NA sont présentes dans les données. Ce comportement par défaut est intentionnel, afin que vous soyez alerté si l’une de vos données est manquante.\nVous pouvez éviter cela en supprimant les valeurs manquantes du calcul. Pour ce faire, incluez l’argument na.rm = TRUE (le “rm” étant une abréviation de “remove”).\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     \n\n[1] NA\n\nmean(my_vector, na.rm = TRUE)\n\n[1] 17.6",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#identifier-les-valeurs-manquantes-dans-un-dataframe",
    "href": "new_pages/missing_data.fr.html#identifier-les-valeurs-manquantes-dans-un-dataframe",
    "title": "20  Données manquantes",
    "section": "20.4 Identifier les valeurs manquantes dans un dataframe",
    "text": "20.4 Identifier les valeurs manquantes dans un dataframe\nLe package naniar permet de détecter et de visualiser l’ampleur de la complétude des données (et donc de leur non-complétude) dans un tableau de données.\n\n# installer et charger le paquet\npacman::p_load(naniar)\n\n\nQuantifier les données manquantes\nLa fonction pct_miss() permet de calculer le pourcentage de toutes les valeurs manquantes. La fonction n_miss() renvoi le nombre de valeurs manquantes.\n\n# pourcentage de données manquantes sur TOUTES les valeurs du dataframe\npct_miss(linelist)\n\n[1] 6.688745\n\n\nLes deux fonctions ci-dessous renvoient le pourcentage de lignes dont une valeur est manquante ou qui sont entièrement complètes.\nNote : NA signifie manquant, mais que `\"\" ou \"\" ne sont pas considérées comme des valeurs manquantes.\n\n# Pourcentage des lignes avec au moins une valeur manquante\npct_miss_case(linelist)   # utiliser n_miss() pour le nombre de lignes\n\n[1] 69.12364\n\n\n\n# Pourcentage des lignes sans valeur manquante\npct_complete_case(linelist) # utiliser n_complete() pour le nombre\n\n[1] 30.87636\n\n\n\n\nVisualiser les données manquantes\nLa fonction gg_miss_var() renvoi le nombre (ou %) de valeurs manquantes dans chaque colonne. Quelques notes :\n\nIl est possible d’ajouter un nom de colonne (pas entre guillemets) à l’argument facet = pour voir le graphique par groupe.\nLes nombres sont affichés par défaut. Utilisez show_pct = TRUE pour voir les pourcentages, .\nIl est possible d’ajouter des étiquettes d’axe et de titre comme pour un ggplot() normal avec + labs(...).\n\n\ngg_miss_var(linelist, show_pct = TRUE)\n\n\n\n\n\n\n\n\nIci, les données sont passées à la fonction à l’aide d’un pipe %&gt;%. L’argument facet = est utilisé pour séparer les données par outcome.\n\nlinelist %&gt;% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n\n\n\n\n\n\n\n\nLa fonction vis_miss() permet de visualiser le dataframe sous forme de carte thermique qui indique quelle valeur est manquante. Vous pouvez également select() certaines colonnes du cadre de données et ne fournir que ces colonnes à la fonction.\n\n# Carte thermique de la complétude des données à l'échelle du dataframe\nvis_miss(linelist)\n\n\n\n\n\n\n\n\n\n\nExplorer et visualiser les relations entre données manquantes\nComment visualiser quelque chose qui n’existe pas ??? Par défaut, ggplot() n’affiche pas les points avec des valeurs manquantes dans les graphiques.\nLe package naniar propose une solution via la fonction geom_miss_point(). Lors de la création d’un nuage de points à partir de deux variables, les paires de valeurs dont l’une est manquante sont montrés en fixant les valeurs manquante à 10% plus bas que la valeur minimale de la colonne, et en les colorant différemment.\nDans le nuage de points ci-dessous, les points rouges sont des enregistrements où la valeur d’une des deux colonne est présente mais où l’autre est manquante. Cela permet de visualiser la distribution des valeurs manquantes par rapport à celle des valeurs non manquantes.\n\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\n\n\n\n\n\n\n\n\nPour évaluer les données manquantes dans un dataframe en stratifiant par une autre colonne, on peut utiliser la fonction gg_miss_fct(), qui retourne une carte thermique du pourcentage de valeurs manquantes dans le dataframe pour chaque catégorie d’une autre variable :\n\ngg_miss_fct(linelist, age_cat5)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat5 = (function (x) ...`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\nℹ The deprecated feature was likely used in the naniar package.\n  Please report the issue at &lt;https://github.com/njtierney/naniar/issues&gt;.\n\n\n\n\n\n\n\n\n\nCette fonction peut aussi être utilisée sur une colonne contenant des dates pour voir comment la complétude des données change au cours du temps :\n\ngg_miss_fct(linelist, date_onset)\n\nWarning: Removed 29 rows containing missing values or values outside the scale range\n(`geom_tile()`).\n\n\n\n\n\n\n\n\n\n\n\nColonnes “fantômes”\nnaniar donne la possibilité de créer un jeu de données “fantôme” (“shadow matrix” en Anglais) pour aller plus loin dans l’étude de la distribution des données manquantes. Essentiellement, pour chaque colonne existante la fonction bind_shadow() crée une nouvelle colonne binaire contenant soit NA, soit !NA (pour “non NA”), et lie toutes ces nouvelles colonnes au jeu de données original avec l’appendice “_NA”. Cela double le nombre de colonnes du jeu de données :\n\nshadowed_linelist &lt;- linelist %&gt;% \n  bind_shadow()\n\nnames(shadowed_linelist)\n\n [1] \"case_id\"                 \"generation\"             \n [3] \"date_infection\"          \"date_onset\"             \n [5] \"date_hospitalisation\"    \"date_outcome\"           \n [7] \"outcome\"                 \"gender\"                 \n [9] \"age\"                     \"age_unit\"               \n[11] \"age_years\"               \"age_cat\"                \n[13] \"age_cat5\"                \"hospital\"               \n[15] \"lon\"                     \"lat\"                    \n[17] \"infector\"                \"source\"                 \n[19] \"wt_kg\"                   \"ht_cm\"                  \n[21] \"ct_blood\"                \"fever\"                  \n[23] \"chills\"                  \"cough\"                  \n[25] \"aches\"                   \"vomit\"                  \n[27] \"temp\"                    \"time_admission\"         \n[29] \"bmi\"                     \"days_onset_hosp\"        \n[31] \"case_id_NA\"              \"generation_NA\"          \n[33] \"date_infection_NA\"       \"date_onset_NA\"          \n[35] \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n[37] \"outcome_NA\"              \"gender_NA\"              \n[39] \"age_NA\"                  \"age_unit_NA\"            \n[41] \"age_years_NA\"            \"age_cat_NA\"             \n[43] \"age_cat5_NA\"             \"hospital_NA\"            \n[45] \"lon_NA\"                  \"lat_NA\"                 \n[47] \"infector_NA\"             \"source_NA\"              \n[49] \"wt_kg_NA\"                \"ht_cm_NA\"               \n[51] \"ct_blood_NA\"             \"fever_NA\"               \n[53] \"chills_NA\"               \"cough_NA\"               \n[55] \"aches_NA\"                \"vomit_NA\"               \n[57] \"temp_NA\"                 \"time_admission_NA\"      \n[59] \"bmi_NA\"                  \"days_onset_hosp_NA\"     \n\n\nCes colonnes “fantômes” peuvent être utilisées pour visualiser la proportion de valeurs manquantes dans une colonne en fonction d’une autre colonne.\nPar exemple, le graphique ci-dessous montre la proportion de données manquantes dans la colonne days_onset_hosp (le nombre de jours entre l’apparition des symptômes et l’hospitalisation), en fonction de la date_hospitalisation. Ici on trace la densité de données manquantes et non manquantes (color =) en fonction de la date d’hospitalisation.\nCe type de visualisation fonctionne mieux si la variable tracée en sur l’axe des abscisses est numérique ou temporelle.\n\nggplot(data = shadowed_linelist,   # dataframe augmenté avec les colonnes fantômes\n  mapping = aes(x = date_hospitalisation, # colonne numérique ou date\n                colour = age_years_NA)) + # colonne fantôme d'intérêt\n  geom_density()                          # trace les courbes de densité\n\n\n\n\n\n\n\n\nLes colonnes fantômes peuvent aussi être utilisé comme stratification dans des statistiques descriptives :\n\nlinelist %&gt;%\n  bind_shadow() %&gt;%                # création des colonnes fantômes\n  group_by(date_outcome_NA) %&gt;%    # groupe par la colonne fantôme de date_outcome\n  summarise(across(\n    .cols = age_years,             # variable d'intérêt à résumer\n    .fns = list(\"mean\" = mean,     # statistiques\n                \"sd\"  = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # autres arguments des fonctions statistiques\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `date_outcome_NA = !NA`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 2 × 6\n  date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min\n  &lt;fct&gt;                    &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 !NA                       16.0         12.6          158.             0\n2 NA                        16.2         12.9          167.             0\n# ℹ 1 more variable: age_years_max &lt;dbl&gt;\n\n\nnaniar n’est pas le seul outil pour représenter la proportion de valeurs manquantes dans une colonne en fonction du temps. On peut aussi manuellement :\n\nAgréger les données dans une unité de temps pertinente (jours, semaines, etc.), en résumant la proportion d’observations avec NA (et toute autre valeur d’intérêt).\nTracez la proportion de données manquantes comme une ligne en utilisant ggplot().\n\nDans l’exemple ci-dessous, nous ajoutons une nouvelle colonne pour la semaine à la linelist, regroupons les données par semaine, puis calculons le pourcentage des enregistrements de cette semaine où la valeur est manquante. (note : si vous voulez le % de 7 jours, le calcul sera légèrement différent).\n\noutcome_missing &lt;- linelist %&gt;%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %&gt;%   # crée colonne semaine\n  group_by(week) %&gt;%      # groupe les lignes par semaine\n  summarise(              # pour chaque semaine, résumme : \n    n_obs = n(),          # nombre total d'observations\n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),  # nombre d'obs avec valeur manquante\n    outcome_p_miss  = outcome_missing / n_obs,    # proportion d'obs avec valeur manquante\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),     # nb de morts\n    outcome_p_dead  = outcome_dead / n_obs) %&gt;%             # prop morts\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %&gt;%    # pivote toutes les colonnes sauf la semaine en format long\n  filter(stringr::str_detect(statistic, \"_p_\"))   # garde uniquement les proportions\n\nEnsuite, nous traçons la proportion de données manquantes par semaine, sous forme de ligne.\nRéférez vous à la page bases de ggplot si vous n’êtes pas familier avec le package ggplot2.\n\nggplot(data = outcome_missing) +\n    geom_line(\n      mapping = aes(x = week, \n                    y = value, \n                    group = statistic, \n                    color = statistic),\n      size = 2,\n      stat = \"identity\") +\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\")) +\n    scale_y_continuous(breaks = c(seq(0, 1, 0.1))) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#utiliser-des-données-avec-des-valeurs-manquantes",
    "href": "new_pages/missing_data.fr.html#utiliser-des-données-avec-des-valeurs-manquantes",
    "title": "20  Données manquantes",
    "section": "20.5 Utiliser des données avec des valeurs manquantes",
    "text": "20.5 Utiliser des données avec des valeurs manquantes\n\nFiltrer les lignes avec valeurs manquantes\nLa fonction drop_na() de dplyr permet de se débarrasser rapidement des lignes avec des valeurs manquantes.\nLa linelist originale contient nrow(linelist) lignes. La linelist sans lignes avec des valeurs manquantes contient moins de lignes :\n\nlinelist %&gt;% \n  drop_na() %&gt;%     # filtre les lignes sans aucune valeur manquante\n  nrow()\n\n[1] 1818\n\n\nOn peut choisir de ne se débarrasser des lignes avec des valeurs manquantes que dans certaines colonnes :\n\nlinelist %&gt;% \n  drop_na(date_onset) %&gt;% # omet les lignes avec des valeurs manquantes dans date_onset\n  nrow()\n\n[1] 5632\n\n\nOn peut passer plusieurs colonnes l’une après l’autre à la fonction, ou utiliser des fonctions utilitaires de “tidyselect”:\n\nlinelist %&gt;% \n  drop_na(contains(\"date\")) %&gt;% # omet lignes avec NA dans n'importe quelle colonne dont le nom contient \"date\"\n  nrow()\n\n[1] 3029\n\n\n\n\n\nGérer les NA dans ggplot()\nIl est souvent judicieux de signaler le nombre de valeurs exclues d’un graphique au lecteur du graphique.\nDans ggplot(), la fonction labs()a un argument caption = qui ajoute un texte de légende sous le graphique. On peut utiliser str_glue() du package stringr pour concaténer valeurs et chaînes de caractères ensemble dans une phrase qui s’ajuste automatiquement aux données (voir exemple ci-dessous).\n\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} du Central Hospital;\n  {nrow(central_data %&gt;% filter(is.na(date_onset)))} cas sans date de début des symptomes et non représentés\"))  \n\nNotes :\n* l’utilisation de \\n pour aller à la ligne.\n* si plusieurs colonnes contribuent à ce que des valeurs ne soient pas affichées (par exemple, l’âge ou le sexe si ceux-ci sont reflétés dans le graphique), il faut également filtrer sur ces colonnes pour calculer correctement le nombre de valeurs non affichées. * on peut sauvegarder la chaîne de caractères en tant qu’objet dans des commandes antérieures à la commande ggplot(), et simplement la référencer dans la str_glue().\n\n\n\nNA dans les facteurs\nSi votre colonne d’intérêt est un facteur, utilisez fct_explicit_na() du package forcats pour convertir les valeurs NA en une chaîne de caractères (plus de détails dans la page Facteurs. Par défaut, la nouvelle valeur est “(Missing)” mais cela peut être ajusté via l’argument na_level =.\n\npacman::p_load(forcats)   # charge le package\n\nlinelist &lt;- linelist %&gt;% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)\n\n[1] \"f\"       \"m\"       \"Missing\"",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#imputation",
    "href": "new_pages/missing_data.fr.html#imputation",
    "title": "20  Données manquantes",
    "section": "20.6 Imputation",
    "text": "20.6 Imputation\nLors de certaines analyses de données, il est nécessaire de “combler les lacunes” et d’imputer les données manquantes. En effet, s’il est souvent possible d’analyser un jeu de données après en avoir supprimé toutes les valeurs manquantes, cela peut néanmoins poser des problèmes à plusieurs égards. Voici deux exemples :\n\nSupprimer toutes les observations avec des valeurs manquantes, ou les variables avec beaucoup de données manquantes peut réduire considérablement la puissance et la capacité à effectuer certains types d’analyse. Par exemple, nous avons vu que seule une faible fraction des lignes de notre linelist ne comporte aucune donnée manquante. Si nous supprimions toutes les lignes contenant au moins une donnée manquante, nous perdrions beaucoup d’informations ! De plus, la plupart de nos variables comportent une certaine quantité de données manquantes - pour la plupart des analyses, il n’est probablement pas raisonnable de toutes les éliminer.\nSelon la raison pour laquelle vos données sont manquantes, l’analyse des données non manquantes seules peut conduire à des biais et des résultats trompeurs. Par exemple, nous avons vu que de nombreux patients ont des données manquantes dans les colonnes concernant des symptômes importants, comme la fièvre ou la toux. Il est possible que cette information n’ait pas été enregistrée pour les personnes qui ne paraissaient pas sévèrement malades. Dans ce cas, si nous supprimions simplement ces observations, nous exclurions une partie des patients en meilleure santé de notre analyse, ce qui pourrait vraiment biaiser les résultats.\n\nIn ne suffit pas seulement d’estimer la quantité de données manquantes, il est également capital de réfléchir à la raison pour laquelle les données peuvent manquer. Cela va guider vos choix quant à l’importance de l’imputation des données manquantes, ainsi que de la méthode d’imputation la plus appropriée à votre situation.\n\nTypes de données manquantes\nVoici les trois grands types de données manquantes, qui correspondent à des mécanismes différents de non-réponse :\n\nDonnées manquantes de manière complètement aléatoire (MMCA) (on trouvera souvent l’acronyme anglais MCAR, pour “Missing Completely at Random”). Dans ce cas, il n’y a pas de relation entre la probabilité de manquer et les autres variables de vos données (ou avec des variables non mesurées). La probabilité d’être manquante est la même pour tous les cas. C’est une situation rare. Néanmoins, si vous avez de bonnes raisons de penser que vos données sont MMCA, l’analyse des données non manquantes (sans imputation) ne faussera pas les résultats (malgré une possible perte de puissance).\nDonnées manquantes aléatoirement (MA, ou MAR en Anglais pour “Missing at Random”. Ce nom est en fait un peu trompeur car MA signifie que les données sont manquantes de manière systématique et prévisible en fonction d’autres variables mesurées. Par exemple, dans notre cas, les docteurs auraient pu considérer que les patients présentant des frissons et des courbatures ont nécessairement de la fièvre, et n’ont pas pris leur température. Cela aboutit à des observations manquantes dans la colonne fièvre, aisément prévisibles grâce aux colonnes frissons et courbatures. Si c’est vrai, nous pourrions facilement prédire que chaque observation manquante avec des frissons et des courbatures a également de la fièvre et utiliser cette information pour imputer nos données manquantes. Dans la pratique, c’est souvent plus compliqué: si un patient présente à la fois des frissons et des courbatures, il est probable qu’il ait également de la fièvre, mais pas toujours. Les données MA sont prévisibles, mais la prédiction n’est jamais parfaite. Il s’agit d’un type très courant de données manquantes\nDonnées manquantes par omission prévisible (MOP) aussi appelées Données manquantes non aléatoirement (MNAR ou NMAR en Anglais, pour “Missing not at Random” ou “Not Missing at Random”). Dans ce cas, la probabilité qu’une valeur soit manquante n’est PAS systématique ou prévisible à l’aide des autres informations dont nous disposons, mais elle n’est pas non plus manquante au hasard. Les données manquent pour des raisons inconnues, sur lesquelles vous n’avez aucune information. La valeur de la variable manquante est liée à la raison pour laquelle elle est manquante. Par exemple, dans nos données, l’age du patient peut manquer parce que certains patients très âgés ne savent pas ou refusent de dire quel âge ils ont. Dans cette situation, les données manquantes sur l’âge sont liées à la valeur elle-même, ne sont donc pas aléatoires ni prévisibles sur la base des autres informations dont nous disposons. Ce mécanisme de non-réponse est non-ignorable, complexe et souvent, la meilleure façon d’y faire face est d’essayer de collecter plus de données ou d’informations sur la raison pour laquelle les données sont manquantes plutôt que de tenter de les imputer.\n\nEn général, imputer des données MA est relativement simple, mais imputer des données MOP est complexe, difficile et souvent impossible. La plupart des méthodes d’imputation les plus répandues font l’hypothèse que les données sont de type MA.\n\n\nPackages utiles\nVoici un certain nombre de packages utiles pour l’imputation des données : Mmisc, missForest (qui utilise les forêts aléatoires pour imputer les données manquantes) et mice (Multivariate Imputation by Chained Equations). Dans cette section, nous nous focaliserons sur le paquet mice, qui met en œuvre diverses techniques. Le responsable du paquet mice a publié un livre détaillé accessible en ligne gratuitement sur l’imputation des données manquantes.\nVoici le code pour charger le paquetage mice :\n\npacman::p_load(mice)\n\n\n\nImputation par la moyenne\nParfois, dans le cas d’analyses simples ou s’il y a de bonnes raisons de penser que que les données sont de type MA, il est possible de simplement remplacer les valeurs manquantes d’une variable par la moyenne de cette variable. Par exemple, nous pourrions avoir de bonnes raisons de penser que les mesures de température manquantes dans nos données étaient MA ou normales. Voici le code permettant de créer une nouvelle variable qui remplace les valeurs de température manquantes par la valeur de température moyenne de notre ensemble de données.\nIl faut rester prudent, car dans de nombreuses situations, le remplacement des données manquantes par la moyenne peut entraîner un biais.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\n\nOn peut procéder de la même manière pour remplacer des données catégoriques par une valeur spécifique. Dans nos données, imaginez que vous sachiez que toutes les observations pour lesquelles il manque une valeur de décharge (qui peut être “Décès” ou “Guéri”) sont en fait des personnes décédées (remarque : ce n’est pas réellement vrai pour cet ensemble de données).\n\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))\n\n\n\nImputation par régression\nUne méthode un peu plus avancée consiste à utiliser un modèle statistique pour prédire les valeurs manquantes et les remplacer. Par exemple, on pourrait imaginer utiliser une régression linéaire simple avec l’état de la fièvre et l’age pour prédire la température lorsque celle-ci est manquante. Dans la vie réelle, il vaut mieux utiliser des modèles plus avancés qu’une approche aussi simple.\n\nsimple_temperature_model_fit &lt;- lm(temp ~ fever + age_years, \n                                   data = linelist)\n\n# Nous utilisons un modèle linéaire simple avec la température comme variable réponse pour prédire les valeurs de température manquantes\npredictions_for_missing_temps &lt;- predict(simple_temperature_model_fit,\n                                         newdata = linelist %&gt;%\n                                              filter(is.na(temp))) \n\nOn peut utiliser la même approche d’imputation par régression avec le package mice pour imputer les les observations de température manquantes :\n\nmodel_dataset &lt;- linelist %&gt;%\n  select(temp, fever, age_years)  \n\ntemp_imputed &lt;- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = FALSE)\n\nWarning: Number of logged events: 1\n\ntemp_imputed_values &lt;- temp_imputed$imp$temp\n\nIl est possible d’utiliser des modèles plus avancés que la régression linéaire simple pour prédire les valeurs manquantes à l’aide d’autres variables. Par exemple, le package missForest utilise les forêts aléatoires pour prédire les valeurs des données manquantes.\nQuel que soit le modèle statistique utilisé pour modéliser les valeurs manquantes, il faut se rappeler que cette approche fonctionne bien avec des données MMCA, mais il faut être très prudent si vous pensez que vos données sont de type MA ou MOP.\nLa qualité de l’imputation dépend de la qualité du modèle de prédiction et même avec un très bon modèle, la variabilité de vos données imputées peut être sous-estimée.\n\n\nReport de la dernière observation et baseline\nLorsque l’on a des données longitudinales ou des séries temporelles, il est parfois pertinent d’utiliser des méthodes d’imputations basées sur le report de la dernière valeur connue (LOCF, pour “Last Observation Carried Forward”) ou le report de la valeur “baseline” (BOCF pour “Baseline Observation Carried Forward”). Concrètement, il s’agit d’utiliser une valeur observée dans le passé et de l’utiliser comme remplacement des données manquantes. Dans le cas de l’imputation LOCF, si plusieurs valeurs sont manquantes à la suite, il faut remonter à la dernière observation non manquante pour ce patient.\nLa fonction fill() du package tidyr peut être utilisée pour l’imputation LOCF et BOCF (mais d’autres packages tels que HMISC, zoo, et data.table peuvent aussi être utilisés). Pour illustrer la syntaxe de fill(), nous allons créer un simple ensemble de données de séries temporelles contenant le nombre de cas d’une maladie pour chaque trimestre des années 2000 et 2001. Cependant, la valeur de l’année pour les trimestres postérieurs à Q1 est manquante et nous devrons donc les imputer. La jonction fill() est également démontrée dans la page Restructurer les données.\n\n# Création d'un jeu de données\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n# Imputation ds données manquantes pour l'année (vers le bas par défaut)\ndisease %&gt;% fill(year)\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nNote : il faut que les données soient correctement triées avant d’utiliser la fonction fill()! Par défaut, la fonction fill() remplit les données vers le bas, mais il est possible d’imputer des valeurs dans différentes directions à l’aide du paramètre .direction. Si nous créons un jeu de données similaire où la valeur de l’année est enregistrée uniquement à la fin de l’année et manquante pour les trimestres précédents :\n\n# Création d'un jeu de données\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n# Imputation des données de l'année \"vers le haut\"\ndisease %&gt;% fill(year, .direction = \"up\")\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nDans cet exemple, l’imputation avec les méthodes LOCF et BOCF sont clairement les solutions les plus adaptée. Néanmoins, dans des situations plus complexes, il peut être difficile de décider si ces méthodes sont appropriées ou non. Par exemple, vous pouvez avoir des valeurs de laboratoire manquantes pour un patient hospitalisé après le premier jour. Cela pourrait signifier que les valeurs de laboratoire n’ont pas changé… ou que le patient s’est rétabli et donc que ses valeurs seraient très différentes après le premier jour ! Utilisez ces méthodes avec prudence.\n\n\nImputation multiple\nNous n’avons pas la place ici de faire une explication détaillée de l’imputation multiple et de quand l’utiliser. Nous vous réferrons au livre (en ligne et gratuit) écrit par l’auteur du paquet mice et ne présentons ici qu’une explication de base de la méthode :\nL’imputation multiple consiste à créer plusieurs jeux de données dans lesquels les valeurs manquantes sont imputées à des valeurs de données “plausibles”. Dans chacun des jeux de données, chaque valeur imputée est tirée aléatoirement dans une distribution estimée (les données non manquantes restent, elles, intouchées), ce qui crée des jeux de données légèrement différents les uns des autres. La distribution utilisée d’où sont tirée les valeurs imputées vient ici encore d’un modèle statistique prédictif (mice propose de nombreuses options pour les méthodes de prédiction, notamment Predictive Mean Matching, Régression logistique et Forêt aléatoire), mais mice prend en charge de nombreux détails de la modélisation. Ensuite, l’analyse que vous aviez planifiée est effectuée sur chacun des jeux de données, et les paramètres estimés par les modèles sont ensuite poolés et leur variance estimée.\nCette méthode fonctionne très bien pour réduire le biais dans les configurations MMCA et MA et permet souvent d’obtenir des estimations plus précises de l’erreur standard.\nNote : en fonction des données, on peut créer plus ou moins de jeux de données avec les données imputées. Le package mice fixe le nombre par défaut à 5.\nVoici un exemple d’application de l’imputation multiple pour prédire la température dans notre jeu de données de liste linéaire, en utilisant l’age et la présence/absence de fièvre :\n\n# imputation des valurs manquantes pour notre jeu de données modèle, et création de 10 jeux de données imputés : \nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) \n\nWarning: Number of logged events: 1\n\nmodel_fit &lt;- with(multiple_imputation, \n                  lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))\n\n         term     estimate    std.error    statistic        df       p.value\n1 (Intercept) 3.703143e+01 0.0270863456 1.367162e+03  26.83673  1.583113e-66\n2   age_years 3.867829e-05 0.0006090202 6.350905e-02 171.44363  9.494351e-01\n3    feveryes 1.978044e+00 0.0193587115 1.021785e+02 176.51325 5.666771e-159\n\n\nIci, nous avons utilisé la méthode d’imputation par défaut de mice, à savoir “Predictive Mean Matching”. Nous avons ensuite utilisé ces jeux de données imputées pour estimer séparément, puis mettre en commun les résultats de régressions linéaires simples sur chacun de ces ensembles de données.\nIl existe de nombreux détails que nous avons survolés et de nombreux paramètres que vous pouvez ajuster pendant le processus d’imputation multiple en utilisant le package mice. Par exemple, vous n’aurez pas toujours des données numériques et vous devrez peut-être utiliser d’autres méthodes d’imputation (mice permet d’imputer de nombreux types de données, avec de nombreuses méthodes). Mais, pour une analyse plus robuste lorsque les données manquantes constituent un problème important, l’imputation multiple est une bonne solution qui ne demande pas toujours beaucoup plus de travail que l’analyse complète des cas.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.fr.html#resources",
    "href": "new_pages/missing_data.fr.html#resources",
    "title": "20  Données manquantes",
    "section": "20.7 Resources",
    "text": "20.7 Resources\nVignette sur le package naniar\nGalerie de visualisation de données manquantes\nLivre gratuit sur l’imputation multiple par l’auteur et le gestionnaire du package mice",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Données manquantes</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.fr.html",
    "href": "new_pages/standardization.fr.html",
    "title": "21  Taux standardisés",
    "section": "",
    "text": "21.1 Vue d’ensemble\nIl existe deux manières principales de normaliser : la normalisation directe et la normalisation indirecte. Supposons que nous voulions normaliser le taux de mortalité par âge et par sexe pour le pays A et le pays B, et comparer les taux normalisés entre ces pays.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Taux standardisés</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.fr.html#vue-densemble",
    "href": "new_pages/standardization.fr.html#vue-densemble",
    "title": "21  Taux standardisés",
    "section": "",
    "text": "Pour une standardisation directe, vous devrez connaître le nombre de personnes à risque et le nombre de décès pour chaque strate d’âge et de sexe, pour le pays A et le pays B. Une strate dans notre exemple pourrait être les femmes âgées de 15 à 44 ans.\n\nPour une standardisation indirecte, il suffit de connaître le nombre total de décès et la structure d’âge et de sexe de chaque pays. Cette option est donc envisageable si les taux de mortalité ou les chiffres de population par âge et par sexe ne sont pas disponibles. La standardisation indirecte est en outre préférable en cas de petits effectifs par strate, car les estimations en standardisation directe seraient influencées par une variation d’échantillonnage importante.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Taux standardisés</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.fr.html#préparation",
    "href": "new_pages/standardization.fr.html#préparation",
    "title": "21  Taux standardisés",
    "section": "21.2 Préparation",
    "text": "21.2 Préparation\nPour montrer comment se fait la standardisation, nous allons utiliser des comptages fictifs de population et de décès du pays A et du pays B, par âge (en catégories de 5 ans) et par sexe (femme, homme). Pour que les ensembles de données soient prêts à être utilisés, nous allons effectuer les étapes de préparation suivantes :\n\nCharger les paquets\n\nCharger les jeux de données\n\nJoignez les données de population et de décès des deux pays.\nPivoter plus longtemps pour qu’il y ait une ligne par strate âge-sexe.\nNettoyez la population de référence (population standard mondiale) et joignez-la aux données du pays.\n\nDans votre scénario, vos données peuvent se présenter sous un format différent. Peut-être vos données sont-elles présentées par province, ville ou autre zone d’attraction. Vous avez peut-être une ligne pour chaque décès et des informations sur l’âge et le sexe pour chacun (ou une proportion importante) de ces décès. Dans ce cas, consultez les pages sur le Travailler sur des données groupées, Pivoter les données, and Tableaux descriptifs pour créer un ensemble de données avec des comptes d’événements et de population par strate âge-sexe.\nNous avons également besoin d’une population de référence, la population standard. Pour les besoins de cet exercice, nous utiliserons la world_standard_population_by_sex (population standard mondiale par sexe). La population standard mondiale est basée sur les populations de 46 pays et a été développée en 1960. Il existe de nombreuses populations “standard” - à titre d’exemple, le site web de NHS Scotland est assez informatif sur la population standard européenne, la population standard mondiale et la population standard écossaise.\n\n\nChargement des paquets\nCe chunk de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n     rio, # importer/exporter des données\n     here, # localisation des fichiers\n     stringr, # nettoyage des caractères et des chaînes de caractères\n     frailtypack, # nécessaire pour dsr, pour les modèles de frailty\n     dsr, # standardiser les taux\n     PHEindicatormethods, # alternative pour la standardisation des taux\n     tidyverse) # gestion et visualisation des données\n\n**ATTENTION:_** Si vous avez une version plus récente de R, le paquet dsr ne peut pas être téléchargé directement avec CRAN. Cependant, il est toujours disponible de l’archive CRAN. Vous pouvez installer et utiliser celui-ci. \nPour les utilisateurs non-Mac :\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n\n\n# Autre solution qui peut fonctionner\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\n\nPour les utilisateurs de Mac :\n\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")\n\n\n\nCharger les données de la population\nVoir la page Télécharger le manuel et les données pour savoir comment télécharger tous les exemples de données du manuel. Vous pouvez importer les données de la page de normalisation directement dans R depuis notre dépôt Github en exécutant les commandes import() suivantes :\n\n# importer les données démographiques du pays A directement depuis Github\nA_demo &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics.csv\")\n\n# importer les décès pour le pays A directement depuis Github\nA_deaths &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryA.csv\")\n\n# Importez les données démographiques pour le pays B directement depuis Github.\nB_demo &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics_2.csv\")\n\n# importer les décès pour le pays B directement depuis Github.\nB_deaths &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryB.csv\")\n\n# Importez les données démographiques pour le pays B directement depuis Github.\nstandard_pop_data &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\nTout d’abord, nous chargeons les données démographiques (comptage des hommes et des femmes par catégorie d’âge de 5 ans) pour les deux pays que nous allons comparer, le “pays A” et le “pays B”.\n\n# Pays A\nA_demo &lt;- import(\"country_demographics.csv\")\n\n\n\n\n\n\n\n\n# Pays B\nB_demo &lt;- import(\"country_demographics_2.csv\")\n\n\n\n\n\n\n\n\n\nChargement du nombre de morts\nDe manière pratique, nous disposons également du nombre de décès survenus pendant la période qui nous intéresse, par âge et par sexe. Les chiffres de chaque pays sont dans un fichier séparé, comme indiqué ci-dessous.\nDécès dans le pays A\n\n\n\n\n\n\nDécès dans le pays B\n\n\n\n\n\n\n\n\nNettoyer les populations et les décès\nNous devons joindre et transformer ces données de la manière suivante :\n\nCombiner les populations des pays en un seul ensemble de données et faire un pivot “long” pour que chaque strate âge-sexe soit une ligne.\n\nCombiner le nombre de décès par pays dans un ensemble de données et faire pivoter “long” pour que chaque strate âge-sexe soit une ligne.\n\nJoindre les décès aux populations\n\nTout d’abord, nous combinons les ensembles de données sur les populations des pays, nous effectuons un pivot plus long et un nettoyage mineur. Voir la page Pivoter les données pour plus de détails.\n\npop_countries &lt;- A_demo %&gt;% # Commencez avec l'ensemble de données du pays A\n     bind_rows(B_demo) %&gt;% # lier les lignes, car les colonnes portent le même nom\n     pivot_longer( # pivot plus long\n          cols = c(m, f), # colonnes à combiner en une seule\n          names_to = \"Sex\", # nom de la nouvelle colonne contenant la catégorie (\"m\" ou \"f\") \n          values_to = \"Population\") %&gt;% # nom de la nouvelle colonne contenant les valeurs numériques pivotées\n     mutate(Sex = recode(Sex, # re-code les valeurs pour plus de clarté\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\n\nLes données de population combinées ressemblent maintenant à ceci (cliquez pour voir les pays A et B) :\n\n\n\n\n\n\nEt maintenant, nous effectuons des opérations similaires sur les deux ensembles de données de décès.\n\ndeaths_countries &lt;- A_deaths %&gt;% # Commencez avec l'ensemble de données des décès du pays A\n     bind_rows(B_deaths) %&gt;% # lier les lignes avec l'ensemble de données B, parce que les colonnes sont nommées de manière identique\n     pivot_longer( # pivot plus long\n          cols = c(Male, Female), # colonne à transformer en une seule\n          names_to = \"Sex\", # nom de la nouvelle colonne contenant la catégorie (\"m\" ou \"f\") \n          values_to = \"Deaths\") %&gt;% # nom pour la nouvelle colonne contenant les valeurs numériques pivotées\n     rename(age_cat5 = AgeCat) # renomme pour plus de clarté\n\nLes données de décès ressemblent maintenant à ceci, et contiennent les données des deux pays :\n\n\n\n\n\n\nNous joignons maintenant les données de décès et de population sur la base des colonnes communes Country, age_cat5, et Sex. Cela ajoute la colonne Deaths.\n\ncountry_data &lt;- pop_countries %&gt;% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\n\nNous pouvons maintenant classer Country, age_cat5, et Sex comme facteurs et définir l’ordre des niveaux en utilisant la fonction fct_relevel() du paquet forcats, comme décrit dans la page sur Facteurs. Notez que le classement des niveaux des facteurs ne change pas visiblement les données, mais la commande arrange() les trie par Pays, catégorie d’âge et sexe.\n\ncountry_data &lt;- country_data %&gt;% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %&gt;% \n          \n  arrange(Country, age_cat5, Sex)\n\n\n\n\n\n\n\n**__ATTENTION:_** Si vous avez peu de décès par strate, envisagez d’utiliser des catégories de 10, ou 15 ans, au lieu de catégories de 5 ans pour l’âge.\n\n\nChargement de la population de référence\nEnfin, pour la standardisation directe, nous importons la population de référence (la “population standard” mondiale par sexe).\n\n# Population de référence\nstandard_pop_data &lt;- import(\"world_standard_population_by_sex.csv\")\n\n\n\n\n\n\n\n\n\n\nNettoyer la population de référence\nLes valeurs des catégories d’âge dans les cadres de données country_data et standard_pop_data devront être alignées.\nActuellement, les valeurs de la colonne age_cat5 du cadre de données standard_pop_data contiennent le mot “years” et “plus”, alors que celles du cadre de données country_data ne le font pas. Nous devrons faire correspondre les valeurs des catégories d’âge. Nous utilisons str_replace_all() du paquet stringr, comme décrit dans la page Caractères et chaînes de caractères, pour remplacer ces motifs par des \"\" sans espace.\nDe plus, le paquet dsr s’attend à ce que dans la population standard, la colonne contenant les comptes soit appelée \"pop\". Nous renommons donc cette colonne en conséquence.\n\n# Suppression d'une chaîne spécifique des valeurs de la colonne\nstandard_pop_clean &lt;- standard_pop_data %&gt;%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"), # supprime \"year\" (année)\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"), # supprimez \"plus\".\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %&gt;% # supprime l'espace \" \".\n     \n     rename(pop = WorldStandardPopulation) # change le nom de la colonne en \"pop\", car cela est attendu par le paquet dsr\n\nCAUTION: Si vous essayez d’utiliser str_replace_all() pour supprimer un symbole plus, cela ne fonctionnera pas car c’est un symbole spécial. “Échappez” au spécial en mettant deux barres obliques inverses devant, comme dans str_replace_call(column, \"\\\\+\", \"\"). \n\n\n21.2.1 Créer un jeu de données avec une population standard\nEnfin, le package PHEindicatormethods, détaillé ci-dessous, attend les populations standards jointes aux événements et aux comptages de population du pays. Nous allons donc créer un jeu de données all_data à cet effet.\n\nall_data &lt;- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))\n\nCet ensemble de données complet ressemble à ceci :",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Taux standardisés</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.fr.html#dsr-package",
    "href": "new_pages/standardization.fr.html#dsr-package",
    "title": "21  Taux standardisés",
    "section": "21.3 dsr package",
    "text": "21.3 dsr package\nNous démontrons ci-dessous le calcul et la comparaison de taux directement standardisés à l’aide du package dsr. Le package dsr vous permet de calculer et de comparer des taux directement standardisés (pas de taux indirectement standardisés !).\nDans la section Préparation des données, nous avons créé des jeux de données distincts pour le nombre de pays et la population standard :\n\nl’objet country_data, qui est un tableau de population avec le nombre de population et le nombre de décès par strate par pays\n\nl’objet standard_pop_clean, contenant le nombre de personnes par strate pour notre population de référence, la population standard mondiale.\n\nNous utiliserons ces ensembles de données distincts pour l’approche dsr.\n\n\nTaux standardisés\nCi-dessous, nous calculons les taux par pays directement standardisés pour l’âge et le sexe. Nous utilisons la fonction dsr().\nA noter - dsr() s’attend à un cadre de données pour les populations des pays et le nombre d’événements (décès), et un autre cadre de données avec la population de référence. Il s’attend également à ce que dans cette base de données de la population de référence, le nom de la colonne unité-temps soit “pop” (nous nous en sommes assurés dans la section Préparation des données).\nIl y a de nombreux arguments, comme annoté dans le code ci-dessous. Notamment, event = est fixé à la colonne Deaths, et le fu = (“follow-up”) est fixé à la colonne Population. Nous définissons les sous-groupes de comparaison comme la colonne Country et nous standardisons sur la base de age_cat5 et Sex. Ces deux dernières colonnes n’ont pas d’argument nommé particulier. Voir ?dsr pour plus de détails.\n\n# Calculez les taux par pays directement standardisés pour l'âge et le sexe\nmortality_rate &lt;- dsr::dsr(\n     data = country_data, # spécifier l'objet contenant le nombre de décès par strate\n     event = Deaths, # colonne contenant le nombre de décès par strate \n     fu = Population, # colonne contenant le nombre de population par strate\n     subgroup = Country, # unités que nous souhaitons comparer\n     age_cat5, # autres colonnes - les taux seront standardisés par celles-ci\n     Sex,\n     refdata = standard_pop_clean, # cadre de données de la population de référence, avec une colonne appelée \"pop\".\n     method = \"gamma\", # méthode pour calculer l'IC à 95%.\n     sig = 0,95, # niveau de signification\n     mp = 100000, # nous voulons les taux pour 100.000 habitants\n     decimals = 2) # nombre de décimales)\n\n\n# Imprimez la sortie sous la forme d'un joli tableau HTML\nknitr::kable(mortality_rate) # Afficher le taux de mortalité avant et après la standardisation directe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubgroup\nNumerator\nDenominator\nCrude Rate (per 1e+05)\n0% LCL (Crude)\n0% UCL (Crude)\nStd Rate (per 1e+05)\n0% LCL (Std)\n0% UCL (Std)\n\n\n\n\nA\n11344\n86790567\n13.07\n13.07\n13.07\n23.57\n23.57\n23.57\n\n\nB\n9955\n52898281\n18.82\n18.82\n18.82\n19.33\n19.32\n19.33\n\n\n\n\n\nCi-dessus, nous voyons que même si le pays A avait un taux de mortalité brut plus faible que le pays B, il a un taux standardisé plus élevé après standardisation directe par âge et par sexe.\n\n\n\nRatios de taux standardisés\n\n# Calculer le RR\nmortality_rr &lt;- dsr::dsrr(\n     data = country_data, # spécifier l'objet contenant le nombre de décès par strate\n     event = Deaths, # colonne contenant le nombre de décès par strate \n     fu = Population, # colonne contenant le nombre de population par strate\n     subgroup = Country, # unités que nous souhaitons comparer\n     age_cat5,\n     Sex, # caractéristiques sur lesquelles nous aimerions nous standardiser \n     refdata = standard_pop_clean, # population de référence, avec des chiffres dans la colonne appelée pop\n     refgroup = \"B\", # référence pour la comparaison\n     estimate = \"ratio\", # type d'estimation\n     sig = 0.95, # niveau de signification\n     mp = 100000, # nous voulons des taux pour 100.000 habitants\n     decimals = 2) # nombre de décimales\n\n# Imprimer le tableau\nknitr::kable(mortality_rr) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Ratio (RR)\n95% LCL (RR)\n95% UCL (RR)\n\n\n\n\nA\nB\n23.57\n1.22\n1.17\n1.27\n\n\nB\nB\n19.33\n1.00\n0.94\n1.06\n\n\n\n\n\nLe taux de mortalité standardisé est 1,22 fois plus élevé dans le pays A que dans le pays B (IC 95 % 1.17-1.27).\n\n\n\nDifférence de taux standardisé\n\n# Calculer RD\nmortality_rd &lt;- dsr::dsrr(\n     data = country_data, # spécifier l'objet contenant le nombre de décès par strate\n     event = Deaths, # colonne contenant le nombre de décès par strate \n     fu = Population, # colonne contenant le nombre de population par strate\n     subgroup = Country, # unités que nous souhaitons comparer\n     age_cat5, # caractéristiques sur lesquelles nous voulons nous standardiser\n     Sex,                        \n     refdata = standard_pop_clean, # population de référence, avec des chiffres dans la colonne appelée pop\n     refgroup = \"B\", # référence pour la comparaison\n     estimate = \"difference\", # type d'estimation\n     sig = 0.95, # niveau de signification\n     mp = 100000, # nous voulons des taux pour 100.000 habitants\n     decimals = 2) # nombre de décimales\n\n# Imprimer le tableau\nknitr::kable(mortality_rd) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Difference (RD)\n95% LCL (RD)\n95% UCL (RD)\n\n\n\n\nA\nB\n23.57\n4.24\n3.24\n5.24\n\n\nB\nB\n19.33\n0.00\n-1.24\n1.24\n\n\n\n\n\nLe pays A a 4.24 décès supplémentaires pour 100.000 habitants (IC 95% 3.24-5.24) par rapport au pays A.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Taux standardisés</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.fr.html#standard_phe",
    "href": "new_pages/standardization.fr.html#standard_phe",
    "title": "21  Taux standardisés",
    "section": "21.4 PHEindicatormethods package",
    "text": "21.4 PHEindicatormethods package\nUne autre façon de calculer les taux standardisés est avec le paquet PHEindicatormethods. Ce package vous permet de calculer les taux standardisés directement et indirectement. Nous allons montrer les deux.\nCette section utilisera le cadre de données all_data créé à la fin de la section Préparation. Ce cadre de données inclut les populations des pays, les événements de décès, et la population de référence standard mondiale. Vous pouvez le visualiser ici.\n\n\nTaux directement standardisés\nCi-dessous, nous regroupons d’abord les données par Pays, puis nous les passons à la fonction phe_dsr() pour obtenir les taux directement standardisés par pays.\nA noter - la population de référence (standard) peut être fournie comme une colonne dans le cadre de données spécifique au pays ou comme un vecteur séparé. Si elle est fournie dans le cadre de données spécifique au pays, vous devez définir stdpoptype = \"field\". Si elle est fournie sous forme de vecteur, définissez stdpoptype = \"vector\". Dans ce dernier cas, vous devez vous assurer que l’ordre des rangées par strate est similaire dans le cadre de données spécifique au pays et dans la population de référence, car les enregistrements seront appariés par position. Dans notre exemple ci-dessous, nous avons fourni la population de référence sous forme de colonne dans le cadre de données spécifique au pays.\nConsultez l’aide de ?phe_dsr ou les liens dans la section Références pour plus d’informations.\n\n# Calculez les taux par pays directement normalisés pour l'âge et le sexe.\nmortality_ds_rate_phe &lt;- all_data %&gt;%\n     group_by(Country) %&gt;%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths, # colonne avec le nombre d'événements observés\n          n = Population, # colonne avec les pops non standard pour chaque strate\n          stdpop = pop, # populations standard pour chaque strate\n          stdpoptype = \"field\")       # soit \"vector\" pour un vecteur autonome, soit \"field\" pour signifier que les populations std sont dans les données.  \n\n# Imprimer le tableau\nknitr::kable(mortality_ds_rate_phe)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\ntotal_count\ntotal_pop\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\nA\n11344\n86790567\n23.56686\n23.08107\n24.05944\n95%\ndsr per 100000\nDobson\n\n\nB\n9955\n52898281\n19.32549\n18.45516\n20.20882\n95%\ndsr per 100000\nDobson\n\n\n\n\n\n\n\n\nTaux standardisés indirectement\nPour la standardisation indirecte, vous avez besoin d’une population de référence avec le nombre de décès et le nombre de population par strate. Dans cet exemple, nous allons calculer les taux pour le pays A en utilisant le pays B comme population de référence, car la population de référence standard_pop_clean n’inclut pas le nombre de décès par strate.\nCi-dessous, nous créons d’abord la population de référence du pays B. Ensuite, nous passons les données de mortalité et de population pour le pays A, nous les combinons avec la population de référence, et nous les passons à la fonction phe_isr(), pour obtenir des taux indirectement standardisés. Bien sûr, vous pouvez aussi faire l’inverse.\nA noter - dans notre exemple ci-dessous, la population de référence est fournie comme un cadre de données séparé. Dans ce cas, nous nous assurons que les vecteurs x =, n =, x_ref = et n_ref = sont tous ordonnés par les mêmes valeurs de catégorie de standardisation (strate) que celles de notre cadre de données spécifique au pays, puisque les enregistrements seront appariés par position.\nConsultez l’aide de ?phe_isr (maintenant calculate_ISRate depuis dec 2022) ou les liens dans la section Références pour plus d’informations.\n\n# Créez la population de référence\nrefpopCountryB &lt;- country_data %&gt;% \n  filter(Country == \"B\") \n\n# Calculer les taux pour le pays A indirectement standardisés par âge et sexe\nmortality_is_rate_phe_A &lt;- country_data %&gt;%\n     filter(Country == \"A\") %&gt;%\n     PHEindicatormethods::calculate_ISRate( #avant c'etait phe_isr()\n          x = Deaths, # colonne avec le nombre d'événements observés\n          n = Population, # colonne avec les pops non standard pour chaque strate\n          x_ref = refpopCountryB$Deaths, # nombre de décès de référence pour chaque strate\n          n_ref = refpopCountryB$Population) # population de référence pour chaque strate\n\n# Imprimez le tableau\nknitr::kable(mortality_is_rate_phe_A)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nobserved\nexpected\nref_rate\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\n11344\n15847.42\n18.81914\n13.47123\n13.22446\n13.72145\n95%\nindirectly standardised rate per 100000\nByars",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Taux standardisés</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.fr.html#ressources",
    "href": "new_pages/standardization.fr.html#ressources",
    "title": "21  Taux standardisés",
    "section": "21.5 Ressources",
    "text": "21.5 Ressources\nSi vous souhaitez voir un autre exemple reproductible utilisant dsr, veuillez consulter cette vignette.\nPour un autre exemple utilisant PHEindicatormethods, veuillez vous rendre sur ce site Web\nVoir les PHEindicatormethods fichier pdf de référence",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Taux standardisés</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.fr.html",
    "href": "new_pages/moving_average.fr.html",
    "title": "22  Moyennes mobiles",
    "section": "",
    "text": "22.1 Préparation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Moyennes mobiles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.fr.html#préparation",
    "href": "new_pages/moving_average.fr.html#préparation",
    "title": "22  Moyennes mobiles",
    "section": "",
    "text": "Chargement des paquets\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  tidyverse, # pour la gestion des données et le viz\n  slider, # pour le calcul des moyennes mobiles\n  tidyquant # pour le calcul des moyennes mobiles dans ggplot\n)\n\n\n\nImporter des données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, cliquez pour télécharger la liste de lignes “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# Importez la liste de cas\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nLes 50 premières lignes de la linelist sont affichées ci-dessous.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Moyennes mobiles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.fr.html#calculer-avec-slider",
    "href": "new_pages/moving_average.fr.html#calculer-avec-slider",
    "title": "22  Moyennes mobiles",
    "section": "22.2 Calculer avec slider",
    "text": "22.2 Calculer avec slider\nUtilisez cette approche pour calculer une moyenne mobile dans un cadre de données avant de tracer.\nLe paquet slider fournit plusieurs fonctions de “fenêtre glissante” pour calculer des moyennes glissantes, des sommes cumulatives, des régressions glissantes, etc. Il traite un cadre de données comme un vecteur de lignes, permettant une itération par ligne sur un cadre de données.\nVoici quelques-unes des fonctions les plus courantes :\n\nslide_dbl() - itère à travers une colonne numérique (“_dbl”) en effectuant une opération utilisant une fenêtre glissante.\n\nslide_sum() - fonction de raccourci de la somme glissante pour slide_dbl().\n\nslide_mean() - fonction de raccourci de la moyenne glissante pour slide_dbl().\n\nslide_index_dbl() - applique la fenêtre glissante sur une colonne numérique en utilisant une colonne séparée pour indexer la progression de la fenêtre (utile si la fenêtre est glissante par date et que certaines dates sont absentes).\n\nslide_index_sum() - fonction de raccourci de la somme roulante avec indexation.\n\nslide_index_mean() - fonction de raccourci de la moyenne mobile avec indexation.\n\n\nLe paquet slider possède de nombreuses autres fonctions qui sont couvertes dans la section Ressources de cette page. Nous abordons brièvement les plus courantes.\nArguments de base\n\n.x, le premier argument par défaut, est le vecteur sur lequel il faut itérer et auquel il faut appliquer la fonction.\n\n.i = pour les versions “index” des fonctions slider - fournir une colonne pour “indexer” le rouleau (voir section ci-dessous)\n\n.f =, le deuxième argument par défaut, soit :\n\nUne fonction, écrite sans parenthèses, comme mean, ou bien\n\nUne formule, qui sera convertie en fonction. Par exemple ~ .x - mean(.x) retournera le résultat de la valeur courante moins la moyenne de la valeur de la fenêtre.\n\nPour plus de détails, voir ce matériel de référence\n\nTaille de la fenêtre\nSpécifiez la taille de la fenêtre en utilisant soit .before, soit .after, soit les deux arguments :\n\n.before = - Fournir un nombre entier\n\n.after = - Fournir un nombre entier\n\n.complete = - Donnez-lui la valeur TRUE si vous voulez que le calcul soit effectué uniquement sur des fenêtres complètes.\n\nPar exemple, pour obtenir une fenêtre de 7 jours incluant la valeur actuelle et les six précédentes, utilisez .before = 6. Pour obtenir une fenêtre “centrée”, donnez le même nombre à .before = et .after =.\nPar défaut, .complete = sera FAUX, donc si la fenêtre complète de lignes n’existe pas, les fonctions utiliseront les lignes disponibles pour effectuer le calcul. Si vous mettez la valeur TRUE, les calculs ne seront effectués que sur des fenêtres complètes.\nExtension de la fenêtre\nPour réaliser des opérations cumulatives, définissez l’argument .before = à Inf. Ceci effectuera l’opération sur la valeur courante et toutes celles qui la précèdent.\n\nRouler par date\nLe cas le plus probable d’utilisation d’un calcul glissant en épidémiologie appliquée est d’examiner une métrique dans le temps. Par exemple, une mesure continue de l’incidence des cas, basée sur le nombre de cas quotidiens.\nSi vous avez des séries temporelles propres avec des valeurs pour chaque date, vous pouvez utiliser slide_dbl(), comme démontré ici dans la page Série chronologique et détection des épidémies.\nCependant, dans de nombreuses circonstances d’épidémiologie appliquée, vous pouvez avoir des dates absentes de vos données, où il n’y a aucun événement enregistré. Dans ces cas, il est préférable d’utiliser les versions “index” des fonctions slider.\n\n\nDonnées indexées\nCi-dessous, nous montrons un exemple d’utilisation de slide_index_dbl() sur la liste de cas. Disons que notre objectif est de calculer une incidence glissante sur 7 jours - la somme des cas utilisant une fenêtre glissante de 7 jours. Si vous cherchez un exemple de moyenne glissante, consultez la section ci-dessous sur le roulement groupé.\nPour commencer, le jeu de données daily_counts est créé pour refléter le nombre de cas quotidiens de la linelist, tel que calculé avec count() de dplyr.\n\n# créez un jeu de données des comptages quotidiens\ndaily_counts &lt;- linelist %&gt;% \n  count(date_hospitalisation, name = \"new_cases\")\n\nVoici le cadre de données daily_counts - il y a nrow(daily_counts) lignes, chaque jour est représenté par une ligne, mais surtout au début de l’épidémie certains jours ne sont pas présents (il n’y avait pas de cas admis ces jours-là).\n\n\n\n\n\n\nIl est crucial de reconnaître qu’une fonction de roulement standard (comme slide_dbl() utiliserait une fenêtre de 7 lignes, et non de 7 jours. Ainsi, s’il y a des dates absentes, certaines fenêtres s’étendront en fait sur plus de 7 jours calendaires !\nUne fenêtre déroulante “intelligente” peut être obtenue avec slide_index_dbl(). L’“index” signifie que la fonction utilise une colonne séparée comme “index” pour la fenêtre de roulement. La fenêtre n’est pas simplement basée sur les lignes du cadre de données.\nSi la colonne d’index est une date, vous avez la possibilité supplémentaire de spécifier l’étendue de la fenêtre à .before = et/ou .after = en unités de lubridate days() ou months(). Si vous faites ces choses, la fonction inclura les jours absents dans les fenêtres comme s’ils étaient là (comme des valeurs NA).\nMontrons une comparaison. Ci-dessous, nous calculons l’incidence des cas sur 7 jours glissants avec des fenêtres régulières et indexées.\n\nrolling &lt;- daily_counts %&gt;% \n  mutate( # créer de nouvelles colonnes\n    # Utiliser slide_dbl()\n    ###################\n    reg_7day = slide_dbl(\n      new_cases, # calculer sur les new_cases\n      .f = ~sum(.x, na.rm = T), # la fonction est sum() avec les valeurs manquantes supprimées\n      .before = 6), # la fenêtre est le ROW et 6 ROWS précédents\n    \n    # Utilisation de slide_index_dbl()\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases, # calculer sur les new_cases\n        .i = date_hospitalisation, # indexé avec date_onset \n        .f = ~sum(.x, na.rm = TRUE), # la fonction est sum() avec les valeurs manquantes supprimées\n        .before = days(6))               # la fenêtre est le JOUR et les 6 JOURS précédents\n    )\n\nObservez comment, dans la colonne normale, pour les 7 premières lignes, le nombre augmente régulièrement malgré le fait que les lignes ne sont pas à moins de 7 jours les unes des autres! La colonne adjacente “indexée” tient compte de ces jours calendaires absents, de sorte que ses sommes sur 7 jours sont beaucoup plus faibles, du moins à cette période de l’épidémie où les cas sont plus espacés.\n\n\n\n\n\n\nVous pouvez maintenant tracer ces données avec ggplot() :\n\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRouler par groupe\nSi vous regroupez vos données avant d’utiliser une fonction slider, les fenêtres de glissement seront appliquées par groupe. Veillez à disposer vos lignes dans l’ordre souhaité par groupe.\nChaque fois qu’un nouveau groupe commence, la fenêtre coulissante recommence. Par conséquent, une nuance à prendre en compte est que si vos données sont groupées et que vous avez défini .complete = TRUE, vous aurez des valeurs vides à chaque transition entre les groupes. Au fur et à mesure que la fonction se déplace vers le bas dans les lignes, chaque transition dans la colonne de regroupement redémarre l’accumulation de la taille minimale de la fenêtre pour permettre un calcul.\nVoir la page du manuel sur le Regroupement des données pour plus de détails sur le regroupement des données.\nCi-dessous, nous comptons les cas de la linelist par date et par hôpital. Ensuite, nous classons les lignes par ordre croissant, d’abord par hôpital, puis par date. Ensuite, nous définissons group_by(). Nous pouvons alors créer notre nouvelle moyenne mobile.\n\ngrouped_roll &lt;- linelist %&gt;%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %&gt;% \n\n  arrange(hospital, date_hospitalisation) %&gt;% # arranger les lignes par hôpital puis par date\n  \n  group_by(hospital) %&gt;% # groupage par hôpital \n    \n  mutate( # moyenne mobile  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases, # le nombre de cas par jour d'hospitalisation\n      .i = date_hospitalisation, # indice sur la date d'admission\n      .f = mean, # utiliser mean()                   \n      .before = days(6) # utilise le jour et les 6 jours précédents\n      )\n  )\n\nVoici le nouvel ensemble de données :\n\n\n\n\n\n\nNous pouvons maintenant tracer les moyennes mobiles, en affichant les données par groupe en spécifiant ~ hospital à facet_wrap() dans ggplot(). Pour le plaisir, nous traçons deux géométries - un geom_col() montrant le nombre de cas quotidiens et un geom_line() montrant la moyenne mobile sur 7 jours.\n\nggplot(data = grouped_roll)+\n  geom_col( # Trace le nombre de cas de daly sous forme de barres grises\n     mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(   # tracer la moyenne mobile sous forme de ligne colorée par hôpital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # créer des mini-plots par hôpital\n  theme_classic()+ # simplifie le fond d'écran  \n  theme(legend.position = \"none\")+ # supprimer la légende\n  labs( # ajout d'étiquettes pour les graphiques\n      title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")\n\n\n\n\n\n\n\n\n**ATTENTION:_** Si vous obtenez une erreur disant “slide() was deprecated in tsibble 0.9.0 and is now defunct. Please use slider::slide() instead.”, cela signifie que la fonction slide() du paquet tsibble masque la fonction slide() du paquet slider. Corrigez cela en spécifiant le package dans la commande, comme slider::slide_dbl()..\n\n\nVous pouvez regrouper les données avant d’utiliser une fonction slider. Par exemple, si vous voulez calculer la même somme glissante de 7 jours que ci-dessus, mais par hôpital. ci-dessus le délai moyen glissant entre l’apparition des symptômes et l’admission à l’hôpital (colonne days_onset_hosp). –&gt;",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Moyennes mobiles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.fr.html#calculer-avec-tidyquant-dans-ggplot",
    "href": "new_pages/moving_average.fr.html#calculer-avec-tidyquant-dans-ggplot",
    "title": "22  Moyennes mobiles",
    "section": "22.3 Calculer avec tidyquant dans ggplot()",
    "text": "22.3 Calculer avec tidyquant dans ggplot()\nLe paquet tidyquant offre une autre approche du calcul des moyennes mobiles - cette fois-ci à partir dans une commande ggplot() elle-même.\nEn dessous de la linelist, les données sont comptées par date d’apparition et sont représentées par une ligne fondue (alpha &lt; 1). La ligne superposée est créée avec geom_ma() du paquet tidyquant, avec une fenêtre de 7 jours (n = 7) avec une couleur et une épaisseur spécifiées.\nPar défaut, geom_ma() utilise une moyenne mobile simple (ma_fun = \"SMA\"), mais d’autres types peuvent être spécifiés, tels que :\n\n“EMA” - moyenne mobile exponentielle (plus de poids aux observations récentes)\n\n“WMA” - moyenne mobile pondérée (wts sont utilisés pour pondérer les observations dans la moyenne mobile)\n\nD’autres peuvent être trouvées dans la documentation de la fonction\n\n\nlinelist %&gt;% \n  count(date_onset) %&gt;% # compte les cas par jour\n  drop_na(date_onset) %&gt;% # Suppression des cas pour lesquels la date d'apparition est manquante\n  ggplot(aes(x = date_onset, y = n))+ # démarrer ggplot\n    geom_line( # tracer les valeurs brutes\n      size = 1,\n      alpha = 0.2 # ligne semi-transparente\n      )+             \n    tidyquant::geom_ma( # tracer la moyenne mobile\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal() # fond simple\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n\nVoir cette vignette pour plus de détails sur les options disponibles dans tidyquant.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Moyennes mobiles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.fr.html#ressources",
    "href": "new_pages/moving_average.fr.html#ressources",
    "title": "22  Moyennes mobiles",
    "section": "22.4 Ressources",
    "text": "22.4 Ressources\nVoir la vignette en ligne utile pour le paquet slider.\nLa page slider github\nUne slider vignette\nVignette tidyquant\nSi votre cas d’utilisation exige que vous “passiez” les week-ends et même les jours fériés, vous aimerez peut-être le paquet almanac.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Moyennes mobiles</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html",
    "href": "new_pages/time_series.fr.html",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "",
    "text": "23.1 Aperçu\nCet onglet démontre l’utilisation de plusieurs paquets pour l’analyse des séries temporelles. Il s’appuie principalement sur les paquets de la famille tidyverts mais utilise également le paquet RECON trending pour ajuster des modèles qui sont plus appropriés à l’épidémiologie des maladies infectieuses.\nNotez que dans l’exemple ci-dessous, nous utilisons un ensemble de données provenant du paquet surveillance. sur Campylobacter en Allemagne (voir le chapitre sur les données, du manuel pour plus de détails). Cependant, si vous vouliez exécuter le même code sur un ensemble de données avec plusieurs pays ou d’autres strates, il y a un exemple de code pour cela dans le fichier r4epis github repo.\nLes sujets abordés sont les suivants :",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#aperçu",
    "href": "new_pages/time_series.fr.html#aperçu",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "",
    "text": "Données de séries temporelles\nAnalyse descriptive\nRégressions ajustées\nRelation de deux séries temporelles\nDétection de l’épidémie\nSéries chronologiques interrompues",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#préparation",
    "href": "new_pages/time_series.fr.html#préparation",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.2 Préparation",
    "text": "23.2 Préparation\n\nPaquets\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger des paquets avec library() depuis base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(rio, # Importation du fichier\n               here, # Localisation de fichiers\n               tidyverse, # gestion des données + graphiques ggplot2\n               tsibble, # gère les ensembles de données de séries temporelles\n               slider, # pour calculer les moyennes mobiles\n               imputeTS, # pour remplir les valeurs manquantes\n               feasts, # pour la décomposition des séries temporelles et l'autocorrélation\n               forecast, # ajustement des termes sin et cosin aux données (note : doit être chargé après feasts)\n               trending, # ajustement et évaluation des modèles \n               tmaptools, # pour obtenir des géocoordonnées (lon/lat) à partir de noms de lieux\n               ecmwfr, # pour interagir avec l'API CDS de copernicus sateliate\n               stars, # pour lire les fichiers .nc (données climatiques)\n               units, # pour définir les unités de mesure (données climatiques)\n               yardstick, # pour l'examen de la précision du modèle\n               surveillance # pour la détection des aberrations\n               )\n\n\n\nChargement des données\nVous pouvez télécharger toutes les données utilisées dans ce manuel en suivant les instructions de la page Télécharger le manuel et les données.\nL’ensemble de données d’exemple utilisé dans cette section est le décompte hebdomadaire des cas de campylobacter signalés en Allemagne entre 2001 et 2011.  Vous pouvez cliquer ici pour télécharger ce fichier de données (.xlsx)..\nCet ensemble de données est une version réduite de l’ensemble de données disponible dans le paquet surveillance (pour plus de détails, chargez le paquet surveillance et voyez ?campyDE)\nImportez ces données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# Importez les comptes dans R\ncounts &lt;- rio::import(\"campylobacter_germany.xlsx\")\n\nLes 10 premières lignes des comptages sont affichées ci-dessous.\n\n\n\n\n\n\n\n\nNettoyer les données\nLe code ci-dessous s’assure que la colonne de date est dans le format approprié. Pour cet onglet, nous utiliserons le package tsibble et donc la fonction yearweek sera utilisée pour créer une variable de semaine calendaire. Il existe plusieurs autres façons de le faire (voir la page Manipuler les dates pour plus de détails), mais pour les séries temporelles, il est préférable de rester dans un seul cadre (tsibble).\n\n## s'assurer que la colonne date est dans le format approprié\ncounts$date &lt;- as.Date(counts$date)\n\n## créer une variable de semaine calendaire \n## adapter les définitions ISO des semaines commençant un lundi\ncounts &lt;- counts %&gt;% \n     mutate(epiweek = yearweek(date, week_start = 1))\n\n\n\nTélécharger les données climatiques\nDans la partie relation de deux séries temporelles de cette page, nous allons comparer le nombre de cas de campylobacter aux données climatiques.\nLes données climatiques de n’importe quel endroit du monde peuvent être téléchargées à partir du satellite Copernicus de l’UE. Il ne s’agit pas de mesures exactes, mais de données basées sur un modèle (similaire à l’interpolation), mais l’avantage est une couverture horaire globale ainsi que des prévisions.\nVous pouvez télécharger chacun de ces fichiers de données climatiques à partir de la page Télécharger le manuel et les données.\nPour les besoins de la démonstration, nous allons présenter le code R permettant d’utiliser le paquet ecmwfr pour extraire ces données du magasin de données climatiques Copernicus Climate Data Store. Vous devrez créer un compte gratuit pour que cela fonctionne. Le site Web du paquet contient un demo utile sur la manière de procéder. Vous trouverez ci-dessous un exemple de code expliquant comment procéder, une fois que vous les clés API appropriées. Vous devez remplacer les X ci-dessous par les identifiants de votre compte. Vous devrez télécharger une année de données à la fois, sinon le serveur s’arrête.\nSi vous n’êtes pas sûr des coordonnées d’un lieu pour lequel vous voulez télécharger des données, vous pouvez utiliser le paquet tmaptools pour extraire les coordonnées des cartes routières ouvertes. Une autre option est le paquet photon mais il n’a pas encore été publié sur CRAN. photon fournit plus de données contextuelles lorsqu’il y a plusieurs correspondances pour votre recherche.\n\n## récupérer les coordonnées de l'emplacement\ncoords &lt;- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## rassembler les long/lats dans un format pour les requêtes ERA-5 (bounding box) \n## (comme on ne veut qu'un seul point, on peut répéter les coordonnées)\nrequest_coords &lt;- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Extraction des données modélisées à partir du satellite copernicus (réanalyse ERA-5)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## Configurer la clé pour les données météo \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXX-XXXXXXXXX\",\n           service = \"cds\") \n\n## Exécution pour chaque année d'intérêt (sinon le serveur s'arrête)\nfor (i in 2002:2011) {\n  \n  ## construire une requête \n  ## voir ici pour savoir comment faire : https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## changer la requête en une liste en utilisant le bouton addin ci-dessus (python to list)\n  ## La cible est le nom du fichier de sortie ! !!\n   request &lt;- request &lt;- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ### Télécharger le fichier et le stocker dans le répertoire de travail actuel.\n  file &lt;- wf_request(user = \"XXXXX\", # ID utilisateur (pour l'authentification)\n                     request = request, # la requête\n                     transfer = TRUE, # télécharger le fichier\n                     path = here::here(\"data\", \"Weather\")) ## chemin pour sauvegarder les données\n  }\n\n\n\nCharger les données climatiques\nQue vous ayez téléchargé les données climatiques via notre manuel ou que vous ayez utilisé le code ci-dessus, vous devriez maintenant avoir 10 ans de fichiers de données climatiques “.nc” stockés dans le même dossier sur votre ordinateur.\nUtilisez le code ci-dessous pour importer ces fichiers dans R avec le paquet stars.\n\n## définir le chemin vers le dossier météo \nfile_paths &lt;- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # remplacer par votre propre chemin de fichier \n  full.names = TRUE)\n\n## ne garder que ceux qui ont le nom courant d'intérêt \nfile_paths &lt;- file_paths[str_detect(file_paths, \"germany\")]\n\n## lire tous les fichiers en tant qu'objet stars \ndata &lt;- stars::read_stars(file_paths)\n\nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \n\n\nUne fois que ces fichiers ont été importés en tant qu’objet data, nous allons les convertir en un cadre de données.\n\n## conversion en cadre de données \ntemp_data &lt;- as_tibble(data) %&gt;% \n  ## ajouter des variables et corriger les unités\n  mutate(\n    ## créer une variable de semaine calendaire \n    epiweek = tsibble::yearweek(time), \n    ## créer une variable de date (début de la semaine calendaire)\n    date = as.Date(epiweek),\n    ## changer la température de kelvin en celsius\n    t2m = set_units(t2m, celsius), \n    ## changer les précipitations de mètres en millimètres \n    tp = set_units(tp, mm)) %&gt;% \n  ## regrouper par semaine (en gardant la date aussi)\n  group_by(epiweek, date) %&gt;% \n  ## obtenir la moyenne par semaine\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#données-de-séries-temporelles",
    "href": "new_pages/time_series.fr.html#données-de-séries-temporelles",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.3 Données de séries temporelles",
    "text": "23.3 Données de séries temporelles\nIl existe un certain nombre de paquets différents pour structurer et traiter les données de données de séries temporelles. Comme nous l’avons dit, nous nous concentrerons sur la famille de paquets tidyverts et nous utiliserons donc le paquet tsibble pour définir notre objet série temporelle. Avoir un ensemble de données défini comme un objet de série temporelle, il est beaucoup plus facile de structurer notre analyse.\nPour ce faire, nous utilisons la fonction tsibble() et spécifions l’“index”, c’est-à-dire la variable spécifiant l’unité de temps qui nous intéresse. Dans notre cas, il s’agit de la variable epiweek.\nSi nous avions un ensemble de données avec des comptages hebdomadaires par province, par exemple, nous pourrions également spécifier la variable de regroupement en utilisant l’argument key =. Cela nous permettrait d’effectuer une analyse pour chaque groupe.\n\n## Définir un objet de série temporelle \ncounts &lt;- tsibble(counts, index = epiweek)\n\nEn regardant class(counts), on constate qu’en plus d’être un cadre de données ordonné (“tbl_df”, “tbl”, “data.frame”), il possède les propriétés supplémentaires d’un cadre de données de série temporelle (“tbl_ts”).\nVous pouvez jeter un coup d’oil rapide à vos données en utilisant ggplot2. Nous voyons sur le graphique que qu’il existe un modèle saisonnier clair, et qu’il n’y a pas de manques. Cependant, il semble y avoir un problème avec la déclaration au début de chaque année, dans la dernière semaine de l’année, puis augmentent pour la première semaine de l’année suivante.\n\n## tracer un graphique linéaire des cas par semaine\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()\n\n\n\n\n\n\n\n\nATTENTION: La plupart des ensembles de données ne sont pas aussi propres que cet exemple. Vous devrez vérifier les doublons et les valuers qui manques comme ci-dessous. \n\n\nDuplicates\ntsibble n’autorise pas les observations en double. Ainsi, chaque ligne devra être unique, ou unique au sein du groupe (variable key). Le paquet a quelques fonctions qui aident à identifier les doublons. Celles-ci incluent are_duplicated() qui vous donne un vecteur VRAI/FAUX indiquant si la ligne est un dupliqué, et duplicates() qui vous donne un cadre de données des lignes dupliquées.\nVoir la page sur De-duplication pour plus de détails sur la façon de sélectionner les lignes que vous voulez.\n\n## obtient un vecteur de VRAI/FAUX si les lignes sont des doublons\nare_duplicated(counts, index = epiweek) \n\n## Obtenez un cadre de données pour les lignes dupliquées. \nduplicates(counts, index = epiweek) \n\n\n\n\nManques\nNous avons vu lors de notre brève inspection ci-dessus qu’il n’y a pas de manques, mais nous avons aussi vu qu’il semble y avoir un problème de retard de déclaration autour du nouvel an. Une façon de résoudre ce problème pourrait être de définir ces valeurs comme manquantes, puis d’imputer les valeurs. La forme la plus simple d’imputation de séries chronologiques consiste à tracer une ligne droite entre les dernières valeurs non manquantes et les valeurs manquantes. Pour ce faire, nous utiliserons la fonction na_interpolation() du package imputeTS.\nConsultez la page Données manquantes pour connaître les autres options d’imputation.\nUne autre solution consisterait à calculer une moyenne mobile, pour essayer de pour tenter d’aplanir ces problèmes de déclaration apparents (voir la section suivante et la page sur les Moyennes mobiles).\n\n## créez une variable avec les manques au lieu des semaines avec des problèmes de déclaration.\ncounts &lt;- counts %&gt;% \n     mutate(case_miss = if_else(\n          ## si epiweek contient 52, 53, 1 ou 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## alors définie comme manquante \n          NA_real_, \n          ## sinon, conservez la valeur dans le cas\n          case\n     ))\n\n## alternativement interpoler les manquants par une tendance linéaire \n## entre deux points adjacents les plus proches\ncounts &lt;- counts %&gt;% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## pour vérifier quelles valeurs ont été imputées par rapport à l'original.\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#analyse-descriptive",
    "href": "new_pages/time_series.fr.html#analyse-descriptive",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.4 Analyse descriptive",
    "text": "23.4 Analyse descriptive\n\n\nMoyennes mobiles\nSi les données sont très bruyantes (les comptes sautent en haut et en bas), alors il peut être utile de calculer une moyenne mobile. Dans l’exemple ci-dessous, pour chaque semaine, nous calculons le nombre moyen de cas des quatre semaines précédentes. Cela permet de lisser les données, pour les rendre plus interprétables. Dans notre cas, cela n’apporte pas grand-chose. Nous nous en tiendrons aux données interpolées pour la suite de l’analyse. Voir la page Moyennes mobiles pour plus de détails.\n\n## créer une variable de moyenne mobile (traite les manques)\ncounts &lt;- counts %&gt;% \n     ## créer la variable ma_4w \n     ## glisser sur chaque ligne de la variable case\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## pour chaque ligne, calculez le nom\n                               ~ mean(.x, na.rm = TRUE),\n                               ## utiliser les quatre semaines précédentes\n                               .before = 4))\n\n### faire une visualisation rapide de la différence \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nPériodicité\nNous définissons ci-dessous une fonction personnalisée pour créer un périodogramme. Voir la page ecrire les fonctions pour des informations sur la façon d’écrire des fonctions dans R.\nTout d’abord, la fonction est définie. Ses arguments incluent un jeu de données avec une colonne counts, start_week = qui est la première semaine du jeu de données, un nombre pour indiquer combien de périodes par an (par exemple 52, 12), et enfin le style de sortie (voir les détails dans le code ci-dessous).\n\n## Arguments de la fonction\n#####################\n## x est un ensemble de données\n## counts est une variable avec des données de comptage ou des taux dans x \n## start_week est la première semaine de votre série de données\n## period est le nombre d'unités dans une année. \n## output indique si vous souhaitez renvoyer le périodogramme spectral ou les semaines de pointe.\n  ## \"périodogramme\" ou \"semaines\".\n\n# Définissez la fonction\nperiodogram &lt;- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## s'assurer que ce n'est pas un tsibble, filtrer sur le projet et ne garder que les colonnes d'intérêt.\n    prepare_data &lt;- dplyr::as_tibble(x)\n    \n    # prepare_data &lt;- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data &lt;- dplyr::select(prepare_data, {{counts}})\n    \n    ## créer une série temporelle \"zoo\" intermédiaire pour pouvoir l'utiliser avec spec.pgram\n    zoo_cases &lt;- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## obtenir un périodogramme spectral n'utilisant pas la transformée de fourier rapide. \n    periodo &lt;- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## retourner les semaines de pointe \n    periodo_weeks &lt;- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## obtenir le périodogramme spectral pour extraire les semaines avec les fréquences les plus élevées \n## (vérification de la saisonnalité) \nperiodo &lt;- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## Tirez le spectre et la fréquence dans un cadre de données pour le tracé.\nperiodo &lt;- data.frame(periodo$freq, periodo$spec)\n\n## Tracez un périodogramme montrant la périodicité la plus fréquente. \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52), y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (weeks)\", y = \"Log(density)\")\n\n\n\n\n\n\n\n## obtenir un vecteur semaines dans l'ordre croissant \npeak_weeks &lt;- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")\n\nATTENTION: Il est possible d’utiliser les semaines ci-dessus pour les ajouter aux termes sin et cosinus, cependant nous utiliserons une fonction pour générer ces termes (voir la section régression ci-dessous) .\n\n\n\nDécomposition\nLa décomposition classique est utilisée pour décomposer une série temporelle en plusieurs parties, qui lorsqu’elles sont prises ensemble constituent le modèle que vous voyez.\nCes différentes parties sont :\n\nLa tendance-cycle (la direction à long terme des données)\n\nLa saisonnalité (motifs répétitifs)\n\nL’aléatoire (ce qui reste après avoir retiré la tendance et la saison).\n\n\n## Décomposition de l'ensemble de données counts \ncounts %&gt;% \n  ## en utilisant un modèle additif de décomposition classique\n  model(classical_decomposition(case_int, type = \"additive\")) %&gt;%\n  ## extraire les informations importantes du modèle\n  components() %&gt;% \n  ## générer un graphique \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nAutocorrélation\nL’autocorrélation vous renseigne sur la relation entre les comptes de chaque semaine et les semaines qui la précèdent (appelées décalages).\nEn utilisant la fonction ACF(), nous pouvons produire un graphique qui nous montre un certain nombre de lignes pour la relation à différents décalages. Si le décalage est de 0 (x = 0), cette ligne sera toujours égale à 1, car elle montre la relation entre les deux. La première ligne illustrée ici (x = 1) montre la relation entre chaque observation et l’observation qui la précède (décalage de 1), la seconde montre la relation entre chaque observation et l’avant-dernière (décalage de 2) et ainsi de suite jusqu’à un décalage de 52 qui montre la relation entre chaque observation et l’observation d’un an (52 semaines avant).\nL’utilisation de la fonction PACF() (pour l’autocorrélation partielle) montre le même type de relation, mais ajustée pour toutes les autres semaines intermédiaires. Ceci est moins informatif pour déterminer la périodicité.\n\n## en utilisant l'ensemble de données counts\ncounts %&gt;% \n  ## calculer l'autocorrélation en utilisant une année complète de lags\n  ACF(case_int, lag_max = 52) %&gt;% \n  ## afficher un graphique\n  autoplot()\n\n\n\n\n\n\n\n## en utilisant l'ensemble de données counts \ncounts %&gt;% \n  ## calculer l'autocorrélation partielle en utilisant une année complète de décalages\n  PACF(case_int, lag_max = 52) %&gt;% \n  ## Afficher un graphique\n  autoplot()\n\n\n\n\n\n\n\n\nVous pouvez tester formellement l’hypothèse nulle d’indépendance d’une série temporelle (c’est à dire qu’elle n’est pas autocorrélée) en utilisant le test de Ljung-Box (dans le paquet stats). Une valeur p significative suggère qu’il existe une autocorrélation dans les données.\n\n## Test d'indépendance \nBox.test(counts$case_int, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  counts$case_int\nX-squared = 462.65, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#ajustement-des-régressions",
    "href": "new_pages/time_series.fr.html#ajustement-des-régressions",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.5 Ajustement des régressions",
    "text": "23.5 Ajustement des régressions\nIl est possible d’ajuster un grand nombre de régressions différentes à une série temporelle, Cependant, nous allons montrer ici comment ajuster une régression binomiale négative, c’est souvent la plus appropriée pour les données de comptage dans les maladies infectieuses.\n\n\nTermes de Fourier\nLes termes de Fourier sont l’équivalent des courbes sin et cosin. La différence est que ceux-ci sont ajustés en fonction de la recherche de la combinaison de courbes la plus appropriée pour expliquervos données.\nSi vous n’ajustez qu’un seul terme de Fourier, cela équivaudrait à ajuster une courbe sin et un cosin pour le décalage le plus fréquent de votre périodogramme (dans notre cas 52 semaines). Nous utilisons la fonction fourier() du paquet forecast.\nDans le code ci-dessous, nous assignons en utilisant le $, car fourier() renvoie deux colonnes (une pour le sin et une pour le cosin) et celles-ci sont ajoutées à l’ensemble de données sous forme de liste, appelée “fourier”. Mais cette liste peut ensuite être utilisée comme une variable normale dans une régression.\n\n## ajout des termes de fourier en utilisant les variables epiweek et case_int\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  fourier(K = 1)\n\n\n\n\nBinomiale négative\nIl est possible d’ajuster des régressions en utilisant les fonctions stats ou MASS de base (par exemple, lm(), glm() et glm.nb()). Cependant, nous utiliserons celles du paquet trending, car cela permet de calculer les intervalles de confiance et de prédictionconfiance et les intervalles de prédiction appropriés (qui ne sont pas disponibles autrement). La syntaxe est la même, et vous spécifiez une variable de résultat puis un tilde (~) puis vous ajoutez vos diverses variables d’exposition d’intérêt séparées par un plus (+).\nL’autre différence est que nous définissons d’abord le modèle et ensuite fit() aux données. Ceci est utile car cela permet de comparer plusieurs modèles différents avec la même syntaxe.\nATTENTION: Si vous vouliez utiliser des taux, plutôt que des comptes, vous pourriez inclure la variable population comme terme de décalage logarithmique, en ajoutant offset(log(population). Vous auriez alors besoin de définir la population à 1, avant d’utiliser predict() afin de produire un taux. \nATTENTION: Pour l’ajustement de modèles plus complexes tels que les modèles comme ARIMA ou prophète, voir le paquet fable.\n\n## définissez le modèle que vous voulez ajuster (binomiale négative). \nmodel &lt;- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n    fourier)\n\n## ajustez votre modèle en utilisant le jeu de données de comptage\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n### calculer les intervalles de confiance et les intervalles de prédiction \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nestimate_res &lt;- data.frame(observed$result)\n\n## Tracez votre régression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## ajouter une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate),\n            col = \"red\") + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne pour le nombre de cas observés\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nRésidus\nPour voir si notre modèle s’adapte bien aux données observées, nous devons examiner les résidus. Les résidus sont la différence entre les comptes observés et les comptes estimés à partir du modèle. Nous pourrions calculer cela simplement en utilisant case_int - estimate, mais la fonction residuals() l’extrait directement de la régression pour nous.\nCe que nous voyons ci-dessous, c’est que nous n’expliquons pas toutes les variations que nous pourrions expliquer avec le modèle. Il se peut que nous devions ajuster plus de termes de Fourier, et s’attaquer à l’amplitude. Cependant, pour cet exemple, nous allons laisser les choses telles quelles. Les graphiques montrent que notre modèle est moins bon dans les pics et les creux (lorsque les comptages sont les plus élevés et les plus bas) et qu’il est plus susceptible de sous-estimer les comptagees observés.\n\n## calculate the residuals \nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = fitted_model$result[[1]]$residuals)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## are residuals normally distributed (are under or over estimating?)  \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 0.01) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## compare observed counts to their residuals \n  ## should also be no pattern \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 336.25, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#relation-entre-deux-séries-temporelles",
    "href": "new_pages/time_series.fr.html#relation-entre-deux-séries-temporelles",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.6 Relation entre deux séries temporelles",
    "text": "23.6 Relation entre deux séries temporelles\nNous examinons ici l’utilisation de données météorologiques (en particulier la température) pour expliquer le nombre de cas de campylobacter.\n\n\nFusionner des ensembles de données\nNous pouvons fusionner nos ensembles de données à l’aide de la variable week. Pour plus d’informations sur la fusion, voir la section du manuel sur les joindres.\n\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts &lt;- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")\n\n\ncounts %&gt;% \n  ## garder les variables qui nous intéressent \n  select(epiweek, case_int, t2m) %&gt;% \n  ## Changez vos données en format long\n  pivot_longer(\n    ## utiliser epiweek comme clé\n    !epiweek,\n    ## déplacez les noms des colonnes vers la nouvelle colonne \"measure\".\n    names_to = \"measure\", \n    ## déplacez les valeurs des cellules vers la nouvelle colonne \"values\".\n    values_to = \"value\") %&gt;% \n  ## créer un graphique avec l'ensemble de données ci-dessus\n  ## Tracez l'epiweek sur l'axe des x et les valeurs (nombres/celsius) sur l'axe des y. \n  ggplot(aes(x = epiweek, y = value)) + \n    ## créez un graphique séparé pour les comptages tempérés et les comptages de cas. \n    ## laissez-les définir leurs propres axes y\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## Tracez les deux comme une ligne\n    geom_line()\n\n\n\n\n\n\n\n\n\n\n\nLags et corrélation croisée\nPour tester formellement quelles semaines sont les plus fortement liées entre les cas et la température. Nous pouvons utiliser la fonction de corrélation croisée (CCF()) du paquet feasts. Vous pouvez également visualiser (plutôt que d’utiliser arrange) en utilisant la fonction autoplot().\n\ncounts %&gt;% \n  ## calculer la corrélation croisée entre les comptages interpolés et la température\n  CCF(case_int, t2m,\n      ## fixer le délai maximum à 52 semaines\n      lag_max = 52, \n      ## retourne le coefficient de corrélation \n      type = \"correlation\") %&gt;% \n  ## arange dans l'ordre décroissant du coefficient de corrélation \n  ## montre les décalages les plus associés\n  arrange(-ccf) %&gt;% \n  ## montrer seulement les dix premiers \n  slice_head(n = 10)\n\n# A tsibble: 10 x 2 [1W]\n        lag   ccf\n   &lt;cf_lag&gt; &lt;dbl&gt;\n 1      -4W 0.749\n 2      -5W 0.745\n 3      -3W 0.735\n 4      -6W 0.729\n 5      -2W 0.727\n 6      -7W 0.704\n 7      -1W 0.695\n 8      -8W 0.671\n 9       0W 0.649\n10      47W 0.638\n\n\nNous voyons qu’un décalage de 4 semaines est le plus fortement corrélé, donc nous créons une variable de température décalée à inclure dans notre régression.\nATTENTION: Notez que les quatre premières semaines de nos données dans la variable de température décalée sont manquantes (NA) - car il n’y a pas quatre semaines précédentes pour obtenir des données. Afin d’utiliser cet ensemble de données avec la fonction predict() du paquet trending, nous devons utiliser l’argument simulate_pi = FALSE dans la fonction predict() plus bas. Si nous voulions utiliser l’option simulate, alors nous devons supprimer ces manques et les stocker comme un nouvel ensemble de données en ajoutant drop_na(t2m_lag4). au morceau de code ci-dessous.\n\ncounts &lt;- counts %&gt;% \n  ## créer une nouvelle variable pour la température décalée de quatre semaines.\n  mutate(t2m_lag4 = lag(t2m, n = 4))\n\n\n\n\nBinomiale négative avec deux variables\nNous ajustons une régression binomiale négative comme nous l’avons fait précédemment. Cette fois, nous ajoutons la variable de température retardée de quatre semaines.\nATTENTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y a des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. \n\n## définissez le modèle que vous voulez ajuster (binomial négatif). \nmodel &lt;- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n    fourier + \n    ## utiliser la température retardée de quatre semaines \n    t2m_lag4\n    )\n\n## ajustez votre modèle en utilisant l'ensemble de données de comptage\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n### calculer les intervalles de confiance et les intervalles de prédiction \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nPour étudier les termes individuels, nous pouvons extraire la régression binomiale négative originale du paquet trending en utilisant get_fitted_model() et la passer au fonction tidy() du paquetage broom pour récupérer les estimations exponentielles et lesintervalles de confiance associés.\nCe que cela nous montre est que la température décalée, après avoir contrôlé la tendance et la saisonnalité, est similaire au nombre de cas (estimation ~ 1) et significativement associée. Cela suggère qu’il pourrait s’agir d’une bonne variable à utiliser pour prédire le nombre de cas futurs (les prévisions climatiques étant facilement accessibles).\n\nfitted_model %&gt;% \n  ## extraire la régression binomiale négative originale\n  get_fitted_model() #%&gt;% \n\n[[1]]\n\nCall:  glm.nb(formula = case_int ~ epiweek + fourier + t2m_lag4, data = data.frame(counts), \n    init.theta = 32.80689607, link = log)\n\nCoefficients:\n (Intercept)       epiweek  fourierS1-52  fourierC1-52      t2m_lag4  \n   5.825e+00     8.464e-05    -2.850e-01    -1.954e-01     6.672e-03  \n\nDegrees of Freedom: 504 Total (i.e. Null);  500 Residual\n  (4 observations deleted due to missingness)\nNull Deviance:      2015 \nResidual Deviance: 508.2    AIC: 6784\n\n  ## obtenir un cadre de données ordonné des résultats\n  #broom::tidy(exponentiate = TRUE, \n  #     conf.int = TRUE)\n\nUne rapide inspection visuelle du modèle montre qu’il pourrait faire un meilleur travail pour d’estimer le nombre de cas observés.\n\nestimate_res &lt;- data.frame(observed$result)\n     \n## Tracez votre régression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## ajouter une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate),\n            col = \"red\") + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne pour le nombre de cas observés\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()\n\n\n\n\n\n\n\n\n\nRésidus\nNous examinons à nouveau les résidus pour voir si notre modèle s’adapte bien aux données observées. Les résultats et l’interprétation sont ici similaires à ceux de la régression précédente, donc il est peut-être plus judicieux de s’en tenir au modèle plus simple sans température.\n\n## calculer les résidus \nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = case_int - estimate)\n\n## les résidus sont-ils assez constants dans le temps (si non : épidémies ? changement de pratique ?)\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## Y a-t-il une autocorrélation dans les résidus (y a-t-il un modèle d'erreur ?) ?  \nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## les résidus sont-ils normalement distribués (y a-t-il sous-estimation ou surestimation ?)  \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## comparer les comptages observés à leurs résidus \n  ## il ne devrait pas y avoir de modèle \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## tester formellement l'autocorrélation des résidus\n## H0 est que les résidus proviennent d'une série à bruit blanc (c'est-à-dire aléatoire)\n## Test d'indépendance \n### si la valeur p est significative alors non aléatoire\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 339.52, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#détection-des-épidémies",
    "href": "new_pages/time_series.fr.html#détection-des-épidémies",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.7 Détection des épidémies",
    "text": "23.7 Détection des épidémies\nNous allons démontrer ici deux méthodes (similaires) de détection des épidémies. La première s’appuie sur les sections précédentes. Nous utilisons le paquet trending pour ajuster les régressions aux années précédentes, et puisprédire ce que nous nous attendons à voir l’année suivante. Si les comptages observés sont supérieursce que nous attendons, cela pourrait suggérer qu’il y a une épidémie. La deuxième méthode est basée sur des principes similaires mais utilise le paquet surveillance,qui possède un certain nombre d’algorithmes différents pour la détection des aberrations.\nATTENTION: Normalement, vous vous intéressez à l’année en cours (où vous ne connaissez que les comptages jusqu’à la semaine actuelle). Donc, dans cet exemple, nous prétendons être dans la semaine 39 de 2011.\n\n\ntendance paquet\nPour cette méthode, nous définissons une ligne de base (qui devrait généralement être d’environ 5 ans de données). Nous ajustons une régression aux données de base, puis nous l’utilisons pour prédire les estimations pour l’année suivante.\n\n\nDate limite\nIl est plus facile de définir vos dates à un endroit, puis de les utiliser dans le reste de votre code.\nIci nous définissons une date de début (quand nos observations ont commencé) et une date limite (la fin de notre période de référence - et le début de la période pour laquelle nous voulons prédire).Nous définissons également le nombre de semaines entre la date limite de la période de référence et la date de fin de la période pour laquelle nous sommes intéressés à prédire.\nATTENTION: Dans cet exemple, nous prétendons être actuellement à la fin du mois de septembre 2011 (“2011 W39”).\n\n## définir la date de début (quand les observations ont commencé)\nstart_date &lt;- min(counts$epiweek)\n\n## définir une semaine de coupure (fin de la ligne de base, début de la période de prédiction)\ncut_off &lt;- yearweek(\"2010-12-31\")\n\n## définir la dernière date qui nous intéresse (c'est-à-dire la fin de la prédiction)\nend_date &lt;- yearweek(\"2011-12-31\")\n\n## trouver combien de semaines dans la période (année) d'intérêt.\nnum_weeks &lt;- as.numeric(end_date - cut_off)\n\n\n\n\n23.7.0.1 Ajoutez des lignes {.unnumbered}.\nPour pouvoir faire des prévisions dans un format tidyverse, nous devons avoir le bon nombre de lignes dans notre jeu de données, c’est-à-dire une ligne pour chaque semaine jusqu’à la date de fin définie ci-dessus. Le code ci-dessous vous permet d’ajouter ces lignes par une variable de regroupement - par exemple, si nous avons plusieurs pays dans un même ensemble de données, nous pouvons ajouter des lignes pour chacun d’entre eux. La fonction group_by_key() de tsibble nous permet d’effectuer ce regroupement, et ensuite de passer les données groupées aux fonctions dplyr, group_modify() et add_row(). Ensuite, nous spécifions la séquence des semaines entre une après la semaine maximale actuellement disponible dans les données et la semaine de fin.\n\n## ajouter les semaines manquantes jusqu'à la fin de l'année \ncounts &lt;- counts %&gt;%\n  ## regrouper par région\n  group_by_key() %&gt;%\n  ## pour chaque groupe, ajoutez les lignes à partir de la semaine d'épi la plus élevée jusqu'à la fin de l'année\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))\n\n\n\n\nTermes de Fourier\nNous devons redéfinir nos termes de Fourier, car nous voulons les adapter à la date de base uniquement, puis prédire (extrapoler) ces termes pour l’annee suivante. Pour ce faire, nous devons combiner deux listes de sortie de la fonction fourier() ensemble ; la première est pour les données de base, et la seconde prédit pour l’année qui nous intéresse (en définissant le paramètre fourier()).\nN.b. pour lier les lignes, nous devons utiliser rbind() (plutôt que tidyverse bind_rows) carles colonnes de fourier sont une liste (et ne sont donc pas nommées individuellement).\n\n## définir les termes de fourier (sincos) \ncounts &lt;- counts %&gt;% \n  mutate(\n    ## combiner les termes de fourier pour les semaines avant et après la date limite de 2010\n    ## (nb. les termes de fourier de 2011 sont prédits)\n    fourier = rbind(\n      ## obtenir les termes de fourier pour les années précédentes\n      fourier(\n        ## garder uniquement les lignes avant 2011\n        filter(counts, \n               epiweek &lt;= cut_off), \n        ## inclure un ensemble de termes sin cos \n        K = 1\n        ), \n      ## prédire les termes de fourier pour 2011 (en utilisant les données de base)\n      fourier(\n        ## garder uniquement les lignes avant 2011\n        filter(counts, \n               epiweek &lt;= cut_off),\n        ## inclure un ensemble de termes sin cos \n        K = 1, \n        ## prédire 52 semaines à l'avance\n        h = num_weeks\n        )\n      )\n    )\n\n\n\n\nDiviser les données et ajuster la régression\nNous devons maintenant diviser notre ensemble de données en deux périodes : la période de base et la période de prédiction. Ceci est fait en utilisant la fonction dplyr group_split() après group_by(), et créera une liste avec deux cadres de données, un pour la période avant la coupure et un pour la période après la coupure.\nNous utilisons ensuite la fonction pluck() du paquet purrr pour extraire les ensembles de données de la liste (ce qui équivaut à utiliser des crochets, par exemple dat[[1]]), et nous pouvons alors ajuster notre modèle aux données de base, et ensuite utiliser la fonction predict() pour nos données d’intérêt après la coupure.\nConsultez la page sur l’itération, les boucles et les listes pour en savoir plus sur purrr.\nATTENTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y a des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. \n\n# diviser les données pour l'ajustement et la prédiction\ndat &lt;- counts %&gt;% \n  group_by(epiweek &lt;= cut_off) %&gt;%\n  group_split()\n\n## définir le modèle que vous voulez ajuster (binomial négatif) \nmodel &lt;- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n    fourier\n)\n\n# définir les données à utiliser pour l'ajustement et celles pour la prédiction.\nfitting_data &lt;- pluck(dat, 2)\npred_data &lt;- pluck(dat, 1) %&gt;% \n  select(case_int, epiweek, fourier)\n\n# ajustement du modèle \nfitted_model &lt;- trending::fit(model, data.frame(fitting_data))\n\n# obtenir le confint et les estimations pour les données ajustées\nobserved &lt;- fitted_model %&gt;% \n  predict(simulate_pi = FALSE)\n\n# prévoir avec les données que l'on veut prévoir avec \nforecast &lt;- fitted_model %&gt;% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## combiner les ensembles de données de base et prédits\nobserved &lt;- bind_rows(observed$result, forecast$result)\n\nComme précédemment, nous pouvons visualiser notre modèle avec ggplot. Nous mettons en évidence les alertes avecpoints rouges pour les comptes observés au-dessus de l’intervalle de prédiction de 95 %. Cette fois, nous ajoutons également une ligne verticale pour indiquer quand la prévision commence.\n\n## Tracez votre régression \nggplot(data = observed, aes(x = epiweek)) + \n  ## ajoutez une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne pour le nombre de cas observés\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## Tracez des points pour les nombres observés supérieurs aux prévisions.\n  geom_point(\n    data = filter(observed, case_int &gt; upper_pi), \n    aes(y = case_int), \n    color = \"red\", \n    size = 2) + \n  ## ajouter une ligne verticale et une étiquette pour montrer où la prévision a commencé\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()\n\nWarning: Removed 13 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\nValidation de la prédiction\nAu-delà de l’inspection des résidus, il est important d’étudier la capacité de votre modèle à prédire les cas dans le futur. Cela vous donne une idée de la fiabilité de vos seuils d’alerte.\nLa méthode traditionnelle de validation consiste à voir dans quelle mesure vous pouvez prédire l’année la plus récente avant l’année en cours (parce que vous ne pouvez pas prédire l’année en cours).Par exemple, dans notre ensemble de données, nous utiliserions les données de 2002 à 2009 pour prédire 2010, et ensuite voir si ces prédictions sont exactes. Ensuite, nous réajustons le modèle pour incluredonnées de 2010 et les utiliser pour prédire les comptages de 2011.\nComme on peut le voir dans la figure ci-dessous, réalisée par Hyndman et al dans “Forecasting principles and practice”.\nfigure reproduite avec l’autorisation des auteurs.\nL’inconvénient de cette méthode est que vous n’utilisez pas toutes les données dont vous disposez et que vous n’obtenez pas le modèle final que vous utilisez pour la prédiction.\nUne alternative consiste à utiliser une méthode appelée validation croisée. Dans ce scénario, vous passez en revue toutes les données disponibles pour ajuster plusieurs modèles afin de prédire un an à l’avance. Vous utilisez de plus en plus de données dans chaque modèle, comme le montre la figure ci-dessous tirée de la même [Hyndman et al texte]((https://otexts.com/fpp3/). Par exemple, le premier modèle utilise 2002 pour prédire 2003, le second utilise 2002 et 2003 pour prédire 2004, et ainsi de suite. figure reproduite avec l’autorisation des auteurs.\nDans la figure ci-dessous, nous utilisons la fonction map() du paquet purrr pour boucler sur chaque ensemble de données. Nous mettons ensuite les estimations dans un seul ensemble de données et les fusionnons avec le nombre de cas original, pour utiliser le paquet yardstick pour calculer les mesures de précision. Nous calculons quatre mesures, notamment Erreur quadratique moyenne (RMSE), Erreur absolue moyenne (MAE) l’erreur absolue moyenne mise à l’échelle (MASE), l’erreur absolue moyenne en pourcentage (MAPE).\nCAUTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y a des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. \n\n## Validation croisée : prédire la ou les semaines à venir en fonction de la fenêtre glissante.\n\n## élargissez vos données en les faisant glisser dans des fenêtres de 52 semaines (avant + après). \n## pour prédire les 52 semaines à venir\n## (crée des chaînes d'observations de plus en plus longues - conserve les données plus anciennes)\n\n## définir la fenêtre que l'on veut faire glisser\nroll_window &lt;- 52\n\n## Définir les semaines à venir à prévoir \nweeks_ahead &lt;- 52\n\n## créer un ensemble de données répétitives, de plus en plus longues.\n## étiqueter chaque ensemble de données avec un identifiant unique.\n## utiliser seulement les cas avant l'année d'intérêt (i.e. 2011)\ncase_roll &lt;- counts %&gt;% \n  filter(epiweek &lt; cut_off) %&gt;% \n  ## Garder uniquement les variables de la semaine et du nombre de cas.\n  select(epiweek, case_int) %&gt;% \n    ## laisser tomber les x dernières observations \n    ## en fonction du nombre de semaines d'anticipation de la prévision. \n    ## (sinon ce sera une prévision réelle à \"inconnu\")\n    slice(1 :(n() - weeks_ahead)) %&gt;%\n    as_tsibble(index = epiweek) %&gt;% \n    ## reconduire chaque semaine dans x après les fenêtres pour créer l'ID de regroupement \n    ## en fonction de la fenêtre de roulement spécifiée\n    stretch_tsibble(.init = roll_window, .step = 1) %&gt;% \n  ## laisser tomber les deux premiers - car il n'y a pas de cas \"avant\".\n  filter(.id &gt; roll_window)\n\n\n## pour chacun des ensembles de données uniques, exécutez le code ci-dessous\nforecasts &lt;- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## garder uniquement le pli courant en cours d'ajustement \n  mini_data &lt;- filter(case_roll, .id == i) %&gt;% \n    as_tibble()\n  \n  ## créer un ensemble de données vides pour la prévision sur \n  forecast_data &lt;- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## ajouter les données de prévision à l'original \n  mini_data &lt;- bind_rows(mini_data, forecast_data)\n  \n  ## définir le cut off basé sur les dernières données de comptage non manquantes. \n  cv_cut_off &lt;- mini_data %&gt;% \n    ## ne garder que les lignes non manquantes\n    drop_na(case_int) %&gt;% \n    ## obtenir la dernière semaine\n    summarise(max(epiweek)) %&gt;% \n    ## extraire ce qui n'est pas dans un dataframe\n    pull()\n  \n  ## Remettre mini_data dans un tsibble\n  mini_data &lt;- tsibble(mini_data, index = epiweek)\n  \n  ## définir les termes de fourier (sincos) \n  mini_data &lt;- mini_data %&gt;% \n    mutate(\n    ## Combinez les termes de Fourier pour les semaines avant et après la date limite.\n    fourier = rbind(\n      ## obtenir les termes de fourier pour les années précédentes\n      forecast::fourier(\n        ### ne conserve que les lignes avant la date butoir\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off), \n        ## inclure un ensemble de termes sin cos \n        K = 1\n        ), \n      ## prédire les termes de fourier pour l'année suivante (en utilisant les données de base)\n      fourier(\n        ## conserver uniquement les lignes avant la coupure\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off),\n        ## inclure un ensemble de termes sin cos \n        K = 1, \n        ## prédire 52 semaines à l'avance\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # diviser les données pour l'ajustement et la prédiction\n  dat &lt;- mini_data %&gt;% \n    group_by(epiweek &lt;= cv_cut_off) %&gt;%\n    group_split()\n\n  ## définir le modèle que vous voulez ajuster (binomiale négative) \n  model &lt;- glm_nb_model(\n    ## définir le nombre de cas comme résultat d'intérêt\n    case_int ~\n      ## utiliser epiweek pour tenir compte de la tendance\n      epiweek +\n      ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n      fourier\n  )\n\n  # définir les données à utiliser pour l'ajustement et celles pour la prédiction.\n  fitting_data &lt;- pluck(dat, 2)\n  pred_data &lt;- pluck(dat, 1)\n  \n  # ajuster le modèle \n  fitted_model &lt;- trending::fit(model, data.frame(fitting_data))\n  \n  # prévoir avec les données que l'on veut prédire avec \n  forecasts &lt;- fitted_model %&gt;% \n    predict(data.frame(pred_data), simulate_pi = FALSE) \n forecasts &lt;- data.frame(forecasts$result[[1]]) %&gt;% \n      ## garder seulement la semaine et l'estimation de la prévision\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## Transformer la liste en un cadre de données avec toutes les prévisions.\nforecasts &lt;- bind_rows(forecasts)\n\n## joindre les prévisions aux données observées\nforecasts &lt;- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## en utilisant {yardstick} calculer les métriques\n  ## RMSE : Root mean squared error (erreur quadratique moyenne)\n  ## MAE : Erreur absolue moyenne   \n  ## MASE : Mean absolute scaled error (erreur absolue moyenne mise à l'échelle)\n  ## MAPE : Erreur absolue moyenne en pourcentage\nmodel_metrics &lt;- bind_rows(\n  ## dans votre ensemble de données forcées, comparez les données observées aux données prédites.\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %&gt;% \n  ### ne conserve que le type de métrique et sa sortie\n  select(Metric = .metric, \n         Measure = .estimate) %&gt;% \n  ## faire en sorte que le format soit large pour pouvoir lier les lignes ensuite\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## Retourner les métriques du modèle \nmodel_metrics\n\n# A tibble: 1 × 4\n   rmse   mae  mase  mape\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  252.  199.  1.96  17.3\n\n\n\n\n\n\nsurveillance paquet\nDans cette section, nous utilisons le paquet surveillance pour créer des seuils d’alerte basés sur des algorithmes de détection d’épidémies. Il existe plusieurs méthodes différentes disponibles dans le paquet, mais nous nous concentrerons ici sur deux options. Pour plus de détails, voir ces articles sur l’application et théorie des alogirths utilisés.\nLa première option utilise la méthode améliorée de Farrington. Celle-ci ajuste un glm binomial négatif (y compris la tendance) et pondère à la baisse les épidémies passées (valeurs aberrantes) pour créer un niveau de seuil.\nLa deuxième option utilise la méthode glrnb. Celle-ci ajuste également un glm binomial négatif binomiale négative, mais inclut la tendance et les termes de Fourier (elle est donc privilégiée ici). La régression est utilisée pour calculer la “moyenne de contrôle” (~valeurs ajustées) - elle utilise ensuite une statistique de rapport de vrai semblance généralisé calculé pour évaluer s’il y a un changement de la moyenne pour chaque semaine. Notez que le seuil pour chaque semaine prend en compte les semaines précédentes, de sorte que s’il y a un changement soutenu, une alarme sera déclenchée. (Notez également qu’après chaque alarme, l’algorithme est réinitialisé).\nAfin de travailler avec le paquet surveillance, nous devons d’abord définir un objet “série temporelle de surveillance” (en utilisant la fonction sts()) pour s’intégrer dans le cadre.\n\n## Définir un objet de série temporelle de surveillance\n## nb. vous pouvez inclure un dénominateur avec l'objet population (voir ?sts)\ncounts_sts &lt;- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## sous-ensemble pour ne garder que l'année de start_date. \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## sous-ensemble pour ne conserver que la semaine à partir de la date de départ\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## définir le type de données (dans ce cas, hebdomadaire)\n                  freq = 52)\n\n## définir la plage de semaines que vous voulez inclure (c'est-à-dire la période de prédiction)\n## nb. l'objet sts ne compte que les observations sans leur attribuer un identifiant de semaine ou d'année. \n## d'année - nous utilisons donc nos données pour définir les observations appropriées.\nweekrange &lt;- cut_off - start_date\n\n\n\nMéthode Farrington\nNous définissons ensuite chacun de nos paramètres pour la méthode de Farrington dans une liste. Ensuite, nous exécutons l’algorithme en utilisant farringtonFlexible() et ensuite nous pouvons extraire le seuil d’une alerte en utilisant farringtonmethod@upperbound pour l’inclure dans notre données. Il est également possible d’extraire un VRAI/FAUX pour chaque semaine si elle a déclenché une alerte (au-dessus du seuil) en utilisant farringtonmethod@alarm.\n\n## définir le contrôle\nctrl &lt;- list(\n  ## définissez la période pour laquelle vous voulez un seuil (i.e. 2011)\n  range = which(counts_sts@epoch &gt; weekrange),\n  b = 9, ## nombre d'années en arrière pour la ligne de base\n  w = 2, ## taille de la fenêtre de roulement en semaines\n  weightsThreshold = 2.58, ## repondération des épidémies passées (méthode noufaily améliorée - l'originale suggère 1)\n  ## pastWeeksNotIncluded = 3, ## utilisation de toutes les semaines disponibles (noufaily suggère d'en éliminer 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normalement, mais 1 est conseillé dans la méthode améliorée (c'est-à-dire toujours garder)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## appliquer la méthode flexible de Farrington\nfarringtonmethod &lt;- farringtonFlexible(counts_sts, ctrl)\n\n## créer une nouvelle variable dans le jeu de données original appelée threshold.\n## contenant la limite supérieure de Farrington. \n## nb. ceci est seulement pour les semaines de 2011 (donc besoin de sous-ensembler les lignes)\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] &lt;- farringtonmethod@upperbound\n\nNous pouvons ensuite visualiser les résultats dans ggplot comme nous l’avons fait précédemment.\n\nggplot(counts, aes(x = epiweek)) + \n  ## ajouter le nombre de cas observés sous forme de ligne\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## ajout de la limite supérieure de l'algorithme d'aberration\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## définir les couleurs\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic() + \n  ## supprimer le titre de la légende \n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nMéthode GLRNB\nDe même pour la méthode GLRNB, nous définissons chacun de nos paramètres pour le dans une liste, puis nous ajustons l’algorithme et extrayons les limites supérieures.\nATTENTION: Cette méthode utilise la “force brute” (similaire au bootstrapping) pour calculer les seuils, donc peut prendre beaucoup de temps!.\nVoir la vignette GLRNB pour plus de détails.\n\n## définir les options de contrôle\nctrl &lt;- list(\n  ## définir la période pour laquelle on veut un seuil (i.e. 2011)\n  range = which(counts_sts@epoch &gt; weekrange),\n  mu0 = list(S = 1, ## nombre de termes de fourier (harmoniques) à inclure\n  trend = TRUE, ## inclusion ou non de la tendance\n  refit = FALSE), ## si l'on refit le modèle après chaque alarme\n  ## cARL = seuil pour la statistique GLR (arbitraire)\n     ## 3 ~ seuil intermédiaire pour minimiser les faux positifs\n     ## 1 s'ajuste aux 99%PI de glm.nb - avec des changements après les pics (seuil abaissé pour l'alerte)\n   c.ARL = 2,\n   # thêta = log(1.5), ## équivaut à une augmentation de 50% des cas dans une épidémie\n   ret = \"cases\" ## retourne la limite supérieure du seuil sous forme de nombre de cas\n  )\n\n## appliquer la méthode glrnb\nglrnbmethod &lt;- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## créer une nouvelle variable dans l'ensemble de données original appelée threshold\n## contenant la limite supérieure de glrnb. \n## nb. ceci est seulement pour les semaines de 2011 (donc besoin de sous-ensembler les lignes)\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] &lt;- glrnbmethod@upperbound\n\nVisualisez les sorties comme précédemment.\n\nggplot(counts, aes(x = epiweek)) + \n  ## ajouter le nombre de cas observés sous forme de ligne\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## ajout de la limite supérieure de l'algorithme d'aberration\n  geom_line(aes(y = threshold_glrnb, color = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## définir les couleurs\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic() + \n  ## supprimer le titre de la légende \n  theme(legend.title = element_blank())",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#série-chronologique-interrompue",
    "href": "new_pages/time_series.fr.html#série-chronologique-interrompue",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.8 Série chronologique interrompue",
    "text": "23.8 Série chronologique interrompue\nLes séries chronologiques interrompues (également appelées régression segmentée ou analyse d’intervention), est souvent utilisée pour évaluer l’impact des vaccins sur l’incidence des maladies. Mais elle peut être utilisée pour évaluer l’impact d’un large éventail d’interventions ou d’introductions. Par exemple, des changements dans les procédures hospitalières ou l’introduction d’une nouvelle souche de maladie dans une population. Dans cet exemple, nous supposerons qu’une nouvelle souche de Campylobacter a été introduite en Allemagne fin 2008, et nous verrons si cela affecte le nombre de cas. Nous utiliserons à nouveau la régression binomiale négative. Cette fois-ci, la régression sera divisée en deux parties, l’une avant l’intervention (ou l’introduction de la nouvelle souche ici) et une autre après (les périodes pré et post). Cela nous permet de calculer un ratio de taux d’incidence comparant les deux périodes. Une explication de l’équation pourrait rendre les choses plus claires (sinon, ignorez-la !).\nLa régression binomiale négative peut être définie comme suit :\n\\[\\log(Y_t)= Î²_0 + Î²_1 \\times t+ Î²_2 \\times Î´(t-t_0) + Î²_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]\nOù : \\(Y_t\\) est le nombre de cas observés au temps \\(t\\).\n\\(pop_t\\) est la taille de la population en 100 000 au moment \\(t\\) (non utilisé ici)\n\\(t_0\\) est la dernière année de la pré-période (y compris la période de transition, le cas échéant).\n\\(Î'(x\\) est la fonction indicatrice (elle vaut 0 si xâ¤0 et 1 si x&gt;0)\n\\((x)^+\\) est l’opérateur de coupure (il vaut x si x&gt;0 et 0 sinon)\n\\(e_t\\) désigne le résidu Des termes supplémentaires, tendance et saison, peuvent être ajoutés si nécessaire.\n\\(Î²_2 \\times Î'(t-t_0) + Î²_3\\times(t-t_0 )^+\\) est la partie linéaire généralisée de la post-période et est nulle dans la pré-période. Cela signifie que les estimations de \\(Î²_2\\) et \\(Î²_3\\) sont les effets de l’intervention.\nNous devons recalculer les termes de fourier sans faire de prévision ici, car nous utiliserons toutes les données dont nous disposons (c’est-à-dire rétrospectivement). De plus, nous devons calculerles termes supplémentaires nécessaires à la régression.\n\n## ajouter les termes de fourier en utilisant les variabless epiweek et case_int\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  fourier(K = 1)\n\n## définir la semaine d'intervention \nintervention_week &lt;- yearweek(\"2008-12-31\")\n\n## définir les variables pour la régression \ncounts &lt;- counts %&gt;% \n  mutate(\n    ## correspond à t dans la formule\n      ## nombre de semaines (on pourrait probablement aussi utiliser la variable epiweeks)\n    # linear = row_number(epiweek), \n    ## correspond au delta(t-t0) dans la formule\n      ## période de pré ou post intervention\n    intervention = as.numeric(epiweek &gt;= intervention_week), \n    ## correspond à (t-t0)^+ dans la formule\n      ## nombre de semaines après l'intervention\n      ## (choisir le plus grand nombre entre 0 et ce qui ressort du calcul)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n\nNous utilisons ensuite ces termes pour ajuster une régression binomiale négative, et produisons un tableau avec le pourcentage de changement. Cet exemple montre qu’il n’y a pas eu de changement significatif.\nATTENTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y a des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. \n\n## définissez le modèle que vous voulez ajuster (binomial négatif). \nmodel &lt;- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes fourier pour tenir compte de la saisonnalité\n    fourier + \n    ## ajouter si dans la pré ou post-période \n    intervention + \n    ## ajouter le temps après l'intervention \n    time_post\n    )\n\n## ajustez votre modèle en utilisant l'ensemble de données de comptage\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n### calculer les intervalles de confiance et les intervalles de prédiction \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\n\n## Afficher les estimations et le pourcentage de changement dans un tableau\nfitted_model %&gt;% \n  ## extraire la régression binomiale négative originale\n  get_fitted_model() %&gt;% \n  ## obtenir un cadre de données ordonné des résultats\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %&gt;% ### ne conserve que les valeurs d'intervention \n  ### ne conserve que la valeur d'intervention \n  filter(term == \"intervention\") %&gt;% \n  ## changer le IRR en pourcentage de changement pour l'estimation et les ICs \n  mutate(\n    ## pour chacune des colonnes d'intérêt - créer une nouvelle colonne\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## appliquer la formule pour calculer le pourcentage de changement\n            .f = function(i) 100 * (i - 1), \n      ## ajouter un suffixe aux nouveaux noms de colonnes avec \"_perc\".\n      .names = \"{.col}_perc\")\n    ) %&gt;% \n  ## ne garder (et renommer) que certaines colonnes \n  select( \"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Variation in percentag\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)\n\nComme précédemment, nous pouvons visualiser les résultats de la régression.\n\nestimate_res &lt;- data.frame(observed$result)\n\nggplot(estimate_res, aes(x = epiweek)) + \n  ## ajouter le nombre de cas observés sous forme de ligne\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## ajout d'une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne verticale et une étiquette pour montrer où la prévision a commencé\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(estimate_res$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## définir les couleurs\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.fr.html#ressources",
    "href": "new_pages/time_series.fr.html#ressources",
    "title": "23  Série temporelle et détection des épidémies",
    "section": "23.9 Ressources",
    "text": "23.9 Ressources\nPrévision : principes et pratique - manuel\nÉtudes de cas d’analyse de séries temporelles EPIET\nCours de Penn State Manuscrit du paquet de surveillance",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Série temporelle et détection des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.fr.html",
    "href": "new_pages/epidemic_models.fr.html",
    "title": "24  Modélisation des épidémies",
    "section": "",
    "text": "24.1 Overview\nIl existe un nombre croissant d’outils pour la modélisation des épidémies qui nous permettent de mener des analyses assez complexes avec un effort minimal.Cette section fournira une aperçu sur la façon d’utiliser ces outils pour :\nIl ne s’agit pas d’un aperçu des méthodologies et des méthodes statistiques qui sous-tendent ces outils. Veuillez donc vous référer à l’onglet Ressources pour des liens vers des documents traitant de ce sujet. Assurez-vous d’avoir une bonne compréhension des les méthodes avant d’utiliser ces outils ; cela vous permettra d’interpréter correctement leurs résultats.\nVoici un exemple de l’un des résultats que nous produirons dans cette section.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modélisation des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.fr.html#overview",
    "href": "new_pages/epidemic_models.fr.html#overview",
    "title": "24  Modélisation des épidémies",
    "section": "",
    "text": "estimer le nombre de reproduction effectif Rt et les statistiques connexes. telles que le temps de doublement\nproduire des projections à court terme de l’incidence future.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modélisation des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.fr.html#préparation",
    "href": "new_pages/epidemic_models.fr.html#préparation",
    "title": "24  Modélisation des épidémies",
    "section": "24.2 Préparation",
    "text": "24.2 Préparation\nNous allons utiliser deux méthodes et packages différents pour l’estimation Rt, à savoir EpiNow et EpiEstim, ainsi que le package projections pour la prévision de l’incidence des cas.\nCe fragment de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur R basics pour plus d’informations sur les paquets R.\n\npacman::p_load(\n   rio, # Importation de fichiers\n   here, # Localisation de fichiers\n   tidyverse, # Gestion des données + graphiques ggplot2\n   epicontacts, # Analyse des réseaux de transmission\n   EpiNow2, # Estimation de Rt\n   EpiEstim, # Estimation Rt\n   projections, # Projections d'incidence\n   incidence2, # Traitement des données d'incidence\n   epitrix, # Fonctions epi utiles\n   distcrete # Distributions discrètes des délais\n)\n\nNous utiliserons la linelist de cas nettoyée pour toutes les analyses de cette section. Si vous voulez suivre, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Consultez la page Télécharger le manuel et les données pour télécharger tous les exemples de données utilisés dans ce manuel.\n\n# Importez la liste de cas nettoyée\nlinelist &lt;- import(\"linelist_cleaned.rds\")",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modélisation des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.fr.html#estimation-de-rt",
    "href": "new_pages/epidemic_models.fr.html#estimation-de-rt",
    "title": "24  Modélisation des épidémies",
    "section": "24.3 Estimation de Rt",
    "text": "24.3 Estimation de Rt\n\nEpiNow2 vs. EpiEstim\nLe taux de reproduction R est une mesure de la transmissibilité d’une maladie, et est défini comme le nombre attendu de cas secondaires par cas infecté. Dans une population totalement sensible, cette valeur représente le nombre de reproduction de base, R0. Cependant, comme le nombre d’individus sensibles dans une population évolue au cours d’une épidémie ou d’une pandémie, et que diverses mesures de réponse sont mises en œuvre, la mesure la plus couramment utilisée de la transmissibilité est le taux de reproduction effectif, Rt ; il est défini défini comme le nombre attendu de cas secondaires par cas infecté à un moment, t.\nLe paquet EpiNow2 fournit le cadre le plus sophistiqué pour l’estimation de Rt. Il présente deux avantages essentiels par rapport à l’autre paquet couramment utilisé, EpiEstim :\n\nIl tient compte des délais de déclaration et peut donc estimer Rt même lorsque les données récentes sont incomplètes.\nIl estime Rt sur les dates d’infection plutôt que sur les dates de début de déclaration, ce qui signifie que l’effet d’une intervention sera immédiatement reflété dans un changement de Rt, plutôt qu’avec un delai.\n\nCependant, elle présente également deux inconvénients majeurs :\n\nElle nécessite la connaissance de la distribution des temps de génération (c’est-à-dire la distribution des délais entre l’infection d’un cas primaire et d’un cas secondaire), la distribution de la période d’incubation (c’est-à-dire la distribution des délais entre l’infection et l’apparition des symptômes) et toute autre distribution de délai pertinente pour vos données (par exemple, si vous avez des dates de déclaration, vous avez besoin de la distribution des délais entre l’apparition des symptômes et la déclaration, ou la période d’incubation). Bien que cela permette une estimation plus précise de Rt, EpiEstim ne requiert que la distribution de l’intervalle sériel (c’est-à-dire la distribution des délais entre l’apparition des symptômes d’un cas primaire et d’un cas secondaire), qui peut être la seule distribution disponible pour vous.\nEpiNow2 est significativement plus lent que EpiEstim, de manière anecdotique par un facteur de 100 à 1000 ! Par exemple, l’estimation de Rt pour l’échantillon de foyers considéré dans cette section prend environ quatre heures (ceci a été exécuté pour un grand d’itérations pour garantir une grande précision et pourrait probablement être réduite si nécessaire) mais il n’en reste pas moins que l’algorithme est lent en général. Cela peut être irréalisable si vous mettez régulièrement à jour votre base de données pour Rt.\n\nLe paquet que vous choisirez d’utiliser dépendra donc des données, du temps et des ressources informatiques dont vous disposez.\n\n\nEpiNow2\n\n24.3.0.1 Estimation des distributions de retard\nLes distributions de retard requises pour exécuter EpiNow2 dépendent des données dont vous disposez. Essentiellement, vous devez être en mesure de décrire le délai entre la date d’infection à la date de l’événement que vous voulez utiliser pour estimer Rt. Si vous utilisez les dates d’apparition, il s’agit simplement de la distribution de la période d’incubation. Si vous utilisez les dates de déclaration, vous avez besoin du délai entre l’infection et la déclaration. Comme il est peu probable que cette distribution soit connue directement, EpiNow2 vous permet d’enchaîner plusieurs distributions de délai ; dans ce cas, le délai entre l’infection et la déclaration est le même.\nComme nous disposons des dates d’apparition des symptômes pour tous nos cas dans la liste d’exemples, nous n’aurons besoin que de la distribution de la période d’incubation pour déterminer le délai d’apparition des symptômes.Nous pouvons soit estimer cette distribution à partir des données ou utiliser les valeurs de la littérature.\nUne estimation de la période d’incubation d’Ebola dans la littérature (tirée de cet article) avec une moyenne de 9,1, un écart-type de 7,3 et une valeur maximale de 30, serait spécifiée comme suit :\n\nincubation_period_lit &lt;- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n\nNotez que EpiNow2 exige que ces distributions de délais soient fournies sur une échelle log d’où l’appel log autour de chaque valeur (sauf le paramètre max qui doit être fourni sur une échelle naturelle). Les paramètres mean_sd et sd_sd définissent l’écart type des estimations de la moyenne. Comme ceux-ci ne sont pas connus dans ce cas, nous choisissons la valeur assez arbitraire de 0.1.\nDans cette analyse, nous estimons plutôt la distribution de la période d’incubation à partir de la linelist elle-même en utilisant la fonction bootstrapped_dist_fit, ce qui va une distribution lognormale aux délais observés entre l’infection et l’apparition de la maladie.\n\n## Estimation de la période d'incubation\nincubation_period &lt;- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n\nL’autre distribution dont nous avons besoin est le temps de génération. Comme nous avons des données sur les temps d’infection et les liens de transmission, nous pouvons estimer cette distribution à partir de la liste de liens en calculant le délai entre les temps d’infection des paires infecteur-infecte. Pour ce faire, nous utilisons la fonction pratique get_pairwise du paquet epicontacts, qui nous permet de calculer les différences par paire des propriétés de la linelist entre les paires de transmission. Nous créons d’abord un objet epicontacts (voir la page Chaînes de transmission pour plus de détails) :\n\n## générer des contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## générer un objet epicontacts\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nNous ajustons ensuite la différence de temps d’infection entre les paires de transmission, calculée en utilisant get_pairwise, à une distribution gamma :\n\n## estimation du temps de génération gamma\ngeneration_time &lt;- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)\n\n\n\nExécution de EpiNow2\nMaintenant, il ne nous reste plus qu’à calculer l’incidence journalière à partir de la liste linéaire, ce que nous pouvons faire facilement avec les fonctions dplyr group_by() et n(). Notez que EpiNow2 exige que les noms des colonnes soient date et confirm.\n\n## Obtenir l'incidence à partir des dates d'apparition\ncases &lt;- linelist %&gt;%\n  group_by(date = date_onset) %&gt;%\n  summarise(confirm = n())\n\nNous pouvons ensuite estimer Rt en utilisant la fonction epinow. Quelques remarques sur les entrées :\n\nNous pouvons fournir n’importe quel nombre de distributions de délais “enchaînés” à l’argument delays. Nous les insérons simplement à côté de l’objet incubation_period dans la fonction delay_opts.\nreturn_output permet de s’assurer que la sortie est retournée dans R et pas seulement un fichier.\nverbose spécifie que nous voulons une lecture de la progression.\nhorizon indique pour combien de jours nous voulons projeter l’incidence future.\nNous passons des options supplémentaires à l’argument stan pour spécifier combien de temps nous voulons exécuter l’inférence pour. L’augmentation de samples et de chains vous donnera une estimation plus précise qui caractérisera mieux l’incertitude.\n\nCependant, l’exécution sera plus longue.\n\n## exécuter epinow\nepinow_res &lt;- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)\n\n\n\nAnalyser les sorties\nUne fois l’exécution du code terminée, nous pouvons tracer un résumé très facilement comme suit. Faites défiler l’image pour voir l’étendue complète.\n\n## Tracer la figure récapitulative\nplot(epinow_res)\n\n\n\n\n\n\n\n\nNous pouvons également examiner diverses statistiques sommaires :\n\n## tableau récapitulatif\nepinow_res$summary\n\n                                 measure                  estimate\n                                  &lt;char&gt;                    &lt;char&gt;\n1: New confirmed cases by infection date                4 (2 -- 6)\n2:        Expected change in daily cases                    Unsure\n3:            Effective reproduction no.        0.88 (0.73 -- 1.1)\n4:                        Rate of growth -0.012 (-0.028 -- 0.0052)\n5:          Doubling/halving time (days)          -60 (130 -- -25)\n    numeric_estimate\n              &lt;list&gt;\n1: &lt;data.table[1x9]&gt;\n2:              0.56\n3: &lt;data.table[1x9]&gt;\n4: &lt;data.table[1x9]&gt;\n5: &lt;data.table[1x9]&gt;\n\n\nPour des analyses plus approfondies et des tracés personnalisés, vous pouvez accéder aux estimations quotidiennes résumées via $estimates$summarised. Nous allons convertir le tableau par défaut data.table en un tibble pour faciliter l’utilisation avec dplyr.\n\n## extraire le résumé et le convertir en tibble\nestimates &lt;- as_tibble(epinow_res$estimates$summarised)\nestimates\n\n\n\n\n\n\n\nA titre d’exemple, faisons un graphique du temps de doublement et de Rt. Nous n’examinerons que les premiers mois de l’épidémie, lorsque Rt est largement supérieur à un, pour éviter de tracer des temps de doublement extrêmement élevés.\nNous utilisons la formule log(2)/taux de croissance pour calculer le temps de doublement à partir du taux de croissance estimé.\n\n## faire des df larges pour le tracé de la médiane\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date &lt; as.Date(\"2014-09-01\")\n  ) %&gt;%\n  ## convertir les taux de croissance en temps de doublement\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## renommer la variable pour refléter la transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## créer des df longs pour le tracé des quantiles\ndf_long &lt;- df_wide %&gt;%\n  ## ici, nous faisons correspondre les quantiles (par exemple, lower_90 à upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## créer un graphique\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## utiliser label_parsed pour permettre l'utilisation d'une étiquette en indice\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## définir manuellement la transparence des quantiles\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nEpiEstim\nPour exécuter EpiEstim, nous devons fournir des données sur l’incidence journalière et spécifier l’intervalle sériel (c’est-à-dire la distribution des délais entre l’apparition des symptômes des cas primaires et secondaires).\nLes données d’incidence peuvent être fournies à EpiEstim sous la forme d’un vecteur, d’un cadre de données ou d’un objet incidence provenant du paquetage original incidence. Vous pouvez même faire la distinction entre les importations et les infections acquises localement ; voir la documentation de ?estimate_R pour plus de détails.\nNous allons créer l’entrée en utilisant incidence2. Voir la page sur Epidemic curves pour plus d’exemples avec le paquet incidence2. Comme il y a eu des mises à jour du paquet incidence2 qui ne correspondent pas complètement à l’entrée attendue de estimateR(), quelques étapes supplémentaires mineures sont nécessaires. L’objet incidence consiste en un tibble avec des dates et leurs nombres de cas respectifs. Nous utilisons complete() de tidyr pour nous assurer que toutes les dates sont incluses (même celles sans cas), puis nous rename() les colonnes pour les aligner avec ce qui est attendu par estimate_R() dans une étape ultérieure.\n\n## Obtenir l'incidence à partir de la date d'apparition\ncases &lt;- incidence2::incidence(linelist, date_index = \"date_onset\") %&gt;% # obtient le nombre de cas par jour\n  tidyr::complete(date_index = seq.Date( # s'assurer que toutes les dates sont représentées\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %&gt;% # convertit les comptes NA en 0\n  rename(I = count, # renomme aux noms attendus par estimateR\n         dates = date_index)\n\nLe paquetage fournit plusieurs options pour spécifier l’intervalle sériel, dont les détails sont fournis dans la documentation de ?estimate_R.\n\nUtiliser des estimations d’intervalles sériels issues de la littérature\nEn utilisant l’option method = \"parametric_si\", nous pouvons spécifier manuellement la moyenne et l’écart type de l’intervalle sériel dans la littérature ou dans un objet config créé à l’aide de la fonction make_config. Nous utilisons une moyenne et un écart-type de 12.0 et 5.2, respectivement, définis dans cet article :\n\n## créer config\nconfig_lit &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\n\nNous pouvons ensuite estimer Rt avec la fonction estimate_R :\n\ncases &lt;- cases %&gt;% \n     filter(!is.na(date))\n\n\n#créer un cadre de données pour la fonction estimate_R()\ncases_incidence &lt;- data.frame(dates = seq.Date(from = min(cases$dates),\n                               to = max(cases$dates), \n                               by = 1))\n\ncases_incidence &lt;- left_join(cases_incidence, cases) %&gt;% \n     select(dates, I) %&gt;% \n     mutate(I = ifelse(is.na(I), 0, I))\n\nJoining with `by = join_by(dates)`\n\nepiestim_res_lit &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_lit\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n\net tracer un résumé des résultats :\n\nplot(epiestim_res_lit)\n\n\n\n\n\n\n\n\n\n\nUtilisation d’estimations d’intervalles en série à partir des données\nComme nous avons des données sur les dates d’apparition des symptômes et les liens de transmission, nous pouvons également estimer l’intervalle sériel à partir de la liste de liens en calculant le délai entre les dates d’apparition des symptômes des paires infecteur-infecté. Comme nous l’avons fait dans la section EpiNow2 nous allons utiliser la fonction get_pairwise du paquet epicontacts qui nous permet de calculer les différences par paires des propriétés de la liste de liens entre les paires de transmission. Nous créons d’abord un objet epicontacts (voir la page Chaînes de transmission pour plus de détails) :\n\n## générer des contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## générer un objet epicontacts\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nNous ajustons ensuite la différence de dates d’apparition entre les paires de transmissions, calculée en utilisant get_pairwise, à une distribution gamma. Nous utilisons l’outil pratique fit_disc_gamma du paquet epitrix pour cette procédure d’ajustement, car nous avons besoin d’une distribution discrète.\n\n## Estimation de l'intervalle sériel gamma\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\nNous passons ensuite ces informations à l’objet config, exécutons EpiEstim et traçons les résultats :\n\n## faire le config\nconfig_emp &lt;- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## Exécuter epiestim\nepiestim_res_emp &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_emp\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n## tracer les résultats\nplot(epiestim_res_emp)\n\n\n\n\n\n\n\n\n\n\nSpécification des fenêtres temporelles d’estimation\nCes options par défaut fournissent une estimation hebdomadaire glissante et peuvent servir d’avertissement si vous estimez Rt trop tôt dans l’épidémie pour une estimation précise.Vous pouvez changer cela en fixant une date de début ultérieure pour l’estimation de Rt, comme indiqué ci-dessous.\nMalheureusement, EpiEstim n’offre qu’une façon très maladroite de spécifier ces temps d’estimation, en ce sens que vous devez fournir un vecteur d’entiers __ se référant aux dates de début et de fin de chaque fenêtre temporelle.\n\n## définir un vecteur de dates commençant le 1er juin\nstart_dates &lt;- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %&gt;%\n  ## soustraire la date de départ pour la convertir en numérique\n  `-`(min(cases$dates)) %&gt;%\n  ## convertir en entier\n  as.integer()\n\n## ajouter six jours pour une fenêtre glissante d'une semaine\nend_dates &lt;- start_dates + 6\n  \n## faire la configuration\nconfig_partial &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n\nMaintenant, nous réexécutons EpiEstim et nous pouvons voir que les estimations ne commencent qu’à partir de juin :\n\n## exécuter epiestim\nepiestim_res_partial &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## tracer les résultats\nplot(epiestim_res_partial)\n\n\n\n\n\n\n\n\n\n\nAnalyser les sorties\nLes principales sorties sont accessibles via $R. A titre d’exemple, nous allons créer un graphe de Rt et une mesure de “potentiel de transmission” donnée par le produit de Rt et du nombre de cas signalés ce jour-là ; cela représente le nombre attendu de cas dans la prochaine génération d’infection.\n\n## créer un cadre de données large pour la médiane\ndf_wide &lt;- epiestim_res_lit$R %&gt;%\n  rename_all(clean_labels) %&gt;%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %&gt;%\n  mutate(\n    ## extraire la date médiane de t_start et t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %&gt;%\n  ## fusionner les données d'incidence quotidienne\n  left_join(cases, \"dates\") %&gt;%\n  ## calculer le risque pour toutes les estimations r\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %&gt;%\n  ## séparer les estimations de r et les estimations de risque\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %&gt;%\n  ## Assigner des niveaux de facteurs\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## créer un cadre de données long à partir des quantiles\ndf_long &lt;- df_wide %&gt;%\n  select(-variable, -median) %&gt;%\n  ## séparer les estimations de r/risque et les niveaux de quantile\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %&gt;%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## créer un graphique\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## utiliser label_parsed pour permettre l'utilisation d'une étiquette en indice\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left' \n  ) +\n  ## définir manuellement la transparence des quantiles\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside' \n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modélisation des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.fr.html#projection-de-lincidence",
    "href": "new_pages/epidemic_models.fr.html#projection-de-lincidence",
    "title": "24  Modélisation des épidémies",
    "section": "24.4 Projection de l’incidence",
    "text": "24.4 Projection de l’incidence\n\nEpiNow2\nEn plus de l’estimation de Rt, EpiNow2 permet également la prévision de Rt et les projections du nombre de cas par l’intégration avec le paquet EpiSoon sous le capot. Tout ce que vous avez à faire est de spécifier l’argument horizon dans votre appel de fonction epinow, indiquant le nombre de jours que vous voulez projeter dans le futur ; voir la section EpiNow2 sous la rubrique “Estimation Rt” pour plus de détails sur la façon de mettre en place EpiNow2. Dans cette section, nous allons simplement tracer les sorties de cette analyse, stockées dans le fichier l’objet epinow_res.\n\n## définir la date minimale pour le tracé\nmin_date &lt;- as.Date(\"2015-03-01\")\n\n## extraire les estimations résumées\nestimates &lt;- as_tibble(epinow_res$estimates$summarised)\n\n## extraire les données brutes sur l'incidence des cas\nobservations &lt;- as_tibble(epinow_res$estimates$observations) %&gt;%\n  filter(date &gt; min_date)\n\n## extraire les estimations prévisionnelles du nombre de cas\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date &gt; min_date\n  )\n\n## convertir en un format encore plus long pour le tracé des quantiles\ndf_long &lt;- df_wide %&gt;%\n  ## ici nous faisons correspondre les quantiles (par exemple, lower_90 à upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## créer un graphique\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## Définir manuellement la transparence des quantiles\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n    theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\nprojections\nLe paquet projections développé par RECON permet de faire très facilement des prévisions d’incidence à court terme, ne nécessitant que la connaissance du nombre de reproduction effectif de reproduction Rt et de l’intervalle de série. Nous verrons ici comment utiliser des estimations d’intervalle sériel de la littérature et comment utiliser nos propres estimations de la liste de diffusion.\n\nUtiliser les estimations d’intervalles sériels de la littérature\nprojections nécessite une distribution d’intervalle série discrétisée de la classe distcrete du paquet distcrete. Nous utiliserons une distribution gamma avec une moyenne de 12,0 et un écart-type de 5,2 définie dans cet article. Pour convertir ces valeurs en paramètres de forme et d’échelle requis pour une distribution gamma. nous utiliserons la fonction gamma_mucv2shapescale du paquet epitrix.\n\n## obtenir les paramètres de forme et d'échelle à partir du mu moyen et du coefficient de\n## variation (par exemple, le rapport entre l'écart type et la moyenne).\nshapescale &lt;- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## fabriquer un objet distcrete\nserial_interval_lit &lt;- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n\nVoici une vérification rapide pour s’assurer que l’intervalle de série est correct. Nous accédons à la densité de la distribution gamma que nous venons de définir par $d, ce qui revient à appeler dgamma :\n\n## vérifiez que l'intervalle série est correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\n\n\nUtilisation des estimations d’intervalles sériels à partir des données\nComme nous avons des données sur les dates d’apparition des symptômes et les liens de transmission, nous pouvons également estimer l’intervalle sériel à partir de la liste de liens en calculant le délai entre les dates d’apparition des symptômes des paires infecteur-infecté. Comme nous l’avons fait dans la section EpiNow2, nous allons utiliser la fonction get_pairwise du paquet epicontacts qui nous permet de calculer les différences par paires des propriétés de la liste de liens entre les paires de transmission. Nous créons d’abord un objet epicontacts (voir la page Chaînes de transmission pour plus de détails) :\n\n## générer des contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## générer un objet epicontacts\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nNous ajustons ensuite la différence de dates d’apparition entre les paires de transmissions, calculée avec get_pairwise, à une distribution gamma. Nous utilisons l’outil pratique fit_disc_gamma du paquet epitrix pour cette procédure d’ajustement, car nous avons besoin d’une distribution discrète.\n\n## Estimation de l'intervalle sériel gamma\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspecter l'estimation\nserial_interval[c(\"mu\", \"sd\")]\n\n$mu\n[1] 11.51047\n\n$sd\n[1] 7.696056\n\n\n\n\nProjection de l’incidence\nPour projeter l’incidence future, nous devons fournir l’incidence historique sous la forme d’un objet incidence, ainsi qu’un échantillon de valeurs Rt plausibles. Nous générerons ces valeurs en utilisant les estimations Rt générées par EpiEstim dans la section précédente (sous “Estimation de la valeur de Rt”) et stockées dans l’objet epiestim_res_emp. Dans le code ci-dessous nous extrayons les estimations de la moyenne et de l’écart type de Rt pour la dernière fenêtre de temps de l’épidémie (en utilisant la fonction tail pour accéder au dernier élément d’un vecteur), et nous simulons 1000 valeurs à partir d’une distribution gamma en utilisant rgamma. Vous pouvez également fournir votre propre vecteur de valeurs Rt que vous souhaitez utiliser pour les projections.\n\n## créer un objet d'incidence à partir des dates d'apparition des symptômes\ninc &lt;- incidence::incidence(linelist$date_onset)\n\n256 missing observations were removed.\n\n## extraire les valeurs r plausibles de l'estimation la plus récente\nmean_r &lt;- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r &lt;- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale &lt;- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r &lt;- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## vérifier la distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNous utilisons ensuite la fonction project() pour effectuer la prévision réelle. Nous spécifions le nombre de jours pour lesquels nous voulons faire une projection via les arguments n_days, et nous spécifions le nombre de simulations en utilisant les arguments n_sim.\n\n## faire une projection\nproj &lt;- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n\nNous pouvons alors facilement tracer l’incidence et les projections en utilisant les fonctions plot() et add_projections(). On peut facilement sous-évaluer l’objet incidence pour ne montrer que les cas les plus récents en utilisant l’opérateur de crochets.\n\n## Tracer l'incidence et les projections\nplot(inc[inc$dates &gt; as.Date(\"2015-03-01\")]) %&gt;%\n  add_projections(proj)\n\n\n\n\n\n\n\n\nVous pouvez également extraire facilement les estimations brutes du nombre de cas quotidiens en convertissant la sortie en un cadre de données.\n\n## convertir en cadre de données pour les données brutes\nproj_df &lt;- as.data.frame(proj)\nproj_df",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modélisation des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.fr.html#ressources",
    "href": "new_pages/epidemic_models.fr.html#ressources",
    "title": "24  Modélisation des épidémies",
    "section": "24.5 Ressources",
    "text": "24.5 Ressources\nVoici un article qui décrit la méthodologie mise en œuvre dans EpiEstim. Voici un article décrivant la méthodologie mise en œuvre dans EpiNow. Voici un article décrivant diverses considérations méthodologiques et pratiques pour l’estimation de Rt.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modélisation des épidémies</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html",
    "href": "new_pages/contact_tracing.fr.html",
    "title": "25  Suivi des contacts",
    "section": "",
    "text": "25.1 Préparation",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html#préparation",
    "href": "new_pages/contact_tracing.fr.html#préparation",
    "title": "25  Suivi des contacts",
    "section": "",
    "text": "Chargement de packages\nCe bout de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charger pour l’utiliser. Vous pouvez aussi charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages R.\n\npacman::p_load(\n  rio,          # importation de données \n  here,         # chemins d'accès relatifs aux fichiers \n  janitor,      # nettoyage des données et tableaux\n  lubridate,    # travailler avec des dates\n  epikit,       # fonction age_categories()\n  apyramid,     # age pyramids\n  tidyverse,    # manipulation et visualisation des données\n  RColorBrewer, # colour palettes\n  formattable,  # fancy tables\n  kableExtra    # formatage des tableaux\n)\n\n\n\nImportation de données\nNous allons importer des jeux de données exemple de contacts, et de leur”suivi”. Ces données ont été récupérées et non imbriquées à partir de l’API Go.Data et stockées dans des fichiers “.rds”.\nVous pouvez télécharger tous les exemples de données pour ce manuel à partir de la page Télécharger le manuel et les données.\nSi vous souhaitez télécharger les exemples de données de suivi des contacts spécifiques à cette page, utilisez les trois liens de téléchargement ci-dessous :\n Cliquer pour télécharger données sur les investigations des cas (.rds file) \n Cliquer pour télécharger les données d’enregistrement de contacts (.rds file) \n Cliquer pour télécharger les données de suivi des contacts (.rds file) \n\n\n\nDans leur forme originale dans les fichiers téléchargeables, les données reflètent les données fournies par l’API Go.Data (en savoir plus sur APIs here). À titre d’exemple, nous allons nettoyer les données pour les rendre plus faciles à lire sur cette page. Si vous utilisez une instance Go.Data, vous pouvez consulter les instructions complètes sur la façon de récupérer vos données here.\nCi-dessous, les jeux de données sont importés à l’aide de la fonction import() du package rio. Voir la page Importation et exportation pour les différentes manières d’importer des données. Nous utilisons here() pour spécifier le chemin du fichier - vous devez fournir le chemin du fichier spécifique à votre ordinateur. Nous utilisons ensuite select() pour sélectionner seulement certaines colonnes des données, afin de simplifier pour les besoins de la démonstration.\n\nDonnées des cas\nCes données sont un tableau des cas, et des informations les concernant.\n\ncases &lt;- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %&gt;% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)\n\nVoici les nrow(cases) cas :\n\n\n\n\n\n\n\n\nDonnées sur les contacts\nCes données sont un tableau de tous les contacts et des informations les concernant. Là encore, vous pouvez fournir votre propre chemin de fichier. Après l’importation, nous effectuons quelques étapes préliminaires de nettoyage des données, notamment :\n\nDéfinir age_class comme facteur et inverser l’ordre des niveaux pour que les plus jeunes soient les premiers.\n\nSélectionner seulement certaines colonnes, en renommant l’une d’entre elles.\n\nAttribuer artificiellement les lignes dont le 2 niveau d’administration est manquant à “Djembe”, pour améliorer la clarté de certains exemples de visualisation.\n\n\ncontacts &lt;- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %&gt;% \n  mutate(age_class = forcats::fct_rev(age_class)) %&gt;% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %&gt;% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))\n\nVoici les nrow(contacts) lignes de le contacts dataframe:\n\n\n\n\n\n\n\n\nDonnées de suivi\nCes données sont des enregistrements des interactions de “suivi” avec les contacts. Chaque contact est censé avoir une rencontre chaque jour pendant 14 jours après son exposition.\nNous importons et effectuons quelques étapes de nettoyage. Nous sélectionnons certaines colonnes, et convertissons également une colonne de caractères en toutes les valeurs minuscules.\n\nfollowups &lt;- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %&gt;% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %&gt;% \n  mutate(followup_status = str_to_lower(followup_status))\n\nVoici les 50 premières lignes de la base de données nrow(followups)-row followups (chaque ligne est une interaction de suivi, avec le statut du suivi dans la colonne followup_status) :\n\n\n\n\n\n\n\n\nDonnées de relations\nIci, nous importons des données montrant la relation entre les cas et les contacts. Nous sélectionnons certaines colonnes à afficher.\n\nrelationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)\n\nVous trouverez ci-dessous les 50 premières lignes du jeu de données relations, qui enregistre toutes les relations entre les cas et les contacts.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html#analyses-descriptives",
    "href": "new_pages/contact_tracing.fr.html#analyses-descriptives",
    "title": "25  Suivi des contacts",
    "section": "25.2 Analyses descriptives",
    "text": "25.2 Analyses descriptives\nVous pouvez utiliser les techniques abordées dans d’autres pages de ce manuel pour effectuer des analyses descriptives de vos cas, de vos contacts et de leurs relations. Vous trouverez ci-dessous quelques exemples\n\nDémographie\nComme le montre la page consacrée aux Pyramides démographiques, vous pouvez visualiser la répartition par âge et par sexe (nous utilisons ici le package apyramide).\n\nAge et sexe des contacts\nLa pyramide ci-dessous compare la répartition par âge des contacts, par sexe. Notez que les contacts dont l’âge est manquant sont inclus dans leur propre barre en haut. Vous pouvez modifier ce comportement par défaut, mais envisagez alors d’indiquer le nombre de contacts manquants dans une légende.\n\napyramid::age_pyramid(\n  data = contacts,                                   # utiliser la base de données des contacts\n  age_group = \"age_class\",                           # colonne d'âge catégorielle\n  split_by = \"gender\") +                             # genre pour les moitiés de la pyramide\n  labs(\n    fill = \"Gender\",                                 # titre de la légende\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # titre du graphique\n  theme_minimal()                                    # un fond simple\n\n\n\n\n\n\n\n\nAvec la structure de données Go.Data, le jeu de données relations contient les âges des cas et des contacts, vous pourriez donc utiliser ce jeu de données et créer une pyramide des âges montrant les différences entre ces deux groupes de personnes. Le tableau de données relations sera modifié pour transformer les colonnes d’âge numériques en catégories (voir la page Nettoyage des données et fonctions de base). Nous faisons également pivoter le tableau de données pour faciliter le traçage avec ggplot2 (voir Pivoter les données).\n\nrelation_age &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  transmute(        # transmute est comme mutate() mais supprime toutes les autres colonnes non mentionnées\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %&gt;% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivotement plus long\n\n\nrelation_age\n\n# A tibble: 200 × 2\n   category         age_class\n   &lt;chr&gt;            &lt;fct&gt;    \n 1 source_age_class 80+      \n 2 target_age_class 15-19    \n 3 source_age_class &lt;NA&gt;     \n 4 target_age_class 50-54    \n 5 source_age_class &lt;NA&gt;     \n 6 target_age_class 20-24    \n 7 source_age_class 30-34    \n 8 target_age_class 45-49    \n 9 source_age_class 40-44    \n10 target_age_class 30-34    \n# ℹ 190 more rows\n\n\nMaintenant nous pouvons tracer cet ensemble de données transformées avec age_pyramid() comme avant, mais en remplaçant gender par category (contact, ou cas).\n\napyramid::age_pyramid(\n  data = relation_age,                               # utiliser un ensemble de données de relations modifiées\n  age_group = \"age_class\",                           # colonne d'âge catégorielle\n  split_by = \"category\") +                           # par cas et contacts\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # pour spécifier les couleurs ET les étiquettes\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # titre de la légende\n    title = \"Pyramides demographiques de cas et contacts de COVID-19\")+ # titre du graph\n  theme_minimal()                                              # fond simple\n\n\n\n\n\n\n\n\nNous pouvons également visualiser d’autres caractéristiques telles que la répartition par profession (par exemple, sous la forme d’un diagramme circulaire).\n\n# Clean dataset and get counts by occupation\nocc_plot_data &lt;- cases %&gt;% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # faire des valeurs manquantes NA une catégorie\n         occupation = forcats::fct_infreq(occupation)) %&gt;% # ordonner les niveaux de facteurs par ordre de fréquence\n  count(occupation)                                          # obtenir des chiffres par profession\n  \n# Make pie chart\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Occupation connue des cas de covid-19\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nContacts par cas\nLe nombre de contacts par cas peut être une unité de mesure importante pour évaluer la qualité du dénombrement des contacts et la conformité de la population à la réponse de santé publique.\nEn fonction de votre structure de données, cela peut être évalué avec un ensemble de données qui contient tous les cas et les contacts. Dans les ensembles de données de Go.Data, les liens entre les cas (“sources”) et les contacts (“cibles”) sont stockés dans le jeu de données relationships.\nDans cet ensemble de données, chaque ligne est un contact, et le cas source est listé dans la ligne. Aucun contact n’a de relations avec plusieurs affaires. multiples, mais si c’est le cas, vous devrez peut-être en tenir compte avant de faire le graphique (et de les explorer aussi !).\nNous commençons par compter le nombre de lignes (contacts) par cas source. Ceci est enregistré comme un tableau de données.\n\ncontacts_per_case &lt;- relationships %&gt;% \n  count(source_visualid)\n\ncontacts_per_case\n\n   source_visualid  n\n1   CASE-2020-0001 13\n2   CASE-2020-0002  5\n3   CASE-2020-0003  2\n4   CASE-2020-0004  4\n5   CASE-2020-0005  5\n6   CASE-2020-0006  3\n7   CASE-2020-0008  3\n8   CASE-2020-0009  3\n9   CASE-2020-0010  3\n10  CASE-2020-0012  3\n11  CASE-2020-0013  5\n12  CASE-2020-0014  3\n13  CASE-2020-0016  3\n14  CASE-2020-0018  4\n15  CASE-2020-0022  3\n16  CASE-2020-0023  4\n17  CASE-2020-0030  3\n18  CASE-2020-0031  3\n19  CASE-2020-0034  4\n20  CASE-2020-0036  1\n21  CASE-2020-0037  3\n22  CASE-2020-0045  3\n23            &lt;NA&gt; 17\n\n\nNous utilisons geom_histogram() pour représenter ces données sous forme d’histogramme.\n\nggplot(data = contacts_per_case)+        # commencer avec le tableau de données créé ci-dessus\n  geom_histogram(mapping = aes(x = n))+  # afficher l'histogramme du nombre de contacts par cas\n  scale_y_continuous(expand = c(0,0))+   # supprimer l'espace excédentaire en dessous de 0 sur l'axe des ordonnées\n  theme_light()+                         # simplifier le fond\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html#suivi-de-contacts",
    "href": "new_pages/contact_tracing.fr.html#suivi-de-contacts",
    "title": "25  Suivi des contacts",
    "section": "25.3 Suivi de contacts",
    "text": "25.3 Suivi de contacts\nLes données de recherche des contacts contiennent souvent des données de “suivi”, qui enregistrent les résultats des contrôles quotidiens des symptômes des personnes en quarantaine. L’analyse de ces données permet d’orienter la stratégie de réponse, d’identifier les contacts susceptibles d’être perdus pour le suivi ou de développer la maladie.\n\nNettoyage de données\nCes données peuvent exister sous différents formats. Elles peuvent exister sous la forme d’une large avec une ligne par contact et une colonne par “jour” de suivi. jour” de suivi. Voir Pivoter les données pour obtenir des descriptions des données “longues” et données “larges” et comment faire pivoter des données plus larges ou plus longues.\nDans notre exemple Go.Data, ces données sont stockées dans le tableau followups, qui est dans un format “long” avec une ligne par interaction de suivi. Les 50 premières lignes ressemblent à ceci :\n\n\n\n\n\n\nATTENTION: Méfiez-vous des doublons lorsque vous traitez des données de suivi, car il peut y avoir plusieurs suivis erronés le même jour pour un contact donné. Cela peut sembler être une erreur mais reflète la réalité - par exemple, un agent de recherche de contacts pourrait soumettre un formulaire de suivi en début de journée alors qu’il n’a pas pu joindre le contact, et soumettre un second formulaire lorsqu’il a été joint par la suite. La façon dont vous souhaitez traiter les doublons dépend du contexte opérationnel. - veillez simplement à documenter clairement votre approche.\nVoyons combien d’instances de lignes “en double” nous avons :\n\nfollowups %&gt;% \n  count(contact_id, date_of_followup) %&gt;%   # obtenir des jours de suivi uniques\n  filter(n &gt; 1)                             # afficher les enregistrements où le nombre est supérieur à 1 \n\n  contact_id date_of_followup n\n1       &lt;NA&gt;       2020-09-03 2\n2       &lt;NA&gt;       2020-09-04 2\n3       &lt;NA&gt;       2020-09-05 2\n\n\nDans notre exemple de données, les seuls enregistrements auxquels cela s’applique sont ceux auxquels il manque un ID ! Nous pouvons les supprimer. Mais, pour les besoins de la démonstration, nous allons montrer les étapes de la déduplication afin qu’il n’y ait qu’un seul encoutrement de suivi par personne et par jour. Voir la page sur déduplication pour plus de détails. Nous supposerons que l’enregistrement de rencontre le plus récent est le bon. Nous profitons également de l’occasion pour nettoyer la colonne followup_number (le “jour” du suivi qui devrait qui devrait être compris entre 1 et 14).\n\nfollowups_clean &lt;- followups %&gt;%\n  \n  # Enlever les doublons\n  group_by(contact_id, date_of_followup) %&gt;%        # grouper les lignes par jour de suivi\n  arrange(contact_id, desc(date_of_followup)) %&gt;%   # organiser les lignes, par jour de suivi, par date de suivi (le plus récent en haut)\n  slice_head() %&gt;%                                  # ne conserver que la première ligne par id contact\n  ungroup() %&gt;% \n  \n  # Autres nettoyages\n  mutate(followup_number = replace(followup_number, followup_number &gt; 14, NA)) %&gt;% # nettoyer des données erronées\n  drop_na(contact_id)                               # supprimer les id_contact dont les données sont manquantes\n\nPour chaque rencontre de suivi, nous avons un statut de suivi (tel que si la rencontre a eu lieu et, le cas échéant, si le contact a eu des symptômes ou non). Pour voir toutes les valeurs, nous pouvons exécuter un rapide tabyl() (de janitor) ou table() (de base R) (voir Tableaux descriptifs) par followup_status pour voir la fréquence de chacun des résultats.\nDans cet ensemble de données, “vu_not_ok” signifie “vu avec des symptômes”, et “vu_ok” signifie “vu sans symptômes”.\n\nfollowups_clean %&gt;% \n  tabyl(followup_status)\n\n followup_status   n    percent\n          missed  10 0.02325581\n   not_attempted   5 0.01162791\n   not_performed 319 0.74186047\n     seen_not_ok   6 0.01395349\n         seen_ok  90 0.20930233\n\n\n\n\nGraphe dans le temps\nComme les données de dates sont continues, nous utiliserons un histogramme pour les représenter avec date_du_suivi assigné à l’axe des abscisses. Nous pouvons obtenir un histogramme “empilé” en spécifiant un argument fill = dans aes(), que nous assignons à la colonne followup_status. Par conséquent, vous pouvez définir le titre de la légende en utilisant l’argument fill = de labs().\nOn constate que les contacts ont été identifiés par vagues (correspondant vraisemblablement aux vagues épidémiques de cas), et que vl’achèvement du suivi ne semble pas s’être amélioré au cours de l’épidémie.\n\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # Afficher tous les niveaux de facteurs (followup_status) dans la légende, même ceux qui ne sont pas utilisés.\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # sous-titres dynamiques\n\n\n\n\n\n\n\n\nATTENTION: Si vous préparez de nombreux graphiques (par exemple pour plusieurs juridictions), vous voudrez que les légendes apparaissent de manière identique, même si les données sont plus ou moins complètes ou composées. Il peut y avoir des graphiques pour lesquels tous les statuts de suivi ne sont pas présents dans les données, mais vous voulez quand même que ces catégories apparaissent dans les légendes. Dans les ggplots (comme ci-dessus), vous pouvez spécifier l’argument drop = FALSE de la fonction scale_fill_discrete(). Dans les tableaux, utilisez tabyl() qui montre les comptes pour tous les niveaux de facteurs, ou si vous utilisez count() de dplyr ajoutez l’argument .drop = FALSE pour inclure les comptes pour tous les niveaux de facteurs.\n\n\nSuivi quotidien individuel\nSi votre épidémie est suffisamment petite, vous voudrez peut-être voir chaque contact individuellement et voir son statut au cours de son suivi. Heureusement, cet tableau de données followups contient déjà une colonne avec le le “numéro” du jour du suivi (1-14). Si cette colonne n’existe pas dans vos données, vous pouvez la créer en calculant la différence entre la date de la dernière rencontre et la date à laquelle le suivi devait commencer pour le contact.\nUn mécanisme de visualisation pratique (si le nombre de cas n’est pas trop important) peut être un diagramme de dispersion, réalisé avec geom_tile(). Voir plus de détails dans la page heat plot.\n\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # lignes grises\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))\n\n\n\n\n\n\n\n\n\n\nAnalyse par groupe\nCes données de suivi sont peut-être consultées journellement ou hebdomadairement pour la prise de décision opérationnelle. Vous souhaitez peut-être des désagrégations plus significatives par zone géographique ou par équipe de suivi des contacts. Nous pouvons le faire en ajustant les colonnes fournies à group_by().\n\nplot_by_region &lt;- followups_clean %&gt;%                                        # commencer par l'ensemble de données de suivi\n  count(admin_1_name, admin_2_name, followup_status) %&gt;%   # obtenir les chiffres par région-statut unique (crée la colonne 'n' avec les chiffres)\n  \n  # begin ggplot()\n  ggplot(                                         # commencer le ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # réorganiser les facteurs administratifs en fonction des valeurs numériques de la colonne 'n'.\n                  y = n,                            # hauteur de la barre de la colonne 'n'.\n                  fill = followup_status,           # colorer les barres empilées en fonction de leur statut\n                  label = n))+                      # passer à geom_label()              \n  geom_col()+                                     # barres empilées, cartographie obtenue au-dessus\n  geom_text(                                      # ajouter du texte, cartographie obtenue à partir de la version précédente\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # Simplifier le fond\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduire les facettes \n\nplot_by_region",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html#tableaux-kpi",
    "href": "new_pages/contact_tracing.fr.html#tableaux-kpi",
    "title": "25  Suivi des contacts",
    "section": "25.4 Tableaux KPI",
    "text": "25.4 Tableaux KPI\nIl existe un certain nombre d’indicateurs clés de performance ( KPI) qui peuvent être calculés et suivis à différents niveaux de désagrégation et sur différentes périodes de temps afin de contrôler les performances de la recherche de contacts. Une fois que vous maîtrisez les calculs et le format de base du tableau, il est assez facile d’intervertir les différents KPI.\nIl existe de nombreuses sources de KPI pour le suivi des contacts, comme celle de ResolveToSaveLives.org. La majeure partie du travail consistera à parcourir votre structure de données et à réfléchir à tous les critères d’inclusion/exclusion. Nous présentons quelques exemples ci-dessous, en utilisant la structure de métadonnées de Go.Data :\n\n\n\n\n\n\n\n\n\nCatégorie\nIndicateur\nGo.Data Numérateur\nGo.Data D énominateur\n\n\n\n\nIndicateur de processus -Rapidité du Suivi de contact\n% cas interviewé et isololé dans les 24h du cas rapport\nNOMBRE DE case_id OU (da te_of_reporting - da te _of_data_entry) &lt; 1 jour et (is ol ation_startdate - da te _of_data_entry) &lt; 1 jour\nNOMBRE DE case_id\n\n\nIndicateur de processus -Rapidité du Suivi de contact\n% contacts notifié et mis en quarantaine dans 24h d’ élicitation\nNOMBRE DE contact_id OÙ followup_status == “SEEN_NOT_OK” OR “SEEN_OK” ET d ate_of_followup - da te_of_reporting &lt; 1 jour\nNOMBRE DE c  ontact_id\n\n\nIndicateur de processus - Complétude des tests\n% nouveaux symptômes cas testés et interviewé dans les 3 jours de début de symptôme\nNOMBRE DE case_id OÙ (da te_of_reporting - date_of_onset) &lt; =3 jours\nNOMBRE DE case_id\n\n\nIndicateur de résultat - Globale ment\n% nouveaux cas parmi les contacts listés\nNOMBRE DE case_id OÙ was_contact == “TRUE”\nNOMBRE DE case_id\n\n\n\nNous vous proposons ci-dessous un exemple de création d’un tableau visuel pour afficher le suivi des contacts dans les différentes zones d’administration. À la fin, nous le convertirons en tableau de présentation avec le package formattable (mais vous pouvez utiliser d’autres packages comme flextable - voir Tableaux de présentation).\nLa manière de créer un tel tableau dépend de la structure de vos données de suivi des contacts. Utilisez la page Tableaux descriptifs pour apprendre à résumer les données à l’aide des fonctions dplyr.\nNous allons créer une table qui sera dynamique et changera au fur et à mesure que les données changeront. Pour rendre les résultats intéressants, nous allons définir une “date de rapport” pour nous permettre de simuler l’exécution du tableau à un certain jour (nous choisissons le 10 juin 2020). Les données sont filtrées à cette date.\n\n# Définissez \"Date du rapport\" pour simuler l'exécution du rapport avec des données \"à partir de\" cette date.\nreport_date &lt;- as.Date(\"2020-06-10\")\n\n# Créez des données de suivi pour refléter la date du rapport.\ntable_data &lt;- followups_clean %&gt;% \n  filter(date_of_followup &lt;= report_date)\n\nMaintenant, sur la base de notre structure de données, nous allons faire ce qui suit :\n\nCommencez par les données followups et résumez-les pour inclure, pour chaque contact unique :\n\n\n\nLa date du dernier enregistrement (quel que soit le statut du suivi).\n\nLa date de la dernière suivi où le contact a été “vu”\n\nle statut du suivi lors de cette dernière suivi (par exemple, avec des symptômes, sans symptômes)\n\n\n\nJoignez ces données aux données des contacts, qui contiennent d’autres informations telles que le statut général du contact, la date de la dernière exposition à un cas, etc. Nous allons également calculer des indicateurs intéressants pour chaque contact, comme le nombre de jours depuis la dernière exposition.\n\nNous regroupons les données de contact élargies par région géographique (admin_2_name) et calculons des statistiques sommaires par région\n\nEnfin, nous mettons en forme le tableau pour qu’il soit bien présenté.\n\nTout d’abord, nous résumons les données de suivi pour obtenir les informations qui nous intéressent :\n\nfollowup_info &lt;- table_data %&gt;% \n  group_by(contact_id) %&gt;% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %&gt;% \n  ungroup()\n\nVoici à quoi ressemblent ces données :\n\n\n\n\n\n\nMaintenant, nous allons ajouter ces informations à l’ensemble de données contacts, et calculer quelques colonnes supplémentaires.\n\ncontacts_info &lt;- followup_info %&gt;% \n  right_join(contacts, by = \"contact_id\") %&gt;% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\n\nVoici à quoi ressemblent ces données. Il faut noter la colonne contacts à droite, et la nouvelle colonne calculée à l’extrême droite.\n\n\n\n\n\n\nEnsuite, nous résumons les données sur les contacts par région, afin d’obtenir un tableaux de synthèse des colonnes de statistiques.\n\ncontacts_table &lt;- contacts_info %&gt;% \n  \n  group_by(`Admin 2` = admin_2_name) %&gt;%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure &lt; 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure &gt;= 8 & days_since_exposure &lt; 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen &gt;= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %&gt;% \n    \n  arrange(desc(`Registered contacts`))\n\n\n\n\n\n\n\nEt maintenant, nous appliquons le style des paquets formattable et knitr. y compris une note de pied de page qui indique la date “en date du”.\n\ncontacts_table %&gt;%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %&gt;%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %&gt;%\n  kable_styling(\"hover\", full_width = FALSE) %&gt;%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %&gt;% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf contacts currently under follow up\n\n\nStatus of last visit\n\n\n\nAdmin 2\nRegistered contacts\nActive contacts\nIn first week\nIn second week\nBecame case\nLost to follow up\nNever seen\nFollowed up - signs\nFollowed up - no signs\nNot Followed up\n\n\n\n\nDjembe \n59\n30\n44\n0\n2\n15\n22\n0\n0\n0\n\n\nTrumpet\n3\n1\n3\n0\n0\n0\n0\n0\n0\n0\n\n\nVenu \n2\n0\n0\n0\n2\n0\n2\n0\n0\n0\n\n\nCongas \n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\nCornet \n1\n0\n1\n0\n1\n0\n1\n0\n0\n0\n\n\n\nNote: \n\n\n\n\n\n\n\n\n\n\n\n\n Data are current to Jun 10 2020",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html#matrices-de-transmission",
    "href": "new_pages/contact_tracing.fr.html#matrices-de-transmission",
    "title": "25  Suivi des contacts",
    "section": "25.5 Matrices de transmission",
    "text": "25.5 Matrices de transmission\nComme indiqué sur la page Heat plots, vous pouvez créer une matrice de “qui a infecté qui” en utilisant geom_tile().\nLorsque de nouveaux contacts sont créés, Go.Data stocke ces informations de liens dans le lien relationships de l’API ; et nous pouvons voir les 50 premières lignes de cet ensemble de données ci-dessous. Cela signifie que nous pouvons créer un diagramme de chaleur avec relativement peu d’étapes étant donné que chaque contact est déjà joint à son cas source.\n\n\n\n\n\n\nComme nous l’avons fait ci-dessus pour la pyramide des âges comparant les cas et les contacts, nous pouvons sélectionner les quelques variables dont nous avons besoin et créer des colonnes avec des groupes d’âge catégoriques pour les sources (cas) et les cibles (contacts).\n\nheatmap_ages &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  mutate(                              # transmute est comme mutate() mais supprime toutes les autres colonnes\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \n\nComme décrit précédemment, nous créons des tableaux croisés ;\n\ncross_tab &lt;- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab\n\n            target_cases\nsource_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54\n       0-4     0   0     0     0     0     0     0     0     0     1     0\n       5-9     0   0     1     0     0     0     0     1     0     0     0\n       10-14   0   0     0     0     0     0     0     0     0     0     0\n       15-19   0   0     0     0     0     0     0     0     0     0     0\n       20-24   1   1     0     1     2     0     2     1     0     0     0\n       25-29   1   2     0     0     0     0     0     0     0     0     0\n       30-34   0   0     0     0     0     0     0     0     1     1     0\n       35-39   0   2     0     0     0     0     0     0     0     1     0\n       40-44   0   0     0     0     1     0     2     1     0     3     1\n       45-49   1   2     2     0     0     0     3     0     1     0     3\n       50-54   1   2     1     2     0     0     1     0     0     3     4\n       55-59   0   1     0     0     1     1     2     0     0     0     0\n       60-64   0   0     0     0     0     0     0     0     0     0     0\n       65-69   0   0     0     0     0     0     0     0     0     0     0\n       70-74   0   0     0     0     0     0     0     0     0     0     0\n       75-79   0   0     0     0     0     0     0     0     0     0     0\n       80+     1   0     0     2     1     0     0     0     1     0     0\n            target_cases\nsource_cases 55-59 60-64 65-69 70-74 75-79 80+\n       0-4       1     0     0     0     0   0\n       5-9       1     0     0     0     0   0\n       10-14     0     0     0     0     0   0\n       15-19     0     0     0     0     0   0\n       20-24     1     0     0     0     0   1\n       25-29     0     0     0     0     0   0\n       30-34     1     0     0     0     0   0\n       35-39     0     0     0     0     0   0\n       40-44     1     0     0     0     1   1\n       45-49     2     1     0     0     0   1\n       50-54     1     0     1     0     0   1\n       55-59     0     0     0     0     0   0\n       60-64     0     0     0     0     0   0\n       65-69     0     0     0     0     0   0\n       70-74     0     0     0     0     0   0\n       75-79     0     0     0     0     0   0\n       80+       0     0     0     0     0   0\n\n\nconvertir en format long avec des proportions ;\n\nlong_prop &lt;- data.frame(prop.table(cross_tab))\n\net créer une carte géographique pour l’âge.\n\nggplot(data = long_prop)+       # utiliser des données longues, avec des proportions comme Freq\n  geom_tile(                    # visualisez-le en tuiles\n    aes(\n      x = target_cases,         # l'axe des x est l'âge du cas\n      y = source_cases,     # l'axe y est l'âge de l'infecteur\n      fill = Freq))+            # La couleur de la tuile est la colonne Freq dans les données\n  scale_fill_gradient(          # ajuster la couleur de remplissage des tuiles\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # labels\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.fr.html#resources",
    "href": "new_pages/contact_tracing.fr.html#resources",
    "title": "25  Suivi des contacts",
    "section": "25.6 Resources",
    "text": "25.6 Resources\nhttps://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting\nhttps://worldhealthorganization.github.io/godata/\nhttps://community-godata.who.int/",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Suivi des contacts</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html",
    "href": "new_pages/survey_analysis.fr.html",
    "title": "26  Analyse d’enquête",
    "section": "",
    "text": "26.1 Aperçu\nCette page démontre l’utilisation de plusieurs packages pour l’analyse d’enquêtes.\nLa plupart des paquets R d’enquête reposent sur le paquet survey pour effectuer des analyses pondérées. Nous utiliserons survey ainsi que srvyr (une enveloppe pour survey permettant un codage de type tidyverse) et gtsummary (une enveloppe pour survey permettant de créer des tableaux prêts à être publiés).Bien que le paquet original survey ne permette pas le codage de style tidyverse, tidyverse, il présente l’avantage supplémentaire d’autoriser les modèles linéaires généralisés pondérés par les pondérés par les enquêtes (qui seront ajoutés à cette page à une date ultérieure). Nous allons également démontrer l’utilisation d’une fonction du paquet sitrep pour créer des poids d’échantillonnage (n.b ce paquet n’est pas encore sur CRAN, mais peut être installé à partir de github).\nLa plupart de cette page est basée sur le travail effectué pour le projet “R4Epis” ; pour le code détaillé et les modèles R-markdown, voir la page github [“R4Epis”] (https://github.com/R4EPI/sitrep). Une partie du code basé sur le paquet survey est basé sur les premières versions de Études de cas EPIET.\nPour l’instant, cette page ne traite pas du calcul de la taille des échantillons ou de l’échantillonnage. Pour un calculateur de taille d’échantillon simple à utiliser, voir OpenEpi. La page GIS basics du manuel comportera éventuellement une section sur l’échantillonnage aléatoire spatial, et cette page comportera éventuellement une section sur les cadres d’échantillonnage. Cette page contiendra également une section sur les bases de sondage ainsi que sur le calcul de la taille des échantillons.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#aperçu",
    "href": "new_pages/survey_analysis.fr.html#aperçu",
    "title": "26  Analyse d’enquête",
    "section": "",
    "text": "Données d’enquête\nTemps d’observation\nPondération\nObjets de la conception de l’enquête\nAnalyse descriptive\nProportions pondérées\nTaux pondérés",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#préparation",
    "href": "new_pages/survey_analysis.fr.html#préparation",
    "title": "26  Analyse d’enquête",
    "section": "26.2 Préparation",
    "text": "26.2 Préparation\n\nPaquets\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger des paquets avec library() depuis base R. Voir la page sur [R basics] pour plus d’informations sur les paquets R.\nIci, nous démontrons également l’utilisation de la fonction p_load_gh() de pacman pour installer et charger un paquet de github qui n’a pas encore été publié sur CRAN.\n\n## charger des paquets depuis CRAN\npacman::p_load(rio, # Importation du fichier\n               here, # Localisation de fichiers\n               tidyverse, # gestion des données + graphiques ggplot2\n               tsibble, # gère les ensembles de données de séries temporelles\n               survey, # pour les fonctions d'enquête\n               srvyr, # wrapper dplyr pour le paquet d'enquête\n               gtsummary, # wrapper pour le paquet d'enquête pour produire des tableaux\n               apyramid, # un paquet dédié à la création de pyramides des âges\n               patchwork, # pour combiner des ggplots\n               ggforce # pour les tracés alluviaux/sankey\n               ) \n\n## charger les paquets de github pour le temps d'observation / fonctions de pondération\nif(!require(sitrep)){\n   remotes::install_github(\"r4epi/sitrep\")\n   library(sitrep)\n}\n\nLoading required package: sitrep\n\n\n\n\nCharger les données\nL’ensemble de données d’exemple utilisé dans cette section :\n\ndes données fictives d’enquête de mortalité.\ncomptes de population fictifs pour la zone d’enquête.\nDictionnaire de données pour les données fictives de l’enquête sur la mortalité.\n\nCeci est basé sur l’enquête pré-approuvée par le comité d’examen éthique de MSF OCA. Le site données fictives ont été produites dans le cadre du projet “R4Epis”. Tout ceci est basé sur les données collectées à l’aide de KoboToolbox, qui est un logiciel de collecte de données basé sur Open Data Kit.\nKobo vous permet d’exporter à la fois les données collectées et le dictionnaire de données pour cet ensemble de données. Nous vous recommandons vivement de le faire, car cela simplifie le nettoyage des données et est utile pour rechercher des variables/questions.\nTIP: Le dictionnaire de données de Kobo comporte des noms de variables dans la colonne “nom” de la feuille d’enquête. Les valeurs possibles pour chaque variable sont spécifiées dans la feuille de choix. Dans la feuille de choix, “name” a la valeur abrégée et les colonnes “label::english” et “label::french” ont les versions longues appropriées. L’utilisation de la fonction msf_dict_survey() du paquet epidict pour importer un fichier Excel du dictionnaire Kobo sera reformaté pour vous afin de pouvoir l’utiliser facilement pour le recodage. \nCAUTION: Le jeu de données d’exemple n’est pas le même comme un export (comme dans Kobo vous exportez différents niveaux de questionnaire individuellement). - voir la section sur les données d’enquête ci-dessous pour fusionner les différents niveaux.\nLe jeu de données est importé à l’aide de la fonction import() du paquet rio. Consultez la page Importation et exportation pour connaître les différentes façons d’importer des données.\n\n# Importez les données d'enquête\nsurvey_data &lt;- rio::import(\"survey_data.xlsx\")\n\n# Importez le dictionnaire dans R\nsurvey_dict &lt;- rio::import(\"survey_dict.xlsx\") \n\nLes 10 premières lignes de l’enquête sont affichées ci-dessous.\n\n\n\n\n\n\nNous voulons également importer les données sur la population d’échantillonnage afin de pouvoir produire des pondérations appropriées. Ces données peuvent se présenter sous différents formats. Cependant, nous vous suggérons de les présenter comme suit (vous pouvez simplement les saisir dans un excel).\n\n# Importez les données de la population\npopulation &lt;- rio::import(\"population.xlsx\")\n\nLes 10 premières lignes de l’enquête sont affichées ci-dessous.\n\n\n\n\n\n\nPour les enquêtes en grappes, vous pouvez souhaiter ajouter des poids d’enquête au niveau de la grappe. Vous pouvez lire ces données comme ci-dessus. Alternativement, s’il n’y a que quelques comptages, ils peuvent être entrés comme suit dans un tibble. Dans tous les cas, vous aurez besoin d’avoir une colonne avec un identifiant de grappe qui correspondant à vos données d’enquête, et une autre colonne avec le nombre de ménages dans chaque grappe.\n\n## définir le nombre de ménages dans chaque cluster\ncluster_counts &lt;- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))\n\n\n\nNettoyer les données\nL’exemple ci-dessous permet de s’assurer que la colonne date est au bon format. Il existe plusieurs autres façons de procéder (voir la page Travailler avec des dates pour plus de détails), mais l’utilisation du dictionnaire pour définir les dates est rapide et facile.\nNous créons également une variable de groupe d’âge en utilisant la fonction age_categories() de epikit - voir la section Nettoyage de données et fonctions essentielles pour plus de détails. De plus, nous créons une variable de caractère définissant dans quel district se trouvent les différents clusters.\nEnfin, nous recodons toutes les variables oui/non en variables VRAI/FAUX, sinon elles ne peuvent pas être utilisées par les fonctions de proportion survey.\n\n## sélectionne les noms de variables de date dans le dictionnaire \nDATEVARS &lt;- survey_dict %&gt;% \n  filter(type == \"date\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## filtre pour correspondre aux noms des colonnes de vos données\n  pull(name) # sélectionne les variables de date\n  \n## changer en dates \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## ajouter ceux dont l'âge est uniquement en mois à la variable année (diviser par douze).\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## définir la variable groupe d'âge\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## créer une variable caractère basée sur les groupes d'une autre variable \nsurvey_data &lt;- survey_data %&gt;% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## sélectionner les noms de variables oui/non dans le dictionnaire \nYNVARS &lt;- survey_dict %&gt;% \n  filter(type == \"yn\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## filtre pour correspondre aux noms des colonnes de vos données\n  pull(name) # select yn vars\n  \n## changer en dates \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(all_of(YNVARS), str_detect, pattern = \"yes\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#données-denquête",
    "href": "new_pages/survey_analysis.fr.html#données-denquête",
    "title": "26  Analyse d’enquête",
    "section": "26.3 Données d’enquête",
    "text": "26.3 Données d’enquête\nIl existe de nombreux plans d’échantillonnage différents qui peuvent être utilisés pour les enquêtes. Ici, nous allons démontrer le code pour : - Stratifié - en grappes - Stratifié et grappe\nComme décrit ci-dessus (en fonction de la façon dont vous concevez votre questionnaire), les données de chaque niveau seront exportées comme un ensemble de données séparé de Kobo. Dans notre exemple, il y a un niveau pour les ménages et un niveau pour les individus au sein de ces ménages.\nCes deux niveaux sont liés par un identifiant unique. Pour un ensemble de données Kobo, cette variable est “_index” au niveau du ménage, qui correspond à “_parent_index” au niveau de l’individu. Cela créera de nouvelles lignes pour le ménage avec chaque individu correspondant, voir la section du manuel sur Joindre des données pour plus de détails.\n\n## Joignez les données des individus et des ménages pour former un ensemble de données complet.\nsurvey_data &lt;- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## créer un identifiant unique en combinant les index des deux niveaux \nsurvey_data &lt;- survey_data %&gt;% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#temps-dobservation",
    "href": "new_pages/survey_analysis.fr.html#temps-dobservation",
    "title": "26  Analyse d’enquête",
    "section": "26.4 Temps d’observation",
    "text": "26.4 Temps d’observation\nPour les enquêtes de mortalité, nous voulons maintenant savoir combien de temps chaque individu a été présent dans l’emplacement afin de pouvoir calculer un taux de mortalité approprié pour notre période d’intérêt. Ceci n’est pas pertinent pour toutes les enquêtes, mais particulièrement pour les enquêtes de mortalité, car elles sont fréquemment menées auprès de populations mobiles ou déplacées.\nPour ce faire, nous définissons d’abord notre période d’intérêt, également connue sous le nom de période de rappel (c’est-à-dire le moment où l’enquête est menée). Nous pouvons ensuite utiliser cette période pour définir des dates inappropriées comme manquantes, c’est-à-dire que si des décès sont signalés en dehors de la période d’intérêt.\n\n## Définit le début/la fin de la période de rappel.\n## peut être changé en variables de date provenant de l'ensemble de données \n## (par exemple, date d'arrivée et date du questionnaire)\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end = as.Date(\"2018-05-01\")\n  )\n\n\n# Définir les dates inappropriées à NA sur la base de règles \n## par exemple, arrivées avant le début, départs après la fin.\nsurvey_data &lt;- survey_data %&gt;%\n      mutate(\n           arrived_date = if_else(arrived_date &lt; recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date &lt; recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date &gt; recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date &gt; recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n\nNous pouvons ensuite utiliser nos variables de date pour définir les dates de début et de fin pour chaque individu. Nous pouvons utiliser la fonction find_start_date() de sitrep pour affiner les causes des les dates et ensuite utiliser cela pour calculer la différence entre les jours (personne-temps).\nDate de début : L’événement d’arrivée approprié le plus tôt dans votre période de rappel. Soit le début de votre période de rappel (que vous définissez à l’avance), soit une date après le début de la période de rappel, le cas échéant (par exemple, les arrivées ou les naissances).\nDate de fin : Soit la fin de votre période de rappel, soit une date antérieure à la fin du rappel.\n\n## Créer de nouvelles variables pour les dates/causes de début et de fin.\nsurvey_data &lt;- survey_data %&gt;% \n     ## choisir la date la plus ancienne saisie dans l'enquête.\n     ## à partir des naissances, des arrivées dans les ménages et des arrivées dans les camps. \n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end = \"recall_end\",\n                  datecol = \"startdate\",\n                  datereason = \"startcause\"\n                 ) %&gt;%\n     ## choisir la date la plus ancienne saisie dans l'enquête\n     ## à partir des départs du camp, des décès et de la fin de l'étude\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end = \"recall_end\",\n                datecol = \"enddate\",\n                datereason = \"endcause\" \n               )\n\n\n## étiqueter ceux qui étaient présents au début/à la fin (sauf les naissances/décès)\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(\n       ## remplir la date de début pour qu'elle corresponde au début de la période de rappel (pour ceux qui sont vides) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## définir la cause de début comme présente au début si elle est égale à la période de rappel \n       ## sauf si elle est égale à la date de naissance \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## remplir la date de fin pour qu'elle corresponde à la fin de la période de rappel (pour ceux qui sont vides) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## définir la cause de fin comme étant présente à la fin si égale à la fin de rappel \n       ## sauf si elle est égale à la date de décès\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Définir la durée d'observation en jours\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(obstime = as.numeric(enddate - startdate))",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#pondération",
    "href": "new_pages/survey_analysis.fr.html#pondération",
    "title": "26  Analyse d’enquête",
    "section": "26.5 Pondération",
    "text": "26.5 Pondération\nIl est important d’éliminer les observations erronées avant d’ajouter les poids de l’enquête. Par exemple, si vous avez des observations avec un temps d’observation négatif, vous devrez les vérifier (vous pouvez le faire avec la fonction assert_positive_timespan() de sitrep. Une autre chose est si vous voulez supprimer les lignes vides (par exemple avec drop_na(uid)) ou supprimer les doublons (voir la section du manuel sur la déduplication pour plus de détails). Ceux qui n’ont pas de consentement doivent aussi être supprimés.\nDans cet exemple, nous filtrons les cas que nous voulons supprimer et les stockons dans un cadre de données séparé - de cette façon, nous pouvons décrire ceux qui ont été exclus de l’enquête. Nous utilisons ensuite la fonction anti_join() de dplyr pour supprimer ces cas exclus de nos données d’enquête.\nDANGER: Vous ne pouvez pas avoir de valeurs manquantes dans votre variable de poids, ni dans aucune des variables pertinentes pour le plan de sondage (par exemple, les variables d’âge, de sexe, de strates ou de grappes).\n\n## stockez les cas que vous abandonnez afin de pouvoir les décrire (par exemple, non-consentant. \n## ou mauvais village/cluster)\ndropped &lt;- survey_data %&gt;% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## utiliser les cas abandonnés pour supprimer les lignes inutilisées de l'ensemble des données de l'enquête.  \nsurvey_data &lt;- anti_join(survey_data, dropped, by = names(dropped))\n\nComme mentionné ci-dessus, nous montrons comment ajouter des poids pour trois plans d’étude différents (stratifié, en grappe et en grappe stratifié). Ceux-ci nécessitent des informations sur la population source et/ou les grappes enquêtées. Nous utiliserons le code de la grappe stratifiée pour cet exemple, mais utilisez celui qui est le plus approprié à votre plan d’étude.\n\n# stratified ------------------------------------------------------------------\n# Créez une variable appelée \"surv_weight_strata\".\n# contient les poids pour chaque individu - par groupe d'âge, sexe et district sanitaire.\nsurvey_data &lt;- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# obtient le nombre de personnes d'individus interrogés par ménage\n# ajoute une variable avec les comptes de la variable index du ménage (parent)\nsurvey_data &lt;- survey_data %&gt;%\n  add_count(index, name = \"interviewed\")\n\n\n## crée des poids de cluster\nsurvey_data &lt;- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# stratifié et cluster ------------------------------------------------------\n# créer un poids d'enquête pour la grappe et les strates\nsurvey_data &lt;- survey_data %&gt;%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#objets-de-conception-denquête",
    "href": "new_pages/survey_analysis.fr.html#objets-de-conception-denquête",
    "title": "26  Analyse d’enquête",
    "section": "26.6 Objets de conception d’enquête",
    "text": "26.6 Objets de conception d’enquête\nCréez un objet d’enquête en fonction de la conception de votre étude. Utilisé de la même manière que les cadres de données pour calculer les proportions de poids, etc. Assurez-vous que toutes les variables nécessaires sont créées avant cela.\nIl y a quatre options, commentez celles que vous n’utilisez pas : - aléatoire simple - Stratifié - en grappe - Grappe stratifiée\nPour ce modèle, nous supposerons que nous regroupons les enquêtes dans deux strates distinctes (districts sanitaires A et B). Pour obtenir des estimations globales, nous devons donc combiner les poids des grappes et des strates.\nComme nous l’avons mentionné précédemment, il existe deux paquets disponibles pour ce faire. Le classique est survey et il existe un paquetage appelé srvyr qui crée des objets et des fonctions adaptés à tidyverse. Nous ferons la démonstration des deux, mais notez que la plupart du code de ce chapitre utilisera des objets basés sur srvyr. La seule exception est que le paquet gtsummary n’accepte que les objets survey.\n\n26.6.1 Paquet **Survey\nLe paquet survey utilise effectivement le codage base R, et il n’est donc pas possible d’utiliser les pipes (%&gt;%) ou d’autres syntaxes dplyr. Avec le paquetage survey, nous utilisons la fonction svydesign() pour définir un objet d’enquête avec les clusters, les poids et les strates appropriés.\nNOTE: nous devons utiliser le tilde (~) devant les variables, ceci parce que le package utilise la syntaxe base R d’affectation des variables basée sur des formules. \n\n# aléatoire simple ---------------------------------------------------------------\nbase_survey_design_simple &lt;- svydesign(ids = ~1, # 1 pour aucun id de grappe\n                   weights = NULL, # aucun poids ajouté\n                   strata = NULL, # l'échantillonnage est simple (pas de strates)\n                   data = survey_data # doit spécifier l'ensemble de données\n                  )\n\n## stratified ------------------------------------------------------------------\nbase_survey_design_strata &lt;- svydesign(ids = ~1, # 1 pour aucun id de cluster\n                   weights = ~surv_weight_strata, # variable de poids créée ci-dessus\n                   strata = ~health_district, # l'échantillonnage a été stratifié par district\n                   data = survey_data # il faut spécifier l'ensemble de données\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster &lt;- svydesign(ids = ~village_name, # ids de cluster\n                   weights = ~surv_weight_cluster, # variable de poids créée ci-dessus\n                   strata = NULL, # l'échantillonnage était simple (pas de strates)\n                   data = survey_data # il faut spécifier l'ensemble de données\n                  )\n\n# cluster stratifié ----------------------------------------------------------\nbase_survey_design &lt;- svydesign(ids = ~village_name, # ids de cluster\n                   weights = ~surv_weight_cluster_strata, # variable de poids créée ci-dessus\n                   strata = ~health_district, # l'échantillonnage a été stratifié par district\n                   data = survey_data # doit spécifier l'ensemble de données\n                  )\n\n\n\n26.6.2 Paquet **Srvyr\nAvec le paquet srvyr, nous pouvons utiliser la fonction as_survey_design(), qui a les mêmes arguments que ci-dessus, mais autorise les tubes (%&gt;%), et nous n’avons donc pas besoin d’utiliser le tilde (%&gt;%).\n\n## aléatoire simple ---------------------------------------------------------------\nsurvey_design_simple &lt;- survey_data %&gt;% \n  as_survey_design(ids = 1, # 1 pour aucun id de grappe \n                   weights = NULL, # Aucun poids ajouté\n                   strata = NULL # l'échantillonnage était simple (pas de strates)\n                  )\n## stratified ------------------------------------------------------------------\nsurvey_design_strata &lt;- survey_data %&gt;%\n  as_survey_design(ids = 1, # 1 pour aucun id de cluster\n                   weights = surv_weight_strata, # variable de poids créée ci-dessus\n                   strata = health_district # l'échantillonnage a été stratifié par district\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # ids de la grappe\n                   weights = surv_weight_cluster, # variable de poids créée ci-dessus\n                   strata = NULL # l'échantillonnage était simple (pas de strates)\n                  )\n\n## cluster stratifié ----------------------------------------------------------\nsurvey_design &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # ids de la grappe\n                   weights = surv_weight_cluster_strata, # variable de poids créée ci-dessus\n                   strata = health_district # l'échantillonnage a été stratifié par district\n                  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#analyse-descriptive",
    "href": "new_pages/survey_analysis.fr.html#analyse-descriptive",
    "title": "26  Analyse d’enquête",
    "section": "26.7 Analyse descriptive",
    "text": "26.7 Analyse descriptive\nL’analyse descriptive et la visualisation de base sont traitées en détail dans d’autres chapitres du manuel, nous ne nous y attarderons donc pas ici. Pour plus de détails, voir les chapitres sur les tableaux descriptifs, les tests statistiques, les tableaux de présentation, [les bases du ggplot] (#ggplot_basics) et rapports R markdown.\nDans cette section, nous allons nous concentrer sur la manière d’étudier le biais dans votre échantillon et de le visualiser. Nous nous pencherons également sur la visualisation du flux de population dans le cadre d’une enquête à l’aide de diagrammes alluviaux/sankey.\nEn général, vous devriez envisager d’inclure les analyses descriptives suivantes :\n\nLe nombre final de grappes, de ménages et d’individus inclus.\n\nNombre d’individus exclus et les raisons de cette exclusion\nNombre médian (fourchette) de ménages par grappe et d’individus par ménage.\n\n\n26.7.1 Biais d’échantillonnage\nComparez les proportions dans chaque groupe d’âge entre votre échantillon et la population source. Ceci est important pour pouvoir mettre en évidence un éventuel biais d’échantillonnage. Vous pouvez également répéter cette opération en examinant les distributions par sexe.\nNotez que ces p-values ne sont qu’indicatives, et qu’une discussion descriptive (ou une visualisation avec les pyramides d’âge ci-dessous) des distributions dans votre échantillon d’étude par rapport à la population source est plus importante que le test binomial lui-même. Cela est dû au fait que l’augmentation de la taille de l’échantillon conduira le plus souvent à des différences qui peuvent ne pas être pertinentes après la pondération de vos données.\n\n## dénombrements et saillies de la population étudiée.\nag &lt;- survey_data %&gt;% \n  group_by(age_group) %&gt;% \n  drop_na(age_group) %&gt;% \n  tally() %&gt;% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## comptes et props de la population source\npropcount &lt;- population %&gt;% \n  group_by(age_group) %&gt;%\n    tally(population) %&gt;%\n    mutate(proportion = n / sum(n))\n\n## lier ensemble les colonnes de deux tables, regrouper par âge, et effectuer un \n## un test binomial pour voir si n/total est significativement différent de la population\n## proportion.\n  ## Le suffixe ajoute ici du texte à la fin des colonnes dans chacun des deux ensembles de données.\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %&gt;%\n  group_by(age_group) %&gt;%\n  ## broom::tidy(binom.test()) crée une trame de données à partir du test binomial et ## ajoutera les variables p.p. à la trame de données.\n  ## ajoutera les variables p.value, parameter, conf.low, conf.high, method, and\n  ## alternative. Nous n'utiliserons que p.value ici. Vous pouvez inclure d'autres\n  ## d'autres colonnes si vous souhaitez faire état des intervalles de confiance.\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %&gt;%\n  unnest(cols = c(binom)) %&gt;% # important pour l'expansion du cadre de données binom.test\n  mutate(proportion_pop = proportion_pop * 100) %&gt;%\n  ## Ajustement des valeurs de p pour corriger les faux positifs. \n  ## (parce que l'on teste plusieurs groupes d'âge). Cela ne fera une \n  ## une différence que si vous avez plusieurs catégories d'âge\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %&gt;%\n                      \n  ## N'affichez que les valeurs de p supérieures à 0,001 (celles qui sont inférieures sont signalées comme &lt;0,001)\n  mutate(p.value = ifelse(p.value &lt; 0.001, \n                          \"&lt;0.001\", \n                          as.character(round(p.value, 3)))) %&gt;% \n  \n  ## renommez les colonnes de manière appropriée\n  select(\n    \"Groupe d'âge\" = age_group,\n    \"Population étudiée (n)\" = n,\n    \"Population étudiée (%)\" = proportion,\n    \"Population source (n)\" = n_pop,\n    \"Population source (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )\n\n# A tibble: 5 × 6\n# Groups:   Groupe d'âge [5]\n  `Groupe d'âge` `Population étudiée (n)` `Population étudiée (%)`\n  &lt;chr&gt;                             &lt;int&gt;                    &lt;dbl&gt;\n1 0-2                                  12                   0.0256\n2 3-14                                 42                   0.0896\n3 15-29                                64                   0.136 \n4 30-44                                52                   0.111 \n5 45+                                 299                   0.638 \n# ℹ 3 more variables: `Population source (n)` &lt;dbl&gt;,\n#   `Population source (%)` &lt;dbl&gt;, `P-value` &lt;chr&gt;\n\n\n\n\n26.7.2 Pyramides démographiques\nLes pyramides démographiques (ou âge-sexe) sont un moyen facile de visualiser la distribution dans la population de votre enquête. Il est également intéressant de créer des tableaux descriptifs et le sexe par strates d’enquête. Nous allons démontrer l’utilisation du paquet apyramide car il permet de pondérées en utilisant notre objet de conception d’enquête créé ci-dessus. Autres options pour créer pyramides démographiques sont traitées en détail dans ce chapitre du manuel. Nous utiliserons également une fonction wrapper de apyramid appelée age_pyramid() qui permet de gagner quelque lignes de code pour produire un graphique avec des proportions.\nComme pour le test binomial formel de différence, vu plus haut dans la section sur le biais d’échantillonnage, nous sommes intéressés ici à visualiser si notre population échantillonnée est sensiblement différente de la population source et si la pondération corrige cette différence. Pour ce faire, nous allons utiliser le paquet patchwork pour montrer nos visualisations ggplot côte à côte ; pour plus de détails, voir la section sur la combinaison de tracés dans le chapitre du manuel Astuces de ggplot du manuel. Nous allons visualiser notre population source, notre population d’enquête non pondérée et notre population d’enquête pondérée. Vous pouvez également envisager de visualiser chaque strate de votre enquête, pars exemple ici, en utilisant l’argument stack_by = \"health_district\" (voir ?plot_age_pyramid pour plus de détails).\nNOTE: Les axes x et y sont inversés dans les pyramides .\n\n## définir les limites et les étiquettes de l'axe des x ---------------------------------------------\n## (mettez à jour ces chiffres pour qu'ils correspondent aux valeurs de votre graphique)\nmax_prop &lt;- 35 ## choisissez la plus haute proportion que vous voulez montrer \nstep &lt;- 5 # choisissez l'espace que vous voulez entre les étiquettes. \n\n## cette partie définit le vecteur en utilisant les nombres ci-dessus avec des ruptures d'axe.\nbreaks &lt;- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## cette partie définit le vecteur en utilisant les nombres ci-dessus avec les limites de l'axe\nlimits &lt;- c(max_prop/100 * -1, max_prop/100)\n\n## Cette partie définit le vecteur en utilisant les nombres ci-dessus avec les étiquettes d'axe.\nlabels &lt;- c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## créer des graphiques individuellement --------------------------------------------------\n\n## tracer la population source \n## nb : cette population doit être réduite à la population globale (c'est-à-dire en enlevant les districts de santé).\nsource_population &lt;- population %&gt;%\n  ## s'assurer que l'âge et le sexe sont des facteurs\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %&gt;% \n  group_by(age_group, sex) %&gt;% \n  ## additionner les comptes pour chaque district de santé \n  summarise(population = sum(population)) %&gt;% \n  ## supprimer le regroupement pour pouvoir calculer la proportion globale\n  ungroup() %&gt;% \n  mutate(proportion = population / sum(population)) %&gt;% \n  ## tracer la pyramide \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## Afficher uniquement le libellé de l'axe des y (sinon répété dans les trois graphiques)\n  labs(title = \"Population source\", \n       y = \"\", \n       x = \"Groupe d'âge (années)\") + \n  ## rendre l'axe des x identique pour tous les graphiques \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## Tracez l'échantillon de population non pondéré \nsample_population &lt;- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## Afficher uniquement le libellé de l'axe des x (sinon répété dans les trois graphiques)\n  labs(title = \"Population échantillon non pondérée\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## rendre l'axe des x identique pour tous les graphiques \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## tracer la population de l'échantillon pondéré \nweighted_population &lt;- survey_design %&gt;% \n  ## S'assurer que les variables sont des facteurs\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %&gt;%\n  age_pyramid(\n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## Afficher uniquement le libellé de l'axe des x (sinon répété dans les trois graphiques)\n  labs(title = \"Echantillon de population pondéré\", \n       y = \"\", \n       x = \"\") + \n  ## rendre l'axe des x identique pour tous les graphiques \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combine les trois tracés ----------------------------------------------------\n## Combinez trois tracés côte à côte en utilisant + \nsource_population + sample_population + weighted_population + \n  ## ne montrer qu'une seule légende et définir le thème \n  ## notez l'utilisation de & pour combiner le thème avec plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\", # déplace la légende vers le bas\n        legend.title = element_blank(), # supprimer le titre\n        text = element_text(size = 18), # change la taille du texte\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # tourner le texte de l'axe x\n       )\n\n\n\n\n\n\n\n\n\n\n26.7.3 Diagramme alluvial/sankey\nLa visualisation des points de départ et des résultats pour les individus peut être très utile pour obtenir une vue d’ensemble. L’application est évidente pour les populations mobiles, mais il existe de nombreuses autres applications telles que les cohortes ou toute autre situation où il y a des transitions d’états pour les individus. Ces diagrammes ont plusieurs noms différents, y compris alluvial, sankey et ensembles parallèles - les détails sont dans le chapitre du manuel consacré aux diagrammes et graphiques.\n\n## résumer les données\nflow_table &lt;- survey_data %&gt;%\n  count(startcause, endcause, sex) %&gt;% # obtenir des comptages \n  gather_set_data(x = c(\"startcause\", \"endcause\")) # changer de format pour le tracé\n\n\n\n## Tracez votre ensemble de données \n  ## sur l'axe des x, les causes de début et de fin.\n  ## gather_set_data génère un ID pour chaque combinaison possible.\n  ## La division par y donne les combinaisons possibles de début et de fin.\n  ## la valeur n donne les comptes (peut aussi être changée en proportion).\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colorer les lignes par sexe \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) + ### remplir les cases d'étiquettes en gris.\n  ## remplir les cases d'étiquettes en gris\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") + ## changer la couleur du texte et l'angle de l'étiquette.\n  ## changer la couleur et l'angle du texte (doit être ajusté)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) + ## ajuster la couleur et l'angle du texte (doit être ajusté)\n  ## suppression des étiquettes d'axe\n  theme_void()+\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#proportions-pondérées",
    "href": "new_pages/survey_analysis.fr.html#proportions-pondérées",
    "title": "26  Analyse d’enquête",
    "section": "26.8 Proportions pondérées",
    "text": "26.8 Proportions pondérées\nCette section détaillera comment produire des tableaux pour les effectifs et les proportions pondérés, avec les intervalles de confiance associés et l’effet de plan. Il existe quatre options différentes utilisant les fonctions des paquets suivants : survey, srvyr, sitrep et gtsummary. Pour un codage minimal permettant de produire un tableau standard de style épidémiologique, nous recommandons la fonction sitrep - qui est un wrapper pour le code srvyr ; notez cependant que ce n’est pas encore sur CRAN et que cela peut changer dans le futur. Autrement, le code survey est susceptible d’être le plus stable à long terme, alors que srvyr s’intégrera le mieux dans les flux de travail de tidyverse. Bien que les fonctions gtsummary ont beaucoup de potentiel, elles semblent expérimentales et incomplètes au moment de la rédaction.\n\n26.8.1 Paquet **Survey\nNous pouvons utiliser la fonction svyciprop() de survey pour obtenir des proportions pondérées et les intervalles de confiance à 95% qui les accompagnent. Il est intéressant de noter que svyprop() ne semble accepter que les variables comprises entre 0 et 1 (ou VRAI/FAUX), donc les variables catégorielles ne fonctionneront pas.\nNOTE: Les fonctions de survey acceptent également les objets de conception srvyr, mais ici nous avons utilisé l’objet de conception survey juste pour la cohérence .\n\n## produire des comptes pondérés \nsvytable(~died, base_survey_design)\n\ndied\n     FALSE       TRUE \n1406244.43   76213.01 \n\n## produit des proportions pondérées\nsvyciprop(~died, base_survey_design, na.rm = T)\n\n              2.5% 97.5%\ndied 0.0514 0.0208  0.12\n\n## obtenir l'effet du plan de sondage \nsvymean(~died, base_survey_design, na.rm = T, deff = T) %&gt;% \n  deff()\n\ndiedFALSE  diedTRUE \n 3.755508  3.755508 \n\n\nNous pouvons combiner les fonctions de survey présentées ci-dessus en une fonction que nous définissons nous-mêmes ci-dessous, appelée svy_prop ; et nous pouvons alors utiliser cette fonction avec map() du paquetage purrr pour itérer sur plusieurs variables et créer un tableau. Voir le chapitre du manuel itération pour plus de détails sur purrr.\n\n# Définissez la fonction permettant de calculer les effectifs pondérés, les proportions, l'IC et l'effet de plan.\n# x est la variable entre guillemets \n# design est votre objet de conception d'enquête\n\nsvy_prop &lt;- function(design, x) {\n  \n  ## mettre la variable d'intérêt dans une formule \n  form &lt;- as.formula(paste0( \"~\" , x))\n  ## garder seulement la colonne VRAIE des comptes de svytable\n  weighted_counts &lt;- svytable(form, design)[[2]]\n  ## calculer les proportions (multiplier par 100 pour obtenir des pourcentages).\n  weighted_props &lt;- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extraire les intervalles de confiance et les multiplier pour obtenir des pourcentages.\n  weighted_confint &lt;- confint(weighted_props) * 100\n  ## utiliser svymean pour calculer l'effet de plan et ne garder que la colonne TRUE.\n  design_eff &lt;- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combiner en un seul cadre de données\n  full_table &lt;- cbind(\n    \"Variable\" = x,\n    \"Count\" = weighted_counts,\n    \"Proportion\" = weighted_props,\n    weighted_confint, \n    \"Design effect\" = design_eff\n    )\n  \n  ## Retourner le tableau sous forme de cadre de données\n  full_table &lt;- data.frame(full_table, \n             ## supprimer les noms de variables des lignes (c'est une colonne séparée maintenant)\n             row.names = NULL)\n  \n  ## Remplacer les valeurs numériques par des valeurs numériques\n  full_table[ , 2:6] &lt;- as.numeric(full_table[ , 2:6])\n  \n  ## Retourner le cadre de données\n  full_table\n}\n\n## itérer sur plusieurs variables pour créer un tableau \npurrr::map(\n  ## définir les variables d'intérêt\n  c(\"left\", \"died\", \"arrived\"), \n  ## déclarer la fonction utilisée et les arguments pour cette fonction (design)\n  svy_prop, design = base_survey_design) %&gt;% \n  ## réduire la liste à un seul cadre de données\n  bind_rows() %&gt;% \n  ## round \n  mutate(across(where(is.numeric), round, digits = 1))\n\n  Variable    Count Proportion X2.5. X97.5. Design.effect\n1     left 701199.1       47.3  39.2   55.5           2.4\n2     died  76213.0        5.1   2.1   12.1           3.8\n3  arrived 761799.0       51.4  40.9   61.7           3.9\n\n\n\n\n26.8.2 Paquet **Srvyr\nAvec srvyr, nous pouvons utiliser la syntaxe dplyr pour créer une table. Notez que la méthode fonction survey_mean() est utilisée et que l’argument de proportion est spécifié, ainsi que également que la même fonction est utilisée pour calculer l’effet de plan. Ceci est dû au fait que srvyr englobe les deux fonctions du paquetage survey, svyciprop() et svymean(), qui sont utilisées dans la section ci-dessus.\nNOTE: Il ne semble pas non plus possible d’obtenir des proportions à partir de variables catégorielles en utilisant srvyr, si vous en avez besoin, consultez la section ci-dessous utilisant sitrep .\n\n## utiliser l'objet de conception srvyr\nsurvey_design %&gt;% \n  summarise(\n    ## produire les comptes pondérés \n    counts = survey_total(died), \n    ## produire les proportions pondérées et les intervalles de confiance \n    ## multiplier par 100 pour obtenir un pourcentage \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produire l'effet de plan \n    deff = survey_mean(died, deff = TRUE)) %&gt;% \n  ## conserver uniquement les lignes d'intérêt\n  ## (supprimez les erreurs standard et répétez le calcul des proportions)\n  select(counts, props, props_low, props_upp, deff_deff)\n\n# A tibble: 1 × 5\n  counts props props_low props_upp deff_deff\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 76213.  5.14      2.08      12.1      3.76\n\n\nLà encore, nous pourrions écrire une fonction pour itérer sur plusieurs variables en utilisant le paquet purrr. Voir le chapitre du manuel itération pour plus de détails sur purrr.\n\n# Définit la fonction permettant de calculer les effectifs pondérés, les proportions, l'IC et l'effet du plan de sondage.\n# design est l'objet de votre plan de sondage\n# x est la variable entre guillemets \n\n\nsrvyr_prop &lt;- function(design, x) {\n  \n  summarise(\n    ## utiliser l'objet du plan de sondage\n    design, \n    ## produire les comptes pondérés \n    counts = survey_total(.data[[x]]), \n    ## produire les proportions pondérées et les intervalles de confiance \n    ## multiplier par 100 pour obtenir un pourcentage \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produire l'effet de plan \n    deff = survey_mean(.data[[x]], deff = TRUE)) %&gt;% \n  ## ajouter le nom de la variable\n  mutate(variable = x) %&gt;% \n  ## ne conserve que les lignes d'intérêt\n  ## (supprimez les erreurs standard et répétez le calcul des proportions)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## itérer sur plusieurs variables pour créer un tableau \npurrr::map(\n  ## définir les variables d'intérêt\n  c(\"left\", \"died\", \"arrived\"), \n  ## déclarer la fonction utilisée et les arguments pour cette fonction (design)\n  ~srvyr_prop(.x, design = survey_design)) %&gt;% \n  ## réduire la liste à un seul cadre de données\n  bind_rows()\n\n# A tibble: 3 × 6\n  variable  counts props props_low props_upp deff_deff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 left     701199. 47.3      39.2       55.5      2.38\n2 died      76213.  5.14      2.08      12.1      3.76\n3 arrived  761799. 51.4      40.9       61.7      3.93\n\n\n\n\n26.8.3 Paquet **Sitrep\nLa fonction tab_survey() de sitrep est une enveloppe pour srvyr, vous permettant de créer des tableaux pondérés avec un codage minimal. Elle vous permet également de calculer proportions pondérées pour les variables catégorielles.\n\n## utilisation de l'objet survey design\nsurvey_design %&gt;% \n  ## passe les noms des variables d'intérêt sans les citer\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE, # calculer l'effet du plan de sondage\n             pretty = TRUE # fusionner la proportion et le 95%CI\n             )\n\nWarning: removing 257 missing value(s) from `education_level`\n\n\n# A tibble: 9 × 5\n  variable        value            n  deff ci               \n  &lt;chr&gt;           &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            \n1 arrived         TRUE       761799.  3.93 51.4% (40.9-61.7)\n2 arrived         FALSE      720658.  3.93 48.6% (38.3-59.1)\n3 left            TRUE       701199.  2.38 47.3% (39.2-55.5)\n4 left            FALSE      781258.  2.38 52.7% (44.5-60.8)\n5 died            TRUE        76213.  3.76 5.1% (2.1-12.1)  \n6 died            FALSE     1406244.  3.76 94.9% (87.9-97.9)\n7 education_level higher     171644.  4.70 42.4% (26.9-59.7)\n8 education_level primary    102609.  2.37 25.4% (16.2-37.3)\n9 education_level secondary  130201.  6.68 32.2% (16.5-53.3)\n\n\n\n\n26.8.4 Paquet **Gtsummary\nAvec gtsummary, il ne semble pas y avoir de fonctions intégrées pour ajouter des intervalles de confiance ou l’effet de plan. Ici nous montrons comment définir une fonction pour ajouter des intervalles de confiance et ensuite ajouter des intervalles de confiance à une table gtsummary créée en utilisant la fonction tbl_svysummary().\n\nconfidence_intervals &lt;- function(data, variable, by, ...) {\n  \n  ## extraire les intervalles de confiance et les multiplier pour obtenir des pourcentages.\n  props &lt;- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## Extraire les intervalles de confiance \n  as.numeric(confint(props) * 100) %&gt;% ### rendre numérique et multiplier pour le pourcentage\n    round(., digits = 1) %&gt;% ## arrondir à un chiffre\n    c(.) %&gt;% ## extraire les chiffres de la matrice\n    paste0(., collapse = \"-\") ## combine en un seul caractère\n}\n\n## utiliser l'objet de conception du paquet d'enquêtes\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died), ## définir les variables à inclure\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %&gt;% ## définir les statistiques d'intérêt\n  add_n() %&gt;% ## ajoute le total pondéré \n  add_stat(fns = everything() ~ confidence_intervals) %&gt;% ## ajouter les ICs\n  ## modifier les en-têtes de colonnes\n  modify_header(\n    list(\n      n ~ \"**Total pondéré (N)**\",\n      stat_0 ~ \"**Compte pondéré**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )\n\n\n\n\n\n\n\n\nCharacteristic\nTotal pondéré (N)\nCompte pondéré1\n95%CI\n\n\n\n\narrived\n1,482,457\n761,799 (51%)\n40.9-61.7\n\n\nleft\n1,482,457\n701,199 (47%)\n39.2-55.5\n\n\ndied\n1,482,457\n76,213 (5.1%)\n2.1-12.1\n\n\n\n1 n (%)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#ratios-pondérés",
    "href": "new_pages/survey_analysis.fr.html#ratios-pondérés",
    "title": "26  Analyse d’enquête",
    "section": "26.9 Ratios pondérés",
    "text": "26.9 Ratios pondérés\nDe même, pour les ratios pondérés (comme pour les ratios de mortalité), vous pouvez utiliser le paquetage survey ou le paquet srvyr. Vous pouvez également écrire des fonctions (similaires à celles ci-dessus) pour itérer sur plusieurs variables. Vous pourriez également créer une fonction pour gtsummary comme ci-dessus mais actuellement, elle n’a pas de fonctionnalité intégrée.\n\n26.9.1 Paquet **Survey\n\nratio &lt;- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci &lt;- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)\n\n      obstime    2.5 %   97.5 %\ndied 5.981922 1.194294 10.76955\n\n\n\n\n26.9.2 Paquet SRVYR (paquet)\n\nsurvey_design %&gt;% \n  ### ratio d'enquête utilisé pour tenir compte du temps d'observation \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )\n\n# A tibble: 1 × 3\n  mortality mortality_low mortality_upp\n      &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1      5.98         0.349          11.6",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.fr.html#ressources",
    "href": "new_pages/survey_analysis.fr.html#ressources",
    "title": "26  Analyse d’enquête",
    "section": "26.10 Ressources",
    "text": "26.10 Ressources\nPage des statistiques de l’UCLA\nAnalyse des données d’enquête gratuite\npaquet srvyr\npaquet gtsummary\nÉtudes de cas de l’enquête EPIET",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Analyse d'enquête</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html",
    "href": "new_pages/survival_analysis.fr.html",
    "title": "27  Analyse de survie",
    "section": "",
    "text": "27.1 Aperçu\nL’analyse de survie s’attache à décrire pour un individu ou un groupe d’individus donné, un point d’événement défini appelé l’échec (apparition d’une maladie, guérison d’une maladie, décès, rechute après réponse à un traitement…) qui survient après une période de temps appelée le temps d’échec (ou le temps de suivi dans les études de cohorte/population) pendant laquelle les individus sont observés. Pour déterminer le temps d’échec, il est alors nécessaire de définir un temps d’origine (qui peut être la date d’inclusion, la date du diagnostic…).\nLa cible d’inférence de l’analyse de survie est alors le temps entre une origine et un événement. Dans la recherche médicale actuelle, elle est largement utilisée dans les études cliniques pour évaluer l’effet d’un traitement par exemple, ou en épidémiologie du cancer pour évaluer une grande variété de mesures de survie au cancer.\nElle s’exprime généralement par la probabilité de survie qui est la probabilité que l’événement d’intérêt ne se soit pas produit avant une durée t.\nCensure : La censure se produit lorsqu’à la fin du suivi, certains des individus n’ont pas eu l’événement d’intérêt, et donc leur temps réel jusqu’à l’événement est inconnu. Nous nous concentrerons principalement sur la censure à droite ici, mais pour plus de détails sur la censure et l’analyse de survie en général, vous pouvez consulter les références.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html#préparation",
    "href": "new_pages/survival_analysis.fr.html#préparation",
    "title": "27  Analyse de survie",
    "section": "27.2 Préparation",
    "text": "27.2 Préparation\n\nChargement des paquets\nPour effectuer des analyses de survie dans R, un des paquets les plus utilisés est le paquet survival. Nous l’installons d’abord et le chargeons ensuite, ainsi que les autres paquets qui seront utilisés dans cette section :\nDans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les paquets installés avec library() de base R. Voir la page sur [R basics] pour plus d’informations sur les paquets R.\nCette page explore les analyses de survie en utilisant la linelist utilisée dans la plupart des pages précédentes et sur laquelle nous appliquons quelques changements pour avoir des données de survie correctes.\n\n\nImportation du jeu de données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre le mouvement, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# importation de linelist\nlinelist_case_data &lt;- rio::import(\"linelist_cleaned.rds\")\n\n\n\nGestion et transformation des données\nEn bref, les données de survie peuvent être décrites comme ayant les trois caractéristiques suivantes :\n\nla variable dépendante ou réponse est le temps d’attente jusqu’à l’occurrence d’un événement bien défini,\nles observations sont censurées, en ce sens que pour certaines unités, l’événement d’intérêt ne s’est pas produit au moment où les données sont analysées, et\nil existe des prédicteurs ou des variables explicatives dont nous souhaitons évaluer ou contrôler l’effet sur le temps d’attente.\n\nAinsi, nous allons créer les différentes variables nécessaires pour respecter cette structure et effectuer l’analyse de survie.\nNous définissons\n\nun nouveau cadre de données linelist_surv pour cette analyse\n\nnotre événement d’intérêt comme étant le “décès” (donc notre probabilité de survie sera la probabilité d’être en vie après un certain temps après le moment d’origine),\nle temps de suivi (futime) comme le temps entre le moment de l’apparition et le moment du résultat en jours,\nles patients censurés comme ceux qui se sont rétablis ou pour lesquels le résultat final n’est pas connu, c’est-à-dire que l’événement “décès” n’a pas été observé (event=0).\n\nCAUTION: Puisque dans une étude de cohorte réelle, l’information sur le moment de l’origine et la fin du suivi est connue étant donné que les individus sont observés, nous éliminerons les observations où la date d’apparition ou la date de l’issue est inconnue. De même, les cas où la date d’apparition est postérieure à la date de l’issue seront supprimés car ils sont considérés comme erronés.\nTIP: Étant donné que le filtrage sur une date supérieure à (&gt;) ou inférieure à (&lt;) peut supprimer les lignes avec des valeurs manquantes, l’application du filtre sur les mauvaises dates supprimera également les lignes avec des dates manquantes.\nNous utilisons ensuite case_when() pour créer une colonne age_cat_small dans laquelle il n’y a que 3 catégories d’âge.\n\n#Créer une nouvelle donnée appelée linelist_surv à partir de la donnée linelist_case_data.\n\nlinelist_surv &lt;- linelist_case_data %&gt;% \n     \n  dplyr::filter(\n       # supprimez les observations dont la date d'apparition ou la date d'issue est erronée ou manquante.\n       date_outcome &gt; date_onset) %&gt;% \n  \n  dplyr::mutate(\n       # créer la var événement qui vaut 1 si le patient est décédé et 0 s'il a été censuré à droite\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # créer la var sur le temps de suivi en jours\n       futime = as.double(date_outcome - date_onset), \n    \n       # créer une nouvelle variable de catégorie d'âge avec seulement 3 niveaux de strates\n       age_cat_small = dplyr::case_when( \n            age_years &lt; 5 ~ \"0-4\",\n            age_years &gt;= 5 & age_years &lt; 20 ~ \"5-19\",\n            age_years &gt;= 20 ~ \"20+\"),\n       \n       # l'étape précédente a créé la var age_cat_small en tant que caractère.\n       # maintenant le convertir en facteur et spécifier les niveaux.\n       # Notez que les valeurs NA restent des NA et ne sont pas mises dans un niveau \"inconnu\" par exemple,\n       # puisque dans les prochaines analyses, elles devront être supprimées.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\n\nTIP: Nous pouvons vérifier les nouvelles colonnes que nous avons créées en faisant un résumé sur le futime et un tableau croisé entre event et outcome à partir duquel il a été créé. Outre cette vérification, c’est une bonne habitude de communiquer la durée médiane de suivi lors de l’interprétation des résultats de l’analyse de survie.\n\nsummary(linelist_surv$futime)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    6.00   10.00   11.98   16.00   64.00 \n\n# croiser les tableaux de la nouvelle var événement et de la var résultat à partir de laquelle elle a été créée.\n# pour s'assurer que le code a fait ce qu'il était censé faire.\nlinelist_surv %&gt;% \n  tabyl(outcome, event)\n\n outcome    0    1\n   Death    0 1952\n Recover 1547    0\n    &lt;NA&gt; 1040    0\n\n\nMaintenant, nous croisons la nouvelle var age_cat_small et l’ancienne col age_cat pour nous assurer que les affectations sont correctes.\n\nlinelist_surv %&gt;% \n  tabyl(age_cat_small, age_cat)\n\n age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n           0-4 834   0     0     0     0     0     0   0   0\n          5-19   0 852   717   575     0     0     0   0   0\n           20+   0   0     0     0   862   554    69   5   0\n          &lt;NA&gt;   0   0     0     0     0     0     0   0  71\n\n\nMaintenant, nous examinons les 10 premières observations des données linelist_surv en regardant des variables spécifiques (y compris celles nouvellement créées).\n\nlinelist_surv %&gt;% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %&gt;% \n  head(10)\n\n   case_id age_cat_small date_onset date_outcome outcome event futime\n1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\n\n\nNous pouvons aussi croiser les colonnes age_cat_small et gender pour avoir plus de détails sur la distribution de cette nouvelle colonne par sexe. Nous utilisons tabyl() et les fonctions adorn de janitor comme décrit dans la page [Descriptive tables].\n\n\nlinelist_surv %&gt;% \n  tabyl(gender, age_cat_small, show_na = F) %&gt;% \n  adorn_totals(where = \"both\") %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\")\n\n gender         0-4          5-19           20+          Total\n      f 482 (22.4%) 1,184 (54.9%)   490 (22.7%) 2,156 (100.0%)\n      m 325 (15.0%)   880 (40.6%)   960 (44.3%) 2,165 (100.0%)\n  Total 807 (18.7%) 2,064 (47.8%) 1,450 (33.6%) 4,321 (100.0%)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html#bases-de-lanalyse-de-survie",
    "href": "new_pages/survival_analysis.fr.html#bases-de-lanalyse-de-survie",
    "title": "27  Analyse de survie",
    "section": "27.3 Bases de l’analyse de survie",
    "text": "27.3 Bases de l’analyse de survie\n\nConstruction d’un objet de type surv\nNous allons d’abord utiliser Surv() de survival pour construire un objet de type survie à partir des colonnes de temps de suivi et d’événement.\nLe résultat d’une telle étape est de produire un objet de type Surv qui condense les informations de temps et si l’événement d’intérêt (le décès) a été observé. Cet objet sera finalement utilisé dans le côté droit des formules de modèle suivantes (voir documentation).\n\n# Utilisez la syntaxe Suv() pour les données censurées à droite\nsurvobj &lt;- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\n\n\n\n\n\n\nPour revoir, voici les 10 premières lignes des données linelist_surv, en ne visualisant que certaines colonnes importantes.\n\nlinelist_surv %&gt;% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %&gt;% \n  head(10)\n\n   case_id date_onset date_outcome futime outcome event\n1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n3   893f25 2014-05-21   2014-05-29      8 Recover     0\n4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n6   369449 2014-06-02   2014-06-07      5   Death     1\n7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n8   1389ca 2014-06-05   2014-06-09      4   Death     1\n9   2978ac 2014-06-06   2014-06-15      9   Death     1\n10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n\n\nEt voici les 10 premiers éléments de survobj. Il s’imprime essentiellement comme un vecteur de temps de suivi, avec “+” pour représenter si une observation a été censurée à droite. Voyez comment les chiffres s’alignent au-dessus et en dessous.\n\n#imprimez les 50 premiers éléments du vecteur pour voir comment il se présente\nhead(survobj, 10)\n\n [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+\n\n\n\n\nExécution des analyses initiales\nNous commençons ensuite notre analyse en utilisant la fonction survfit() pour produire un objet survfit, qui s’adapte aux calculs par défaut pour les estimations Kaplan Meier (KM) de la courbe de survie globale (marginale), qui sont en fait une fonction échelon avec des sauts aux moments des événements observés. L’objet final survfit contient une ou plusieurs courbes de survie et est créé en utilisant l’objet Surv comme variable de réponse dans la formule du modèle.\nNOTE: L’estimation de Kaplan-Meier est une estimation non paramétrique du maximum de vraisemblance (MLE) de la fonction de survie. (voir les ressources pour plus d’informations).\nLe résumé de cet objet survfit donnera ce que l’on appelle une table de survie. Pour chaque pas de temps du suivi (temps) où un événement s’est produit (par ordre croissant) :\n\nle nombre de personnes qui étaient à risque de développer l’événement (les personnes qui n’ont pas encore eu l’événement ou qui ont été censurées : n.risk)\n\nceux qui ont développé l’événement (n.event)\n\net à partir de ce qui précède : la probabilité de ne pas développer l’événement (probabilité de ne pas mourir, ou de survivre au-delà de ce moment spécifique).\n\nenfin, l’erreur standard et l’intervalle de confiance pour cette probabilité sont dérivés et affichés.\n\nNous ajustons les estimations de la GC en utilisant la formule où l’objet “survobj” précédemment survécu est la variable de réponse. “~ 1” précise que nous exécutons le modèle pour la survie globale.\n\n# ajuster les estimations KM en utilisant une formule où l'objet Surv \"survobj\" est la variable de réponse.\n# \"~ 1\" signifie que nous exécutons le modèle pour la survie globale.  \nlinelistsurv_fit &lt;- survival::survfit(survobj ~ 1)\n\n#imprimez son résumé pour plus de détails\nsummary(linelistsurv_fit)\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1   4539      30    0.993 0.00120        0.991        0.996\n    2   4500      69    0.978 0.00217        0.974        0.982\n    3   4394     149    0.945 0.00340        0.938        0.952\n    4   4176     194    0.901 0.00447        0.892        0.910\n    5   3899     214    0.852 0.00535        0.841        0.862\n    6   3592     210    0.802 0.00604        0.790        0.814\n    7   3223     179    0.757 0.00656        0.745        0.770\n    8   2899     167    0.714 0.00700        0.700        0.728\n    9   2593     145    0.674 0.00735        0.660        0.688\n   10   2311     109    0.642 0.00761        0.627        0.657\n   11   2081     119    0.605 0.00788        0.590        0.621\n   12   1843      89    0.576 0.00809        0.560        0.592\n   13   1608      55    0.556 0.00823        0.540        0.573\n   14   1448      43    0.540 0.00837        0.524        0.556\n   15   1296      31    0.527 0.00848        0.511        0.544\n   16   1152      48    0.505 0.00870        0.488        0.522\n   17   1002      29    0.490 0.00886        0.473        0.508\n   18    898      21    0.479 0.00900        0.462        0.497\n   19    798       7    0.475 0.00906        0.457        0.493\n   20    705       4    0.472 0.00911        0.454        0.490\n   21    626      13    0.462 0.00932        0.444        0.481\n   22    546       8    0.455 0.00948        0.437        0.474\n   23    481       5    0.451 0.00962        0.432        0.470\n   24    436       4    0.447 0.00975        0.428        0.466\n   25    378       4    0.442 0.00993        0.423        0.462\n   26    336       3    0.438 0.01010        0.419        0.458\n   27    297       1    0.436 0.01017        0.417        0.457\n   29    235       1    0.435 0.01030        0.415        0.455\n   38     73       1    0.429 0.01175        0.406        0.452\n\n\nEn utilisant summary(), nous pouvons ajouter l’option times et spécifier certaines heures auxquelles nous voulons voir les informations de survie.\n\n#imprime son résumé à des moments précis\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    5   3899     656    0.852 0.00535        0.841        0.862\n   10   2311     810    0.642 0.00761        0.627        0.657\n   20    705     446    0.472 0.00911        0.454        0.490\n   30    210      39    0.435 0.01030        0.415        0.455\n   60      2       1    0.429 0.01175        0.406        0.452\n\n\nNous pouvons également utiliser la fonction print(). L’argument print.rmean = TRUE permet d’obtenir le temps de survie moyen et son erreur standard (se).\nNOTE: La durée moyenne de survie restreinte (RMST) est une mesure de survie spécifique de plus en plus utilisée dans l’analyse de survie des cancers et qui est souvent définie comme l’aire sous la courbe de survie, étant donné que nous observons les patients jusqu’au temps restreint T (plus de détails dans la section Ressources).\n\n# Imprimez l'objet linelistsurv_fit avec le temps de survie moyen et son se. \nprint(linelistsurv_fit, print.rmean = TRUE)\n\nCall: survfit(formula = survobj ~ 1)\n\n        n events rmean* se(rmean) median 0.95LCL 0.95UCL\n[1,] 4539   1952   33.1     0.539     17      16      18\n    * restricted mean with upper limit =  64 \n\n\nTIP: Nous pouvons créer l’objet surv directement dans la fonction survfit() et économiser une ligne de code. Cela ressemblera alors à : linelistsurv_quick &lt;- survfit(Surv(futime, event) ~ 1, data=linelist_surv).\n\n\nRisque cumulé\nOutre la fonction summary(), nous pouvons également utiliser la fonction str() qui donne plus de détails sur la structure de l’objet survfit(). Il s’agit d’une liste de 16 éléments.\nParmi ces éléments, il y en a un important : cumhaz, qui est un vecteur numérique. Il pourrait être tracé pour permettre de montrer le danger cumulatif, le danger étant le taux instantané d’occurrence de l’événement (voir références).\n\nstr(linelistsurv_fit)\n\nList of 16\n $ n        : int 4539\n $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n $ type     : chr \"right\"\n $ logse    : logi TRUE\n $ conf.int : num 0.95\n $ conf.type: chr \"log\"\n $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n $ call     : language survfit(formula = survobj ~ 1)\n - attr(*, \"class\")= chr \"survfit\"\n\n\n\n\n\nTracer les courbes de Kaplan-Meir\nUne fois les estimations KM ajustées, nous pouvons visualiser la probabilité d’être en vie à un moment donné en utilisant la fonction de base plot() qui dessine la “courbe de Kaplan-Meier”. En d’autres termes, la courbe ci-dessous est une illustration classique de l’expérience de survie dans l’ensemble du groupe de patients.\nNous pouvons rapidement vérifier le temps de suivi min et max sur la courbe.\nUne manière simple d’interpréter est de dire qu’au temps zéro, tous les participants sont encore en vie et que la probabilité de survie est alors de 100%. Cette probabilité diminue au fil du temps, à mesure que les patients meurent. La proportion de participants survivant après 60 jours de suivi est d’environ 40 %.\n\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\", # étiquette de l'axe des x\n     ylab=\"Probabilité de survie\", # étiquette de l'axe des y\n     main= \"Courbe de survie globale\" # titre de la figure\n     )\n\n\n\n\n\n\n\n\nL’intervalle de confiance des estimations de survie KM est également tracé par défaut et peut être écarté en ajoutant l’option conf.int = FALSE à la commande plot().\nPuisque l’événement d’intérêt est la “mort”, dessiner une courbe décrivant les compléments des proportions de survie conduira à dessiner les proportions de mortalité cumulées. Ceci peut être fait avec lines(), qui ajoute des informations à un graphique existant.\n\n# tracé original\nplot(\n  linelistsurv_fit,\n  xlab = \"Jours de suivi\",       \n  ylab = \"Probabilité de survie\",       \n  mark.time = TRUE, # marque les événements sur la courbe : un \"+\" est imprimé à chaque événement\n  conf.int = FALSE, # ne pas tracer l'intervalle de confiance\n  main = \"Courbe de survie globale et mortalité cumulée\"\n  )\n\n# Dessinez une courbe supplémentaire au tracé précédent\nlines(\n  linelistsurv_fit,\n  lty = 3, # utiliser un type de ligne différent pour plus de clarté\n  fun = \"event\", # dessine les événements cumulés au lieu de la survie \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# Ajoutez une légende au graphique\nlegend(\n  \"topright\", # position de la légende\n  legend = c(\"Survival\", \"Cum. Mortality\"), # texte de la légende \n  lty = c(1, 3), # types de lignes à utiliser dans la légende\n  cex = .85, # paramètres qui définissent la taille du texte de la légende\n  bty = \"n\", # aucun type de boîte à dessiner pour la légende\n  )",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html#comparaison-des-courbes-de-survie",
    "href": "new_pages/survival_analysis.fr.html#comparaison-des-courbes-de-survie",
    "title": "27  Analyse de survie",
    "section": "27.4 Comparaison des courbes de survie",
    "text": "27.4 Comparaison des courbes de survie\nPour comparer la survie au sein de différents groupes de nos participants ou patients observés, nous pourrions avoir besoin de regarder d’abord leurs courbes de survie respectives, puis d’effectuer des tests pour évaluer la différence entre les groupes indépendants. Cette comparaison peut concerner des groupes basés sur le sexe, l’âge, le traitement, la comorbidité…\n\nTest du log rank\nLe test du log rank est un test populaire qui compare l’ensemble de l’expérience de survie entre deux ou plusieurs groupes indépendants et peut être considéré comme un test permettant de savoir si les courbes de survie sont identiques (se chevauchent) ou non (hypothèse nulle d’aucune différence de survie entre les groupes). La fonction survdiff() du paquet survie permet d’exécuter le test log-rank lorsque l’on spécifie rho = 0 (ce qui est le cas par défaut). Le résultat du test donne une statistique de chi-deux ainsi qu’une valeur p puisque la statistique de log-rang est approximativement distribuée comme une statistique de test de chi-deux.\nNous essayons d’abord de comparer les courbes de survie par groupe de sexe. Pour cela, nous essayons d’abord de les visualiser (vérifier si les deux courbes de survie se chevauchent). Un nouvel objet survfit sera créé avec une formule légèrement différente. Ensuite, l’objet survdiff sera créé.\nEn fournissant ~ gender comme partie droite de la formule, nous ne traçons plus la survie globale mais plutôt par sexe.\n\n# créez le nouvel objet survfit basé sur le sexe\nlinelistsurv_fit_sex &lt;- survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n\nMaintenant, nous pouvons tracer les courbes de survie par sexe. Jetez un oeil à l’ordre des niveaux de strates dans la colonne sexe avant de définir vos couleurs et votre légende.\n\n# définissez les couleurs\ncol_sex &lt;- c(\"light green\", \"dark green\")\n\n# Créez le graphique\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Jours de suivi\",\n  ylab = \"Probabilité de survie\")\n\n# ajouter une légende\nlegend(\n  \"topright\",\n  legend = c(\"Female\", \"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\n\nEt maintenant nous pouvons calculer le test de la différence entre les courbes de survie en utilisant `survdiff()``\n\n#Test de la différence entre les courbes de survie\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )\n\nCall:\nsurvival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n\nn=4321, 218 observations deleted due to missingness.\n\n            N Observed Expected (O-E)^2/E (O-E)^2/V\ngender=f 2156      924      909     0.255     0.524\ngender=m 2165      929      944     0.245     0.524\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nNous constatons que la courbe de survie des femmes et celle des hommes se chevauchent et que le test log-rank ne met pas en évidence de différence de survie entre les femmes et les hommes.\nCertains autres packages R permettent d’illustrer les courbes de survie de différents groupes et de tester la différence en une seule fois. En utilisant la fonction ggsurvplot() du paquet survminer, nous pouvons également inclure dans notre courbe les tableaux de risque imprimés pour chaque groupe, ainsi que la p-value du test log-rank.\nCAUTION: Les fonctions survminer exigent que vous spécifiiez l’objet de survie et que vous spécifiiez à nouveau les données utilisées pour ajuster l’objet de survie. N’oubliez pas de le faire pour éviter les messages d’erreur non spécifiques. \n\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv, # spécifiez à nouveau les données utilisées pour ajuster linelistsurv_fit_sex \n    conf.int = FALSE, # ne pas montrer l'intervalle de confiance des estimations KM\n    surv.scale = \"percent\", # présente les probabilités sur l'axe des ordonnées en %.\n    break.time.by = 10, # présente l'axe du temps avec un incrément de 10 jours\n    xlab = \"Jours de suivi\",\n    ylab = \"Probabilité de survie\",\n    pval = T, # imprimer la valeur p du test de Log-rank \n    pval.coord = c(40,.91), # imprimer la valeur p à ces coordonnées de tracé\n    risk.table = T, # imprime le tableau des risques en bas de page \n    legend.title = \"Gender\", # légende des caractéristiques\n    legend.labs = c(\"Female\", \"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\", # spécifier la palette de couleurs \n    surv.median.line = \"hv\", # dessine des lignes horizontales et verticales sur les médianes de survie\n    ggtheme = theme_light() # simplifie le fond du graphique\n)\n\n\n\n\n\n\n\n\nNous pouvons également vouloir tester les différences de survie en fonction de la source d’infection (source de contamination).\nDans ce cas, le test Log rank donne suffisamment de preuves d’une différence dans les probabilités de survie à alpha= 0.005. Les probabilités de survie des patients qui ont été infectés lors de funérailles sont plus élevées que les probabilités de survie des patients qui ont été infectés dans d’autres lieux, ce qui suggère un bénéfice de survie.\n\nlinelistsurv_fit_source &lt;- survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# plot\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\", # types de lignes\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Jours de suivi\",\n  ylab= \"Probabilité de survie\",\n  pval = T,\n  pval.coord = c(40, .91),\n  risk.table = T,\n  legend.title = \"Source d'infection\",\n  legend.labs = c(\"Funéraire\", \"Autre\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\", \"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)\n\nWarning in geom_segment(aes(x = 0, y = max(y2), xend = max(x1), yend = max(y2)), : All aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html#analyse-de-régression-de-cox",
    "href": "new_pages/survival_analysis.fr.html#analyse-de-régression-de-cox",
    "title": "27  Analyse de survie",
    "section": "27.5 Analyse de régression de Cox",
    "text": "27.5 Analyse de régression de Cox\nLa régression des risques proportionnels de Cox est l’une des techniques de régression les plus populaires pour l’analyse de survie. D’autres modèles peuvent également être utilisés puisque le modèle de Cox requiert des hypothèses importantes qui doivent être vérifiées pour une utilisation appropriée, comme l’hypothèse des risques proportionnels : voir les références.\nDans un modèle de régression à risques proportionnels de Cox, la mesure de l’effet est le taux de risque (HR), qui est le risque d’échec (ou le risque de décès dans notre exemple), étant donné que le participant a survécu jusqu’à un moment spécifique. Habituellement, nous sommes intéressés par la comparaison de groupes indépendants en ce qui concerne leurs risques, et nous utilisons un rapport de risque, qui est analogue à un rapport de cotes dans le cadre d’une analyse de régression logistique multiple. La fonction cox.ph() du paquet survival est utilisée pour ajuster le modèle. La fonction cox.zph() du paquet survival peut être utilisée pour tester l’hypothèse de risques proportionnels pour un ajustement du modèle de régression de Cox.\nNOTE: Une probabilité doit être comprise entre 0 et 1. Cependant, le hasard représente le nombre attendu d’événements par unité de temps.\n\nSi le rapport de risque d’un prédicteur est proche de 1, alors ce prédicteur n’affecte pas la survie,\nsi le HR est inférieur à 1, alors le prédicteur est protecteur (c’est-à-dire associé à une meilleure survie),\net si le HR est supérieur à 1, alors le prédicteur est associé à un risque accru (ou à une diminution de la survie).\n\n\nAjustement d’un modèle de Cox\nNous pouvons d’abord ajuster un modèle pour évaluer l’effet de l’âge et du sexe sur la survie. En imprimant simplement le modèle, nous avons les informations sur :\n\nles coefficients de régression estimés coef qui quantifient l’association entre les prédicteurs et le résultat,\nleur exponentielle (pour faciliter l’interprétation, exp(coef)) qui produit le rapport de risque,\nleur erreur standard se(coef),\nle z-score : combien d’erreurs standard le coefficient estimé est-il éloigné de 0,\net la valeur p : la probabilité que le coefficient estimé puisse être 0.\n\nLa fonction summary() appliquée à l’objet modèle de cox donne plus d’informations, comme l’intervalle de confiance du HR estimé et les différents résultats du test.\nL’effet de la première covariable gender est présenté dans la première ligne. genderm (masculin) est imprimé, ce qui implique que le premier niveau de strate (“f”), c’est-à-dire le groupe féminin, est le groupe de référence pour le sexe. Ainsi, l’interprétation du paramètre de test est celle des hommes par rapport aux femmes. La valeur p indique qu’il n’y a pas suffisamment de preuves d’un effet du sexe sur le risque attendu ou d’une association entre le sexe et la mortalité toutes causes confondues.\nLe même manque de preuves est noté concernant le groupe d’âge.\n\n#ajustement du modèle de cox\nlinelistsurv_cox_sexage &lt;- survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#imprimer le modèle ajusté\nlinelistsurv_cox_sexage\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n                      coef exp(coef) se(coef)      z     p\ngenderm           -0.03149   0.96900  0.04767 -0.661 0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n\nLikelihood ratio test=2.8  on 3 df, p=0.4243\nn= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n#sommaire du modèle\nsummary(linelistsurv_cox_sexage)\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n  n= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n                      coef exp(coef) se(coef)      z Pr(&gt;|z|)\ngenderm           -0.03149   0.96900  0.04767 -0.661    0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ngenderm               0.969     1.0320    0.8826     1.064\nage_cat_small5-19     1.099     0.9103    0.9680     1.247\nage_cat_small20+      1.052     0.9509    0.9176     1.205\n\nConcordance= 0.514  (se = 0.007 )\nLikelihood ratio test= 2.8  on 3 df,   p=0.4\nWald test            = 2.78  on 3 df,   p=0.4\nScore (logrank) test = 2.78  on 3 df,   p=0.4\n\n\nIl était intéressant d’exécuter le modèle et de regarder les résultats, mais un premier coup d’oeil pour vérifier si les hypothèses de risques proportionnels sont respectées pourrait aider à gagner du temps.\n\ntest_ph_sexage &lt;- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage\n\n              chisq df    p\ngender        0.454  1 0.50\nage_cat_small 0.838  2 0.66\nGLOBAL        1.399  3 0.71\n\n\nNOTE: Un deuxième argument appelé méthode peut être spécifié lors du calcul du modèle de cox, qui détermine comment les liens sont traités. Le défaut est “efron”, et les autres options sont “breslow” et “exact”.\nDans un autre modèle, nous ajoutons d’autres facteurs de risque tels que la source de l’infection et le nombre de jours entre la date d’apparition et l’admission. Cette fois, nous vérifions d’abord l’hypothèse des risques proportionnels avant de poursuivre.\nDans ce modèle, nous avons inclus un prédicteur continu (days_onset_hosp). Dans ce cas, nous interprétons les estimations des paramètres comme l’augmentation du logarithme attendu du risque relatif pour chaque augmentation d’une unité du prédicteur, les autres prédicteurs restant constants. Nous vérifions d’abord l’hypothèse de risques proportionnels.\n\n#fit le modèle\nlinelistsurv_cox &lt;- coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#Tester le modèle de risque proportionnel\nlinelistsurv_ph_test &lt;- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test\n\n                   chisq df       p\ngender           0.45062  1    0.50\nage_years        0.00199  1    0.96\nsource           1.79622  1    0.18\ndays_onset_hosp 31.66167  1 1.8e-08\nGLOBAL          34.08502  4 7.2e-07\n\n\nLa vérification graphique de cette hypothèse peut être effectuée avec la fonction ggcoxzph() du paquet survminer.\n\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n\n\n\n\n\n\n\n\nLes résultats du modèle indiquent qu’il existe une association négative entre la durée entre le début de la maladie et l’admission et la mortalité toutes causes confondues. Le risque attendu est 0,9 fois plus faible chez une personne qui est admise un jour plus tard qu’une autre, le sexe restant constant. Ou, de manière plus directe, une augmentation d’une unité de la durée entre le début de la maladie et l’admission est associée à une diminution de 10,7 % (coef *100) du risque de décès.\nLes résultats montrent également une association positive entre la source d’infection et la mortalité toutes causes confondues. C’est-à-dire qu’il y a un risque accru de décès (1,21x) pour les patients qui ont eu une source d’infection autre que les funérailles.\n\n#imprimez le résumé du modèle\nsummary(linelistsurv_cox)\n\nCall:\ncoxph(formula = Surv(futime, event) ~ gender + age_years + source + \n    days_onset_hosp, data = linelist_surv)\n\n  n= 2772, number of events= 1180 \n   (1767 observations deleted due to missingness)\n\n                     coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \ngenderm          0.004710  1.004721  0.060827  0.077   0.9383    \nage_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \nsourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \ndays_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\ngenderm            1.0047     0.9953    0.8918    1.1319\nage_years          0.9978     1.0023    0.9930    1.0025\nsourceother        1.1953     0.8366    1.0133    1.4100\ndays_onset_hosp    0.9012     1.1097    0.8764    0.9267\n\nConcordance= 0.566  (se = 0.009 )\nLikelihood ratio test= 71.31  on 4 df,   p=1e-14\nWald test            = 59.22  on 4 df,   p=4e-12\nScore (logrank) test = 59.54  on 4 df,   p=4e-12\n\n\nNous pouvons vérifier cette relation avec une table :\n\nlinelist_case_data %&gt;% \n  tabyl(days_onset_hosp, outcome) %&gt;% \n  adorn_percentages() %&gt;%  \n  adorn_pct_formatting()\n\n days_onset_hosp Death Recover   NA_\n               0 44.3%   31.4% 24.3%\n               1 46.6%   32.2% 21.2%\n               2 43.0%   32.8% 24.2%\n               3 45.0%   32.3% 22.7%\n               4 41.5%   38.3% 20.2%\n               5 40.0%   36.2% 23.8%\n               6 32.2%   48.7% 19.1%\n               7 31.8%   38.6% 29.5%\n               8 29.8%   38.6% 31.6%\n               9 30.3%   51.5% 18.2%\n              10 16.7%   58.3% 25.0%\n              11 36.4%   45.5% 18.2%\n              12 18.8%   62.5% 18.8%\n              13 10.0%   60.0% 30.0%\n              14 10.0%   50.0% 40.0%\n              15 28.6%   42.9% 28.6%\n              16 20.0%   80.0%  0.0%\n              17  0.0%  100.0%  0.0%\n              18  0.0%  100.0%  0.0%\n              22  0.0%  100.0%  0.0%\n              NA 52.7%   31.2% 16.0%\n\n\nNous devrions examiner et étudier pourquoi cette association existe dans les données. Une explication possible serait que les patients qui vivent assez longtemps pour être admis plus tard avaient une maladie moins grave au départ. Une autre explication peut-être plus probable est que, puisque nous avons utilisé un faux ensemble de données simulées, ce schéma ne reflète pas la réalité !\n\n\n\nForest plots\nNous pouvons ensuite visualiser les résultats du modèle de cox en utilisant les parcelles forestières pratiques avec la fonction ggforest() du paquet survminer.\n\nggforest(linelistsurv_cox, data = linelist_surv)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html#covariables-dépendantes-du-temps-dans-les-modèles-de-survie",
    "href": "new_pages/survival_analysis.fr.html#covariables-dépendantes-du-temps-dans-les-modèles-de-survie",
    "title": "27  Analyse de survie",
    "section": "27.6 Covariables dépendantes du temps dans les modèles de survie",
    "text": "27.6 Covariables dépendantes du temps dans les modèles de survie\nCertaines des sections suivantes ont été adaptées avec la permission d’une excellente introduction à l’analyse de survie dans R par le Dr Emily Zabor.\nDans la dernière section, nous avons abordé l’utilisation de la régression de Cox pour examiner les associations entre les covariables d’intérêt et les résultats de survie, mais ces analyses reposent sur la mesure de la covariable au départ, c’est-à-dire avant le début du suivi de l’événement.\nQue se passe-t-il si vous vous intéressez à une covariable qui est mesurée après le début du suivi ? Ou, que se passe-t-il si vous avez une covariable qui peut changer dans le temps ?\nPar exemple, vous travaillez peut-être avec des données cliniques où vous avez répété les mesures des valeurs de laboratoire de l’hôpital qui peuvent changer dans le temps. C’est un exemple de Covariable Dépendante du Temps. Pour résoudre ce problème, vous avez besoin d’une configuration spéciale, mais heureusement, le modèle cox est très flexible et ce type de données peut également être modélisé avec les outils du paquet survival.\n\nConfiguration des covariables dépendantes du temps\nL’analyse des covariables dépendantes du temps dans R nécessite la configuration d’un ensemble de données spécial. Si cela vous intéresse, consultez l’article plus détaillé de l’auteur du paquet survival Utilisation de covariables dépendantes du temps et de coefficients dépendants du temps dans le modèle de Cox.\nPour cela, nous allons utiliser un nouvel ensemble de données du package SemiCompRisks nommé BMT, qui comprend des données sur 137 patients ayant subi une greffe de moelle osseuse. Les variables sur lesquelles nous allons nous concentrer sont :\n\nT1 - temps (en jours) jusqu’au décès ou au dernier suivi.\n\ndelta1 - indicateur de décès ; 1-Dead, 0-Alive\n\nTA - temps (en jours) jusqu’à la maladie aiguë du greffon contre l’hôte.\n\ndeltaA - indicateur de la maladie aiguë du greffon contre l’hôte ;\n\n1 - Développement d’une réaction aiguë du greffon contre l’hôte.\n\n0 - N’a jamais développé de maladie aiguë du greffon contre l’hôte.\n\n\nNous allons charger cet ensemble de données à partir du paquet survival en utilisant la commande base R data(), qui peut être utilisée pour charger des données qui sont déjà incluses dans un paquet R qui est chargé. Le cadre de données BMT apparaîtra dans votre environnement R.\n\ndata(BMT, package = \"SemiCompRisks\")\n\n\nAjouter l’identifiant unique du patient\nIl n’y a pas de colonne d’identifiant unique dans les données BMT, ce qui est nécessaire pour créer le type de jeu de données que nous voulons. Nous utilisons donc la fonction rowid_to_column() du paquet tidyverse tibble pour créer une nouvelle colonne d’identification appelée my_id (ajoute une colonne au début du cadre de données avec des identifiants de ligne séquentiels, en commençant par 1). Nous nommons le cadre de données bmt.\n\nbmt &lt;- rowid_to_column(BMT, \"my_id\")\n\nL’ensemble de données ressemble maintenant à ceci :\n\n\n\n\n\n\n\n\nDévelopper les lignes de patients\nEnsuite, nous allons utiliser la fonction tmerge() avec les fonctions d’aide event() et tdc() pour créer le jeu de données restructuré. Notre but est de restructurer l’ensemble de données pour créer une ligne séparée pour chaque patient pour chaque intervalle de temps où ils ont une valeur différente pour deltaA. Dans ce cas, chaque patient peut avoir au maximum deux lignes selon qu’il a développé ou non une maladie aiguë du greffon contre l’hôte pendant la période de collecte des données. Nous appellerons notre nouvel indicateur de développement de la maladie aiguë du greffon contre l’hôte agvhd.\n\ntmerge() crée un long jeu de données avec plusieurs intervalles de temps pour les différentes valeurs de covariables pour chaque patient.\nevent() crée le nouvel indicateur d’événement pour aller avec les intervalles de temps nouvellement créés.\ntdc() crée la colonne de covariable dépendante du temps, agvhd, pour aller avec les intervalles de temps nouvellement créés.\n\n\ntd_dat &lt;- \n  tmerge(\n    data1 = bmt %&gt;% select(my_id, T1, delta1), \n    data2 = bmt %&gt;% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\n\nPour voir ce que cela donne, examinons les données des 5 premiers patients individuels.\nLes variables d’intérêt dans les données originales ressemblaient à ceci :\n\nbmt %&gt;% \n  select(my_id, T1, delta1, TA, deltaA) %&gt;% \n  filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1   TA deltaA\n1     1 2081      0   67      1\n2     2 1602      0 1602      0\n3     3 1496      0 1496      0\n4     4 1462      0   70      1\n5     5 1433      0 1433      0\n\n\nLe nouvel ensemble de données pour ces mêmes patients ressemble à ceci :\n\ntd_dat %&gt;% \n  filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1 tstart tstop death agvhd\n1     1 2081      0      0    67     0     0\n2     1 2081      0     67  2081     0     1\n3     2 1602      0      0  1602     0     0\n4     3 1496      0      0  1496     0     0\n5     4 1462      0      0    70     0     0\n6     4 1462      0     70  1462     0     1\n7     5 1433      0      0  1433     0     0\n\n\nMaintenant, certains de nos patients ont deux lignes dans l’ensemble de données correspondant aux intervalles où ils ont une valeur différente de notre nouvelle variable, agvhd. Par exemple, le patient 1 a maintenant deux lignes avec une valeur agvhd de zéro du temps 0 au temps 67, et une valeur de 1 du temps 67 au temps 2081.\n\n\n\nRégression de Cox avec covariables dépendantes du temps\nMaintenant que nous avons remodelé nos données et ajouté la nouvelle variable aghvd dépendante du temps, ajustons un simple modèle de régression de Cox à variable unique. Nous pouvons utiliser la même fonction coxph() que précédemment, nous devons juste changer notre fonction Surv() pour spécifier à la fois le temps de début et de fin pour chaque intervalle en utilisant les arguments time1 = et time2 =.\n\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    agvhd, data = td_dat)\n\n  n= 163, number of events= 80 \n\n        coef exp(coef) se(coef)    z Pr(&gt;|z|)\nagvhd 0.3351    1.3980   0.2815 1.19    0.234\n\n      exp(coef) exp(-coef) lower .95 upper .95\nagvhd     1.398     0.7153    0.8052     2.427\n\nConcordance= 0.535  (se = 0.024 )\nLikelihood ratio test= 1.33  on 1 df,   p=0.2\nWald test            = 1.42  on 1 df,   p=0.2\nScore (logrank) test = 1.43  on 1 df,   p=0.2\n\n\nEncore une fois, nous allons visualiser les résultats de notre modèle cox en utilisant la fonction ggforest() du paquet survminer :\n\nggforest(bmt_td_model, data = td_dat)\n\n\n\n\n\n\n\n\nComme vous pouvez le constater à partir du diagramme forestier, de l’intervalle de confiance et de la valeur p, il ne semble pas y avoir de forte association entre le décès et la maladie aiguë du greffon contre l’hôte dans le contexte de notre modèle simple.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.fr.html#ressources",
    "href": "new_pages/survival_analysis.fr.html#ressources",
    "title": "27  Analyse de survie",
    "section": "27.7 Ressources",
    "text": "27.7 Ressources\nAnalyse de survie partie I : concepts de base et premières analyses\nAnalyse de survie en R\nAnalyse de survie dans la recherche sur les maladies infectieuses : décrire les événements dans le temps\nChapitre sur les modèles de survie avancés Princeton\nUtilisation de covariables et de coefficients dépendant du temps dans le modèle de Cox\nAide-mémoire pour l’analyse de survie R\nFeuille de calcul Survminer\nArticle sur les différentes mesures de survie pour les données des registres du cancer avec le code R fourni comme matériel supplémentaire",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Analyse de survie</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html",
    "href": "new_pages/gis.fr.html",
    "title": "28  GIS basics",
    "section": "",
    "text": "28.1 Présentation\nLes caracteristiques geospatiales de vos données peuvent fournir des informations capitales en situation de pandemie.En effet, ils permettent de repondent à des questions tels que:\nL’accent mis sur le SIG à travers ces pages rend accessible toutes les compétences pertinentes pouvant être utilisées en cas de reponse pandemique.On va voir les methodes simples pour visualiser les donnees spatiales grace aux packages tmap et ggplot.Nous allons aussi passer en revue le package sf qui permet une manipulation des donnees de types vecteurs. Enfin on va aborder brievement les statistiques spatiales à travers les notions de dependance spatiale, l’autocorrelation spatiale et la regression spatiale en utilisant le package spdep",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#présentation",
    "href": "new_pages/gis.fr.html#présentation",
    "title": "28  GIS basics",
    "section": "",
    "text": "Ou se trouve les zones à risques de la maladie\nComment les zones à risques evoluent dans le temps\nL’accessibilité du plateau medical et la nécessité d’apporter des améliorations",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#mots-clés",
    "href": "new_pages/gis.fr.html#mots-clés",
    "title": "28  GIS basics",
    "section": "28.2 Mots clés",
    "text": "28.2 Mots clés\nQuelques mots clés sont definis en bas.Pour une bonne initiation au SIG nous suggérons de suivre l’un des tutoriels proposés dans les références.\nSysteme d’Information Geographique(SIG) - Un SIG est un outil informatique ou un environnement qui permet de regrouper, de manipuler, d’analyser et de visualiser les données spatiales",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#logiciels-sig",
    "href": "new_pages/gis.fr.html#logiciels-sig",
    "title": "28  GIS basics",
    "section": "Logiciels SIG",
    "text": "Logiciels SIG\nLes logiciels populaires de SIG qui existent, fonctionnent sur la base d’une interface graphique qui interagit apres un clic de l’utlisateur.Ces outils peuvent etre utlisés sans aucun prerequis en programmation et ont comme avantage de pouvoir selectionner et placer des icones et des elements sur une carte manuellement.Les logiciels de SIG les plus connus sont :\nARCGIS - un logiciel commercial developpé par la compagnie ESRI.A ce jour il reste le logiciel de SIG le plus populaire.\nQGIS - un logiciel de SIG libre d’utilisation qui fait pratiquement la meme choses que ARCGIS. On peut Telecharger QGIS par ici\nFaire du SIG en utilisant R peut sembler frustant pour les premiers pas parce qu’à la place de pointer et cliquer , il faut maintenant ecrire des lignes de commande dans une interface (on a besoin de coder pour obtenir un resultat ).Mais ce changement de paradigme présente des avantages tels que l’automatisation et la reproductibilité dans la conception des carte et les analyses realisées.\n\nDonnées spatiales\nLes types de données utilisées en SIG sont de deux natures: les rasters et les vecteurs\nDonnées vecteurs - Les données vecteurs dont l’utilisation est la plus courante dans l’environnement SIG sont dotés de proprietes géometriques par les sommets et les lignes reliant les sommets. Les données vecteurs largement utilisées peuvent être divisées en trois :\n\nPoints - le point est constitué d’un pair de coordonnnées (x,y) qui marque un lieu précis dans l’espace à travers le systeme de coordonnées. Il est la forme simple de représentation des donnees spatiales et peuvent etre utilisé pour situer le lieu d’apparition d’une maladie lors d’une pandémie (la maison du patient) ou un endroit (exemple : hôpital) sur une carte .\nLignes - Une ligne est composée de deux points reliés.Elle a une longueur et peut etre utilisée pour representer les routes ou les cours d’eaux\nPolygones - Un polygones est une association minimum de 3 points reliés les uns aux autres .Les caractéristiques d’un polygone sont : le périmètre et l’aire.En pratique ils sont utilisés pour delmiter les contours d’une zone (village) ou une infractructures(hopital)\n\nDonnées Rasters - A coté des données vecteurs on a des rasters qui sont des matrix constitués par des cellules contenant chacunes des informations par exemple l’altitude, la temperature, la pente, la couverture forestière etc. les rasters peuvent servir de fond de carte pour les donnees vecteurs\n\n\nVisualisation des données spatiales\nPour afficher sur une carte des donnnées spatiales à partir d’un logiciel de SIG il est nécessaire de la part de l’utilisateur de connaitre l’emplacement des donnees .Lors qu’il nous arrive de manipuler des données vecteurs ce qui est d’ailleurs le plus frequents, les données sont stocker dans des fichiers shapefiles\nShapefiles - Un shapefile est un format de données vecteurs tres repandus dans le monde du SIG et il permet de stocker des donnees pouvant etre des points des lignes et des polygones.C’est en realite une collection ou un ensemnble de fichiers se terminant avec les extensions .shp,.shx et .dbf.Tout ces fichiers doivent etre presents dans un et unique dossiers pour obtenir une donnée shapefile fiable. L’ensemble de ces fichiers shapefile peuvent être comprimer en format zip pour un envoi à travers un mail ou un telechargement à partir d’un site web\nLe shapefile contient des information sur un objet de la surface terreste modelisé et sa localisation géographique .Cela est important parce que bien que la terre est une geoide le système de coordonnées bidimentionnel au niveau des shapefiles permet de situer un objet sur la surface de la terre\nSystéme de réference de coordonnées  - Un CRS est un système de coordonnées utilisé pour localiser géographiquement un objet sur la surface de la terre .Il a quelques composantes clés:\n\nSysteme de Coordonnées - Plusieurs systèmes de coordonnées existent mais il est important de savoir les coodonnées géographiques utilisées sont adossées à quel système.Les degres pour le longitude/latitude sont fréquents mais on note aussi l’usage des coordonnées UTM\nUnités - Connaitre l’unité du système de coordonnées(degres ou decimal) est primordiale pour faire certaines analyses spatiales\nDatum - C’est une modélisation de la terre revue au fil des annees, il est important de vérifier que les cartes utilisées ont le meme datum ou systeme geodesique\nProjection - C’est l’utilisation d’équation mathematique pour projeter la forme geoide de la terre sur une surface plane\n\nRappellons que les données spatiales peuvent être manipulées sans avoir recours aux outils cartographiques ci-dessous",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#débuter-avec-le-sig",
    "href": "new_pages/gis.fr.html#débuter-avec-le-sig",
    "title": "28  GIS basics",
    "section": "28.3 Débuter avec le SIG",
    "text": "28.3 Débuter avec le SIG\nIl y a quelques éléments clés que vous devrez avoir et auxquels vous devrez penser pour faire une carte. Ces éléments sont les suivants :\n\nUn jeu de données - il peut s’agir d’un format de données spatiales (comme les shapefiles, comme indiqué ci-dessus) ou d’un format non spatial (par exemple, un simple csv).\nSi votre ensemble de données n’est pas dans un format spatial, vous aurez également besoin d’un jeu données de référence. Les données de référence sont constituées de la représentation spatiale des données et des attributs associés, qui peuvent inclure des éléments contenant les informations relatives à l’emplacement et à l’adresse d’entités spécifiques.\n\nSi vous travaillez avec des limites géographiques prédéfinies (par exemple, des régions administratives), les fichiers de forme de référence peuvent souvent être téléchargés gratuitement depuis une agence gouvernementale ou une organisation de partage de données. En cas de doute, un bon point de départ est de rechercher sur Google ” [régions] shapefile “.\nSi vous avez des informations d’adresse, mais pas de latitude et de longitude, vous devrez peut-être utiliser un moteur de géocodage pour obtenir les données de référence spatiale pour vos enregistrements.\n\nUne idée de la manière dont vous voulez présenter les informations de vos ensembles de données à votre public cible. Il existe de nombreux types de cartes, et il est important de réfléchir au type de carte qui correspond le mieux à vos besoins.\n\n\nTypes of maps for visualizing your data\n\n\nLes types de cartes pour visualiser vos données\nCarte chloroplethe - ce sont des cartes thematiques ou les couleurs l’ombrage et les motifs sont utilisés pour representer les valeurs des variables présentes dans les attributs en fonction des unités geograpphiques.Par exemple, une valeur plus grande peut être indiquée par une couleur plus foncée qu’une valeur plus petite. Ce type de carte est particulièrement utile pour visualiser une variable et son évolution dans des régions ou des zones géopolitiques définies.\n\n\n\n\n\n\n\n\n\ncarte de fréquentation de la densite des cas - C’est Un type de carte thematique ou l’intensité des couleurs est proportionnelle à la valeur de l’observation cela ne fait pas intervenir des zones ou des limites geographiques et adminitratives. Ce genre de carte est utilisé pour montrerles zones à risques ou les lieux à forte concentration de variables observées\n\n\n\n\n\n\n\n\n\nCarte de densité de points - Une carte thematique qui utilise des points pour représenter la valeur du variable dans les données.Ce type de carte permet de visualiser les données avec un nuage de point afin d’identifier la presence de clusters ou foyers\nCarte à symboles proportionnels (carte à symboles gradués) - une carte thématique similaire à une carte choroplèthe, mais au lieu d’utiliser une couleur pour indiquer la valeur d’un attribut, elle utilise un symbole (généralement un cercle) en relation avec la valeur. Par exemple, une valeur plus grande peut être indiquée par un symbole plus grand qu’une valeur plus petite. Ce type de carte est idéal lorsque vous souhaitez visualiser la taille ou la quantité de vos données dans des régions géographiques.\nVous pouvez également combiner plusieurs types de visualisations différentes pour montrer des schémas géographiques complexes. Par exemple, les cas (points) de la carte ci-dessous sont colorés en fonction de l’établissement de santé le plus proche (voir la légende). Les grands cercles rouges montrent les zones de couverture des établissements de santé d’un certain rayon, et les points rouges brillants les cas qui étaient en dehors de toute zone de desserte :\n\n\n\n\n\n\n\n\n\nRemarque : L’objectif principal de cette page SIG est basé sur le contexte de la réponse aux épidémies sur le terrain. Par conséquent, le contenu de la page couvrira les manipulations, visualisations et analyses de données spatiales de base.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#preparation",
    "href": "new_pages/gis.fr.html#preparation",
    "title": "28  GIS basics",
    "section": "28.4 Preparation",
    "text": "28.4 Preparation\n\nChargement packages\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,           # Pour importer les données\n  here,          # Pour situer l'emplacement des donnes\n  tidyverse,     # nettoyer manipuler et visualiser les données( inclure le package ggplot2)\n  sf,            # manipuler les donnees spatiales avec le package sf\n  tmap,          # pour produire des cartes simples, fonctionne pour les cartes interactives et statiques\n  janitor,       # pour nettoyer les noms de colonnes\n  OpenStreetMap, # pour ajouter la  carte de base OSM sur la carte ggplot\n  spdep          # statistiques spatiales\n  ) \n\nVous pouvez consulter une vue d’ensemble de tous les paquets R qui traitent des données spatiales sur le site CRAN “Spatial Task View”.\n\n\nExemple de données de cas\nÀ des fins de démonstration, nous travaillerons avec un échantillon aléatoire de 1000 cas provenant du dataframe linelist de l’épidémie d’Ebola simulée (d’un point de vue computationnel, travailler avec moins de cas est plus facile à afficher dans ce manuel). Si vous souhaitez suivre le processus, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds).\nComme nous prenons un échantillon aléatoire de cas, vos résultats peuvent être légèrement différents de ce qui est démontré ici lorsque vous exécutez les codes par vous-même.\nImportez les données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# importer le jeu de données linelist nettoyé\nlinelist &lt;- import(\"linelist_cleaned.rds\")  \n\nEnsuite, nous sélectionnons un échantillon aléatoire de 1000 lignes en utilisant sample() de base R.\n\n# générer 1000 numéros de ligne aléatoires, à partir du nombre de lignes de la linelist\nsample_rows &lt;- sample(nrow(linelist), 1000)\n\n#  creons un sous-ensembles de linelist   pour ne garder que les lignes de l'échantillon, et toutes les colonnes\nlinelist &lt;- linelist[sample_rows,]\n\nMaintenant nous voulons convertir cette linelist qui est de classe dataframe, en un objet de classe “sf” (caractéristiques spatiales). Étant donné que la linelist a deux colonnes “lon” et “lat” représentant la longitude et la latitude de la résidence de chaque cas, cela sera facile.\nNous utilisons le package sf (caractéristiques spatiales) et sa fonction st_as_sf() pour créer le nouvel objet que nous appelons linelist_sf. Ce nouvel objet ressemble essentiellement à la linelist, mais les colonnes lon et lat ont été désignées comme des colonnes de coordonnées, et un système de référence de coordonnées (CRS) a été attribué pour l’affichage des points. 4326 identifie nos coordonnées comme étant basées sur le Système géodésique mondial 1984 (WGS84) - qui est la norme pour les coordonnées GPS.\n\n# Creons un objet  sf \nlinelist_sf &lt;- linelist %&gt;%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nVoici à quoi ressemble le dataframe original linelist. Dans cette démonstration, nous n’utiliserons que la colonne date_onset et geometry (qui a été construite à partir des champs de longitude et de latitude ci-dessus et qui est la dernière colonne du dataframe).\n\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n\n\n\n\n\n\n\nshapefiles des limites administratives\nSierra Leone: shapefiles des limites administratives\nPar avance, nous avons téléchargé toutes les limites administratives de la Sierra Leone à partir du Humanitarian Data Exchange (HDX) site Web ici. Alternativement, vous pouvez télécharger ces données et toutes les autres données d’exemple pour ce manuel via notre package R, comme expliqué dans la page Télécharger le manuel et les données.\nNous allons maintenant procéder comme suit pour enregistrer le shapefile Admin Level 3 dans R :\n\nImporter les shapefiles\nNettoyer les noms des colonnes\n\nFiltrer les lignes pour ne garder que les zones d’intérêt.\n\nPour importer un fichier shapefile, nous utilisons la fonction read_sf() de sf. Le chemin du fichier est fourni via here(). - Dans notre cas, le fichier se trouve dans notre projet R dans les sous-dossiers “data”, “gis” et “shp”, avec le nom de fichier “sle_adm3.shp” (voir les pages sur Importation et exportation et Projets R pour plus d’informations). Vous devrez fournir votre propre chemin de fichier.\nEnsuite, nous utilisons clean_names() du package janitor pour normaliser les noms de colonnes du fichier shapefile. Nous utilisons également filter() pour ne conserver que les lignes dont le nom d’administrateur est “Western Area Urban” ou “Western Area Rural”.\n\n# ADM3 level clean\nsle_adm3 &lt;- sle_adm3_raw %&gt;%\n  janitor::clean_names() %&gt;% # normaliser les noms de colonnes\n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filtre pour garder certaines zones\n\nVous pouvez voir ci-dessous à quoi ressemble le fichier shapefile après importation et nettoyage. Faites défiler vers la droite pour voir s’il y a des colonnes avec le niveau d’administration 0 (pays), le niveau d’administration 1, le niveau d’administration 2, et enfin le niveau d’administration 3. Chaque niveau a un nom de caractère et un identifiant unique “pcode”. Le pcode se développe avec chaque niveau d’administration croissant, par exemple SL (Sierra Leone) -&gt; SL04 (Western) -&gt; SL0410 (Western Area Rural) -&gt; SL040101 (Koya Rural).\n\n\n\n\n\n\n\n\nPopulation data\nSierra Leone : Population par ADM3\nCes données peuvent être téléchargées sur HDX (lien ici) ou via notre package R epirhandbook comme expliqué dans la page Télécharger le manuel et les données. Nous utilisons import() pour charger le fichier .csv. Nous passons également le fichier importé à clean_names() pour standardiser la syntaxe des noms de colonnes.\n\n# Population par ADM3\nsle_adm3_pop &lt;- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %&gt;%\n  janitor::clean_names()\n\nVoici à quoi ressemble le fichier de la population. Faites défiler vers la droite pour voir comment chaque juridiction a des colonnes avec la population “masculine”, la population “féminine”, la population “totale”, et la répartition de la population en colonnes par groupe d’âge.\n\n\n\n\n\n\n\n\nInfractructures sanitaires\nSierra Leone : Données sur les établissements de santé provenant d’OpenStreetMap.\nEncore une fois, nous avons téléchargé les emplacements des établissements de santé à partir de HDX ici ou via les instructions dans la page [Télécharger le manuel et les données](#download_book_data.\nNous importons le shapefile des points des établissements avec read_sf(), nettoyons à nouveau les noms des colonnes, et filtrons ensuite pour ne garder que les points étiquetés comme “hôpital”, “clinique”, ou “médecins”.\n\n#  Les donnees shapefiles de OSM sur  les infractuctures sanitaires \nsle_hf &lt;- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %&gt;% \n  janitor::clean_names() %&gt;%\n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))\n\nVoici le dataframe obtenu defile jusqu’a en bas pour voir le nom de l’infrastructures sanitaires et les coordonnées geographiques à travers la colonne geometry.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#visualiser-les-coordonnées",
    "href": "new_pages/gis.fr.html#visualiser-les-coordonnées",
    "title": "28  GIS basics",
    "section": "28.5 Visualiser les coordonnées",
    "text": "28.5 Visualiser les coordonnées\nLa manière la plus simple de visualiser des coordonnées X-Y (longitude/latitude, points), dans ce cas de figure, est de les dessiner sous forme de points directement à partir de l’objet linelist_sf que nous avons créé dans la section de préparation.\nLe package tmap offre des capacités de cartographie simples à la fois pour le mode statique (mode “plot”) et interactif (mode “view”) avec seulement quelques lignes de code. La syntaxe de tmap est similaire à celle de ggplot2, de sorte que les commandes sont ajoutées les unes aux autres avec +. Vous trouverez plus de détails dans cette vignette.\n\nDéfinir le mode tmap. Dans ce cas, nous utiliserons le mode “plot”, qui produit des sorties statiques.\n\n\ntmap_mode(\"plot\") # choisir soit  \"view\" ou \"plot\"\n\nCi-dessous, seulement les points sont affichés. tm_shape() prend comme argument : l’objet linelist_sf. Ensuite , Nous ajoutons des points via tm_dots(), en spécifiant la taille et la couleur. Comme linelist_sf est un objet sf, nous avons déjà désigné les deux colonnes qui contiennent les coordonnées lat/long et le système de référence des coordonnées (CRS) :\n\n# Juste les cas (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n\n\n\n\n\n\n\n\nles points seulement ne sont pas assez informatifs. Nous devons donc également cartographier les limites administratives :\nApres cela, nous utilisons tm_shape() (voir documentation) mais au lieu de fournir le shapefile des points ou les cas sont localisés, nous fournissons le shapefile des limites administratives (polygones).\nAvec l’argument bbox = (bbox signifie “bounding box”) nous pouvons spécifier l’emprise des coordonnées. Nous allons d’abord visualiser la carte sans l’emprise bbox, et ensuite avec l’emprise de l’objet.\n\n# Uniquement les frontieres administratives (polygones)\ntm_shape(sle_adm3) +               # Shapefiles des limites administratives\n  tm_polygons(col = \"#F7F7F7\")+    # afficher les polygones en gris clairs\n  tm_borders(col = \"#000000\",      # parametrer la couleur des bordures   et l'epaisseur des lignes\n             lwd = 2) +\n  tm_text(\"admin3name\")            # le texte de la colonne à afficher pour chaque polygone\n\n\n#Comme ci-dessus, mais avec un zoom à partir de l'emprise\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # sommet\n                  -13.2, 8.5)) +  # sommet\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEt maintenant les points et les polygones ensemble :\n\n# tous ensemble\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # donner un titre à la carte\n\n\n\n\n\n\n\n\nPour lire une bonne comparaison des options de mappage dans R, consultez cet article de blog.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#jointures-spatiales",
    "href": "new_pages/gis.fr.html#jointures-spatiales",
    "title": "28  GIS basics",
    "section": "28.6 Jointures spatiales",
    "text": "28.6 Jointures spatiales\nVous êtes peut-être familier avec la jonction de données d’un jeu de données à un autre. Plusieurs méthodes sont présentées à la page Joindre des données de ce manuel. Une jointure spatiale a un objectif similaire mais exploite les relations spatiales. Au lieu de compter sur des valeurs communes dans les colonnes pour faire correspondre correctement les observations, vous pouvez utiliser leurs relations spatiales, comme le fait qu’une observation soit dans une autre, ou le plus proche voisin d’une autre, ou dans un buffer d’un certain rayon d’une autre, etc.\nLe package sf offre diverses méthodes de jointures spatiales. Vous trouverez plus de documentation sur la méthode st_join et les types de jointures spatiales dans cette référence.\n\nPoints dans le polygone\nAttribuer spatialement des unités administratives aux cas\nVoici une question intéressante : la liste de cas ne contient aucune information sur les unités administratives des cas. Bien qu’il soit idéal de collecter ces informations au cours de la phase initiale de collecte des données, nous pouvons également attribuer des unités administratives aux cas individuels sur la base de leurs relations spatiales (c’est-à-dire l’intersection d’un point avec un polygone).\nCi-dessous, nous allons croiser spatialement les emplacements de nos cas (points) avec les limites d’ADM3 (polygones) :\n\nCommencer par l’objet linelist (points)\n\nJointure spatiale aux limites, en définissant le type de jointure comme etant “st_intersects”.\n\nUtilisez select() pour ne garder que certaines des colonnes de la nouvelle limite administrative.\n\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # joindre le fichier des limites administratives à  linelist sur la base de l'intersection spatiale.\n  sf::st_join(sle_adm3, join = st_intersects)\n\nToutes les colonnes de sle_adms ont été ajoutées à la linelist ! Chaque cas a maintenant des colonnes détaillant les niveaux administratifs dont il fait partie. Dans cet exemple, nous voulons seulement garder deux des nouvelles colonnes (niveau administratif 3), donc nous sélectionnons() les anciens noms de colonnes et seulement les deux supplémentaires d’intérêt :\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # joindre le fichier des limites administratives au fichier linelist, sur la base de l'intersection spatiale.\n  sf::st_join(sle_adm3, join = st_intersects) %&gt;% \n  \n  # Conservez les anciens noms de colonnes et deux nouveaux noms admin d'intérêt\n  select(names(linelist_sf), admin3name, admin3pcod)\n\nCi-dessous, à des fins d’affichage, vous pouvez voir les dix premiers cas et les limites administratives de niveau 3(ADM3) qui y ont été rattachées, en fonction de l’endroit où le point a croisé les formes polygonales.\n\n# Vous verrez maintenant les noms ADM3 attachés à chaque cas.\nlinelist_adm %&gt;% select(case_id, admin3name, admin3pcod)\n\nSimple feature collection with 1000 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -13.27052 ymin: 8.447887 xmax: -13.20722 ymax: 8.490746\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     case_id     admin3name admin3pcod                   geometry\n1631  0c97ee      Central I   SL040201 POINT (-13.22679 8.472649)\n2483  e8da84        East II   SL040204 POINT (-13.21111 8.475342)\n1237  697194 Mountain Rural   SL040102 POINT (-13.21546 8.454844)\n3641  811fb2       West III   SL040208 POINT (-13.26702 8.456449)\n518   1fa5a7 Mountain Rural   SL040102 POINT (-13.21824 8.451489)\n4168  934d1f Mountain Rural   SL040102 POINT (-13.22096 8.462292)\n5056  99bd62         West I   SL040206 POINT (-13.24836 8.487274)\n430   f839c6     Central II   SL040202 POINT (-13.23735 8.487942)\n125   49e88d Mountain Rural   SL040102  POINT (-13.21127 8.46463)\n1174  47eaae       West III   SL040208 POINT (-13.25324 8.459599)\n\n\nNous pouvons maintenant décrire nos cas par unité administrative - ce que nous ne pouvions pas faire avant la jointure spatiale !\n\n# Créer un nouveau dataframe contenant le nombre de cas par unité administrative.\ncase_adm3 &lt;- linelist_adm %&gt;%          # commencer avec linelist avec de nouveaux admin colonnes\n  as_tibble() %&gt;%                      # convert en format  tibble pour un meilleur affichage\n  group_by(admin3pcod, admin3name) %&gt;% # regrouper par   unite admin, à la fois  par le nom   et le  pcode \n  summarise(cases = n()) %&gt;%           # utilisons la fonction summarize et  comptons les lignes\n  arrange(desc(cases))                     # arrangement par ordre decroissant\n\ncase_adm3\n\n# A tibble: 10 × 3\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;\n 1 SL040102   Mountain Rural   294\n 2 SL040208   West III         246\n 3 SL040207   West II          156\n 4 SL040204   East II          106\n 5 SL040201   Central I         62\n 6 SL040203   East I            49\n 7 SL040206   West I            47\n 8 SL040202   Central II        21\n 9 SL040205   East III          14\n10 &lt;NA&gt;       &lt;NA&gt;               5\n\n\nNous pouvons également créer un diagramme en barres du nombre de cas par unité administrative.\nDans cet exemple, nous commençons le ggplot() avec la linelist_adm, afin de pouvoir appliquer des fonctions de facteurs comme fct_infreq() qui ordonne les barres par fréquence (voir la page sur les Facteurs pour des conseils).\n\nggplot(\n    data = linelist_adm,                       # Debuter  avec linelist qui contient les infos sur les unites admin \n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # L'axe des x est constitué d'unités administratives, classées par fréquence (inversée).\n  geom_bar()+                                # créer des barres, la hauteur est le nombre de lignes\n  coord_flip()+                              # retournement des axes X et Y pour une lecture plus aisée des unités d'admin\n  theme_classic()+                           # simplifier le fond\n  labs(                                      # titres et les  labels\n    x = \"Admin Niveau 3\",\n    y = \"Number of cases\",\n    title = \"Nombre de cas par unité adminstrative\",\n    caption = \"Tel que déterminé par une jointure spatiale, à partir de 1000 cas échantillonnés de façon aléatoire dans linelist.\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nLe voisin le plus proche\nTrouver l’établissement de santé le plus proche / la zone de captage\nIl peut être utile de savoir où sont situés les établissements de santé par rapport aux foyers de maladies.\nNous pouvons utiliser la méthode de jointure st_nearest_feature de la fonction st_join() (package sf) pour visualiser l’établissement de santé le plus proche des cas individuels.\n\nNous commençons avec le fichier de forme linelist linelist_sf.\n\nNous joignons spatialement avec sle_hf, qui est les emplacements des établissements de santé et des cliniques (points)\n\n\n# Établissement de santé le plus proche de chaque cas\nlinelist_sf_hf &lt;- linelist_sf %&gt;%                  # commencons avec linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %&gt;%   # données de la clinique la plus proche jointes aux données du cas \n  select(case_id, osm_id, name, amenity) %&gt;%       # conserver les colonnes d'intérêt, notamment l'identifiant, le nom, le type et la géométrie de l'établissement de santé\n  rename(\"nearest_clinic\" = \"name\")                # renommer pour plus de clarté\n\nNous pouvons voir ci-dessous (les 50 premières lignes) que chaque cas a maintenant des données sur la clinique/hôpital le plus proche.\n\n\n\n\n\n\nNous pouvons voir que “Den Clinic” est l’établissement de santé le plus proche pour environ 30 % des cas.\n\n# Nombre de cas par établissement de santé\nhf_catchment &lt;- linelist_sf_hf %&gt;%   # commencer par linelist comprenant les données de la clinique la plus proche\n  as.data.frame() %&gt;%                # convertir de shapefile à dataframe\n  count(nearest_clinic,              # compter les lignes par \"nom\" (de la clinique)\n        name = \"case_n\") %&gt;%         # assign new counts column as \"case_n\"\n  arrange(desc(case_n))              # classer par ordre décroissant\n\nhf_catchment                         # Afficher sur  la console\n\n                         nearest_clinic case_n\n1                            Den Clinic    378\n2       Shriners Hospitals for Children    333\n3         GINER HALL COMMUNITY HOSPITAL    161\n4                             panasonic     56\n5 Princess Christian Maternity Hospital     28\n6                     ARAB EGYPT CLINIC     20\n7                                  &lt;NA&gt;     13\n8                  MABELL HEALTH CENTER     11\n\n\nPour visualiser les résultats, nous pouvons utiliser tmap - cette fois-ci en mode interactif pour une visualisation plus facile.\n\ntmap_mode(\"view\")   # Utiliser tmap en  mode  interactive  \n\n# Visualiser les points ou sont localisés les cas et cliniques\ntm_shape(linelist_sf_hf) +            # visualiser les cas\n  tm_dots(size=0.08,                  # cas colorés par la clinique la plus proche\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # tracer les  cliniques en gros points noirs\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # superposition du nom de l'installation\ntm_view(set.view = c(-13.2284, 8.4699, 13), # ajuster le zoom (coordonnées du centre, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cas, colorés par la clinique la plus proche\")\n\n\n\n\n\n\n\nBuffer\nNous pouvons également explorer combien de cas sont situés à moins de 2,5 km (~30 minutes) de distance de marche de l’établissement de santé le plus proche.\nRemarque : pour des calculs de distance plus précis, il est préférable de reprojeter votre objet sf dans le système de projection de la carte locale, tel que l’UTM (Terre projetée sur une surface plane). Dans cet exemple, pour des raisons de simplicité, nous nous en tiendrons au système de coordonnées géograhpiques World Geodetic System (WGS84) (la Terre est représentée par une surface sphérique / ronde, les unités sont donc en degrés décimaux). Nous utiliserons une conversion générale de : 1 degré décimal = ~111km.\nPour plus d’informations sur les projections cartographiques et les systèmes de coordonnées, consultez cet article esri. Ce blog traite des différents types de projection cartographique et de la manière de choisir une projection appropriée en fonction de la zone d’intérêt et du contexte de votre carte / analyse.\nTout d’abord, créez un tampon circulaire d’un rayon de ~2,5 km autour de chaque établissement de santé. Ceci est fait avec la fonction st_buffer() de tmap. Parce que l’unité de la carte est en degrés décimaux lat/long, c’est ainsi que “0,02” est interprété. Si le système de coordonnées de votre carte est en mètres, le nombre doit être fourni en mètres.\n\nsle_hf_2k &lt;- sle_hf %&gt;%\n  st_buffer(dist=0.02)       # degrés décimaux se traduisant par environ 2,5 km \n\nCi-dessous, nous traçons les zones tampons elles-mêmes, avec les valeurs de :\n\ntmap_mode(\"plot\")\n# Creons une zone tampon circulaire\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # materialiser les installations cliniques avec  de gros points rouges\n  tm_dots(size=0.3, col='black')      \n\n\n\n\n\n\n\n\nEnsuite, nous intersectons ces tampons avec les cas (points) en utilisant st_join() et le type de jointure de st_intersects. C’est-à-dire que les données de la zone tampon sont jointes aux points qu’ils croisent.\n\n# Intersecter les cas observés  avec la zone tampon\nlinelist_sf_hf_2k &lt;- linelist_sf_hf %&gt;%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %&gt;%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %&gt;%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n\nMaintenant, nous pouvons compter les résultats : nrow(linelist_sf_hf_2k[is.na(linelist_sf_hf_2k$osm_id.y),]) sur 1000 cas ne recoupent aucun tampon (cette valeur est manquante), et vivent donc à plus de 30 minutes de marche de l’établissement de santé le plus proche.\n\n# Cas qui n'ont pas été croisés avec l'un des tampons de l'établissement de santé\nlinelist_sf_hf_2k %&gt;% \n  filter(is.na(osm_id.y)) %&gt;%\n  nrow()\n\n[1] 1000\n\n\nNous pouvons visualiser les résultats de telle sorte que les cas qui n’ont intersecté aucun tampon apparaissent en rouge.\n\ntmap_mode(\"view\")\n\n# Affichez  d'abord les cas en points\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# tracer les installations cliniques en gros points noirs\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# Superposez ensuite les zones tampons des établissements de santé sous forme de polylignes.\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Highlight cases that are not part of any health facility buffers\n# en points noirs  \ntm_shape(linelist_sf_hf_2k %&gt;%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# ajouter le titre\ntm_layout(title = \"Nombre de Cas par zone couverture des cliniques \")\n\n\n\n\n\n\n\nles autres jointures spatiales\nLes valeurs alternatives pour l’argument join comprennent (de la documentation)\n\nst_contains_properly\n\nst_contains\n\nst_covered_by\n\nst_covers\n\nst_crosses\n\nst_disjoint\n\nst_equals_exact\n\nst_equals\n\nst_is_within_distance\n\nst_nearest_feature\n\nst_overlaps\n\nst_touches\n\nst_within",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#choropleth-maps",
    "href": "new_pages/gis.fr.html#choropleth-maps",
    "title": "28  GIS basics",
    "section": "28.7 Choropleth maps",
    "text": "28.7 Choropleth maps\nLes cartes choroplèthes peuvent être utiles pour visualiser vos données par zone prédéfinie, généralement une unité administrative ou une zone de santé. Dans le cadre de la réponse aux épidémies, cela peut aider à cibler l’allocation des ressources pour des zones spécifiques présentant des taux d’incidence élevés, par exemple.\nMaintenant que nous avons les noms des unités administratives attribués à tous les cas (voir la section sur les jointures spatiales, ci-dessus), nous pouvons commencer à cartographier le nombre de cas par zone (cartes choroplèthes).\nPuisque nous disposons également des données de population par ADM3, nous pouvons ajouter ces informations à la table case_adm3 créée précédemment.\nNous commençons avec le cadre de données créé à l’étape précédente case_adm3, qui est un tableau récapitulatif de chaque unité administrative et de son nombre de cas.\n\nLes données de population sle_adm3_pop sont jointes à l’aide d’un left_join() de dplyr sur la base des valeurs communes à la colonne admin3pcod dans le dataframe case_adm3, et à la colonne adm_pcode dans le dataframe sle_adm3_pop. Voir la page Joindre des données).\n\nselect() est appliqué au nouveau dataframe, pour ne garder que les colonnes utiles - total est la population totale.\n\nLes cas pour 10.000 habitants sont calculés comme une nouvelle colonne avec mutate().\n\n\n# Ajouter les données de la population et calculer les cas pour 10K de population\ncase_adm3 &lt;- case_adm3 %&gt;% \n     left_join(sle_adm3_pop,                             #ajouter des colonnes à partir du jeu données pop\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %&gt;%  # jointure basee sur les valeurs communes à ces deux colonnes\n     select(names(case_adm3), total) %&gt;%                 # ne conserver que les colonnes importantes, notamment la population totale\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # créer une nouvelle colonne avec le taux de cas pour 10000, arrondi à 3 décimales\n\ncase_adm3                                                # imprimer sur la console pour l'affichage\n\n# A tibble: 10 × 5\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases  total case_10kpop\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;  &lt;int&gt;       &lt;dbl&gt;\n 1 SL040102   Mountain Rural   294  33993       86.5 \n 2 SL040208   West III         246 210252       11.7 \n 3 SL040207   West II          156 145109       10.8 \n 4 SL040204   East II          106  99821       10.6 \n 5 SL040201   Central I         62  69683        8.90\n 6 SL040203   East I            49  68284        7.18\n 7 SL040206   West I            47  60186        7.81\n 8 SL040202   Central II        21  23874        8.80\n 9 SL040205   East III          14 500134        0.28\n10 &lt;NA&gt;       &lt;NA&gt;               5     NA       NA   \n\n\nfaire une Jointure cette table au shapefile ADM3 polygones pour la cartographie.\n\ncase_adm3_sf &lt;- case_adm3 %&gt;%                 # Commencer par les cas et classer par unité administrative\n  left_join(sle_adm3, by=\"admin3pcod\") %&gt;%    # jointure aux données shapefile par colonne commune\n  select(objectid, admin3pcod,                # ne conserver que certaines colonnes d'intérêt\n         admin3name = admin3name.x,           # nettoyer le nom de   ce  column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %&gt;%                        # conserver la géométrie pour que les polygones puissent être cartographier\n  drop_na(objectid) %&gt;%                       # supprimer les lignes vides\n  st_as_sf()                                  # convertir en  shapefile\n\nCartographier le resultat\n\n# tmap mode\ntmap_mode(\"plot\")               # carte statique\n\n# visualiser les polygones\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # colorier en fonction  du nombre de cas \n        tm_text(\"admin3name\")   # afficher les noms\n\n\n\n\n\n\n\n\nNous pouvons cartographier le taux d’incidence\n\n# Cases per 10K population\ntmap_mode(\"plot\")             # mode affiche statique\n\n# plot\ntm_shape(case_adm3_sf) +                # visualiser lespolygons\n  tm_polygons(\"case_10kpop\",            # colorier en fonction du colonnes contenant le pourcentages des cas\n              breaks=c(0, 10, 50, 100), # définir des points de rupture pour les couleurs\n              palette = \"Purples\"       # utiliser une palette de couleurs violettes\n              ) +\n  tm_text(\"admin3name\")                 # afficher le texte",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#cartographie-avec-ggplot2",
    "href": "new_pages/gis.fr.html#cartographie-avec-ggplot2",
    "title": "28  GIS basics",
    "section": "28.8 Cartographie avec ggplot2",
    "text": "28.8 Cartographie avec ggplot2\nSi vous êtes déjà familiarisé avec l’utilisation de ggplot2, vous pouvez utiliser ce package pour créer des cartes statiques de vos données. La fonction geom_sf() dessinera différents objets en fonction des caractéristiques (points, lignes ou polygones) présentes dans vos données. Par exemple, vous pouvez utiliser geom_sf() dans un ggplot() utilisant des données sf avec une géométrie polygonale pour créer une carte choroplèthe.\nPour illustrer comment cela fonctionne, nous pouvons commencer avec le fichier de forme ADM3 polygones que nous avons utilisé plus tôt. Rappelez-vous qu’il s’agit des régions de niveau administratif 3 de la Sierra Leone :\n\nsle_adm3\n\nSimple feature collection with 12 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 20\n   objectid admin3name   admin3pcod admin3ref_n admin2name admin2pcod admin1name\n *    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n 1      155 Koya Rural   SL040101   Koya Rural  Western A… SL0401     Western   \n 2      156 Mountain Ru… SL040102   Mountain R… Western A… SL0401     Western   \n 3      157 Waterloo Ru… SL040103   Waterloo R… Western A… SL0401     Western   \n 4      158 York Rural   SL040104   York Rural  Western A… SL0401     Western   \n 5      159 Central I    SL040201   Central I   Western A… SL0402     Western   \n 6      160 East I       SL040203   East I      Western A… SL0402     Western   \n 7      161 East II      SL040204   East II     Western A… SL0402     Western   \n 8      162 Central II   SL040202   Central II  Western A… SL0402     Western   \n 9      163 West III     SL040208   West III    Western A… SL0402     Western   \n10      164 West I       SL040206   West I      Western A… SL0402     Western   \n11      165 West II      SL040207   West II     Western A… SL0402     Western   \n12      167 East III     SL040205   East III    Western A… SL0402     Western   \n# ℹ 13 more variables: admin1pcod &lt;chr&gt;, admin0name &lt;chr&gt;, admin0pcod &lt;chr&gt;,\n#   date &lt;date&gt;, valid_on &lt;date&gt;, valid_to &lt;date&gt;, shape_leng &lt;dbl&gt;,\n#   shape_area &lt;dbl&gt;, rowcacode0 &lt;chr&gt;, rowcacode1 &lt;chr&gt;, rowcacode2 &lt;chr&gt;,\n#   rowcacode3 &lt;chr&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nNous pouvons utiliser la fonction left_join() de dplyr pour ajouter les données que nous souhaitons mapper à l’objet shapefile. Dans ce cas, nous allons utiliser le cadre de données case_adm3 que nous avons créé plus tôt pour résumer le nombre de cas par région administrative ; cependant, nous pouvons utiliser cette même approche pour mapper n’importe quelle donnée stockée dans un cadre de données.\n\nsle_adm3_dat &lt;- sle_adm3 %&gt;% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join =  retenir seulement si dans les deux objets de données\n\nselect(sle_adm3_dat, admin3name.x, cases) # affiche les variables sélectionnées sur la console\n\nSimple feature collection with 9 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 9 × 3\n  admin3name.x   cases                                                  geometry\n  &lt;chr&gt;          &lt;int&gt;                                        &lt;MULTIPOLYGON [°]&gt;\n1 Mountain Rural   294 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.4…\n2 Central I         62 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.48…\n3 East I            49 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.49…\n4 East II          106 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.4…\n5 Central II        21 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.4…\n6 West III         246 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.4…\n7 West I            47 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.49…\n8 West II          156 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.4…\n9 East III          14 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.4…\n\n\nPour réaliser un graphique en colonnes du nombre de cas par région, en utilisant ggplot2, nous pourrions alors appeler geom_col() comme suit :\n\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # réorganiser l'axe des x par ordre décroissant 'cases'\n               y=cases)) +                                  # l'axe des y est le nombre de cas par région\n  theme_bw() +\n  labs(                                                     # définir le texte de la figure\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # angle des étiquettes de l'axe des x de 45 degrés pour un meilleur ajustement\n\n\n\n\n\n\n\n\nSi nous voulons utiliser ggplot2 pour réaliser une carte choroplèthe du nombre de cas, nous pouvons utiliser une syntaxe similaire pour appeler la fonction geom_sf() :\n\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # donnons une variable d'entrée  à fill pour varier selon le nombre de cas\n\n\n\n\n\n\n\n\nNous pouvons ensuite personnaliser l’apparence de notre carte en utilisant une grammaire cohérente dans ggplot2, par exemple :\n\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # changeons le gradient de couleur\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # mettre du texte dans le graphe\n       subtitle = \"Admin level 3\"\n  )\n\n\n\n\n\n\n\n\nPour les utilisateurs de R qui sont à l’aise avec ggplot2, geom_sf() offre une implémentation simple et directe qui convient aux visualisations cartographiques de base. Pour en savoir plus, lisez la vignette geom_sf() ou le livre ggplot2.\n\n\n28.8.1 Basemaps\n\n\nOpenStreetMap\nNous décrivons ci-dessous comment obtenir un plan de base pour une carte ggplot2 en utilisant les fonctionnalités d’OpenStreetMap. Les méthodes alternatives incluent l’utilisation de ggmap qui nécessite un enregistrement gratuit auprès de Google (détails).\nOpenStreetMap est un projet collaboratif visant à créer une carte du monde librement modifiable. Les données de géolocalisation sous-jacentes (par exemple, l’emplacement des villes, des routes, des caractéristiques naturelles, des aéroports, des écoles, des hôpitaux, des routes, etc.) sont considérées comme le principal résultat du projet.\nTout d’abord, nous chargeons le paquet OpenStreetMap, à partir duquel nous allons obtenir notre carte de base.\nEnsuite, nous créons l’objet map, que nous définissons en utilisant la fonction openmap() du paquet OpenStreetMap (documentation). Nous fournissons les éléments suivants :\n\nupperLeft et lowerRight Deux paires de coordonnées spécifiant les limites du carreau de la carte de base.\n\nDans ce cas, nous avons mis les valeurs max et min des lignes de la linelist, afin que la carte réponde dynamiquement aux données.\n\nzoom = (si null il est déterminé automatiquement)\n\ntype = quel type de carte de base - nous avons listé plusieurs possibilités ici et le code utilise actuellement la première ([1]) “osm”.\n\nmergeTiles = nous avons choisi TRUE pour que les tuiles de base soient toutes fusionnées en une seule.\n\n\n# charger  package\npacman::p_load(OpenStreetMap)\n\n# Ajustez la carte de base par le couple de coordonnées lat/long. Choisir le type de tuile\nmap &lt;- openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\n\nSi nous traçons cette carte de base maintenant, en utilisant autoplot.OpenStreetMap() du paquet OpenStreetMap, vous voyez que les unités sur les axes ne sont pas des coordonnées de latitude/longitude. Il utilise un système de coordonnées différent. Pour afficher correctement les résidences du cas (qui sont stockées en lat/long), cela doit être changé.\n\nautoplot.OpenStreetMap(map)\n\n\n\n\n\n\n\n\nAinsi, nous voulons convertir la carte en latitude/longitude avec la fonction openproj() du paquet OpenStreetMap. Nous fournissons la carte de base map et nous fournissons également le système de référence de coordonnées (CRS) que nous voulons. Nous le faisons en fournissant la chaîne de caractères “proj.4” pour la projection WGS 1984, mais vous pouvez également fournir le CRS d’autres manières. (voir cette page pour mieux comprendre ce qu’est une chaîne proj.4)\n\n# Projection WGS84\nmap_latlon &lt;- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n\nMaintenant, lorsque nous créons le tracé, nous voyons que les axes contiennent des coordonnées de latitude et de longitude. Le système de coordonnées a été converti. Maintenant, nos cas seront tracés correctement s’ils sont superposés !\n\n# la representation graphique d'une carte doit se faire en  utilisant \"autoplot\" afin de pouvoir travailler avec ggplot.\nautoplot.OpenStreetMap(map_latlon)\n\n\n\n\n\n\n\n\nConsultez les tutoriels ici et ici pour plus d’informations.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#cartes-thermiques-de-densité-avec-contours",
    "href": "new_pages/gis.fr.html#cartes-thermiques-de-densité-avec-contours",
    "title": "28  GIS basics",
    "section": "28.9 Cartes thermiques de densité avec contours",
    "text": "28.9 Cartes thermiques de densité avec contours\nNous décrivons ci-dessous comment réaliser une carte thermique de densité des cas, sur une carte de base, en commençant par une liste de lignes (une ligne par cas).\n\nCréer une tuile basemap à partir d’OpenStreetMap, comme décrit ci-dessus.\n\nTracez les cas de linelist en utilisant les colonnes de latitude et de longitude.\n\nConvertir les points en une carte thermique de densité avec stat_density_2d() de ggplot2,\n\nLorsque nous avons une carte de base avec des coordonnées de latitude et de longitude, nous pouvons tracer nos cas par-dessus en utilisant les coordonnées de latitude et de longitude de leur résidence.\nEn s’appuyant sur la fonction autoplot.OpenStreetMap() pour créer la carte de base, les fonctions de ggplot2 s’ajouteront facilement par-dessus, comme le montre geom_point() ci-dessous :\n\n## la representation graphique d'une carte doit se faire en  utilisant \"autoplot\" afin de pouvoir travailler avec ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # commercer avec basemap\n  geom_point(                                       # ajouter des points xy à partir des colonnes lon et lat de la linelist \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # abandonner entièrement la légende\n  labs(x = \"Longitude\",                             # titres et etiquettes\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n\n\n\n\n\n\n\n\nLa carte ci-dessus peut être difficile à interpréter, surtout si les points se chevauchent. Vous pouvez donc tracer une carte de densité en 2d en utilisant la fonction ggplot2 stat_density_2d(). Vous utilisez toujours les coordonnées lat/lon de la linelist, mais une estimation de densité à noyau 2D est effectuée et les résultats sont affichés avec des lignes de contour - comme une carte topographique. Lisez la documentation complète ici.\n\n# commencer par la carte de base\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # ajouter le graphique de densité\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # spécifier l'échelle de couleurs\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # etiquettes\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")\n\n\n\n\n\n\n\n\n\n\nCarte thermique des séries chronologiques\nLa carte thermique de densité ci-dessus montre les cas cumulés. Nous pouvons examiner l’épidémie dans le temps et l’espace en facettant la carte de chaleur en fonction du mois d’apparition des symptômes, tel qu’il est dérivé de la liste des lignes.\nNous commençons dans la linelist, en créant une nouvelle colonne avec l’année et le mois d’apparition des symptômes. La fonction format() de base R change la façon dont une date est affichée. Dans ce cas, nous voulons “YYYY-MM”.\n\n# Extrait mois de l'apparition\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examiner les valeurs \ntable(linelist$date_onset_ym, useNA = \"always\")\n\n\n2014-04 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 \n      2      12      14      36     104     168     193     126      97      75 \n2015-02 2015-03 2015-04    &lt;NA&gt; \n     51      44      28      50 \n\n\nMaintenant, nous introduisons simplement le facettage via ggplot2 à la carte thermique de densité. facet_wrap() est appliqué, en utilisant les nouvelles colonnes comme lignes. Nous avons fixé le nombre de colonnes de facettes à 3 pour plus de clarté.\n\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# commencer avec  basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # ajouter le graphique de densité\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # spécifier l'échelle de couleurs\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # etiquettes\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facetter le graphique par mois-année de début d'activité\n  facet_wrap(~ date_onset_ym, ncol = 4)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#statistiques-spatiales",
    "href": "new_pages/gis.fr.html#statistiques-spatiales",
    "title": "28  GIS basics",
    "section": "28.10 Statistiques spatiales",
    "text": "28.10 Statistiques spatiales\nJusqu’à présent, la plupart de nos discussions ont porté sur la visualisation des données spatiales. Dans certains cas, vous pouvez également être intéressé par l’utilisation des statistiques spatiales pour mesurer la force des relations spatiales des attributs dans vos données. Cette section donne un bref aperçu de certains concepts clés des statistiques spatiales et suggère quelques ressources utiles à explorer si vous souhaitez effectuer des analyses spatiales plus poussées.\n\nLes relations spatiales\nAvant de pouvoir calculer toute statistique spatiale, nous devons spécifier les relations entre les objets de nos données. Il existe de nombreuses façons de conceptualiser les relations spatiales, mais un modèle simple et couramment appliqué est celui de la adjacence - plus précisément, nous nous attendons à une relation géographique entre les zones qui partagent une frontière ou qui sont “voisines” les unes des autres.\nNous pouvons quantifier les relations d’adjencence entre les polygones des régions administratives dans les données sle_adm3 que nous avons utilisées avec le package spdep. Nous allons spécifier une contiguïté queen, ce qui signifie que les voisins possèdent au moins un segment de frontière commune.les voisins possèdent au moins un segment de frontière commune Dans notre cas, avec des polygones irréguliers, la distinction est triviale, mais dans certains cas, le choix entre la reine et la tour peut ne pas etre evident\n\nsle_nb &lt;- spdep::poly2nb(sle_adm3_dat, queen=T) #Extraction de la liste des voisins \nsle_adjmat &lt;- spdep::nb2mat(sle_nb)    # créer une matrice résumant les relations entre voisins\nsle_listw &lt;- spdep::nb2listw(sle_nb)   # créer l'objet listw (liste de poids) -- nous en aurons besoin plus tard\n\nsle_nb\n\nNeighbour list object:\nNumber of regions: 9 \nNumber of nonzero links: 30 \nPercentage nonzero weights: 37.03704 \nAverage number of links: 3.333333 \n\nround(sle_adjmat, digits = 2)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\nattr(,\"call\")\nspdep::nb2mat(neighbours = sle_nb)\n\n\nLa matrice affiché ci-dessus montre les relations entre les 9 régions de nos données sle_adm3. Un score de 0 indique que deux régions ne sont pas voisines, tandis que toute valeur différente de 0 indique une relation de voisinage. Les valeurs de la matrice sont normalisées afin que chaque région ait un poids total par ligne egale à 1.\nUne meilleure façon de faire ressortir ces relations de voisinage est de les reprensenter graphiquement :\n\nplot(sle_adm3_dat$geometry) +                                           # visualiser les limites de la region\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # ajout des relation de voisinage\n\n\n\n\n\n\n\n\nNous avons utilisé une approche d’adjacence pour identifier les polygones voisins ; les voisins que nous avons identifiés sont aussi parfois appelés voisins basés sur la contiguïté. Mais ce n’est qu’une façon de choisir les régions qui sont censées avoir une relation géographique. Les approches alternatives les plus courantes pour identifier les relations géographiques génèrent des voisins basés sur la distance ; brièvement, il s’agit de :\n\nK-plus proches voisins - Sur la base de la distance entre les centroïdes (le centre géographiquement pondéré de chaque région polygonale), sélectionnez les n régions les plus proches comme voisines. Un seuil de proximité de distance maximale peut également être fixé. Dans spdep, vous pouvez utiliser knearneigh() (voir documentation).\nDistance threshold neighbors - Sélectionne les voisins sur la base d’une un seuil de distance definie. Dans spdep, ces relations de voisinage peuvent être identifiées en utilisant dnearneigh() (voir documentation).\n\n\n\nAutocorrélation spatiale\nLa première loi de la géographie de Tobler, souvent citée, stipule que “Tout interagit avec tout, mais deux objets proches ont plus de chance de le faire que deux objets éloignés”. En épidémiologie, cela signifie souvent que la probabilité d’obtenir un résultat sanitaire particulier dans une région donnée est plus liée au resultats des régions voisines qu’à celui des régions éloignées. Ce concept a été formalisé sous le nom d’autocorrélation spatiale - la propriété statistique selon laquelle les objets spatiaux ayant des valeurs similaires sont localisées dans l’espace. Les mesures statistiques de l’autocorrélation spatiale peuvent être utilisées pour quantifier la dépendance spatiale dans vos données, localiser l’endroit où ont trouve des patterns, et identifier les patterns d’autocorrélation spatiale entre des variables distinctes dans vos données. Cette section donne un aperçu de certaines mesures courantes d’autocorrélation spatiale et de la façon de les calculer dans R.\nI de Moran - Il s’agit d’une statistique globale de synthèse de la corrélation entre la valeur d’une variable dans une région et les valeurs de cette même variable dans les régions voisines. La statistique I de Moran est généralement comprise entre -1 et 1. Une valeur de 0 n’indique aucun modèle de corrélation spatiale, tandis que des valeurs plus proches de 1 ou de -1 indiquent une autocorrélation spatiale plus forte (valeurs similaires proches) ou une dispersion spatiale (valeurs dissemblables proches), respectivement.\nPar exemple, nous allons calculer une statistique I de Moran pour quantifier l’autocorrélation spatiale dans les cas d’Ebola que nous avons cartographiés plus tôt (rappelez-vous, il s’agit d’un sous-ensemble de cas provenant du cadre de données de la linelist épidémique simulée). Le paquet spdep possède une fonction, moran.test, qui peut faire ce calcul pour nous :\n\nmoran_i &lt;-spdep::moran.test(sle_adm3_dat$cases,    # vecteur numérique avec la variable d'intérêt\n                            listw=sle_listw)       # listw object résumant les relations de voisinage\n\nmoran_i                                            # print les résultats du test I de Moran\n\n\n    Moran I test under randomisation\n\ndata:  sle_adm3_dat$cases  \nweights: sle_listw    \n\nMoran I statistic standard deviate = 1.7397, p-value = 0.04096\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.23072089       -0.12500000        0.04180906 \n\n\nLa sortie de la fonction moran.test() nous montre une statistique de Moran I de round(moran_i$estimate[1],2). Cela indique la présence d’une autocorrélation spatiale dans nos données - plus précisément, que les régions présentant un nombre similaire de cas d’Ebola sont susceptibles d’être proches les unes des autres. La valeur p fournie par moran.test() est générée par comparaison avec l’espérance sous l’hypothèse nulle d’absence d’autocorrélation spatiale, et peut être utilisée si vous avez besoin de rapporter les résultats d’un test d’hypothèse formel.\nLocal Moran’s I - Nous pouvons décomposer la statistique (globale) de Moran I calculée ci-dessus pour identifier l’autocorrélation spatiale localisée, c’est-à-dire pour identifier des groupes spécifiques dans nos données. Cette statistique, qui est parfois appelée Indicateur local d’association spatiale (LISA), résume l’étendue de l’autocorrélation spatiale autour de chaque région individuelle. Elle peut être utile pour trouver les points “chauds” et “froids” sur la carte.\nPour montrer un exemple, nous pouvons calculer et cartographier le I de Moran local pour les comptes de cas d’Ebola utilisés ci-dessus, avec la fonction local_moran() de spdep :\n\n# calculer le I de Moran local\nlocal_moran &lt;- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable d'interet \n  listw=sle_listw                                  # listw object avec la ponderation de voisinage\n)\n\n# joindre les results  à un jeu de données sf \nsle_adm3_dat&lt;- cbind(sle_adm3_dat, local_moran)    \n\n# cartographier\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nGetis-Ord Gi* - Il s’agit d’une autre statistique couramment utilisée pour l’analyse des points chauds ; en grande partie, la popularité de cette statistique est liée à son utilisation dans l’outil d’analyse des points chauds d’ArcGIS. Elle est basée sur l’hypothèse que, généralement, la différence de valeur d’une variable entre des régions voisines devrait suivre une distribution normale. Elle utilise une approche de type z-score pour identifier les régions qui ont des valeurs significativement plus élevées (point chaud) ou significativement plus basses (point froid) d’une variable spécifiée, par rapport à leurs voisins.\nNous pouvons calculer et cartographier la statistique Gi* en utilisant la fonction localG() de spdep :\n\n# Effectuer une analyse G locale\ngetis_ord &lt;- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# joindre les résultats aux données SF\nsle_adm3_dat$getis_ord &lt;- as.numeric(getis_ord)\n\n# afficher la carte\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nComme vous pouvez le constater, la carte des Getis-Ord Gi* est légèrement différente de la carte des Moran locaux que j’ai produite précédemment. Cela reflète le fait que la méthode utilisée pour calculer ces deux statistiques est légèrement différente ; celle que vous devez utiliser dépend de votre cas d’utilisation spécifique et de la question de recherche qui vous intéresse.\nTest L de Lee - Il s’agit d’un test statistique de corrélation spatiale bivariée. Il vous permet de vérifier si la configuration spatiale d’une variable donnée x est similaire à la configuration spatiale d’une autre variable, y, dont on suppose qu’elle est liée spatialement à x.\nPour donner un exemple, testons si la configuration spatiale des cas d’Ebola de l’épidémie simulée est corrélée à la configuration spatiale de la population. Pour commencer, nous devons avoir une variable population dans nos données sle_adm3. Nous pouvons utiliser la variable total du dataframe sle_adm3_pop que nous avons chargé précédemment.\n\nsle_adm3_dat &lt;- sle_adm3_dat %&gt;% \n  rename(population = total)                          # renommer 'total' en  'population'\n\nNous pouvons rapidement visualiser les configurations spatiales des deux variables côte à côte, pour voir si elles se ressemblent :\n\ntmap_mode(\"plot\")\n\ncases_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arranger en facettes 2x1\n\n\n\n\n\n\n\n\nVisuellement, les modèles semblent dissemblables. Nous pouvons utiliser la fonction lee.test() de spdep pour tester statistiquement si le modèle d’autocorrélation spatiale des deux variables est lié. La statistique L sera proche de 0 s’il n’y a pas de corrélation entre les modèles, proche de 1 s’il y a une forte corrélation positive (c’est-à-dire que les modèles sont similaires), et proche de -1 s’il y a une forte corrélation négative (c’est-à-dire que les modèles sont inverses).\n\nlee_test &lt;- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 à comparer\n  y=sle_adm3_dat$population,     # variable 2 à comparer\n  listw=sle_listw                # listw objet avec les poids des voisins\n)\n\nlee_test\n\n\n    Lee's L statistic randomisation\n\ndata:  sle_adm3_dat$cases ,  sle_adm3_dat$population \nweights: sle_listw  \n\nLee's L statistic standard deviate = -0.87523, p-value = 0.8093\nalternative hypothesis: greater\nsample estimates:\nLee's L statistic       Expectation          Variance \n      -0.14231862       -0.04508674        0.01234158 \n\n\nLe résultat ci-dessus montre que la statistique L de Lee pour nos deux variables était round(lee_test$estimate[1],2), ce qui indique une faible corrélation négative. Cela confirme notre évaluation visuelle selon laquelle le schéma des cas et la population ne sont pas liés l’un à l’autre, et fournit la preuve que le schéma spatial des cas n’est pas strictement le résultat de la densité de population dans les zones à haut risque.\nLa statistique de Lee L peut être utile pour faire ce genre d’inférences sur la relation entre des variables distribuées dans l’espace ; cependant, pour décrire la nature de la relation entre deux variables de manière plus détaillée, ou pour ajuster les facteurs de confusion, des techniques de régression spatiale seront nécessaires. Celles-ci sont décrites brièvement dans la section suivante.\n\n\nRégression spatiale\nVous pouvez souhaiter faire des inférences statistiques sur les relations entre les variables de vos données spatiales. Dans ce cas, il est utile d’envisager des techniques de régression spatiale, c’est-à-dire des approches de la régression qui prennent explicitement en compte l’organisation spatiale des unités dans vos données. Voici quelques raisons pour lesquelles vous pouvez avoir besoin d’envisager des modèles de régression spatiale, plutôt que des modèles de régression standard tels que les GLM :\n\nLes modèles de régression standard supposent que les résidus sont indépendants les uns des autres. En présence d’une forte autocorrélation spatiale, les résidus d’un modèle de régression standard sont susceptibles d’être également autocorrélés dans l’espace, violant ainsi cette hypothèse. Cela peut entraîner des problèmes d’interprétation des résultats du modèle, auquel cas un modèle spatial serait préférable.\nLes modèles de régression supposent aussi généralement que l’effet d’une variable x est constant sur toutes les observations. Dans le cas d’une hétérogénéité spatiale, les effets que nous souhaitons estimer peuvent varier dans l’espace, et nous pouvons être intéressés par la quantification de ces différences. Dans ce cas, les modèles de régression spatiale offrent plus de flexibilité pour estimer et interpréter les effets.\n\nLes détails des approches de régression spatiale dépassent le cadre de ce manuel. Cette section donnera plutôt un aperçu des modèles de régression spatiale les plus courants et de leurs utilisations, et vous renverra à des références qui pourront vous être utiles si vous souhaitez approfondir ce domaine.\nModèles d’erreurs spatiales - Ces modèles supposent que les termes d’erreur entre les unités spatiales sont corrélés, auquel cas les données violeraient les hypothèses d’un modèle MCO standard. Les modèles d’erreur spatiaux sont aussi parfois appelés modèles autorégressifs simultanés (SAR). Ils peuvent être ajustés en utilisant la fonction errorsarlm() du paquet spatialreg (fonctions de régression spatiale qui faisaient autrefois partie de spdep).\nModèles de décalage spatial - Ces modèles supposent que la variable dépendante pour une région i est influencée non seulement par la valeur des variables indépendantes dans i, mais aussi par les valeurs de ces variables dans les régions voisines de i. Comme les modèles à erreurs spatiales, les modèles à décalage spatial sont aussi parfois décrits comme des modèles autorégressifs simultanés (SAR). Ils peuvent être ajustés en utilisant la fonction lagsarlm() du paquet spatialreg.\nLe paquet spdep contient plusieurs tests de diagnostic utiles pour décider entre les modèles MCO standard, les modèles à décalage spatial et les modèles à erreur spatiale. Ces tests, appelés Diagnostics du multiplicateur de Lagrange, peuvent être utilisés pour identifier le type de dépendance spatiale de vos données et choisir le modèle le plus approprié. La fonction lm.LMtests() peut être utilisée pour calculer tous les tests du multiplicateur de Lagrange. Anselin (1988) fournit également un diagramme de flux utile pour décider du modèle de régression spatiale à utiliser en fonction des résultats des tests du multiplicateur de Lagrange :\n\n\n\n\n\n\n\n\n\nModèles hiérarchiques bayésiens - Les approches bayésiennes sont couramment utilisées pour certaines applications de l’analyse spatiale, le plus souvent pour la cartographie des maladies. Elles sont préférables dans les cas où les données de cas sont peu distribuées (par exemple, dans le cas d’un résultat rare) ou statistiquement “bruyantes”, car elles peuvent être utilisées pour générer des estimations “lissées” du risque de maladie en tenant compte du processus spatial latent sous-jacent. Cela peut améliorer la qualité des estimations. Elles permettent également à l’enquêteur de préspécifier (via le choix de l’antériorité) les modèles de corrélation spatiale complexes qui peuvent exister dans les données, ce qui peut rendre compte de la variation spatialement dépendante et indépendante des variables indépendantes et dépendantes. Dans R, les modèles hiérarchiques bayésiens peuvent être ajustés à l’aide du paquet CARbayes (voir vignette) ou de R-INLA (voir site web et manuel). R peut également être utilisé pour appeler un logiciel externe qui effectue des estimations bayésiennes, comme JAGS ou WinBUGS.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.fr.html#resources",
    "href": "new_pages/gis.fr.html#resources",
    "title": "28  GIS basics",
    "section": "28.11 Resources",
    "text": "28.11 Resources\n\nR Simple Features and sf package vignette\nR tmap package vignette\nggmap: Spatial Visualization with ggplot2\nIntro to making maps with R, overview of different packages\nSpatial Data in R (EarthLab course)\nApplied Spatial Data Analysis in R textbook\nSpatialEpiApp - a Shiny app that is downloadable as an R package, allowing you to provide your own data and conduct mapping, cluster analysis, and spatial statistics.\nAn Introduction to Spatial Econometrics in R workshop",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>GIS basics</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html",
    "href": "new_pages/tables_presentation.fr.html",
    "title": "29  Présenter avec des tables",
    "section": "",
    "text": "29.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html#préparation",
    "href": "new_pages/tables_presentation.fr.html#préparation",
    "title": "29  Présenter avec des tables",
    "section": "",
    "text": "Charger les packages\nInstaller et charger flextable. Dans ce manuel, nous mettons l’accent sur la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser . Vous pouvez également charger des “packages” avec library() à partir de R base. Voir la page sur Bases de R pour plus d’informations sur les “packages” R.\n\npacman::p_load(\n  rio,            # importer/exporter\n  here,           # chemin vers les fichiers\n  flextable,      # creer des tables HTML  \n  officer,        # fonctions d'aide pour les tables\n  tidyverse)      # data management, resume, et visualisation\n\n\n\nImporter des données\nPour commencer, nous importons la liste linéaire (“linelist”) nettoyée des cas d’une épidémie d’Ebola qui a été simulée. Si vous voulez suivre en travaillant sur la base, cliquez pour télécharger la version “clean”  (en fichier .rds). Importez les données avec la fonction import() du “package” rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# importer la liste lineaire\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la liste linéaire sont affichées ci-dessous.\n\n\n\n\n\n\n\n\nPréparer la table\nComme expliqué plus haut, avant de commencer à utiliser flextable, vous devez d’abord créer la table que vous voulez présenter sous forme de tableau de données. Consultez la page sur les Tables descriptives et les Données pivotantes pour apprendre à créer un tableau de données à l’aide de “packages” tels que janitor et dplyr. Vous devez disposer le contenu en lignes et en colonnes comme vous voulez qu’il soit affiché. C’est à dire on part de notre base de données principales, on lui applique les modifications et opérations nécessaires pour synthétiser l’information que l’on veut présenter dans notre table finale et ce résultat sera enregistré dans un tableu de données. Ensuite, ce tableau de données sera soumis à flextable pour l’afficher avec la mise en forme voulue ajoutant des couleurs, des en-têtes, des polices, etc.\nVoici un exemple tiré de la page Tables descriptives sur la conversion de la “liste linéaire des cas” en un tableau de données qui résume/synthétise l’issue finale des patients et les valeurs CT (seuil de cycle dans un test de détection du virus par PCR) par hôpital, avec une ligne de totaux en bas. Le résultat est enregistré sous le nom de table.\n\ntable &lt;- linelist %&gt;% \n  \n  # Obtenez les valeurs résumees par hôpital et issue finale\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # Grouper les donnees selon ces deux variables\n  summarise(                                           # Creer un nouveau résumé des variables d'intérêt \n    N = n(),                                            # Nombre de lignes par  groupe \"hospital-outcome\"     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # Valeur CT mediane  par groupe\n  \n  # ajouter le total\n  ############\n  bind_rows(                                           # Liez le tableau précédent avec ce mini-tableau de totaux\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Grouper avec var \"outcome\" uniquement et non par  \"hospital\"    \n      summarise(\n        N = n(),                                       # Nombre de lignes pour l'ensemble des données    \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # Valeur CT mediane pour l'ensemble des données    \n  \n  # Modifier en format long-large\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivoter du format long au format large\n    values_from = c(ct_value, N),                       # nouvelles valeurs sont crees depuis les vars \"ct\" et \"count\"\n    names_from = outcome) %&gt;%                           # nouveaux noms de colonne crees depuis var \"outcomes\"\n  mutate(                                              # Creer de nouvelles colonnes\n    N_Known = N_Death + N_Recover,                               # nombre de cas avec l'issue finale connue\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # pourcentage de cas decedes (1 decimale)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # pourcentage de cas gueris (1 decimale)\n  select(                                              # Re-ordonner l'apparition des colonnes\n    hospital, N_Known,                                   # Colonnes d'Intro\n    N_Recover, Pct_Recover, ct_value_Recover,            # Colonnes concernant les gueris\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Colonnes concernant les deces\n  arrange(N_Known)                                    # Trier les lignes de façon croissante (Total de la ligne en dernier)\n\ntable  # afficher la table\n\n# A tibble: 7 × 8\n# Groups:   hospital [7]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Missing          1125       514 45.7%                     21     611 54.3%    \n6 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n7 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html#premiers-pas-avec-flextable",
    "href": "new_pages/tables_presentation.fr.html#premiers-pas-avec-flextable",
    "title": "29  Présenter avec des tables",
    "section": "29.2 Premiers pas avec flextable",
    "text": "29.2 Premiers pas avec flextable\n\nCréer un objet flextable\nPour créer et gérer les objets flextable, nous passons d’abord le tableau de données avec les informqtions que nous voulons présenter par la fonction flextable() et nous enregistrons le résultat sous le nom de my_table.\n\nmy_table &lt;- flextable(table) \nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nAprès avoir fait cela, nous pouvons progressivement faire passer l’objet my_table par plus de fonctions de formatage flextable.\nDans cette page, pour des raisons de clarté, nous sauvegarderons la table à des étapes intermédiaires sous le nom de my_table, en ajoutant des fonctions flextable étape par étape. Si vous voulez voir tout le code du début à la fin écrit en un seul bloc, visitez la section Tout le code ensemble ci-dessous.\nLa syntaxe générale de chaque ligne de code flextable est la suivante :\n\nfunction(table, i = X, j = X, part = \"X\"), where:\n\nLa “fonction” peut être l’une des nombreuses fonctions différentes, telles que width() pour déterminer la largeur des colonnes, bg() pour définir les couleurs d’arrière-plan, align() pour définir si le texte est aligné au centre/à droite/à gauche, et ainsi de suite.\ntable = est le nom du tableau de données, mais il n’est pas nécessaire de l’indiquer si le tableau de données est intégré à la fonction.\npart = indique la partie de la table à laquelle la fonction appelée sera appliqué. Par ex: “header” pour l’entête de la table, “body” pour le corps de la table ou “all” pour toutes les parties de la table.\ni = spécifie la ligne à laquelle appliquer la fonction, où ‘X’ est le numéro de la ligne. S’il s’agit de plusieurs lignes, par exemple de la première à la troisième ligne, on peut spécifier : i = c(1:3). Notez que si ‘body’ est sélectionné, la première ligne commence sous la section d’en-tête.\nj = spécifie la colonne à laquelle appliquer la fonction, où ‘x’ est le numéro ou le nom de la colonne. Si plusieurs colonnes, par exemple la cinquième et la sixième, on peut spécifier : `j = c(5,6).\n\n\nVous pouvez trouver la liste complète des fonctions de formatage flextable ici ou consulter la documentation en tapant ?flextable.\n\n\nLargeur de la colonne\nNous pouvons utiliser la fonction autofit(), qui permet d’étirer et de réajuster la table de façon esthétique de sorte que chaque cellule ne comporte qu’une seule ligne de texte. La fonction qflextable() est un raccourci pratique pour flextable() et autofit().\n\nmy_table %&gt;% autofit()\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nCependant, cela n’est pas toujours approprié, surtout si les cellules contiennent des valeurs très longues, ce qui signifie que le tableau risque de ne pas tenir sur la page.\nÀ la place, nous pouvons spécifier des largeurs avec la fonction width(). Il faut parfois essayer plusieurs valeurs pour savoir laquelle correspond le mieux. Dans l’exemple ci-dessous, nous spécifions des largeurs différentes pour la colonne 1, la colonne 2 et les colonnes 4 à 8.\n\nmy_table &lt;- my_table %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nEn-têtes de colonnes\nNous voulons des en-têtes plus clairs pour faciliter l’interprétation du contenu du tableau.\nPour cette table, nous voudrons ajouter une deuxième couche d’en-tête afin que les colonnes couvrant les mêmes sous-groupes puissent être regroupées. Nous faisons cela avec la fonction add_header_row() avec top = TRUE. Nous précisons le nouveau nom de chaque colonne avec l’option values =, en laissant des valeurs vides \"\" pour les colonnes que nous savons que nous fusionnerons plus tard.\nNous renommons également les noms des en-têtes dans le désormais deuxième en-tête dans une commande séparée en utilisant set_header_labels().\nEnfin, pour “regrouper” certains en-têtes de colonnes dans l’en-tête supérieur, nous utilisons merge_at() pour fusionner les en-têtes de colonnes dans la ligne d’en-tête supérieure.\n\nmy_table &lt;- my_table %&gt;% \n  \n  add_header_row(\n    top = TRUE,                # Nouvel en-tête placé au-dessus de la rangée d'en-tête existante\n    values = c(\"Hospital\",     # Valeurs d'en-tête pour chaque colonne ci-dessous\n               \"Total cases with known outcome\", \n               \"Recovered\",    # Celui ci servira d'en-tête de niveau supérieur pour cette colonne et les deux suivantes\n               \"\",\n               \"\",\n               \"Died\",         # Celui ci servira d'en-tête de niveau supérieur pour cette colonne et les deux suivantes\n               \"\",             # Laisser vide comme ce sera fusionné avec \"Died\".\n               \"\")) %&gt;% \n    \n  set_header_labels(         # Renommer les colonnes de la ligne d'en-tête originale\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # Fusionner horizontalement les colonnes 3 à 5 dans une nouvelle ligne d'en-tête\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Fusionnez horizontalement les colonnes 6 à 8 dans une nouvelle ligne d'en-tête.\n\nmy_table  # afficher la table résultante\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nBordures et arrière-plan\nVous pouvez ajuster les bordures, les lignes internes, etc. avec diverses fonctions flextable. Il est souvent plus facile de commencer par supprimer toutes les bordures existantes avec border_remove().\nEnsuite, vous pouvez appliquer des thèmes de bordure par défaut en passant la table à theme_box(), theme_booktabs(), ou theme_alafoli().\nVous pouvez ajouter des lignes verticales et horizontales avec une variété de fonctions. hline() et vline() ajoutent des lignes à une ligne ou une colonne spécifiée, respectivement. Dans chacune d’elles, vous devez spécifier dans quelle partie de la table vous voulez le rajouter en précisant part = comme étant soit “all”,“body” ou “header”. Pour les lignes verticales, spécifiez la colonne à l’argument j =, et pour les lignes horizontales la ligne à i =. D’autres fonctions comme vline_right(), vline_left(), hline_top(), et hline_bottom() ajoutent des lignes aux bords externes de la table seulement.\nDans toutes ces fonctions, le style de ligne lui-même doit être spécifié par border = et doit être le résultat d’une commande séparée utilisant la fonction fp_border() du “package” officer. Cette fonction vous aide à définir la largeur et la couleur de la ligne. Vous pouvez la définir avant d’appeler les commandes de table, comme indiqué ci-dessous.\n\n# définir le style de la ligne de bordure\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# ajouter des lignes de bordure au tableau\nmy_table &lt;- my_table %&gt;% \n\n  # Enlever toutes les bordures existantes\n  border_remove() %&gt;%  \n  \n  # ajouter des lignes horizontales via un thème prédéterminé\n  theme_booktabs() %&gt;% \n  \n  # ajouter des lignes verticales pour séparer les sections \"Recovered\" et \"Died\"\n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # a la colonne 2 \n  vline(part = \"all\", j = 5, border = border_style)       # a la colonne 5\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nPolice et alignement\nNous alignons au centre toutes les colonnes, sauf la colonne la plus à gauche, avec les noms des hôpitaux, en utilisant la fonction align() de flextable.\n\nmy_table &lt;- my_table %&gt;% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nDe plus, nous pouvons augmenter la taille de la police de l’en-tête et la mettre en gras. Nous pouvons également mettre en gras la ligne du total.\n\nmy_table &lt;-  my_table %&gt;%  \n  fontsize(i = 1, size = 12, part = \"header\") %&gt;%   # ajuster la taille de la police de l'en-tête\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;%     # ajuster le caractère en gras de l'en-tête\n  bold(i = 7, bold = TRUE, part = \"body\")           # ajuster les caractères en gras de la ligne totale (ligne 7 du corps de la table)\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nPour aérer la table, nous pouvons nous assurer que les colonnes de proportion n’affichent qu’une seule décimale en utilisant la fonction colformat_num(). Notez que cela aurait également pu être fait au stade de la gestion des données dans le tableau de données créé et fourni à flextable() avec la fonction round().\n\nmy_table &lt;- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nFusionner des cellules\nTout comme nous fusionnons les cellules horizontalement dans la ligne d’en-tête, nous pouvons également fusionner les cellules verticalement en utilisant merge_at() et en spécifiant les lignes (i) et les colonnes (j). Ici, nous fusionnons les valeurs “Hospital” et “Total cases with known outcome” verticalement pour leur donner plus d’espace.\n\nmy_table &lt;- my_table %&gt;% \n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nCouleur d’arrière-plan\nPour distinguer le contenu du corps de la table des en-têtes, nous pouvons ajouter une mise en forme supplémentaire, par exemple en modifiant la couleur de l’arrière-plan. Dans cet exemple, nous changeons le corps du tableau en gris.\n\nmy_table &lt;- my_table %&gt;% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html#mise-en-forme-conditionnelle",
    "href": "new_pages/tables_presentation.fr.html#mise-en-forme-conditionnelle",
    "title": "29  Présenter avec des tables",
    "section": "29.3 Mise en forme conditionnelle",
    "text": "29.3 Mise en forme conditionnelle\nL’un des points forts de flextable est qu’il nous permet de faire des mises en forme de notre table finale selon des conditions que nous aurons fixées selon l’information que nous voulons souligner. Nous pouvons ainsi donc mettre en évidence toutes les valeurs d’une colonne qui répondent à une certaine condition. Par exemple nous voulons mettre l’accent sur les cas où plus de 55 % des cas sont décédés. Il suffit de mettre les critères dans l’argument i = ou j =, précédé d’un tilde ~. Attention: la condition doit être précisée en utilisant le nom de la colonne (variable) dans le tableau de donnée fourni à flextable() non en utilisant le nom de la colonne qui s’affiche dans l’en-tête de la table finale.\n\nmy_table %&gt;% \n  bg(j = 7, i = ~ Pct_Death &gt;= 55, part = \"body\", bg = \"red\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nOu bien, nous pouvons mettre en évidence la ligne entière répondant à un certain critère, tel qu’un hôpital d’intérêt. Pour ce faire, il suffit de supprimer la spécification de la colonne (j) afin que les critères s’appliquent à toutes les colonnes.\n\nmy_table %&gt;% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html#tbl_pres_all",
    "href": "new_pages/tables_presentation.fr.html#tbl_pres_all",
    "title": "29  Présenter avec des tables",
    "section": "29.4 L’ensemble du code",
    "text": "29.4 L’ensemble du code\nCi-dessous, nous regroupons tout le code des sections précédentes en un seul bloc comme vous serez amené à le faire.\n\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # importer/exporter\n  here,           # chemin vers les fichiers\n  flextable,      # creer des tables HTML \n  officer,        # fonctions d'aide pour les tables\n  tidyverse)      # data management, resume, et visualisation\n\ntable &lt;- linelist %&gt;% \n\n  # Obtenez les valeurs résumees par hôpital et issue finale\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # Grouper les donnees selon ces deux variables\n  summarise(                                           # Creer un nouveau résumé des variables d'intérêt\n    N = n(),                                            # Nombre de lignes par  groupe \"hospital-outcome\"\n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # Valeur CT mediane  par groupe\n  \n  # add totals\n  ############\n  bind_rows(                                           # Liez le tableau précédent avec ce mini-tableau de totaux\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # # Grouper avec var \"outcome\" uniquement et non par  \"hospital\"    \n      summarise(\n        N = n(),                                       # Nombre de lignes pour l'ensemble des données      \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # Valeur CT mediane pour l'ensemble des données\n  \n  # Passer du format long de la table au format large\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivoter du format long au format large\n    values_from = c(ct_value, N),                       # nouvelles valeurs sont crees depuis les vars \"ct\" et \"count\"\n    names_from = outcome) %&gt;%                           # nouveaux noms de colonne crees depuis var \"outcomes\"\n  mutate(                                              # Creer de nouvelles colonnes\n    N_Known = N_Death + N_Recover,                               # nombre de cas avec l'issue finale connue\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # pourcentage de cas decedes (1 decimale)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # pourcentage de cas gueris (1 decimale)\n  select(                                              # Re-ordonner l'apparition des colonnes\n    hospital, N_Known,                                   # Colonnes d'Intro\n    N_Recover, Pct_Recover, ct_value_Recover,            # Colonnes concernant les gueris\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Colonnes concernant les deces\n  arrange(N_Known) %&gt;%                                 # Trier les lignes de façon croissante (Total de la ligne en dernier)\n\n  # formatting\n  ############\n  flextable() %&gt;%              # la table est pippee depuis les codes ci-dessus\n  add_header_row(\n    top = TRUE,                # Nouvel en-tête placé au-dessus de la rangée d'en-tête existante\n    values = c(\"Hospital\",     # Valeurs d'en-tête pour chaque colonne ci-dessous\n               \"Total cases with known outcome\", \n               \"Recovered\",    # Celui ci servira d'en-tête de niveau supérieur pour cette colonne\n               \"\",\n               \"\",\n               \"Died\",         # Celui ci servira d'en-tête de niveau supérieur pour cette colonne\n               \"\",             # Laisser vide comme ce sera fusionné avec \"Died\"\n               \"\")) %&gt;% \n    set_header_labels(         # Renommer les colonnes de la ligne d'en-tête originale\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # Fusionner horizontalement les colonnes 3 à 5 dans une nouvelle ligne d'en-tête\n  merge_at(i = 1, j = 6:8, part = \"header\") %&gt;%  \n  border_remove() %&gt;%  \n  theme_booktabs() %&gt;% \n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style) %&gt;%   # at column 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\") %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1) %&gt;% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %&gt;% \n  bg(., part = \"body\", bg = \"gray95\")  %&gt;% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %&gt;% \n  colformat_num(., j = c(4,7), digits = 1) %&gt;%\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;% \n  bold(i = 7, bold = TRUE, part = \"body\")\n\n`summarise()` has grouped output by 'hospital'. You can override using the\n`.groups` argument.\n\ntable\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html#sauvegarder-votre-table",
    "href": "new_pages/tables_presentation.fr.html#sauvegarder-votre-table",
    "title": "29  Présenter avec des tables",
    "section": "29.5 Sauvegarder votre table",
    "text": "29.5 Sauvegarder votre table\nIl existe différentes façons d’intégrer la table finale dans votre production.\n\nSauvegarder une seule table\nVous pouvez exporter les tableaux vers des fichiers Word, PowerPoint ou HTML ou sous format image (PNG). Pour ce faire, utilisez l’une des fonctions suivantes :\n\nsave_as_docx()\n\nsave_as_pptx()\n\nsave_as_image()\n\nsave_as_html()\n\nPar exemple, ci-dessous, nous enregistrons notre table comme un document Word. Notez la syntaxe du premier argument - vous pouvez simplement fournir le nom de votre objet flextable, par exemple my_table, ou vous pouvez lui donner un “nom” comme indiqué ci-dessous (le nom est “my table”). Si vous lui donnez un nom, celui-ci apparaîtra comme le titre de la table dans le document Word. Nous fournissons également le code pour sauvegarder la table sous format image PNG.\n\n# Modifiez le tableau \"my table\" en fonction des besoins pour le titre du tableau.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\n\nNotez que les “packages” webshot ou webshot2 sont nécessaires pour sauvegarder un flextable comme une image. Les images peuvent sortir avec des arrière-plans transparents.\nSi vous voulez voir une version “en direct” de la sortie du flextable dans le format de document prévu, utilisez print() et spécifiez un des éléments ci-dessous pour preview =. Le document s’ouvrira “en direct” sur votre ordinateur dans le logiciel spécifié, mais ne sera pas sauvegardé. Cela peut être utile pour vérifier si le tableau tient dans une page/diapositive ou pour le copier rapidement dans un autre document. Vous pouvez utiliser la méthode d’impression avec l’argument preview défini à “pptx” ou “docx”.\n\nprint(my_table, preview = \"docx\") # Exemple de document Word\nprint(my_table, preview = \"pptx\") # Exemple de document Powerpoint\n\n\n\nIntégrer la table dans R markdown\nCette table peut être intégrée dans un document automatisé, une sortie R markdown, si l’objet table est appelé dans le chunk R markdown. Cela signifie que la table peut être mise à jour dans le cadre d’un rapport où les données sont susceptibles de changer, de sorte que les chiffres peuvent être actualisés.\nVoir les détails dans la page Rapports avec R Markdown de ce manuel.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.fr.html#ressources",
    "href": "new_pages/tables_presentation.fr.html#ressources",
    "title": "29  Présenter avec des tables",
    "section": "29.6 Ressources",
    "text": "29.6 Ressources\nLa documentation compléte sur flextable est ici: https://ardata-fr.github.io/flextable-book/ Le lien Github est ici\nUn guide sur toutes les fonctions flextable peût être trouvée ici\nVous pouvez accéder à une galerie de beaux exemples de tables flextable avec code ici",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Présenter avec des tables</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html",
    "href": "new_pages/ggplot_basics.fr.html",
    "title": "30  Les bases de ggplot",
    "section": "",
    "text": "30.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#préparation",
    "href": "new_pages/ggplot_basics.fr.html#préparation",
    "title": "30  Les bases de ggplot",
    "section": "",
    "text": "Charger les extensions (“packages”)\nCe chunk de code montre le chargement des “packages” nécessaires aux analyses. Dans ce manuel, nous souligons la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser. On peut également charger des “packages” avec library() à partir de R base. Voir la page sur Bases de R pour plus d’informations sur les “packages” R.\n\npacman::p_load(\n  rio,            # importer/exporter \n  here,           # localiser des fichiers\n  stringr,         # travailler avec des caractères \n  janitor,\n  ggforce,\n  tidyverse      # inclut ggplot2 et d'autres extensions de data management\n)\n\n\n\nImporter des données\nPour commencer, nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre en travaillant sur le jeu de données, cliquez pour télécharger la version “clean”  (en fichier .rds). Importez les données avec la fonction import() du “package” rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la liste linéaire sont affichées ci-dessous. Nous allons nous concentrer sur les variables continues age, wt_kg (le poids en kilos), ct_blood (valeurs CT), et days_onset_hosp (différence entre la date de début de symptômes et l’hospitalisation).\n\n\n\n\n\n\n\n\nNettoyage général\nLorsque nous préparons des données pour les visualiser, il est préférable de faire en sorte qu’elles respectent autant que possible les normes pour des données bien rangées. Les pages de ce manuel consacrées à la gestion des données, telles que Nettoyage des données et fonctions de base, expliquent comment y parvenir.\nEn préparant les données pour la visualisation, nous pouvons avoir recours à certaines pratiques simples qui pourraient améliorer le contenu des données pour faciliter et rendre pratique leur représentation. Toutefois cela n’équivaut pas nécessairement à une meilleure manipulation des données. Par exemple :\n\nRemplacer les valeurs manquantes NA dans une colonne de caractères par la chaîne de caractères “Inconnu”.\n\nEnvisager de convertir une colonne en classe facteur pour que leurs valeurs aient des niveaux ordinaux prescrits.\n\nNettoyer certaines colonnes de manière à ce que leurs valeurs (qui étaient codées de façon à être maniables) avec des caractères spéciaux comme des “underscores” (tirets bas), etc. soient transformées en texte normal ou en majuscules (voir Caractères et chaînes de caractères).\n\nVoici quelques exemples concrets de ce genre de pratiques :\n\n#creer une version d'affichage des colonnes avec des noms plus pratiques/maniables\nlinelist &lt;- linelist %&gt;%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m à Male \n                            gender == \"f\" ~ \"Female\",      # f à Female,\n                            is.na(gender) ~ \"Unknown\"),    # NA à Unknown\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # remplacer les valeurs NA de la variable \"outcome\" par \"Unknown\" (\"Inconnu\").\n  )\n\n\n\nTransformation large-long\nEn ce qui concerne la structure des données, pour ggplot2, nous voulons souvent faire pivoter nos données dans des formats longs. Pour en savoir plus, consultez la page Pivoter les données.\n\n\n\n\n\n\n\n\n\nPar exemple, supposons que nous voulons visualiser des données qui sont dans un format “large”, comme pour chaque cas dans la linelist et leurs symptômes. Ci-dessous, nous créons une mini-linelist appelée symptoms_data qui ne contient que les colonnes case_id et les différentes variables des symptômes.\n\nsymptoms_data &lt;- linelist %&gt;% \n  select(c(case_id, fever, chills, cough, aches, vomit))\n\nVoici à quoi ressemblent les 50 premières lignes de cette mini-linelist - voyez comment elles sont présentées en format “large” avec chaque symptôme en tant que colonne :\n\n\n\n\n\n\nSi nous voulions représenter graphiquement le nombre de cas présentant des symptômes spécifiques, nous sommes limités par le fait que chaque symptôme est une colonne spécifique. Cependant, nous pouvons restructurer (“pivoter”) les colonnes de symptômes dans un format plus long comme ceci :\n\nsymptoms_data_long &lt;- symptoms_data %&gt;%    # commencer avec la mini-linelist appelée symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivoter toutes les colonnes à l'exception de case_id (on veut regrouper les colonnes avec les symptômes)\n    names_to = \"symptom_name\",             # assigner un nom à la nouvelle colonne qui va contenir les différents symptômes regroupés \n    values_to = \"symptom_is_present\") %&gt;%  # assigner un nom à la nouvelle colonne qui va contenir les valeurs des différents symptômes regroupés (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convertir les valeurs NA en \"unknown\" (inconnu)\n\nVoici les 50 premières lignes. Notez que chaque cas a désormais 5 lignes - une pour chaque symptôme possible. Les nouvelles colonnes symptom_name et symptom_is_present sont le résultat de la restructuration (ou “pivot”). Il faut cependant retenir que ce format peut ne pas être très utile pour d’autres opérations, mais qu’il est utile pour la représentation des données.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#bases-de-ggplot",
    "href": "new_pages/ggplot_basics.fr.html#bases-de-ggplot",
    "title": "30  Les bases de ggplot",
    "section": "30.2 Bases de ggplot",
    "text": "30.2 Bases de ggplot\n“Grammaire des graphiques” - ggplot2\nConstuire/générer des graphiques avec ggplot2 est basé sur “l’ajout” de couches de graphique et d’éléments de conception/représentation les uns sur les autres, chaque commande étant ajoutée aux précédentes avec un symbole “plus” (+). Le résultat est un ensemble d’objets graphiques multicouche qui peut être enregistré, modifié, imprimé, exporté, etc.\nLes objets ggplot peuvent être très complexes, mais l’ordre de base des couches ressemble généralement à ceci :\n\nCommencez par la commande de base ggplot() - cela “ouvre” le ggplot et permet d’ajouter les fonctions suivantes avec +. Généralement, le jeu de données à partir duquel on veut générer des graphiques est également spécifié comme argument dans cette commande.\n\nAjouter des couches “geom” - ces fonctions sont des éléments de représentation graphique qui permettent de visualiser les données comme des formes géométriques (geoms), par exemple comme un graphique à barres, un graphique linéaire, un nuage de points, un histogramme (ou une combinaison des différentes formes!). Ces fonctions commencent toutes par le préfixe geom_.\n\nAjoutez des éléments de conception au graphique tels que les noms des axes, le titre, les polices, les tailles, les schémas de couleurs, les légendes ou la rotation des axes.\n\nUn exemple simple de code fictif permettant de dessiner un graphique avec ggplot2 est le suivant. Nous allons expliquer chaque composante dans les sections ci-dessous.\n\n# représenter les données dans my_data comme des points coloriés en rouge\nggplot(data = my_data)+                   # utiliser le jeu de données \"my_data\"\n  geom_point(                             # ajouter une couche de points (dots)\n    mapping = aes(x = col1, y = col2),    # préciser quelles données de my_data nous voulons représenter sous forme de points en donnant les coordonnées précises des points pour chaque axe\n    color = \"red\")+                       # autres spécifications pour le geom\n  labs()+                                 # ici on ajoute les titres, noms des axes, etc.\n  theme()                                 # ici on ajuste les couleurs, les polices, les tailles, etc. pour les éléments du graphique qui ne dépende pas des données (axes, titres, etc.)",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#ggplot",
    "href": "new_pages/ggplot_basics.fr.html#ggplot",
    "title": "30  Les bases de ggplot",
    "section": "30.3 ggplot()",
    "text": "30.3 ggplot()\nLa commande initiale de tout graphique ggplot2 est ggplot(). Cette commande crée simplement un cadre blanc qui représente la base de l’objet graphique et sur lequel on peut ajouter des couches. Elle “ouvre” la voie à l’ajout de couches supplémentaires avec le symbole +.\nGénéralement, la commande ggplot() inclut l’argument data = pour le graphique. Ceci permet de définir le jeu de données qui sera utilisé par défaut pour les couches suivantes du graphique.\nCette commande se terminera par un + après la fermeture des parenthèses. Cela laisse la commande “ouverte”. Les fonctions ne s’exécuteront et le graphique n’apparaîtra que si la commande complète inclut une couche finale sans un + à la fin. Cela indique qu’on ne veut plus rajouter d’éléments de représentation graphique et que le graphique final peut être affiché.\n\n# Ceci dessine juste un cadre blanc qui est la base de l'objet graphique\nggplot(data = linelist)",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#geoms",
    "href": "new_pages/ggplot_basics.fr.html#geoms",
    "title": "30  Les bases de ggplot",
    "section": "30.4 Geoms",
    "text": "30.4 Geoms\nUn cadre blanc (la base de l’objet graphique) n’est certainement pas suffisant - nous devons créer des premiers éléments du graphique qui définissent les formes géométriques du graphique à partir de nos données (par exemple, des diagrammes en barres, des histogrammes, des nuages de points, des diagrammes en boîte).\nCeci est fait en ajoutant des couches “geoms” à la commande initiale ggplot(). Il existe de nombreuses fonctions ggplot2 qui créent des “geoms”. Chacune de ces fonctions commence par “geom_”, nous les appellerons donc génériquement geom_XXXX(). Il y a plus de 40 “geoms” dans ggplot2 et beaucoup d’autres créés par des utilisateurs. Vous pouvez les voir sur la galerie ggplot2. Certains parmi les “geoms” les plus utilisés sont listés ci-dessous :\n\nHistogrammes - geom_histogram()\n\nDiagrammes en barres - geom_bar() ou geom_col() (voir la section “Diagrammes en barres”)\n\nLes diagrammes en boîte - geom_boxplot().\n\nLes nuages de points (par exemple les diagrammes de dispersion) - geom_point().\n\nGraphiques linéaires - geom_line() ou geom_path().\n\nLignes de tendance - geom_smooth().\n\nDans un graphique, on peut afficher un ou plusieurs “geom”. Chacun d’entre eux est ajouté aux commandes ggplot2 précédentes avec un +, et ils sont représentés séquentiellement de sorte que les “geom” les plus récents soient tracés au-dessus des précédents.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#ggplot_basics_mapping",
    "href": "new_pages/ggplot_basics.fr.html#ggplot_basics_mapping",
    "title": "30  Les bases de ggplot",
    "section": "30.5 “Mappage” ou comment faire correspondre les données au graphique",
    "text": "30.5 “Mappage” ou comment faire correspondre les données au graphique\nLa plupart des fonctions “geom” doivent savoir les variables précises du jeu de données qu’elles doivent utiliser pour créer leurs formes. Nous devons donc leur indiquer comment mapper (assigner) ces variables aux attributs du graphique tels que les axes (quelle variable sera représentée sur quel axe), les couleurs des formes (quelle modalité de quelle variable représenter en telle ou telle couleur), les tailles des formes, etc. Pour la plupart des “geom”, les composantes essentielles qui doivent être mises en correspondance avec les colonnes des données sont l’axe des x et (si nécessaire) celui des y.\nOn parle ainsi de “mappage” qui n’est dans ce cadre rien d’autre qu’une mise en relation entre un attribut graphique du “geom” et une variable du jeu de données utilisée pour faire la représentation graphique.\nCe “mappage” (correspondance/assignation) se fait avec l’argument mapping =. Les “mappages” que nous fournissons à l’argument mapping doivent être enveloppés dans la fonction aes(), donc nous écririons quelque chose comme mapping = aes(x = col1, y = col2), comme montré ci-dessous.\nCi-dessous, dans la commande ggplot(), les données sont définies comme la liste des cas linelist. Dans l’argument mapping = aes(), la colonne age est mise en correspondance avec l’axe des x, et la colonne wt_kg est mise en correspondance avec l’axe des y.\nAprès un +, les commandes de représentation graphique continuent. Une forme est créée avec la fonction “geom” geom_point(). Ce “geom” hérite des “mappages” de la commande ggplot() ci-dessus - il connaît les affectations axe-colonne et procède à la visualisation de ces relations sous forme de points sur la base du graphique (le cadre blanc dessiné avec la première fonction).\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\n\n\n\n\n\n\n\n\nComme autre exemple, les commandes suivantes utilisent les mêmes données, un “mappage” légèrement différent, et un “geom” différent. La fonction geom_histogram() ne nécessite qu’une colonne mappée sur l’axe des x, puisque l’axe des y est généré automatiquement (représente le comptage de chaque modalité fait automatiquement par la fonction).\n\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nAttributs (esthétiques) du graphique\nDans le jargon de ggplot, “l’esthétique” d’un graphique a une signification assez spécifique. Il s’agit d’une propriété visuelle des données représentées. Notons que le terme “esthétique” fait ici référence aux données de variables “mappées” dans les “geoms”/formes - et non à l’affichage des éléments environnants du graphique qui ne dépendent pas des données tel que les titres, les noms des axes, la couleur de fond (qu’on pourrait associer au mot “esthétique” en français courant). Dans ggplot, ces éléments d’affichage non reliés aux données sont appelés “thèmes” et sont déterminés par une commande theme() (voir cette section).\nPar conséquent, les caractéristiques esthétiques/attributs du graphique peuvent concerner les couleurs, les tailles, la transparence, le placement, etc. des données représentées. Tous les “geoms” n’auront pas les mêmes options esthétiques, mais beaucoup parmi ces options peuvent être utilisées par la plupart des “geoms”. Voici quelques exemples :\n\nshape = Afficher un point avec geom_point() comme un point, une étoile, un triangle, ou un carré…\n\nfill = La couleur intérieure (par exemple d’une barre ou d’un diagramme en boîte)\n\ncolor = La ligne extérieure d’une barre, d’un diagramme en boîte, etc., ou la couleur du point si on utilise geom_point()\n\nsize = Taille (par exemple, l’épaisseur de la ligne, la taille du point)\n\nalpha = La transparence (1 = opaque, 0 = invisible)\n\nbinwidth = La largeur des cases de l’histogramme\n\nwidth = La largeur des colonnes du diagramme en barre\nlinetype = Le type de ligne (par exemple, solide, en pointillés …)\n\nIl est possible d’affecter des valeurs à ces attributs de deux manières :\n\nAffecter une valeur fixe/statique (par exemple, color = \"blue\") qui sera donc appliquée à toutes les observations représentées\n\nRelier l’attribut à une variable de données (par exemple, color = hospital) de telle sorte que l’affichage de chaque observation dépende de sa valeur dans cette variable. \n\n\n\nAffecter un attribut à une valeur fixe\nSi nous souhaitions que l’attribut de l’objet graphique soit statique, c’est-à-dire qu’elle soit la même pour chaque observation des données, nous écrivons son affectation dans le “geom” mais en dehors de toute instruction mapping = aes(). Ces affectations peuvent ressembler à size = 1 ou color = \"blue\". Voici deux exemples :\n\nDans le premier exemple, l’instruction mapping = aes() se trouve dans la commande ggplot() et les axes sont associés aux variables d’âge et de poids dans notre jeu de données. Les attributs du graphique, color =, size =, et alpha = (pour déterminer la transparence) sont assignées à des valeurs statiques. Pour plus de clarté, ceci est fait dans la fonction geom_point(), car vous pouvez ajouter d’autres “geoms” par la suite qui prendraient des valeurs différentes pour leur esthétique d’affichage.\n\nDans le deuxième exemple, l’histogramme ne nécessite que la mise en relation de la variable d’intérêt à l’axe des x . Les valeurs statiques de l’histogramme binwidth =, color =, fill = (couleur de l’intérieur des barres) et alpha = sont à nouveau définies dans le “geom”.\n\n\n# Diagramme de dispersion\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # définir les données et le mappage des axes\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # définir l'esthétique du point statique\n\n# histogramme\nggplot(data = linelist, mapping = aes(x = age))+       # définir les données et les axes\n  geom_histogram(              # afficher l'histogramme\n    binwidth = 7,                # largeur des barres\n    color = \"red\",               # couleur de la ligne de la barre\n    fill = \"blue\",               # couleur intérieure de la barre\n    alpha = 0.1)                 # transparence de la barre\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelier un attribut aux valeurs d’une variable\nL’alternative consiste à relier l’attribut de l’objet graphique aux valeurs d’une variable. Dans cette approche, l’affichage de cet attribut dépendra des valeurs prises dans cette variable. Si les valeurs de la variable sont continues, l’échelle d’affichage (légende) de cet attribut sera continue. Si les valeurs de la variable sont discrètes, la légende affichera chaque valeur et les données représentées apparaîtront comme “groupées” de manière distincte (pour en savoir plus, consultez la section groupage de cette page).\nPour ce faire, nous devons associer l’attribut du graphique à un nom de variable de notre jeu de données (sans guillemets) ie le “mapper”. Ceci doit donc être fait dans une fonction mapping = aes() (note : il y a plusieurs endroits dans le code où nous pouvons faire ces assignations (de mappage), comme discuté ci-dessous).\nDeux exemples sont présentés ci-dessous.\n\nDans le premier exemple, l’attribut color = (de chaque point) est mappé à la variable age - et une échelle est apparue dans la légende ! Pour l’instant, notons simplement que l’échelle existe - nous montrerons comment la modifier dans les sections suivantes.\n\nDans le deuxième exemple, deux nouveaux attributs sont également associés à des variables (color = et size =), tandis que les attributs shape = et alpha = sont associés à des valeurs fixes en dehors de toute fonction mapping = aes().\n\n\n# Diagramme de dispersion\nggplot(data = linelist,   # définir les données\n       mapping = aes(     # mapper l'attribut aux valeurs de la colonne\n         x = age,         # mapper l'axe des x à la variable des âges           \n         y = wt_kg,       # mapper l'axe des y à la variable des poids\n         color = age)     # mapper l'attribut color à la variable des âges\n       )+     \n  geom_point()         # afficher les données comme des points \n\n#  Diagramme de dispersion\nggplot(data = linelist,   # définir les données\n       mapping = aes(     # mapper les attributs aux variables\n         x = age,           # mapper l'axe des x à la variable des âges           \n         y = wt_kg,         # mapper l'axe des y à la variable des poids\n         color = age,       #mapper l'attribut color à la variable des âges\n         size = age))+      # mapper l'attribut size (taille des points) à la variable des âges\n  geom_point(             # afficher les données comme des points\n    shape = \"diamond\",      # preciser la forme des points comme des diamants\n    alpha = 0.3)            # transparence des points à 30%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote : Les axes sont toujours assignées à des variables dans les données (pas à des valeurs statiques), et sont donc toujours mappées dans mapping = aes().\nIl devient important de garder la trace des différentes couches du graphique et les attributs lorsque vous créez des graphiques plus complexes - par exemple des graphiques avec plusieurs “geoms”. Dans l’exemple ci-dessous, l’attribut size = est assigné deux fois - une fois pour geom_point() et une fois pour geom_smooth() - et les deux fois comme une valeur statique.\n\nggplot(data = linelist,\n       mapping = aes(           # mapper les attributs qux variables\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # ajouter des points pour chaque ligne de données\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # ajouter une courbe de tendance \n    method = \"lm\",              # avec une méthode linéaire\n    size = 2)                   # taille (largeur de la ligne) de 2\n\n\n\n\n\n\n\n\n\n\nComment et quand faire le mappage\nLe mappage dans mapping = aes() peut être écrit à plusieurs endroits dans les commandes du ggplot et peut même être écrit plus d’une fois. Cela peut être écrit dans la commande supérieure ggplot(), et/ou pour chaque “geom” individuel en dessous. Les possibilités comprennent :\n\nLes affectations de mappage effectuées dans la commande supérieure ggplot() et qui seront héritées par défaut dans tous les “geom” inférieurs, comme c’est le cas pour x = et y = ci-dessous.\nLes affectations de mappage effectuées dans un “geom” et qui ne s’appliquent qu’à ce “geom”.\n\nDe même, l’argument data = spécifié dans la commande supérieure ggplot() s’appliquera par défaut à tous les “geom” inférieurs. Toutefois on peut aussi spécifier des jeux de données différents pour chaque “geom” (mais c’est plus complexe).\nAinsi, chacune des 3 commandes suivantes (avec des mappages faits à différents niveaux du code) créera le même graphique :\n\n#  Ces commandes produiront exactement le même graphique.\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))\n\n\n\nGroupage\nOn peut facilement regrouper les données et les “représenter par groupe”. En fait, nous l’avons déjà fait !\nPour cela nous allons assigner la colonne de “regroupement” à l’attribut approprié du graphique, dans un mapping = aes(). Ci-dessus, nous avons fait une démonstration en utilisant des valeurs continues lorsque nous avons assigné l’attributsize = à la variable age. Cependant, cela fonctionne de la même manière pour les colonnes discrètes/catégorielles.\nPar exemple, si nous voulons que les points soient affichés par sexe, nous pouvons définir mapping = aes(color = gender). Une légende apparaît automatiquement. Cette affectation peut être faite dans le mapping = aes() de la commande supérieure ggplot() (et elle va être héritée par le “geom”), ou elle peut être définie dans un mapping = aes() séparé dans le “geom”. Les deux approches sont présentées ci-dessous :\n\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n# Cette autre version de code produit le même graphique\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)\n\nNotez que selon le “geom”, vous devrez utiliser différents arguments pour regrouper les données. Pour geom_point(), vous utiliserez probablement color =, shape = ou size =. Alors que pour geom_bar(), vous utiliseriez plus probablement fill =. Cela dépend simplement du “geom” et de l’attribut du graphique que vous voulez utiliser pour refléter les groupages.\nPour votre information - la manière la plus basique d’regrouper les données est d’utiliser seulement l’argument group = dans mapping = aes(). Cependant, cela ne changera pas les couleurs, le remplissage ou les formes. Elle ne créera pas non plus de légende. Pourtant, les données sont groupées, donc les affichages statistiques des données peuvent être affectés.\nPour ajuster l’ordre des groupes dans un graphique, consultez la page Trucs et Astuces avec ggplot ou la page sur les Facteurs. Vous trouverez de nombreux exemples de graphiques groupés dans les sections ci-dessous sur la représentation des données continues et catégorielles.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#ggplot_basics_facet",
    "href": "new_pages/ggplot_basics.fr.html#ggplot_basics_facet",
    "title": "30  Les bases de ggplot",
    "section": "30.6 Facets / Petits-multiples",
    "text": "30.6 Facets / Petits-multiples\nLes “facets”, ou “petits-multiples”, sont utilisés pour séparer un graphique en une figure à plusieurs sections selon les valeurs d’une ou plusieurs variables qualitatives. Le même type de graphique est ainsi créé plusieurs fois, chaque (sous-)graphique utilisant un sous-groupe du même ensemble de données.\nLe “faceting” est une fonctionnalité fournie avec ggplot2, de sorte que les légendes et les axes de chaque graphe d’un sous-groupe du jeu de données (“facet”) sont automatiquement alignés. Il existe d’autres paquets (“packages”) discutés dans la page Trucs et Astuces avec ggplot qui sont utilisés pour combiner des graphiques complètement différents (i.e. qui cette fois ne sont pas les mêmes graphiques répétés pour chaque sous-groupe d’un même jeu de données) en une seule figure. On peut citer cowplot et patchwork.\nLe “faceting” est effectué avec l’une des fonctions ggplot2 suivantes :\n\nfacet_wrap() Pour montrer un graphique différent pour chaque niveau d’une seule variable. Un exemple de ceci pourrait être de montrer une courbe d’épidémie différente pour chaque hôpital dans une région. Les “facets” sont ordonnées par ordre alphabétique, sauf si la variable est un facteur avec un autre ordre défini.\n\n\n\nOn peut utiliser certaines options pour déterminer la disposition des “facets”, par exemple nrow = 1 ou ncol = 1 pour contrôler le nombre de lignes ou de colonnes dans lesquelles les “facets” sont disposés.\n\n\nfacet_grid() Cette fonction est utilisée lorsque nous souhaitons introduire une seconde variable dans l’arrangement des “facets”. Ici, chaque graphe d’une grille montre l’intersection entre les valeurs de deux variables. Par exemple, des courbes épidémiques pour chaque combinaison hôpital-groupe d’âge avec les hôpitaux en haut (colonnes) et les groupes d’âge sur les côtés (lignes).\n\n\n\nDans ce cas-ci nrow et ncol ne sont pas pertinents, car les sous-groupes sont présentés dans une grille.\n\nChacune de ces fonctions accepte une syntaxe de formule pour spécifier la ou les variables à utiliser pour le “faceting” Les deux acceptent jusqu’à deux variables, une de chaque côté d’un tilde ~.\n\nPour facet_wrap(), on écrira le plus souvent le nom d’une seule variable précédée d’un tilde ~ comme facet_wrap(~hospital). Cependant on peut préciser deux noms de variables si c’est que l’on veut représenter facet_wrap(outcome ~hospital) - chaque combinaison unique s’affichera dans un graphique séparé, mais ils ne seront pas disposés dans une grille. Si on décide de ne fournir qu’une seule variable à la fonction, un point . est utilisé comme bouche-trou de l’autre côté de la formule - voir les exemples de code.\nPour facet_grid() nous pouvons également spécifier une ou deux variables à la formule (facet_grid( rows ~ columns)). Si on ne veut en spécifier qu’une, on peut placer un point . de l’un ou l’autre côté du tilde comme facet_grid(. ~ hospital) ou facet_grid(hospital ~ .).\n\nLes “facets” peuvent rapidement contenir une quantité écrasante d’informations - il est important de s’assurer que nous n’avons pas trop de modalités pour chaque variable qualitative que nous choisissons de “facetter”. Voici quelques exemples rapides avec le jeu de données sur le paludisme (voir Télécharger le manuel et les données) qui contient les données sur le nombre de cas de paludisme quotidiens pour différentes structures de santé par groupe d’âge.\nCi-dessous, nous importons ces données et effectuons quelques modifications rapides pour plus de simplicité :\n\n# Ces donnees sont le nombre de cas de palu par jour par structure\nmalaria_data &lt;- import(here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;%  # importer\n  select(-submitted_date, -Province, -newid)                                 # enlever les colonnes (variables) dont on n'a pas besoin pour les prochaines étapes\n\nLes 50 premières lignes des données sur le paludisme sont affichées ci-dessous. Notez qu’il y a une colonne malaria_tot, mais aussi des colonnes pour le nombre de cas par groupe d’âge (celles-ci seront utilisées dans le second exemple facet_grid()).\n\n\n\n\n\n\n\nfacet_wrap()\nPour le moment, concentrons-nous sur les variables malaria_tot et District. Ignorons pour l’instant les colonnes du nombre de cas par âge. Nous allons tracer des courbes épidémiques avec geom_col(), qui produit une colonne pour chaque jour à la hauteur spécifiée sur l’axe des y fournie par la variable malaria_tot (les données sont déjà des nombres de cas quotidiens, donc nous utilisons geom_col() - voir la section “Diagramme en barres” ci-dessous).\nLorsque nous ajoutons la commande facet_wrap(), nous spécifions un tilde (~) et ensuite la variable à utiliser pour le “facet” (District dans ce cas). On peut placer une autre variable sur le côté gauche du tilde, - cela créera un “facet” pour chaque combinaison - mais nous recommandons de le faire avec facet_grid() à la place. Dans ce cas d’utilisation, un “facet” est créé pour chaque valeur unique de District.\n\n# Un graphique avec des facets par district\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # tracer le nombre de cas sous forme de colonnes\n  theme_minimal()+                              # simplifier les  arrière-plans\n  labs(                                         # ajouter  les noms d'axes, titres ... \n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # les facets sont créés\n\n\n\n\n\n\n\n\n\n\nfacet_grid()\nNous pouvons utiliser une approche facet_grid() pour croiser deux variables. Disons que nous voulons croiser District et la variable âge. Eh bien, nous devons faire quelques transformations de données sur les colonnes d’âge pour obtenir ces données dans le format “long” préféré de ggplot. Les groupes d’âge ont tous leurs propres colonnes - nous les voulons dans une seule colonne appelée age_group et une autre appelée num_cases. Voir la page sur Pivoter les données pour plus d’informations sur ce processus.\n\nmalaria_age &lt;- malaria_data %&gt;%\n  select(-malaria_tot) %&gt;% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # choisir la variable à mettre en format \"long\"\n    names_to = \"age_group\",      # la nouvelle variable avec tous les groupes d'âge est nommée age_group\n    values_to = \"num_cases\"      # les valeurs dans les anciennes colonnes séparées sont regroupées dans une nouvelle unique colonne appelée num_cases\n  ) %&gt;%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\n\nLes 50 premières lignes des données transformées ressemblent désormais comme suit :\n\n\n\n\n\n\nLorsque vous passez les deux variables à facet_grid(), le plus simple est d’utiliser la notation de formule (par exemple x ~ y) où x représente les lignes et y les colonnes. Voici le graphique, utilisant facet_grid() pour montrer les graphiques pour chaque combinaison des colonnes age_group et District.\n\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(District ~ age_group)\n\n\n\n\n\n\n\n\n\n\nAxes libres ou fixes\nLes échelles des axes affichées lors du “faceting” sont par défaut les mêmes (fixes) pour tous les “facets”. C’est utile pour les comparaisons croisées, mais pas toujours approprié.\nLorsque l’on utilise facet_wrap() ou facet_grid(), on peut ajouter scales = \"free_y\" pour “libérer” ou rendre indépendant les axes y des “facets” afin qu’ils soient représentés à l’échelle de leur sous-ensemble de données spécifique. Ceci est particulièrement utile si les nombres sont faibles pour une des sous-catégories et que les tendances sont difficiles à voir en laissant l’échelle pareille pour tous les “facets”. Au lieu de “free_y”, on peut aussi écrire “free_x” pour faire la même chose pour l’axe des x (par exemple pour les dates) ou pour faire court “free” pour les deux axes. Notez que dans facet_grid, les échelles y seront les mêmes pour les “facets” de la même ligne, et les échelles x seront les mêmes pour les “facets” de la même colonne.\nEn utilisant uniquement facet_grid, on peut ajouter space = \"free_y\" ou space = \"free_x\" pour que la hauteur ou la largeur réelle de la “facets” soit pondérée par les valeurs de la figure à l’intérieur. Cela ne fonctionne que si scales = \"free\" (y ou x) est déjà appliqué.\n\n# Axe des y libre\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # tracer le nombre de cas sous forme de colonnes\n  theme_minimal()+                              # simplifier les  arrière-plans\n  labs(                                         # ajouter  les noms d'axes, titres ... \n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # les facets sont créés\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRéorganiser l’affichage des “facets”\nVoir ce post sur la façon de réorganiser les modalités/niveaux des variables facteurs dans les “facets”.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#stocker-les-graphiques-produits",
    "href": "new_pages/ggplot_basics.fr.html#stocker-les-graphiques-produits",
    "title": "30  Les bases de ggplot",
    "section": "30.7 Stocker les graphiques produits",
    "text": "30.7 Stocker les graphiques produits\n\nSauvegarder les graphiques dans l’environnement\nPar défaut, lorsque nous exécutons une commande ggplot(), le graphique sera affiché dans l’onglet “Plots” de RStudio. Cependant, nous pouvons également enregistrer le celui-ci en tant qu’objet en utilisant l’opérateur d’affectation &lt;- et en lui donnant un nom. Il ne s’affichera alors que si le nom de l’objet lui-même est exécuté. On peut également l’afficher en faisant appel à la fonction R base print(), mais cela n’est nécessaire que dans certaines circonstances, par exemple si le graphique est créé à l’intérieur d’une boucle for utilisée pour afficher plusieurs graphiques à la fois (voir la page Itération, boucles et listes).\n\n# definir le graphique\nage_by_wt &lt;- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# l'afficher\nage_by_wt    \n\n\n\n\n\n\n\n\n\n\nModifier des graphiques de l’environnement\nUne des particularités de ggplot2 est que nous pouvons définir un graphiquee (comme ci-dessus), puis lui ajouter des couches en commençant par son nom. Nous n’avons pas besoin de répéter toutes les commandes qui ont créé le graphique original !\nPar exemple, pour modifier le graphe age_by_wt qui a été défini ci-dessus, pour inclure une ligne verticale à l’âge de 50 ans, il suffit d’ajouter un + et de commencer à ajouter des couches supplémentaires au graphe.\n\nage_by_wt+\n  geom_vline(xintercept = 50)\n\n\n\n\n\n\n\n\n\n\nExporter les graphiques\nL’exportation de ggplots est facilitée par la fonction ggsave() de ggplot2. Elle peut fonctionner de deux façons :\n\nSpécifier le nom de l’objet graphique, puis le chemin d’accès au fichier et le nom du fichier avec l’extension.\n\nPar exemple : ggsave(my_plot, here(\"plots\", \"my_plot.png\"))\n\n\nExécutez la commande avec seulement un chemin d’accès au fichier, pour sauvegarder le dernier graphique qui a été imprimé.\n\nPar exemple : ggsave(here(\"plots\", \"my_plot.png\")).\n\n\nVous pouvez exporter en png, pdf, jpeg, tiff, bmp, svg, ou plusieurs autres types de fichiers, en spécifiant l’extension du fichier dans le chemin d’accès au fichier.\nVous pouvez également spécifier les arguments width = (largeur), height = (hauteur), et units = (unités) (soit “in”, “cm”, ou “mm”). Vous pouvez également spécifier dpi = avec un nombre pour la résolution du graphe (par exemple 300). Consultez les détails de la fonction en entrant ?ggsave ou en lisant la documentation en ligne.\nRappelez-vous que vous pouvez utiliser la syntaxe here() pour fournir le chemin d’accès au fichier souhaité. Voir la page Importation et exportation pour plus d’informations.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#etiquettes-du-graphe",
    "href": "new_pages/ggplot_basics.fr.html#etiquettes-du-graphe",
    "title": "30  Les bases de ggplot",
    "section": "30.8 Etiquettes du graphe",
    "text": "30.8 Etiquettes du graphe\nVous voudrez certainement ajouter ou ajuster les étiquettes du graphique. Ceci est le plus facile à faire avec la fonction labs() qui est ajoutée au graphe avec + tout comme les “geoms” l’ont été.\nDans labs(), vous pouvez fournir des chaînes de caractères à ces arguments :\n\nx = et y = Le titre de l’axe des x et de l’axe des y (étiquettes des axes)\n\ntitle = Le titre du graphique principal\n\nsubtitle = Le sous-titre du graphique, en plus petit texte sous le titre\n\ncaption = La note de bas de graphe du graphique, en bas à droite par défaut.\n\nVoici un graphique que nous avons fait plus tôt, mais avec des étiquettes plus jolies :\n\nage_by_wt &lt;- ggplot(\n  data = linelist,   # preciser le jeu de donnees\n  mapping = aes(     # mapper les attributs aux valeurs des variables\n         x = age,           # mapper l'axe des x à l'âge            \n         y = wt_kg,         # mapper l'axe des y au poids (weight)\n         color = age))+     # mapper la couleur à l'âge\n  geom_point()+           # afficher les données comme des points\n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt\n\n\n\n\n\n\n\n\nASTUCE: Remarquez comment, dans l’affectation de la note de bas de graphe, nous avons utilisé str_glue() du package stringr pour implanter du code R dynamique dans le texte de la chaîne de caractères. La légende affichera la date “Data as of :” qui reflète la date d’hospitalisation maximale dans la liste linéaire utilisée pour dessiner le graphe. Pour en savoir plus, consultez la page Caractères et chaînes de caractères.\nNOTE: Une remarque sur la spécification du titre de la légende : Il n’y a pas un unique argument “titre de légende”, car on peut avoir plusieurs échelles dans votre légende. Dans labs(), on peut écrire l’argument pour l’attribut graphique utilisé pour créer la légende, et fournir le titre de cette façon. Par exemple, ci-dessus, nous avons assigné color = age pour créer la légende. Par conséquent, nous fournissons color = à labs() et nous attribuons le titre de légende souhaité (“Age” avec un A majuscule). Si on crée la légende avec aes(fill = COLUMN), alors dans labs() on écrira fill = pour ajuster le titre de cette légende. La section sur les échelles de couleurs dans la page ggplot tips fournit plus de détails sur l’édition des légendes, et une approche alternative utilisant les fonctions scales_().",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#ggplot_basics_themes",
    "href": "new_pages/ggplot_basics.fr.html#ggplot_basics_themes",
    "title": "30  Les bases de ggplot",
    "section": "30.9 Thèmes",
    "text": "30.9 Thèmes\nUne des meilleures parties de ggplot2 est le large contrôle que nous pouvons avoir sur le graphique - nous pouvons définir n’importe quoi ! Comme mentionné plus haut, les éléments du graphique qui ne sont pas reliés aux données sont ajustés par la fonction theme(). Par exemple, la couleur de fond du graphique, la présence/absence de lignes de grille, et la police/taille/couleur/alignement du texte (titres, sous-titres, légendes, texte des axes…). Ces ajustements peuvent être effectués de deux manières :\n\nUtiliser une fonction thème toute faite theme_() pour faire des ajustements généraux - ceux-ci incluent theme_classic(), theme_minimal(), theme_dark(), theme_light(), theme_grey(), theme_bw() entre autres.\n\nAjustez chaque petit aspect du graphique individuellement dans theme().\n\n\nFonctions thème toute faites\nComme elles sont assez simples, nous allons démontrer l’utilisation des fonctions thème prêtes à l’utilisation ci-dessous et ne les décrirons pas davantage ici.\nNOTE: Notez que tout micro-ajustement supplémentaire avec theme() doit être fait après l’utilisation d’une fonction thème toute faite (sinon les ajustements ne seront pas pris en compte).\nEcrivez-les avec des parenthèses vides.\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModifier le thème\nLa fonction theme() peut prendre un grand nombre d’arguments, dont chacun modifie un aspect très spécifique du graphique. Il n’est pas possible de couvrir tous les arguments, mais nous allons décrire le modèle général pour leur utilisation et vous montrer comment trouver le nom de l’argument dont vous avez besoin. La syntaxe de base est la suivante :\n\nDans theme() écrivez le nom de l’argument pour l’élément du graphique que vous voulez modifier, comme plot.title =\n\nFournissez une fonction element_() à l’argument\n\n\n\nLe plus souvent, utilisez element_text(), mais d’autres incluent element_rect() pour les couleurs d’arrière-plan du canevas, ou element_blank() pour supprimer les éléments du graphique\n\n\n\nA l’intérieur de la fonction element_(), écrivez des affectations d’arguments pour faire les ajustements fins que vous désirez.\n\nCette description était assez abstraite, voici donc quelques exemples.\nLe graphique ci-dessous a l’air assez stupide, mais il sert à vous montrer une variété de façons dont vous pouvez ajuster vos graphes.\n\nNous commençons avec le graphique age_by_wt défini juste au-dessus et ajoutons theme_classic().\n\nPour des ajustements plus fins, on ajoute theme() et on inclut un argument pour chaque élément du graphe à ajuster.\n\nIl peut être intéressant d’organiser les arguments en sections logiques. Pour décrire quelques-uns de ceux utilisés ci-dessous :\n\nlegend.position = est unique en ce qu’il accepte des valeurs simples comme “bottom”, “top”, “left” et “right”. Mais en général, les arguments liés au texte nécessitent que vous placiez les détails dans element_text().\n\nLa taille du titre avec element_text(size = 30)\n\nL’alignement horizontal de la note de bas de graphe avec element_text(hjust = 0) (de droite à gauche)\n\nLe sous-titre est en italique avec element_text(face = \"italic\")\n\n\nage_by_wt + \n  theme_classic()+                                 # pre-definir les ajustements avec un theme tout-prêt\n  theme(\n    legend.position = \"bottom\",                    # déplacer la legende en dessous\n    \n    plot.title = element_text(size = 30),          # taille du titre à 30\n    plot.caption = element_text(hjust = 0),        # note de bas de graphe alignée à gauche\n    plot.subtitle = element_text(face = \"italic\"), # sous-titre en italique\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # ajustement pour le texte sur l'axe des x uniquement \n    axis.text.y = element_text(size = 15),         # ajustement pour le texte sur l'axe des y uniquement\n    \n    axis.title = element_text(size = 20)           # ajustement pour les titres des deux axes\n    )     \n\n\n\n\n\n\n\n\nVoici quelques arguments theme() particulièrement courants. Vous reconnaîtrez certains motifs, comme l’ajout de .x ou .y pour appliquer le changement seulement à un axe.\n\n\n\n\n\n\n\ntheme() argument\nCe qu’il ajuste\n\n\n\n\nplot.title = element_text()\nLe titre\n\n\nplot.subtitle = element_text()\nLe sous-titre\n\n\nplot.caption = element_text()\nLa note de bas de graphe (family, face, color, size, angle, vjust, hjust…)\n\n\naxis.title = element_text()\nTitre des axes (both x and y) (size, face, angle, color…)\n\n\naxis.title.x = element_text()\nTitre des axes: axe des x uniquement (utiliser .y pour axe des y uniquement)\n\n\naxis.text = element_text()\nTexte sur les axes (pour les deux axes)\n\n\naxis.text.x = element_text()\nTexte sur les axes: axe des x uniquement (utiliser .y pour axe des y uniquement)\n\n\naxis.ticks = element_blank()\nSupprimer les coches des axes\n\n\naxis.line = element_line()\nLignes des axes (color, size, linetype: solid dashed dotted etc)\n\n\nstrip.text = element_text()\nTexte de bande des “facet” (colour, face, size, angle…)\n\n\nstrip.background = element_rect()\nBande des “facet” (fill, colour, size…)\n\n\n\nVous vous dîtes surement “Mais il y a tellement d’arguments pour les thémes! Comment pourrais-je me les rappeler tous ?”. Ne vous inquiétez pas - il est impossible de se souvenir de tous. Heureusement, il existe quelques outils pour vous aider :\nLa documentation tidyverse sur modifier le thème, qui contient une liste complète.\nTIP: Exécutez la commande theme_get() de ggplot2 pour imprimer une liste de tous les &gt;90 arguments de theme() sur la console.\nTIP: Si jamais vous voulez supprimer un élément d’un graphe, vous pouvez aussi le faire via theme(). Passez simplement element_blank() en argument pour le faire disparaître complètement. Pour les légendes, préciser legend.position = \"none\".",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#couleurs",
    "href": "new_pages/ggplot_basics.fr.html#couleurs",
    "title": "30  Les bases de ggplot",
    "section": "30.10 Couleurs",
    "text": "30.10 Couleurs\nVeuillez consulter cette section sur les échelles de couleurs de la page “Trucs et Astuces dans ggplot”.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#utiliser-le-pipe-avec-ggplot2",
    "href": "new_pages/ggplot_basics.fr.html#utiliser-le-pipe-avec-ggplot2",
    "title": "30  Les bases de ggplot",
    "section": "30.11 Utiliser le “pipe” avec ggplot2",
    "text": "30.11 Utiliser le “pipe” avec ggplot2\nLorsque vous utilisez des “pipes” pour nettoyer et transformer vos données, il est facile de passer les données transformées dans ggplot().\nLes “pipes” (qui passent le jeu de données d’une fonction à l’autre) laisseront place aux + une fois que la fonction ggplot() sera appelée. Notez que dans ce cas, il n’est pas nécessaire de spécifier l’argument data =, car il est automatiquement défini comme le jeu de données passé dans le pipe.\nVoici à quoi cela peut ressembler :\n\nlinelist %&gt;%                                                     # commencer avec la liste lineaire\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # selectionner les  variables qui nous interessent\n  pivot_longer(                                                  # pivoter en format long\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # remplacer les valeurs  manquantes\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  \n  ggplot(                                                        # commencer le ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+ # remarquez qu'ici on passe aux +\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#représenter-des-données-continues",
    "href": "new_pages/ggplot_basics.fr.html#représenter-des-données-continues",
    "title": "30  Les bases de ggplot",
    "section": "30.12 Représenter des données continues",
    "text": "30.12 Représenter des données continues\nTout au long de cette page, vous avez déjà vu de nombreux exemples de représentation de données continues. Nous les consolidons ici brièvement et présentons quelques variantes.\nLes visualisations couvertes ici incluent :\n\nLes graphiques pour une variable continue :\n\nHistogramme, un graphique classique pour présenter la distribution d’une variable continue. Diagramme en boîte (également appelé boîte à moustaches), pour montrer les 25ème, 50ème et 75ème percentiles, les extrémités de la distribution et les valeurs aberrantes (limitations importantes).\nGraphique de gigue, pour montrer toutes les valeurs sous forme de points qui sont “gigueux” afin qu’ils puissent (presque) tous être vus, même si deux d’entre eux ont la même valeur.\nGraphiques en violon, montre la distribution d’une variable continue basée sur la largeur symétrique du “violon”. Sina plot, est une combinaison du graphique de gigue et du graphique de violin, où les points individuels sont montrés mais dans la forme symétrique de la distribution (via le “package” ggforce).\nNuage de points pour deux variables continues.\nHeatmaps pour trois variables continues (lien vers la page Heat plots).\n\n\n\nHistogrammes\nLes histogrammes peuvent ressembler à des diagrammes en barres, mais ils sont distincts car ils mesurent la distribution d’une variable continue. Il n’y a pas d’espace entre les “barres”, et une seule colonne est fournie à geom_histogram().\nLe code ci-dessous permet de générer des histogrammes, qui regroupent les données continues en gammes et les affichent dans des barres adjacentes de hauteur variable. Ceci est fait en utilisant geom_histogram(). Voir la section “Diagrammes en barres” de la page ggplot basics pour comprendre la différence entre geom_histogram(), geom_bar(), et geom_col().\nNous allons montrer la distribution des âges des cas. Dans mapping = aes(), nous spécifierons la colonne dont nous voulons voir la distribution. On peut affecter cette colonne à l’axe des x ou des y.\nLes lignes seront assignées à des “bins” basés sur leur âge numérique, et ces “bins” seront représentés graphiquement par des barres. Si vous spécifiez un nombre de “bins” avec l’attribut graphique bins =, les points de rupture sont espacés de manière égale entre les valeurs minimum et maximum de l’histogramme. Si bins = n’est pas spécifié, un nombre approprié de bins sera deviné et ce message sera affiché après le tracé :\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nSi vous ne voulez pas spécifier un nombre de “bins” à bins =, vous pouvez alternativement spécifier binwidth = dans les unités de l’axe. Nous donnons quelques exemples montrant différents bins et largeurs de bins :\n\n# A) Histogramme tracé par défaut\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) Plus de bins\nggplot(data = linelist, aes(x = age))+  # mapper la variable age à l'axe des x\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Moins de bins\nggplot(data = linelist, aes(x = age))+  # mapper la variable age à l'axe des x\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# D) Plus de bins\nggplot(data = linelist, aes(x = age))+  # mapper la variable age à l'axe des x\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPour obtenir des proportions lissées, on peut utiliser geom_density() :\n\n# Fréquence avec axe de proportion, lissée\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Fréquence empilée avec axe de proportion, lissée\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPour obtenir un histogramme “empilé” (d’une colonne continue de données), nous pouvons faire l’une des choses suivantes :\n\nUtilisez geom_histogram() avec l’argument fill = dans aes() et affecté à la colonne de regroupement, ou\n\nUtilisez geom_freqpoly(), qui est probablement plus facile à lire (vous pouvez toujours définir binwidth =).\n\nPour voir les proportions de toutes les valeurs, définissez le paramètre y = after_stat(density) (utilisez exactement cette syntaxe non modifiée pour vos données). Note : ces proportions seront affichées par groupe.\n\nChacun d’entre eux est présenté ci-dessous (notez l’utilisation de color = ou fill = dans chacun d’entre eux) :\n\n# Histogramme \"empilé\"\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frequence\nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frequence avec axe en proportion \nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frequence avec axe en proportion, lissé\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi vous voulez vous amuser un peu, essayez geom_density_ridges du “package” ggridges (vignette ici.\nPour plus de détails sur les histogrammes, consultez la page tidyverse page sur geom_histogram().\n\n\nDiagrammes en boîtes\nLes diagrammes en boîte sont très utilisés, mais ils ont des limites importantes. Ils peuvent masquer la distribution réelle - par exemple, une distribution bimodale. Voir cette galerie de graphiques R et cet article data-to-viz pour plus de détails. Cependant, ils affichent joliment l’écart interquartile et les valeurs aberrantes - ils peuvent donc être superposés à d’autres types de graphiques qui montrent la distribution de manière plus détaillée.\nNous vous rappelons ci-dessous les différentes composantes d’un diagramme en boîte :\n\n\n\n\n\n\n\n\n\nLorsque vous utilisez geom_boxplot() pour créer un box plot, vous mappez généralement un seul axe (x ou y) dans aes(). L’axe spécifié détermine si les tracés sont horizontaux ou verticaux.\nDans la plupart des “geoms”, nous créons un graphique par groupe en faisant correspondre un attribut comme color = ou fill = à une variable dans aes(). Cependant, pour les diagrammes en boîte, nous pouvons le faire en assignant la variable de regroupement à l’axe non assigné (x ou y). Ci-dessous se trouve le code pour un diagramme de boîte de toutes les valeurs d’âge dans l’ensemble de données, et ensuite le code pour afficher un box plot pour chaque sexe (non manquant) dans l’ensemble du jeu de données. Notez que les valeurs NA (manquantes) apparaîtront comme un diagramme de boîte séparé, sauf si elles sont supprimées. Dans cet exemple, nous avons également défini le “remplissage” de la colonne “gender” (issue finale de chaque cas) afin que chaque diagramme de boîtes soit d’une couleur différente - mais ce n’est pas nécessaire.\n\n# A) Diagramme de boîte d'ensemble\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # uniquement axe y mappé (non axe des x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Diagramme de boîte par groupe\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # supprimer la légende (redondant)\n  labs(title = \"B) Boxplot by gender\")      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPour le code permettant d’ajouter un diagramme en boîte aux bords d’un nuage de points (diagrammes “marginaux”), voir la page Trucs et Astuces avec ggplot.\n\n\nGraphes en violon, gigue, et “sina”\nCi-dessous, vous trouverez le code pour créer des diagrammes en violon (geom_violin) et jitter (gigue) (geom_jitter) pour montrer les distributions. Vous pouvez spécifier que le remplissage ou la couleur est également déterminé par les données, en insérant ces options dans aes().\n\n# A) Jitter par groupe\nggplot(data = linelist %&gt;% drop_na(outcome),      # supprimer les valeurs manquantes\n       mapping = aes(y = age,                     # mapper la variable continue\n           x = outcome,                           # mapper la variable de regroupement\n           color = outcome))+                     # mapper la couleur avec la variable outcome \n  geom_jitter()+                                  # Creer le graphique\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) Violin par groupe\nggplot(data = linelist %&gt;% drop_na(outcome),       # supprimer les valeurs manquantes\n       mapping = aes(y = age,                      # mapper la variable continue\n           x = outcome,                            # mapper la variable de regroupement\n           fill = outcome))+                       # mapper la ouleur avec la variable outcome\n  geom_violin()+                                   # Creer le graphique\n  labs(title = \"B) violin plot by gender\")    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous pouvez combiner les deux en utilisant la fonction geom_sina() du “package” ggforce. La fonction trace les points de gigue dans la forme du tracé de violon. Lorsqu’il est superposé au tracé du violon (en ajustant les transparences), il peut être plus facile à interpréter visuellement.\n\n# A) Sina  par group\nggplot(\n  data = linelist %&gt;% drop_na(outcome), \n  aes(y = age,           # mapper la variable numérique\n      x = outcome)) +    # mapper la variable de regroupement\n  geom_violin(\n    aes(fill = outcome), # remplissage (couleur de fond du violon)\n    color = \"white\",     # contour blanc\n    alpha = 0.2)+        # transparence\n  geom_sina(\n    size=1,                # Changer la taille des gigues\n    aes(color = outcome))+ # mapper la couleur des points avec la variable outcome\n  scale_fill_manual(       # Definir des couleurs de remplissage (de fond) des violons en precisant quelle couleur prend chaque modalite de la variable outcome\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Definir des couleurs des points en precisant quelle couleur prend chaque modalite de la variable outcome\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Supprimer l'arriere-plan gris\n  theme(legend.position = \"none\") +                # Supprimer la legende non-necessaire\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      \n\n\n\n\n\n\n\n\n\n\nDeux variables continues\nEn suivant une syntaxe similaire, geom_point() vous permettra de tracer deux variables continues l’une en fonction de l’autre dans un scatter plot (un nuage de points/un diagramme de dispersion). Ceci est utile pour montrer les valeurs réelles plutôt que leurs distributions. Un diagramme de dispersion basique de l’âge par rapport au poids est montré dans (A). Dans (B), nous utilisons à nouveau facet_grid() pour montrer la relation entre deux variables continues dans la liste lineaire.\n\n# Diagramme de dispersion du poids et de l'âge\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Diagramme de dispersion du poids et de l'âge par sexe et issue finale du cas\nggplot(data = linelist %&gt;% drop_na(gender, outcome), #garder que le sexe/issue finale non manquant\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrois variables continues\nVous pouvez afficher trois variables continues en utilisant l’argument fill = pour créer un graphique thermique (heat plot). La couleur de chaque “cellule” reflétera la valeur de la troisième colonne de données continues. Voir la page Astuces en ggplot et la page sur les Graphiques thermiques pour plus de détails et plusieurs exemples.\nIl existe des moyens de créer des graphiques 3D dans R, mais pour l’épidémiologie appliquée, ils sont souvent difficiles à interpréter et donc moins utiles pour la prise de décision.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#représenter-des-données-catégorielles",
    "href": "new_pages/ggplot_basics.fr.html#représenter-des-données-catégorielles",
    "title": "30  Les bases de ggplot",
    "section": "30.13 Représenter des données catégorielles",
    "text": "30.13 Représenter des données catégorielles\nLes données catégoriques peuvent être des valeurs de caractères, des valeurs logiques (VRAI/FAUX) ou des facteurs (voir la page Facteurs).\n\nPréparation\n\nStructure des données\nLa première chose à comprendre au sujet de vos données catégorielles est de savoir si elles existent sous forme d’observations brutes, comme une liste linéaire de cas, ou sous forme de résumé ou de tableau de données agrégées contenant des comptages ou des proportions. L’état de vos données aura un impact sur la fonction de traçage que vous utiliserez :\n\nSi vos données sont des observations brutes avec une ligne par observation, vous utiliserez probablement geom_bar().\n\nSi vos données sont déjà agrégées en nombres ou en proportions, vous utiliserez probablement geom_col().\n\n\n\nClasse des variables et ordre des valeurs\nEnsuite, examinez la classe des colonnes que vous voulez tracer. Nous examinons hospital, d’abord avec class() de base R, et avec tabyl() de janitor.\n\n# Voir la classe de la variable hospital - on peut voir que c'est une variable de type caractère\nclass(linelist$hospital)\n\n[1] \"character\"\n\n# Regardez les valeurs et les proportions dans la variable hospital\nlinelist %&gt;% \n  tabyl(hospital)\n\n                             hospital    n    percent\n                     Central Hospital  454 0.07710598\n                    Military Hospital  896 0.15217391\n                              Missing 1469 0.24949049\n                                Other  885 0.15030571\n                        Port Hospital 1762 0.29925272\n St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n\n\nNous pouvons voir que les valeurs à l’intérieur sont des caractères, car il s’agit de noms d’hôpitaux, et par défaut elles sont classées par ordre alphabétique. Il existe des valeurs “autres” et “manquantes”, que nous préférerions voir figurer dans les dernières sous-catégories lors de la présentation des répartitions. Nous transformons donc cette variable en facteur et la réorganisons. Ce point est traité plus en détail dans la page Facteurs.\n\n# Convertir en facteur et définir l'ordre des niveaux pour que \"Other\" et \"Missing\" soient les derniers.\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\n\n\nlevels(linelist$hospital)\n\n[1] \"St. Mark's Maternity Hospital (SMMH)\"\n[2] \"Port Hospital\"                       \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Other\"                               \n[6] \"Missing\"                             \n\n\n\n\n\ngeom_bar()\nUtilisez geom_bar() si vous voulez que la hauteur des barres (ou la hauteur des composants des barres empilées) reflète le nombre de lignes pertinentes dans les données. Ces barres auront des espaces entre elles, à moins que l’attribut graphique width = soit ajusté.\n\nNe fournissez qu’une seule affectation de colonne d’axe (généralement l’axe des x). Si vous fournissez x et y, vous obtiendrez Error: stat_count() can only have an x or y aesthetic.\n\nVous pouvez créer des barres empilées en ajoutant une affectation de colonne fill = dans mapping = aes().\n\nL’axe opposé sera intitulé “count” par défaut, car il représente le nombre de lignes.\n\nCi-dessous, nous avons affecté la variable “outcome” (issue finale) à l’axe des y, mais il pourrait tout aussi bien être sur l’axe des x. Si vous avez des valeurs de caractères plus longues, il est parfois préférable de retourner les barres sur le côté et de placer la légende en bas. Cela peut avoir un impact sur la façon dont vos niveaux de facteurs sont ordonnés - dans ce cas, nous les inversons avec fct_rev() pour mettre les manquants et les autres en bas.\n\n# A) Issues finales pour l'ensemble des cas\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Issues finales pour les cas par hôpital\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_col()\nUtilisez geom_col() si vous voulez que la hauteur des barres (ou la hauteur des composants des barres empilées) reflète des valeurs pré-calculées qui existent dans les données. Il s’agit souvent de chiffres ou de proportions résumés ou “agrégés”.\nFournissez des affectations de variables pour les deux axes à geom_col(). Généralement, la colonne de l’axe des x est discrète et celle de l’axe des y est numérique.\nDisons que nous avons cet ensemble de données outcomes :\n\n\n# A tibble: 2 × 3\n  outcome     n proportion\n  &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 Death    1022       56.2\n2 Recover   796       43.8\n\n\nLe code ci-dessous utilise geom_col pour créer des diagrammes en barres simples afin de montrer la distribution de l’issue finale des cas Ebola. Avec geom_col, x et y doivent être spécifiés. Ici, x est la variable catégorielle sur l’axe des x, et y est la colonne de proportions générée proportion.\n\n# Issues finales pour l'ensemble des cas\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\n\n\n\n\n\n\n\n\nPour montrer les répartitions par hôpital, il faudrait que notre tableau contienne plus d’informations et qu’il soit au format “long”. Nous créons ce tableau avec les fréquences des catégories combinées outcome et hospital (voir la page Travailler sur des données groupées pour des conseils sur le regroupement).\n\noutcomes2 &lt;- linelist %&gt;% \n  drop_na(outcome) %&gt;% \n  count(hospital, outcome) %&gt;%  # compter les lignes par hôpital et issue finale\n  group_by(hospital) %&gt;%        # regrouper pour que les proportions soient sur le total de \"hospital\"\n  mutate(proportion = n/sum(n)*100) # calculer les proportions de décès et de guerison au sein de chaque \"hospital\" \n\nhead(outcomes2) # Voir les premières lignes de la table \n\n# A tibble: 6 × 4\n# Groups:   hospital [3]\n  hospital                             outcome     n proportion\n  &lt;fct&gt;                                &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n3 Port Hospital                        Death     785       57.6\n4 Port Hospital                        Recover   579       42.4\n5 Central Hospital                     Death     193       53.9\n6 Central Hospital                     Recover   165       46.1\n\n\nNous créons ensuite le ggplot avec quelques mises en forme supplémentaires :\n\nInverser les axes : Nous avons inversé les axes avec coord_flip() pour pouvoir lire les noms des hôpitaux. Barres côte-à-côte : Nous avons ajouté d’un argument position = \"dodge\" pour que les barres pour les décès et la guérison soient présentées côte à côte plutôt qu’empilées. Notez que les barres empilées sont la valeur par défaut.\nLargeur de colonne : Nous avons spécifié ‘width’, donc les colonnes sont deux fois moins larges que la largeur maximale possible. Ordre des variable : Nous avons inversé l’ordre des catégories sur l’axe des y de sorte que ‘Autre’ et ‘Manquant’ soient en bas, avec scale_x_discrete(limits=rev). Notez que nous avons utilisé cette méthode plutôt que scale_y_discrete parce que l’hôpital est indiqué dans l’argument x de aes(), même si visuellement il est sur l’axe des ordonnées. Nous faisons cela parce que ggplot semble présenter les catégories à l’envers, sauf si nous lui disons de ne pas le faire.\n\nAutres détails : Les étiquettes/titres et couleurs ont été ajoutés dans labs et scale_fill_color respectivement.\n\n\n# Issue finale pour l'ensemble des cas par hopital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # mapper axe des x avec les proportions pre-calculées\n      y = fct_rev(hospital),          # inverser les catégories de la variable 'hospital' pour que missing/other sont en dernier\n      fill = outcome),                # remplissage par issue finale\n    width = 0.5)+                    # barres moins larges (sur 1)\n  theme_minimal() +                  # theme minimal \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # titre légende \n       y = \"Count\",                  # titre axe des y \n       x = \"Hospital of admission\")+ # titre axe des x\n  scale_fill_manual(                 # préciser des couleurs manuellement\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) \n\n\n\n\n\n\n\n\nNotez que les proportions sont binaires, et que l’on peut donc préférer ne pas utiliser le terme “guérison” et ne montrer que la proportion de décès. Ceci n’est qu’une illustration.\nSi vous utilisez geom_col() avec des données de dates (par exemple une courbe épidémique à partir de données regroupées) - vous voudrez ajuster l’argument width = pour supprimer les lignes de “gap” entre les barres. Si vous utilisez des données quotidiennes, réglez width = 1. Si vous utilisez des données hebdomadaires, width = 7. CAUTION: Les mois ne sont pas possibles car chaque mois a un nombre de jours différent..\n\n\ngeom_histogram()\nLes histogrammes peuvent ressembler à des diagrammes en barres, mais ils sont distincts car ils mesurent la distribution d’une variable continue. Il n’y a pas d’espace entre les “barres”, et une seule colonne est fournie à geom_histogram(). Il existe des arguments spécifiques aux histogrammes tels que bin_width = et breaks = pour spécifier comment les données doivent être classées. La section ci-dessus sur les données continues et la page sur les Courbes épidémiques fournissent des détails supplémentaires.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.fr.html#ressources",
    "href": "new_pages/ggplot_basics.fr.html#ressources",
    "title": "30  Les bases de ggplot",
    "section": "30.14 Ressources",
    "text": "30.14 Ressources\nIl existe une grande quantité de ressources et d’aide en ligne, en particulier avec ggplot. Voir :\n\nAntisèche ggplot2\nUn autre antisèche\nPage tidyverse sur les bases de ggplot\n\nRepresentation des variables continues\n\nPage R for Data Science sur la visualisation des donnees\nPage R for Data Science sur les graphiques pour mieux communiquer",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Les bases de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html",
    "href": "new_pages/ggplot_tips.fr.html",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "",
    "text": "31.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#préparation",
    "href": "new_pages/ggplot_tips.fr.html#préparation",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "",
    "text": "Charger les extensions (“packages”)\nCe bout de code montre le chargement des “packages” nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser . On peut également charger des “packages” avec library() à partir de R base. Voir la page sur Bases de R pour plus d’informations sur les “packages” R.\n\npacman::p_load(\n  tidyverse,      # inclut ggplot2 et d'autres extensions de  data management\n  rio,            # importer/exporter\n  here,           # localiser des fichiers\n  stringr,        #  travailler avec des caracteres     \n  scales,         # transformer des valeurs numeriques\n  ggrepel,        # bien placer des  étiquettes \n  gghighlight,    # mettre en évidence une partie de l'intrigue\n  RColorBrewer    # gammes de couleurs\n)\n\n\n\nImporter des données\nPour commencer, nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre en travaillant sur la base, cliquez pour télécharger la version “clean”  (en fichier .rds). Importez les données avec la fonction import() du “package” rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la liste linéaire sont affichées ci-dessous.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#ggplot_tips_colors",
    "href": "new_pages/ggplot_tips.fr.html#ggplot_tips_colors",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.2 Palettes de couleur, le remplissage, les axes, etc.",
    "text": "31.2 Palettes de couleur, le remplissage, les axes, etc.\nNous avons déjà parlé du “mappage” dans la page sur les Bases de ggplot. Ainsi lorsque le mappage est établi, ie les attributs du graphique (par exemple, la taille, la couleur, la forme, le remplissage, l’axe du tracé) associés à des variables dans les données, on pourrait amener à vouloir modifier ce mappage pour que notre graphique reflète mieux le message que nous voulons délivrer. Ceci est possible avec les commandes scales qui vont permettre des ajustements de l’affichage exact du résultat de nos mappages . Par exemple la couleur reliée à une variable précise sera modifiée ou précisée selon nos besoins avec scale_color, la taille (size) pourrait être ajustée selon les valeurs minimales et maximales avec scale_size etc. Dans cette section, nous développerons l’utilisation de certains scales courants.\n\n31.2.1 Palettes de couleurs\nUne chose qui peut être initialement difficile à comprendre avec ggplot2 est le contrôle des palettes de couleurs. Notez que cette section traite de la couleur des objets du graphe (“geoms”/formes) tels que les points, les barres, les lignes, les tuiles, etc. Pour ajuster la couleur des textes accessoires (non reliés aux données) , des titres ou de la couleur de fond, consultez la section Themes de la page ggplot basics.\nPour contrôler la “couleur” des objets du graphe, vous devrez ajuster soit l’attribut color = (la couleur extérieure), soit l’attribut fill = (la couleur intérieure). Une exception à cette configuration est geom_point(), où vous ne pouvez contrôler que color =, qui contrôle la couleur du point (intérieur et extérieur).\nLorsque vous définissez la couleur ou le remplissage, vous pouvez soit utiliser des noms de couleurs reconnus par R comme “red” (voir complete list ou entrer dans ?colors), ou une couleur hexadécimale spécifique comme \"#ff0505\".\n\n# histogramme - \nggplot(data = linelist, mapping = aes(x = age))+       # definir donnees et axes\n  geom_histogram(              # afficher l'histogramme\n    binwidth = 7,                # taille des bins\n    color = \"red\",               # couleur de ligne des bins\n    fill = \"lightblue\")          # couleur interieure des bins (fill) \n\n\n\n\n\n\n\n\nComme expliqué dans la page ggplot basics sur comment relier les données aux éléments graphiques, les attributs graphiques tels que fill = et color = peuvent être définis soit à l’extérieur d’une instruction mapping = aes() soit à l’intérieur d’une telle instruction. Si vous êtes en dehors de aes(), la valeur assignée doit être statique (par exemple, color = \"blue\") et s’appliquera à toutes les données tracées par le “geom”. Si elle est à l’intérieur, l’attribut doit être mise en correspondance avec une variable, comme color = hospital, et l’expression variera en fonction de la valeur de cette ligne dans les données. Quelques exemples :\n\n# Couleur statique pour les points et pour la ligne\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Couleur mappée sur une variable continue\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Couleur mappée sur une variable discrète\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# diagramme en barres, remplissage pour variable discrète, couleur pour la valeur statique\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScales\nUne fois que vous avez associé une variable à un attribut graphique (par exemple x =, y =, fill =, color =…) via un mappage, la manière de l’affichage de celui-ci pourra être modifié par les “scales” qui vont aussi définir la façon dont la légende correspondante va être affichée. On peut voir ci-dessus comment les “scales” peuvent être continues, discrètes, en format date, etc. en fonction du type/classe de variable assignée. Si vous avez plusieurs attributs affectés à des variables, votre graphique aura plusieurs “scales”.\nVous pouvez contrôler les “scqles” avec la fonction scales_() appropriée. Les fonctions “scales” de ggplot() ont 3 parties qui s’écrivent comme ceci : scale_AESTHETIC_METHOD().\n\nLa première partie, scale_(), est fixe.\nLa deuxième partie (“AESTHETIC”), doit être l’attribut pour lequel vous voulez ajuster l’échelle (_fill_, _shape_, _color_, _size_, _alpha_…) - les options ici incluent également _x_ et _y_.\nLa troisième partie (“METHOD”), sera soit _discrete(), continuous(), _date(), _gradient(), ou _manual() selon la classe de la variable et comment on veut la contrôler. Il en existe d’autres, mais ce sont les plus utilisées.\n\nAssurez-vous que vous utilisez la bonne fonction pour la “scale” ! Sinon, votre commande “scale” n’aura pas l’air de changer quoi que ce soit. Si vous avez plusieurs “scales”, vous pouvez utiliser plusieurs fonctions “scale” pour les ajuster ! Par exemple :\n\n\nArguments des “Scales”\nChaque type de “scale” a ses propres arguments, bien qu’il y ait quelques chevauchements. Interrogez la fonction comme ?scale_color_discrete dans la console R pour voir la documentation des arguments de la fonction.\nPour les “scales” continues, utilisez breaks = pour fournir une séquence de valeurs avec seq() (prenez to =, from =, et by = comme indiqué dans l’exemple ci-dessous. Définissez expand = c(0,0) pour éliminer l’espace de remplissage autour des axes (ceci peut être utilisé sur toute “scale” _x_ ou _y_.\nPour les “scales” discrètes, vous pouvez ajuster l’ordre d’apparition des modalités de la variable avec breaks =, et la façon dont les valeurs s’affichent avec l’argument labels =. Fournissez un vecteur caractère à chacun d’eux (voir l’exemple ci-dessous). Vous pouvez également écarter les valeurs manquantes NA facilement en définissant na.translate = FALSE.\nLes nuances des “scales” au format date sont traitées plus en détail dans la page Courbes épidémiques.\n\n\nRéglages manuels\nL’une des astuces les plus utiles consiste à utiliser des fonctions “scale” de façon “manuelle” pour assigner explicitement les couleurs comme vous le souhaitez. Ce sont des fonctions avec la syntaxe scale_xxx_manual() (par exemple scale_colour_manual() ou scale_fill_manual()). Chacun des arguments ci-dessous est démontré dans l’exemple de code ci-dessous.\n\nAttribuer des couleurs aux valeurs de données avec l’argument values = argument.\n\nSpécifier une couleur pour les données manquantes NA avec l’argument na.value =\n\nModifier la façon dont les valeurs sont écrites dans la légende avec l’argument labels =\n\nModifier le titre de la légende avec l’argument name =\n\nCi-dessous, nous créons un graphique à barres et montrons comment il apparaît par défaut, puis avec trois “scales” ajustées - la “scale” continue de l’axe des y, la “scale” discrète de l’axe des x, et l’ajustement manuel du remplissage (couleur intérieure de la barre).\n\n# BASELINE - pas d'ajustement de la scale\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n\n\n\n\n\n\n# SCALES AJUSTEES\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # simplifier le background\n  \n  scale_y_continuous(                # scale continue pour l'axe des y (comptage)\n    expand = c(0,0),                 # eviter un graphe trop rembourré\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # scale discrete pour l'axe des x (gender)\n    expand = c(0,0),                  # eviter un graphe trop rembourré\n    drop = FALSE,                     # afficher toutes les modalités de la variable facteur (même si non utilisée dans la représentation)\n    na.translate = FALSE,             # retirer les valeurs NA \n    labels = c(\"Died\", \"Recovered\"))+ # Changer l'affichage des valeurs\n    \n  \n  scale_fill_manual(                  # Spécifier Manuellement la couleur intérieure des barres\n    values = c(\"m\" = \"violetred\",     # préciser les couleurs que prennent chaque modalité\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          #  ré-étiqueter la légende (utiliser l'affectation \"=\" pour éviter les erreurs)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # titre de la legende\n    na.value = \"grey\"                 # assigner une couleur aux valeurs manquantes\n  )+\n  labs(title = \"Adjustment of scales\") # Préciser le titre\n\n\n\n\n\n\n\n\n\n\n“Scales” d’axes continus\nLorsque les données sont mappées sur les axes du graphique, ceux-ci peuvent également être ajustés à l’aide de commandes “scales’. Un exemple courant est l’ajustement de l’affichage d’un axe (par exemple l’axe des y) qui est mappé à une variable avec des données continues.\nNous pouvons vouloir ajuster la continuité ou l’affichage des valeurs dans le ggplot en utilisant scale_y_continuous(). Comme indiqué ci-dessus, utilisez l’argument breaks = pour fournir une séquence de valeurs de graduation qui serviront de “ruptures” le long de la “scale”. A cet argument, vous pouvez fournir un vecteur c() contenant le nombre de graduation souhaitées, ou vous pouvez fournir une séquence régulière de nombres en utilisant la fonction R base seq(). Cette fonction seq() accepte to =, from =, et by =.\n\n# BASELINE - pas d'ajustement de la scale\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfficher les pourcentages\nSi les valeurs de vos données originales sont des proportions, vous pouvez facilement les afficher sous forme de pourcentages avec “%” en fournissant labels = scales::percent dans votre commande scales, comme montré ci-dessous.\nUne alternative serait de convertir les valeurs en caractères et d’ajouter un caractère “%” à la fin, mais cette approche entraînera des complications car vos données ne seront plus des valeurs numériques continues.\n\n# Axe des y originellement en proportions\n#############################\nlinelist %&gt;%                                   # commencer avec les données d'intérêt: linelist\n  group_by(hospital) %&gt;%                       # agréger les données selon les modalités de la variable hopital\n  summarise(                                   # créer un résumé par colonnes\n    n = n(),                                     # compter le nombre total de lignes \n    deaths = sum(outcome == \"Death\", na.rm=T),   # compter le nombre de décès par groupe\n    prop_death = deaths/n) %&gt;%                   # calculer la proportion de décès par groupe\n  ggplot(                                      # tracer le graphique\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Afficher les proportions de l'axe des y avec des pourcentages\n########################################\nlinelist %&gt;%         \n  group_by(hospital) %&gt;% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %&gt;% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # afficher les proportions comme des pourcentages\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÉchelle logarithmique\nPour transformer un axe continu en échelle logarithmique, ajouter trans = \"log2\" à la commande “scale”. Pour les besoins de l’exemple, nous créons un jeu de données des régions avec leurs valeurs respectives de preparedness_index et de cas cumulés.\n\nplot_data &lt;- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data\n\n  region preparedness_index cases_cumulative\n1      A                8.8               15\n2      B                7.5               45\n3      C                3.4               80\n4      D                3.6               20\n5      E                2.1               21\n6      F                7.9                7\n7      G                7.0               51\n8      H                5.6               30\n9      I                1.0             1442\n\n\nLes cas cumulés pour la région “I” sont nettement supérieurs à ceux de toutes les autres régions. Dans de telles circonstances, vous pouvez choisir d’afficher l’axe des y en utilisant une échelle logarithmique afin que le lecteur puisse voir les différences entre les régions ayant moins de cas cumulés.\n\n# Axe y original\npreparedness_plot &lt;- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # points pour chaque region \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # ajouter les etiquette\n  theme_minimal()\n\npreparedness_plot                  # affichier le graphe originel\n\n\n# print with y-axis transformed\npreparedness_plot+                   # appeler le graphe créé ci-dessus\n  scale_y_continuous(trans = \"log2\") # ajouter la transformation pour l'axe des y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGradient de couleur\nLes fonctions “scales” pour un remplissage en gradient de couleur (dégradé) peuvent impliquer des nuances supplémentaires. Les valeurs par défaut sont généralement très agréables, mais vous pouvez souhaiter ajuster les valeurs, les coupures, etc.\nPour illustrer comment ajuster une “scale” de couleur continue, nous utiliserons un ensemble de données de la page Suivi des contacts qui contient les âges des cas et de leurs cas sources.\n\ncase_source_relationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_age, target_age) \n\nCi-dessous, nous produisons un diagramme “raster” de la densité des tuiles thermiques. Nous ne détaillerons pas comment (voir le lien dans le paragraphe ci-dessus) mais nous nous concentrerons sur la façon dont nous pouvons ajuster la “scale” de couleurs. Pour en savoir plus sur la fonction stat_density2d() ggplot2 ici. Notez que la “scale” de remplissage est continue.\n\ntrans_matrix &lt;- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\n\nNous allons maintenant montrer quelques variations de la “scale” de remplissage :\n\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaintenant, nous allons montrer quelques exemples d’ajustement du nombre de graduations de l’échelle :\n\nscale_fill_gradient() accepte deux couleurs (haut/bas).\nscale_fill_gradientn() accepte un vecteur de n’importe quelle longueur de couleurs à values = (les valeurs intermédiaires seront interpolées)\n\nUtiliser scales::rescale() pour ajuster la façon dont les couleurs sont positionnées le long du gradient ; il redonne à votre vecteur de positions une valeur comprise entre 0 et 1.\n\n\ntrans_matrix + \n  scale_fill_gradient(     # gradient à deux côtés\n    low = \"aquamarine\",    # petites valeurs\n    high = \"purple\",       # grandes valeurs\n    na.value = \"grey\",     # valeur des NA\n    name = \"Density\")+     # Titre de la Legende\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ couleurs à mapper\ntrans_matrix + \n  scale_fill_gradientn(    # gradient de 3 couleurs (low/mid/high)\n    colors = c(\"blue\", \"yellow\",\"red\") # fournir les couleurs dans un vecteur\n  )+\n  labs(title = \"3-color scale\")\n\n# Utiliser rescale() pour ajuster le positionnement des couleurs\ntrans_matrix + \n  scale_fill_gradientn(    # fournir autant de coleurs que l'on veut\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # positions des couleurs sont redimensionnées entre 0 and 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# utilisation de limites pour découper les valeurs qui prennent une couleur de remplissage\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPalettes\n\nColorbrewer et Viridis\nPlus généralement, si vous voulez des palettes prédéfinies, vous pouvez utiliser les fonctions scale_xxx_brewer ou scale_xxx_viridis_y.\nLes fonctions ‘brewer’ peuvent fonctionner à partir des palettes colorbrewer.org.\nLes fonctions ‘viridis’ s’inspirent des palettes viridis (adaptées aux daltoniens !), qui “fournissent des cartes de couleurs qui sont perceptiblement uniformes en couleur et en noir et blanc. Elles sont également conçues pour être perçues par des spectateurs souffrant de formes courantes de daltonisme.” (Pour en savoir plus, voir ici et ici). Préciser si la palette est discrète, continue ou binaire en le spécifiant à la fin de la fonction (par exemple, discrète est scale_xxx_viridis_d).\nIl est conseillé de tester votre graphe dans ce simulateur de daltonisme. Si vous avez un schéma de couleurs rouge/vert, essayez plutôt un schéma “chaud-froid” (rouge-bleu) comme décrit ici\nVoici un exemple tiré de la page ggplot basics, utilisant différents schémas de couleurs.\n\nsymp_plot &lt;- linelist %&gt;%                                         # commencer avec la linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # selectionner les colonnes\n  pivot_longer(                                                  # pivoter en format long\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # remplacer les valeurs manquantes\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  ggplot(                                                        # commencer le ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  #afficher le graphe avec les couleurs par defaut\n\n#################################\n# afficher le graphe avec les couleurs specifiées manuellement\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # definir explicitement les couleurs\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # ordonner les facteurs correctement\n    name = \"\"                           # ne pas afficher de titre pour la légende\n\n  ) \n\n#################################\n# afficher avec les couleurs discretes viridis\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#changement-de-lordre-des-variables-discrètes",
    "href": "new_pages/ggplot_tips.fr.html#changement-de-lordre-des-variables-discrètes",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.3 Changement de l’ordre des variables discrètes",
    "text": "31.3 Changement de l’ordre des variables discrètes\nChanger l’ordre dans lequel les variables discrètes apparaissent est souvent difficile à comprendre pour les personnes qui ne connaissent pas les graphiques ggplot2. Il est cependant facile de comprendre comment faire cela une fois que vous avez compris comment ggplot2 gère les variables discrètes en intrinsèque. En général, si une variable discrète est utilisée, elle est automatiquement convertie en un type factor - qui ordonne les facteurs par ordre alphabétique par défaut. Pour gérer cela, vous devez simplement réorganiser les niveaux de facteurs (modalités) pour refléter l’ordre dans lequel vous souhaitez qu’ils apparaissent dans le graphique. Pour des informations plus détaillées sur la façon de réorganiser les objets facteur, voir la section Variables de type facteur du guide.\nNous pouvons voir un exemple commun en utilisant les groupes d’âge - par défaut le groupe d’âge 5-9 sera placé au milieu des groupes d’âge (vu l’ordre alphanumérique), mais nous pouvons le déplacer derrière le groupe d’âge 0-4 du graphique en réordonnant les facteurs.\n\nggplot(\n  data = linelist %&gt;% drop_na(age_cat5),                         # supprimer les lignes où age_cat5 est manquant\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # reordonner la var facteur\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n31.3.0.1 ggthemr\nPensez également à utiliser le “package” (extension) ggthemr. Vous pouvez télécharger ce “package” sur Github en suivant les instructions ici. Il propose des palettes très agréables d’un point de vue esthétique, mais sachez que celles-ci ont généralement un nombre maximal de valeurs qui peut être limitatif si vous voulez plus de 7 ou 8 couleurs.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#courbes-de-niveau",
    "href": "new_pages/ggplot_tips.fr.html#courbes-de-niveau",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.4 Courbes de niveau",
    "text": "31.4 Courbes de niveau\nLes courbes de niveau sont utiles lorsque vous avez de nombreux points qui risquent de se superposer les uns les autres lors de la représentation (“surtraçage”). Elles permettent une différente visualisation de la répartition des points dans l’espace. Les données de cas utilisées ci-dessus sont à nouveau représentées, mais plus simplement en utilisant stat_density2d() et stat_density2d_filled() pour produire des niveaux de contour discrets - comme une carte topographique. Pour en savoir plus sur les statistiques, cliquez ici.\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#distributions-marginales",
    "href": "new_pages/ggplot_tips.fr.html#distributions-marginales",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.5 Distributions marginales",
    "text": "31.5 Distributions marginales\nPour montrer les distributions sur les rebords d’un nuage de points geom_point(), vous pouvez utiliser le “package” ggExtra et sa fonction ggMarginal(). Sauvegardez votre ggplot original comme un objet, puis passez-le à ggMarginal() comme indiqué ci-dessous. Voici les arguments clés :\n\nVous devez spécifier le type = comme étant soit un histogramme (“histogram”), une densité (“density”), un “boxplot”, un graphe en violon (“violin”), ou un “densigram”).\n\nPar défaut, les graphiques marginaux apparaissent pour les deux axes. Vous pouvez définir margins = sur “x” ou “y” si vous n’en voulez qu’un seul.\n\nParmi les autres arguments facultatifs, citons fill = (couleur de la barre), color = (couleur de la ligne), size = (taille du tracé par rapport à la taille de la marge, donc plus le nombre est grand, plus le tracé marginal est petit).\n\nVous pouvez fournir d’autres arguments spécifiques aux axes à xparams = et yparams =. Par exemple, pour avoir des tailles de cases d’histogramme différentes, comme indiqué ci-dessous.\n\nVous pouvez faire en sorte que les tracés marginaux reflètent les groupes (les variables qui ont été assignées à color = dans l’attribut de votre ggplot()). Si c’est le cas, définissez l’argument ggMarginal() groupColour = ou groupFill = à TRUE, comme indiqué ci-dessous.\nPour en savoir plus, consultez cette vignette, la R Graph Gallery ou la documentation de la fonction R ?ggMarginal.\n\n# Installer/charger ggExtra\npacman::p_load(ggExtra)\n\n# Diagramme de dispersion basique du poids et de l'âge\nscatter_plot &lt;- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n\nPour ajouter des histogrammes marginaux, utilisez type = \"histogram\". Vous pouvez éventuellement définir groupFill = TRUE pour obtenir des histogrammes empilés.\n\n# le graphe d'avant avec les histogrammes de chaque variable présentés sur les rebords\nggMarginal(\n  scatter_plot,                     # ajouter les histogrammes marginaux\n  type = \"histogram\",               # specifier qu'on veut un  histogramme\n  fill = \"lightblue\",               # couleur intérieure des barres de l'histogramme\n  xparams = list(binwidth = 10),    # autres parametres pour l'axe des x\n  yparams = list(binwidth = 5))     # autres parametres pour l'axe des y\n\n\n\n\n\n\n\n\nGraphique de densité marginale avec valeurs groupées/colorées :\n\n# Scatter plot, coloriée selon la variable d'interet (le sexe)\n# la variable d'interet est assignee à l'argument \"color\" dans ggplot. groupFill dans ggMarginal est fixée à TRUE\nscatter_plot_color &lt;- ggplot(data = linelist %&gt;% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n\n\n\n\n\n\n\n\nDéfinissez l’argument size = pour ajuster la taille relative du graphe marginal. Plus le nombre est petit, plus le graphe marginal est grand. Vous pouvez également définir color = au besoin.\nCi-dessous se trouve un boxplot marginal, avec une démonstration de l’utilisation de l’argument margins = pour avoir le graphique marginal que sur un seul axe :\n\n# avec boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # afficher un graphe marginal uniquement sur l'axe x\n  type = \"boxplot\")",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#étiquetage-pratiqueintelligent",
    "href": "new_pages/ggplot_tips.fr.html#étiquetage-pratiqueintelligent",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.6 Étiquetage pratique/intelligent",
    "text": "31.6 Étiquetage pratique/intelligent\nDans ggplot2, il est également possible d’ajouter du texte aux graphiques. Cependant, cela s’accompagne d’une limitation notable : les étiquettes de texte entrent souvent en conflit avec les points de données dans un graphique, ce qui les rend désordonnées ou difficiles à lire. Il n’y a pas de moyen idéal de gérer ce problème dans le “package” de base, mais il existe un module complémentaire ggplot2, connu sous le nom de ggrepel, qui rend la gestion de ce problème très simple !\nLe “package” ggrepel fournit deux nouvelles fonctions, geom_label_repel() et geom_text_repel(), qui remplacent geom_label() et geom_text(). Utilisez simplement ces fonctions à la place des fonctions de base pour produire des étiquettes soignées. Dans la fonction, mappez l’attribut graphique aes() comme toujours, mais incluez l’argument label = auquel vous fournissez un nom de variable contenant les valeurs que vous voulez afficher (par exemple l’id du patient, ou le nom, etc.). Vous pouvez créer des étiquettes plus complexes en combinant des variables et des retours à la ligne (\\n) dans str_glue() comme indiqué ci-dessous.\nTIP: Quelques conseils\n\nUtilisez min.segment.length = 0 pour toujours dessiner des segments de ligne, ou min.segment.length = Inf pour ne jamais les dessiner.\n\nUtilisez size = en dehors de aes() pour définir la taille du texte.\n\nUtilisez force = pour modifier le degré de répulsion entre les étiquettes et leurs points respectifs (la valeur par défaut est 1).\n\nIncluez fill = dans aes() pour que l’étiquette soit colorée par la valeur.\n\nUne lettre “a” peut apparaître dans la légende - ajoutez guides(fill = guide_legend(override.aes = aes(color = NA))) pour la supprimer\n\n\nPour en savoir plus, consultez ce tutoriel très détaillé.\n\npacman::p_load(ggrepel)\n\nlinelist %&gt;%                                               # commencer avec les données d'intérêt linelist\n  group_by(hospital) %&gt;%                                   # agréger les données par les différentes modalités de la variable hopital\n  summarise(                                               # créer une nouvelles base avec les données résumées par hopital\n    n_cases = n(),                                           # nombre de cas pq hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # délai moyen par hopital\n  ) %&gt;% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # envoyer la base modifiée dans la fonction ggplot\n  geom_point(size = 2)+                                    # ajouter les points\n  geom_label_repel(                                        # ajouter les étiquettes des points \n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # comment les étiquettes vont apparaître\n      ), \n    size = 3,                                              # taille du texte pour les étiquettes\n    min.segment.length = 0)+                               # afficher  tous les segments de ligne              \n  labs(                                                    # ajouter des étiquettes aux axes \n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\n\n\n\n\n\n\n\n\nVous pouvez étiqueter seulement un sous-ensemble de points de données - en utilisant la syntaxe standard ggplot() pour fournir différentes data = pour chaque couche geom du graphique. Ci-dessous, tous les cas sont représentés, mais seulement quelques-uns sont étiquetés.\n\nggplot()+\n  # Tous les points en gris\n  geom_point(\n    data = linelist,                                   # la base complète fournie à ggplot\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # gris et semi-transparent\n  \n  # Quelques points en noir\n  geom_point(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # filtrer les données à représenter\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # couleur par défaut (noir) et non transparente\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # filtrer les données pour les étiquettes à afficher\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # couleurs des boites d'étiquettes selon outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # étiquette créée avec str_glue()\n    min.segment.length = 0) +                                  # afficher  tous les segments de ligne \n  \n  # supprimer lettre \"a\" de l'intérieur des boites\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # étiquettes des axes\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#axes-de-temps",
    "href": "new_pages/ggplot_tips.fr.html#axes-de-temps",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.7 Axes de temps",
    "text": "31.7 Axes de temps\nTravailler avec des axes temporels dans ggplot peut sembler intimidant, mais est très facile grâce à quelques fonctions clés. Rappelez-vous que lorsque vous travaillez avec le temps ou la date, vous devez vous assurer que les variables correctes sont formatées en tant que classe de date ou de “datetime” - voir la page Travailler avec les dates pour plus d’informations à ce sujet, ou la page Courbes épidémiques (section ggplot) pour des exemples.\nL’ensemble de fonctions les plus utiles pour travailler avec des dates dans ggplot2 sont les fonctions d’échelle (scale_x_date(), scale_x_datetime()), et leurs fonctions d’axe des ordonnées. Ces fonctions vous permettent de définir la fréquence des étiquettes d’axe et le format des étiquettes d’axe. Pour savoir comment formater les dates, consultez à nouveau la section travailler avec les dates ! Vous pouvez utiliser les arguments date_breaks et date_labels pour spécifier l’apparence des dates :\n\ndate_breaks vous permet de spécifier la fréquence des ruptures d’axe (le nombre de graduations) - vous pouvez passer une chaîne ici (par exemple \"3 months\", ou “2 days\")\ndate_labels vous permet de définir le format dans lequel les dates sont affichées. Vous pouvez passer une chaîne de format de date à ces arguments (par exemple, \"%b-%d-%Y\") :\n\n\n# faire une courbe épi en fonction de la date d'apparition des symptômes, lorsque cela est disponible\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # graduation par mois\n    date_breaks = \"1 months\",\n    # les étiquettes vont afficher le mois puis le jour\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\nUne solution facile pour obtenir des étiquettes de date efficaces sur l’axe des x est d’assigner l’argument labels = dans scale_x_date() à la fonction label_date_short() du “package” scales. Cette fonction construira automatiquement des étiquettes de date efficaces (pour en savoir plus, cliquez ici). Un avantage supplémentaire de cette fonction est que les étiquettes s’adapteront automatiquement à l’évolution de vos données dans le temps, des jours aux semaines, aux mois et aux années.\nVous trouverez un exemple complet dans la section de la page Courbes épidémiques sur les étiquettes de date à plusieurs niveaux, mais un exemple rapide est présenté ci-dessous pour référence :\n\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    labels = scales::label_date_short()  # étiquettes de date plus pratiques d'un coup\n  )+\n  theme_classic()",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#mise-en-évidence",
    "href": "new_pages/ggplot_tips.fr.html#mise-en-évidence",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.8 Mise en évidence",
    "text": "31.8 Mise en évidence\nLa mise en évidence d’éléments spécifiques dans un graphique est un moyen utile d’attirer l’attention sur une instance spécifique d’une variable tout en fournissant des informations sur la dispersion de l’ensemble des données. Bien que cela ne soit pas facile à faire dans la base ggplot2, il existe un “package” externe qui peut aider à le faire, connu sous le nom de gghighlight. Il est facile à utiliser dans la syntaxe ggplot.\nLe “package” gghighlight utilise la fonction gghighlight() pour obtenir cet effet. Pour utiliser cette fonction, fournissez une déclaration logique à la fonction - cela peut avoir des résultats assez flexibles, mais ici nous allons montrer un exemple de la distribution de l’âge des cas dans notre liste linéaire, en les mettant en évidence par résultat.\n\n# charger gghighlight\nlibrary(gghighlight)\n\n# remplacer les valeurs NA avec \"unknown\" dans la variable \"outcome\"\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produire un histogramme de tous les cas par age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # mettre en évidence les cas ou le patient est décédé\n\n\n\n\n\n\n\n\nCela fonctionne aussi très bien avec les fonctions de “facet” - cela permet à l’utilisateur de produire des graphiques répétitifs (selon les modalités la variable d’intérêt) mais cette fois au lieu que chaque sous-graphe concerne une modalité particulière de la variable sur laquelle le “faceting” est fait, tout sera représenté dans chaque sous-graphe mais avec les données de la modalité d’intérêt qui seront mises en évidence avec une couleur spécifique! Ci-dessous, nous comptons les cas par semaine et traçons les courbes épidémiques par hôpital (color = et facet_wrap() réglé sur la colonne hospital).\n\n# produire un histogramme de tous les cas par age\nlinelist %&gt;% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %&gt;% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # mettre en évidence les cas ou le patient est décédé\n  facet_wrap(~hospital)                              # créer les \"facets\" par outcome",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#représenter-différentsmultiples-jeux-de-données",
    "href": "new_pages/ggplot_tips.fr.html#représenter-différentsmultiples-jeux-de-données",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.9 Représenter différents/multiples jeux de données",
    "text": "31.9 Représenter différents/multiples jeux de données\nNotez qu’il peut être difficile d’aligner correctement les axes pour tracer les données de plusieurs ensembles de données différents dans le même graphique. Considérez l’une des stratégies suivantes :\n\nFusionnez les données avant de les représenter, et convertissez-les au format “long” avec une colonne reflétant l’ensemble de données.\nUtilisez cowplot ou un logiciel similaire pour combiner deux graphiques (voir ci-dessous).",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#combiner-des-graphiques",
    "href": "new_pages/ggplot_tips.fr.html#combiner-des-graphiques",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.10 Combiner des graphiques",
    "text": "31.10 Combiner des graphiques\nDeux “packages” très utiles pour combiner des graphiques sont cowplot et patchwork. Dans cette page, nous nous concentrerons principalement sur cowplot, avec une utilisation occasionnelle de patchwork.\nVoici l’introduction au cowplot en ligne. Vous pouvez lire la documentation plus complète de chaque fonction ici. Nous couvrirons ci-dessous quelques-uns des cas d’utilisation et des fonctions les plus courantes.\nLe “package” cowplot fonctionne en tandem avec ggplot2 - essentiellement, vous l’utilisez pour arranger et combiner les ggplots et leurs légendes en figures composées. Il peut également accepter les graphiques R base.\n\npacman::p_load( #charger les packages dont on aura besoin\n  tidyverse,      # pour manipuler et visualiser des données\n  cowplot,        # pour combiner des graphes\n  patchwork       # pour combiner des graphes\n)\n\nBien que le “faceting” (décrit dans la page bases de ggplot) soit une approche pratique de la représentation graphique, il est parfois impossible d’obtenir les résultats souhaités avec son approche relativement restrictive. Dans ce cas, vous pouvez choisir de combiner des graphiques en les collant ensemble dans un graphique plus grand. Il y a trois packages bien connus qui sont parfaits pour cela - cowplot, gridExtra, et patchwork. Cependant, ces package font largement les mêmes choses, donc nous nous concentrerons sur cowplot pour cette section.\n\nplot_grid()\nLe package cowplot a une gamme assez large de fonctions, mais l’utilisation la plus simple peut être réalisée par l’utilisation de plot_grid(). Il s’agit en fait d’un moyen d’arranger des graphiques prédéfinis dans une formation en grille. Nous pouvons travailler sur un autre exemple avec le jeu de données sur le paludisme - ici, nous pouvons représenter le nombre total de cas par district, et également montrer la courbe épidémique dans le temps.\n\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# diagramme en barres du nombre total de cas par district\np1 &lt;- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# courbe epidemique en fonction du temps\np2 &lt;- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 colonne et deux lignes - empilées l'une sur l'autre\n                   ncol = 1,\n                   nrow = 2,\n                   # le graphe du haut fait 2/3 de la hauteur du second\n                   rel_heights = c(2, 3))\n\n\n\n\n\n\n\n\n\n\nCombiner les légendes\nSi vos graphiques ont la même légende, il est relativement simple de les combiner. Utilisez simplement l’approche cowplot ci-dessus pour combiner les graphiques, mais supprimez la légende de l’une d’entre elles (pour éviter la dé-duplication).\nSi vos graphiques ont des légendes différentes, vous devez utiliser une autre approche :\n\nCréez et enregistrez vos graphiques sans légendes en utilisant theme(legend.position = \"none\").\nExtrayez les légendes de chaque graphe en utilisant get_legend() comme indiqué ci-dessous - mais extrayez les légendes des graphes modifiés pour afficher réellement la légende.\nCombinez les légendes dans un panneau de légendes.\nCombinez les graphes et le panneau de légendes.\n\nPour la démonstration, nous montrons les deux graphiques séparément, puis disposés dans une grille avec leurs propres légendes (utilisation laide et inefficace de l’espace) :\n\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\n\nVoici à quoi ressemblent les deux graphiques lorsqu’ils sont combinés en utilisant plot_grid() sans combiner leurs légendes :\n\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n\n\n\n\n\n\n\n\nEt maintenant, nous montrons comment combiner les légendes. Essentiellement, ce que nous faisons est de définir chaque graphique sans sa légende (theme(legend.position = \"none\"), et ensuite nous définissons la légende de chaque graphe séparément, en utilisant la fonction get_legend() de cowplot. Lorsque nous extrayons la légende du graphe sauvegardé, nous devons ajouter + la légende à nouveau, y compris en spécifiant le placement (\"right\") et des ajustements plus petits pour l’alignement des légendes et de leurs titres. Ensuite, nous combinons les légendes ensemble verticalement, puis nous combinons les deux graphes avec les légendes nouvellement combinées. Voilà !\n\n# Définir graphe 1 sans legende\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Définir graphe 2 sans legende\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extraire légende de p1 (de p1 + legend)\nleg_p1 &lt;- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extraire légende verticale\n                                      legend.justification = c(0,0.5))+ # pour bien  aligner la légende\n                                labs(fill = \"Outcome\"))                 # titre de la légende\n# extraire légende de p2 (de p2 + legend)\nleg_p2 &lt;- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extraire légende verticale   \n                                      legend.justification = c(0,0.5))+  # pour bien  aligner la légende\n                                labs(fill = \"Age Category\"))             # titre de la légende\n\n# créer un tracé vierge pour l'alignement de la légende\n#blank_p &lt;- patchwork::plot_spacer() + theme_void()\n\n# créer un panneau de légendes, qui peut être superposé (ou utiliser l'espaceur commenté ci-dessus)\nlegends &lt;- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combiner les deux graphiques et le panneau de légendes combiné\ncombined &lt;- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # afficher ce qui est enregistré sous \"combined\"\n\n\n\n\n\n\n\n\nCette solution a été tirée de cette pubication avec une correction mineure pour aligner les légendes inspiré de cette pubication.\nNOTE: Note amusante - le “cow” dans cowplot vient du nom du créateur - Claus O. Wilke.\n\n\nEncastrer des graphiques\nVous pouvez encastrer un graphique dans un autre en utilisant cowplot. Voici les points à prendre en compte :\n\nDéfinissez le graphique principal avec theme_half_open() de cowplot ; il peut être préférable d’avoir la légende en haut ou en bas.\nDéfinissez le graphique à encastrer. Le mieux est d’avoir un graphe où vous n’avez pas besoin de légende. Vous pouvez supprimer les éléments du thème du graphe avec element_blank() comme indiqué ci-dessous.\nCombinez-les en appliquant ggdraw() au graphe principal, puis en ajoutant draw_plot() au graphe à encastrer et en spécifiant les coordonnées (x et y du coin inférieur gauche), la hauteur et la largeur en tant que proportion par rapport au graphe principal.\n\n\n# Définir graphe principal\nmain_plot &lt;- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Définir graphe à encastrer\ninset_plot &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combiner graphe principal avec celui à encastrer\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)\n\n\n\n\n\n\n\n\nCette technique est expliquée plus en détail dans ces deux vignettes:\nWilke lab\nDocumentation draw_plot()",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#axes-doubles",
    "href": "new_pages/ggplot_tips.fr.html#axes-doubles",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.11 Axes doubles",
    "text": "31.11 Axes doubles\nUn axe y secondaire est souvent un ajout demandé à un graphique ggplot2. Bien que la validité de tels graphiques fasse l’objet d’un débat animé au sein de la communauté de la visualisation de données, et qu’ils ne sont souvent pas recommandés, il se peut que vous devriez y avoir recours. Nous présentons ci-dessous une méthode pour y parvenir : l’utilisation du package cowplot pour combiner deux graphiques séparés.\nCette approche implique la création de deux graphiques distincts - l’un avec un axe y sur la gauche, et l’autre avec un axe y sur la droite. Tous deux utiliseront un theme_cowplot() spécifique et doivent avoir le même axe des x. Ensuite, dans une troisième commande, les deux graphiques sont alignés et superposés l’un sur l’autre. Les fonctionnalités de cowplot, dont celle-ci n’est qu’une partie, sont décrites en profondeur sur ce site.\nPour démontrer cette technique, nous allons superposer la courbe épidémique avec une ligne représentant le pourcentage hebdomadaire de patients décédés. Nous utilisons cet exemple parce que l’alignement des dates sur l’axe des x est plus complexe que, par exemple, l’alignement d’un graphique à barres avec un autre graphique. Quelques points à noter :\n\nL’épicurve et la ligne sont agrégées en semaines avant d’être tracées et les date_breaks et les date_labels sont identiques - nous faisons cela pour que les axes x des deux graphiques soient les mêmes lorsqu’ils sont superposés.\nL’axe des y est déplacé vers la droite pour le graphique 2 avec l’argument position = de scale_y_continuous().\nLes deux graphiques utilisent theme_cowplot().\n\nNotez qu’il existe un autre exemple de cette technique sur la page Courbes épidémiques - superposition de l’incidence cumulée sur l’épicurve.\nTracer le graphique 1\nCeci reste essentiellement une épicurve. Nous utilisons geom_area() juste pour démontrer son utilisation (aire sous une ligne, par défaut).\n\npacman::p_load(cowplot)            # charger/installer cowplot au besoin\n\np1 &lt;- linelist %&gt;%                 # sauvegarder le graphe comme un objet nommé p1\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # afficher p1\n\n\n\n\n\n\n\n\nTracer le graphique 2\nCréez le deuxième graphique qui montre une ligne du pourcentage hebdomadaire de décès.\n\np2 &lt;- linelist %&gt;%         # sauvegarder le graphe comme un objet nommé p2\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %&gt;% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # afficher p2\n\n\n\n\n\n\n\n\nMaintenant, nous alignons le graphique en utilisant la fonction align_plots(), en spécifiant l’alignement horizontal et vertical (“hv”, qui peut aussi être “h”, “v”, “none”). Nous spécifions également l’alignement de tous les axes (haut, bas, gauche et droite) avec “tblr”. Il en résulte un objet de classe liste (avec 2 éléments).\nEnsuite, nous dessinons les deux graphiques ensemble en utilisant ggdraw() (de cowplot) et en référençant les deux parties de l’objet aligned_plots.\n\naligned_plots &lt;- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # aligner les deux graphes et les sauvegarder en tant que liste\naligned_plotted &lt;- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # les superposer et sauvegarder le  visuel résultant\naligned_plotted                                                                # afficher les graphiques superposés",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#packages-pour-vous-aider",
    "href": "new_pages/ggplot_tips.fr.html#packages-pour-vous-aider",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.12 Packages pour vous aider",
    "text": "31.12 Packages pour vous aider\nIl existe quelques packages R très intéressants, spécialement conçus pour vous aider à naviguer dans ggplot2 :\n\nFaire du ggplot2 via clique-boutton avec equisse\nequisse fournit une interface graphique pour la construction de graphiques avec ggplot2. “Cet addin vous permet d’explorer interactivement vos données en les visualisant avec le package ggplot2. Il vous permet de dessiner des diagrammes en barres, des courbes, des diagrammes de dispersion, des histogrammes, des boxplot et des objets sf, puis d’exporter le graphique ou de récupérer le code pour reproduire le graphique.”\nInstallez puis lancez l’addin via le menu RStudio ou avec esquisse::esquisser().\nVoir la page Github\nDocumentation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#divers",
    "href": "new_pages/ggplot_tips.fr.html#divers",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.13 Divers",
    "text": "31.13 Divers\n\nAffichage numérique\nVous pouvez désactiver la notation scientifique en exécutant cette commande avant le graphique.\n\noptions(scipen=999)\n\nOu appliquez number_format() du package scales à une valeur ou une colonne spécifique, comme indiqué ci-dessous.\nUtilisez les fonctions du package scales pour ajuster facilement l’affichage des nombres. Ces fonctions peuvent être appliquées aux variables de votre jeu de données, mais sont présentées sur des nombres individuels pour les besoins de l’exemple.\n\nscales::number(6.2e5)\n\n[1] \"620 000\"\n\nscales::number(1506800.62,  accuracy = 0.1,)\n\n[1] \"1 506 800.6\"\n\nscales::comma(1506800.62, accuracy = 0.01)\n\n[1] \"1,506,800.62\"\n\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")\n\n[1] \"1.506.800,62\"\n\nscales::percent(0.1)\n\n[1] \"10%\"\n\nscales::dollar(56)\n\n[1] \"$56\"\n\nscales::scientific(100000)\n\n[1] \"1e+05\"",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.fr.html#ressources",
    "href": "new_pages/ggplot_tips.fr.html#ressources",
    "title": "31  Trucs et Astuces avec ggplot",
    "section": "31.14 Ressources",
    "text": "31.14 Ressources\nInspiration ggplot graph gallery\nGuide pour la présentation des données de surveillance\nFacets et étiquettes Fonction d’étiquetage\nAjuster l’ordre des modalités des variables de type facteur fct_reorder\nfct_inorder\nRé-arranger un boxplot\nRé-ordonner une variable dans ggplot2\nR for Data Science - Factors\nLégendes\nAjuster l’ordre d’une légende\nNotes de bas de graphique: Alignement des notes du graphique\nEtiquettes\nggrepel\nAnti-sèches\nBeautiful plotting with ggplot2",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Trucs et Astuces avec ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html",
    "href": "new_pages/epicurves.fr.html",
    "title": "32  Courbes épidémiques",
    "section": "",
    "text": "32.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#préparation",
    "href": "new_pages/epicurves.fr.html#préparation",
    "title": "32  Courbes épidémiques",
    "section": "",
    "text": "Paquets\nCe chunk de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installs avec library() de base R. Voir la page sur R basics pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio,         # import/export de fichiers\n  here,        # chemins de fichiers relatifs \n  lubridate,   # travailler avec des dates/epiweeks\n  aweek,       # paquet alternatif pour travailler avec les dates/semaines\n  #incidence2, # paquet alternatif \n  #i2extras,    # supplément à incidence2\n  scales,      # fonctions utiles pour les échelles d'axes\n  stringr,     # recherche et manipulation de chaînes de caractères\n  forcats,     # travail avec des facteurs\n  RColorBrewer,# palettes de couleurs de colorbrewer2.org\n  tidyverse    # gestion des données + graphiques ggplot2\n) \n\n\n\nImporter des données\nDeux exemples de jeux de données sont utilisés dans cette section :\n\nListe de cas individuels d’une épidémie simulée.\n\nComptage agrégé par hôpital à partir de la même épidémie simulée.\n\nLes jeux de données sont importés à l’aide de la fonction import() du paquetage rio. Voir la page Importation et exportation pour les différentes maniéres d’importer des données.\nListe de cas\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour les suivre pas à pas, consultez les instructions de la page Télécharger le manuel et les données. Nous supposons que le fichier est dans le répertoire de travail, donc aucun sous-dossier n’est spécifié dans ce chemin de fichier.\n\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nLes 50 premiéres lignes sont affichées ci-dessous.\n\n\n\n\n\n\nComptes de cas agrégés par hôpital\nPour les besoins du manuel, le jeu de données des comptages hebdomadaires agrégés par hôpital est créé à partir de la linelist avec le code suivant.\n\n# Importez les données de comptage dans R\ncount_data &lt;- linelist %&gt;% \n  group_by(hospital, date_hospitalisation) %&gt;% \n  summarize(n_cases = dplyr::n()) %&gt;% \n  filter(date_hospitalisation &gt; as.Date(\"2013-06-01\")) %&gt;% \n  ungroup()\n\nLes 50 premiéres lignes sont affichées ci-dessous :\n\n\n\n\n\n\n\n\nDéfinir les paramétres\nPour la production d’un rapport, vous pouvez souhaiter définir des paramétres modifiables tels que la date à laquelle les données sont actuelles (la “date des données”). Vous pouvez ensuite faire référence à l’objet data_date dans votre code lorsque vous appliquez des filtres ou dans des légendes dynamiques.\n\n## définit la date du rapport pour le rapport\n## note : peut étre défini à Sys.Date() pour la date actuelle\ndata_date &lt;- as.Date(\"2015-05-15\")\n\n\n\nVérifier les dates\nVérifiez que chaque colonne de date pertinente est de la classe Date et posséde une plage de valeurs appropriée. Vous pouvez le faire simplement en utilisant hist() pour les histogrammes, ou range() avec na.rm=TRUE, ou avec ggplot() comme ci-dessous.\n\n# vérifier la plage de dates d'apparition\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#epicurves-avec-ggplot2",
    "href": "new_pages/epicurves.fr.html#epicurves-avec-ggplot2",
    "title": "32  Courbes épidémiques",
    "section": "32.2 Epicurves avec ggplot2",
    "text": "32.2 Epicurves avec ggplot2\nL’utilisation de ggplot() pour construire votre épicurve permet plus de flexibilité et de personnalisation, mais nécessite plus d’efforts et de compréhension du fonctionnement de ggplot().\nContrairement à l’utilisation du paquet incidence2, vous devez manuellement contrôler l’agrégation des cas par temps (en semaines, mois, etc.) et les intervalles des étiquettes sur l’axe des dates. Ceci doit étre soigneusement géré.\nCes exemples utilisent un sous-ensemble de l’ensemble de données linelist - seulement les cas de l’hôpital central.\n\ncentral_data &lt;- linelist %&gt;% \n  filter(hospital == \"Central Hospital\")\n\nPour produire une épicurve avec ggplot(), il y a trois éléments principaux :\n\nUn histogramme, avec les cas de la liste de lignes agrégés en “bins” distingués par des points de “rupture” spécifiques.\n\nDes échelles pour les axes et leurs étiquettes\n\nDes thèmes pour l’apparence du graphique, y compris les titres, les étiquettes, les légendes, etc.\n\n\nSpécifier les cas en bacs\nNous montrons ici comment spécifier la façon dont les cas seront agrégés dans des cases d’histogramme (“barres”). Il est important de reconnaétre que l’agrégation des cas dans les cases de l’histogramme n’est pas nécessairement les mêmes intervalles que les dates qui apparaîtront sur l’axe des abscisses.\nVous trouverez ci-dessous le code le plus simple pour produire des épicurves quotidiennes et hebdomadaires.\nDans la commande globale ggplot(), le jeu de données est fourni avec data =. Sur cette base, la géométrie d’un histogramme est ajoutée avec un +. Dans la commande geom_histogram(), nous mappons l’esthétique de telle sorte que la colonne date_onset soit mappée sur l’axe des x. Toujours dans geom_histogram() mais non dans aes(), nous définissons la binwidth = des bins de l’histogramme, en jours. Si cette syntaxe ggplot2 est confuse, revoyez la page sur les bases de ggplot.\nCAUTION: Tracer des cas hebdomadaires en utilisant binwidth = 7 fait démarrer le premier bin de 7 jours au premier cas, qui pourrait étre n’importe quel jour de la semaine ! Pour créer des semaines spécifiques, voir la section ci-dessous .\n\n# quotidien \nggplot(data = central_data) + # set data\n  geom_histogram( # ajouter un histogramme\n    mapping = aes(x = date_onset), # map date column to x-axis\n    binwidth = 1)+ # cas groupés par 1 jour \n  labs(title = \"Central Hospital - Quotidiennement\") # titre\n\n# hebdomadaire\nggplot(data = central_data) + # set data \n  geom_histogram( # ajouter un histogramme\n      mapping = aes(x = date_onset), # mappage de la colonne date sur l'axe des x\n      binwidth = 7)+ # cas classés tous les 7 jours, à partir du premier cas ( !) \n  labs(title = \"Central Hospital - Tranches de 7 jours, à partir du premier cas\") # titre\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotons que le premier cas de cet ensemble de données de l’hôpital Central a vu ses symptômes apparaître le :\n\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")\n\n[1] \"Thursday 01 May, 2014\"\n\n\nPour spécifier manuellement les ruptures des cases de l’histogramme, n’utilisez pas l’argument binwidth =, mais fournissez un vecteur de dates à breaks =..\ncréez le vecteur de dates avec la fonction R base seq.Date(). Cette fonction attend les arguments to =, from =, et by =. Par exemple, la commande ci-dessous renvoie les dates mensuelles commençant le 15 janvier et se terminant le 28 juin.\n\nmonthly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks # print\n\n [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\"\n [6] \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\"\n[11] \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\"\n[16] \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n\n\nCe vecteur peut étre fourni à geom_histogram() sous la forme breaks = :\n\n# mensuel \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+ # fournit le vecteur prédéfini de breaks                    \n  labs(title = \"Bins de cas mensuels\") # titre\n\n\n\n\n\n\n\n\nUne simple séquence de date hebdomadaire peut étre retournée en définissant by = \"week\". Par exemple :\n\nweekly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n\nUne alternative à la fourniture de dates de début et de fin spécifiques consiste à écrire un code dynamique pour que les bacs hebdomadaires commencent le lundi précédant le premier cas. **Nous utiliserons ces vecteurs de date dans les exemples ci-dessous.\n\n# Séquence de dates hebdomadaires du lundi pour CENTRAL HOSPITAL\nweekly_breaks_central &lt;- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi avant le premier cas\n  to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi aprés la derniére affaire\n  by = \"week\")\n\nDécortiquons le code plutôt déconcertant ci-dessus :\n\nLa valeur “from” (date la plus ancienne de la séquence) est crée comme suit : la valeur minimale de la date (min() avec na.rm=TRUE) dans la colonne date_onset est introduite dans floor_date() du paquet lubridate. floor_date() défini sur “week” renvoie la date de début de la “semaine” de ce cas, étant donné que le jour de début de chaque semaine est un lundi (week_start = 1).\n\nDe même, la valeur “to” (date de fin de la séquence) est créée en utilisant la fonction inverse ceiling_date() pour retourner le lundi aprés le dernier cas.\n\nL’argument “by” de seq.Date() peut étre défini sur un nombre quelconque de jours, de semaines ou de mois.\n\nUtilisez week_start = 7 pour les semaines de dimanche.\n\nComme nous utiliserons ces vecteurs de date tout au long de cette page, nous en définissons également un pour l’ensemble du foyer (ce qui précéde ne concerne que l’hôpital central).\n\n# Séquence pour l'ensemble du foyer\nweekly_breaks_all &lt;- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # lundi avant le premier cas\n  to = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # lundi aprés la derniére affaire\n  by = \"week\")\n\nCes sorties seq.Date() peuvent étre utilisées pour créer les ruptures des cases de l’histogramme, mais aussi les ruptures pour les étiquettes de date, qui peuvent étre indépendantes des cases. Vous en saurez plus sur les étiquettes de date dans les sections suivantes.\nTIP: Pour une commande ggplot() plus simple, sauvegardez à l’avance les ruptures de bacs et les ruptures d’étiquettes de dates en tant que vecteurs nommés, et fournissez simplement leurs noms à breaks =..\n\n\nExemple d’épicurve hebdomadaire\nVous trouverez ci-dessous un exemple de code détaillé pour produire des épicurves hebdomadaires pour les semaines du lundi, avec des barres alignées, des étiquettes de date et des lignes de grille verticales. Cette section est destinée à l’utilisateur qui a besoin de code rapidement. Pour comprendre en profondeur chaque aspect (thèmes, étiquettes de date, etc.), passez aux sections suivantes. A noter :\n\nLes cassures de l’histogramme sont définies avec seq.Date() comme expliqué ci-dessus pour commencer le lundi avant le premier cas et pour finir le lundi aprés le dernier cas.\n\nL’intervalle des étiquettes de date est spécifié manuellement par date_breaks = dans scale_x_date(), ou automatiquement par label = label_date_short() (paquet scales).\n\nL’intervalle des petites lignes verticales entre les étiquettes de date est spécifié par date_minor_breaks =.\n\nNous utilisons closed = \"left\" dans le geom_histogram() pour nous assurer que les dates sont comptées dans les bonnes bins.\n\nexpand = c(0,0) dans les échelles x et y supprime l’espace excédentaire de chaque côte des axes, ce qui garantit également que les étiquettes de date commencent à partir de la premiére barre.\n\n\n# ALIGNEMENT TOTAL DE LA SEMAINE DU LUNDI\n#############################\n# définir la séquence des pauses hebdomadaires\nweekly_breaks_central &lt;- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi avant la premiére affaire\n      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi aprés la derniére affaire\n      by = \"week\")    # les bins sont de 7 jours \n\n\nggplot(data = central_data) + \n  \n  # créer un histogramme : spécifier les points de rupture des bacs : commence le lundi avant le premier cas, se termine le lundi aprés le dernier cas\n  geom_histogram(\n    \n    # esthétique de la mapping\n    mapping = aes(x = date_onset), # colonne de date mappée sur l'axe des x\n    \n    # ruptures de la case de l'histogramme\n    breaks = weekly_breaks_central, # pauses des cases de l'histogramme définies précédemment\n    \n    closed = \"left\",  # compter les cas à partir du début du point d'bin\n\n    # barres\n    color = \"darkblue\", # couleur des lignes autour des barres\n    fill = \"lightblue\" # couleur de remplissage dans les barres\n  )+ \n    \n  # étiquettes de l'axe des x\n  scale_x_date(\n    expand = c(0,0), # suppression de l'espace excédentaire sur l'axe des x avant et aprés les barres de cas\n    date_breaks = \"4 weeks\", # les étiquettes de date et les principales lignes de grille verticales apparaissent toutes les 3 semaines du lundi\n    date_minor_breaks = \"week\", # les lignes verticales mineures apparaissent chaque lundi de semaine\n    #date_labels = \"%a\\n%d\\n%b\\n'%y\", # option de formatage manuel des étiquettes de date\n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  # Axe des y\n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sur l'axe des y en dessous de 0 (alignement de l'histogramme sur l'axe des x)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifie le fond du graphique\n  \n  theme(\n    plot.caption = element_text(hjust = 0, # légende sur le côte gauche\n                                face = \"italic\"), # légende en italique\n    axis.title = element_text(face = \"bold\"))+ # titres des axes en gras\n  \n  # étiquettes incluant une légende dynamique\n  labs(\n    title = \"Incidence hebdomadaire des cas (semaines de lundi)\",\n    subtitle = \"Notez l'alignement des barres, des lignes de grille verticales et des étiquettes d'axe sur les semaines du lundi\",\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Incidence hebdomadaire des cas signalés\",\n    caption = stringr::str_glue(\"n = {nrow(central_data)} de Central Hospital ; Les occurrences de cas ranges de {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}{nrow(central_data %&gt;% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))\n\n\n\n\n\n\n\n\n\nSemaines de dimanche\nPour obtenir le graphique ci-dessus pour les semaines de dimanche, quelques modifications sont nécessaires, car les date_breaks = \"weeks\" ne fonctionnent que pour les semaines de lundi.\n\nLes points de rupture des bins de l’histogramme doivent étre fixés au dimanche (week_start = 7)\n\nDans scale_x_date(), les ruptures de date similaires doivent étre fournies à breaks = et minor_breaks = pour s’assurer que les étiquettes de date et les lignes de grille verticales s’alignent sur les dimanches.\n\nPar exemple, la commande scale_x_date() pour les semaines du dimanche pourrait ressembler à ceci :\n\nscale_x_date(\n    expand = c(0,0),\n    \n    # spécifie l'intervalle des étiquettes de date et des principales lignes de grille verticales\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche avant la premiére affaire\n      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche aprés la derniére affaire\n      by = \"4 weeks\"),\n    \n    # spécifier l'intervalle de la ligne de grille verticale mineure \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche avant le premier cas\n      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche aprés la derniére affaire\n      by = \"week\"),\n   \n    # format des étiquettes de date\n    #date_labels = \"%a\\n%d\\n%b\\n%y\", # option de formatage manuel des étiquettes de date.\n                                      # Jour, au-dessus abréviation du mois, au-dessus\n                                      # année à 2 chiffres\n    label = scales::label_date_short())+ # format des étiquettes automatique\n\n\n\n\nGrouper/colorer par valeur\nLes barres de l’histogramme peuvent étre colorées par groupe et “empilées”. Pour désigner la colonne de regroupement, effectuez les modifications suivantes. Voir la page ggplot basics pour plus de détails.\n\nDans le mappage esthétique de l’histogramme aes(), mettez en correspondance le nom de la colonne avec les arguments group = et fill =.\n\nSupprimez tout argument fill = à l’extérieur de aes(), car il remplacera celui qui se trouve à l’intérieur.\n\nLes arguments inside de aes() s’appliqueront par groupe, alors que les arguments outside s’appliqueront à toutes les barres (par exemple, vous pouvez toujours vouloir color = à l’extérieur, pour que chaque barre ait la même bordure).\n\nVoici à quoi ressemblerait la commande aes() pour grouper et colorer les barres par sexe :\n\naes(x = date_onset, group = gender, fill = gender)\n\nLe voici appliqué :\n\nggplot(data = linelist) + # commencer avec linelist (many hospitals)\n  \n  # faire un histogramme : spécifier les points de rupture de la benne : commence le lundi avant le premier cas, se termine le lundi aprés le dernier cas\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital, # définir les données pour qu'elles soient groupées par hôpital\n      fill = hospital), # remplissage des barres (couleur intérieure) par hôpital\n    \n    # les pauses sont les semaines de lundi\n    breaks = weekly_breaks_all, # séquence de pauses hebdomadaires du lundi pour toute l'épidémie, définie dans le code précédent \n    \n    closed = \"left\", # Compter les cas à partir du début du point d'arrêt\n    \n    # Couleur autour des barres\n    color = \"black\")\n\n\n\n\n\n\n\n\n\n\nAjuster les couleurs\n\nPour manuellement régler le remplissage pour chaque groupe, utilisez scale_fill_manual() (note : scale_color_manual() est différent !).\n\nUtilisez l’argument values = pour appliquer un vecteur de couleurs.\n\nUtilisez na.value = pour spécifier une couleur pour les valeurs NA.\n\nUtilisez l’argument labels = pour changer le texte des éléments de la légende. Pour étre sur, fournissez un vecteur nommé comme c(\"old\" = \"new\", \"old\" = \"new\") ou ajustez les valeurs dans les données elles-mêmes.\n\nUtilisez name = pour donner un titre correct à la légende.\n\n\nPour plus d’informations sur les échelles et les palettes de couleurs, consultez la page sur les bases de ggplot.\n\n\nggplot(data = linelist)+ # commencer avec linelist (plusieurs hôpitaux)\n  \n  # faire un histogramme\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital, # cas groupés par hôpital\n        fill = hospital), # remplissage des barres par hôpital\n    \n    # bin breaks\n    breaks = weekly_breaks_all, # séquence de bin breaks hebdomadaires du lundi, définie dans le code précédent\n    \n    closed = \"left\", # Compter les cas à partir du début du point d'arrêt\n  \n    color = \"black\")+ # couleur de la bordure de chaque barre\n  \n  # spécification manuelle des couleurs\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St.Mark's\"),\n    name = \"Hospital\") # spécifier les couleurs de remplissage (\"values\") - attention à l'ordre !\n\n\n\n\n\n\n\n\n\n\nAjuster l’ordre des niveaux\nLe meilleur moyen d’ajuster l’ordre dans lequel les barres groupées sont empilées est de classer la colonne de groupage en tant que classe Facteur. Vous pouvez alors désigner l’ordre des niveaux de facteurs (et leurs étiquettes d’affichage). Voir la page sur facteurs ou ggplot tips pour plus de détails.\nAvant de réaliser le tracé, utilisez la fonction fct_relevel() du paquet forcats pour convertir la colonne de regroupement en classe facteur et ajuster manuellement l’ordre des niveaux, comme détaillé dans la page sur les facteurs. Pour ajuster les niveaux de manière plus avancée, utilisez fct_lump(), qui combine automatiquement les petites catégories en une catégorie “Autre”.\n\n# charger le paquet forcats pour travailler avec les facteurs\npacman::p_load(forcats)\n\n# définir un nouvel ensemble de données avec l'hôpital comme facteur\nplot_data &lt;- linelist %&gt;% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convertir en facteur et définir \"Manquant\" et \"Autre\" comme niveaux supérieurs pour apparaétre sur le sommet de l'épicurve.\n\nlevels(plot_data$hospital) # Imprime les niveaux dans l'ordre\n\n[1] \"Missing\"                             \n[2] \"Other\"                               \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\nDans le graphique ci-dessous, les seules différences par rapport au précédent sont que la colonne hospital a été consolidée comme ci-dessus, et que nous utilisons guides() pour inverser l’ordre de la légende, de sorte que “Missing” se trouve en bas de la légende.\n\nggplot(plot_data) + # Utiliser le NOUVEL ensemble de données avec les hôpitaux comme facteurs réordonnés.\n  \n  # créer un histogramme\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital, # cas groupés par hôpital\n        fill = hospital), # remplissage des barres (couleur) par hôpital\n    \n    breaks = weekly_breaks_all, # séquence de pauses hebdomadaires du lundi pour toute l'épidémie, définie en haut de la section ggplot\n    \n    closed = \"left\", # Compter les cas à partir du début du point d'arrêt\n\n    color = \"black\")+ # couleur de la bordure autour de chaque barre\n    \n  # étiquettes de l'axe des x\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace excédentaire sur l'axe des x avant et aprés les barres de cas\n    date_breaks = \"3 weeks\", # les étiquettes apparaissent toutes les 3 semaines du lundi\n    date_minor_breaks = \"week\", # les lignes verticales apparaissent tous les lundis de la semaine\n    label = scales::label_date_short())+ # format des étiquettes de date efficace\n  \n  # Axe des y\n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sur l'axe des y en dessous de 0\n  \n  # spécification manuelle des couleurs, ! attention à l'ordre\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St.Marks\"),\n    name = \"Hospital\")+ \n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier le fond du graphique\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # légende à gauche en italique\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+ # titres des axes en gras\n  \n  # étiquettes\n  labs(\n    title = \"Incidence hebdomadaire des cas par hôpital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Cas hebdomadaires\")\n\n\n\n\n\n\n\n\nTIP: Pour inverser l’ordre de la légende uniquement, ajoutez cette commande ggplot2 : guides(fill = guide_legend(reverse = TRUE)).\n\n\nAjuster la légende\nPour en savoir plus sur les légendes et les échelles, consultez la page ggplot tips. Voici quelques points saillants :\n\nModifiez le titre de la légende soit dans la fonction d’échelle, soit avec labs(fill = \"Legend title\") (si vous utilisez color = esthétique, alors utilisez labs(color = \"\")).\n\ntheme(legend.title = element_blank()) pour ne pas avoir de titre de légende\n\ntheme(legend.position = \"top\") (“bottom”, “left”, “right”, ou “none” pour supprimer la légende)\ntheme(legend.direction = \"horizontal\") légende horizontale\nguides(fill = guide_legend(reverse = TRUE)) pour inverser l’ordre de la légende\n\n\n\nBarres côte à côte\nL’affichage côte à côte des barres de groupe (par opposition à l’empilement) est spécifié dans geom_histogram() avec position = \"dodge\" placé en dehors de aes().\nS’il y a plus de deux groupes de valeurs, ceux-ci peuvent devenir difficiles à lire. Envisagez plutôt d’utiliser un graphique à facettes (petits multiples). Pour améliorer la lisibilité dans cet exemple, les valeurs de sexe manquantes sont supprimées.\n\nggplot(central_data %&gt;% drop_na(gender))+ # Commencez par les cas de l'hôpital central en supprimant les valeurs manquantes pour le sexe.\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender, # cas groupés par sexe\n          fill = gender), # barres remplies par sexe\n        \n        # histogramme bin breaks\n        breaks = weekly_breaks_central, # séquence de dates hebdomadaires pour le foyer central - définie en haut de la section ggplot\n        \n        closed = \"left\",\n        \n        color = \"black\", # couleur du bord des barres\n        \n        position = \"dodge\")+ # barres SIDE-BY-SIDE\n                      \n  \n  # Les étiquettes sur l'axe des x\n  scale_x_date(\n       expand = c(0,0), # supprimer l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n       date_breaks = \"3 weeks\", # les étiquettes apparaissent toutes les 3 semaines du lundi\n       date_minor_breaks = \"week\", # les lignes verticales apparaissent tous les lundis de la semaine\n       label = scales::label_date_short())+ # format des étiquettes de date efficace\n\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire sur l'axe des y entre le bas des barres et les étiquettes\n  \n  #échelle des couleurs et des étiquettes de légende\n  scale_fill_manual(values = c(\"brown\", \"orange\"), # spécifie les couleurs de remplissage (\"values\") - attention à l'ordre !\n                    na.value = \"grey\" )+     \n\n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphe\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n        axis.title = element_text(face = \"bold\"))+ # titres des axes en gras\n  \n  # étiquettes\n  labs(title = \"Incidence hebdomadaire des cas, par sexe\",\n       subtitle = \"Sous-titre\",\n       fill = \"Gender\", # fournir un nouveau titre pour la légende\n       x = \"Semaine d'apparition des symptômes\",\n       y = \"Incidence hebdomadaire des cas signalés\")\n\n\n\n\n\n\n\n\n\n\nLimites de l’axe\nIl existe deux façons de limiter l’étendue des valeurs des axes.\nGénéralement, la méthode préférée est d’utiliser la commande coord_cartesian(), qui accepte xlim = c(min, max) et ylim = c(min, max) (où vous fournissez les valeurs min et max). Ceci agit comme un “zoom” sans réellement supprimer de données, ce qui est important pour les statistiques et les mesures sommaires.\nAlternativement, vous pouvez définir les valeurs maximales et minimales de la date en utilisant limits = c() dans scale_x_date(). Par exemple :\n\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # définit une date minimum mais laisse la date maximum ouverte.  \n\nSi vous souhaitez que l’axe des abscisses s’tende jusqu’é une date spécifique (par exemple, la date du jour), même si aucun nouveau cas n’a été signalé, vous pouvez utiliser :\n\nscale_x_date(limits = c(NA, Sys.Date())) # garantit que l'axe des dates s'étendra jusqu'à la date du jour  \n\nDANGER: Soyez prudent en fixant les ruptures d’échelle ou les limites de l’axe des y (par exemple, 0 à 30 par 5 : seq(0, 30, 5)). De tels nombres statiques peuvent couper votre tracé trop court si les données changent pour dépasser la limite !.\n\n\nLibellés des axes de date / lignes de grille\nTIP: Rappelez-vous que les étiquettes de l’axe des dates sont indépendantes de l’agrégation des données en barres, mais visuellement, il peut étre important d’aligner les bacs, les étiquettes de date et les lignes de grille verticales.\nPour modifier les étiquettes de date et les lignes de grille, utilisez scale_x_date() de l’une de ces façons :\n\nSi vos bins d’histogramme sont des jours, lundi des semaines, des mois ou des années :\n\nUtilisez date_breaks = pour spécifier l’intervalle des étiquettes et des lignes de grille principales (par exemple “jour”, “semaine”, “3 semaines”, “mois” ou “année”).\nUtilisez date_minor_breaks = pour spécifier l’intervalle des lignes verticales mineures (entre les étiquettes de date)\n\nAjoutez expand = c(0,0) pour que les étiquettes commencent à la premiére barre.\n\nUtilisez date_labels = pour spécifier le format des étiquettes de date avec la syntaxe strptime - voir la page Dates pour des conseils (e.g. utilisez \\n pour une nouvelle ligne), OU utilisez label = label_date_short() (du paquet scales) pour des étiquettes de date automatiques et efficaces.\n\nSi les cases de votre histogramme sont des semaines de dimanche :\n\nUtilisez breaks = et minor_breaks = en fournissant une séquence de ruptures de date pour chacun d’entre eux.\nVous pouvez toujours utiliser date_labels = et expand = pour le formatage comme décrit ci-dessus.\n\n\nQuelques notes :\n\nVoir la section ggplot d’ouverture pour des instructions sur la façon de créer une séquence de dates en utilisant seq.Date().\n\nVoir cette page ou la page travailler avec des dates pour des conseils sur la création d’étiquettes de date.\n\n\nDémonstrations\nVous trouverez ci-dessous une démonstration de tracés où les bacs et les étiquettes/grilles sont alignés et non alignés :\n\n# Bacs de 7 jours + étiquettes du lundi\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7, # bins de 7 jours avec début au premier cas\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire sur l'axe des x en dessous et aprés les barres de cas\n    date_breaks = \"3 weeks\", # Lundi toutes les 3 semaines\n    date_minor_breaks = \"week\", # lundi semaines\n    \n    #date_labels = \"%a\\n%d\\n%b\\n'%y\", # option de formatage manuel des étiquettes de date\n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x, mise à plat\n  \n  labs(\n    title = \"MAL ALIGNÉ\",\n    subtitle = \" ! ATTENTION : Les barres de 7 jours commencent le jeudi avec le premier cas.\\n Grandes lignes de grille et étiquettes de date au 1er de chaque mois.\\n Lignes de grille mineures chaque lundi.\")\n\n\n\n# Tranches de 7 jours + Mois\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n    date_breaks = \"months\", # 1er du mois\n    date_minor_breaks = \"week\", # semaines de lundi\n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  scale_y_continuous(\n    expand = c(0,0)) + # Suppression de l'espace excédentaire sous l'axe des x, mise à plat des données \n  \n  labs(\n    title = \"MAL ALIGNÉ\",\n    subtitle = \" ! ATTENTION : Les barres de 7 jours commencent le jeudi avec le premier cas\\nLes lignes de grille principales et les étiquettes de date au 1er de chaque mois\\nLes lignes de grille mineures sont hebdomadaires le lundi\\nNotez l'espacement inégal de certaines lignes de grille et les tics non alignés avec les barres\"\n    )\n\n\n# ALIGNEMENT TOTAL DU LUNDI : spécifier que les pauses manuelles sont des lundis\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # les ruptures d'histogramme sont fixées à 7 jours commençant le lundi avant le premier cas\n    breaks = weekly_breaks_central, # défini plus tôt dans cette page\n    \n    closed = \"left\",\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire sur l'axe x en dessous et aprés les barres de cas\n    date_breaks = \"4 weeks\", # Lundi toutes les 4 semaines\n    date_minor_breaks = \"week\", # lundi semaines \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # Suppression de l'espace excédentaire sous l'axe des x, mise à plat des données \n  \n  labs(\n    title = \"Lundis ALIGNÉS\",\n    subtitle = \"Les intervalles de 7 jours sont réglés manuellement pour commencer le lundi avant le premier cas (28 avr.)\\n Les étiquettes de date et les lignes de grille sont aussi sur les lundis\")\n\n\n# ALIGNEMENT TOTAL DES LUNDIS AVEC LES étiQUETTES DE MOIS :\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # ruptures d'histogramme fixées à 7 jours commençant le lundi avant le premier cas\n    breaks = weekly_breaks_central, # défini plus tôt dans cette page\n    \n    color = \"darkblue\",\n    \n    closed = \"left\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire sur l'axe x en dessous et aprés les barres de cas\n    date_breaks = \"months\", # Lundi toutes les 4 semaines\n    date_minor_breaks = \"week\", # lundi semaines \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x, mise à plat \n  \n  theme(panel.grid.major = element_blank())+ # Suppression des lignes de grille principales (tombent le 1er du mois)\n          \n  labs(\n    title = \"Lundis ALIGNÉS avec étiquettes MONTHLY\",\n    subtitle = \"Bacs de 7 jours réglés manuellement pour commencer le lundi avant le premier cas (28 avril) - étiquettes de date le 1er du mois - Suppression des principaux quadrillages mensuels\")\n\n\n# ALIGNEMENT TOTAL DU DIMANCHE : spécifier les ruptures manuelles des bacs ET les étiquettes pour les dimanches\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # ruptures d'histogramme fixées à 7 jours commençant le dimanche avant le premier cas\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    closed = \"left\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # les ruptures de l'étiquette de date et les principales lignes de la grille sont fixées à toutes les 3 semaines, en commençant le dimanche avant le premier cas.\n    breaks = seq.Date(\n         from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n         to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n         by = \"3 weeks\"),\n    \n    # grilles mineures fixées à la semaine commençant le dimanche avant le premier cas\n    minor_breaks = seq.Date(\n         from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n         to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n         by = \"7 days\"),\n    \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x, mise à plat \n  \n  labs(title = \"Dimanches ALIGNÉS\",\n       subtitle = \"Les intervalles de 7 jours ont été réglés manuellement pour commencer le dimanche avant le premier cas (27 avril)\\n Les étiquettes de date et les lignes de grille ont également été réglées manuellement sur les dimanches\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDonnées agrégées\nSouvent, au lieu d’une liste de lignes, vous commencez par des comptages agrégés d’établissements, de districts, etc. Vous pouvez faire une épicurve avec ggplot() mais le code sera légérement différent. Cette section va utiliser le jeu de données count_data qui a été importé plus tôt, dans la section de préparation des données. Ce jeu de données est la linelist agrégée au nombre de jours d’hospitalisation. Les 50 premiéres lignes sont affichôes ci-dessous.\n\n\n\n\n\n\n\nTracer des épicentres quotidiens\nNous pouvons tracer une épicurve quotidienne à partir de ces comptes quotidiens. Voici les différences par rapport au code :\n\nDans le mappage esthétique aes(), spécifiez y = comme colonne de comptage (dans ce cas, le nom de la colonne est n_cases).\nAjoutez l’argument stat = \"identity\" dans geom_histogram(), qui spécifie que la hauteur de la barre doit étre la valeur y =, et non le nombre de lignes comme c’est le cas par défaut.\n\nAjoutez l’argument width = pour éviter les lignes blanches verticales entre les barres. Pour les données quotidiennes, fixez la valeur à 1. Pour les données de comptage hebdomadaire, fixez la valeur à 7. Pour les données de comptage mensuel, les lignes blanches sont un probléme (chaque mois a un nombre de jours différent) - envisagez de transformer votre axe des x en un facteur ordonné catégorique (mois) et utilisez `geom_col()``.\n\n\nggplot(data = count_data) +\n  geom_histogram(\n    mapping = aes(x = date_hospitalisation, y = n_cases),\n    stat = \"identity\",\n    width = 1) + # pour les comptages quotidiens, définir width = 1 pour éviter les espaces blancs entre les barres\n  labs(\n    x = \"Date du rapport\", \n    y = \"Nombre de cas\",\n    title = \"Incidence quotidienne des cas, à partir des données de comptage quotidiennes\")\n\n\n\n\n\n\n\n\n\n\nTracer les comptages hebdomadaires\nSi vos données sont déjà des comptages de cas par semaine, elles peuvent ressembler à cet ensemble de données (appelé count_data_weekly) :\nLes 50 premiéres lignes de count_data_weekly sont affichées ci-dessous. Vous pouvez voir que les comptes ont été agrégés en semaines. Chaque semaine est affichée par le premier jour de la semaine (lundi par défaut).\n\n\n\n\n\n\nMaintenant, tracez le graphique de façon à ce que x = la colonne epiweek. N’oubliez pas d’ajouter y = la colonne des comptes à la mapping esthétique, et ajoutez stat = \"identity\" comme expliqué ci-dessus.\n\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek, # l'axe des x est l'epiweek (en tant que classe Date)\n      y = n_cases_weekly, # l'axe des y est la hauteur du nombre de cas hebdomadaires\n      group = hospital, # nous regroupons les barres et les couleurs par hôpital\n      fill = hospital),\n    stat = \"identity\")+ # ceci est également nécessaire lorsque l'on trace des données de comptage\n     \n  # étiquettes pour l'axe des x\n  scale_x_date(\n    date_breaks = \"2 months\", # étiquettes tous les 2 mois \n    date_minor_breaks = \"1 month\", # grilles tous les mois\n    label = scales::label_date_short())+ # format des étiquettes automatique\n     \n  # Choisissez la palette de couleurs (utilise le paquet RColorBrewer)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Semaine d'apparition\", \n    y = \"Incidence hebdomadaire des cas\",\n    fill = \"Hospital\",\n    title = \"Incidence hebdomadaire des cas, à partir des données de comptage agrégées par hôpital\")\n\n\n\n\n\n\n\n\n\n\n\nMoyennes mobiles\nVoir la page sur les Moyennes mobiles pour une description détaillée et plusieurs options. Vous trouverez ci-dessous une option pour calculer des moyennes mobiles avec le package slider. Dans cette approche, la moyenne mobile est calculée dans l’ensemble de données avant le tracé :\n\nRegroupez les données en comptes si nécessaire (quotidien, hebdomadaire, etc.) (voir la page sur groupage des données).\n\ncréez une nouvelle colonne pour contenir la moyenne mobile, créée avec slide_index() du paquet slider.\n\nTracez la moyenne mobile comme une geom_line() au-dessus (aprés) l’histogramme épicurvien\n\nVoir l’utile vignette pour le paquet slider\n\n# charger le paquet\npacman::p_load(slider) # slider utilisé pour calculer les moyennes mobiles\n\n# créer un jeu de données de comptages quotidiens et de moyennes mobiles sur 7 jours\n#######################################################\nll_counts_7day &lt;- linelist %&gt;% # commencer avec linelist\n  \n  ## compter les cas par date\n  count(date_onset, name = \"new_cases\") %&gt;% # nommer une nouvelle colonne avec les comptages comme \"new_cases\".\n  drop_na(date_onset) %&gt;% # supprime les cas dont la date_onset est manquante\n  \n  ## calculer le nombre moyen de cas dans la fenétre de 7 jours\n  mutate(\n    avg_7day = slider::slide_index( # créer une nouvelle colonne\n      new_cases, # calcul basé sur la valeur de la colonne new_cases\n      .i = date_onset, # l'index est la colonne date_onset, donc les dates non présentes sont incluses dans la fenétre \n      .f = ~mean(.x, na.rm = TRUE), # La fonction est mean() avec les valeurs manquantes supprimées.\n      .before = 6, # la fenétre est le jour et les 6 jours précédents\n      .complete = FALSE), # doit étre FALSE pour que unlist() fonctionne à l'étape suivante\n    avg_7day = unlist(avg_7day)) # convertit la liste des classes en classes numériques\n\n\n# tracer\n######\nggplot(data = ll_counts_7day) + # commencer avec le nouvel ensemble de données défini ci-dessus \n    geom_histogram( # crée un histogramme épicurve\n      mapping = aes(\n        x = date_onset, # colonne de date comme axe des x\n        y = new_cases), # la hauteur est le nombre de nouveaux cas quotidiens\n        stat = \"identity\", # la hauteur est la valeur y\n        fill=\"#92a8d1\", # couleur froide pour les barres\n        colour = \"#92a8d1\", # même couleur pour la bordure des barres\n        )+ \n    geom_line( # créer une ligne pour la moyenne mobile\n      mapping = aes(\n        x = date_onset, # colonne de date pour l'axe des x\n        y = avg_7day, # valeur y définie dans la colonne de la moyenne mobile\n        lty = \"7-day \\nrolling avg\"), # nom de la ligne dans la légende\n      color=\"red\", # couleur de la ligne\n      size = 1) + # largeur de la ligne\n    scale_x_date( # échelle de date\n      date_breaks = \"1 month\",\n      label = scales::label_date_short(), # format des étiquettes automatique\n      expand = c(0,0)) +\n    scale_y_continuous( # échelle de l'axe des y\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y = \"Nombre de cas confirmés\",\n      fill = \"Legende\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank()) # supprime le titre de la légende\n\n\n\n\n\n\n\n\n\n\nFacettes/petits-multiples\nComme pour les autres ggplots, vous pouvez créer des graphiques à facettes (“petits multiples”). Comme expliqué dans la page ggplot tips de ce manuel, vous pouvez utiliser soit facet_wrap() soit facet_grid(). Ici, nous faisons une démonstration avec facet_wrap(). Pour les épicurves, facet_wrap() est typiquement plus facile car il est probable que vous n’ayez besoin de faire une facette que sur une seule colonne.\nLa syntaxe générale est facet_wrap(rows ~ cols), où à gauche du tilde (~) est le nom d’une colonne à répartir sur les “rows” du graphique à facettes, et à droite du tilde est le nom d’une colonne à répartir sur les “columns” du graphique à facettes. Plus simplement, il suffit d’utiliser un seul nom de colonne, à droite du tilde : facet_wrap(~age_cat).\nAxes libres\nVous devrez décider si les échelles des axes pour chaque facette sont “fixées” aux mêmes dimensions (par défaut), ou “libres” (ce qui signifie qu’elles changeront en fonction des données de la facette). Faites-le avec l’argument scales = dans facet_wrap() en spécifiant “free_x” ou “free_y”, ou “free”.\nNombre de cols et de rangs de facettes\nCela peut étre spécifié avec ncol = et nrow = dans facet_wrap().\nOrdre des facettes\nPour changer l’ordre d’apparition, changez l’ordre sous-jacent des niveaux de la colonne de facteurs utilisée pour créer les facettes.\nesthétique\nLa taille et le visage de la police, la couleur de la bande, etc. peuvent étre modifiés par theme() avec des arguments comme :\n\nstrip.text = element_text() (taille, couleur, face, angle…)\nstrip.background = element_rect() (par exemple element_rect(fill=“grey”))\n\nstrip.position = (position de la bande “bas”, “haut”, “gauche” ou “droite”)\n\nLibellés des bandes\nLes étiquettes des graphiques à facettes peuvent étre modifiées par les “étiquettes” de la colonne comme facteur, ou par l’utilisation d’un “labeller”.\nFaites une étiquette comme celle-ci, en utilisant la fonction as_labeller() de ggplot2. Puis fournissez l’étiqueteuse à l’argument labeller = de facet_wrap() comme indiqué ci-dessous.\n\nmy_labels &lt;- as_labeller(c(\n     \"0-4\" = \"0-4 ans\",\n     \"5-9\" = \"5-9 ans\",\n     \"10-14\" = \"10-14 ans\",\n     \"15-19\" = \"15-19 ans\",\n     \"20-29\" = \"20-29 ans\",\n     \"30-49\" = \"30-49 ans\",\n     \"50-69\" = \"50-69 ans\",\n     \"70+\" = \"Plus de 70 ans\"))\n\nUn exemple de graphique à facettes - facetté par la colonne age_cat.\n\n# faire le graphe\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat), # les arguments à l'intérieur de aes() s'appliquent par groupe\n      \n    color = \"black\", # les arguments hors aes() s'appliquent à toutes les données\n        \n    # ruptures d'histogramme\n    breaks = weekly_breaks_central,\n    closed = \"left\")+ # vecteur de date prédéfini (voir plus haut dans cette page)\n                      \n  # Les étiquettes sur l'axe des x\n  scale_x_date(\n    expand = c(0,0), # supprimez l'espace excédentaire sur l'axe des x en dessous et aprés les barres de cas\n    date_breaks = \"2 months\", # les étiquettes apparaissent tous les 2 mois\n    date_minor_breaks = \"1 month\", # les lignes verticales apparaissent tous les 1 mois \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire sur l'axe des y entre le bas des barres et les étiquettes\n  \n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphique\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+ # titres des axes en gras\n  \n  # créer des facettes\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # étiquettes\n  labs(\n    title = \"Incidence hebdomadaire des cas, par catégorie d'âge\",\n    subtitle = \"Sous-titre\",\n    fill = \"Catégorie d'âge\", # fournir un nouveau titre pour la légende\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Cas incidents hebdomadaires signalés\",\n    caption = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital ; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}{nrow(central_data %&gt;% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))\n\n\n\n\n\n\n\n\nVoir ce lien pour plus d’informations sur les étiqueteuses.\n\n32.2.0.1 Épidémie totale dans l’arriére-plan de la facette\nPour afficher l’épidémie totale en arriére-plan de chaque facette, ajoutez la fonction gghighlight() avec des parenthôses vides au ggplot. Cette fonction provient du paquet gghighlight. Notez que le maximum de l’axe des y dans toutes les facettes est maintenant basé sur le pic de l’épidémie entiére. Il y a plus d’exemples de ce package dans la page ggplot tips.\n\nggplot(central_data) + \n  \n  # Epicurves par groupe\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat), # les arguments à l'intérieur de aes() s'appliquent par groupe\n    \n    color = \"black\", # les arguments hors aes() s'appliquent à toutes les données\n    \n    # ruptures d'histogramme\n    breaks = weekly_breaks_central,\n    closed = \"left\")+ # vecteur de dates prédéfini (voir en haut de la section ggplot)                \n  \n  # ajoute une épidémie grise en arriére-plan à chaque facette\n  gghighlight::gghighlight()+\n  \n  # étiquettes sur l'axe des x\n  scale_x_date(\n    expand = c(0,0), # Suppression de l'espace excédentaire sur l'axe des x sous et aprés les barres de cas\n    date_breaks = \"2 months\", # les étiquettes apparaissent tous les 2 mois\n    date_minor_breaks = \"1 month\", # les lignes verticales apparaissent tous les 1 mois \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire de l'axe des y en dessous de 0\n  \n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphique\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+ # titres des axes en gras\n  \n  # créer des facettes\n  facet_wrap(\n    ~age_cat, # chaque facette est une valeur de age_cat\n    ncol = 4, # nombre de colonnes\n    strip.position = \"top\", # position du titre/strip de la facette\n    labeller = my_labels)+ # labeller définit ci-dessus\n  \n  # étiquettes\n  labs(\n    title = \"Incidence hebdomadaire des cas, par catégorie d'âge\",\n    subtitle = \"Sous-titre\",\n    fill = \"Catégorie d'âge\", # fournit un nouveau titre pour la légende\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Cas incidents hebdomadaires signalés\",\n    caption = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital ; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}{nrow(central_data %&gt;% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))\n\n\n\n\n\n\n\n\n\n\nUne facette avec des données\nSi vous voulez avoir une seule boîte à facettes qui contient toutes les données, dupliquez l’ensemble des données et traitez les doublons comme une seule valeur de facette. La fonction “helper” CreateAllFacet() ci-dessous peut vous aider (gràce à cet article de blog). Quand elle est exécutée, le nombre de lignes double et il y aura une nouvelle colonne appelée facet dans laquelle les lignes dupliquées auront la valeur “all”, et les lignes originales auront la valeur originale de la colonne de facettes. Il ne vous reste plus qu’à effectuer la facette sur la colonne facet.\nVoici la fonction d’aide. Exécutez-la pour qu’elle soit disponible pour vous.\n\n# définir la fonction d'aide\nCreateAllFacet &lt;- function(df, col){\n     df$facet &lt;- df[[col]]\n     temp &lt;- df\n     temp$facet &lt;- \"all\"\n     merged &lt;-rbind(temp, df)\n     \n     # s'assurer que la valeur de la facette est un facteur\n     merged[[col]] &lt;- as.factor(merged[[col]])\n     \n     return(merged)\n}\n\nAppliquez maintenant la fonction d’aide à l’ensemble de données, sur la colonne age_cat :\n\n# créez un jeu de données dupliqué et avec une nouvelle colonne \"facet\" pour afficher \"toutes\" les catégories d'âge comme autre niveau de facette.\ncentral_data2 &lt;- CreateAllFacet(central_data, col = \"age_cat\") %&gt;%\n  \n  # définir les niveaux de facteurs\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `facet = fct_relevel(...)`.\nCaused by warning:\n! 1 unknown level in `f`: 70+\n\n# vérifier les niveaux\ntable(central_data2$facet, useNA = \"always\")\n\n\n  all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  &lt;NA&gt; \n  454    84    84    82    58    73    57     7     9 \n\n\nLes changements notables de la commande ggplot() sont les suivants :\n\nLes données utilisées sont maintenant central_data2 (deux fois plus de lignes, avec une nouvelle colonne “facet”).\nL’étiqueteuse devra étre mise à jour, si elle est utilisée.\n\nOptionnel : pour obtenir des facettes empilées verticalement : la colonne facette est déplacée vers les lignes de l’équation et remplacée à droite par “.” (facet_wrap(facet~.)), et ncol = 1. Vous pouvez aussi avoir besoin d’ajuster la largeur et la hauteur de l’image du graphique en png (voir ggsave() dans ggplot tips).\n\n\nggplot(central_data2) + \n  \n  # Epicurves réelles par groupe\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat), # les arguments à l'intérieur de aes() s'appliquent par groupe\n        color = \"black\", # les arguments hors aes() s'appliquent à toutes les données\n        \n        # ruptures d'histogramme\n        breaks = weekly_breaks_central, # vecteur de dates prédéfini (voir en haut de la section ggplot)\n        closed = \"left\")+ \n                     \n  # étiquettes sur l'axe des x\n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n    date_breaks = \"2 months\", # les étiquettes apparaissent tous les 2 mois\n    date_minor_breaks = \"1 month\", # les lignes verticales apparaissent tous les 1 mois \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire sur l'axe des y entre le bas des barres et les étiquettes\n  \n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphique\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # créer des facettes\n  facet_wrap(facet~. , # chaque parcelle est une valeur de la facette\n             ncol = 1)+            \n\n  # étiquettes\n  labs(title = \"Incidence hebdomadaire des cas, par catégorie d'âge\",\n       subtitle = \"Sous-titre\",\n       fill = \"Catégorie d'âge\", # fournit un nouveau titre pour la légende\n       x = \"Semaine d'apparition des symptômes\",\n       y = \"Cas incidents hebdomadaires signalés\",\n       caption = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital ; Case onsets range from\n                                   {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à\n                                   {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#données-provisoires",
    "href": "new_pages/epicurves.fr.html#données-provisoires",
    "title": "32  Courbes épidémiques",
    "section": "32.3 Données provisoires",
    "text": "32.3 Données provisoires\nLes données les plus récentes présentées dans les épicurves doivent souvent étre marquées comme provisoires, ou sujettes à des retards de déclaration. Ceci peut étre fait en ajoutant une ligne verticale et/ou un rectangle sur un nombre de jours spécifié. Voici deux options :\n\nUtilisez annotate() :\n\nPour une ligne, utilisez annotate(geom = \"segment\"). Fournissez x, xend, y, et yend. Ajustez la taille, le type de ligne (lty) et la couleur.\n\nPour un rectangle, utilisez annotate(geom = \"rect\"). Fournissez xmin/xmax/ymin/ymax. Ajustez la couleur et l’alpha.\n\n\nRegroupez les données par statut provisoire et colorez ces barres différemment.\n\nCAUTION: Vous pourriez essayer geom_rect() pour dessiner un rectangle, mais l’ajustement de la transparence ne fonctionne pas dans un contexte de linelist. Cette fonction superpose un rectangle pour chaque observation/rangée ! Utilisez soit un alpha trés faible (par exemple 0,01), soit une autre approche. \n\nUtilisation de annotate()\n\nDans annotate(geom = \"rect\"), les arguments xmin et xmax doivent recevoir des entrées de la classe Date.\n\nNotez que, comme ces données sont agrégées en barres hebdomadaires et que la derniére barre s’étend jusqu’au lundi suivant le dernier point de données, la région ombrée peut sembler couvrir 4 semaines.\n\nVoici un annotate() exemple en ligne\n\n\nggplot(central_data) + \n  \n  # histogramme\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central, # vecteur de date prédéfini - voir en haut de la section ggplot\n    \n    color = \"darkblue\",\n    \n    closed = \"left\",\n    \n    fill = \"lightblue\") +\n\n  # échelles\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0), # Suppression de l'espace excédentaire sur l'axe des x sous et aprés les barres de cas\n    date_breaks = \"1 month\", # 1er du mois\n    date_minor_breaks = \"1 month\", # 1er du mois\n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  # étiquettes et theme\n  labs(\n    title = \"Utilisant annotate()\\nRectangle et ligne montrant que les données des 21 derniers jours sont provisoires\",\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Indication hebdomadaire des cas\")+ \n  theme_minimal()+\n  \n  # ajoute un rectangle rouge semi-transparent aux données provisoires\n  annotate(\n    \"rect\",\n    xmin = as.Date(max(central_data$date_onset, na.rm = T) - 21), # la note doit étre enveloppée dans as.Date()\n    xmax = as.Date(Inf), # la note doit étre enveloppée dans as.Date()\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.2, # alpha facile et intuitif à ajuster en utilisant annotate()\n    fill = \"red\")+\n  \n  # ajoute une ligne verticale noire au-dessus des autres couches\n  annotate(\n    \"segment\",\n    x = max(central_data$date_onset, na.rm = T) - 21, # 21 jours avant les derniéres données\n    xend = max(central_data$date_onset, na.rm = T) - 21, \n    y = 0, # la ligne commence à y = 0\n    yend = Inf, # ligne jusqu'au sommet du graphique\n    size = 2, # taille de la ligne\n    color = \"black\",\n    lty = \"solid\")+ # type de ligne, par exemple \"solid\", \"dashed\".\n\n  # ajouter du texte dans le rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Sujet à des délais de déclaration\",\n    angle = 90)\n\n\n\n\n\n\n\n\nLa même ligne verticale noire peut étre obtenue avec le code ci-dessous, mais en utilisant geom_vline() vous perdez la possibilité de contrôler la hauteur :\n\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")\n\n\n\nCouleur des barres\nUne autre approche pourrait consister à ajuster la couleur ou l’affichage des barres de données provisoires elles-mêmes. Vous pouvez créer une nouvelle colonne dans l’étape de préparation des données et l’utiliser pour regrouper les données, de sorte que les ” aes(fill = )`” des données provisoires puissent avoir une couleur ou un alpha différent des autres barres.\n\n# ajouter une colonne\n############\nplot_data &lt;- central_data %&gt;% \n  mutate(tentative = case_when(\n    date_onset &gt;= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative si dans les 7 derniers jours\n    TRUE ~ \"Reliable\")) # tout le reste est fiable\n\n# tracé\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogramme\n  geom_histogram(\n    breaks = weekly_breaks_central, # vecteur de données prédéfini, voir en haut de la page ggplot\n    closed = \"left\",\n    color = \"black\") +\n\n  # échelles\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0), # Supprimez l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n    date_breaks = \"3 weeks\", # Lundi toutes les 3 semaines\n    date_minor_breaks = \"week\", # lundi semaines \n    label = scales::label_date_short())+ # format des étiquettes automatique\n  \n  # étiquettes et theme\n  labs(title = \"Afficher les jours de déclaration provisoire\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank()) # supprimer le titre de la légende",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#étiquettes-de-date-à-plusieurs-niveaux",
    "href": "new_pages/epicurves.fr.html#étiquettes-de-date-à-plusieurs-niveaux",
    "title": "32  Courbes épidémiques",
    "section": "32.4 Étiquettes de date à plusieurs niveaux",
    "text": "32.4 Étiquettes de date à plusieurs niveaux\nSi vous voulez des étiquettes de date à plusieurs niveaux (par exemple, le mois et l’année) sans dupliquer les niveaux d’étiquette inférieurs, envisagez l’une des approches ci-dessous :\nRappelez-vous - vous pouvez utiliser des outils tels que \\n avec les arguments date_labels ou labels pour placer des parties de chaque étiquette sur une nouvelle ligne en dessous. Toutefois, les codes ci-dessous vous aident à placer les années ou les mois (par exemple) sur une ligne inférieure et seulement une fois.\nLa méthode la plus simple est l’argument labels = de scale_x_date() à la fonction label_date_short() du package scales (note : n’oubliez pas d’inclure des parenthèses vides (), comme indiqué ci-dessous). Cette fonction construira automatiquement des étiquettes de date efficaces (pour en savoir plus, cliquez ici). Un autre avantage de cette fonction est que les étiquettes s’adaptent automatiquement à l’évolution de vos données dans le temps : de jours, en semaines, en mois et en années.\n\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = weekly_breaks_central,   \n    closed = \"left\",                  \n    color = \"darkblue\",\n    fill = \"lightblue\") +\n\n  # y-axis \n  scale_y_continuous(expand = c(0,0))+\n  \n  # x-axis\n  scale_x_date(\n    expand = c(0,0),                      \n    date_breaks = \"1 month\", \n    labels = scales::label_date_short())+ # étiquettes de date efficaces\n  \n  # extra\n  labs(\n    title = \"Using label_date_short()\\nTo make automatic and efficient date labels\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()\n\n\n\n\n\n\n\n\nUne deuxième option consiste à utiliser le facettage. Ci-dessous :\n\nLe nombre de cas est agrégé en semaines pour des raisons esthétiques. Voir la page Epicurves (onglet données agrégées) pour plus de détails.\n\nUne ligne geom_area() est utilisée au lieu d’un histogramme, car l’approche par facettes ci-dessous ne fonctionne pas bien avec les histogrammes.\n\nAggréger en comptages hebdomadaires\n\n# créez un ensemble de données sur le nombre de cas par semaine.\n#######################################\ncentral_weekly &lt;- linelist %&gt;%\n  filter(hospital == \"Central Hospital\") %&gt;% # Filtrer linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %&gt;% # count(week) %&gt;% # count(week)  \n  count(week) %&gt;% # résume le nombre de cas hebdomadaires\n  drop_na(week) %&gt;% # Suppression des cas dont la date d'apparition est manquante\n  complete( # remplir toutes les semaines où aucun cas n'a été signalé\n    week = seq.Date(\n      from = min(week),   \n      to = max(week),\n      by = \"week\"),\n    fill = list(n = 0))                        # convertir les nouvelles valeurs NA en comptage 0\n\nFaire des graphiques\n\n# tracer avec une bordure de boîte sur l'année\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) + # établir x et y pour tout le graphique\n  geom_line(stat = \"identity\", # créer une ligne, la hauteur de la ligne est le nombre de comptage\n            color = \"#69b3a2\") + # couleur de la ligne\n  geom_point(size=1, color=\"#69b3a2\") + # faire des points aux points de données hebdomadaires\n  geom_area(fill = \"#69b3a2\", # zone de remplissage sous la ligne\n            alpha = 0.4)+ # transparence du remplissage\n  scale_x_date(date_labels=\"%b\", # format de l'étiquette de la date pour montrer le mois \n               date_breaks=\"month\", # étiquettes de date au 1er de chaque mois\n               expand=c(0,0)) + # supprimer l'espace excédentaire\n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x\n  facet_grid(~lubridate::year(week), # facette sur l'année (de la colonne de la classe Date)\n             space=\"free_x\",                \n             scales=\"free_x\", # les axes x s'adaptent à la plage de données (pas \"fixe\")\n             switch=\"x\") + # étiquettes des facettes (année) en bas de page\n  theme_bw() +\n  theme(strip.placement = \"outside\", # placement des étiquettes de facettes\n          strip.background = element_blank(), # pas de fond d'étiquette de facette\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(color=\"grey40\"), # bordure grise du PANEL de la facette\n          panel.spacing=unit(0, \"cm\"))+ # Pas d'espace entre les panneaux à facettes\n  labs(title = \"Étiquettes annuelles imbriquées - points, ombrées, bordure d'étiquette\")\n\n\n\n\n\n\n\n\nLes techniques ci-dessus ont été adaptées de this et this post sur stackoverflow.com.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#double-axe",
    "href": "new_pages/epicurves.fr.html#double-axe",
    "title": "32  Courbes épidémiques",
    "section": "32.5 Double axe",
    "text": "32.5 Double axe\nBien qu’il y ait des discussions acharnées sur la validité des doubles axes au sein de la communauté de visualisation des données, de nombreux superviseurs d’épi veulent toujours voir une épicurve ou un graphique similaire avec un pourcentage superposé à un deuxiéme axe. Ce sujet est abordé plus en détail dans la page ggplot tips, mais un exemple utilisant la méthode cowplot est présenté ci-dessous :\n\nDeux graphiques distincts sont créés, puis combinés avec le paquet cowplot.\n\nLes graphiques doivent avoir exactement le même axe des x (limites définies), sinon les données et les étiquettes ne seront pas alignées.\n\nChacun utilise theme_cowplot() et l’un d’entre eux a l’axe des y déplacé sur le côte droit du graphique\n\n\n#Chargez le paquet\npacman::p_load(cowplot)\n\n# Faire le premier tracé de l'histogramme épicurve\n#######################################\nplot_cases &lt;- linelist %&gt;% \n  \n  # Tracer les cas par semaine\n  ggplot()+\n  \n  # créer un histogramme  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks chaque semaine en commençant le lundi avant le premier cas, jusqu'au lundi aprés le dernier cas\n    closed = \"left\",\n    breaks = weekly_breaks_all)+ # vecteur prédéfini de dates hebdomadaires (voir en haut de la section ggplot)\n        \n  # spécifier le début et la fin de l'axe des dates pour l'aligner avec les autres graphiques\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+ # min/max des pauses hebdomadaires prédéfinies de l'histogramme\n  \n  # étiquettes\n  labs(\n      y = \"Cas quotidiens\",\n      x = \"Date d'apparition des symptômes\"\n    )+\n  theme_cowplot()\n\n\n# faire un second tracé du pourcentage de décés par semaine\n###########################################\nplot_deaths &lt;- linelist %&gt;% # commence avec linelist\n  group_by(week = floor_date(date_onset, \"week\")) %&gt;% # créer une colonne semaine\n  \n  # résumer pour obtenir le pourcentage hebdomadaire de cas décédés\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %&gt;% \n  \n  # commencer le tracé\n  ggplot()+\n  \n  # ligne du pourcentage hebdomadaire de décés\n  geom_line( # créer une ligne de pourcentage de décés\n    mapping = aes(x = week, y = pct_died), # spécifie la hauteur des y comme colonne pct_died\n    stat = \"identity\", # fixer la hauteur de la ligne à la valeur de la colonne pct_death, et non au nombre de lignes (par défaut)\n    size = 2,\n    color = \"black\")+\n  \n  # mêmes limites de l'axe des dates que l'autre graphique - alignement parfait\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+ # min/max des pauses hebdomadaires prédéfinies de l'histogramme\n  \n  \n  # ajustements de l'axe des y\n  scale_y_continuous( # ajuster l'axe des y\n    breaks = seq(0,100, 10), # définit les intervalles de rupture de l'axe des pourcentages\n    limits = c(0, 100), # définit l'étendue de l'axe des pourcentages\n    position = \"right\")+ # déplace l'axe des pourcentages vers la droite\n  \n  # étiquette pour l'axe des Y, pas d'étiquette pour l'axe des X\n  labs(x = \"\",\n       y = \"Pourcentage décédé\") +  # étiquette de l'axe des pourcentages\n  \n  theme_cowplot() # ajoutez ceci pour que les deux graphiques fusionnent bien ensemble\n\nUtilisez maintenant cowplot pour superposer les deux graphiques. Une attention particuliére a été portée à l’alignement de l’axe des x, au côte de l’axe des y et à l’utilisation de theme_cowplot().\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\n\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#incidence-cumulée",
    "href": "new_pages/epicurves.fr.html#incidence-cumulée",
    "title": "32  Courbes épidémiques",
    "section": "32.6 Incidence cumulée",
    "text": "32.6 Incidence cumulée\nCette page traitera de la façon de calculer l’incidence cumulée et de la tracer avec ggplot().\nSi vous commencez avec une liste de cas, créez une nouvelle colonne contenant le nombre cumulé de cas par jour dans une épidémie en utilisant cumsum() de base R :\n\ncumulative_case_counts &lt;- linelist %&gt;% \n  count(date_onset) %&gt;% # nombre de lignes par jour (retourné dans la colonne \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n) # nouvelle colonne du nombre cumulé de lignes à chaque date\n    )\n\nLes 10 premiéres lignes sont affichôes ci-dessous :\n\n\n\n\n\n\nCette colonne cumulative peut ensuite étre tracée en fonction de la date_onset, en utilisant `geom_line()`` :\n\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n\n\n\n\n\n\n\n\nOn peut aussi le superposer à l’épicurve, avec un double axe en utilisant la méthode cowplot décrite ci-dessus et dans la page ggplot tips :\n\n#charger le paquet\n\npacman::p_load(cowplot)\n\n\n# Faire le premier tracé de l'histogramme épicurve\nplot_cases &lt;- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Cas quotidiens\",\n    x = \"Date d'apparition des symptômes\"\n  ) +\n  theme_cowplot()\n\n# créer un second tracé de la ligne des cas cumulés\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cas cumulés\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\n\nUtilisez maintenant cowplot pour superposer les deux graphiques. Une attention particuliére a été portée à l’alignement de l’axe des x, au côte de l’axe des y et à l’utilisation de theme_cowplot().\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\n\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.fr.html#ressources",
    "href": "new_pages/epicurves.fr.html#ressources",
    "title": "32  Courbes épidémiques",
    "section": "32.7 Ressources",
    "text": "32.7 Ressources",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Courbes épidémiques</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.fr.html",
    "href": "new_pages/age_pyramid.fr.html",
    "title": "33  Pyramides démographiques et échelles de Likert",
    "section": "",
    "text": "33.1 Preparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pyramides démographiques et échelles de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.fr.html#preparation",
    "href": "new_pages/age_pyramid.fr.html#preparation",
    "title": "33  Pyramides démographiques et échelles de Likert",
    "section": "",
    "text": "Charger les packages\nCe morceau de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les packages installés avec library() à partir de la base R. Voir la page sur les bases de R pour plus d’informations sur les packages R.\n\npacman::p_load(rio,       # Pour importer les données\n               here,      # Pour localiser les fichiers\n               tidyverse, # Pour nettoyer, traiter et représenter les données (inclut le package ggplot2)\n               apyramid,  # Un package dédié à la création de pyramides des âges\n               janitor,   # Tableaux et nettoyage des données\n               stringr)   # Pour travailler avec des chaînes de caractères pour les titres, les légendes, etc.\n\n\n\nImporter les données\nPour commencer, nous importons la liste de cas nettoyée d’une épidémie d’Ebola simulée. Si vous voulez le faire en même temps, cliquez pour télécharger la liste des cas “nettoyée”. (sous le format .rds). Importez des données à l’aide de la fonction import() du package rio (elle gère de nombreux types de fichiers tels que .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# Importer la liste des cas dans R\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la liste des cas sont affichées ci-dessous.\n\n\n\n\n\n\n\n\nNettoyage\nPour réaliser une pyramide démographique traditionnelle par âge/sexe, les données doivent d’abord être nettoyées de la manière suivante :\n\nLa colonne sexe doit être nettoyée.\nSelon votre méthode, l’âge doit être stocké soit sous forme numérique, soit dans une colonne de catégorie d’âge.\n\nSi vous utilisez des catégories d’âge, les valeurs de la colonne doivent être ordonnées correctement, soit par défaut en alphanumérique, soit intentionnellement en convertissant en facteur de classe.\nCi-dessous nous utilisons tabyl() du package janitor pour inspecter les colonnes gender et age_cat5.\n\nlinelist %&gt;% \n  tabyl(age_cat5, gender)\n\n age_cat5   f   m NA_\n      0-4 640 416  39\n      5-9 641 412  42\n    10-14 518 383  40\n    15-19 359 364  20\n    20-24 305 316  17\n    25-29 163 259  13\n    30-34 104 213   9\n    35-39  42 157   3\n    40-44  25 107   1\n    45-49   8  80   5\n    50-54   2  37   1\n    55-59   0  30   0\n    60-64   0  12   0\n    65-69   0  12   1\n    70-74   0   4   0\n    75-79   0   0   1\n    80-84   0   1   0\n      85+   0   0   0\n     &lt;NA&gt;   0   0  86\n\n\nNous effectuons également un rapide histogramme sur la colonne age pour nous assurer qu’elle est propre et correctement classée :\n\nhist(linelist$age)",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pyramides démographiques et échelles de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.fr.html#le-package-apyramid",
    "href": "new_pages/age_pyramid.fr.html#le-package-apyramid",
    "title": "33  Pyramides démographiques et échelles de Likert",
    "section": "33.2 Le package apyramid",
    "text": "33.2 Le package apyramid\nLe package apyramid est un produit du projet R4Epis. Vous pouvez en savoir plus sur ce paquet ici. Il vous permet de réaliser rapidement une pyramide des âges. Pour des situations plus nuancées, voir la section ci-dessous utilisez ggplot(). Vous pouvez en savoir plus sur le package apyramid dans sa page d’aide en entrant ?age_pyramid dans votre console R.\n\nDonnées sous forme de liste des cas\nEn utilisant l’ensemble de données linelist nettoyées, nous pouvons créer une pyramide des âges avec une simple commande age_pyramid(). Dans cette commande :\n\nLe paramètre data = est défini comme le tableau de données linelist.\nLe paramètre age_group = (pour l’axe des ordonnées) est défini comme le nom de la colonne d’âge catégorique (entre guillemets).\nLe paramètre split_by = (pour l’axe des abscisses) est défini comme la colonne sexe.\n\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\n\n\n\n\n\n\n\n\nLa pyramide peut être affichée avec le pourcentage de tous les cas sur l’axe des abscisses, au lieu du nombre, en incluant proportional = TRUE.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\n\n\n\n\n\n\n\n\nLors de l’utilisation du package apyramid, si la colonne split_by est binaire (par exemple homme/femme, ou oui/non), le résultat apparaîtra comme une pyramide. Cependant, s’il y a plus de deux valeurs dans la colonne split_by (sans compter NA), la pyramide apparaîtra comme un diagramme à barres à facettes avec des barres grises dans le “fond” indiquant la plage des données non facettées pour ce groupe d’âge. Dans ce cas, les valeurs de split_by = apparaîtront comme des libellés en haut de chaque panneau de facettes. Par exemple, voici ce qui se passe si la colonne hospital est attribuée à split_by =.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  \n\n\n\n\n\n\n\n\n\nValeurs manquantes\nLes lignes qui ont des valeurs manquantes NA dans les colonnes split_by = ou age_group =, si elles sont codées comme NA, ne déclencheront pas les facettes indiquées ci-dessus. Par défaut, ces lignes ne seront pas affichées. Cependant, vous pouvez demander à ce qu’elle apparaissent dans un graphique à barres adjacent et en tant que groupe d’âge distinct en haut, en spécifiant na.rm = FALSE.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # Montre les patients dont l'âge ou le sexe est manquant\n\n\n\n\n\n\n\n\n\n\nProportions, couleurs et attributs graphiques\nPar défaut, les barres affichent les nombres (pas les pourcentages), une ligne en pointillés au milieu de chaque groupe est affichée, et les couleurs sont vertes/violettes. Chacun de ces paramètres peut être ajusté, comme indiqué ci-dessous :\nVous pouvez également ajouter des commandes ggplot() supplémentaires au graphique en utilisant la syntaxe standard de ggplot() “+”, comme des attributs graphiques et des ajustements de libellés :\n\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # afficher les pourcentages, pas les chiffres\n  show_midpoint = FALSE,            # supprimer la ligne du milieu de la barre\n  #pal = c(\"orange\", \"purple\")      # permet de préciser des couleurs alternatives (mais pas des libellés différents)\n  )+                 \n  \n  # commandes supplémentaires de ggplot\n  theme_minimal()+                               # simplifier le fond\n  scale_fill_manual(                             # préciser des couleurs ET des libellés\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # les libellés x et y sont inversées\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # légende en bas\n    axis.text = element_text(size = 10, face = \"bold\"),  # polices/tailles\n    axis.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nDonnées aggrégées\nLes exemples ci-dessus supposent que vos données sont au format de liste de cas, avec une ligne par observation. Si vos données sont déjà agrégées par catégorie d’âge, vous pouvez toujours utiliser le package apyramid, comme indiqué ci-dessous.\nPour la démonstration, nous agrégeons les données de la liste de cas en nombre de cas par catégorie d’âge et par sexe, dans un format “large”. Cela fera comme si vos données étaient aggrégées dès le départ. Pour en savoir plus sur le Regroupement des données et le Pivotage des données, consultez leurs pages respectives.\n\ndemo_agg &lt;- linelist %&gt;% \n  count(age_cat5, gender, name = \"cases\") %&gt;% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %&gt;% \n  rename(`missing_gender` = `NA`)\n\n…ce qui fait que le jeu de données ressemble à ceci : avec des colonnes pour la catégorie d’âge, et le nombre d’hommes, le nombre de femmes, et le nombre de valeurs manquantes.\n\n\n\n\n\n\nPour préparer ces données pour la pyramide des âges, nous allons faire pivoter les données pour qu’elles soient “longues” avec la fonction pivot_longer() de dplyr. Ceci est dû au fait que ggplot() préfère généralement les données “longues”, et apyramid utilise ggplot().\n\n# Faire pivoter les données agrégées afin qu'elles soient \"longues\"\ndemo_agg_long &lt;- demo_agg %&gt;% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # Colonnes à \"allonger\"\n    names_to = \"gender\",                # Nom de la nouvelle colonne de catégorie\n    values_to = \"counts\") %&gt;%           # Nom pour la nouvelle colonne de comptage\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # On convertit  \"missing_gender\" en NA\n\n\n\n\n\n\n\nUtilisez ensuite les arguments split_by = et count = de age_pyramid() pour spécifier les colonnes respectives dans les données :\n\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# Nom de la colonne pour la catégorie d'âge\n                      split_by = \"gender\",   # Nom de la colonne pour le sexe\n                      count = \"counts\")      # Nom de la colonne pour le nombre de cas\n\n\n\n\n\n\n\n\nNotez dans l’exemple ci-dessus que l’ordre des facteurs “m” et “f” est différent (pyramide inversée). Pour ajuster l’ordre, vous devez redéfinir le sexe dans les données agrégées comme un facteur et ordonner les niveaux comme vous le souhaitez. Voir la page Facteurs.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pyramides démographiques et échelles de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.fr.html#demo_pyr_gg",
    "href": "new_pages/age_pyramid.fr.html#demo_pyr_gg",
    "title": "33  Pyramides démographiques et échelles de Likert",
    "section": "33.3 ggplot()",
    "text": "33.3 ggplot()\nL’utilisation de ggplot() pour construire votre pyramide des âges offre plus de flexibilité, mais demande plus d’efforts et de compréhension du fonctionnement de ggplot(). Il est également plus facile de faire des erreurs accidentelles.\nPour utiliser ggplot() afin de créer des pyramides démographiques, vous devez créer deux diagrammes à barres (un pour chaque sexe), convertir les valeurs de l’un des diagrammes en valeurs négatives, et enfin inverser les axes x et y pour afficher les diagrammes à barres verticalement, leurs bases se rejoignant au milieu du diagramme.\n\nPréparation\nCette approche utilise une colonne d’âge sous forme numérique, et non la colonne catégorielle age_cat5. Nous allons donc vérifier que la classe de cette colonne est bien numérique.\n\nclass(linelist$age)\n\n[1] \"numeric\"\n\n\nVous pourriez utiliser la même logique ci-dessous pour construire une pyramide à partir de données catégorielles en utilisant geom_col() au lieu de geom_histogram().\n\n\n\nConstruction du graphe\nTout d’abord, il faut comprendre que pour réaliser une telle pyramide à l’aide de ggplot(), l’approche est la suivante :\n\nDans la fonction ggplot(), créez deux histogrammes en utilisant la colonne numérique de l’âge. Créez-en un pour chacune des deux valeurs de regroupement (dans ce cas, les sexes masculin et féminin). Pour ce faire, les données de chaque histogramme sont spécifiées dans leurs commandes geom_histogram() respectives, avec les filtres respectifs appliqués à linelist.\nUn graphique aura des valeurs de comptage positives, tandis que l’autre aura ses comptages convertis en valeurs négatives - cela crée la “pyramide” avec la valeur 0 au milieu du graphique. Les valeurs négatives sont créées en utilisant un terme spécial de ggplot2 ..count.. et en les multipliant par -1.\nLa commande coord_flip() permute les axes X et Y, ce qui a pour effet de rendre les graphiques verticaux et de créer la pyramide.\nEnfin, les étiquettes des valeurs de l’axe des comptes doivent être modifiées pour qu’elles apparaissent comme des comptes “positifs” des deux côtés de la pyramide (bien que les valeurs sous-jacentes d’un côté soient négatives).\n\nUne version simple de cette méthode, utilisant geom_histogram(), est présentée ci-dessous :\n\n  # commencer le ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # histogramme femmes\n  geom_histogram(data = linelist %&gt;% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # histogramme hommes (valeurs converties en négatif)\n  geom_histogram(data = linelist %&gt;% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # Inversion des axes X et Y\n  coord_flip() +\n  \n  # Ajustement de l'échelle de l'axe des nombres de cas\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n\n\n\n\n\n\n\n\nDANGER: Si les limites de votre axe de nombre de cas sont trop basses, et qu’une barre de compte les dépasse, la barre disparaîtra entièrement ou sera artificiellement raccourcie ! Faites attention à ce phénomène si vous analysez des données qui sont régulièrement mises à jour. Pour éviter cela, les limites de votre axe de comptage doivent s’ajuster automatiquement à vos données, comme ci-dessous\nIl y a beaucoup de choses que vous pouvez changer/ajoutez à cette version simple :\n\nAjuster automatiquement l’échelle de l’axe des comptes à vos données (éviter les erreurs discutées dans l’avertissement ci-dessous).\n\nSpécifier manuellement les couleurs et les étiquettes de légende\n\nConvertir les nombre de cas en pourcentages\nPour convertir les nombres de cas en pourcentages (du total), faites-le dans vos données avant de les représenter. Ci-dessous, nous obtenons les comptes d’âge et de sexe, puis on utilise ungroup(), et enfin mutate() pour créer de nouvelles colonnes de pourcentage. Si vous voulez des pourcentages par sexe, sautez l’étape de dégroupage.\n\n# créer un jeu de données avec la proportion du total\npyramid_data &lt;- linelist %&gt;%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %&gt;% \n  ungroup() %&gt;%                 # dégrouper de sorte à ce que les pourcentages ne soit pas par groupe\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent))    # convertir les hommes en négatif\n                              # les valeur NA doivent aussi être numériques\n\nIl est important de noter que nous enregistrons les valeurs max et min afin de connaître les limites de l’échelle. Elles seront utilisées dans la commande ggplot() ci-dessous.\n\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nmax_per\n\n[1] 10.9\n\nmin_per\n\n[1] -7.1\n\n\nEnfin, nous effectuons le ggplot() sur les données en pourcentage. Nous spécifions scale_y_continuous() pour étendre les longueurs prédéfinies dans chaque direction (“positive” et “négative”). Nous utilisons floor() et ceiling() pour arrondir les décimales dans la direction appropriée (vers le bas ou vers le haut) pour le côté de l’axe.\n\n# Commencer le ggplot\n  ggplot()+  # par défaut l'axe X est l'âge en années;\n\n  # graphe des données des cas\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # contour blanc autour de chaque barre\n  \n  # Inverser les axes X et Y pour rendre la pyramide verticale\n  coord_flip()+\n  \n\n  # Ajuster les échelles des axes\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # suite des valeurs deux par deux\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # suite des valeurs absolues deux par deux, avec \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # Préciser manuellement les couleurs et les étiquettes\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # Etiqueter les valeur (en se rappellant que X et Y sont inversés)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # Attributs graphiques et élements du thème\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )\n\n\n\n\n\n\n\n\n\n\n\nComparer à une référence\nGrâce à la flexibilité de ggplot(), vous pouvez avoir une deuxième couche de barres en arrière-plan qui représente la pyramide des âges “réelle” ou “de référence”. Cela peut fournir une visualisation agréable pour comparer les données observées avec les données de référence.\nImportez et visualisez les données de population (voir la page Télécharger le manuel et les données) :\n\n# i Import des données démographiques d'une population\npop &lt;- rio::import(\"country_demographics.csv\")\n\n\n\n\n\n\n\nTout d’abord, quelques étapes de gestion des données :\nNous enregistrons ici l’ordre des catégories d’âge que nous voulons voir apparaître. En raison de certaines bizarreries dans l’implémentation de ggplot(), dans ce scénario spécifique, il est plus facile de stocker ces données comme un vecteur de caractères et de les utiliser plus tard dans la fonction graphique.\n\n# enregistrer les niveaux d'âge catégoriel corrects\nage_levels &lt;- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n\nCombinez les données de population et de cas à l’aide de la fonction du paquet dplyr, bind_rows() :\n\nTout d’abord, assurez-vous qu’elles ont exactement les mêmes noms de colonnes, valeurs de catégories d’âge et valeurs de sexe.\n\nFaites en sorte qu’ils aient la même structure de données : colonnes de catégorie d’âge, de sexe, de nombre et de pourcentage du total.\n\nLiez-les ensemble, l’un au-dessus de l’autre (bind_rows()).\n\n\n# Créer/transformer les données de population, avec le pourcentage du total\n########################################################\npop_data &lt;- pop %&gt;% \n  pivot_longer(      # On faire \"pivoter\" la colonne sexe à l'aide de pivot_longer\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %&gt;% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % du total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent))  # Pour les hommes on converti le pourcentage en négatif\n\nExaminer les données de population modifiées\n\n\n\n\n\n\nOn peut maintenant faire la même chose pour les données des cas. C’est légèrement différent car elle commence par les lignes de cas et non par des totaux.\n\n# créer des données sur les cas par âge/sexe, avec le pourcentage du total\n#######################################################\ncase_data &lt;- linelist %&gt;%\n  count(age_cat5, gender, name = \"counts\") %&gt;%  # nombre par groupes age-sexe\n  ungroup() %&gt;% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculer le % du total pour les groupes d'âge et de sexe\n    percent = case_when(                                     # our les hommes on converti le pourcentage en négatif\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent))\n\nExaminer les données des cas modifiées\n\n\n\n\n\n\nLes deux jeux de données sont maintenant combinés, l’un au-dessus de l’autre (ils ont les mêmes noms de colonnes). Nous pouvons “nommer” chaque jeux de données, et utiliser l’argument .id = pour créer une nouvelle colonne “data_source” qui indiquera de quel cadre de données chaque ligne provient. Nous pouvons utiliser cette colonne pour filtrer dans la fonction ggplot().\n\n# combiner les données de cas et de population (mêmes noms de colonnes, valeurs age_cat et valeurs de sexe)\npyramid_data &lt;- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n\nEnregistre les valeurs maximales et minimales en pourcentage, utilisées dans la fonction de traçage pour définir l’étendue du tracé (et ne pas couper les barres !).\n\n# Définir l'étendue de l'axe des pourcentages, utilisé pour les limites du graphe.\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nLe graphique est maintenant réalisé avec ggplot() :\n\nUn graphique en barres des données de population (barres plus larges et plus transparentes)\nUn histogramme des données de cas (petites barres, plus solides)\n\n\n# Entamer le ggplot\n##############\nggplot()+  # l'axe des x par défaut est l'âge en années;\n\n  # Graphe des données de population\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # Contour noir autour des barres\n    alpha = 0.2,                                    # plus transparent\n    width = 1)+                                     # plein largeur\n  \n  # Graphe des données des cas\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # Catégorie d'âge comme axes des x d'origine\n      y = percent,                                # % comme axe des Y d'origine\n      fill = gender),                             # Couleur de remplissage des barres en fonctio ns du sexe\n    colour = \"black\",                               # Contour noir autour des barres\n    alpha = 1,                                      # pas transparent \n    width = 0.3)+                                   # largeur réduite\n  \n  # inversersion des axes X et Y pour rendre la pyramide verticale\n  coord_flip()+\n  \n  # s'assurer à la main que l'axe de l'âge est ordonné correctement\n  scale_x_discrete(limits = age_levels)+     # défini dans le morceua de code ci-dessus\n  \n  # définir l'axe des pourcentages \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # Le min et le max sont définis ci-dessus\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                #  De min_per (pourcentage minimum) à max_per (pourcentage maximum) par 2 \n    labels = paste0(                                                       # Pour les libellés, coller ensemble... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # Définir manuellement les couleurs et les étiquettes de légende\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # attribuer des couleurs aux valeurs des données\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # modifier les libellés qui apparaissent dans la légende, noté l'ordre\n  ) +\n\n  # Ajouter au graphes les libellés et les titres \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # Paramètres graphiques optionnels\n  theme(\n    legend.position = \"bottom\",                             # Deplacer la légende en bas du graphe\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pyramides démographiques et échelles de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.fr.html#échelle-de-likert",
    "href": "new_pages/age_pyramid.fr.html#échelle-de-likert",
    "title": "33  Pyramides démographiques et échelles de Likert",
    "section": "33.4 Échelle de Likert",
    "text": "33.4 Échelle de Likert\nLes techniques utilisées pour réaliser une pyramide des âges avec ggplot() peuvent également être utilisées pour réaliser des graphiques de données d’enquêtes à échelle de Likert.\nImportez les données (voir la page Télécharger le manuel et les données si vous le souhaitez).\n\n# importer les données de réponse de l'enquête likert\nlikert_data &lt;- rio::import(\"likert_data.csv\")\n\nCommencez avec des données qui ressemblent à ceci, avec une classification catégorielle de chaque répondant (statut) et leurs réponses à 8 questions sur une échelle de type Likert à 4 points (“Très mauvais”, “Mauvais”, “Bon”, “Très bon”).\n\n\n\n\n\n\nTout d’abord, quelques étapes de gestion des données :\n\nPivoter les données afin qu’elles soient “longues” plutôt que “larges”\nCréer une nouvelle colonne direction qui indique si une réponse était globalement “positive” ou “négative”\nDéfinisser l’ordre du niveau de Facteur pour la colonne status et la colonne Response\nEnregistrez la valeur maximale pour que les limites du graphique soient appropriées.\n\n\nmelted &lt;- likert_data %&gt;% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %&gt;% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # On inverse  'Very Poor' et 'Poor' pour que l'ordre soit le bon\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# Permet d'obtenir la plus grande valeur pour les limites d'échelle\nmelted_max &lt;- melted %&gt;% \n  count(status, Question) %&gt;% # nombre de ligne\n  pull(n) %&gt;%                 # Colonne 'n'\n  max(na.rm=T)                # Maximum\n\nMaintenant, créez le graphique. Comme dans les pyramides des âges ci-dessus, nous créons deux graphes à barres et inversons les valeurs de l’un d’entre eux en négatif.\nOn utilise geom_bar() parce que nos données sont une ligne par observation, et non pas des comptes agrégés. Nous utilisons le terme spécial de ggplot2 ..count.. dans l’un des graphiques en barres pour inverser les valeurs négatives (-1), et nous définissons position = \"stack\" pour que les valeurs s’empilent les unes sur les autres.\n\n# Créer le graphe\nggplot()+\n     \n  # graphique à barres des réponses \"négatives\" \n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # counts inverted to negative\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     #  graphique à barres des réponses \"positives\" \n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # inversion des axes x et y\n     coord_flip()+\n  \n     # Ligne noire verticale à 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # On convertit les libellés pour qu'il n'y ai que des chiffres positifs\n    scale_y_continuous(\n      \n      # limites de l'échelle des x\n      limits = c(-ceiling(melted_max/10)*11,    # séquence de négatif à positif par 10, bords arrondis vers l'extérieur au 5 le plus proche\n                 ceiling(melted_max/10)*10),   \n      \n      # valeurs de l'échelle de l'axe des x\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # libellés de l'échelle de l'axe des x\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # échelle de couleur attribuées manuellement\n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # attribue les couleurs\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # donne l'ordre de la légende\n     \n    \n     \n    # Convertit le graphe de sorte à ce que chaque sous graphe corresponde à une question\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # libellés, titres, légende\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # Paramètres graphiques \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # Titre de chaque sous graphique\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # Cadre noir autour de chaque sous graphique",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pyramides démographiques et échelles de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.fr.html#resources",
    "href": "new_pages/age_pyramid.fr.html#resources",
    "title": "33  Pyramides démographiques et échelles de Likert",
    "section": "33.5 Resources",
    "text": "33.5 Resources\nDocumentation de apyramid",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pyramides démographiques et échelles de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.fr.html",
    "href": "new_pages/heatmaps.fr.html",
    "title": "34  Graphiques thermiques",
    "section": "",
    "text": "34.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Graphiques thermiques</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.fr.html#préparation",
    "href": "new_pages/heatmaps.fr.html#préparation",
    "title": "34  Graphiques thermiques",
    "section": "",
    "text": "Chargement des paquets\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  tidyverse, # manipulation et visualisation de données\n  rio, # importation de données \n  lubridate # travail avec les dates\n  )\n\nEnsembles de données\nCette page utilise la liste de cas d’une épidémie simulée pour la section de la matrice de transmission, et un jeu de données séparé du nombre quotidien de cas de paludisme par établissement pour la section du suivi des mesures. Ils sont chargés et nettoyés dans leurs sections individuelles.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Graphiques thermiques</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.fr.html#matrice-de-transmission",
    "href": "new_pages/heatmaps.fr.html#matrice-de-transmission",
    "title": "34  Graphiques thermiques",
    "section": "34.2 Matrice de transmission",
    "text": "34.2 Matrice de transmission\nLes tuiles thermiques peuvent être utiles pour visualiser les matrices. Un exemple est d’afficher “qui a infecté qui” dans une épidémie. Cela suppose que vous disposiez d’informations sur les événements de transmission.\nNotez que la page Recherche des contacts contient un autre exemple de création d’une matrice de contacts en tuiles thermiques, à l’aide d’un ensemble de données différent (peut-être plus simple) où les âges des cas et leurs sources sont soigneusement alignés sur la même ligne du cadre de données. Ces mêmes données sont utilisées pour réaliser une carte de densité dans la page Astuces de ggplot. L’exemple ci-dessous part d’une liste de cas et implique donc une manipulation considérable des données avant d’obtenir un cadre de données traçable. Il existe donc de nombreux scénarios parmi lesquels choisir…\nNous commençons à partir de la liste de cas d’une épidémie d’Ebola simulée. Si vous souhaitez nous suivre, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation pour plus de détails).\nLes 50 premières lignes de la liste de lignes sont présentées ci-dessous à titre de démonstration :\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nDans cette linelist :\n\nIl y a une ligne par cas, identifié par case_id.\n\nIl y a une colonne ultérieure infector qui contient le case_id de l’infector, qui est aussi un cas dans la linelist\n\n\n\n\n\n\n\n\nPréparation des données\nObjectif : Nous devons obtenir un cadre de données de type “long” qui contient une ligne par route de transmission âge-âge possible, avec une colonne numérique contenant la proportion de cette ligne de tous les événements de transmission observés dans la liste de lignes.\nIl faudra plusieurs étapes de manipulation des données pour y parvenir :\n\nCréer un cadre de données pour les cas\nPour commencer, nous créons un cadre de données des cas, de leurs âges, et de leurs infecteurs - nous appelons ce cadre de données case_ages. Les 50 premières lignes sont affichées ci-dessous.\n\ncase_ages &lt;- linelist %&gt;% \n  select(case_id, infector, age_cat) %&gt;% \n  rename(\"case_age_cat\" = \"age_cat\")\n\n\n\n\n\n\n\n\n\nCréation d’un cadre de données d’infecteurs\nEnsuite, nous créons un cadre de données des infecteurs - pour l’instant, il est constitué d’une seule colonne. Il s’agit des identifiants des infecteurs de la liste de diffusion. Tous les cas n’ont pas un infecteur connu, nous supprimons donc les valeurs manquantes. Les 50 premières lignes sont affichées ci-dessous.\n\ninfectors &lt;- linelist %&gt;% \n  select(infector) %&gt;% \n  drop_na(infector)\n\n\n\n\n\n\n\nEnsuite, nous utilisons des jointures pour obtenir l’âge des infecteurs. Ce n’est pas simple, car dans la linelist, les âges des infecteurs ne sont pas listés en tant que tels. Nous obtenons ce résultat en joignant le cas linelist aux infecteurs. Nous commençons par les infecteurs, et left_join() (ajoutons) la case linelist de sorte que la colonne infector id du cadre de données “baseline” de gauche rejoint la colonne case_id du cadre de données linelist de droite.\nAinsi, les données de l’enregistrement du cas de l’infecteur dans la linelist (y compris l’âge) sont ajoutées à la ligne de l’infecteur. Les 50 premières lignes sont affichées ci-dessous.\n\ninfector_ages &lt;- infectors %&gt;% # commence par infectors\n  left_join( # ajoute les données de la linelist à chaque infecteur  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %&gt;% # faire correspondre l'infector à ses informations en tant que cas\n  select(infector, age_cat) %&gt;% # ne conserve que les colonnes d'intérêt\n  rename(\"infector_age_cat\" = \"age_cat\") # renommer pour plus de clarté\n\n\n\n\n\n\n\nEnsuite, nous combinons les cas et leurs âges avec les infecteurs et leurs âges. Chacun de ces cadres de données possède la colonne infector, elle est donc utilisée pour la jointure. Les premières lignes sont affichées ci-dessous :\n\nages_complete &lt;- case_ages %&gt;%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %&gt;% # chacun a la colonne infector\n  drop_na() # supprime les lignes avec des données manquantes\n\nWarning in left_join(., infector_ages, by = \"infector\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 6 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\nCi-dessous, un simple tableau croisé des chiffres entre les groupes d’âge des cas et des infecteurs. Des étiquettes ont été ajoutées pour plus de clarté.\n\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)\n\n       infectors\ncases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n  0-4   105 156   105   114   143   117    13   0\n  5-9   102 132   110   102   117    96    12   5\n  10-14 104 109    91    79   120    80    12   4\n  15-19  85 105    82    39    75    69     7   5\n  20-29 101 127   109    80   143   107    22   4\n  30-49  72  97    56    54    98    61     4   5\n  50-69   5   6    15     9     7     5     2   0\n  70+     1   0     2     0     0     0     0   0\n\n\nNous pouvons convertir ce tableau en un cadre de données avec data.frame() de base R, qui le convertit aussi automatiquement au format “long”, ce qui est souhaité pour le ggplot(). Les premières lignes sont présentées ci-dessous.\n\nlong_counts &lt;- data.frame(table(\n    cas = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\n\n\n\n\n\n\n\nMaintenant, nous faisons la même chose, mais nous appliquons prop.table() de base R au tableau pour qu’au lieu de compter, nous obtenions des proportions du total. Les 50 premières lignes sont affichées ci-dessous.\n\nlong_prop &lt;- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))\n\n\n\n\n\n\n\n\n\n\nCréer un diagramme de chaleur\nMaintenant, nous pouvons enfin créer le graphique de chaleur avec le paquet ggplot2, en utilisant la fonction geom_tile(). Consultez la page Astuces de ggplot pour en savoir plus sur les échelles de couleur et de remplissage, en particulier la fonction scale_fill_gradient().\n\nDans l’esthétique aes() de geom_tile(), définissez x et y comme l’âge du cas et l’âge de l’infecteur.\n\nDe plus, dans aes(), mettez l’argument fill = dans la colonne Freq - c’est la valeur qui sera convertie en une couleur de tuile.\n\nDéfinissez une couleur d’échelle avec scale_fill_gradient() - vous pouvez spécifier les couleurs hautes et basses.\n\nNotez que scale_color_gradient() est différent ! Dans ce cas, vous voulez le remplissage\n\n\nComme la couleur est faite via “fill”, vous pouvez utiliser l’argument fill = dans labs() pour changer le titre de la légende.\n\n\nggplot(data = long_prop)+ # utilise des données longues, avec des proportions comme Freq\n  geom_tile( # visualisation en tuiles\n    aes(\n      x = cases, # l'axe des x est l'âge du cas\n      y = infectors, # l'axe des y est l'âge de l'infecteur\n      fill = Freq))+ # la couleur de la tuile correspond à la colonne Freq dans les données\n  scale_fill_gradient( # ajuste la couleur de remplissage des tuiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs( # étiquettes\n    x = \"Âge du cas\",\n    y = \"Âge du contaminateur\",\n    title = \"Qui a infecté qui\",\n    subtitle = \"Matrice de fréquence des événements de transmission\",\n    fill = \"Proportion de tous les événements de transmission\" # titre de la légende\n  )",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Graphiques thermiques</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.fr.html#rapport-sur-les-mesures-dans-le-temps",
    "href": "new_pages/heatmaps.fr.html#rapport-sur-les-mesures-dans-le-temps",
    "title": "34  Graphiques thermiques",
    "section": "34.3 Rapport sur les mesures dans le temps",
    "text": "34.3 Rapport sur les mesures dans le temps\nSouvent, en santé publique, un objectif est d’évaluer les tendances dans le temps pour de nombreuses entités (établissements, juridictions, etc.). Une façon de visualiser ces tendances dans le temps est un diagramme de chaleur où l’axe des x est le temps et l’axe des y sont les nombreuses entités.\n\nPréparation des données\nNous commençons par importer un jeu de données de rapports quotidiens sur le paludisme provenant de nombreux établissements. Les rapports contiennent une date, une province, un district et un nombre de cas de paludisme. Voir la page Télécharger le manuel et les données pour savoir comment télécharger ces données. Voici les 30 premières lignes :\n\nfacility_count_data &lt;- import(\"malaria_facility_count_data.rds\")\n\n\n\n\n\n\n\n\nAgréger et résumer\nL’objectif de cet exemple est de transformer les comptages quotidiens de cas de paludisme totaux de l’établissement (vus dans l’onglet précédent) en statistiques récapitulatives hebdomadaires des performances de déclaration de l’établissement - dans ce cas, la proportion de jours par semaine où l’établissement a déclaré des données. Pour cet exemple, nous allons montrer les données uniquement pour le District de Spring.\nPour ce faire, nous allons procéder aux étapes suivantes de gestion des données :\n\nFiltrer les données comme il convient (par lieu, par date).\n\nCréer une colonne hebdomadaire en utilisant floor_date() du package lubridate.\n\nCette fonction renvoie la date de début de la semaine d’une date donnée, en utilisant une date de début spécifiée de chaque semaine (par exemple “Lundi”)\n\n\nLes données sont regroupées par les colonnes “lieu” et “semaine” pour créer des unités d’analyse de “semaine d’installation”.\n\nLa fonction summarise() crée de nouvelles colonnes pour refléter les statistiques sommaires par groupe de semaine d’installation :\n\nNombre de jours par semaine (7 - une valeur statique)\n\nNombre de rapports reçus de la semaine d’installation (peut être plus de 7 !)\n\nSomme des cas de malaria rapportés par la semaine d’installation (juste pour l’intérêt)\n\nNombre de jours uniques dans la semaine d’installation pour lesquels des données ont été rapportées.\nPourcentage des 7 jours par semaine d’installation pour lesquels des données ont été déclarées.\n\n\nLe cadre de données est joint avec right_join() à une liste complète de toutes les combinaisons possibles de semaine d’installation, pour rendre l’ensemble de données complet. La matrice de toutes les combinaisons possibles est créée en appliquant expand() aux deux colonnes du cadre de données tel qu’il est à ce moment-là dans la chaîne de production (représenté par .). Comme un right_join() est utilisé, toutes les lignes du cadre de données expand() sont conservées, et ajoutées à agg_weeks si nécessaire. Ces nouvelles lignes apparaissent avec des valeurs résumées NA (manquantes).\n\nNous faisons ci-dessous une démonstration étape par étape :\n\n# Créer un ensemble de données de résumé hebdomadaire\nagg_weeks &lt;- facility_count_data %&gt;% \n  \n  # Filtrez les données comme il se doit\n  filter(\n    District == \"Spring\",\n    data_date &lt; as.Date(\"2020-08-01\")) \n\nMaintenant, le jeu de données a 608 lignes, alors qu’il avait précédemment 3038.\nEnsuite, nous créons une colonne week reflétant la date de début de la semaine pour chaque enregistrement. Ceci est réalisé avec le package lubridate et la fonction floor_date(), qui est définie sur “week” et pour que les semaines commencent le lundi (jour 1 de la semaine - le dimanche serait le 7). Les lignes du haut sont présentées ci-dessous.\n\nagg_weeks &lt;- agg_weeks %&gt;% \n  # Créez une colonne semaine à partir de data_date\n  mutate(\n    week = lubridate::floor_date( # créer une nouvelle colonne de semaines\n      data_date, # colonne de date\n      unit = \"week\", # donne le début de la semaine\n      week_start = 1))                                # les semaines commencent le lundi \n\nLa nouvelle colonne de semaine est visible à l’extrême droite du cadre de données.\n\n\n\n\n\n\nMaintenant, nous regroupons les données en semaines d’installation et les résumons pour produire des statistiques par semaine d’installation. Consultez la page sur les Tableaux descriptifs pour obtenir des conseils. Le regroupement en lui-même ne modifie pas la trame de données, mais il a un impact sur la façon dont les statistiques récapitulatives suivantes sont calculées.\nLes lignes du haut sont présentées ci-dessous. Notez comment les colonnes ont complètement changé pour refléter les statistiques récapitulatives souhaitées. Chaque ligne reflète une semaine d’installation.\n\nagg_weeks &lt;- agg_weeks %&gt;%   \n\n  # Regroupement en semaines d'installation\n  group_by(location_name, week) %&gt;%\n  \n  # Créez des colonnes de statistiques récapitulatives sur les données groupées\n  summarize(\n    n_days = 7, # 7 jours par semaine           \n    n_reports = dplyr::n(), # nombre de rapports reçus par semaine (peut être &gt;7)\n    malaria_tot = sum(malaria_tot, na.rm = T), # nombre total de cas de paludisme signalés\n    n_days_reported = length(unique(data_date)), # nombre de jours uniques de déclaration par semaine\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;%      # pourcentage de jours de déclaration\n  ungroup(location_name, week)    #ungroup() alors expand() marche dans les prochaines etapes\n\n\n\n\n\n\n\nEnfin, nous exécutons la commande ci-dessous pour nous assurer que TOUTES les semaines d’installation possibles sont présentes dans les données, même si elles étaient absentes auparavant.\nNous utilisons un right_join() sur lui-même (l’ensemble de données est représenté par “.”) mais il a été étendu pour inclure toutes les combinaisons possibles des colonnes week et location_name. Voir la documentation sur la fonction expand() dans la page sur Pivoter les donnees. Avant d’exécuter ce code, l’ensemble de données contient 107 lignes.\n\n# Créez un cadre de données pour chaque semaine d'installation possible.\nexpanded_weeks &lt;- agg_weeks %&gt;% \n  tidyr::expand(location_name, week) # étendre le cadre de données pour inclure toutes les combinaisons possibles établissement-semaine\n\nVoici expanded_weeks, avec 180 lignes:\n\n\n\n\n\n\nAvant d’exécuter ce code, agg_weeks contient 107 lignes.\n\n# Utilisez une jointure à droite avec la liste étendue des semaines d'installation pour combler les lacunes dans les données.\nagg_weeks &lt;- agg_weeks %&gt;%      \n  right_join(expanded_weeks) %&gt;% # Assurez-vous que toutes les combinaisons possibles de semaines d'installation apparaissent dans les données.\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # Convertir les valeurs manquantes en 0                           \n\nJoining with `by = join_by(location_name, week)`\n\n\nAprès avoir exécuté ce code, agg_weeks contient 180 lignes.\n\n\n\n\nCréer un graphique de chaleur\nLe ggplot() est réalisé en utilisant geom_tile() du paquet ggplot2 :\n\nLes semaines sur l’axe des x sont transformées en dates, permettant l’utilisation de scale_x_date().\n\nL’axe des ordonnées affiche tous les noms des établissements.\n\nLe “remplissage” est “p_days_reported”, la performance pour cette semaine d’installation (numérique).\n\nscale_fill_gradient() est utilisé sur le remplissage numérique, en spécifiant des couleurs pour le haut, le bas, et NA.\n\nLa fonction scale_x_date() est utilisée sur l’axe des x pour spécifier les étiquettes toutes les 2 semaines et leur format.\n\nLes thèmes d’affichage et les étiquettes peuvent être ajustés si nécessaire.\n\n\n\n\nBasique\nUn graphique thermique de base est produit ci-dessous, en utilisant les couleurs, les échelles, etc. par défaut. Comme expliqué ci-dessus, dans le aes() pour le geom_tile() vous devez fournir une colonne pour l’axe des x, une colonne pour l’axe des y, et une colonne pour le fill =. Le remplissage est la valeur numérique qui présente comme couleur de tuile.\n\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))\n\n\n\n\n\n\n\n\n\n\nTracé nettoyé\nNous pouvons améliorer l’apparence de ce graphique en ajoutant des fonctions ggplot2 supplémentaires, comme indiqué ci-dessous. Voir la page sur les astuces de ggplot pour plus de détails.\n\nggplot(data = agg_weeks)+ \n  \n  # affiche les données sous forme de tuiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+ # lignes de grille blanches\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # axe des dates\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace supplémentaire sur les côtés\n    date_breaks = \"2 weeks\", # étiquettes toutes les 2 semaines\n    date_labels = \"%d\\n%b\")+ # le format est jour sur mois (\\n dans la nouvelle ligne)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier l'arrière-plan\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1, \"cm\"), # hauteur de la clé de légende\n    legend.key.width = grid::unit(0.6, \"cm\"), # largeur de la clé de légende\n    \n    axis.text.x = element_text(size=12), # taille du texte de l'axe\n    axis.text.y = element_text(vjust=0.2), # alignement du texte de l'axe\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"), # taille et gras du titre de l'axe\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"), # titre aligné à droite, large, gras\n    plot.caption = element_text(hjust = 0, face = \"italic\"), # légende alignée à droite et en italique\n    )+\n  \n  # étiquettes du graphique\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Reporting\\nperformance (%)\", # titre de la légende, car la légende montre le remplissage\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \"Établissements de santé du district, mai-juillet 2020\",\n       caption = \"Semaines de 7 jours commençant le lundi\")\n\n\n\n\n\n\n\n\n\n\n\nAxe des y ordonné\nActuellement, les installations sont ordonnées “alpha-numériquement” de bas en haut. Si vous voulez ajuster l’ordre des installations de l’axe des y, convertissez-les en facteur de classe et fournissez l’ordre. Voir la page sur les Facteurs pour des conseils.\nPuisqu’il y a beaucoup d’installations et que nous ne voulons pas les écrire toutes, nous allons essayer une autre approche - classer les installations dans un cadre de données et utiliser la colonne de noms résultante comme ordre de niveau de facteur. Ci-dessous, la colonne location_name est convertie en un facteur, et l’ordre de ses niveaux est établi sur la base du nombre total de jours de déclaration déposés par l’installation sur l’ensemble de la période.\nPour ce faire, nous créons un cadre de données qui représente le nombre total de rapports par établissement, classés par ordre croissant. Nous pouvons utiliser ce vecteur pour ordonner les niveaux de facteurs dans le graphique.\n\nfacility_order &lt;- agg_weeks %&gt;% \n  group_by(location_name) %&gt;% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %&gt;% \n  arrange(tot_reports) # ordre ascendant\n\nVoir le cadre de données ci-dessous :\n\n\n\n\n\n\nUtilisez maintenant une colonne du cadre de données ci-dessus (facility_order$location_name) comme ordre des niveaux de facteur de location_name dans le cadre de données agg_weeks :\n\n# charger le paquet \npacman::p_load(forcats)\n\n# créer le facteur et définir les niveaux manuellement\nagg_weeks &lt;- agg_weeks %&gt;% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\n\nEt maintenant, les données sont à nouveau tracées, le nom de l’emplacement étant un facteur ordonné :\n\nggplot(data = agg_weeks)+ \n  \n  # afficher les données sous forme de tuiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+ # lignes de grille blanches\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # axe des dates\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace supplémentaire sur les côtés\n    date_breaks = \"2 weeks\", # étiquettes toutes les 2 semaines\n    date_labels = \"%d\\n%b\")+ # le format est jour sur mois (\\n dans la nouvelle ligne)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier l'arrière-plan\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1, \"cm\"), # hauteur de la clé de légende\n    legend.key.width = grid::unit(0.6, \"cm\"), # largeur de la clé de légende\n    \n    axis.text.x = element_text(size=12), # taille du texte de l'axe\n    axis.text.y = element_text(vjust=0.2), # alignement du texte de l'axe\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"), # taille et gras du titre de l'axe\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"), # titre aligné à droite, large, gras\n    plot.caption = element_text(hjust = 0, face = \"italic\"), # légende alignée à droite et en italique\n    )+\n  \n  # étiquettes du graphique\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Reporting\\nperformance (%)\", # titre de la légende, car la légende montre le remplissage\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \"Établissements de santé du district, mai-juillet 2020\",\n       caption = \"Semaines de 7 jours commençant le lundi\")\n\n\n\n\n\n\n\n\n\n\n\nAfficher les valeurs\nVous pouvez ajouter une couche geom_text() au dessus des tuiles, pour afficher les numéros réels de chaque tuile. Attention, cela peut ne pas être joli si vous avez beaucoup de petites tuiles !\nLe code suivant a été ajouté : geom_text(aes(label = p_days_reported)). Ceci ajoute du texte sur chaque tuile. Le texte affiché est la valeur assignée à l’argument label =, qui dans ce cas a été fixé à la même colonne numérique p_days_reported qui est aussi utilisée pour créer le gradient de couleur.\n\nggplot(data = agg_weeks)+ \n  \n  # affiche les données sous forme de tuiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+ # lignes de grille blanches\n  \n  # Texte\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+ # ajouter le texte au dessus de la tuile\n  \n  # remplir l'échelle\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # axe des dates\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace supplémentaire sur les côtés\n    date_breaks = \"2 weeks\", # étiquettes toutes les 2 semaines\n    date_labels = \"%d\\n%b\")+ # le format est jour sur mois (\\n dans la nouvelle ligne)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier l'arrière-plan\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1, \"cm\"), # hauteur de la clé de légende\n    legend.key.width = grid::unit(0.6, \"cm\"), # largeur de la clé de légende\n    \n    axis.text.x = element_text(size=12), # taille du texte de l'axe\n    axis.text.y = element_text(vjust=0.2), # alignement du texte de l'axe\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"), # taille et gras du titre de l'axe\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"), # titre aligné à droite, large, gras\n    plot.caption = element_text(hjust = 0, face = \"italic\"), # légende alignée à droite et en italique\n    )+\n  \n  # étiquettes du graphique\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Reporting\\nperformance (%)\", # titre de la légende, car la légende montre le remplissage\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \"Établissements de santé du district, mai-juillet 2020\",\n       caption = \"Semaines de 7 jours commençant le lundi\")",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Graphiques thermiques</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.fr.html#ressources",
    "href": "new_pages/heatmaps.fr.html#ressources",
    "title": "34  Graphiques thermiques",
    "section": "34.4 Ressources",
    "text": "34.4 Ressources\nscale_fill_gradient()\nGalerie de graphiques R - carte thermique",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Graphiques thermiques</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html",
    "href": "new_pages/diagrams.fr.html",
    "title": "35  Diagrammes et schémas",
    "section": "",
    "text": "35.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html#préparation",
    "href": "new_pages/diagrams.fr.html#préparation",
    "title": "35  Diagrammes et schémas",
    "section": "",
    "text": "Chargement des paquets\nCe chunk de code montre le chargement des paquets nécessaires pour les analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets bases de R.\n\npacman::p_load(\n  DiagrammeR, # pour les diagrammes de flux\n  networkD3, # pour les diagrammes alluviaux/Sankey\n  tidyverse) # gestion et visualisation des données\n\n\n\nImporter des données\nLa plupart du contenu de cette page ne nécessite pas de jeu de données. Cependant, dans la section sur le diagramme de Sankey, nous utiliserons la liste de cas d’une simulation d’épidémie d’Ebola. Si vous souhaitez suivre cette partie, cliquez pour télécharger la liste de cas “propre” (en fichier format .rds). Importez les données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# Importez la liste de cas\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la linelist sont affichées ci-dessous.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html#diagrammes-de-flux",
    "href": "new_pages/diagrams.fr.html#diagrammes-de-flux",
    "title": "35  Diagrammes et schémas",
    "section": "35.2 Diagrammes de flux",
    "text": "35.2 Diagrammes de flux\nOn peut utiliser le paquet R DiagrammeR pour créer des diagrammes/schémas de flux. Ils peuvent être statiques, ou s’ajuster dynamiquement en fonction des changements dans un ensemble de données.\nOutils\nLa fonction grViz() est utilisée pour créer un diagramme “Graphviz”. Cette fonction accepte une chaîne de caractères en entrée contenant les instructions pour réaliser le diagramme. Dans cette chaîne de caractères, les instructions sont écrites dans un langage différent, DOT; il est assez facile d’apprendre les bases de le langage DOT.\nStructure de base\n\nOuvrez les instructions grViz(\"\n\nSpécifiez la direction et le nom du graphique, et ouvrez les parenthèses, par exemple digraph mon_diagramme_de_flux {\nDéclaration du graphique (disposition, direction du rang)\n\nDéclaration des noeuds (crée les noeuds)\nDéclarations de contours/bords (donne les liens entre les noeuds)\n\nFermer les instructions }\")\n\n\nExemples simples\nVous trouverez ci-dessous deux exemples simples\nUn exemple très minimal :\n\n## Un tracé minimal\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -&gt; b -&gt; c\n}\")\n\n\n\n\n\nUn exemple avec un contexte de santé publique un peu plus appliqué :\n\n# Toutes les instructions se trouvent dans une grande chaîne de caractères\n# 'digraph' signifie 'graphique directionnel', puis le nom du graphique \n\n# déclaration du graphique, déclaration des noueds, forme et largeur de noueds, noms des noeuds, bords ou contours\n  #######\n  #################\n\ngrViz(\"    \ndigraph surveillance_diagram { \n  \n  \n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  \n  node [shape = circle, \n       fixedsize = true\n       width = 1.3]               \n  \n  Primary\n  Secondary\n  Tertiary\n\n  \n  Primary -&gt; Secondary [label = ' transfert de cas']\n  Secondary -&gt; Tertiary [label = ' transfert de cas']\n}\n\")\n\n\n\n\n\n\n\nSyntaxe\nSyntaxe de base\nLes noms de nouds, ou les déclarations de bords, peuvent être séparés par des espaces, des points-virgules ou des nouvelles lignes.\nDirection du rang\nUn graphique peut être réorienté pour se déplacer de gauche à droite en ajustant l’argument rankdir dans la déclaration du graphique. Le défaut est TB (top-to-bottom; de haut en bas), mais il peut être LR (left-to-right, gauche-à-droite), ou l’inverse (RL,BT).\nNoms de nouds\nLes noms de noeuds peuvent être des mots simples, comme dans l’exemple ci-dessus. Pour utiliser des noms de plusieurs mots ou des caractères spéciaux (par exemple, parenthèses, tirets), placez le nom du noud entre guillemets simples (’ ’). Il peut être plus facile d’avoir un nom de nœud court et d’attribuer un label, comme indiqué ci-dessous entre crochets [ ]. Si vous voulez avoir une nouvelle ligne dans le nom du nœud, vous devez le faire via une étiquette. Utilisez \\n dans l’étiquette du nœud entre guillemets simples, comme indiqué ci-dessous.\nSous-groupes\nDans les déclarations des bords/contours, des sous-groupes peuvent être créés de chaque côté de le bords avec des crochets ({ }). Le bord s’applique alors à tous les nouds entre crochets. Ceci est un raccourci.\nMise en page\n\ndot (définir rankdir comme soit TB, LR, RL, ou BT)\nneato\n\ntwopi\n\ncirco\n\nNoeuds - attributs modifiables\n\nlabel (texte, entre guillemets simples si plusieurs mots)\n\nfillcolor (plusieurs couleurs possibles)\n\nfontcolor\n\nalpha (transparence 0-1)\n\nshape (ellipse, ovale, diamant, ouf, texte en clair, point, carré, triangle)\n\nstyle\n\nsides\n\nperipheries\n\nfixedsize (h x l)\n\nheight\n\nwidth\n\ndistortion\n\npenwidth (largeur de la bordure de la forme)\n\nx (déplacement gauche/droite)\n\ny (déplacement haut/bas)\n\nfontname\n\nfontsize\n\nicon\n\nBords - attributs modifiables\n\narrowsize\n\narrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)\n\narrowtail\n\ndir (direction, )\n\nstyle (pointillé, …)\n\ncolor\n\nalpha\n\nheadport (texte devant la tête de la flèche)\n\ntailport (texte situé derrière la queue de flèche)\n\nfontname\n\nfontsize\n\nfontcolor (couleur de la police)\n\npenwidth (largeur de la flèche)\n\nminlen (longueur minimale)\n\nNoms de couleurs : valeurs hexadécimales ou noms de couleurs ‘X11’, voir ici pour les détails sur X11\n\n\nExemples complexes\nL’exemple ci-dessous développe le diagramme de surveillance, en ajoutant des noms de noeuds complexes, des bords groupées, des couleurs et un style spécifique.\n\n# Toutes les instructions se trouvent dans une grande chaîne de caractères\n# 'digraph' signifie 'graphique directionnel', puis le nom du graphique \n# déclaration du graphique\n# disposition de haut en bas\n  #################\n# nouds (formes cercles)\n  #################\n  #bords et bord groupé\n\n\n\nDiagrammeR::grViz(\" \ndigraph surveillance_diagram { \n  \n  \n  graph [layout = dot,\n         rankdir = TB, \n         fontsize = 10]\n  \n\n  \n  node [shape = circle, \n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary [label = 'Site Primaire'] \n  Secondary [label = 'Site Secondaire'] \n  Tertiary [label = 'Site Tertiaire'] \n  SC [label = 'Coordination de\\nla Surveillance',\n             fontcolor = darkgreen] \n\n\n  Primary -&gt; Secondary [label = 'Transfert de cas',\n                          fontcolor = red,\n                          color = red]\n  Secondary -&gt; Tertiary [label = 'Transfert de cas',\n                          fontcolor = red,\n                          color = red]\n  \n\n  {Primary Secondary Tertiary} -&gt; SC [label = 'déclaration des cas',\n                                      fontcolor = darkgreen,\n                                      couleur = darkgreen,\n                                      style = dashed]\n}\n\")\n\n\n\n\n\nGroupements de sous-graphiques\nPour regrouper les noeuds dans des clusters encadrés, placez-les dans le même sous-graphique nommé (subgraph name {}). Pour que chaque sous-graphe soit identifié dans une boîte de délimitation, commencez le nom du sous-graphique par “cluster”, comme le montrent les 4 boîtes ci-dessous.\n\nDiagrammeR::grViz(\"             # All instructions are within a large character string\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n  # nodes (circles)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # width of circles\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Site Primaire'] \n    Secondary [label = 'Site Secondaire'] \n    Tertiary  [label = 'Site Tertiaire'] \n    SC        [label = 'Coordination de\\nla Surveillance',\n               fontcolor = darkgreen] \n  }\n  \n  # nodes (boxes)\n  ###############\n  node [shape = box,                     # node shape\n        fontname = Helvetica]            # text font in node\n  \n  subgraph cluster_active {\n    Active [label = 'Surveillance\\nActive'] \n    HCF_active [label = 'HCF\\nRecherche Active']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Surveillance basée sur\\n les événements (SBE)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Surveillance basée sur\\n les communautés(SBC)']\n    RECOs\n  }\n  \n  # edges\n  #######\n  {Primary Secondary Tertiary} -&gt; SC [label = 'déclaration des cas']\n  Primary   -&gt; Secondary [label = 'transfert de cas',\n                          fontcolor = red]\n  Secondary -&gt; Tertiary [label = 'transfert de cas',\n                          fontcolor = red]\n  \n  HCF_active -&gt; Active\n  \n  {'Social Media' Radio} -&gt; EBS\n  \n  RECOs -&gt; CBS\n}\n\")\n\n\n\n\n\nFormes des nouds\nL’exemple ci-dessous, emprunté à ce tutoriel, montre les formes de nouds appliquées et une abréviation pour les connexions de bords en série.\n\n# définir les styles globaux des noeuds. Nous pouvons les remplacer dans la boîte si nous le souhaitons.\n# définitions des bords avec les ID des nouds\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataframe 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataframe 2', shape = folder, fillcolor = Beige]\nprocess [label = 'Process \\n Data']\nstatistical [label = 'Analyse\\nStatistique'] \nresults [label= 'Résultats']\n\n\n{data1 data2} -&gt; process -&gt; statistical -&gt; results\n}\")\n\n\n\n\n\n\n\nSorties\nComment gérer et sauvegarder les sorties\n\nLes résultats apparaîtront dans le volet de visualisation de RStudio, par défaut dans le coin inférieur droit, à côté de Files, Plots, Packages et Help.\n\nPour exporter, vous pouvez “Enregistrer en tant qu’image” ou “Copier a le presse-papiers” à partir de la Viewer. Le graphique s’ajustera à la taille spécifiée.\n\n\n\nFigures paramétrées\nVoici une citation de ce tutoriel : https://mikeyharper.uk/flowcharts-in-r-using-diagrammer/\n“Figures paramétrées : L’un des grands avantages de la conception de figures dans R est que nous sommes en mesure de connecter les figures directement à notre analyse en lisant les valeurs R directement dans nos schemas de flux. Par exemple, supposons que vous ayez créé un processus de filtrage qui supprime les valeurs après chaque étape d’un processus, vous pouvez avoir une figure montrant le nombre de valeurs restantes dans l’ensemble de données après chaque étape de votre processus. Pour ce faire, vous pouvez utiliser le symbole @@X directement dans la figure, puis y faire référence dans le pied de page du graphique en utilisant [X] :, où X est un indice numérique unique.”\nNous vous encourageons à revoir ce tutoriel si le paramétrage est quelque chose qui vous intéresse.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html#diagrammes-alluvialsankey",
    "href": "new_pages/diagrams.fr.html#diagrammes-alluvialsankey",
    "title": "35  Diagrammes et schémas",
    "section": "35.3 Diagrammes Alluvial/Sankey",
    "text": "35.3 Diagrammes Alluvial/Sankey\n\nChargement des paquets\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\nNous chargeons le paquet networkD3 pour produire le diagramme, et aussi tidyverse pour les étapes de préparation des données.\n\npacman::p_load(\n  networkD3,\n  tidyverse)\n\n\n\nGraphique à partir d’un ensemble de données\nTracer les connexions dans un jeu de données. Nous démontrons ci-dessous l’utilisation de le package networkD3 sur le cas linelist. Voici un tutoriel en ligne.\nNous commençons par obtenir le nombre de cas pour chaque combinaison unique de catégorie d’âge et d’hôpital. Pour plus de clarté, nous avons supprimé les valeurs dont la catégorie d’âge est manquante. Nous renommons également les colonnes hospital et age_cat en source et target respectivement. Ce seront les deux côtés du diagramme alluvial.\n\n# comptes par hôpital et par catégorie d'âge\nlinks &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = hospital,\n         target = age_cat)\n\nL’ensemble de données ressemble maintenant à ceci :\n\n\n\n\n\n\nMaintenant, nous créons un jeu de données de tous les noeuds du diagramme, sous la colonne name. Il s’agit de toutes les valeurs de hospital et age_cat. Notez que nous nous assurons qu’elles sont toutes de classe caractères avant de les combiner, et ajustons les colonnes ID pour qu’elles soient des numeros au lieu d’étiquettes :\n\n# Les noms uniques des noeuds\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\nnodes # imprimer\n\n                                   name\n1                      Central Hospital\n2                     Military Hospital\n3                               Missing\n4                                 Other\n5                         Port Hospital\n6  St. Mark's Maternity Hospital (SMMH)\n7                                   0-4\n8                                   5-9\n9                                 10-14\n10                                15-19\n11                                20-29\n12                                30-49\n13                                50-69\n14                                  70+\n\n\nNous éditons le cadre de données links, que nous avons créé ci-dessus avec count(). Nous ajoutons deux colonnes numériques, IDsource et IDtarget, qui reflèteront/créeront réellement les liens entre les noeuds. Ces colonnes contiendront les numéros numéros de rangs (position) des noeuds de source et de target. On soustrait 1 pour que ces numéros de position commencent à 0 (et pas à 1).\n\n# correspond aux nombres, pas aux noms\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\nLe jeu de données des liens ressemble maintenant à ceci :\n\n\n\n\n\n\nTracez maintenant le diagramme de Sankey avec sankeyNetwork(). Vous pouvez en savoir plus sur chaque argument en exécutant ?sankeyNetwork dans la console. Notez que si vous ne définissiez pas iterations = 0, l’ordre de vos noeuds ne serait pas celui attendu.\n\n# graphique\n######\np &lt;- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0) # Assurez-vous que l'ordre des noeuds est celui des données.\np\n\n\n\n\n\nVoici un exemple où le résultat du patient est également inclus. Notez que dans l’étape de préparation des données, nous devons calculer le nombre de cas entre l’âge et l’hôpital, et séparément entre l’hôpital et le résultat - puis lier tous ces comptes ensemble avec bind_rows().\n\n# Nombre de cas par hôpital et par catégorie d'âge\nage_hosp_links &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = age_cat, \n         target = hospital)\n\nhosp_out_links &lt;- linelist %&gt;% \n    drop_na(age_cat) %&gt;% \n    select(hospital, outcome) %&gt;% \n    count(hospital, outcome) %&gt;% \n    rename(source = hospital, \n           target = outcome)\n\n# combiner les liens\nlinks &lt;- bind_rows(age_hosp_links, hosp_out_links)\n\n# Les noms uniques des noeuds\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\n# Créer des numéros d'identification\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\n# graphique\n######\np &lt;- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np\n\n\n\n\n\nhttps://www.displayr.com/sankey-diagrams-r/",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html#chronologie-des-événements",
    "href": "new_pages/diagrams.fr.html#chronologie-des-événements",
    "title": "35  Diagrammes et schémas",
    "section": "35.4 Chronologie des événements",
    "text": "35.4 Chronologie des événements\nPour faire une timeline montrant des événements spécifiques, vous pouvez utiliser le paquet vistime.\nVoir cette vignette\n\n# charger le paquet\npacman::p_load(vistime, # créer la ligne de temps\n               plotly # pour la visualisation interactive\n               )\n\nVoici l’ensemble de données d’événements avec lequel nous commençons :\n\n\n\n\n\n\n\np &lt;- vistime(data) # appliquer vistime\n\nlibrary(plotly)\n\n# étape 1 : transformation en liste\npp &lt;- plotly_build(p)\n\n# étape 2 : taille des marqueurs\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size &lt;- 10\n}\n\n# étape 3 : taille du texte\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size &lt;- 10\n}\n\n\n# étape 4 : position du texte\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition &lt;- \"right\"\n}\n\n#imprimer\npp",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html#dags",
    "href": "new_pages/diagrams.fr.html#dags",
    "title": "35  Diagrammes et schémas",
    "section": "35.5 DAGs",
    "text": "35.5 DAGs\nVous pouvez construire un DAG manuellement en utilisant le paquet DiagammeR et le langage DOT comme décrit ci-dessus.\nAlternativement, il existe des paquets comme ggdag et daggity.\nIntroduction aux DAGs - vignette ggdag\nInférence causale avec les dags dans R",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.fr.html#ressources",
    "href": "new_pages/diagrams.fr.html#ressources",
    "title": "35  Diagrammes et schémas",
    "section": "35.6 Ressources",
    "text": "35.6 Ressources\nUne grande partie de ce qui précède concernant le langage DOT est adaptée du tutoriel sur ce site.\nUn autre tutoriel sur DiagammeR plus approfondi.\nIci, un page sur les diagrammes de Sankey.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagrammes et schémas</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.fr.html",
    "href": "new_pages/combination_analysis.fr.html",
    "title": "36  Analyse des combinaisons",
    "section": "",
    "text": "36.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse des combinaisons</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.fr.html#préparation",
    "href": "new_pages/combination_analysis.fr.html#préparation",
    "title": "36  Analyse des combinaisons",
    "section": "",
    "text": "Chargement des paquets\nCe chunk de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur R - les bases pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  tidyverse, # gestion et visualisation de données\n  UpSetR,    # paquet spécial pour les graphiques combinés\n  ggupset)   # paquet spécial pour les tracés combinés\n\n\n\n\nImporter les données\nPour commencer, nous importons la linelist nettoyée des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importer et exporter des données pour plus de détails).\n\n# importer la liste de cas linelist \nlinelist_sym &lt;- import(\"linelist_cleaned.rds\")\n\nCette linelist comprend cinq variables “oui/non” sur les symptômes déclarés. Nous devrons transformer un peu ces variables pour utiliser le paquet ggupset afin de réaliser notre tracé. Visualisez les données (faites défiler vers la droite pour voir les variables de symptômes).\n\n\n\n\n\n\n\n\n\nRe-formatage des valeurs\nPour s’aligner sur le format attendu par ggupset, nous convertissons les “yes” (“oui”) et “no” (“non”) en nom de symptôme réel, en utilisant case_when() de dplyr. Si “non”, nous mettons la valeur en blanc, donc les valeurs sont soit NA ou le symptôme.\n\n# crée une colonne avec les symptômes nommés, séparés par des points-virgules\nlinelist_sym_1 &lt;- linelist_sym %&gt;% \n  \n  # convertissez les valeurs \"oui\" et \"non\" dans le nom du symptôme lui-même\n  mutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n       chills = ifelse(chills == \"yes\", \"chills\", NA),\n       cough = ifelse(cough == \"yes\", \"cough\", NA),\n       aches = ifelse(aches == \"yes\", \"aches\", NA),\n       vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\n\nMaintenant, nous faisons deux dernières colonnes :\n\nConcaténation (collage) de tous les symptômes du patient (une colonne de caractères)\n\nConvertir la colonne ci-dessus en classe list, afin qu’elle puisse être acceptée par ggupset pour faire le graphe.\n\nVoir la page sur Caractères et chaînes de caractères pour en savoir plus sur la fonction unite() de stringr.\n\nlinelist_sym_1 &lt;- linelist_sym_1 %&gt;% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \" ; \",\n        remove = TRUE,\n        na.rm = TRUE) %&gt;% \n  mutate(\n    # Faites une copie de la colonne all_symptoms, mais de la classe \"list\" (qui est nécessaire pour utiliser ggupset() à l'étape suivante).\n    all_symptoms_list = as.list(strsplit(all_symptoms, \" ; \"))\n    )\n\nVisualisez les nouvelles données. Notez les deux colonnes vers l’extrémité droite - les valeurs combinées collées, et la liste",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse des combinaisons</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.fr.html#ggupset",
    "href": "new_pages/combination_analysis.fr.html#ggupset",
    "title": "36  Analyse des combinaisons",
    "section": "36.2 ggupset",
    "text": "36.2 ggupset\nCharger le paquet\n\npacman::p_load(ggupset)\n\nCréez le graphique. Nous commençons par un ggplot() et un geom_bar(), mais ensuite nous ajoutons la fonction spéciale scale_x_upset() du ggupset.\n\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signes et symptômes\",\n  subtitle = \"Les 10 combinaisons les plus fréquentes de signes et de symptômes\",\n  caption = \"Caption ici\",\n  x = \"Combinaison de symptômes\",\n  y = \"Fréquence dans l'ensemble de données\")\n\n\n\n\n\n\n\n\nDe plus amples informations sur ggupset peuvent être trouvées en ligne ou hors ligne dans la documentation du paquet dans votre onglet d’aide RStudio ?ggupset.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse des combinaisons</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.fr.html#upsetr",
    "href": "new_pages/combination_analysis.fr.html#upsetr",
    "title": "36  Analyse des combinaisons",
    "section": "36.3 UpSetR",
    "text": "36.3 UpSetR\nLe paquet UpSetR permet de personnaliser davantage le tracé, mais il peut être plus difficile à exécuter :\nChargez le paquet\n\npacman::p_load(UpSetR)\n\nNettoyage des données\nNous devons convertir les valeurs des symptômes de la linelist en 1 / 0.\n\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n  \n  # convertissez les valeurs \"oui\" et \"non\" dans le nom du symptôme lui-même\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n\nSi vous êtes intéressé par une commande plus efficace, vous pouvez profiter de la fonction +(), qui convertit les 1 et les 0 en fonction d’une déclaration logique. Cette commande utilise la fonction across() pour modifier plusieurs colonnes à la fois (pour en savoir plus, lisez la section Nettoyage des données et des fonctions de base).\n\n# convertissez \"oui\" et \"non\" a 1 et 0\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n  \n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n\nMaintenant, faites le graphique en utilisant la fonction personnalisée upset() - en utilisant seulement les colonnes de symptômes. Vous devez désigner les “ensembles” à comparer (les noms des colonnes de symptômes). Vous pouvez aussi utiliser nsets = et order.by = \"freq\" pour n’afficher que les X combinaisons les plus importantes.\n\n# Créer le graphique\nUpSetR::upset(\n  select(linelist_sym_2, fever, chills, cough, aches, vomit),\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n  order.by = \"freq\",\n  sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # couleurs optionnelles\n  empty.intersections = \"on\",\n  # nsets = 3,\n  number.angles = 0,\n  point.size = 3.5,\n  line.size = 2, \n  mainbar.y.label = \"Symptoms Combinations\",\n  sets.x.label = \"Patients with Symptom\")",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse des combinaisons</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.fr.html#ressources",
    "href": "new_pages/combination_analysis.fr.html#ressources",
    "title": "36  Analyse des combinaisons",
    "section": "36.4 Ressources",
    "text": "36.4 Ressources\nLa page github de UpSetR\nUne version Shiny App - vous pouvez télécharger vos propres données\n*documentation - difficile à interpréter",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Analyse des combinaisons</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.fr.html",
    "href": "new_pages/transmission_chains.fr.html",
    "title": "37  Chaînes de transmission",
    "section": "",
    "text": "37.1 Aperçu\nL’outil principal pour manipuler, analyser, et visualiser les chaînes de transmission et les données de recherche de contact est le paquet epicontacts, développé par RECON. Essayez le graphique interactif ci-dessous en passant la souris sur les noeuds pour obtenir plus d’informations et en cliquant dessus pour surligner les cas descendants.\nWarning in epicontacts::make_epicontacts(linelist = linelist, contacts =\ncontacts, : Cycle(s) detected in the contact network: this may be unwanted",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Chaînes de transmission</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.fr.html#préparation",
    "href": "new_pages/transmission_chains.fr.html#préparation",
    "title": "37  Chaînes de transmission",
    "section": "37.2 Préparation",
    "text": "37.2 Préparation\n\nCharger les paquets\nCommencez par charger les paquets standards nécessaires à l’importation et à la manipulation des données. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger des paquets avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n   rio, # Importation de fichiers\n   here, # Localisation de fichiers\n   tidyverse, # Gestion des données + graphiques ggplot2\n   remotes # Installation de paquets depuis github\n)\n\nVous aurez besoin de la version de développement de epicontacts, qui peut être installée de github en utilisant la fonction p_install_github() de pacman. Vous n’avez besoin d’exécuter cette commande ci-dessous qu’une seule fois, et pas à chaque fois que vous utilisez le paquet (par la suite, vous pouvez utiliser p_load() comme d’habitude).\n\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n\n\nImporter les données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour suivre le code, consultez les instructions de la page Télécharger le manuel et les données. Le jeu de données est importé à l’aide de la fonction import() du paquet rio. Voir la page Importation et exportation pour connaître les différentes methodes d’importer des données.\n\n# Importez la liste de cas\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nLes 50 premières lignes de la linelist sont affichées ci-dessous. Les colonnes case_id, generation, infector, et source sont particulièrement intéressantes.\n\n\n\n\n\n\n\n\nCréation d’un objet epicontacts\nNous devons ensuite créer un objet epicontacts, qui nécessite deux types de données:\n\nune linelist documentant les cas où les colonnes sont des variables et les lignes correspondent à des cas uniques.\nune liste de bords définissant les liens entre les cas sur la base de leurs identifiants uniques (il peut s’agir de contacts, des événements de transmission, etc.)\n\nComme nous avons déjà une linelist, il nous suffit de créer une liste de bord entre les cas, plus précisément entre leurs ID. Nous pouvons extraire les liens de transmission de la linelist en liant la colonne infector avec la colonne case_id. A ce stade, nous pouvons également ajouter des “propriétés de bords”, c’est-à-dire toute variable décrivant le lien entre les deux cas, mais pas les cas eux-mêmes. Pour illustration, nous allons ajouter une variable location décrivant l’emplacement de l’événement de transmission, et une variable duration (durée) décrivant la durée du contact en jours.\nDans le code ci-dessous, la fonction transmute de le paquet dplyr est similaire à mutate, sauf qu’elle ne conserve que les colonnes que nous avons spécifiées dans la fonction. La fonction drop_na enlevera toutes les lignes où les colonnes spécifiées ont une valeur NA. Dans ce cas, nous ne voulons conserver que les lignes où l’infecteur est connu.\n\n## générer des contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %&gt;%\n  drop_na(infector)\n\nNous pouvons maintenant créer l’objet epicontacts en utilisant la fonction make_epicontacts . Nous devons spécifier quelle colonne de la linelist correspond à l’identifiant unique du cas, ainsi que les colonnes des contacts qui pointent vers les identifiants uniques des cas impliqués dans chaque lien. Ces liens sont directionnels en le sens que l’infection va de l’infecteur à le cas, les arguments from et to en conséquence. Nous définissons donc l’argument directed (direction) à TRUE (VRAI), ce qui affectera les opérations futures.\n\n## générer un objet epicontacts\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n\nWarning in make_epicontacts(linelist = linelist, contacts = contacts, id =\n\"case_id\", : Cycle(s) detected in the contact network: this may be unwanted\n\n\nEn examinant les objets epicontacts, on peut voir que la colonne case_id de la linelist a été renommée à id et que les colonnes case_id et infector des contacts ont été renommées à from et to. Cela garantit la cohérence dans le traitement, visualisation et analyse de l’objet epicontacts.\n\n## visualiser l'objet epicontacts\nepic\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 5,888 cases in linelist; 3,800 contacts; directed \n\n  // linelist\n\n# A tibble: 5,888 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 8689b7          4 NA             2014-05-13 2014-05-14           2014-05-18  \n 3 11f8ea          2 NA             2014-05-16 2014-05-18           2014-05-30  \n 4 b8812a          3 2014-05-04     2014-05-18 2014-05-20           NA          \n 5 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 be99c8          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 369449          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 f393b4          4 NA             2014-06-05 2014-06-06           2014-06-18  \n10 1389ca          4 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 3,800 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Nosocomial        6\n 2 f90f5f b8812a Nosocomial        9\n 3 11f8ea 893f25 Nosocomial        9\n 4 aec8ec be99c8 Nosocomial       10\n 5 893f25 07e3e8 Nosocomial        2\n 6 133ee7 369449 Nosocomial        9\n 7 996f3a 2978ac Nosocomial        2\n 8 133ee7 57a565 Nosocomial        3\n 9 37a6f6 fc15ef Community         4\n10 9f6884 2eaa9a Nosocomial        9\n# ℹ 3,790 more rows",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Chaînes de transmission</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.fr.html#manipulation",
    "href": "new_pages/transmission_chains.fr.html#manipulation",
    "title": "37  Chaînes de transmission",
    "section": "37.3 Manipulation",
    "text": "37.3 Manipulation\n\nSous-ensemble\nLa méthode subset() pour les objets epicontacts permet, entre autres, de filtrer les réseaux en fonction des propriétés de la linelinst (“attributs de noeuds”) et de la jeu de données de contacts (“attributs de bords”).Ces valeurs doivent être passées comme des listes nommées à l’argument respectif. Par exemple, dans le code ci-dessous, nous ne gardons dans la linelist que les cas masculins qui ont une date d’infection entre avril et juillet 2014 (les dates sont spécifiées en tant que plages) et des liens de transmission qui ont eu lieu dans l’hôpital.\n\nsub_attributes &lt;- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 69 cases in linelist; 1,900 contacts; directed \n\n  // linelist\n\n# A tibble: 69 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 3 2978ac          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15  \n 4 57a565          4 2014-05-28     2014-06-13 2014-06-15           NA          \n 5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09  \n 6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09  \n 7 f327be          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14  \n 8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16  \n 9 a47529          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26  \n10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01  \n# ℹ 59 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 1,900 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Nosocomial        6\n 2 f90f5f b8812a Nosocomial        9\n 3 11f8ea 893f25 Nosocomial        9\n 4 aec8ec be99c8 Nosocomial       10\n 5 893f25 07e3e8 Nosocomial        2\n 6 133ee7 369449 Nosocomial        9\n 7 996f3a 2978ac Nosocomial        2\n 8 133ee7 57a565 Nosocomial        3\n 9 9f6884 2eaa9a Nosocomial        9\n10 8e104d ddddee Nosocomial        8\n# ℹ 1,890 more rows\n\n\nNous pouvons utiliser la fonction thin pour filtrer la linelist afin d’inclure les cas trouvés dans les contacts en définissant l’argument what = \"linelist\", ou pour filtrer les contacts pour inclure les cas qui sont trouvés dans la linelist en définissant l’argument what = \"contacts\". Dans le code ci-dessous, nous filtrons davantage l’objet epicontacts pour ne garder que les liens de transmission impliquant les cas masculins infectés entre avril et juillet que nous avons filtrés ci-dessus. Nous pouvons voir que seulement deux liens de transmission correspondent à cette spécification.\n\nsub_attributes &lt;- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)\n\n[1] 3\n\n\nLes réseaux peuvent être élagués pour n’inclure que les composants qui sont connectés à certains noeuds. L’argument cluster_id prend un vecteur d’identifiants de cas et renvoie la linelist des individus qui sont liés, directement ou indirectement, à ces IDs. Dans le code ci-dessous, nous pouvons voir qu’un total de 13 cas de la linelist sont impliqués dans les clusters contenant 2ae019 et 71577a.\n\nsub_id &lt;- subset(epic, cluster_id = c(\"2ae019\", \"71577a\"))\nnrow(sub_id$linelist)\n\n[1] 13\n\n\nLa méthode subset() pour les objets epicontacts permet aussi de filtrer par la taille des cluster en utilisant les arguments cs, cs_min et cs_max. Dans le code ci-dessous, nous gardons seulement les cas liés à des clusters de 10 cas ou plus, et nous pouvons voir que 271 cas de la linelist sont impliqués dans de tels clusters.\n\nsub_cs &lt;- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)\n\n[1] 271\n\n\n\n\nAccéder les IDs\nLa fonction get_id() récupère les informations sur les IDs des cas dans les données, et peut être paramétrée comme la suite:\n\nlinelist : IDs dans les données de la linelist\ncontacts : IDs dans la jeu de données des contacts (“from” et “to” combinés)\nfrom : IDs dans la colonne “from” de la base de données des contacts.\nto : IDs dans la colonne “to” du jeu de données des contacts\nall : IDs qui apparaissent n’importe où dans l’un ou l’autre des jeu de données.\ncommon : IDs qui apparaissent à la fois dans la jeu de données des contacts et dans la linelist.\n\nPar exemple, quels sont les dix premiers ID dans la jeu de données des contacts ?\n\ncontacts_ids &lt;- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)\n\n [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\"\n [9] \"9f6884\" \"4802b1\"\n\n\nCombien d’identifiants sont trouvés à la fois dans la linelist et dans les contacts ?\n\nlength(get_id(epic, \"common\"))\n\n[1] 4352",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Chaînes de transmission</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.fr.html#visualisation",
    "href": "new_pages/transmission_chains.fr.html#visualisation",
    "title": "37  Chaînes de transmission",
    "section": "37.4 Visualisation",
    "text": "37.4 Visualisation\n\nGraphique de base\nToutes les visualisations des objets epicontacts sont gérées par la fonction plot. Nous allons d’abord filtrer l’objet epicontacts pour n’inclure que les cas ayant une date d’apparition en juin 2014, en utilisant la fonction subset, et filtrer seulement les contacts liés à ces cas à l’aide de la fonction thin.\n\n## sous-ensemble objet epicontacts\nsub &lt;- epic %&gt;%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %&gt;%\n thin(\"contacts\")\n\nNous pouvons ensuite créer le graphique interactif de base très simplement comme suit :\n\n## tracer l'objet epicontacts\nplot(\n  sub,\n  width = 700,\n  height = 700\n)\n\n\n\n\n\nVous pouvez déplacer les noeuds en les faisant glisser, les survoler pour obtenir plus d’informations et cliquer dessus pour subligner les cas connectés.\nIl existe un grand nombre d’arguments pour modifier ce graphique. Nous allons couvrir les principaux ici, mais consultez la documentation via ?vis_epicontacts (la fonction appelée lors de l’utilisation de plot sur un objet epicontacts) pour obtenir une description complète des arguments de la fonction.\n\nVisualiser les attributs des noeuds\nLa couleur, la forme et la taille d’un noeud peuvent être associées à une colonne specifiée de la linelist, en utilisant les arguments node_color, node_shape et node_size. Ceci est similaire à la syntaxe aes de ggplot2.\nLes couleurs, formes et tailles spécifiques des noeuds peuvent être spécifiées comme suit :\n\nCouleurs via l’argument col_pal, soit en fournissant une liste de noms pour la spécification manuelle de chaque couleur comme fait ci-dessous, ou en fournissant une fonction de palette de couleurs, telle que colorRampPalette(c(\"black\", \"red\", \"orange\")) fournira un gradient de couleurs entre les trois spécifiées.\nShapes en passant une liste nommée à l’argument shapes, et en spécifiant une forme pour chaque élément unique dans la colonne de la linelist spécifiée avec l’argument node_shape. Voir codeawesome pour les formes disponibles.\nTaille en passant une gamme de taille des noeuds à l’argument size_range.\n\nVoici un exemple, où la couleur représente le résultat, la forme le sexe et la taille l’âge :\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nVisualisation des attributs de bords\nLa couleur, la largeur et le type de ligne de le bords peuvent être associés à une colonne du jeu de données contacts en utilisant les arguments edge_color, edge_width et edge_linetype, comme la suite:\n\nCouleurs via l’argument edge_col_pal, de la même manière que pour col_pal.\nLargeurs en passant une gamme de taille des noeuds à l’argument width_range.\n\nVoici un exemple :\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  #edge_col_pal = c(Community = \"orange\", Nosocomial = \"violet\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\n\nAxe temporel\nNous pouvons également visualiser le réseau selon un axe temporel en faisant correspondre l’argument x_axis à une colonne de la linelist. Dans l’exemple ci-dessous, l’axe des x représente la date d’apparition des symptômes. Nous avons également spécifié l’argument arrow_size pour nous assurer que les flèches ne sont pas trop grandes, et nous avons défini label = FALSE pour rendre la figure moins encombrée.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nIl existe un grand nombre d’arguments supplémentaires pour spécifier d’avantage la façon dont ce réseau est visualisé le long d’un axe temporel, que vous pouvez vérifier via ?vis_temporal_interactive (la fonction appelée lors de l’utilisation de plot sur un objet epicontacts avec x_axis spécifié). Nous allons voir quelques examples ci-dessous.\n\nSpécifier la forme de l’arbre de transmission\nIl y a deux formes principales que l’arbre de transmission peut prendre, spécifiées en utilisant l’argument network_shape. La première est une forme branchée comme indiqué ci-dessus, où un bord droite relie deux noeuds connectes. C’est la représentation la plus intuitive mais elle peut donner lieu à des bords qui se chevauchent dans un réseau dense. La deuxième forme est le rectangle, qui produit un arbre ressemblant à une phylogénie. Par exemple :\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nOn peut assigner à chaque noud de cas une position verticale unique en modifiant l’argument position_dodge. La position des cas non liés (c’est-à-dire sans contacts signalés) est spécifiée à l’aide de l’argument unlinked_pos.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  hieght = 700,\n  width = 700\n)\n\n\n\n\n\nLa position du noeud parent par rapport aux noeuds enfants peut être spécifiée en utilisant l’argument parent_pos. L’option par défaut est de placer le noeud parent au milieu, mais il peut être placé en bas (parent_pos = 'bottom') ou en haut (parent_pos = 'top').\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nEnregistrement des graphiques et des figures\nVous pouvez enregistrer un graphique sous forme de fichier html interactif et autonome avec la fonction visSave du paquet VisNetwork :\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %&gt;%\n  visNetwork::visSave(\"network.html\")\n\nL’enregistrement de ces sorties de réseau sous forme d’image est malheureusement moins facile et nécessite d’enregistrer le fichier en tant que html et ensuite de faire une capture d’écran utilisant le paquet webshot. Dans le code ci-dessous, nous convertissons le fichier html sauvegardé ci-dessus en un PNG :\n\nwebshot(url = \"network.html\", file = \"network.png\")\n\n\n\n\nLigne chronologique\nVous pouvez également ajouter les chronologie de cas sur le réseau, qui sont représentées sur l’axe des x de chaque cas. Ceci peut être utilisé pour visualiser localisations des cas, par exemple, ou le temps jusqu’au résultat. Pour générer une ligne chronologique, nous devons créer un dataframe d’au moins trois colonnes indiquant l’ID du cas, la date de début de l’“événement” et la date de fin de l’“événement”. Vous pouvez également ajouter n’importe quel nombre d’autres colonnes qui peuvent ensuite être mappées aux noeuds et aux bords. Dans le code ci-dessous, nous générons une ligne chronologique allant de la date de l’apparition des symptômes à la date du résultat. Nous conservons les variables de résultat et d’hôpital que nous utilisons pour définir la forme et la couleur des noeuds. Notez que vous pouvez avoir plus qu’une ligne/événement chronologique par cas, par exemple si un cas a etait transféré entre plusieurs hôpitaux.\n\n## générer une ligne chronologique\ntimeline &lt;- linelist %&gt;%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n\nNous passons ensuite l’élément chronologique à l’argument timeline. Nous pouvons faire correspondre les attributs de la ligne chronologique aux couleurs, formesm et tailles des noeuds de la même manière que celle définie dans les sections précédentes, sauf que nous avons deux noeuds: le noeud de début et de fin de chaque ligne chronologique qui ont des arguments distincts. Par exemple, tl_start_node_color définit quelle colonne de la ligne chronologique est mappée à la couleur du noeud de départ, tandis que tl_end_node_shape définit quelle colonne de la ligne chronologique est utilise pour la forme du noeud final. Nous pouvons également faire correspondre la couleur, la largeur, le type de ligne et les étiquettes de bord de la ligne chronologique via les arguments tl_edge_*.\nVoir ?vis_temporal_interactive (la fonction appelée de plot() avec un objet epicontacts) pour plus de détails. Chaque argument est également annoté dans le code ci-dessous :\n\n## définir les formes\nshapes &lt;- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## définir les couleurs\ncolours &lt;- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## faire un graphique\nplot(\n  sub,\n  ## coordonnée x maximale de la date d'apparition de la maladie\n  x_axis = \"date_onset\",\n  ## utiliser une forme de réseau rectangulaire\n  network_shape = \"rectangle\",\n  ## mappe les formes de noeuds de cas à la colonne de sexe\n  node_shape = \"gender\",\n  ## nous ne voulons pas mapper la couleur des noeuds à aucune colonne, cela est important car la valeur par défaut est de mapper à l'id du noeud, ce qui va perturber le schéma de couleurs\n  node_color = NULL,\n  ## définir la taille du noeud de cas à 30 (comme il ne s'agit pas d'un caractère, node_size n'est pas mappée à une colonne mais interprétée comme la taille réelle du noeud)\n  node_size = 30,\n  ## définir la largeur du lien de transmission à 4 (comme il ne s'agit pas d'un caractère, edge_width n'est pas affectée à une colonne mais interprétée comme la largeur réelle du bord)\n  edge_width = 4,\n  ## fournir l'objet ligne chronologique\n  timeline = timeline,\n  ## mappe la forme du noeud de fin à la colonne de résultat dans l'objet de ligne chronologique\n  tl_end_node_shape = \"outcome\",\n  ## définir la taille du noeud final à 15 (comme il ne s'agit pas d'un caractère, cet argument n'est pas associé à la colonne des résultats dans l'objet ligne  chronologique).\n  tl_end_node_size = 15,\n  ## mappez la couleur du bord de la ligne de temps à la colonne de l'hôpital\n  tl_edge_color = \"hospital\",\n  ## Définir la largeur du bord de la ligne de temps à 2 (comme il ne s'agit pas d'un caractère, cet argument n'est pas associé à la colonne de l'hôpital).\n  tl_edge_width = 2,\n  ## mappez les étiquettes des bords à la variable hospital\n  tl_edge_label = \"hospital\",\n  ## spécifier la forme pour chaque attribut de noeud (défini ci-dessus)\n  shapes = shapes,\n  ## spécifier la palette de couleurs (définie ci-dessus)\n  col_pal = colours,\n  ## définir la taille de la flèche à 0.5\n  arrow_size = 0.5,\n  ## utiliser deux colonnes dans la légende\n  legend_ncol = 2,\n  ## définir la taille de la police\n  font_size = 15,\n  ## définir le formatage des dates\n  date_labels = c(\"%d %b %Y\"),\n  ## ne pas tracer les étiquettes d'identification sous les noeuds\n  label = FALSE,\n  ## spécifier la hauteur\n  height = 1000,\n  ## spécifier la largeur\n  width = 1200,\n  ## assurez-vous que chaque noeud de cas a une coordonnée y unique, ceci est très important\n  ## lors de l'utilisation de lignes chronologiques, sinon les lignes chronologiques se chevauchant de différents cas\n  position_dodge = TRUE\n)\n\nWarning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed\nas ID not found in linelist or start/end date is NA",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Chaînes de transmission</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.fr.html#analyse",
    "href": "new_pages/transmission_chains.fr.html#analyse",
    "title": "37  Chaînes de transmission",
    "section": "37.5 Analyse",
    "text": "37.5 Analyse\n\nRésumé\nNous pouvons obtenir un aperçu de certaines propriétés du réseau en utilisant la fonction summary.\n\n## résumer l'objet epicontacts\nsummary(epic)\n\n\n/// Overview //\n  // number of unique IDs in linelist: 5888\n  // number of unique IDs in contacts: 5511\n  // number of unique IDs in both: 4352\n  // number of contacts: 3800\n  // contacts with both cases in linelist: 56.868 %\n\n/// Degrees of the network //\n  // in-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n\n  // out-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n\n  // in and out degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   1.000   1.078   1.000   7.000 \n\n/// Attributes //\n  // attributes in linelist:\n generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n\n  // attributes in contacts:\n location duration\n\n\nPar exemple, nous pouvons voir que seulement 57% des contacts ont les deux cas dans la linelist ; cela signifie que nous ne disposons pas de données de le linelist sur un nombre significatif de cas impliqués dans ces chaînes de transmission.\n\n\nCaractéristiques par paires\nLa fonction get_pairwise() permet de traiter les variables de la linelist en fonction de chaque paire dans l’ensemble de données de contact. Dans l’exemple suivant, la date d’apparition de la maladie est extraite de la liste de lignes afin de calculer la différence entre la date d’apparition de la maladie pour chaque paire dans l’ensemble de données de contact. La valeur produite par cette comparaison représente l’ intervalle de série (si).\n\nsi &lt;- get_pairwise(epic, \"date_onset\")   \nsummary(si)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    5.00    9.00   11.01   15.00   99.00    1820 \n\ntibble(si = si) %&gt;%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Intervalle de série\",\n    y = \"Fréquence\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1820 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nLa fonction get_pairwise() va interpréter la classe de la colonne utilisée pour la comparaison, et adaptera sa méthode de comparaison des valeurs en conséquence. Pour les nombres et les dates (comme l’exemple si ci-dessus), la fonction va soustraire les valeurs. Lorsqu’elle est appliquée à des colonnes qui sont des caractères ou des catégories, get_pairwise() collera les valeurs ensemble. Comme la fonction permet également un traitement arbitraire (voir l’argument “f”), ces combinaisons discrètes peuvent être facilement mises en tableau et analysées.\n\nhead(get_pairwise(epic, \"gender\"), n = 10)\n\n [1] \"f -&gt; m\" NA       \"m -&gt; m\" NA       \"m -&gt; f\" \"f -&gt; f\" NA       \"f -&gt; m\"\n [9] NA       \"m -&gt; f\"\n\nget_pairwise(epic, \"gender\", f = table)\n\n           values.to\nvalues.from   f   m\n          f 464 516\n          m 510 468\n\nfisher.test(get_pairwise(epic, \"gender\", f = table))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  get_pairwise(epic, \"gender\", f = table)\np-value = 0.03758\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6882761 0.9892811\nsample estimates:\nodds ratio \n 0.8252575 \n\n\nIci, nous voyons une association significative entre les liens de transmission et le sexe.\n\n\nIdentifier les clusters\nLa fonction get_clusters() peut être utilisée pour identifier les composants connectés dans un objet epicontacts. Tout d’abord, nous l’utilisons pour récupérer un data.frame contenant les informations sur les clusters :\n\nclust &lt;- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42 \n\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Taille des clusters\",\n    y = \"Fréquence\"\n  )\n\n\n\n\n\n\n\n\nExaminons les plus grands clusters. Pour cela, nous ajoutons des informations sur les clusters à l’objet epicontacts, puis nous le sous-ensemblons pour ne garder que les plus grands clusters :\n\nepic &lt;- get_clusters(epic)\nmax_size &lt;- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))\n\n\n\n\n\n\n\nCalcul des degrés\nLe degré d’un noeud correspond à son nombre de bords ou de connexions avec d’autres noeuds. get_degree() fournit une méthode simple pour calculer cette valeur pour les objets epicontacts. Un degré élevé dans ce contexte indique un individu qui était en contact avec beaucoup d’autres personnes. L’argument type indique que nous souhaitons compter à la fois le degré d’entrée et le degré de sortie, l’argument only_linelist indique que nous voulons calculer le degré pour les cas de la linelist.\n\ndeg_both &lt;- get_degree(epic, type = \"both\", only_linelist = TRUE)\n\nQuels sont les individus qui ont les dix plus grands contacts ?\n\nhead(sort(deg_both, decreasing = TRUE), 10)\n\n916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n     7      6      6      6      5      5      5      5      5      5 \n\n\nQuel est le nombre moyen de contacts ?\n\nmean(deg_both)\n\n[1] 1.078473",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Chaînes de transmission</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.fr.html#ressources",
    "href": "new_pages/transmission_chains.fr.html#ressources",
    "title": "37  Chaînes de transmission",
    "section": "37.6 Ressources",
    "text": "37.6 Ressources\nLe site pour le paquet epicontacts fournit une vue d’ensemble des fonctions du paquet et contient quelques vignettes plus approfondies.\nLa page github peut être utilisée pour soulever des problèmes et demander des fonctionnalités.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Chaînes de transmission</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.fr.html",
    "href": "new_pages/phylogenetic_trees.fr.html",
    "title": "38  Les arbres phylogénétiques",
    "section": "",
    "text": "38.1 Aperçu\nLes arbres phylogénétiques sont utilisés pour visualiser et décrire la parenté et l’évolution des organismes à partir de la séquence de leur code génétique.\nOn peut les construire à partir de séquences génétiques en utilisant des méthodes basées sur la distance (comme la méthode neighbor-joining) ou les méthodes probabiliste (comme la méthode de maximum de vraisemblance et la méthode Bayesian Markov Chain Monte Carlo). Le séquençage de nouvelle génération (NGS) devient de plus en plus abordable et populaire en santé publique pour caractériser des agents pathogènes à l’origine des maladies infectieuses. Les appareils de séquençage portables réduisent le délai d’exécution et offrent la possibilité de rendre les résultats disponible en temps réel pour les enquêtes sur les épidémies. Les données NGS peuvent être utilisées pour identifier l’origine ou la source d’une souche épidémique ainsi que sa propagation, et pour déterminer la présence de gènes de résistance antimicrobienne. Pour visualiser la parenté génétique entre les échantillons, un arbre phylogénétique est construit.\nDans cette page, nous allons apprendre à utiliser le package ggtree, qui permet la visualisation combinée d’arbres phylogénétiques avec des données d’échantillons supplémentaires sous la forme de tableaux de données. Cela nous permettra d’observer les tendances et de comprendre la dynamique de l’épidémie.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Les arbres phylogénétiques</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.fr.html#préparation",
    "href": "new_pages/phylogenetic_trees.fr.html#préparation",
    "title": "38  Les arbres phylogénétiques",
    "section": "38.2 Préparation",
    "text": "38.2 Préparation\n\nImportation des packages\nCes lignes de code importe les packages necessaire pour l’analyse. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire puis l’importe pour l’utiliser dans la session de Rstudio. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages en R.\n\npacman::p_load(\n  rio,             # import/export\n  here,            # gestion des chemins d'accès\n  tidyverse,       # gestion des données + graphiques (ggplot2)\n  ape,             # pour importer and exporter les fichiers phylogénétiques\n  ggtree,          # pour visualiser les fichiers phylogénétiques\n  treeio,          # pour visualiser les fichiers phylogénétiques\n  ggnewscale)      # pour ajouter les palettes de couleurs supplémentaire\n\n\n\nImport data\nLes données pour cette page peuvent être téléchargées suivant les instructions de la page Télécharger le manuel et les données.\nIl existe plusieurs formats différents dans lesquels un arbre phylogénétique peut être enregistré (par exemple, Newick, NEXUS, Phylip). Un format couramment utilisés est celui des fichiers Newick (.nwk), qui est la norme pour représenter les arbres sous une forme facilement exploitable par ordinateur. Cela signifie qu’un arbre entier peut être représenté par un format de chaîne de caractères tel que “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59) ;”, énumérant tous les nœuds, les extrémités et leur relation (longueur de branche) les uns avec les autres.\nNote : Il est important de comprendre que le fichier de l’arbre phylogénétique en lui-même ne contient pas de données de séquençage, mais est simplement le résultat des distances génétiques entre les séquences. Nous ne pouvons donc pas extraire les données de séquençage d’un fichier arbre.\nTout d’abord, nous utilisons la fonction read.tree() du package ape pour importer un fichier d’arbre phylogénétique de Newick au format .txt, et le enregistrer dans un objet liste de classe “phylo”. Si nécessaire, utilisez la fonction here() du package here pour spécifier le chemin relatif du fichier.\nNote : Dans ce cas, l’arbre Newick est enregistré au format .txt pour faciliter sa manipulation et son téléchargement de Github.\n\ntree &lt;- ape::read.tree(\"Shigella_tree.txt\")\n\nNous inspectons notre objet arbre et voyons qu’il contient 299 pointes (ou échantillons) et 236 nœuds.\n\ntree\n\n\nPhylogenetic tree with 299 tips and 236 internal nodes.\n\nTip labels:\n  SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\nNode labels:\n  17, 29, 100, 67, 100, 100, ...\n\nRooted; includes branch lengths.\n\n\nEnsuite, nous importons un fichier en format .csv contenant des informations supplémentaires pour chaque échantillon séquencé, tel que le sexe, le pays d’origine et les attributs de résistance antimicrobienne, en utilisant la fonction import() du package rio :\n\nsample_data &lt;- import(\"sample_data_Shigella_tree.csv\")\n\nCi-dessous, vous trouverez les 50 premières lignes de données :\n\n\n\n\n\n\n\n\nNettoyer et inspecter\nNous nettoyons et inspectons nos données : Pour pouvoir associer les données échantillon à l’arbre phylogénétique, les valeurs de la colonne Sample_ID dans le tableau de données sample_data doit correspondre aux valeurs tip.labels dans le fichier tree :\nNous vérifions le format du tip.labels dans le fichier tree en regardant les 6 premières entrées en utilisant head() de base R.\n\nhead(tree$tip.label) \n\n[1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\"\n[6] \"S17BD05939\"\n\n\nNous nous assurons également que la première colonne de notre tableau de données sample_data est Sample_ID. Nous regardons les noms des colonnes de notre jeu de données en utilisant colnames() de base R.\n\ncolnames(sample_data)   \n\n [1] \"Sample_ID\"                  \"serotype\"                  \n [3] \"Country\"                    \"Continent\"                 \n [5] \"Travel_history\"             \"Year\"                      \n [7] \"Belgium\"                    \"Source\"                    \n [9] \"Gender\"                     \"gyrA_mutations\"            \n[11] \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n[13] \"MIC_CIP\"                   \n\n\nNous regardons les Sample_IDs dans le jeu de données pour nous assurer que le format est le même que dans le tip.label (par exemple, les lettres sont en majuscules, pas de soulignement supplémentaire _ entre les lettres et les chiffres, etc.)\n\nhead(sample_data$Sample_ID) # Nous vérifions les 6 premières entrées en utilisant head()\n\n[1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\"\n[6] \"S18BD02657\"\n\n\nNous pouvons aussi vérifier si tous les échantillons sont présents dans le fichier tree et vice versa en générant un vecteur logique de VRAI ou FAUX là où ils correspondent ou non. Ceux-ci ne sont pas imprimés ici, pour plus de simplicité.\n\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\n\nNous pouvons utiliser ces vecteurs pour démontrer les ID des échantillons qui ne sont pas sur l’arbre (il n’y en a pas).\n\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]\n\ncharacter(0)\n\n\nAprès inspection, nous pouvons voir que le format de Sample_ID dans le dataframe correspond au format des noms d’échantillons dans le tip.labels. Ceux-ci n’ont pas besoin d’être triés dans le même ordre pour être appariés.\nVoilà on est prêts à partir !",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Les arbres phylogénétiques</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.fr.html#visualisation-simple-de-larbre",
    "href": "new_pages/phylogenetic_trees.fr.html#visualisation-simple-de-larbre",
    "title": "38  Les arbres phylogénétiques",
    "section": "38.3 Visualisation simple de l’arbre",
    "text": "38.3 Visualisation simple de l’arbre\n\nDiverses configurations d’arbres\nggtree offre nombreux formats de configuration d’arbres différents et certains peuvent être plus adéquats que d’autres pour votre usage spécifique. Ci-dessous, vous trouverez quelques illustrations. Pour d’autres options, voir ce livre en ligne.\nVoici quelques exemples des configurations d’arbres :\n\nggtree(tree)                                            # arbre linéaire simple\nggtree(tree,  branch.length = \"none\")                   # arbre linéaire simple avec toutes les pointes alignées \nggtree(tree, layout=\"circular\")                         # arbre circulaire simple\nggtree(tree, layout=\"circular\", branch.length = \"none\") # arbre circulaire simple avec toutes les pointes alignées \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArbre simple plus données échantillons\nL’opérateur %&lt;+% est utilisé pour connecter le tableau de donnees sample_data avec le fichier arbre. L’annotation la plus facile de votre arbre est l’ajout des noms des échantillons aux extrémités, ainsi que la coloration des points d’extrémité et si désiré des branches :\nVoici un exemple d’arbre circulaire :\n\nggtree(tree, layout = \"circular\", branch.length = 'none') %&lt;+% sample_data + # %&lt;+% ajoute le tableau des données l'échantillon à l'arbre\n  aes(color = Belgium)+                       # colore les branches en fonction d'une variable de votre tableau de données \n  scale_color_manual(\n    name = \"Sample Origin\",                      # le nom de votre palette de couleurs (qui apparaîtra dans la légende comme ceci)\n    breaks = c(\"Yes\", \"No\"),                     # les différentes options de votre variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # comment vous voulez que les différentes options soient nommées dans votre légende, ce qui permet de les formater\n    values = c(\"blue\", \"black\"),                  # la couleur que vous voulez attribuer à la variable\n    na.value = \"black\") +                        # colorer les valeurs NA en noir également\n  new_scale_color()+                             # permet d'ajouter une couleur supplémentaire pour une autre variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # colorer les pointes par continent. Vous pouvez changer la forme en ajoutant \"shape = \"\n      size = 1.5)+                               # Définit la taille du point à la extremite \n  scale_color_brewer(\n    name = \"Continent\",                    # nom de votre palette de couleurs (qui apparaîtra dans la légende comme ceci)\n    palette = \"Set1\",                      # nous choisissons un ensemble de couleurs fournies avec le package brewer \n    na.value = \"grey\") +                    # pour les valeurs NA nous choisissons la couleur grise\n  geom_tiplab(                             # ajoute le nom de l'échantillon à l'extrémité de sa branche\n    color = 'black',                       # (ajoutez autant de lignes de texte que vous souhaitez avec + , mais vous devrez ajuster la valeur du décalage pour les placer les à côté des autres) \n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align = TRUE) +    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # titre de votre graphique\n  theme(\n    axis.title.x = element_blank(), # supprime le titre de l'axe x\n    axis.title.y = element_blank(), # supprime le titre de l'axe y\n    legend.title = element_text(    # définit la taille de la police et le format du titre de la légende\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # définit la taille de la police et le format du texte de la légende\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # définit la taille de la police et le format du titre du graphique\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # # définit le position du légende\n    legend.box = \"vertical\",        # # définit le position du légende\n    legend.margin = margin())   \n\n\n\n\n\n\n\n\nVous pouvez exporter le graphique de votre arbre avec ggsave() comme vous le feriez avec n’importe quel autre objet ggplot. Écrit de cette façon, ggsave() enregistre la dernière image produite dans le chemin de fichier que vous spécifiez. Rappelez-vous que vous pouvez utiliser here() et les chemins de fichiers relatifs pour sauvegarder facilement dans des sous-dossiers, etc.\n\nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Les arbres phylogénétiques</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.fr.html#manipulation-de-larbre",
    "href": "new_pages/phylogenetic_trees.fr.html#manipulation-de-larbre",
    "title": "38  Les arbres phylogénétiques",
    "section": "38.4 Manipulation de l’arbre",
    "text": "38.4 Manipulation de l’arbre\nParfois, vous pouvez avoir un très grand arbre phylogénétique et vous n’êtes intéressé que par une partie de l’arbre. Par exemple, si vous avez produit un arbre incluant des échantillons historiques ou internationaux afin d’obtenir un aperçu de la place de l’ensemble de vos données dans le schema général. Mais ensuite, pour examiner vos données de plus près, vous ne voulez inspecter que cette partie du grand arbre.\nComme le fichier de l’arbre phylogénétique n’est que le résultat de l’analyse des données de séquençage, nous ne pouvons pas manipuler l’ordre des nœuds et des branches dans le fichier lui-même. Ceux-ci ont déjà été déterminés dans une analyse précédente à partir des données de séquençage brutes. Nous sommes cependant en mesure de zoomer sur certaines parties, de cacher certaines parties et même de sous-ensembler une partie de l’arbre.\n\nZoomer pour agrandir\nSi vous ne voulez pas “couper” votre arbre, mais seulement en inspecter une partie de plus près, vous pouvez zoomer pour voir une partie spécifique.\nTout d’abord, nous traçons l’arbre entier au format linéaire et ajoutons des étiquettes numériques à chaque nœud de l’arbre.\n\np &lt;- ggtree(tree,) %&lt;+% sample_data +\n  geom_tiplab(size = 1.5) +                # étiquette les extrémités de toutes les branches avec le nom de l'échantillon dans le fichier de l'arbre\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # étiquette tous les nœuds de l'arbre\n\np  # imprime\n\n\n\n\n\n\n\n\nPour zoomer sur une branche particulière (qui déborde à droite), utilisez viewClade() sur l’objet ggtree p et fournissez le numéro du noeud pour obtenir une vue plus détaillée :\n\nviewClade(p, node = 452)\n\n\n\n\n\n\n\n\n\n\nRéduire les branches\nCependant, nous pouvons vouloir ignorer cette branche et la réduire à ce même noeud (noeud n° 452) en utilisant collapse(). Cet arbre est défini comme p_collapsed.\n\np_collapsed &lt;- collapse(p, node = 452)\np_collapsed\n\n\n\n\n\n\n\n\nPour plus de clarté, lorsque nous imprimons p_collapsed, nous ajoutons un geom_point2() (un diamant bleu) au noeud de la branche réduite.\n\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # nous attribuons un symbole au nœud réduit\n            size = 5,                     # définir la taille du symbole\n            shape = 23,                   # définir la forme du symbole\n            fill = \"steelblue\")           # définir la coleur du symbole\n\n\n\n\n\n\n\n\n\n\nSous-ensembler un arbre\nSi nous voulons faire un changement plus permanent et créer un nouvel arbre réduit avec lequel travailler, nous pouvons sous-ensembler une partie avec tree_subset(). Vous pouvez ensuite le sauvegarder comme un nouveau fichier newick tree ou un fichier .txt.\nTout d’abord, nous inspectons les noeuds de l’arbre et les étiquettes des extrémités afin de décider ce qu’il faut sous-ensembler.\n\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %&lt;+% sample_data +               # nous ajoutons les données de l'échantillon en utilisant l'opérateur %&lt;+%.\n  geom_tiplab(size = 1)+                                # étiqueter les extrémités de toutes les branches avec le nom de l'échantillon dans le fichier arbre\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # étiquette tous les noeuds de l'arbre \n theme(\n   legend.position = \"none\",                            # supprime la légende tous ensemble\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\n\n\n\n\n\n\n\n\nMaintenant, disons que nous avons décidé de sous-ensembler l’arbre au noeud 528 (ne garder que les pointes dans cette branche après le noeud 528) et nous le sauvegardons comme un nouvel objet sub_tree1 :\n\nsub_tree1 &lt;- tree_subset(\n  tree,\n  node = 528)                                            # nous sous-ensemblons l'arbre au nœud 528\n\nExaminons l’arbre subset tree 1:\n\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\n\n\n\n\n\n\n\n\nVous pouvez également effectuer un sous-ensemble basé sur un échantillon particulier, en spécifiant le nombre de noeuds “en arrière” que vous souhaitez inclure. Sous-ensemble la même partie de l’arbre basé sur un échantillon, dans ce cas S17BD07692, en remontant de 9 noeuds et nous le sauvegardons comme un nouvel objet sub_tree2 :\n\nsub_tree2 &lt;- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels_back définit le nombre de nœuds en arrière de la pointe de l'échantillon que vous voulez atteindre.\n\nExaminons l’arbre subset tree 2:\n\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n\n\n\n\n\n\n\n\nVous pouvez également sauvegarder votre nouvel arbre soit comme un type Newick ou même un fichier texte en utilisant la fonction write.tree() du package ape :\n\n# pour sauvegarder en format .nwk format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# pour sauvegarder en format .txt format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')\n\n\n\nRotation des nœuds dans un arbre\nComme mentionné précédemment, nous ne pouvons pas modifier l’ordre des pointes ou des noeuds dans l’arbre, car cela est basé sur leur parenté génétique et ne peut pas être manipulé de manière visuelle. Mais nous pouvons roter des branches autour des nœuds si cela facilite notre visualisation.\nTout d’abord, nous traçons notre nouveau subset tree 2 avec des étiquettes de nœuds pour choisir le nœud que nous voulons manipuler et nous enregistrons dans un objet ggtree plot p.\n\np &lt;- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # étiquette tous les nœuds de l'arbre\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\n\n\n\n\n\n\n\n\nNous pouvons ensuite manipuler les nœuds en appliquant ggtree::rotate() ou ggtree::flip() : Note : pour illustrer quels noeuds nous manipulons, nous appliquons d’abord la fonction geom_hilight() de ggtree pour mettre en évidence les échantillons dans les noeuds qui nous intéressent et nous enregistrons cet objet ggtree plot dans un nouvel objet p1.\n\np1 &lt;- p + geom_hilight(  # met en évidence le nœud 39 en bleu, \"extend =\" nous permet de définir la longueur du bloc de couleur\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # met en évidence le nœud 39 en jaune\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # imprime\n\n\n\n\n\n\n\n\nMaintenant nous pouvons faire tourner le noeud 37 dans l’objet p1 de sorte que les échantillons sur le noeud 38 se déplacent vers le haut. Nous enregistrons l’arbre pivoté dans un nouvel objet p2.\n\np2 &lt;- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # imprime\n\n\n\n\n\n\n\n\nOu nous pouvons utiliser la commande flip pour faire pivoter le noeud 36 de l’objet p1 et faire passer le noeud 37 en haut et le noeud 39 en bas. Nous enregistrons l’arbre retourné dans un nouvel objet p3.\n\np3 &lt;-  flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # imprime\n\n\n\n\n\n\n\n\n\n\nExemple de sous-arbre avec annotation d’échantillon de données\nDisons que nous investiguons le cluster de cas avec expansion clonale qui s’est produit en 2017 et 2018 au nœud 39 de notre sous-arbre. Nous ajoutons l’année d’isolement de la souche ainsi que l’historique des voyages et la couleur par pays pour voir l’origine d’autres souches étroitement liées :\n\nggtree(sub_tree2) %&lt;+% sample_data +     # nous utilisons l'opérateur %&lt;+% pour faire le lien avec le fichier sample_data \n  geom_tiplab(                          # étiquette les extrémités de toutes les branches avec le nom de l'échantillon dans le fichier arbre\n    size = 2.5,\n    offset = 0.001,\n    align = TRUE) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # définir les limites de l'axe x de notre arbre \n  geom_tippoint(aes(color=Country),     # colorer le point d'extrémité par continent\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                          # ajouter l'année d'isolation comme étiquette de texte aux extrémités\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    align = TRUE)+ \n  geom_tiplab(                          # ajouter l'historique de voyage comme étiquette de texte aux extrémités, en couleur rouge\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align = TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # ajouter le titre du graphique\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                    # ajouter une étiquette à l'axe x \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\nNotre observation pointe vers un événement d’importation de souches en provenance d’Asie, qui ont ensuite circulé en Belgique au fil des ans et semblent avoir causé notre dernière épidémie.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Les arbres phylogénétiques</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.fr.html#arbres-plus-complexes-ajout-de-cartes-thermiques-des-données-de-léchantillon",
    "href": "new_pages/phylogenetic_trees.fr.html#arbres-plus-complexes-ajout-de-cartes-thermiques-des-données-de-léchantillon",
    "title": "38  Les arbres phylogénétiques",
    "section": "Arbres plus complexes : ajout de cartes thermiques des données de l’échantillon",
    "text": "Arbres plus complexes : ajout de cartes thermiques des données de l’échantillon\nNous pouvons ajouter des informations plus complexes, telles que la présence catégorielle de gènes de résistance aux antimicrobiens et des valeurs numériques pour la résistance aux antimicrobiens effectivement mesurée sous la forme d’une carte thermique en utilisant la fonction ggtree::gheatmap().\nTout d’abord, nous devons tracer notre arbre (qui peut être linéaire ou circulaire) et le enregistrer dans un nouvel objet ggtree plot p : Nous allons utiliser le sub_tree de la partie 3).\n\np &lt;- ggtree(sub_tree2, branch.length='none', layout='circular') %&lt;+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\n\n\n\n\n\n\n\n\nEnsuite, nous préparons nos données. Pour visualiser différentes variables avec de nouveaux schémas de couleurs, nous sous-ensemblons notre dataframe à la variable désirée. Il est important d’ajouter le Sample_ID comme rownames sinon il ne pourra pas faire correspondre les données à l’arbre tip.labels :\nDans notre exemple, nous voulons examiner le sexe et les mutations qui pourraient conférer une résistance à la Ciprofloxacine, un important antibiotique de première ligne utilisé pour traiter les infections à Shigella.\nNous créons un tableau de données pour le sexe :\n\ngender &lt;- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) &lt;- sample_data$Sample_ID\n\nNous créons un tableau de données pour les mutations du gène gyrA, qui confèrent une résistance à la ciprofloxacine :\n\ncipR &lt;- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) &lt;- sample_data$Sample_ID\n\nNous créons un tableau de données pour la concentration minimale inhibitrice (CMI) mesurée pour la Ciprofloxacine en provenance du laboratoire :\n\nMIC_Cip &lt;- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) &lt;- sample_data$Sample_ID\n\nNous créons un premier graphique en ajoutant une carte thermique binaire pour le sexe à l’arbre phylogénétique et en la sauvegardant dans un nouvel objet graphique ggtree h1 :\n\nh1 &lt;-  gheatmap(p, gender,                                 # Nous ajoutons une couche de carte thermique du tableau de données de sexe à notre graphique arbre.\n                offset = 10,                               # l'offset déplace la carte thermique vers la droite,\n                width = 0.10,                              # la largeur définit la largeur de la colonne de la carte thermique,\n                color = NULL,                              # la couleur définit la bordure des colonnes de la carte thermique.\n         colnames = FALSE) +                               # cache les noms des colonnes de la carte thermique\n  scale_fill_manual(name = \"Gender\",                       # définit le schéma de coloration et la légende pour le sexe\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nNous ajoutons ensuite des informations sur les mutations du gène gyrA, qui confèrent une résistance à la Ciprofloxacine :\nNote : La présence de mutations ponctuelles chromosomiques dans les données WGS a été déterminée au préalable à l’aide de l’outil PointFinder développé par Zankari et al. (voir la référence dans la section des références supplémentaires)\nTout d’abord, nous attribuons un nouveau schéma de couleurs à notre objet de tracé existant h1 et le sauvegardons dans un nouvel objet h2. Cela nous permet de définir et de modifier les couleurs de notre deuxième variable dans la carte thermique.\n\nh2 &lt;- h1 + new_scale_fill() \n\nEnsuite, nous ajoutons la deuxième couche de carte thermique à h2 et nous enregistrons les graphiques combinés dans un nouvel objet h3 :\n\nh3 &lt;- gheatmap(h2, cipR,         # ajoute la deuxième ligne de la carte thermique décrivant les mutations de résistance à la Ciprofloxacine\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh3\n\n\n\n\n\n\n\n\nNous répétons le processus ci-dessus, en ajoutant d’abord une nouvelle couche d’échelle de couleurs à notre objet existant h3, puis en ajoutant les données continues sur la concentration minimale inhibitrice (CMI) de la Ciprofloxacine pour chaque souche à l’objet résultant h4 pour produire l’objet final h5 :\n\n# D'abord nous ajoutons le nouveau schéma de coloration :\nh4 &lt;- h3 + new_scale_fill()\n\n# puis nous combinons les deux en une nouvelle graphique :\nh5 &lt;- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # nous définissons ici un schéma de couleurs de gradient pour la variable continue de CMI\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5\n\n\n\n\n\n\n\n\nWe can do the same exercise for a linear tree:\n\np &lt;- ggtree(sub_tree2) %&lt;+% sample_data +\n  geom_tiplab(size = 3) + # etiquetter les pointes\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\n\n\n\n\n\n\n\n\nTout d’abord, nous ajoutons le sexe :\n\nh1 &lt;-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nPuis nous ajoutons les mutations de résistance à la Ciprofloxacine après avoir ajouté une autre couche de schéma de couleurs :\n\nh2 &lt;- h1 + new_scale_fill()\nh3 &lt;- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n h3\n\n\n\n\n\n\n\n\nOn ajoute ensuite la concentration minimale inhibitrice déterminée par le laboratoire (CMI) :\n\nh4 &lt;- h3 + new_scale_fill()\nh5 &lt;- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Les arbres phylogénétiques</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.fr.html#resources",
    "href": "new_pages/phylogenetic_trees.fr.html#resources",
    "title": "38  Les arbres phylogénétiques",
    "section": "38.5 Resources",
    "text": "38.5 Resources\nhttp://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors https://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html https://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: a novel web tool for WGS-based detection of antimicrobial resistance associated with chromosomal point mutations in bacterial pathogens, Journal of Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764–2768, https://doi.org/10.1093/jac/dkx217",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Les arbres phylogénétiques</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.fr.html",
    "href": "new_pages/interactive_plots.fr.html",
    "title": "39  Graphiques interactifs",
    "section": "",
    "text": "39.1 Préparation",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Graphiques interactifs</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.fr.html#préparation",
    "href": "new_pages/interactive_plots.fr.html#préparation",
    "title": "39  Graphiques interactifs",
    "section": "",
    "text": "Importation des packages\nCes lignes de code importe les packages necessaire pour l’analyse. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages en R.\n\npacman::p_load(\n  rio,       # Importation/exportation\n  here,      # chemins de fichiers\n  lubridate, # Travailler avec les dates\n  plotly,    # Graphiques interactifs\n  scales,    # les pourcentages rapides\n  tidyverse  # gestion et visualisation des données \n  ) \n\n\n\nCommencez avec un ggplot()\nDans cette page, nous supposons que vous commencez avec un graphique ggplot() que vous voulez rendre interactif. Nous allons construire plusieurs de ces graphiques dans cette page, en utilisant le case linelist utilisé dans la plupart des pages de ce manuel.\n\n\nImportation des données\nPour commencer, nous allons importer une base de données appelée linelist_cleaned contenant les cas d’une épidémie d’Ebola simulée. Pour suivre, click to download the “clean” linelist (as .rds file). Importez les données avec la fonction import() du package rio (cette fonction supporte de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page [Import and Export] pour plus de détails).\n\n# importer le cas de la liste de lignes\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la liste des lignes sont affichées ci-dessous.",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Graphiques interactifs</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.fr.html#tracer-avec-ggplotly",
    "href": "new_pages/interactive_plots.fr.html#tracer-avec-ggplotly",
    "title": "39  Graphiques interactifs",
    "section": "39.2 Tracer avec ggplotly()",
    "text": "39.2 Tracer avec ggplotly()\nLa fonction ggplotly() du package plotly permet de facilement rendre un ggplot() interactif. Il suffit de sauvegarder votre ggplot() et de le passer à la fonction ggplotly().\nCi-dessous, nous traçons une simple courbe représentant la proportion de cas décédés au cours d’une semaine donnée :\nNous commençons par créer un tableau résumé de chaque semaine épidémiologique, et le pourcentage de cas avec un bilan connu qui sont décédés.\n\nweekly_deaths &lt;- linelist %&gt;%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %&gt;%  # créer et regrouper les données par la colonne epiweek\n  summarise(                                              # créer un nouveau tableau de données résumé  :\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # nombre de cas par groupe dont le statut est connu\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # nombre de cas par groupe qui sont décédés\n    pct_death = 100*(n_death / n_known_outcome)           # pourcentage des cas de statut connu qui sont décédés \n  )\n\nHere is the first 50 rows of the weekly_deaths dataset.\n\n\n\n\n\n\nEnsuite, nous créons le graphique avec ggplot2, en utilisant geom_line().\n\ndeaths_plot &lt;- ggplot(data = weekly_deaths)+            # commencer par les données hebdomadaires des décès \n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # faire la ligne  \n\ndeaths_plot   # imprimer\n\n\n\n\n\n\n\n\nNous pouvons rendre ce graphique interactif en le passant simplement à ggplotly(), comme ci-dessous. Survolez votre souris sur la ligne pour afficher les valeurs x et y. Vous pouvez zoomer sur le tracé, et le déplacer. Vous pouvez également voir des icônes en haut à droite du graphe. Dans cet ordre, elles vous permettent de :\n\nTélécharger la vue actuelle sous forme d’image PNG\n\nZoomer avec une boîte de sélection\n\nFaire un panoramique, ou déplacer le graphe en cliquant et en faisant rouler le graphe\nFaire un zoom in ou out, ou revenir au zoom par défaut.\n\nRétablir les axes par défaut\n\nActivation/désactivation des “lignes de pointes”, qui sont les lignes pointillées partant du point interactif et s’étendant vers les axes x et y.\n\nAjustements pour que les données s’affichent lorsque vous ne survolez pas la ligne.\n\n\ndeaths_plot %&gt;% plotly::ggplotly()\n\n\n\n\n\nLes données groupées fonctionnent également avec ggplotly(). Ci-dessous, un épicurve hebdomadaire est fait, groupé par outcome. Les barreaux empilés sont interactifs. Cliquez sur les différents éléments de la légende (ils apparaîtront/disparaîtront).\n\n# Faire une courbe épidémique avec incidence2 pacakge\np &lt;- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %&gt;% plot(fill = outcome)\n\n\n# Faire le graphique interactif \np %&gt;% plotly::ggplotly()",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Graphiques interactifs</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.fr.html#modifications",
    "href": "new_pages/interactive_plots.fr.html#modifications",
    "title": "39  Graphiques interactifs",
    "section": "39.3 Modifications",
    "text": "39.3 Modifications\n\nTaille du fichier\nQuand vous exportez dans un HTML généré par R Markdown (comme ce livre!), vous voulez que le graphe ait une taille de données aussi réduite que possible (sans effets secondaires négatifs dans la plupart des cas). Pour cela, il suffit de passer le graphique interactif à partial_bundle(), également de plotly.\n\np &lt;- p %&gt;% \n  plotly::ggplotly() %&gt;%\n  plotly::partial_bundle()\n\n\n\nBoutons\nCertains des boutons sur un plotly standard sont superflus et peuvent être distrayants, vous pouvez donc les supprimer. Vous pouvez le faire simplement en passant la sortie dans config() de plotly et en spécifiant les boutons à enlever. Dans l’exemple ci-dessous, nous spécifions en avance les noms des boutons à supprimer, et les transmettons à l’argument modeBarButtonsToRemove =. Nous définissons également displaylogo = FALSE pour supprimer le logo plotly.\n\n## ces boutons sont distrayants et nous voulons les enlever\nplotly_buttons_remove &lt;- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np &lt;- p %&gt;%          # re-définir le graphique interactif sans ces boutons \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Graphiques interactifs</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.fr.html#heat-tiles",
    "href": "new_pages/interactive_plots.fr.html#heat-tiles",
    "title": "39  Graphiques interactifs",
    "section": "39.4 Heat tiles",
    "text": "39.4 Heat tiles\nVous pouvez rendre presque tous les graphiques ggplot() interactifs, y compris les heat tiles. Dans la page sur les Graphiques thermiques, vous pouvez lire comment créer le graphique ci-dessous, qui affiche la proportion de jours par semaine pendant lesquels certains facilités ont rapporté des données à leur province.\nVoici le code, bien que nous ne le décriions pas en détails ici.\n\n# importer les données\nfacility_count_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# regrouper les données en semaines pour le Spring district \nagg_weeks &lt;- facility_count_data %&gt;% \n  filter(District == \"Spring\",\n         data_date &lt; as.Date(\"2020-08-01\")) %&gt;% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %&gt;% \n  group_by(location_name, week, .drop = F) %&gt;%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;% \n  ungroup(location_name, week) %&gt;% \n  right_join(tidyr::expand(., week, location_name)) %&gt;% \n  mutate(week = aweek::week2date(week))\n\n# Créer le graphique\nmetrics_plot &lt;- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Rapport de\\nperformance (%)\",\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \" Les établissements de santé de district, Avril-Mai 2019 \",\n       caption = \"Semaines de 7 jours commençant le lundi.\")\n\nmetrics_plot # imprimer\n\n\n\n\n\n\n\n\nCi-dessous, nous le rendons interactif et le modifions pour les boutons simples et la taille du fichier.\n\nmetrics_plot %&gt;% \n  plotly::ggplotly() %&gt;% \n  plotly::partial_bundle() %&gt;% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Graphiques interactifs</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.fr.html#ressources",
    "href": "new_pages/interactive_plots.fr.html#ressources",
    "title": "39  Graphiques interactifs",
    "section": "39.5 Ressources",
    "text": "39.5 Ressources\nPlotly n’est pas seulement conçu pour R, mais fonctionne aussi très bien avec Python (et en fait avec tous les langages de Data science puisqu’il est construit en JavaScript). Vous pouvez en savoir plus à ce sujet sur le site plotly website",
    "crumbs": [
      "Visualisation des données",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Graphiques interactifs</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html",
    "href": "new_pages/rmarkdown.fr.html",
    "title": "40  Production de rapports avec R Markdown",
    "section": "",
    "text": "40.1 Préparation\nContexte du R Markdown\nPour expliquer certains des concepts et des “packages” impliqués :\nEn résumé, le processus qui se déroule en arrière-plan (vous n’avez pas besoin de connaître toutes ces étapes !) consiste à transmettre le fichier .Rmd à knitr, qui exécute les morceaux de code R et crée un nouveau fichier .md (markdown) comprenant le code R et son résultat rendu. Le fichier .md est ensuite traité par pandoc pour créer le produit fini : un document Microsoft Word, un fichier HTML, un document Powerpoint, un PDF, etc.\n(source: https://rmarkdown.rstudio.com/authoring_quick_tour.html):\nInstallation\nPour créer une sortie R Markdown, vous devez avoir installé les éléments suivants :\npacman::p_load(tinytex)     # installer le package tinytex \ntinytex::install_tinytex()  # commande R pour installer TinyTeX",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#préparation",
    "href": "new_pages/rmarkdown.fr.html#préparation",
    "title": "40  Production de rapports avec R Markdown",
    "section": "",
    "text": "Markdown est un “langage” qui vous permet d’écrire un document en texte brut, qui peut être converti en HTML et autres formats. Il n’est pas spécifique à R. Les fichiers écrits en Markdown ont une extension ‘.md’.\nR Markdown : est une variante de markdown qui est spécifique à R - il vous permet d’écrire un document en utilisant markdown pour produire du texte et pour incorporer du code R et afficher leurs sorties. Les fichiers R Markdown ont une extension ‘.Rmd’.\nrmarkdown - le “package” : Il est utilisé par R pour convertir le fichier .Rmd en la sortie souhaitée. Il se concentre sur la conversion de la syntaxe markdown (texte), nous avons donc également besoin de…\nknitr : Ce “package” R lira les morceaux de code, les exécutera et les ” tricotera” dans le document. C’est ainsi que les tableaux et les graphiques sont inclus à côté du texte.\nPandoc : Enfin, pandoc convertit le résultat en Word/PDF/Powerpoint, etc. Il s’agit d’un logiciel distinct de R mais qui est installé automatiquement avec RStudio.\n\n\n\n\n\n\n\nLe package rmarkdown (knitr sera également installé automatiquement).\nPandoc, qui doit être installé avec RStudio. Si vous n’utilisez pas RStudio, vous pouvez télécharger Pandoc ici.\nSi vous souhaitez générer une sortie PDF (un peu plus délicat), vous devrez installer LaTeX. Pour les utilisateurs de R Markdown qui n’ont pas installé LaTeX auparavant, nous vous recommandons d’installer TinyTeX. Vous pouvez utiliser les commandes suivantes:",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#démarrage",
    "href": "new_pages/rmarkdown.fr.html#démarrage",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.2 Démarrage",
    "text": "40.2 Démarrage\n\nInstaller le package R rmarkdown\nInstallez le “package” R rmarkdown. Dans ce manuel, nous mettons l’accent sur la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser . On peut également charger des “packages” avec library() à partir de R base. Voir la page sur R - les bases pour plus d’informations sur les packages R.\n\npacman::p_load(rmarkdown)\n\n\n\nCréer un nouveau fichier Rmd\nDans RStudio, ouvrez un nouveau fichier R markdown, en commençant par ‘File’, puis ‘New file’ et enfin ‘R markdown…’.\n\n\n\n\n\n\n\n\n\nR Studio vous donnera quelques options de sortie parmi lesquelles choisir. Dans l’exemple ci-dessous, nous sélectionnons “HTML” car nous voulons créer un document HTML. Le titre et les noms des auteurs ne sont pas importants. Si le type de document de sortie que vous voulez n’est pas l’un de ceux-là, ne vous inquiétez pas - vous pouvez choisir n’importe lequel et le changer dans le script plus tard.\n\n\n\n\n\n\n\n\n\nCela ouvrira un nouveau script .Rmd.\n\n\nImportant à savoir\nLe répertoire de travail\nLe répertoire de travail d’un fichier markdown est l’endroit où le fichier Rmd lui-même est enregistré. Par exemple, si le projet R se trouve dans ~/Documents/projetX et que le fichier Rmd lui-même se trouve dans un sous-dossier ~/Documents/projetX/markdownfiles/markdown.Rmd, le code read.csv(\"data.csv\") dans le markdown cherchera un fichier csv dans le dossier markdownfiles, et non dans le dossier racine du projet où les scripts dans les projets chercheraient normalement automatiquement.\nPour faire référence à des fichiers ailleurs, vous devrez soit utiliser le chemin complet du fichier, soit utiliser le package here. Le package here définit le répertoire de travail comme étant le dossier racine du projet R et est expliqué en détail dans les pages Projets R et Importer et exporter des données de ce manuel. Par exemple, pour importer un fichier appelé “data.csv” depuis le dossier projectX, le code serait import(here(\"data.csv\")).\nNotez que l’utilisation de setwd() dans les scripts R Markdown n’est pas recommandée – elle ne s’applique qu’au morceau de code dans lequel elle est écrite.\nTravailler sur un disque plutôt que sur votre ordinateur\nParce que R Markdown peut rencontrer des problèmes avec pandoc lorsqu’il est exécuté sur un serveur de stockage partagé, il est recommandé que votre dossier soit sur votre machine locale, par exemple dans un projet dans “Mes Documents”. Si vous utilisez Git (fortement recommandé !), cela vous sera familier. Pour plus de détails, consultez les pages du manuel intitulées R sur les lecteurs réseau et Erreurs fréquentes.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#les-composantes-du-r-markdown",
    "href": "new_pages/rmarkdown.fr.html#les-composantes-du-r-markdown",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.3 Les composantes du R Markdown",
    "text": "40.3 Les composantes du R Markdown\nUn document R Markdown peut être édité dans RStudio tout comme un script R standard. Lorsque vous démarrez un nouveau script R Markdown, RStudio essaie d’être utile en affichant un modèle qui explique les différentes sections d’un script R Markdown.\nCe qui suit est ce qui apparaît lorsque vous démarrez un nouveau script Rmd destiné à produire une sortie HTML (comme dans la section précédente).\n\n\n\n\n\n\n\n\n\nComme vous pouvez le constater, un fichier Rmd comporte trois éléments de base : YAML, le texte Markdown et les morceaux de code R.\nCes éléments vont créer et devenir votre document de sortie. Voir le diagramme ci-dessous :\n\n\n\n\n\n\n\n\n\n\nMétadonnées YAML\nAppelées “métadonnées YAML” ou simplement “YAML”, elles se trouvent en haut du document R Markdown. Cette section du script indique à votre fichier Rmd le type de sortie à produire, les préférences de formatage et d’autres métadonnées telles que le titre du document, l’auteur et la date. Il existe d’autres utilisations qui ne sont pas mentionnées ici (mais auxquelles il est fait référence dans la section “Produire une sortie”). Notez que l’indentation est importante ; les tabulations ne sont pas acceptées, mais les espaces le sont.\nCette section doit commencer par une ligne contenant seulement trois tirets --- et doit se terminer par une ligne contenant seulement trois tirets ---. Les paramètres YAML se présentent sous forme de paires key:value. L’emplacement des deux points dans YAML est important : les paires key:value sont séparées par des deux points (et non par des signes égaux !).\nLe fichier YAML doit commencer par les métadonnées du document. L’ordre de ces paramètres YAML primaires (non indentés) n’a pas d’importance. Par exemple :\ntitle: \"Mon document\"\nauthor: \"Moi\"\ndate: \"2024-05-08\"\nVous pouvez utiliser du code R dans des valeurs YAML en l’écrivant en tant que code en ligne (précédé de r dans les crochets arrière) mais aussi entre guillemets (voir l’exemple ci-dessus pour date:).\nDans l’image ci-dessus, parce que nous avons cliqué que notre sortie par défaut serait un fichier html, nous pouvons voir que le YAML dit output: html_document. Cependant, nous pouvons aussi changer cela pour dire powerpoint_presentation ou word_document ou même pdf_document.\n\n\nTexte\nIl s’agit de la narration de votre document, y compris les titres et les en-têtes. Il est écrit dans le langage “markdown”, qui est utilisé dans de nombreux logiciels différents.\nVous trouverez ci-dessous les principales façons d’écrire ce texte. Vous trouverez une documentation plus complète sur l’antisèche R Markdown sur le site Web de RStudio.\n\nNouvelles lignes\nDans le format R Markdown, pour aller à une nouvelle ligne, saisissez deux espaces à la fin de la ligne précédente, puis appuyez sur Entrée/Retour.\n\n\nPolice\nEntourez votre texte normal de ces caractères pour modifier la façon dont il apparaît dans le fichier de sortie.\n\nCaractères de soulignement (_text_) ou astérisque simple (*text*) pour italiciser.\nDouble astérisque (**text**) pour mettre le texte en gras.\nDes “quotes” inversés (text) pour afficher le texte sous forme de code.\n\nL’apparence réelle de la police peut être définie en utilisant des modèles spécifiques (spécifiés dans les métadonnées YAML ; voir l’exemple des onglets).\n\n\nCouleur\nIl n’existe pas de mécanisme simple pour modifier la couleur du texte dans R Markdown. Une solution de contournement, si votre fichier de sortie est un fichier HTML, consiste à ajouter une ligne HTML dans le texte Markdown. Le code HTML ci-dessous imprimera une ligne de texte en rouge gras.\n&lt;span style=\"color: red;\"&gt;**_DANGER:_** Ceci est un avertissement.&lt;/span&gt;  \nDANGER: Ceci est un avertissement.\n\n\nTitres et en-têtes\nUn symbole de hachage dans une partie de texte d’un script R Markdown crée un titre. C’est différent d’un morceau de code R dans le script, dans lequel un symbole de hachage est un mécanisme pour commenter/annoter/désactiver, comme dans un script R normal.\nDifférents niveaux de titre sont établis avec différents nombres de symboles de hachage au début d’une nouvelle ligne. Un symbole de hachage est un titre ou une rubrique primaire. Deux symboles de hachage correspondent à un sous-titre (deuxième niveau). Les titres de troisième et quatrième niveaux peuvent être établis avec un nombre croissant de symboles de hachage.\n# Titre (Titre 1)\n\n## Sous-titre (Titre 2)\n\n### Sous-sous-titre (Titre 3)\n\n\nPuces et numérotation\nUtilisez des astérisques (*) pour créer une liste de puces. Terminez la phrase précédente, saisissez deux espaces, tapez sur Entrée/Retour deux fois, puis commencez vos puces. Insérez un espace entre l’astérisque et le texte de votre puce. Après chaque puce, saisissez deux espaces, puis appuyez sur la touche Entrée/Retour. Les sous-puces fonctionnent de la même manière, mais sont en retrait. Les numérotations fonctionnent de la même manière, mais au lieu d’un astérisque, écrivez 1), 2), etc. Voici à quoi pourrait ressembler le texte de votre script R Markdown.\n\nVoici mes puces (il y a deux espaces après ce deux-points):    \n\n\n* Puce 1 (suivi de deux espaces et Entrée/Retour) \n* Puce 2 (suivi de deux espaces et Entrée/Retour) \n  * Sous-puce 1 (suivi de deux espaces et Entrée/Retour)  \n  * Sous-puce 2 (suivi de deux espaces et Entrée/Retour)  \n  \n\n\nCommenter du texte\nVous pouvez “commenter” du texte R Markdown de la même manière que vous pouvez utiliser le “#” pour commenter une ligne de code R dans un chunk R. Il suffit de mettre le texte en surbrillance et d’appuyer sur Ctrl+Shift+c (Cmd+Shift+c pour Mac). Le texte sera entouré de flèches et deviendra vert. Il n’apparaîtra pas dans votre résultat.\n\n\n\n\n\n\n\n\n\n\n\n\nMorceaux de code\nLes sections du script qui sont dédiées à l’exécution du code R sont appelées “chunks”. C’est là que vous pouvez charger des “packages”, importer des données et effectuer la gestion et la visualisation des données. Il peut y avoir de nombreux “chunks” de code (mettez en autant qu’il en faut pour un code plus lisible et comprehensible), ils peuvent donc vous aider à organiser votre code R en parties, éventuellement entrecoupées de texte. Remarque : ces “chunks” auront une couleur de fond légèrement différente de celle de la partie narrative du document.\nChaque chunk s’ouvre sur une ligne qui commence par trois “quotes” inversés et des crochets qui contiennent les paramètres du chunk ({ }). Le chunk se termine par trois autres “quotes” inversés.\nVous pouvez créer un nouveau chunk en le tapant vous-même, en utilisant le raccourci clavier “Ctrl + Alt + i” (ou Cmd + Shift + r sur Mac), ou en cliquant sur l’icône verte “insérer un nouveau chunk de code” en haut de votre éditeur de script.\nQuelques remarques sur le contenu des accolades { }:\n\nIls commencent par ‘r’ pour indiquer que le nom du langage dans le chunk est R.\nAprès le r, vous pouvez éventuellement écrire un “nom” de chunk – ceux-ci ne sont pas nécessaires mais peuvent vous aider à organiser votre travail. Notez que si vous nommez vos morceaux, vous devez TOUJOURS utiliser des noms uniques, sinon R se plaindra lorsque vous essaierez de compiler le rendu.\nLes accolades peuvent également inclure d’autres options, écrites comme tag=value, telles que :\neval = FALSE pour ne pas exécuter le code R\necho = FALSE pour ne pas imprimer le code source R du chunk dans le document de sortie.\nwarning = FALSE pour ne pas afficher les avertissements générés par le code R\nmessage = FALSE pour ne pas imprimer les messages produits par le code R.\ninclude = soit TRUE/FALSE si l’on veut inclure les sorties du chunk (par exemple les graphiques) dans le document.\nout.width = et out.height = - à fournir dans le style out.width = \"75%\"\nfig.align = \"center\" ajuste l’alignement d’une figure sur la page.\nfig.show='hold' si votre chunk imprime plusieurs figures et que vous souhaitez qu’elles soient affichées les unes à côté des autres (à associer à out.width = c(\"33%\", \"67%\"). Vous pouvez également définir fig.show='asis' pour les afficher en dessous du code qui les génère, 'hide' pour les cacher, ou 'animate' pour concaténer plusieurs d’entre elles dans une animation.`\nUn en-tête de chunk doit être écrit en une ligne.\nEssayez d’éviter les points, les caractères de soulignement et les espaces. Utilisez des tirets ( - ) à la place si vous avez besoin d’un séparateur.\n\nLisez plus en détail les options knitr ici.\nCertaines des options ci-dessus peuvent être configurées par clique-bouton en utilisant les boutons de réglage en haut à droite du chunk. Ici, vous pouvez spécifier quelles parties du chunk vous voulez que le document rendu inclue, à savoir le code, les sorties et les avertissements. Cela se traduira par des préférences écrites entre les crochets, par exemple echo=FALSE si vous spécifiez que vous voulez seulement afficher le rendu et non le code qui le produit ‘Show output only’.\n\n\n\n\n\n\n\n\n\nIl y a aussi deux flèches en haut à droite de chaque chunk, qui sont utiles pour exécuter du code dans un chunk, ou tout le code des chunks précédents. Survolez-les pour voir ce qu’elles font.\nPour que les options globales soient appliquées à tous les chunks du script, vous pouvez les configurer dans le tout premier chunk de code R du script. Par exemple, pour que seules les sorties soient affichées pour chaque chunk de code et non le code lui-même, vous pouvez inclure cette commande dans le chunk de code R :\n\nknitr::opts_chunk$set(echo = FALSE) \n\n\nInclure du code R dans la partie Texte du Markdown\nVous pouvez également inclure un minimum de code R dans le corps du texte de votre document Markdown en utilisant les “quotes” inversés. Dans les “quotes” inversés, commencez le code par “r” et un espace, afin que RStudio sache qu’il doit évaluer le code en tant que code R. Voir l’exemple ci-dessous.\nL’exemple ci-dessous montre plusieurs niveaux de titres, des puces, et utilise du code R pour la date actuelle (Sys.Date()) pour l’évaluer en une date imprimée.\n\n\n\n\n\n\n\n\n\nL’exemple ci-dessus est simple (affichage de la date actuelle), mais en utilisant la même syntaxe, vous pouvez afficher des valeurs produites par un code R plus complexe (par exemple, pour calculer le min, la médiane, le max d’une colonne). Vous pouvez également intégrer des objets R ou des valeurs qui ont été créés dans des morceaux de code R plus tôt dans le script.\nPar exemple, le script ci-dessous calcule la proportion de cas âgés de moins de 18 ans, en utilisant les fonctions tidyverse, et crée les objets less18, total, et less18prop. Cette valeur dynamique est insérée dans le texte suivant. Nous voyons à quoi cela ressemble lorsqu’il est rendu dans un document Word.\n\n\n\n\n\n\n\n\n\n\n\n\nImages\nVous pouvez inclure des images dans votre document R Markdown en utilisant l’une des méthodes suivantes:\n\n![](\"path/to/image.png\")  \n\nSi la première méthode ne marche pas, esssayez d’utiliser: knitr::include_graphics()\n\nknitr::include_graphics(\"path/to/image.png\")\n\n Rappelez-vous, votre chemin de fichier pourrait être écrit en utilisant le package. here\n\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))\n\n\n\nTables\nCréez un tableau en utilisant des traits d’union ( - ) et des barres ( | ). Le nombre de traits d’union avant/entre les barres permet de déterminer le nombre d’espaces dans la cellule avant que le texte ne commence à se positionner.\nColumn 1 |Column  2 |Column 3\n---------|----------|--------\nCell A   |Cell B    |Cell C\nCell D   |Cell E    |Cell F\nLe code ci-dessus produit le tableau ci-dessous :\n\n\n\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\nCell A\nCell B\nCell C\n\n\nCell D\nCell E\nCell F\n\n\n\n\n\nSections à onglets\nPour les sorties HTML, on peut organiser les sections en “onglets”. Il suffit d’ajouter .tabset dans les accolades { } qui sont ouvertes juste après le titre de la section. Tous les sous-titres situés sous ce titre (jusqu’à un autre titre de même niveau) apparaîtront sous forme d’onglets sur lesquels l’utilisateur pourra cliquer. En savoir plus ici\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous pouvez ajouter une option supplémentaire .tabset-pills après .tabset pour donner aux onglets eux-mêmes un aspect plus esthétique avec un fond en noir.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#structure-du-fichier-r-markdown",
    "href": "new_pages/rmarkdown.fr.html#structure-du-fichier-r-markdown",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.4 Structure du fichier R Markdown",
    "text": "40.4 Structure du fichier R Markdown\nIl existe plusieurs façons de structurer votre fichier R Markdown et les scripts R associés. Chacune présente des avantages et des inconvénients :\n\nR Markdown autonome - tout ce qui est nécessaire pour le rapport est importé ou créé dans le même fichier R Markdown.\n\nFaire appel à (sourcer) d’autres fichiers - Vous pouvez exécuter des scripts R externes avec la commande source() et utiliser leurs sorties dans le Rmd.\nScripts dépendant ou dérivé (“child script”) - un mécanisme alternatif pour la commande source()\n\nUtiliser un “runfile” - Exécuter des commandes dans un script R avant de rendre le Markdown R.\n\n\nRmd autonome\nPour un rapport relativement simple, on peut choisir d’organiser notre script R Markdown de manière à ce qu’il soit “autonome” et n’implique pas de scripts externes.\nTout ce dont on a besoin pour exécuter le script R Markdown est importé ou créé dans le fichier Rmd, y compris tous les morceaux de code et le chargement des “packages”. Cette approche “autonome” est appropriée lorsqu’on n’a pas besoin de faire beaucoup de traitement de données (par exemple, elle apporte un fichier de données propre ou semi-propre) et que le rendu du R Markdown ne prendra pas trop de temps.\nDans ce scénario, une organisation logique du script R Markdown pourrait être la suivante :\n\nDéfinir les options globales de knitr.\nChargement des “packages”\nImporter les données\n\nTraiter les données\nProduire des résultats (tableaux, graphiques, etc.)\nSauvegarder les résultats, le cas échéant (.csv, .png, etc.)\n\n\nFaire appel à (sourcer) d’autres fichiers\nUne variante de l’approche “autonome” consiste à faire en sorte que les morceaux de code R Markdown “sourcent” (exécutent) d’autres scripts R. Cela peut rendre votre script R Markdown moins encombré, plus simple et plus facile à organiser. Cela peut rendre votre script R Markdown moins encombré, plus simple et plus facile à organiser. Elle peut également être utile si vous souhaitez afficher les chiffres finaux au début du rapport. Dans cette approche, le script R Markdown final combine simplement les sorties prétraitées dans un document.\nUne façon de le faire est de fournir les scripts R (chemin et nom de fichier avec extension) à la commande base R source().\n\nsource(\"your-script.R\", local = knitr::knit_global())\n# ou sys.source(\"your-script.R\", envir = knitr::knit_global())\n\nNotez que lorsque vous utilisez source() dans le R Markdown, les fichiers externes seront toujours exécutés pendant le rendu de votre fichier Rmd. Par conséquent, chaque script est exécuté à chaque fois que vous rendez le rapport. Ainsi, le fait d’avoir ces commandes source() dans le R Markdown n’accélère pas votre temps d’exécution, et ne vous aide pas beaucoup à débloquer, puisque les erreurs produites seront toujours affichées lors de l’exécution du R Markdown.\nUne alternative est d’utiliser l’option child = knitr.\nVous devez être conscient des différents environnements de R. Les objets créés dans un environnement ne seront pas nécessairement disponibles dans l’environnement utilisé par le Markdown R.\n\n\n\nRunfile\nPar exemple, vous pouvez charger les “packages”, charger et nettoyer les données, et même créer les graphiques d’intérêt avant render(). Ces étapes peuvent se produire dans le script R, ou dans d’autres scripts qui sont “sourcés”. Tant que ces commandes se produisent dans la même session RStudio et que les objets sont enregistrés dans l’environnement, les objets peuvent ensuite être appelés dans le contenu Rmd. Ensuite, le R markdown lui-même ne sera utilisé que pour l’étape finale - pour produire la sortie avec tous les objets prétraités. Il est beaucoup plus facile de débloquer si quelque chose dans le code ne va pas.\nCette approche implique l’utilisation du script R qui contient la ou les commandes render() pour pré-traiter les objets qui alimentent le balisage R.\nCette approche est utile pour les raisons suivantes :\n\nDes messages d’erreur plus informatifs - ces messages seront générés par le script R, et non par le Markdown R. Les erreurs du Markdown R ont tendance à vous indiquer que vous n’avez pas besoin de les corriger. Les erreurs du Markdown R ont tendance à vous indiquer quel “chunk” a un problème, mais ne vous diront pas quelle ligne.\nLe cas échéant, vous pouvez exécuter des étapes de traitement longues avant la commande render() - elles ne seront exécutées qu’une seule fois.\n\nDans l’exemple ci-dessous, nous avons un script R séparé dans lequel nous pré-traitons un objet data dans l’environnement R, puis nous rendons le fichier “create_output.Rmd” en utilisant render().\n\ndata &lt;- import(\"datafile.csv\") %&gt;%       # Charger les données et les sauvegarder dans l'environnement\n  select(age, hospital, weight)          # Sélectionner les colonnes d'interet\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Creer le fichier Rmd \n\n\n\nStructure du dossier\nLe flux de travail concerne également la structure globale des dossiers, par exemple un dossier “output” pour les documents et figures créés, et des dossiers “data” ou “inputs” pour les données nettoyées. Nous n’entrerons pas dans les détails ici, mais consultez la page Organisation des rapports de routine.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#production",
    "href": "new_pages/rmarkdown.fr.html#production",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.5 Produire le document",
    "text": "40.5 Produire le document\nVous pouvez produire le document de la manière suivante :\n\nManuellement en appuyant sur le bouton “Knit” en haut de l’éditeur de script RStudio (rapide et facile).\nExécuter la commande render() (exécutée en dehors du script R Markdown)\n\n\nOption 1: Bouton “Knit”\nUne fois le fichier Rmd ouvert, appuyez sur l’icône/bouton “Knit” en haut du fichier.\nR Studio affichera la progression dans un onglet “R Markdown” près de votre console R. Le document s’ouvrira automatiquement une fois terminé.\nLe document sera enregistré dans le même dossier que votre script R markdown, et avec le même nom de fichier (à l’exception de l’extension). Ce n’est évidemment pas idéal pour le contrôle de version (il sera écrasé à chaque fois que vous cliquerez pour produire le fichier Rmd, à moins d’être déplacé manuellement), car vous devrez peut-être renommer le fichier vous-même (par exemple, ajouter une date).\nC’est le bouton de raccourci de RStudio pour la fonction render() de rmarkdown. Cette approche n’est compatible qu’avec un fihcier R markdown autonome, où tous les composants nécessaires existent ou proviennent du fichier.\n\n\n\n\n\n\n\n\n\n\n\nOption 2: Commande render()\nUne autre façon de produire votre sortie R Markdown est d’exécuter la fonction render() (du “package” rmarkdown). Vous devez exécuter cette commande en dehors du script R Markdown - donc soit dans un script R séparé (souvent appelé “fichier d’exécution”), soit comme une commande autonome dans la Console R.\n\nrmarkdown::render(input = \"my_report.Rmd\")\n\nComme avec “knit”, les paramètres par défaut enregistreront la sortie Rmd dans le même dossier que le script Rmd, avec le même nom de fichier (à part l’extension de fichier). Par exemple, “mon_rapport.Rmd”, une fois exécuté, créera “mon_rapport.docx” si vous décider de sortir le fichier vers un document Word. Cependant, en utilisant render() vous avez la possibilité d’utiliser des paramètres différents. render() peut accepter des arguments tels que :\n\noutput_format = C’est le format de sortie vers lequel convertir (par exemple, \"html_document\", \"pdf_document\", \"word_document\", ou \"all\"). Vous pouvez également le spécifier dans le YAML à l’intérieur du script R Markdown.\noutput_file = C’est le nom du fichier de sortie (et le chemin du fichier). Il peut être créé par des fonctions R telles que here() ou str_glue(), comme illustré ci-dessous.\noutput_dir = C’est un répertoire de sortie (dossier) pour enregistrer le fichier. Cela vous permet de choisir un autre répertoire que celui dans lequel le fichier Rmd est enregistré.\noutput_options = Vous pouvez fournir une liste d’options qui remplaceront celles du script YAML (par exemple )\noutput_yaml = Vous pouvez fournir le chemin d’accès à un fichier .yml qui contient des spécifications YAML.\nparams = Voir la section sur les paramètres ci-dessous.\nVoir la liste complète ici\n\nPar exemple, pour améliorer le contrôle de version, la commande suivante enregistre le fichier de sortie dans un sous-dossier “outputs”, avec la date du jour dans le nom du fichier. Pour créer le nom du fichier, la fonction str_glue() du paquet stringr est utilisée pour ‘coller’ ensemble des chaînes statiques (écrites en clair) avec du code R dynamique (écrit entre crochets). Par exemple, si nous sommes le 10 avril 2021, le nom du fichier ci-dessous sera “Report_2021-04-10.docx”. Voir la page sur Caractères et chaînes de caractères pour plus de détails sur str_glue().\n\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) \n\nAu fur et à mesure de l’exécution du fichier Rmarkdown, la console RStudio vous montrera la progression du rendu jusqu’à 100%, et un message final pour indiquer que l’exécution est achevée.\n\n\nOption 3 : package reportfactory\nLe “package” R reportfactory offre une méthode alternative d’organisation et de compilation de rapports R Markdown adapté aux cas où vous exécutez des rapports régulièrement (par exemple, quotidiennement, hebdomadairement…). Il facilite la compilation de plusieurs fichiers R Markdown et l’organisation de leurs sorties. Essentiellement, il fournit une “usine” à partir de laquelle vous pouvez exécuter les rapports R Markdown, obtenir des dossiers automatiquement horodatés pour les fichiers de sortie, et avoir un contrôle de version “léger”.\nPour en savoir plus sur ce flux de travail, consultez la page Organisation des rapports de routine.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#rapports-paramétrés",
    "href": "new_pages/rmarkdown.fr.html#rapports-paramétrés",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.6 Rapports paramétrés",
    "text": "40.6 Rapports paramétrés\nVous pouvez utiliser le paramétrage pour rendre un rapport dynamique, de sorte qu’il puisse être exécuté avec des paramètres spécifiques (par exemple, une date ou un lieu spécifique ou avec certaines options d’exécution). Nous nous concentrons ci-dessous sur les principes de base, mais il existe d’autres détails en ligne sur les rapports paramétrés.\nEn utilisant la liste linéaire des cas Ebola comme exemple, disons que nous voulons exécuter un rapport de surveillance standard pour chaque hôpital chaque jour. Nous montrons comment on peut le faire en utilisant des paramètres.\nImportant: les rapports dynamiques sont également possibles sans la structure formelle des paramètres (sans params:), en utilisant de simples objets R dans un script R adjacent. Ceci est expliqué à la fin de cette section.\n\nDéfinition des paramètres\nVous avez plusieurs options pour spécifier les valeurs des paramètres pour votre sortie R Markdown.\n\nOption 1 : Définir les paramètres dans YAML\nEditez le YAML pour inclure une option params:, avec des déclarations indentées pour chaque paramètre que vous voulez définir. Dans cet exemple, nous créons les paramètres date et hôpital, pour lesquels nous spécifions des valeurs. Ces valeurs sont susceptibles de changer à chaque fois que le rapport est exécuté. Si vous utilisez le bouton “Knit” pour produire le résultat, les paramètres auront ces valeurs par défaut. De même, si vous utilisez render(), les paramètres auront ces valeurs par défaut, sauf indication contraire dans la commande render().\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Central Hospital\n---\nEn arrière-plan, ces valeurs de paramètres sont contenues dans une liste en lecture seule appelée params. Ainsi, vous pouvez insérer les valeurs des paramètres dans le code R comme vous le feriez pour un autre objet/valeur R dans votre environnement. Tapez simplement params$ suivi du nom du paramètre. Par exemple params$hospital pour représenter le nom de l’hôpital (“Central Hospital” par défaut).\nNotez que les paramètres peuvent également contenir les valeurs vrai ou faux, et donc ceux-ci peuvent être inclus dans vos options knitr pour un “chunk” R. Par exemple, vous pouvez définir {r, eval=params$run} au lieu de {r, eval=FALSE}, et maintenant si le chunk s’exécute ou non dépend de la valeur d’un paramètre run:.\nNotez que pour les paramètres qui sont des dates, ils seront entrés comme une chaîne. Donc, pour que params$date soit interprété dans le code R, il faudra probablement l’envelopper avec as.Date() ou une fonction similaire pour le convertir en classe Date.\n\n\nOption 2 : Définir les paramètres dans render()\nComme mentionné plus haut, une alternative à l’appui sur le bouton “Knit” pour produire la sortie est d’exécuter la fonction render() à partir d’un script séparé. Dans ce dernier cas, vous pouvez spécifier les paramètres à utiliser dans ce rendu à l’argument params = de render().\nNotez que toutes les valeurs de paramètres fournies ici vont écraser leurs valeurs par défaut si elles sont écrites dans le YAML. Nous écrivons les valeurs entre guillemets car dans ce cas, elles doivent être définies comme des valeurs de type chaîne de caractères.\nLa commande ci-dessous rend “surveillance_report.Rmd”, spécifie un nom de fichier de sortie dynamique et un dossier, et fournit une list() de deux paramètres et leurs valeurs à l’argument params =.\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))\n\n\n\nOption 3 : Définir les paramètres à l’aide d’une interface utilisateur graphique\nPour une sensation plus interactive, vous pouvez également utiliser l’interface utilisateur graphique (GUI) pour sélectionner manuellement les valeurs des paramètres. Pour ce faire, nous pouvons cliquer sur le menu déroulant à côté du bouton “Knit” et choisir “Knit with parameters”.\nUne fenêtre pop-up apparaît alors pour vous permettre de saisir les valeurs des paramètres établis dans le YAML du document.\n\n\n\n\n\n\n\n\n\nVous pouvez réaliser la même chose avec une commande render() en spécifiant params = \"ask\", comme démontré ci-dessous.\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)\n\nToutefois, la saisie de valeurs dans cette fenêtre “pop-up” est sujette à des erreurs et à des fautes d’orthographe. Vous préférerez peut-être ajouter des restrictions aux valeurs qui peuvent être saisies dans les menus déroulants. Vous pouvez le faire en ajoutant dans le YAML plusieurs spécifications pour chaque entrée params: .\n\nlabel: est le titre de ce menu déroulant particulier.\nvalue: est la valeur par défaut (de départ)\n\ninput: est défini sur select pour le menu déroulant\n\nchoices: Donne les valeurs éligibles dans le menu déroulant\n\nCi-dessous, ces spécifications sont écrites pour le paramètre hôpital.\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---\nLors de l’exécution du fichier (via le bouton “tricot avec des paramètres” ou par render()), la fenêtre pop-up aura des options déroulantes à sélectionner.\n\n\n\n\n\n\n\n\n\n\n\n\nExemple paramétré\nLe code suivant crée des paramètres pour date et ’hôpital, qui sont utilisés dans le R Markdown comme params$date et params$hospital, respectivement.\nDans le rapport qui en résulte, vous pouvez voir comment les données sont filtrées sur l’hôpital spécifique, et le titre du graphique fait référence à l’hôpital et à la date corrects. Nous utilisons ici le fichier “linelist_cleaned.rds”, mais il serait particulièrement approprié que la linelist elle-même comporte également un horodatage pour s’aligner sur la date paramétrée.\n\n\n\n\n\n\n\n\n\nLancer l’excecution produit la sortie finale avec la police et la mise en page par défaut.\n\n\n\n\n\n\n\n\n\n\n\nParamétrisation sans params\nSi vous exécutez un fichier R Markdown avec render() à partir d’un script séparé, vous pouvez en fait avoir le résultat du paramétrage sans utiliser la fonctionnalité params:.\nPar exemple, dans le script R qui contient la commande render(), vous pouvez simplement définir hôpital et date comme deux objets R (valeurs) avant la commande render(). Dans le R Markdown, vous n’auriez pas besoin d’avoir une section params: dans le YAML, et nous ferions référence à l’objet date plutôt qu’à params$date et à hôpital plutôt qu’à params$hospital.\n\n# Il s'agit d'un script R distinct du fichier R Markdown.\n\n# définir les objets R\nhospital &lt;- \"Central Hospital\"\ndate &lt;- \"2021-04-10\"\n\n# Exécuter le fichier R markdown\nrmarkdown::render(input = \"create_output.Rmd\") \n\nSuivre cette approche signifie que vous ne pouvez pas “Exécuter avec des paramètres”, utiliser l’interface graphique ou inclure des options d’exécution dans les paramètres. Cependant, elle permet de simplifier le code, ce qui peut être avantageux.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#rapports-en-boucle",
    "href": "new_pages/rmarkdown.fr.html#rapports-en-boucle",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.7 Rapports en boucle",
    "text": "40.7 Rapports en boucle\nNous pouvons vouloir exécuter un rapport plusieurs fois, en faisant varier les paramètres d’entrée, afin de produire un rapport pour chaque juridiction/unité. Cela peut être fait en utilisant des outils d’itération, qui sont expliqués en détail dans la page Itération, boucles et listes. Les options comprennent le paquet purrr, ou l’utilisation d’une boucle for comme expliqué ci-dessous.\nCi-dessous, nous utilisons une simple boucle for pour générer un rapport de surveillance pour tous les hôpitaux d’intérêt. Ceci est fait avec une seule commande (au lieu de changer manuellement le paramètre de l’hôpital un par un). La commande permettant de rendre les rapports doit exister dans un script séparé sauf le rapport Rmd. Ce script contiendra également des objets définis à parcourir en boucle - la date du jour, et un vecteur de noms d’hôpitaux à parcourir en boucle.\n\nhospitals &lt;- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \n\nNous introduisons ensuite ces valeurs une par une dans la commande render() en utilisant une boucle, qui exécute la commande une fois pour chaque valeur du vecteur hospitals. La lettre i représente la position de l’index (1 à 4) de l’hôpital actuellement utilisé dans cette itération, tel que hospital_list[1] serait “Central Hospital”. Cette information est fournie à deux endroits dans la commande render() :\n\nAu nom du fichier, de sorte que le nom du fichier de la première itération, s’il est produit le 10 avril 2021, sera “Report_Central Hospital_2021-04-10.docx”, enregistré dans le sous-dossier “output” du répertoire de travail.\nPour params = de sorte que le Rmd utilise le nom de l’hôpital en interne chaque fois que la valeur params$hospital est appelée (par exemple pour filtrer l’ensemble de données sur l’hôpital particulier uniquement). Dans cet exemple, quatre fichiers seront créés - un pour chaque hôpital.\n\n\nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#canevas-modèles-de-document",
    "href": "new_pages/rmarkdown.fr.html#canevas-modèles-de-document",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.8 Canevas (Modèles de document)",
    "text": "40.8 Canevas (Modèles de document)\nEn utilisant un canevas de document (exemple type) qui contient le formatage souhaité, vous pouvez ajuster l’esthétique de la sortie Rmd. Vous pouvez par exemple créer un fichier MS Word ou Powerpoint qui contient des pages/diapositives avec les dimensions, les filigranes, les fonds et les polices de caractères souhaités.\n\nDocuments Word\nPour créer un canevas, commencez un nouveau document Word (ou utilisez une sortie existante avec un formatage qui vous convient), et modifiez les polices en définissant les Styles. Dans Style,les titres 1, 2 et 3 font référence aux différents niveaux d’en-tête markdown (respectivement # Header 1, ## Header 2 et ## Header 3). Cliquez avec le bouton droit de la souris sur le style et cliquez sur “modifier” pour changer le formatage de la police ainsi que le paragraphe (par exemple, vous pouvez introduire des sauts de page avant certains styles, ce qui peut faciliter l’espacement). D’autres aspects du document Word, tels que les marges, la taille de la page, les en-têtes, etc., peuvent être modifiés comme un document Word habituel dans lequel vous travaillez directement.\n\n\n\n\n\n\n\n\n\n\n\nDocuments Powerpoint\nComme ci-dessus, créez un nouveau jeu de diapositives ou utilisez un fichier Powerpoint existant avec le formatage souhaité. Pour une édition plus poussée, cliquez sur ‘View’ et ‘Slide Master’. À partir de là, vous pouvez modifier l’apparence de la diapositive “de base” en modifiant le formatage du texte dans les zones de texte, ainsi que les dimensions de l’arrière-plan/de la page pour l’ensemble de la page.\n\n\n\n\n\n\n\n\n\nMalheureusement, l’édition des fichiers Powerpoint est un peu moins souple :\n\nUn en-tête de premier niveau (# Header 1) deviendra automatiquement le titre d’une nouvelle diapositive,\nUn texte ## Header 2 n’apparaîtra pas comme un sous-titre mais comme un texte dans la zone de texte principale de la diapositive (à moins que vous ne trouviez un moyen de manoeuvrer la slide de base).\nLes graphiques et les tableaux générés seront automatiquement placés dans de nouvelles diapositives. Vous devrez les combiner, par exemple avec la fonction patchwork pour combiner les ggplots, afin qu’ils apparaissent sur la même page. Consultez cet article de blog sur l’utilisation du paquet patchwork pour placer plusieurs images sur une seule diapositive.\n\nVoir le paquet officer pour un outil permettant de travailler plus en profondeur avec les présentations Powerpoint.\n\n\nIntégration des canevas (modèle de document) dans le YAML\nUne fois qu’un canevas est préparé, le détail de celui-ci peut être ajouté dans le YAML du fichier Rmd sous la ligne “output” et sous l’endroit où le type de document est spécifié (qui va sur une ligne séparée elle-même). Notons que reference_doc peut être utilisé pour les modèles de diapositives Powerpoint.\nIl est plus facile de sauvegarder le canevas dans le même dossier que celui où se trouve le fichier Rmd (comme dans l’exemple ci-dessous), ou dans un sous-dossier.\n---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---\n\n\nFormatage des fichiers HTML\nLes fichiers HTML n’utilisent pas de modèles, mais les styles peuvent être configurés dans le YAML. Les HTML sont des documents interactifs, et sont particulièrement flexibles. Nous couvrons ici quelques options de base.\n\nTable des matières : On peut ajouter une table des matières avec toc: true ci-dessous, et aussi spécifier qu’elle reste visible (“flottante”) quand on la fait défiler, avec toc_float: true.\nThèmes : Nous pouvons nous référer à certains thèmes pré-faits, qui proviennent d’une bibliothèque de thèmes Bootswatch. Dans l’exemple ci-dessous, nous utilisons cerulean. D’autres options incluent : journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, et yeti.\nMise en évidence : Cette configuration modifie l’aspect du texte mis en évidence (par exemple, le code dans les morceaux qui sont affichés). Les styles pris en charge sont default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark et textmate.\n\nVoici un exemple de la manière d’intégrer les options ci-dessus dans le YAML.\n---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---\nVous trouverez ci-dessous deux exemples de sorties HTML comportant toutes deux des tables des matières flottantes, mais avec des thèmes et des styles de mise en évidence différents :",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#contenu-dynamique",
    "href": "new_pages/rmarkdown.fr.html#contenu-dynamique",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.9 Contenu dynamique",
    "text": "40.9 Contenu dynamique\nDans une sortie HTML, le contenu de votre rapport peut être dynamique. Voici quelques exemples :\n\nTableaux\nDans un rapport HTML, vous pouvez imprimer des tableaux de données de telle sorte que le contenu soit dynamique, avec des filtres et des barres de défilement. Il existe plusieurs “packages” qui offrent cette possibilité.\nPour ce faire, avec le “package” DT, tel qu’il est utilisé dans ce manuel, vous pouvez insérer un morceau de code comme celui-ci :\n\n\n\n\n\n\n\n\n\nLa fonction datatable() affichera le tableau de données fourni comme un tableau dynamique pour le lecteur. Vous pouvez définir rownames = FALSE pour simplifier le côté gauche de la table. filter = \"top\" fournit un filtre sur chaque colonne. Dans l’argument option(), fournissez une liste d’autres spécifications. Nous en incluons deux ci-dessous : pageLength = 5 fixe le nombre de lignes qui apparaissent à 5 (les lignes restantes peuvent être visualisées en cliquant sur les flèches), et scrollX=TRUE active une barre de défilement en bas du tableau (pour les colonnes qui s’étendent trop à droite).\nSi votre jeu de données est très grand, pensez à n’afficher que les X premières lignes en enveloppant le nom du jeu de données dans head().\n\n\nLes widgets HTML\nLes widgets HTML pour R sont une classe spéciale de “packages” R qui permettent une interactivité accrue en utilisant des bibliothèques JavaScript. Vous pouvez les intégrer dans des sorties HTML R Markdown.\nVoici quelques exemples courants de ces widgets :\n\nPlotly (utilisé dans cette page du manuel et dans la page Graphiques interactifs).\nvisNetwork (utilisé dans la page Chaînes de transmission de ce manuel)\nLeaflet (utilisé dans la page Bases des GIS de ce manuel)\ndygraphs (utile pour afficher de manière interactive des données de séries chronologiques)\n\nDT (datatable()) (utilisé pour afficher des tableaux dynamiques avec filtre, tri, etc.)\n\nLa fonction ggplotly() de plotly est particulièrement facile à utiliser. Voir la page Graphiques interactifs.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.fr.html#ressources",
    "href": "new_pages/rmarkdown.fr.html#ressources",
    "title": "40  Production de rapports avec R Markdown",
    "section": "40.10 Ressources",
    "text": "40.10 Ressources\nDe plus amples informations sont disponibles sur le site:\n\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://rmarkdown.rstudio.com/articles_intro.html\n\nUne bonne explication de markdown vs knitr vs Rmarkdown se trouve ici: https://stackoverflow.com/questions/40563479/relationship-between-r-markdown-knitr-pandoc-and-bookdown",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Production de rapports avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html",
    "href": "new_pages/reportfactory.fr.html",
    "title": "41  Organisation des rapports de routine",
    "section": "",
    "text": "41.1 Préparation",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#préparation",
    "href": "new_pages/reportfactory.fr.html#préparation",
    "title": "41  Organisation des rapports de routine",
    "section": "",
    "text": "Charger les packages\nDepuis RStudio, installez la dernière version du package reportfactory depuis Github.\nVous pouvez le faire via le “package” pacman avec p_load_current_gh() qui forcera l’installation de la dernière version depuis Github. Tapez la chaîne de caractères “reconverse/reportfactory”, qui spécifie l’organisation Github (reconverse) et le répertoire (reportfactory). Vous pouvez également utiliser install_github() du “package” remotes, comme alternative.\n\n# Installer et charger la dernière version du package depuis Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternative",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#nouvelle-factory",
    "href": "new_pages/reportfactory.fr.html#nouvelle-factory",
    "title": "41  Organisation des rapports de routine",
    "section": "41.2 Nouvelle “factory”",
    "text": "41.2 Nouvelle “factory”\nPour créer une nouvelle “factory”, exécutez la fonction new_factory(). Ceci créera un nouveau dossier de projet R autonome. Par défaut :\n\n“factory” sera ajoutée à votre répertoire de travail.\nLe nom du projet R de la “factory” sera appelé “new_factory.Rproj”.\n\nVotre session RStudio s’installera dans ce projet R.\n\n\n# Ceci créera la \"factory\" dans le répertoire de travail\nnew_factory()\n\nEn regardant à l’intérieur de la “factory”, vous pouvez voir que des sous-dossiers et certains fichiers ont été créés automatiquement.\n\n\n\n\n\n\n\n\n\n\nLe dossier report_sources contient vos scripts R Markdown, qui génèrent vos rapports.\n\nLe dossier outputs contient les fichiers de sortie du rapport (par exemple, HTML, Word, PDF, etc.).\n\nLe dossier scripts peut être utilisé pour stocker d’autres scripts R (par exemple, ceux qui proviennent de vos scripts Rmd).\n\nLe dossier data peut être utilisé pour contenir vos données à partir desquelles vous travvaillez (les sous-dossiers “raw” et “clean” sont inclus).\n\nUn fichier .here, afin que vous puissiez utiliser le package here pour faire appel aux fichiers dans les sous-dossiers selon leur relation avec le dossier à la racine (voir la page Projets R pour plus de détails).\n\nUn fichier gitignore a été créé au cas où vous lieriez ce projet R à un répertoire Github (voir Contrôle de version et collaboration avec Git et Github).\n\nUn fichier README vide, si vous utilisez un dépôt Github.\n\nCAUTION: selon les paramètres de votre ordinateur, des fichiers tels que “.here” peuvent exister mais restés cachés.\nParmi les paramètres par défaut, en voici quelques-uns que vous pourriez vouloir ajuster dans la commande new_factory() :\n\nfactory = - Fournit un nom pour le dossier de la “factory” (par défaut “new_factory”)\n\npath = - Désigne un chemin de fichier pour la nouvelle “factory” (par défaut le répertoire de travail)\n\nreport_sources = - Donne un autre nom au sous-dossier qui contient les scripts R Markdown (par défaut, “report_sources”)\n\noutputs = Fournit un nom alternatif pour le dossier qui contient les fichiers de sortie du rapport (par défaut “outputs”).\n\nVoir ?new_factory pour une liste complète des arguments.\nLorsque vous créez la nouvelle “factory”, votre session R est transférée vers le nouveau projet R, vous devez donc charger à nouveau le “package” reportfactory.\n\npacman::p_load(reportfactory)\n\nMaintenant vous pouvez lancer la commande factory_overview() pour voir la structure interne (tous les dossiers et fichiers) de la “factory”.\n\nfactory_overview()            #  afficher l'aperçu de la factory dans la console\n\nL’“arbre” suivant des dossiers et fichiers de la “factory” est affiché dans la console R. Notez que dans le dossier “data”, il y a des sous-dossiers pour les données “raw” et “clean”, et des exemples de données CSV. Il y a aussi “example_report.Rmd” dans le dossier “report_sources”.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#créer-un-rapport",
    "href": "new_pages/reportfactory.fr.html#créer-un-rapport",
    "title": "41  Organisation des rapports de routine",
    "section": "41.3 Créer un rapport",
    "text": "41.3 Créer un rapport\nÀ partir du projet R de la fabrique, créez un rapport R Markdown comme vous le feriez normalement, et enregistrez-le dans le dossier “report_sources”. Consultez la page Production de rapports avec R Markdown pour obtenir des instructions. À titre d’exemple, nous avons ajouté les éléments suivants à la fabrique :\n\nUn nouveau script R markdown intitulé “daily_sitrep.Rmd”, enregistré dans le dossier “report_sources”.\n\nLes données du rapport (“linelist_cleaned.rds”), enregistrées dans le sous-dossier “clean” du dossier “data”.\n\nNous pouvons voir en utilisant factory_overview() notre R Markdown dans le dossier “report_sources” et le fichier de données dans le dossier “clean” data (en surbrillance) :\n\n\n\n\n\n\n\n\n\nVoici une capture d’écran du début du fihier R Markdown “daily_sitrep.Rmd”. Vous pouvez voir que le format de sortie est défini comme étant HTML, via l’en-tête YAML output: html_document.\n\n\n\n\n\n\n\n\n\nDans ce script simple, il y a des commandes pour :\n\nCharger les “packages” nécessaires\n\nImporter les données de la liste linéaire en utilisant un chemin de fichier du “package” here (pour en savoir plus, consultez la page Importer et exporter des données).\n\n\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\n\n\nImprimer un tableau récapitulatif des cas, et exportez-le avec export() comme un fichier .csv.\n\nImprimer une courbe épidemiologique, et l’exporter avec ggsave() comme un fichier .png.\n\nVous pouvez examiner la liste des rapports R Markdown dans le dossier “report_sources” avec cette commande :\n\nlist_reports()",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#compiler",
    "href": "new_pages/reportfactory.fr.html#compiler",
    "title": "41  Organisation des rapports de routine",
    "section": "41.4 Compiler",
    "text": "41.4 Compiler\nDans une “factory”, “compiler” un rapport R Markdown signifie que le script .Rmd sera exécuté et que la sortie sera produite (comme spécifié dans le script YAML, par exemple en HTML, Word, PDF, etc).\nLa fabrique créera automatiquement un dossier daté et horodaté pour les sorties dans le dossier “outputs”.\nLe rapport lui-même et tous les fichiers exportés produits par le script (par exemple, csv, png, xlsx) seront enregistrés dans ce dossier. En outre, le script Rmd lui-même sera enregistré dans ce dossier, de sorte que vous ayez une trace de cette version du script.\nCela contraste avec le comportement normal d’un R Markdown exécuté en indépendant, qui enregistre les sorties à l’emplacement du script Rmd. Ce comportement par défaut peut donner lieu à des dossiers encombrés et désordonnés. La “factory” vise à améliorer l’organisation lorsque l’on doit exécuter des rapports fréquemment.\n\nCompiler par nom\nVous pouvez compiler un rapport spécifique en exécutant compile_reports() et en fournissant le nom du script Rmd (sans extension .Rmd) à reports =. Pour simplifier, vous pouvez sauter le reports = et juste écrire le nom R Markdown entre guillemets, comme ci-dessous.\n\n\n\n\n\n\n\n\n\nCette commande compile uniquement le rapport “daily_sitrep.Rmd”, en sauvegardant le rapport HTML, le tableau .csv et les exportations des courbes épi .png dans un sous-dossier daté et horodaté spécifique au rapport, dans le dossier “outputs”.\nNotez que si vous choisissez de fournir l’extension .Rmd, vous devez saisir correctement l’extension telle qu’elle est enregistrée dans le nom du fichier (.rmd vs. .Rmd).\nNotez également que lorsque vous compilez, vous pouvez voir plusieurs fichiers apparaître temporairement dans le dossier “report_sources” - mais ils disparaîtront rapidement lorsqu’ils seront transférés dans le bon dossier “outputs”.\n\n\nCompiler par numéro\nVous pouvez également spécifier le script Rmd à compiler en fournissant un nombre ou un vecteur de nombres à reports =. Les nombres doivent correspondre à l’ordre dans lequel les rapports apparaissent lorsque vous exécutez list_reports().\n\n# Compilez les deuxième et quatrième Rmds dans le dossier \"report_sources\".\ncompile_reports(reports = c(2, 4))\n\n\n\nCompiler tous les rapports\nVous pouvez compiler tous les rapports R Markdown dans le dossier “report_sources” en mettant l’argument reports = à TRUE.\n\n\n\n\n\n\n\n\n\n\n\nCompilation à partir du sous-dossier\nVous pouvez ajouter des sous-dossiers au dossier “report_sources”. Pour exécuter un rapport R Markdown à partir d’un sous-dossier, il suffit de fournir le nom du dossier à subfolder =. Voici un exemple de code pour compiler un rapport Rmd qui se trouve dans un sous-dossier de “report_sources”.\n\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\n\nVous pouvez compiler tous les rapports Rmd dans un sous-dossier en fournissant le nom du sous-dossier à reports =, avec un slash à la fin, comme ci-dessous.\n\ncompile_reports(reports = \"for_partners/\")\n\n\n\nParamétrisation\nComme indiqué dans la page sur Production de rapports avec R Markdown, vous pouvez exécuter des rapports avec des paramètres spécifiques. Vous pouvez passer ces paramètres comme une liste à compile_reports() via l’argument params =. Par exemple, dans ce rapport fictif, trois paramètres sont fournis aux rapports R Markdown.\n\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)\n\n\n\nEn utilisant un “run-file”\nSi vous avez plusieurs rapports à exécuter, pensez à créer un script R qui contient toutes les commandes compile_reports(). Un utilisateur peut simplement exécuter toutes les commandes de ce script R et tous les rapports seront compilés. Vous pouvez enregistrer ce “fichier d’exécution” dans le dossier “scripts”.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#fichiers-de-sortie",
    "href": "new_pages/reportfactory.fr.html#fichiers-de-sortie",
    "title": "41  Organisation des rapports de routine",
    "section": "41.5 Fichiers de sortie",
    "text": "41.5 Fichiers de sortie\nAprès avoir compilé les rapports plusieurs fois, le dossier “outputs” pourrait ressembler à ceci (certains éléments surlignés pour plus de clarté) :\n\n\n\n\n\n\n\n\n\n\nDans “outputs”, des sous-dossiers ont été créés pour chaque rapport Rmd.\n\nDans ces dossiers, d’autres sous-dossiers ont été créés pour chaque compilation unique.\n\nCes dossiers sont datés et horodatés (“2021-04-23_T11-07-36” signifie 23 avril 2021 à 11:07:36).\n\nVous pouvez modifier le format de l’horodatage. Voir ?compile_reports.\n\nDans chaque dossier de compilation par date/heure, la sortie du rapport est stockée (par exemple HTML, PDF, Word) avec le script Rmd (contrôle de version !) et tout autre fichier exporté (par exemple table.csv, epidemic_curve.png).\n\nVoici une vue de l’intérieur d’un des dossiers horodatés, pour le rapport “daily_sitrep”. Le chemin du fichier est surligné en jaune pour plus de clarté.\n\n\n\n\n\n\n\n\n\nEnfin, vous trouverez ci-dessous une capture d’écran de la sortie du rapport HTML.\n\n\n\n\n\n\n\n\n\nVous pouvez utiliser list_outputs() pour consulter une liste des fichiers de sortie.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#divers",
    "href": "new_pages/reportfactory.fr.html#divers",
    "title": "41  Organisation des rapports de routine",
    "section": "41.6 Divers",
    "text": "41.6 Divers\n\nExécution\nVous pouvez toujours “exécuter” un de vos rapports R Markdown en cliquant sur le bouton “Knit”, si vous le souhaitez. Si vous faites cela, comme par défaut, les sorties apparaîtront dans le dossier où le Rmd est enregistré - le dossier “report_sources”. Dans les versions précédentes de reportfactory, avoir des fichiers non-Rmd dans “report_sources” empêchait la compilation, mais ce n’est plus le cas. Vous pouvez exécuter compile_reports() et aucune erreur ne se produira.\n\n\nScripts\nNous vous encourageons à utiliser le dossier “scripts” pour stocker les “fichiers d’exécution” ou les scripts .R qui proviennent de vos scripts .Rmd. Consultez la page Production de rapports avec R Markdown pour obtenir des conseils sur la manière de structurer votre code dans plusieurs fichiers.\n\n\nExtras\n\nAvec reportfactory, vous pouvez utiliser la fonction list_deps() pour lister tous les “packages” requis pour tous les rapports dans l’ensemble de la fabrique.\nIl y a un “package” de support utilisé en de développement appelé rfextras qui offre plus de fonctions d’aide pour vous assister dans la construction des rapports, comme :\n\nload_scripts() - source/charge tous les scripts .R dans un dossier donné (le dossier “scripts” par défaut).\n\nfind_latest() - trouve la dernière version d’un fichier (par exemple, le dernier jeu de données).",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.fr.html#ressources",
    "href": "new_pages/reportfactory.fr.html#ressources",
    "title": "41  Organisation des rapports de routine",
    "section": "41.7 Ressources",
    "text": "41.7 Ressources\nVoir la page Github du “package” reportfactory\nVoir la page Github du package rfextras",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organisation des rapports de routine</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html",
    "href": "new_pages/flexdashboard.fr.html",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "",
    "text": "42.1 Préparation",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#préparation",
    "href": "new_pages/flexdashboard.fr.html#préparation",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "",
    "text": "Charger les paquets\nDans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.\n\npacman::p_load(\n  rio, # import/export de données     \n  here, # localisation des fichiers\n  tidyverse, # gestion et visualisation des données\n  flexdashboard, # versions tableaux de bord des rapports R Markdown\n  shiny, # figures interactives\n  plotly # figures interactives\n)\n\n\n\nImporter des données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, cliquez pour télécharger la liste de lignes “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).\n\n# Importez la liste de cas\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nLes 50 premières lignes de la linelist sont affichées ci-dessous.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#créer-un-nouveau-r-markdown",
    "href": "new_pages/flexdashboard.fr.html#créer-un-nouveau-r-markdown",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.2 Créer un nouveau R Markdown",
    "text": "42.2 Créer un nouveau R Markdown\nAprès avoir installé le package, créez un nouveau fichier R Markdown en cliquant sur Fichier &gt; Nouveau fichier &gt; R Markdown.\n\n\n\n\n\n\n\n\n\nDans la fenêtre qui s’ouvre, sélectionnez “From Template” et choisissez le modèle “Flex Dashboard”. Vous serez ensuite invité à nommer le document. Dans l’exemple de cette page, nous allons nommer notre R Markdown “outbreak_dashboard.Rmd”.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#le-script",
    "href": "new_pages/flexdashboard.fr.html#le-script",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.3 Le script",
    "text": "42.3 Le script\nLe script est un script R Markdown, et a donc les mêmes composants et la même organisation que les scripts décrits dans la page sur les Rapports avec R Markdown. Nous allons brièvement les revoir et souligner les différences avec les autres formats de sortie R Markdown.\n\nYAML\nEn haut du script se trouve l’en-tête “YAML”. Il doit commencer par trois tirets --- et doit se terminer par trois tirets ---. Les paramètres YAML sont présentés par paires key: value. L’indentation et le placement des deux points dans YAML sont importants: les paires key: value sont séparées par des deux points (pas par des signes égaux !).\nLe fichier YAML doit commencer par les métadonnées du document. L’ordre de ces paramètres YAML primaires (non indentés) n’a pas d’importance. Par exemple :\n\ntite: \"Mon document\"\nauthor: \"Moi\"\ndate: \"`r Sys.Date()`\"\n\nVous pouvez utiliser du code R dans des valeurs YAML en le mettant comme du code en ligne (précédé de r entre guillemets) mais aussi entre guillemets (voir ci-dessus pour Date).\nUn paramètre YAML obligatoire est output:, qui spécifie le type de fichier à produire (par exemple, html_document, pdf_document, word_document, ou powerpoint_presentation). Pour flexdashboard, la valeur de ce paramètre est un peu confuse - elle doit être définie comme output:flexdashboard::flex_dashboard. Notez les deux-points simples et doubles, et le trait de soulignement. Ce paramètre de sortie YAML est souvent suivi par un deux-points supplémentaire et des sous-paramètres indentés (voir les paramètres orientation: et vertical_layout: ci-dessous).\n\ntitle: \"Mon tableau de bord\"\nauthor: \"Moi\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll\n\nComme indiqué ci-dessus, des indentations (2 espaces) sont utilisées pour les sous-paramètres. Dans ce cas, n’oubliez pas de mettre un deux-points supplémentaire après le primaire, comme key:value:.\nLe cas échéant, les valeurs logiques doivent être données dans YAML en minuscules (true, false, null). Si un deux-points fait partie de votre valeur (par exemple, dans le titre), mettez la valeur entre guillemets. Voir les exemples dans les sections ci-dessous.\n\n\nMorceaux de code\nUn script R Markdown peut contenir plusieurs “chunks” de code - il s’agit de zones du script dans lesquelles vous pouvez écrire du code R sur plusieurs lignes et qui fonctionnent comme des mini-scripts R.\nLes morceaux de code sont créés à l’aide de trois crochets arrière et de parenthèses avec un “r” minuscule à l’intérieur. Le chunk est fermé par trois crochets arrière. Vous pouvez créer un nouveau chunk en le tapant vous-même, en utilisant le raccourci clavier “Ctrl + Alt + i” (ou Cmd + Shift + r sur Mac), ou en cliquant sur l’icône verte “insérer un nouveau chunk de code” en haut de votre éditeur de script. De nombreux exemples sont donnés ci-dessous.\n\n\nTexte narratif\nEn dehors d’un “chunk” de code R, vous pouvez écrire un texte narratif. Comme décrit dans la page Rapports avec R Markdown, vous pouvez mettre du texte en italique en l’entourant d’un astérisque (texte italique), ou en gras en l’entourant de deux astérisques (texte gras). Rappelez-vous que les puces et les schémas de numérotation sont sensibles aux nouvelles lignes, à l’indentation et au fait de terminer une ligne par deux espaces.\nVous pouvez également insérer du code R en ligne dans du texte, comme décrit à la page Rapports avec R Markdown, en entourant le code de barres obliques inversées et en commençant la commande par “r” : 2 (voir l’exemple avec la date ci-dessus).\n\n\nTitres\nDifférents niveaux de titres sont établis avec différents nombres de symboles de hachage, comme décrit dans la page Rapports avec R Markdown.\nDans flexdashboard, un titre primaire (#) crée une “page” du tableau de bord. Les titres de deuxième niveau (##) créent une colonne ou une ligne en fonction de votre paramètre orientation: (voir les détails ci-dessous). Les titres de troisième niveau (###) créent des panneaux pour les graphiques, les tableaux, le texte, etc.\n# Titre de premier niveau (page)\n\n## En-tête de deuxième niveau (ligne ou colonne)  \n\n### En-tête de troisième niveau (panneau pour le graphique, le tableau, etc.)",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#attributs-de-section",
    "href": "new_pages/flexdashboard.fr.html#attributs-de-section",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.4 Attributs de section",
    "text": "42.4 Attributs de section\nComme dans un markdown R normal, vous pouvez spécifier des attributs à appliquer aux parties de votre tableau de bord en incluant des options key=value après un titre, entre des accolades { }. Par exemple, dans un rapport HTML R Markdown typique, vous pouvez organiser les sous-titres en onglets avec ## Ma rubrique {.tabset}.\nNotez que ces attributs sont écrits après un titre dans une partie texte du script. Ils sont différents des options knitr insérées en haut des morceaux de code R, telles que out.height =.\nLes attributs de section spécifiques à flexdashboard comprennent :\n\n{data-orientation=} Défini à rows ou columns. Si votre tableau de bord comporte plusieurs pages, ajoutez cet attribut à chaque page pour indiquer l’orientation (expliqué plus en détail dans la section de mise en page).\n\n{data-width=} et {data-height=} définissent la taille relative des graphiques, colonnes, lignes disposés dans la même dimension (horizontale ou verticale). Les tailles absolues sont ajustées pour remplir au mieux l’espace sur n’importe quel dispositif d’affichage grâce au moteur flexbox.\n\nLa hauteur des graphiques dépend également de la définition du paramètre YAML vertical_layout: fill ou vertical_layout: scroll. S’il est défini sur scroll, la hauteur des figures reflétera l’option traditionnelle fig.height = dans le chunk de code R.\n\nVoir la documentation complète sur la taille sur le flexdashboard website\n\n\n{.hidden} Utilisez cette option pour exclure une page spécifique de la barre de navigation.\n\n{data-navbar=} Utilisez ceci dans un titre de niveau page pour l’imbriquer dans un menu déroulant de la barre de navigation. Indiquez le nom (entre guillemets) du menu déroulant. Voir l’exemple ci-dessous.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#layout",
    "href": "new_pages/flexdashboard.fr.html#layout",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.5 Mise en page",
    "text": "42.5 Mise en page\nAjustez la mise en page de votre tableau de bord de la manière suivante :\n\nAjoutez des pages, des colonnes/lignes et des graphiques avec des titres R Markdown (par exemple, #, ## ou ###).\n\nAjustez l’orientation: de paramètre YAML à rangees ou colonnes.\n\nSpécifiez si la mise en page remplit le navigateur ou permet le défilement.\n\nAjouter des onglets à un titre de section particulier\n\n\nPages\nLes titres de premier niveau (#) dans le R Markdown représentent les “pages” du tableau de bord. Par défaut, les pages apparaissent dans une barre de navigation en haut du tableau de bord.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous pouvez regrouper des pages en un “menu” dans la barre de navigation supérieure en ajoutant l’attribut {data-navmenu=} au titre de la page. Attention, n’incluez pas d’espaces autour du signe égal, sinon cela ne fonctionnera pas !\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :\n\n\n\n\n\n\n\n\n\nVous pouvez également convertir une page ou une colonne en une “barre latérale” sur le côté gauche du tableau de bord en ajoutant l’attribut {.sidebar}. Elle peut contenir du texte (visible de n’importe quelle page) ou, si vous avez intégré l’interactivité shiny, elle peut être utile pour contenir des commandes d’entrée utilisateur telles que des curseurs ou des menus déroulants.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :\n\n\n\n\n\n\n\n\n\n\n\nOrientation\nDéfinissez le paramètre YAML orientation: pour indiquer comment vos titres Markdown de second niveau (##) doivent être interprétés - comme orientation: colonnes ou orientation: lignes.\nLes titres de second niveau (##) seront interprétés comme de nouvelles colonnes ou lignes en fonction de ce paramètre orientation.\nSi vous définissez orientation: colonnes, les titres de second niveau créeront de nouvelles colonnes dans le tableau de bord. Le tableau de bord ci-dessous comporte une page, contenant deux colonnes, avec un total de trois panneaux. Vous pouvez ajuster la largeur relative des colonnes avec {data-width=} comme indiqué ci-dessous.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :\n\n\n\n\n\n\n\n\n\nSi vous définissez orientation: lignes, les en-têtes de second niveau créeront de nouvelles lignes au lieu de colonnes. Voici le même script que ci-dessus, mais avec orientation: lignes pour que les en-têtes de second niveau produisent des lignes au lieu de colonnes. Vous pouvez ajuster la hauteur relative des lignes avec {data-height=} comme indiqué ci-dessous.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :\n\n\n\n\n\n\n\n\n\nSi votre tableau de bord comporte plusieurs pages, vous pouvez désigner l’orientation pour chaque page spécifique en ajoutant l’attribut {data-orientation=} à l’en-tête de chaque page (spécifiez soit lignes soit colonnes sans les guillemets).\n\n\nOnglets\nVous pouvez diviser le contenu en onglets avec l’attribut {.tabset}, comme dans les autres sorties HTML R Markdown.\nIl suffit d’ajouter cet attribut après le titre souhaité. Les sous-titres sous ce titre seront affichés sous forme d’onglets. Par exemple, dans l’exemple de script ci-dessous, la colonne 2 à droite (##) est modifiée de manière à ce que les volets de la courbe épidémique et du tableau (###) soient affichés sous forme d’onglets.\nVous pouvez faire de même avec les lignes si votre orientation est celle des lignes.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#ajout-de-contenu",
    "href": "new_pages/flexdashboard.fr.html#ajout-de-contenu",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.6 Ajout de contenu",
    "text": "42.6 Ajout de contenu\nCommençons à construire un tableau de bord. Notre tableau de bord simple aura 1 page, 2 colonnes, et 4 panneaux. Nous allons construire les panneaux pièce par pièce pour la démonstration.\nVous pouvez facilement inclure des sorties R standard telles que du texte, des ggplots et des tableaux (voir la page Tableaux pour la présentation). Il suffit de les coder dans un chunk de code R comme vous le feriez pour tout autre script R Markdown.\nRemarque : vous pouvez télécharger le script Rmd terminé et la sortie du tableau de bord HTML - voir la page Télécharger le manuel et les données.\n\nTexte\nVous pouvez saisir du texte Markdown et inclure du code en ligne comme pour toute autre sortie R Markdown. Voir la page Rapports avec R Markdown pour plus de détails.\nDans ce tableau de bord, nous incluons un panneau de texte récapitulatif qui comprend un texte dynamique indiquant la dernière date d’hospitalisation et le nombre de cas signalés dans l’épidémie.\n\n\nTableaux\nVous pouvez inclure des morceaux de code R qui impriment des sorties telles que des tableaux. Mais la sortie sera plus belle et s’adaptera mieux à la taille de la fenêtre si vous utilisez la fonction kable() de knitr pour afficher vos tableaux. Les fonctions flextable peuvent produire des tableaux qui sont raccourcis / coupés.\nPar exemple, ci-dessous, nous faisons passer la fonction linelist() par une commande count() pour produire un tableau récapitulatif des cas par hôpital. Finalement, le tableau est envoyé à knitr::kable() et le résultat a une barre de défilement sur la droite. Vous pouvez en savoir plus sur la personnalisation de votre tableau avec kable() et kableExtra ici.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :\n\n\n\n\n\n\n\n\n\nSi vous voulez afficher un tableau dynamique qui permet à l’utilisateur de filtrer, trier et/ou cliquer sur les “pages” du cadre de données, utilisez le package DT et sa fonction datatable(), comme dans le code ci-dessous.\nDans l’exemple de code ci-dessous, le cadre de données linelist est imprimé. Vous pouvez définir rownames = FALSE pour conserver l’espace horizontal, et filter = \"top\" pour avoir les filtres en haut de chaque colonne. Une liste d’autres spécifications peut être fournie à options =. Ci-dessous, nous avons défini pageLength = pour que 5 lignes apparaissent et scrollX = pour que l’utilisateur puisse utiliser une barre de défilement en bas pour faire défiler horizontalement. L’argument class = 'white-space: nowrap' garantit que chaque ligne ne comporte qu’une seule ligne (et non plusieurs). Vous trouverez d’autres arguments et valeurs possibles ici ou en entrant ?datatable.\n\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = liste(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )\n\n\n\nTracés\nVous pouvez imprimer les graphiques dans un tableau de bord comme vous le feriez dans un script R. Dans notre exemple, nous utilisons le paquet incidence2 pour créer une “courbe épidémique” par groupe d’âge avec deux commandes simples (voir la page Courbes épidémiques). Cependant, vous pourriez utiliser ggplot() et imprimer un graphique de la même manière.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :\n\n\n\n\n\n\n\n\n\n\n\nGraphiques interactifs\nVous pouvez également passer un ggplot standard ou un autre objet de tracé à ggplotly() du paquet plotly (voir la page Graphiques interactifs). Cela rendra votre graphique interactif, permettra au lecteur de “zoomer” et affichera en surimpression la valeur de chaque point de données (dans ce scénario, le nombre de cas par semaine et le groupe d’âge dans la courbe).\n\nage_outbreak &lt;- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %&gt;% \n  plotly::ggplotly()\n\nVoici à quoi cela ressemble dans le tableau de bord (gif). Cette fonctionnalité interactive fonctionnera même si vous envoyez le tableau de bord par courriel sous forme de fichier statique (pas en ligne sur un serveur).\n\n\n\n\n\n\n\n\n\n\n\nWidgets HTML\nLes widgets HTML pour R sont une classe spéciale de paquets R qui augmentent l’interactivité en utilisant des bibliothèques JavaScript. Vous pouvez les intégrer dans les sorties Markdown de R (comme un flexdashboard) et dans les tableaux de bord Shiny.\nVoici quelques exemples courants de ces widgets :\n\nPlotly (utilisé dans cette page du manuel et dans la page Graphiques interactifs).\nvisNetwork (utilisé dans la page Chaînes de transmission de ce manuel)\n\nLeaflet (utilisé dans la page bases de GIS de ce manuel)\n\ndigraphs (utile pour montrer de manière interactive des séries de données temporelles)\n\nDT (datatable()) (utilisé pour afficher des tableaux dynamiques avec des filtres, des tris, etc.)\n\nCi-dessous, nous démontrons l’ajout d’une chaîne de transmission d’épidémie qui utilise visNetwork au tableau de bord. Le script ne montre que le nouveau code ajouté à la section “Column 2” du script R Markdown. Vous pouvez trouver le code dans la page Chaînes de transmission de ce manuel.\n\n\n\n\n\n\n\n\n\nVoici ce que produit le script :",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#organisation-du-code",
    "href": "new_pages/flexdashboard.fr.html#organisation-du-code",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.7 Organisation du code",
    "text": "42.7 Organisation du code\nVous pouvez choisir d’avoir tout le code dans le script R Markdown flexdashboard. Alternativement, pour avoir un script de tableau de bord plus propre et concis, vous pouvez choisir de faire appel à du code/figures qui sont hébergés ou créés dans des scripts R externes. Ceci est décrit plus en détail dans la page Rapports avec R Markdown.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#shiny",
    "href": "new_pages/flexdashboard.fr.html#shiny",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.8 Shiny",
    "text": "42.8 Shiny\nL’intégration du paquet R shiny peut rendre vos tableaux de bord encore plus réactifs aux entrées de l’utilisateur. Par exemple, vous pouvez demander à l’utilisateur de sélectionner une juridiction ou une plage de dates, et faire réagir les panneaux à son choix (par exemple, filtrer les données affichées). Pour intégrer la réactivité shiny dans flexdashboard, il vous suffit d’apporter quelques modifications à votre script Markdown R flexdashboard.\nVous pouvez également utiliser shiny pour produire des applications ou des tableaux de bord sans flexdashboard. La page du manuel sur les tableaux de bord avec Shiny donne un aperçu de cette approche, y compris des conseils sur la syntaxe shiny, la structure des fichiers d’application et les options de partage et de publication (y compris les options de serveur libre). Ces conseils syntaxiques et généraux s’appliquent également au contexte flexdashboard.\nL’intégration de shiny dans flexdashboard constitue cependant un changement fondamental pour votre flexdashboard. Il ne produira plus une sortie HTML que vous pouvez envoyer par courriel et que tout le monde peut ouvrir et visualiser. Il s’agira plutôt d’une “application”. Le bouton “Knit” en haut du script sera remplacé par une icône “Run document”, qui ouvrira une instance du tableau de bord interactif localement sur votre ordinateur.\nLe partage de votre tableau de bord nécessitera maintenant que vous.. :\n\nEnvoyer le script Rmd au spectateur, qu’il l’ouvre dans R sur son ordinateur et qu’il exécute l’application, ou bien…\n\nL’application/le tableau de bord est hébergé sur un serveur accessible à l’observateur.\n\nL’intégration de shiny présente donc des avantages, mais aussi des complications. Si le partage facile par email est une priorité et que vous n’avez pas besoin des capacités réactives de shiny, considérez l’interactivité réduite offerte par ggplotly() comme démontré ci-dessus.\nNous donnons ci-dessous un exemple très simple utilisant le même “outbreak_dashboard.Rmd” que ci-dessus. Une documentation complète sur l’intégration de Shiny dans flexdashboard est disponible en ligne ici.\n\nParamètres\nActivez shiny dans un flexdashboard en ajoutant le paramètre YAML runtime: shiny au même niveau d’indentation que output:, comme ci-dessous :\n---\ntitle: \"Tableau de bord d'épidémie (Démo Shiny)\".\noutput: \n  flexdashboard::flex_dashboard :\n    orientation: columns\n    vertical_layout : fill\nruntime: shiny\n---\nIl est également pratique d’activer une “barre latérale” pour contenir les widgets de saisie shiny qui collecteront les informations de l’utilisateur. Comme expliqué ci-dessus, créez une colonne et indiquez l’option {.sidebar} pour créer une barre latérale sur le côté gauche. Vous pouvez ajouter du texte et des morceaux de R contenant les commandes input shiny dans cette colonne.\nSi votre application/ tableau de bord est hébergé sur un serveur et peut avoir plusieurs utilisateurs simultanés, nommez le premier morceau de code R comme global. Incluez les commandes pour importer/charger vos données dans ce chunk. Ce chunk au nom spécial est traité différemment, et les données qui y sont importées ne le sont qu’une fois (et non en continu) et sont disponibles pour tous les utilisateurs. Cela améliore la vitesse de démarrage de l’application.\n\n\nExemple travaillé\nIci, nous adaptons le script flexdashboard “outbreak_dashboard.Rmd” pour inclure shiny. Nous allons ajouter la possibilité pour l’utilisateur de sélectionner un hôpital dans un menu déroulant, et de faire en sorte que la courbe épidémique ne reflète que les cas de cet hôpital, avec un titre de graphique dynamique. Nous faisons ce qui suit :\n\nAjouter runtime: shiny à la YAML.\n\nRe-nommer le chunk de configuration comme global.\n\nCréer une barre latérale contenant :\n\nDu code pour créer un vecteur de noms d’hôpitaux uniques\n\nUne commande selectInput() (menu déroulant shiny) avec le choix des noms d’hôpitaux. La sélection est sauvegardée sous le nom de hospital_choice, qui peut être référencé dans le code suivant comme input$hospital_choice.\n\n\nLe code de la courbe d’épidémie (colonne 2) est enveloppé dans renderPlot({ }), incluant :\n\nUn filtre sur l’ensemble de données qui restreint la colonne hospital à la valeur actuelle de input$hospital_choice.\n\nUn titre dynamique du tracé qui incorpore input$hospital_choice.\n\n\nNotez que tout code faisant référence à une valeur input$ doit se trouver dans une fonction render({}) (pour être réactif).\nVoici le haut du script, incluant YAML, le chunk global, et la barre latérale :\n\n\n\n\n\n\n\n\n\nVoici la colonne 2, avec le tracé de l’épicurve réactive :\n\n\n\n\n\n\n\n\n\nEt voici le tableau de bord :\n\n\n\n\n\n\n\n\n\n\n\nAutres exemples\nPour lire un exemple de tableau de bord Shiny-flexdashboard lié à la santé et utilisant l’interactivité shiny et le widget de cartographie leaflet, consultez ce chapitre du livre en ligne Geospatial Health Data : Modeling and Visualization with R-INLA and Shiny.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#partage",
    "href": "new_pages/flexdashboard.fr.html#partage",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.9 Partage",
    "text": "42.9 Partage\nLes tableaux de bord qui ne contiennent pas d’éléments Shiny produisent un fichier HTML (.html), qui peut être envoyé par courriel (si la taille le permet). Ceci est utile, car vous pouvez envoyer le rapport du “tableau de bord” sans avoir à configurer un serveur pour l’héberger en tant que site web.\nSi vous avez intégré shiny, vous ne pourrez pas envoyer une sortie par e-mail, mais vous pouvez envoyer le script lui-même à un utilisateur R, ou héberger le tableau de bord sur un serveur comme expliqué ci-dessus.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.fr.html#ressources",
    "href": "new_pages/flexdashboard.fr.html#ressources",
    "title": "42  Tableaux de bord avec R Markdown",
    "section": "42.10 Ressources",
    "text": "42.10 Ressources\nLes excellents tutoriels qui ont informé cette page se trouvent ci-dessous. Si vous les consultez, vous pourrez probablement créer votre propre tableau de bord en moins d’une heure.\nhttps://bookdown.org/yihui/rmarkdown/dashboards.html\nhttps://rmarkdown.rstudio.com/flexdashboard/\nhttps://rmarkdown.rstudio.com/flexdashboard/using.html\nhttps://rmarkdown.rstudio.com/flexdashboard/examples.html",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Tableaux de bord avec R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html",
    "href": "new_pages/shiny_basics.fr.html",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "",
    "text": "43.1 Préparation",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#préparation",
    "href": "new_pages/shiny_basics.fr.html#préparation",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "",
    "text": "Chargement des packages\nDans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages R.\nNous commençons par installer le package R shiny :\n\npacman::p_load(\"shiny\")\n\n\n\nImporter des données\nSi vous souhaitez suivre cette page, consultez la section du manuel pour le téléchargement des données. Il y a des liens pour télécharger les scripts R et les fichiers de données qui produisent l’application Shiny finale.\nSi vous essayez de reconstruire l’application à l’aide de ces fichiers, veuillez tenir compte de la structure des dossiers du projet R qui est créée au cours de la démonstration (par exemple, des dossiers pour “data” et pour “funcs”).",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#la-structure-dune-application-shiny",
    "href": "new_pages/shiny_basics.fr.html#la-structure-dune-application-shiny",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.2 La structure d’une application shiny",
    "text": "43.2 La structure d’une application shiny\n\nStructures de fichiers de base\nPour comprendre shiny, nous devons d’abord comprendre comment fonctionne la structure des fichiers d’une application ! Nous devrions créer un tout nouveau répertoire avant de commencer. Cela peut être rendu plus facile en choisissant New project dans Rstudio, et en choisissant Shiny Web Application. Cela créera la structure de base d’une application shiny pour vous.\nEn ouvrant ce projet, vous remarquerez qu’il y a déjà un fichier .R appelé app.R. Il est essentiel que nous ayons une des deux structures de fichiers de base :\n\nUn seul fichier appelé app.R, ou\nDeux fichiers, l’un appelé ui.R et l’autre server.R\n\nDans cette page, nous utiliserons la première approche qui consiste à avoir un seul fichier appelé app.R. Voici un exemple de script :\n\n# exemple de un script app.R\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n    # titre de l'application \n    titlePanel(\"My app\"),\n\n    # Sidebar avec le widget slider input \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # afficher le graphique\n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n\n# Définir la logique du serveur requise pour dessiner un histogramme\n\nserver &lt;- function(input, output) {\n     \n     plot_1 &lt;- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot &lt;- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Executer application \nshinyApp(ui = ui, server = server)\n\nSi vous ouvrez ce fichier, vous remarquerez que deux objets sont définis, un appelé ui et l’autre appelé server. Ces objets doivent être définis dans toutes les applications shiny et sont essentiels à la structure de l’application elle-même ! En fait, la seule différence entre les deux structures de fichiers décrites ci-dessus est que dans la structure 1, ui et server sont définis dans un seul fichier, alors que dans la structure 2, ils sont définis dans des fichiers séparés. Note : nous pouvons aussi (et nous devrions si nous avons une application plus grande) avoir d’autres fichiers .R dans notre structure que nous pouvons sourcer avec source() dans notre application.\n\n\nLe serveur et l’interface utilisateur\nNous devons maintenant comprendre ce que les objets server et ui font réellement. Pour faire simple, ce sont deux objets qui interagissent l’un avec l’autre à chaque fois que l’utilisateur interagit avec l’application shiny.\nL’élément UI d’une shiny app est, à la base, le code R qui crée une interface HTML. Cela signifie que tout ce qui est affiché dans l’interface utilisateur d’une application. Cela inclut généralement :\n\nLes “widgets”, par exemples les menus déroulants, cases à cocher, curseurs, etc. avec lesquels l’utilisateur peut interagir.\nGraphiques, tableaux, etc; toutes sorties générées par le code R.\nLes aspects de navigation d’une application, par exemples les onglets, volets, etc.\nTexte générique, liens hypertextes, etc.\nÉléments HTML et CSS (abordés plus tard)\n\nLa chose la plus importante à comprendre au sujet de l’interface utilisateur est qu’elle reçoit des entrées de l’utilisateur et affiche des sorties du serveur. Aucun code actif n’est exécuté dans l’interface utilisateur à tout moment. Tous les changements vus dans l’interface utilisateur sont transmis au serveur (plus ou moins). Nous devons donc effectuer tous nos tracés, téléchargements, etc. dans le serveur.\nLe serveur de l’application shiny est l’endroit où tout le code est exécuté une fois que l’application démarre. La façon dont cela fonctionne est un peu complique. Le serveur va effectivement réagir à l’interface utilisateur et exécuter des bout de code en réponse. Si les choses changent dans le serveur, elles seront transmises à l’interface utilisateur, où les changements seront visibles. Il est important de noter que le code dans le serveur sera exécuté non consécutivement (ou il est préférable d’y penser de cette façon). En gros, chaque fois qu’une entrée de l’interface utilisateur affecte un bout de code dans le serveur, celui-ci s’exécutera automatiquement, et la sortie sera produite et affichée.\nTout cela semble probablement très abstrait pour l’instant, nous allons donc travailler avec quelques exemples pour avoir une idée claire de la façon dont cela fonctionne réellement.\n\n\nAvant de commencer à construire une application\nAvant de commencer à construire une application, il est extrêmement utile de savoir ce que vous voulez construire. Puisque votre interface utilisateur sera écrite en code, vous ne pouvez pas vraiment visualiser ce que vous construisez, sauf si vous visez quelque chose de spécifique. Pour cette raison, il est extrêmement utile de regarder de nombreux exemples d’applications shinys pour avoir une idée de ce que vous pouvez faire. Encore mieux, si vous pouvez regarder le code source derrière ces applications ! Voici quelques bonnes ressources pour cela :\n\nLa galerie d’applications Rstudio\n\nUne fois que vous avez une idée de ce qui est possible, il est également utile de dessiner ce à quoi vous voulez que votre application ressemble. Vous pouvez faire un dessin soit sur du papier ou dans un logiciel de dessin (PowerPoint, MS paint, etc.). Il est utile de commencer simplement pour votre première application ! Il n’y a certainment pas d’honte à utiliser le code d’une belle application que vous trouvez en ligne comme modèle pour votre travail. C’est beaucoup plus facile que construire quelque chose à partir de zéro !",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#construire-une-interface-utilisateur",
    "href": "new_pages/shiny_basics.fr.html#construire-une-interface-utilisateur",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.3 Construire une interface utilisateur",
    "text": "43.3 Construire une interface utilisateur\nLorsque nous construisons notre application, il est plus facile de travailler d’abord sur l’interface utilisateur afin de voir ce que nous faisons, et de ne pas risquer que l’application échoue à cause d’erreurs de serveur. Comme mentionné précédemment, il est souvent bon d’utiliser un modèle pour travailler sur l’interface utilisateur. Il y a un certain nombre de modèles standards qui peuvent être utilisés avec shiny et qui sont disponibles dans le package de base shiny, mais il est intéressant de noter qu’il y a aussi un certain nombre d’extensions du package comme shinydashboard. Nous allons utiliser un exemple de la base shiny pour commencer.\nUne interface utilisateur shiny est généralement définie comme une série de fonctions imbriquées, dans l’ordre suivant:\n\nUne fonction définissant la mise en page générale (la plus basique est fluidPage(), mais d’autres sont disponibles)\nDes panneaux à l’intérieur de la mise en page tels que:\n\nune barre latérale (sidebarPanel())\nun panneau “principal” (mainPanel())\nun onglet (tabPanel())\nune “colonne” générique (column())\n\nWidgets et sorties : ils peuvent conférer des entrées au serveur (widgets) ou des sorties du serveur (outputs)\n\nLes widgets sont généralement appelés xxxInput(), par exemple selectInput().\nLes sorties sont généralement appelées xxxOutput(), par exemple plotOutput().\n\n\nIl est important de préciser que ces éléments ne peuvent pas être visualisés facilement de manière abstraite. Il est donc préférable de regarder un exemple ! Considérons la création d’une application de base qui visualise nos données de denombrement des equipemnts de lutte contre le paludisme par district. Ces données comportent un grand nombre de paramètres différents, et il serait formidable que l’utilisateur final puisse appliquer des filtres pour voir les données par groupe d’âge/district comme il l’entend ! Nous pouvons utiliser une mise en page shiny très simple pour commencer, la mise en page de la barre latérale. Il s’agit d’une mise en page où les widgets sont placés dans une barre latérale sur la gauche, et le graphique est placé sur la droite.\nElaborons notre application: nous pouvons commencer par un sélecteur qui nous permet de choisir le district où nous voulons visualiser les données, et un autre qui nous permet de visualiser le groupe d’âge qui nous intéresse. Nous allons utiliser ces filtres pour afficher une épicurve qui reflète ces paramètres. Pour cela, nous avons besoin de:\n\nDeux menus déroulants qui nous permettent de choisir le district que nous voulons et le groupe d’âge qui nous intéresse.\nUne zone où nous pouvons montrer notre épicurve obtenue.\n\nCela pourrait ressembler à quelque chose comme ceci:\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # sélecteur pour le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Sélectionnez le groupe d'âge\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nLorsque app.R est exécuté avec le code d’interface utilisateur ci-dessus (sans code actif dans la partie server de app.R) le mise en page apparaît comme ceci. Notez qu’il n’y aura pas de tracé s’il n’y a pas de serveur pour conduire à ce resultat, mais nos entrées fonctionnent !\n\n\n\n\n\n\n\n\n\nC’est une bonne occasion de discuter les fonctionnement des widgets. Notez que chaque widget accepte un inputId, un label, et une série d’autres options qui sont spécifiques au type de widget. Ce inputId est extrêmement important ! Ce sont les IDs qui sont utilisés pour passer les informations de l’IU au serveur. Pour cette raison, ils doivent être uniques. Vous devriez faire un effort pour les nommer de manière sensée et spécifique à ce avec quoi ils interagissent dans le cas de grandes applications.\nVous devez lire attentivement la documentation pour obtenir tous les détails sur ce que font chacun de ces widgets. Les widgets transmettront des types de données spécifiques au serveur en fonction du type de widget, et cela doit être bien compris. Par exemple, selectInput() transmettra un type de caractère au serveur :\n\nSi nous sélectionnons Spring pour le premier widget ici, il transmettra l’objet caractère \"Spring\" au serveur.\nSi nous sélectionnons deux éléments dans le menu déroulant, ils seront transmis sous forme de vecteur de caractères (par exemple, c(\"Spring\", \"Bolo\")).\n\nD’autres widgets transmettront différents types d’objets au serveur ! Par exemple\n\nnumericInput() passera un objet de type numérique au serveur.\ncheckboxInput() transmettra un objet de type logique au serveur (TRUE ou FALSE).\n\nIl est également intéressant de noter le vecteur nommé que nous avons utilisé pour les données d’âge ici. Pour de nombreux widgets, l’utilisation d’un vecteur nommé comme choix affichera les noms du vecteur comme choix d’affichage, mais passera la valeur sélectionnée du vecteur au serveur. Par exemple, ici quelqu’un peut sélectionner “15+” dans le menu déroulant, et l’interface utilisateur transmettra \"malaria_rdt_15\" au serveur - qui se trouve être le nom de la colonne qui nous intéresse !\nIl y a beaucoup de widgets que vous pouvez utiliser dans votre application. Les widgets vous permettent également de télécharger des fichiers dans votre application, et de télécharger des sorties. Il existe également d’excellentes examples de shiny qui vous donnent accès à plus de widgets que le shiny de base. Le package shinyWidgets en est un excellent exemple. Pour voir quelques exemples, vous pouvez consulter les liens suivants :\n\ngalerie de widgets de la base shiny\ngalerie de widgets shinyWidgets",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#chargement-des-données-dans-notre-application",
    "href": "new_pages/shiny_basics.fr.html#chargement-des-données-dans-notre-application",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.4 Chargement des données dans notre application",
    "text": "43.4 Chargement des données dans notre application\nL’étape suivante dans le développement de notre application consiste à mettre en place le serveur et à le faire fonctionner. Pour ce faire, nous devons charger des données dans notre application, et déterminer tous les calculs que nous allons effectuer. Une application shiny n’est pas facile à déboguer, car on ne sait pas toujours d’où viennent les erreurs. Il est donc idéal de faire fonctionner tout le code de traitement et de visualisation des données avant de commencer à créer le serveur lui-même.\nAinsi, étant donné que nous voulons créer une application qui affiche des courbes épi qui changent en fonction de l’entrée de l’utilisateur, nous devons réfléchir au code dont nous aurions besoin pour l’exécuter dans un script R normal. Nous devrons :\n\nCharger nos packages\nCharger nos données\nTransformer nos données\nDévelopper une fonction pour visualiser nos données en fonction des entrées de l’utilisateur.\n\nCette liste est assez simple, et ne devrait pas être trop difficile à réaliser. Il est maintenant important de réfléchir aux parties de ce processus qui doivent être faites une seule fois et à celles qui doivent être exécutées en réponse aux entrées de l’utilisateur. En effet, les applications shiny exécutent généralement du code avant de s’exécuter, ce qui n’est fait qu’une seule fois. La performance de notre application sera améliorée si une grande partie de notre code peut être déplacée dans cette section. Pour cet exemple, nous n’avons besoin de charger nos données/packages et d’effectuer des transformations de base qu’une seule fois, nous pouvons donc placer ce code hors du serveur. Cela signifie que la seule chose dont nous aurons besoin dans le serveur est le code pour visualiser nos données. Développons d’abord tous ces composants dans un script. Cependant, puisque nous visualisons nos données à l’aide d’une fonction, nous pouvons également placer le code pour la fonction en dehors du serveur afin que notre fonction soit dans l’environnement lorsque l’application s’exécute !\nCommençons par charger nos données. Puisque nous travaillons avec un nouveau projet, et que nous voulons le rendre propre, nous pouvons créer un nouveau répertoire appelé data, et y ajouter nos données sur le paludisme. Nous pouvons exécuter ce code ci-dessous dans un script de test que nous supprimerons éventuellement lorsque nous aurons nettoyé la structure de notre application.\n\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# read data\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\nprint(malaria_data)\n\n# A tibble: 3,038 × 10\n   location_name data_date  submitted_date Province District `malaria_rdt_0-4`\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11\n 2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11\n 3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8\n 4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16\n 5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9\n 6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3\n 7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4\n 8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15\n 9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11\n10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19\n# ℹ 3,028 more rows\n# ℹ 4 more variables: `malaria_rdt_5-14` &lt;int&gt;, malaria_rdt_15 &lt;int&gt;,\n#   malaria_tot &lt;int&gt;, newid &lt;int&gt;\n\n\nIl sera plus facile de travailler avec ces données si nous utilisons des données ordonnées standards, nous devons donc également les transformer en un format de données plus long, où le groupe d’âge est une colonne, et les cas une autre colonne. Nous pouvons le faire facilement en utilisant ce que nous avons appris dans la page Pivoter les données.\n\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)\n\n# A tibble: 12,152 × 7\n   location_name data_date  submitted_date Province District age_group       \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;           \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0-4 \n 2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5-14\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15  \n 4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot     \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0-4 \n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5-14\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15  \n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot     \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0-4 \n10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5-14\n# ℹ 12,142 more rows\n# ℹ 1 more variable: cases_reported &lt;int&gt;\n\n\nEt avec cela, nous avons fini de préparer nos données ! Cela raye les points 1, 2 et 3 de notre liste de choses à développer pour notre “script R de test”. La dernière tâche, et la plus difficile, sera de construire une fonction pour produire une épicurve basée sur des paramètres définis par l’utilisateur. Comme nous l’avons mentionné précédemment, il est hautement recommandé à toute personne apprenant shiny de regarder d’abord la section sur la programmation fonctionnelle (Écrire les fonctions) pour comprendre comment cela fonctionne !\nLorsque nous définissons notre fonction, il peut être difficile de penser aux paramètres que nous voulons inclure. Dans le cadre de la programmation fonctionnelle avec shiny, chaque paramètre pertinent est généralement associé à un widget, ce qui facilite la réflexion ! Par exemple, dans notre application actuelle, nous voulons être en mesure de filtrer par district, et avoir un widget pour cela, donc nous pouvons ajouter un paramètre de district pour refléter cela. Nous n’avons pas de fonctionnalité d’application pour filtrer par établissement (pour l’instant), donc nous n’avons pas besoin de l’ajouter comme paramètre. Commençons par créer une fonction avec trois paramètres :\n\nL’ensemble de données de base\nLe district de choix\nLe groupe d’âge choisi\n\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nNous n’entrerons pas dans les détails de cette fonction, car elle est relativement simple dans son fonctionnement. Une chose à noter cependant, c’est que nous gérons les erreurs en retournant NULL alors qu’elle devrait entrainer une erreur. En effet, si le serveur shiny produit un objet NULL au lieu d’un objet plot, rien ne sera affiché dans l’interface utilisateur ! C’est important, car sinon les erreurs vont souvent provoquer l’arrêt du fonctionnement de votre application.\nUne autre chose à noter est l’utilisation de l’opérateur %in% lors de l’évaluation de l’entrée district. Comme mentionné ci-dessus, cela pourrait arriver comme un vecteur de caractères avec plusieurs valeurs, donc l’utilisation de %in% est plus flexible que disons, ==.\nTestons notre fonction !\n\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n\n\n\n\n\n\n\n\nMaintenant que notre fonction fonctionne, nous devons comprendre comment tout cela va s’intégrer dans notre shiny application. Nous avons déjà mentionné le concept de startup code, mais voyons comment l’intégrer dans la structure de notre application. Il y a deux façons de le faire !\n\nPlacer ce code dans votre fichier app.R au début du script (au-dessus de l’interface utilisateur), ou bien\n\nCréer un nouveau fichier dans le répertoire de votre application appelé global.R, et placer le code de démarrage dans ce fichier.\n\nIl convient de noter à ce stade qu’il est généralement plus facile, en particulier pour les applications plus importantes, d’utiliser la deuxième structure de fichiers, car elle vous permet de séparer votre structure de fichiers d’une manière simple. Développons maintenant complètement ce script global.R. Voici à quoi il pourrait ressembler :\n\n# global.R script\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n\n# lire les données\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\n# données nettoyées et  pivotées en longueur\n\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# definir la fonction pour la representation graphique\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # creer le titre du graphe\n  if (!(\"All\" %in% district)) {            \n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filtrer par groupe d'âge\n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nFacile ! Une des grandes caractéristiques de shiny est qu’il comprend à quoi servent les fichiers nommés app.R, server.R, ui.R et global.R, il n’y a donc pas besoin de les connecter entre eux par un quelconque code. Ainsi, il suffit d’avoir ce code dans global.R dans le répertoire pour qu’il s’exécute avant que nous démarrions notre application.\nNous devons également noter que l’organisation de notre application serait améliorée si nous déplacions la fonction de traçage dans son propre fichier - cela sera particulièrement utile lorsque les applications deviendront plus grandes. Pour ce faire, nous pourrions créer un autre répertoire appelé funcs, et y placer cette fonction dans un fichier appelé plot_epicurve.R. Nous pourrions ensuite lire cette fonction via la commande suivante dans global.R.\n\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)\n\nNotez que vous devriez toujours spécifier local = TRUE dans les applications shiny, car cela affectera le sourcing quand/si l’application est publiée sur un serveur.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#développer-un-serveur-dapplications",
    "href": "new_pages/shiny_basics.fr.html#développer-un-serveur-dapplications",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.5 Développer un serveur d’applications",
    "text": "43.5 Développer un serveur d’applications\nMaintenant que nous avons la plupart de notre code, il nous reste à développer notre serveur. Il s’agit de la dernière pièce de notre application, et c’est probablement la plus difficile à comprendre. Le serveur est une grande fonction R, mais il est utile de le considérer comme une série de petites fonctions, ou de tâches que l’application peut exécuter. Il est important de comprendre que ces fonctions ne sont pas exécutées dans un ordre linéaire. Il existe un ordre, mais il n’est pas nécessaire de le comprendre lorsqu’on débute avec Shiny. À un niveau très basique, ces tâches ou fonctions s’activent lorsqu’un changement dans les entrées de l’utilisateur les affecte, à moins que le développeur ne les ait configurées pour qu’elles se comportent différemment. Encore une fois, tout cela est assez abstrait, mais passons d’abord en revue les trois types d’objets shiny de base\n\nLes sources réactives - c’est un autre terme pour les entrées de l’utilisateur. Le serveur shiny a accès aux sorties de l’interface utilisateur par le biais des widgets que nous avons programmés. Chaque fois que les valeurs de ces derniers sont modifiées, elles sont transmises au serveur.\nConducteurs réactifs - ce sont des objets qui existent seulement à l’intérieur du shiny server. Nous n’en avons pas vraiment besoin pour les applications simples, mais ils produisent des objets qui ne peuvent être vus qu’à l’intérieur du serveur, et utilisés dans d’autres opérations. Ils dépendent généralement de sources réactives.\nLes points de terminaison - ce sont les sorties qui sont transmises du serveur à l’interface utilisateur. Dans notre exemple, il s’agit de la courbe épi que nous produisons.\n\nAvec ceci en tête, construisons notre serveur étape par étape. Nous montrons à nouveau le code de l’interface utilisateur à titre de référence :\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Sélectionnez le district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # sélectionnez le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Sélectionnez le groupe d'âge\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nDe ce code UI nous avons :\n\nDeux entrées :\n\nSélecteur de district (avec un inputId de select_district)\nUn sélecteur de groupe d’âge (avec un inputId de select_agegroup)\n\nUne sortie :\n\nL’épicurve (avec un outputId de malaria_epicurve)\n\n\nComme indiqué précédemment, ces noms uniques que nous avons attribués à nos entrées et sorties sont cruciaux. Ils doivent être uniques et sont utilisés pour transmettre des informations entre l’interface utilisateur et le serveur. Dans notre serveur, nous accédons à nos entrées via la syntaxe input$inputID et les sorties sont transmises à l’interface utilisateur via la syntaxe output$output_name Voyons un exemple, car encore une fois, c’est difficile à comprendre autrement !\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}\n\nLe serveur pour une application simple comme celle-ci est en fait assez simple ! Vous remarquerez que le serveur est une fonction avec trois paramètres - input, output, et session - ce n’est pas très important à comprendre pour le moment, mais il est important de s’en tenir à cette configuration ! Dans notre serveur, nous n’avons qu’une seule tâche - elle rend un graphique basé sur la fonction que nous avons créée plus tôt, et les entrées du serveur. Remarquez que les noms des objets d’entrée et de sortie correspondent exactement à ceux de l’interface utilisateur.\nPour comprendre les bases de la façon dont le serveur réagit aux entrées de l’utilisateur, vous devez noter que la sortie saura (grâce au package sous-jacent) quand les entrées changent, et réexécutera cette fonction pour créer un graphique à chaque fois qu’elles changent. Notez que nous utilisons également la fonction renderPlot() ici - c’est l’une des fonctions d’une famille de classes spécifiques qui passent ces objets à une sortie ui. Il existe un certain nombre de fonctions qui se comportent de manière similaire, mais vous devez vous assurer que la fonction utilisée correspond à la classe de l’objet que vous transmettez à l’interface utilisateur ! Par exemple :\n\nrenderText() - envoie du texte à l’interface utilisateur\nrenderDataTable - envoie une table interactive à l’interface utilisateur.\n\nRappelez-vous que ces fonctions doivent également correspondre à la fonction de sortie utilisée dans l’interface utilisateur - ainsi, renderPlot() est associé à plotOutput(), et renderText() est associé à textOutput().\nNous avons enfin créé une application fonctionnelle ! Nous pouvons l’exécuter en appuyant sur le bouton Run App en haut à droite de la fenêtre du script dans Rstudio. Notez que vous pouvez choisir de lancer votre application dans votre navigateur par défaut (plutôt que dans Rstudio), ce qui reflétera plus fidèlement ce à quoi l’application ressemblera pour les autres utilisateurs.\n\n\n\n\n\n\n\n\n\nIl est amusant de noter que dans la console R, l’application est “à l’écoute” ! On parle de réactivité !",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#ajout-de-fonctionnalités-supplémentaires",
    "href": "new_pages/shiny_basics.fr.html#ajout-de-fonctionnalités-supplémentaires",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.6 Ajout de fonctionnalités supplémentaires",
    "text": "43.6 Ajout de fonctionnalités supplémentaires\nÀ ce stade, nous avons enfin une application qui fonctionne, mais nous avons très peu de fonctionnalités. De plus, nous n’avons pas encore touché à la surface de ce que shiny peut faire, il y a donc encore beaucoup à apprendre ! Continuons à développer notre application existante en ajoutant quelques fonctionnalités supplémentaires. Voici quelques éléments qu’il serait bon d’ajouter :\n\nUn texte explicatif\nUn bouton de téléchargement pour notre parcelle - cela permettrait à l’utilisateur d’obtenir une version de haute qualité de l’image qu’il génère dans l’application.\nUn sélecteur pour des equipements particuliers\nUne autre page de tableau de bord - elle pourrait afficher un tableau de nos données.\n\nCela fait beaucoup de choses à ajouter, mais nous pouvons l’utiliser pour en apprendre davantage sur un tas de prouesses différentes en cours. Il y a tant à apprendre sur shiny (il peut être très avancé, mais il est à espérer qu’une fois que les utilisateurs ont une meilleure idée de la façon de l’utiliser, ils peuvent devenir plus à l’aise en utilisant des sources d’apprentissage externes aussi).\n\nAjouter du texte statique\nParlons d’abord de l’ajout de texte statique à notre application shiny. L’ajout de texte à notre application est extrêmement facile, une fois que vous en avez une connaissance de base. Puisque le texte statique ne change pas dans l’application shiny (si vous voulez qu’il change, vous pouvez utiliser les fonctions de rendu de texte dans le serveur ! Nous n’allons pas entrer dans les détails, mais vous pouvez ajouter un certain nombre d’éléments différents à votre interface utilisateur (et même des éléments personnalisés) en interfaçant R avec HTML et css.\nHTML et css sont des langages qui sont explicitement impliqués dans la conception de l’interface utilisateur. Nous n’avons pas besoin de trop les comprendre, mais HTML crée des objets dans l’IU (comme une boîte de texte, ou un tableau), et css est généralement utilisé pour changer le style et l’esthétique de ces objets. Shiny a accès à un large éventail de balises HTML - celles-ci sont présentes pour les objets qui se comportent d’une manière spécifique, comme les en-têtes, les paragraphes de texte, les sauts de ligne, les tableaux, etc. Nous pouvons utiliser certains de ces exemples comme ceci :\n\nh1() - il s’agit d’une balise header, qui rendra le texte inclus automatiquement plus grand, et changera les valeurs par défaut en ce qui concerne la police, la couleur, etc (selon le thème général de votre application). Vous pouvez accéder à des sous-titres plus petits et plus petits avec h2() jusqu’à h6() également. L’utilisation ressemble à :\n\nh1(\"mon en-tête - section 1\")\n\np() - il s’agit d’une balise paragraphe, qui rendra le texte inclus similaire à un texte dans un corps de texte. Ce texte sera automatiquement enveloppé, et sera d’une taille relativement petite (les pieds de page pourraient être plus petits par exemple.) Pensez-y comme le corps de texte d’un document Word. L’utilisation ressemble à :\n\np(\"Ceci est un corps de texte plus large où j'explique la fonction de mon application\")\n\ntags$b() et tags$i() - elles sont utilisées pour créer des tags$b() en gras et des tags$i() en italique avec le texte inclus !\ntags$ul(), tags$ol() et tags$li() - ce sont des balises utilisées pour créer des listes. Elles sont toutes utilisées dans la syntaxe ci-dessous, et permettent à l’utilisateur de créer une liste ordonnée (tags$ol(), c’est-à-dire numérotée) ou non ordonnée (tags$ul(), c’est-à-dire à puces). tags$li() est utilisé pour désigner les éléments de la liste, quel que soit le type de liste utilisé. par exemple :\n\n\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\n\n\nbr() et hr() - ces balises créent respectivement des sauts de ligne et des lignes horizontales (avec un saut de ligne). Utilisez-les pour séparer les sections de votre application et de votre texte ! Il n’est pas nécessaire de passer des éléments à ces balises (les parenthèses peuvent rester vides).\ndiv() - c’est une balise générique qui peut contenir n’importe quoi, et peut être nommée n’importe comment. Une fois que vous aurez progressé dans la conception de l’IU, vous pourrez les utiliser pour compartimenter votre IU, donner des styles spécifiques à certaines sections et créer des interactions entre le serveur et les éléments de l’IU. Nous n’entrerons pas dans les détails, mais il vaut la peine de les connaître !\n\nNotez que chacun de ces objets peut être accédé par tags$... ou pour certains, juste la fonction. Ce sont effectivement des synonymes, mais il peut être utile d’utiliser le style tags$... si vous préférez être plus explicite et ne pas écraser les fonctions accidentellement. Ceci n’est en aucun cas une liste exhaustive des balises disponibles. Il existe une liste complète de toutes les balises disponibles dans shiny ici et encore plus peuvent être utilisées en insérant du HTML directement dans votre interface !\nSi vous vous sentez confiant, vous pouvez également ajouter des éléments de style css à vos balises HTML avec l’argument style dans chacune d’entre elles. Nous n’allons pas entrer dans les détails de ce fonctionnement, mais une astuce pour tester les changements esthétiques d’une interface utilisateur est d’utiliser le mode inspecteur HTML dans chrome (de votre shiny application que vous exécutez dans le navigateur), et de modifier le style des objets vous-même !\nAjoutons du texte à notre application\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # sélecteur pour le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)\n\n\n\n\n\n\n\n\n\n\n\n\nAjouter un lien\nPour ajouter un lien à un site Web, utilisez tags$a() avec le lien et le texte à afficher comme indiqué ci-dessous. Pour avoir un paragraphe autonome, mettez-le dans p(). Pour que seuls quelques mots d’une phrase soient liés, divisez la phrase en plusieurs parties et utilisez tags$a() pour la partie hyperliée. Pour que le lien s’ouvre dans une nouvelle fenêtre du navigateur, ajoutez target = \"_blank\" comme argument.\n\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")\n\n\n\nAjout d’un bouton de téléchargement\nPassons à la deuxième des trois fonctions. Un bouton de téléchargement est une chose assez courante à ajouter à une application et est assez facile à réaliser. Nous devons ajouter un autre Widget à notre interface, et nous devons ajouter une autre sortie à notre serveur pour l’attacher. Nous pouvons également introduire des conducteurs réactifs dans cet exemple !\nMettons d’abord à jour notre interface utilisateur - c’est facile car shiny est livré avec un widget appelé downloadButton() - donnons-lui un inputId et un label.\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # sélecteur pour le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # ligne horizontale\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nNotez que nous avons également ajouté une balise hr() - celle-ci ajoute une ligne horizontale séparant nos widgets de contrôle de nos widgets de téléchargement. C’est une autre des balises HTML dont nous avons parlé précédemment.\nMaintenant que notre interface utilisateur est prête, nous devons ajouter le composant serveur. Les téléchargements sont effectués dans le serveur avec la fonction downloadHandler(). Comme pour notre plot, nous devons l’attacher à une sortie qui a le même inputId que le bouton de téléchargement. Cette fonction prend deux arguments - filename et content - ce sont tous deux des fonctions. Comme vous pouvez le deviner, filename est utilisé pour spécifier le nom du fichier à télécharger, et content est utilisé pour spécifier ce qui doit être téléchargé. content contient une fonction que vous utiliserez pour sauvegarder des données localement - donc si vous téléchargez un fichier csv, vous pourrez utiliser rio::export(). Comme nous téléchargeons un graphique, nous utiliserons ggplot2::ggsave(). Voyons comment nous allons programmer ceci (nous ne l’ajouterons pas encore au serveur).\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nNotez que la fonction content prend toujours un argument file, que nous mettons là où le nom du fichier de sortie est spécifié. Vous pouvez également remarquer que nous répétons du code ici - nous utilisons notre fonction plot_epicurve() deux fois dans ce serveur, une fois pour le téléchargement et une fois pour l’image affichée dans l’application. Bien que cela n’affecte pas massivement les performances, cela signifie que le code pour générer ce tracé devra être exécuté lorsque l’utilisateur change les widgets spécifiant le district et le groupe d’âge, et à nouveau lorsque vous voulez télécharger le tracé. Dans les grandes applications, les décisions sous-optimales comme celle-ci ralentiront de plus en plus les choses, il est donc bon d’apprendre comment rendre notre application plus efficace dans ce sens. Ce qui serait plus logique, c’est d’avoir un moyen d’exécuter le code epicurve lorsque les districts/groupes d’âge sont modifiés, et de laisser ce code être utilisé par les fonctions renderPlot() et downloadHandler(). C’est là que les conducteurs réactifs entrent en jeu !\nLes conducteurs réactifs sont des objets qui sont créés dans le serveur shiny de manière réactive, mais qui ne sont pas édités - ils peuvent simplement être utilisés par d’autres parties du serveur. Il existe un certain nombre de types différents de conducteurs réactifs, mais nous allons passer en revue les deux principaux.\n1.reactive() - c’est le conducteur réactif le plus basique - il réagira à chaque fois que les entrées utilisées à l’intérieur changeront (comme nos widgets de district/groupe d’âge).\n2. eventReactive() - ce conducteur réactif fonctionne de la même manière que reactive(), sauf que l’utilisateur peut spécifier les entrées qui le font réexécuter. Ceci est utile si votre conducteur réactif prend beaucoup de temps à traiter, mais ceci sera expliqué plus tard.\nRegardons les deux exemples :\n\nmalaria_plot_r &lt;- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# ne s'exécute que lorsque le sélecteur de district change !\nmalaria_plot_er &lt;- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\nLorsque nous utilisons la configuration eventReactive(), nous pouvons spécifier quelles entrées provoquent l’exécution de ce morceau de code - ce n’est pas très utile pour nous pour le moment, donc nous pouvons le laisser pour l’instant. Notez que vous pouvez inclure plusieurs entrées avec c().\nVoyons comment nous pouvons intégrer cela dans notre code serveur :\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nVous pouvez voir que nous faisons simplement appel à la sortie de notre réactif que nous avons défini dans nos fonctions de téléchargement et de rendu de tracé. Une chose à noter qui fait souvent trébucher les gens est que vous devez utiliser les sorties des réactifs comme s’il s’agissait de fonctions - vous devez donc ajouter des parenthèses vides à la fin de celles-ci (par exemple, malaria_plot() est correct, et malaria_plot ne l’est pas). Maintenant que nous avons ajouté cette solution, notre application est un peu plus ordonnée, plus rapide et plus facile à modifier puisque tout le code qui exécute la fonction epicurve se trouve à un seul endroit.\n\n\n\n\n\n\n\n\n\n\n\nAjout d’un sélecteur d’equipements\nPassons à la fonctionnalité suivante : un sélecteur d’equipements spécifiques. Nous allons implémenter un autre paramètre dans notre fonction afin de pouvoir le passer comme argument dans notre code. Voyons d’abord ce qu’il en est - il fonctionne sur les mêmes principes que les autres paramètres que nous avons mis en place. Mettons à jour et testons notre fonction.\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n\n  # si il n ya pas de données restantes, retourner NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n\n  # si il n ya pas de données restantes, retourner NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data &lt;- data %&gt;%\n      filter(location_name == facility)\n    \n    plot_title_facility &lt;- facility\n    \n  } else {\n    \n    plot_title_facility &lt;- \"all facilities\"\n    \n  }\n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nTestons ca:\n\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\n\n\n\n\n\n\n\n\nAvec tous les equipements présentes dans nos données, il n’est pas très clair quels equipements correspondent à quels districts - et l’utilisateur final ne le saura pas non plus. Cela pourrait rendre l’utilisation de l’application assez peu intuitive. Pour cette raison, nous devrions faire en sorte que les options des equipements dans l’interface utilisateur changent dynamiquement lorsque l’utilisateur change de district - de sorte que l’une filtre l’autre ! Puisque nous utilisons un grand nombre de variables dans les options, nous pourrions également vouloir générer certaines de nos options pour l’interface utilisateur dans notre fichier global.R à partir des données. Par exemple, nous pouvons ajouter ce morceau de code à global.R après avoir lu nos données :\n\nall_districts &lt;- c(\"All\", unique(malaria_data$District))\n\n# base de données des noms de lieux par district\nfacility_list &lt;- malaria_data %&gt;%\n  group_by(location_name, District) %&gt;%\n  summarise() %&gt;% \n  ungroup()\n\nLet’s look at them:\n\nall_districts\n\n[1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\n\n\n\nfacility_list\n\n# A tibble: 65 × 2\n   location_name District\n   &lt;chr&gt;         &lt;chr&gt;   \n 1 Facility 1    Spring  \n 2 Facility 10   Bolo    \n 3 Facility 11   Spring  \n 4 Facility 12   Dingo   \n 5 Facility 13   Bolo    \n 6 Facility 14   Dingo   \n 7 Facility 15   Barnard \n 8 Facility 16   Barnard \n 9 Facility 17   Barnard \n10 Facility 18   Bolo    \n# ℹ 55 more rows\n\n\nNous pouvons passer ces nouvelles variables à l’interface utilisateur sans aucun problème, puisqu’elles sont globalement visibles à la fois par le serveur et l’interface utilisateur ! Mettons à jour notre interface utilisateur :\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selecteur pour district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select dsitrict\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selecteur pour age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selecteur poiur facility\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # ligne horizontale\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nRemarquez comment nous passons maintenant des variables pour nos choix au lieu de les coder en dur dans l’interface utilisateur ! Cela pourrait également rendre notre code plus compact ! Enfin, nous devrons mettre à jour le serveur. Il sera facile de mettre à jour notre fonction pour incorporer notre nouvelle entrée (nous devons juste la passer comme argument à notre nouveau paramètre), mais nous devons nous rappeler que nous voulons aussi que l’interface utilisateur soit mise à jour dynamiquement lorsque l’utilisateur change le district sélectionné. Il est important de comprendre ici que nous pouvons modifier les paramètres et le comportement des widgets pendant l’exécution de l’application, mais que cela doit être fait dans le serveur. Nous devons comprendre une nouvelle façon d’envoyer des données au serveur pour apprendre à le faire.\nLes fonctions dont nous avons besoin pour comprendre comment faire cela sont connues sous le nom de fonctions observatrices, et sont similaires aux fonctions réactives dans leur comportement. Elles présentent toutefois une différence essentielle :\n\nLes fonctions réactives n’affectent pas directement les sorties et produisent des objets qui peuvent être vus à d’autres endroits du serveur.\nLes fonctions d’observation peuvent affecter les sorties du serveur, mais le font via des effets secondaires d’autres fonctions. (Elles peuvent aussi faire d’autres choses, mais c’est leur principale fonction en pratique).\n\nComme pour les fonctions réactives, il existe deux types de fonctions d’observation, qui sont divisées par la même logique que les fonctions réactives :\n\nobserve() - cette fonction s’exécute à chaque fois que les entrées qu’elle contient changent.\nobserveEvent() - cette fonction s’exécute lorsqu’une entrée spécifiée par l’utilisateur change.\n\nNous devons également comprendre les fonctions fournies par Shiny qui mettent à jour les widgets. Elles sont assez simples à exécuter - elles prennent d’abord l’objet session de la fonction serveur (il n’est pas nécessaire de le comprendre pour l’instant), puis le inputId de la fonction à modifier. Nous passons ensuite de nouvelles versions de tous les paramètres qui sont déjà pris par selectInput() - ceux-ci seront automatiquement mis à jour dans le widget.\nRegardons un exemple isolé de la façon dont nous pourrions utiliser ceci dans notre serveur. Lorsque l’utilisateur change de district, nous voulons filtrer notre tableau d’installations par district, et mettre à jour les choix pour seulement refléter ceux qui sont disponibles dans ce district (et une option pour toutes les installations).\n\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices &lt;- facility_list$location_name\n  } else {\n    new_choices &lt;- facility_list %&gt;%\n      filter(District == input$select_district) %&gt;%\n      pull(location_name)\n  }\n  \n  new_choices &lt;- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\n\nEt voilà ! nous pouvons l’ajouter dans notre serveur, et ce comportement fonctionnera désormais. Voici à quoi devrait ressembler notre nouveau serveur :\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}\n\n\n\n\n\n\n\n\n\n\n\n\nAjout d’un autre onglet avec une table\nNous allons maintenant passer au dernier composant que nous voulons ajouter à notre application. Nous voulons séparer notre interface utilisateur en deux onglets, dont l’un comportera un tableau interactif où l’utilisateur pourra voir les données avec lesquelles il réalise la courbe épidémique. Pour ce faire, nous pouvons utiliser les éléments d’interface intégrés qui sont fournis avec Shiny pour les onglets. À un niveau de base, nous pouvons enfermer la plupart de notre panneau principal dans cette structure générale :\n\n# ... le reste de l'ui\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\n\nAppliquons cela à notre interface utilisateur. Nous voudrons également utiliser le package DT ici - c’est un excellent package pour créer des tableaux interactifs à partir de données préexistantes. Nous pouvons voir qu’il est utilisé pour DT::datatableOutput() dans cet exemple.\n\nui &lt;- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # sélectionneur pour le district\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for age group\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for facility\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # horizontal line\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\n\nMaintenant notre application est organisée en onglets ! Faisons également les modifications nécessaires sur le serveur. Puisque nous n’avons pas besoin de manipuler notre jeu de données avant de le rendre, c’est en fait très simple - nous rendons simplement le jeu de données malaria_data via DT::renderDT() à l’interface utilisateur !\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # rendre le tableau de données à ui\n  output$raw_data &lt;- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#partager-les-applications-shiny",
    "href": "new_pages/shiny_basics.fr.html#partager-les-applications-shiny",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.7 Partager les applications shiny",
    "text": "43.7 Partager les applications shiny\nMaintenant que vous avez développé votre application, vous voulez probablement la partager avec d’autres - c’est le principal avantage de shiny après tout ! Nous pouvons le faire en partageant le code directement, ou nous pouvons le publier sur un serveur. Si nous partageons le code, d’autres personnes pourront voir ce que vous avez fait et s’en inspirer, mais cela annulera l’un des principaux avantages de shiny - il peut éliminer le besoin pour les utilisateurs finaux de maintenir une installation R. Pour cette raison, si vous partagez votre application avec des utilisateurs qui ne sont pas à l’aise avec R, il est beaucoup plus facile de partager une application qui a été publiée sur un serveur.\nSi vous préférez partager le code, vous pouvez créer un fichier .zip de l’application ou, mieux encore, publier votre application sur github et ajouter des collaborateurs.\nCependant, si nous publions l’application en ligne, nous devons faire un peu plus de travail. En fin de compte, nous voulons que votre application soit accessible via une URL Web afin que d’autres puissent y accéder rapidement et facilement. Malheureusement, pour publier votre application sur un serveur, vous devez avoir accès à un serveur sur lequel la publier ! Il existe un certain nombre d’options d’hébergement à cet égard :\n\nshinyapps.io : c’est l’endroit le plus facile pour publier des applications shinys, car il nécessite le moins de travail de configuration possible et offre des licences gratuites, mais limitées.\nRStudio Connect : il s’agit d’une version beaucoup plus puissante d’un serveur R, qui peut effectuer de nombreuses opérations, y compris la publication de shiny apps. Elle est cependant plus difficile à utiliser et moins recommandée pour les utilisateurs débutants.\n\nPour les besoins de ce document, nous utiliserons shinyapps.io, car il est plus facile pour les premiers utilisateurs. Vous pouvez créer un compte gratuit ici pour commencer - il y a également différents plans de prix pour les licesnses de serveur si nécessaire. Plus vous prévoyez d’avoir d’utilisateurs, plus votre plan tarifaire devra être cher, alors tenez-en compte. Si vous cherchez à créer quelque chose à l’usage d’un petit groupe d’individus, une licence gratuite peut convenir parfaitement, mais une application destinée au public peut nécessiter plus de licences.\nTout d’abord, nous devons nous assurer que notre application est adaptée à la publication sur un serveur. Dans votre application, vous devez redémarrer votre session R et vous assurer qu’elle fonctionne sans exécuter de code supplémentaire. C’est important, car une application qui nécessite le chargement de packages ou la lecture de données non définis dans le code de votre application ne fonctionnera pas sur un serveur. Notez également que vous ne pouvez pas avoir de chemins de fichiers explicites dans votre application - ceux-ci seront invalides dans le paramétrage du serveur - l’utilisation du package here résout très bien ce problème. Enfin, si vous lisez des données à partir d’une source qui nécessite une authentification de l’utilisateur, comme les serveurs de votre organisation, cela ne fonctionnera généralement pas sur un serveur. Vous devrez vous mettre en relation avec votre service informatique pour savoir comment mettre le serveur shiny sur la whitelist.\nCréation d’un compte\nUne fois que vous avez votre compte, vous pouvez naviguer vers la page des jetons sous Accounts. Ici, vous devriez ajouter un nouveau jeton - il sera utilisé pour déployer votre application.\nA partir de là, vous devez noter que l’url de votre compte reflétera le nom de votre application - donc si votre application s’appelle mon_app, l’url sera ajouté comme xxx.io/mon_app/. Choisissez judicieusement le nom de votre application ! Maintenant que vous êtes prêt, cliquez sur deploy - si vous réussissez, votre application sera lancée sur l’url que vous avez choisi !\nQuelque chose sur la création d’applications dans des documents ?",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#lecture-complémentaire",
    "href": "new_pages/shiny_basics.fr.html#lecture-complémentaire",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.8 Lecture complémentaire",
    "text": "43.8 Lecture complémentaire\nJusqu’à présent, nous avons couvert beaucoup d’aspects de shiny, et nous avons à peine effleuré la surface de ce qui est offert pour shiny. Bien que ce guide serve d’introduction, il y a beaucoup plus à apprendre pour comprendre pleinement shiny. Vous devriez commencer à créer des applications et ajouter progressivement de plus en plus de fonctionnalités.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#packages-dextension-recommandés",
    "href": "new_pages/shiny_basics.fr.html#packages-dextension-recommandés",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.9 packages d’extension recommandés",
    "text": "43.9 packages d’extension recommandés\nCe qui suit représente une sélection d’extensions de haute qualité pour shiny qui peuvent vous aider à obtenir beaucoup plus de shiny. Sans ordre particulier :\n\nshinyWidgets - ce package vous donne beaucoup plus de widgets qui peuvent être utilisés dans votre application. Lancez shinyWidgets::shinyWidgetsGallery() pour voir une sélection des widgets disponibles avec ce package. Voir des exemples ici\nshinyjs - c’est un excellent package qui donne à l’utilisateur la possibilité d’étendre considérablement l’utilité de shiny via une série de javascript. Les applications de ce package vont de très simples à très avancées, mais vous voudrez peut-être l’utiliser d’abord pour manipuler l’interface utilisateur de manière simple, comme cacher/afficher des éléments, ou activer/désactiver des boutons. En savoir plus ici\nshinydashboard - ce package étend massivement l’interface utilisateur disponible qui peut être utilisée dans shiny, en particulier en permettant à l’utilisateur de créer un tableau de bord complexe avec une variété de mises en page complexes. Voir plus ici\nshinydashboardPlus - Obtenez encore plus de fonctionnalités du framework shinydashboard ! En savoir plus ici\nshinythemes - changez le thème css par défaut de votre application shiny avec une large gamme de modèles prédéfinis ! En savoir plus ici\n\nIl existe également un certain nombre de packages qui peuvent être utilisés pour créer des sorties interactives compatibles avec shiny.\n\nDT est semi-incorporé dans base-shiny, mais fournit un grand ensemble de fonctions pour créer des tableaux interactifs.\nplotly est un package pour créer des graphiques interactifs que l’utilisateur peut manipuler dans l’application. Vous pouvez également convertir vos graphiques en versions interactives via plotly::ggplotly() ! Comme alternatives, dygraphs et highcharter sont également excellents.",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.fr.html#ressources-recommandées",
    "href": "new_pages/shiny_basics.fr.html#ressources-recommandées",
    "title": "43  Tableaux de bord avec Shiny",
    "section": "43.10 Ressources recommandées",
    "text": "43.10 Ressources recommandées",
    "crumbs": [
      "Rapports et tableaux de bord",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Tableaux de bord avec Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html",
    "href": "new_pages/writing_functions.fr.html",
    "title": "44  Fonctions d’écriture",
    "section": "",
    "text": "44.1 Préparation",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#préparation",
    "href": "new_pages/writing_functions.fr.html#préparation",
    "title": "44  Fonctions d’écriture",
    "section": "",
    "text": "Load packages\nCe morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les paquets installés avec library() de base R. Voir la page sur [R basics] pour plus d’informations sur les paquets R.\n\n\nImporter des données\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour les suivre pas à pas, consultez les instructions de la page Télécharger le manuel et les données. Le jeu de données est importé à l’aide de la fonction import() du paquet rio. Voir la page Importer et exporter des données pour les différentes manières d’importer des données.\nNous utiliserons également dans la dernière partie de cette page des données sur la grippe H7N9 de 2013.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#fonctions",
    "href": "new_pages/writing_functions.fr.html#fonctions",
    "title": "44  Fonctions d’écriture",
    "section": "44.2 Fonctions",
    "text": "44.2 Fonctions\nLes fonctions sont utiles en programmation car elles permettent de rendre les codes plus faciles à comprendre, plus courts et moins sujets aux erreurs (à condition qu’il n’y ait pas d’erreurs dans la fonction elle-même).\nSi vous êtes arrivé jusqu’à ce manuel, cela signifie que vous avez rencontré d’innombrables fonctions, car en R, chaque opération est un appel de fonction. +, for, if, [, $, { â¦. Par exemple, x + y est la même chose que '+'(x, y).\nR est l’un des langages qui offre le plus de possibilités de travailler avec des fonctions et qui donne suffisamment d’outils à l’utilisateur pour les écrire facilement. Nous ne devrions pas penser aux fonctions comme étant fixées au sommet ou à la fin de la chaîne de programmation, R offre la possibilité de les utiliser comme s’il s’agissait de vecteurs et même de les utiliser à l’intérieur d’autres fonctions, listes…\nIl existe de nombreuses ressources très avancées sur la programmation fonctionnelle et nous ne donnerons ici qu’un aperçu pour vous aider à démarrer avec la programmation fonctionnelle avec de courts exemples pratiques. Nous vous encourageons ensuite à visiter les liens sur les références pour en savoir plus.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#pourquoi-utiliser-une-fonction",
    "href": "new_pages/writing_functions.fr.html#pourquoi-utiliser-une-fonction",
    "title": "44  Fonctions d’écriture",
    "section": "44.3 Pourquoi utiliser une fonction ?",
    "text": "44.3 Pourquoi utiliser une fonction ?\nAvant de répondre à cette question, il est important de noter que vous avez déjà eu des conseils pour écrire vos toutes premières fonctions R dans la page sur [l’itération, les boucles et les listes] de ce manuel. En fait, l’utilisation de “if/else” et de boucles est souvent au cour de bon nombre de nos fonctions car elles permettent d’élargir l’application de notre code en autorisant des conditions multiples ou d’itérer des codes pour des tâches répétitives.\n\nJe répète plusieurs fois le même bloc de code pour l’appliquer à une variable ou à des données différentes ?\nSi je m’en débarrasse, cela raccourcira-t-il considérablement mon code global et le rendra-t-il plus rapide ?\nEst-il possible que le code que j’ai écrit soit réutilisé mais avec une valeur différente à plusieurs endroits du code ?\n\nSi la réponse à l’une des questions précédentes est “OUI”, alors vous avez probablement besoin d’écrire une fonction",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#comment-r-construit-il-les-fonctions",
    "href": "new_pages/writing_functions.fr.html#comment-r-construit-il-les-fonctions",
    "title": "44  Fonctions d’écriture",
    "section": "44.4 Comment R construit-il les fonctions ?",
    "text": "44.4 Comment R construit-il les fonctions ?\nLes fonctions dans R ont trois composants principaux :\n\nle formals() qui est la liste d’arguments qui contrôle la façon dont nous pouvons appeler la fonction.\nle body() qui est le code à l’intérieur de la fonction, c’est-à-dire entre les parenthèses ou à la suite des parenthèses, selon la façon dont on l’écrit.\n\net,\n\nl’ environnement() qui aide à localiser les variables de la fonction et détermine comment la fonction trouve sa valeur.\n\nUne fois que vous avez créé votre fonction, vous pouvez vérifier chacun de ces composants en appelant la fonction associée.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#syntaxe-et-structure-de-base",
    "href": "new_pages/writing_functions.fr.html#syntaxe-et-structure-de-base",
    "title": "44  Fonctions d’écriture",
    "section": "44.5 Syntaxe et structure de base",
    "text": "44.5 Syntaxe et structure de base\n\nUne fonction devra être nommée correctement afin que son travail soit facilement compréhensible dès que l’on lit son nom. En fait, c’est déjà le cas avec la majorité de l’architecture R de base. Des fonctions comme mean(), print(), summary() ont des noms qui sont très simples.\nUne fonction a besoin d’arguments, comme les données sur lesquelles elle travaille et d’autres objets qui peuvent être des valeurs statiques, entre autres options.\nEt enfin, une fonction donnera une sortie basée sur sa tâche principale et les arguments qui lui ont été donnés. Habituellement, nous utilisons les fonctions intégrées telles que print(), return()… pour produire la sortie. La sortie peut être une valeur logique, un nombre, un caractère, un cadre de données… en bref, tout type d’objet R.\n\nEn gros, c’est la composition d’une fonction :\n\nnom_fonction &lt;- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\n\nNous pouvons créer notre première fonction qui sera appelée `contain_covid19()``.\n\ncontain_covid19 &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\nNous pouvons ensuite vérifier les composants de notre fonction nouvellement créée.\n\nformals(contain_covid19)\n\n$barrier_gest\n\n\n$wear_mask\n\n\n$get_vaccine\n\nbody(contain_covid19)\n\n{\n    if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n        \"yes\") \n        return(\"success\")\n    else (\"please make sure all are yes, this pandemic has to end!\")\n}\n\nenvironment(contain_covid19)\n\n&lt;environment: R_GlobalEnv&gt;\n\n\nMaintenant, nous allons tester notre fonction. Pour appeler notre fonction écrite, vous l’utilisez comme vous utilisez toutes les fonctions R, c’est-à-dire en écrivant le nom de la fonction et en ajoutant les arguments requis.\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")\n\n[1] \"success\"\n\n\nPar précaution, nous pouvons réécrire le nom de chaque argument. Mais sans les préciser, le code devrait fonctionner puisque R a en mémoire le positionnement de chaque argument. Ainsi, tant que vous mettez les valeurs des arguments dans le bon ordre, vous pouvez éviter d’écrire les noms des arguments lors de l’appel des fonctions.\n\ncontain_covid19(\"yes\", \"yes\", \"yes\")\n\n[1] \"success\"\n\n\nVoyons ensuite ce qui se passe si l’une des valeurs est \"no\" ou pas \"yes\".\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\n[1] \"please make sure all are yes, this pandemic has to end!\"\n\n\nSi nous fournissons un argument qui n’est pas reconnu, nous obtenons une erreur:\n\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\n`Erreur dans contain_covid19(barrier_gest = “sometimes”, wear_mask = “yes”, : Impossible de trouver la fonction “contain_covid19”``.\nNOTE: Certaines fonctions (la plupart du temps très courtes et simples) peuvent ne pas avoir besoin de nom et peuvent être utilisées directement sur une ligne de code ou à l’intérieur d’une autre fonction pour effectuer une tâche rapide. Elles sont appelées fonctions anonymes .\nPar exemple ci-dessous est une première fonction anonyme qui ne garde que les variables de caractères le jeu de données.\n\nlinelist %&gt;% \n  dplyr::slice_head(n=10) %&gt;% #équivalent à la fonction \"head\" de base de R et qui renvoie les n premières observations de l'ensemble de données.\n  select(function(x) is.character(x)) \n\n\n\n\n\n\n\nEnsuite, une autre fonction qui sélectionne une observation sur deux de notre ensemble de données (cela peut être utile lorsque nous avons des données longitudinales avec de nombreux enregistrements par patient, par exemple après avoir été classés par date ou par visite). Dans ce cas, la fonction à écrire en dehors de dplyr serait function (x) (x%%2 == 0) pour s’appliquer au vecteur contenant tous les numéros de ligne.\n\nlinelist %&gt;%   \n   slice_head(n=20) %&gt;% \n   tibble::rownames_to_column() %&gt;% # ajoute les indices de chaque obs comme rownames pour voir clairement la sélection finale\n   filter(row_number() %%2 == 0)\n\n\n\n\n\n\n\nUn code R de base possible pour la même tâche serait le suivant :\n\nlinelist_firstobs &lt;- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]\n\n\n\n\n\n\n\nCAUTION: S’il est vrai que l’utilisation de fonctions peut nous aider dans notre code, il peut néanmoins être long d’écrire certaines fonctions ou d’en corriger une si elle n’a pas été pensée en profondeur, écrite de manière adéquate et qu’elle renvoie des erreurs en conséquence. C’est pour cette raison qu’il est souvent recommandé d’écrire d’abord le code R, de s’assurer qu’il fait ce que nous voulons qu’il fasse, puis de le transformer en une fonction avec ses trois composants principaux tels que listés ci-dessus.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#exemples",
    "href": "new_pages/writing_functions.fr.html#exemples",
    "title": "44  Fonctions d’écriture",
    "section": "44.6 Exemples",
    "text": "44.6 Exemples\n\nRetourner les tableaux de proportion pour plusieurs colonnes\nOui, nous avons déjà de belles fonctions dans de nombreux paquets permettant de résumer des informations d’une manière très simple et agréable. Mais nous allons tout de même essayer de créer nos propres fonctions, lors de nos premiers pas dans l’écriture de fonctions.\nDans cet exemple, nous voulons montrer comment l’écriture d’une simple fonction vous évitera de copier-coller le même code plusieurs fois.\n\nproptab_multiple &lt;- function(my_data, var_to_tab){\n  \n  #imprimez le nom de chaque variable d'intérêt avant de faire la tabulation\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #liez les résultats des deux fonctions suivantes par ligne\n        #tabuler la variable d'intérêt: ne donne que des nombres\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calculer les proportions pour chaque variable d'intérêt et arrondir la valeur à 2 décimales\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")\n\n[1] \"gender\"\n\n\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n\nproptab_multiple(linelist, \"age_cat\")\n\n[1] \"age_cat\"\n\n\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n\nproptab_multiple(linelist, \"outcome\")\n\n[1] \"outcome\"\n\n\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nTIP: Comme indiqué ci-dessus, il est très important de commenter vos fonctions comme vous le feriez pour la programmation générale. Gardez à l’esprit que le but d’une fonction est de rendre un code facile à lire, plus court et plus efficace. Alors on devrait être capable de comprendre ce que fait la fonction juste en lisant son nom et avoir plus de détails en lisant les commentaires.\nUne deuxième option est d’utiliser cette fonction dans une autre via une boucle pour faire le processus en une fois :\n\nfor(var_to_tab in c(\"gender\", \"age_cat\", \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}\n\n[1] \"gender\"\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n[1] \"age_cat\"\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n[1] \"outcome\"\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nUne manière plus simple serait d’utiliser la base R “appliquer” au lieu d’une “boucle for” comme exprimé ci-dessous :\nTIP: R est souvent défini comme un langage de programmation fonctionnel et presque chaque fois que vous exécutez une ligne de code, vous utilisez certaines fonctions intégrées. Une bonne habitude pour être plus à l’aise avec l’écriture de fonctions est d’avoir souvent un regard interne sur la façon dont les fonctions de base que vous utilisez quotidiennement sont construites. Le raccourci pour le faire est de sélectionner le nom de la fonction puis de cliquer sur Ctrl+F2 ou fn+F2 ou Cmd+F2 (selon votre ordinateur) .\n\n\n44.6.1 Utilisation de purrr : écrire des fonctions qui peuvent être appliquées de manière itérative.\n\n\nModifier la classe de plusieurs colonnes dans un ensemble de données\nDisons que de nombreuses variables de caractère dans les données originales linelist doivent être changées en “factor” pour des raisons d’analyse et de traçage. Au lieu de répéter l’étape plusieurs fois, nous pouvons juste utiliser lapply() pour faire la transformation de toutes les variables concernées sur une seule ligne de code.\nCAUTION: lapply() renvoie une liste, donc son utilisation peut nécessiter une modification supplémentaire en dernière étape.\nLa même étape peut être effectuée en utilisant la fonction map_if() du paquet purrr.\n\nlinelist_factor2 &lt;- linelist %&gt;%\n  purrr::map_if(is.character, as.factor)\n\nlinelist_factor2 %&gt;%\n        glimpse()\n\nList of 30\n $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA ...\n $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" ...\n $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" ...\n $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" ...\n $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ...\n\n\n\n\nProduire itérativement des graphiques pour différents niveaux d’une variable\nNous allons produire ici un graphique circulaire pour examiner la distribution des résultats des patients en Chine pendant l’épidémie de H7N9 pour chaque province. Au lieu de répéter le code pour chacun d’entre eux, nous allons simplement appliquer une fonction que nous allons créer.\n\n#Préciser les options pour l'utilisation de highchart\noptions(highcharter.theme =  highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#créer une fonction appelée \"chart_outcome_province\" qui prend comme argument l'ensemble de données et le nom de la province pour laquelle on veut tracer la distribution du résultat.\n\nchart_outcome_province &lt;- function(data_used, prov){\n  \n  tab_prov &lt;- data_used %&gt;% \n    filter(province == prov,\n           !is.na(outcome))%&gt;% \n    group_by(outcome) %&gt;% \n    count() %&gt;%\n    adorn_totals(where = \"row\") %&gt;% \n    adorn_percentages(denominator = \"col\", )%&gt;%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %&gt;%\n    filter(outcome != \"Total\") %&gt;% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distribution du résultat en :\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\n\n\n\n\nchart_outcome_province(flu_china, \"Zhejiang\")\n\n\n\n\nchart_outcome_province(flu_china, \"Jiangsu\")\n\n\n\n\n\n\n\nProduire itérativement des tableaux pour différents niveaux d’une variable\nIci, nous allons créer trois indicateurs à résumer dans un tableau et nous voudrions produire ce tableau pour chacune des provinces. Nos indicateurs sont le délai entre l’apparition et l’hospitalisation, le pourcentage de guérison et l’âge médian des cas.\n\nindic_1 &lt;- flu_china %&gt;% \n  group_by(province) %&gt;% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %&gt;%\n  select(province, mean_delay_onset_hosp) %&gt;% \n  distinct()\n     \n\nindic_2 &lt;- flu_china %&gt;% \n            filter(!is.na(outcome)) %&gt;% \n            group_by(province, outcome) %&gt;% \n            count() %&gt;%\n            pivot_wider(names_from = outcome, values_from = n) %&gt;% \n    adorn_totals(where = \"col\") %&gt;% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%&gt;% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 &lt;- flu_china %&gt;% \n            group_by(province) %&gt;% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %&gt;% \n  select(province, median_age_cases) %&gt;% \n  distinct()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `median_age_cases = median(as.numeric(age), na.rm = TRUE)`.\nℹ In group 11: `province = \"Shanghai\"`.\nCaused by warning in `median()`:\n! NAs introduced by coercion\n\n#Joindre les trois ensembles de données d'indicateurs\n\ntable_indic_all &lt;- indic_1 %&gt;% \n  dplyr::left_join(indic_2, by = \"province\") %&gt;% \n        left_join(indic_3, by = \"province\")\n\n\n#Imprimez les indicateurs dans un tableau mobile\n\n\nprint_indic_prov &lt;- function(table_used, prov){\n  \n  #d'abord transformer un peu le dataframe pour faciliter l'impression.\n  indic_prov &lt;- table_used %&gt;%\n    filter(province==prov) %&gt;%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %&gt;% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\", \"perc_recovery\", \"median_age_cases\"),\n   labels=c(\"Délai moyen d'apparition hôpital\", \"Pourcentage de récupération\", \"Âge médian des cas\"))\n   ) %&gt;% \n    ungroup(province) %&gt;% \n    select(indic_label, value)\n  \n\n    tab_print &lt;- flextable(indic_prov) %&gt;%\n    theme_vanilla() %&gt;% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print &lt;- tab_print %&gt;% \n                  autofit() %&gt;%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %&gt;%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %&gt;%\n    flextable::bold(part = \"header\") %&gt;%\n    flextable::color(color = \"white\", part = \"header\") %&gt;% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de : \", prov)) %&gt;% \nbold(part = \"header\")\n \n tab_print &lt;- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\n\nIndicateurs pour la province de : ShanghaiIndicateursEstimationDélai moyen d'apparition hôpital4.0Pourcentage de récupération46.7Âge médian des cas67.0\n\nprint_indic_prov(table_indic_all, \"Jiangsu\")\n\nIndicateurs pour la province de : JiangsuIndicateursEstimationDélai moyen d'apparition hôpital6.0Pourcentage de récupération71.4Âge médian des cas55.0",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#conseils-et-meilleures-pratiques-pour-des-fonctions-bien-rodées",
    "href": "new_pages/writing_functions.fr.html#conseils-et-meilleures-pratiques-pour-des-fonctions-bien-rodées",
    "title": "44  Fonctions d’écriture",
    "section": "44.7 Conseils et meilleures pratiques pour des fonctions bien rodées",
    "text": "44.7 Conseils et meilleures pratiques pour des fonctions bien rodées\nLa programmation fonctionnelle a pour but d’alléger le code et d’en faciliter la lecture. Elle devrait produire le contraire. Les conseils ci-dessous vous aideront à avoir un code propre et facile à lire.\n\nNommage et syntaxe\n\nEvitez d’utiliser des caractères qui auraient pu être facilement pris par d’autres fonctions déjà existantes dans votre environnement.\nIl est recommandé que le nom de la fonction soit court et facile à comprendre pour un autre lecteur.\nIl est préférable d’utiliser des verbes pour le nom de la fonction et des noms pour les noms des arguments.\n\n\n\nNoms de colonnes et évaluation ordonnée\nSi vous voulez savoir comment référencer les noms de colonnes qui sont fournis à votre code en tant qu’arguments, lisez ce guide de programmation tidyverse. Parmi les sujets abordés figurent l’évaluation tidée et l’utilisation de l’accolade double { }.\nPar exemple, voici un squelette de code rapide tiré du tutoriel de la page mentionnée juste au-dessus :\n\nvar_summary &lt;- function(data, var) {\n  data %&gt;%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }})))\n}\nmtcars %&gt;% \n  group_by(cyl) %&gt;% \n  var_summary(mpg)\n\n\n\nTest et gestion des erreurs\nPlus la tâche d’une fonction est compliquée, plus la possibilité d’erreurs est élevée. Il est donc parfois nécessaire d’ajouter une vérification dans la fonction pour aider à comprendre rapidement d’où vient l’erreur et trouver un moyen de la corriger.\n\nIl peut être plus que recommandé d’introduire une vérification de l’absence d’un argument en utilisant missing(argument). Cette simple vérification peut retourner la valeur “VRAI” ou “FAUX”.\n\n\ncontain_covid19_missing &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask == \"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")\n\n[1] \"please provide arg1\"\n[1] \"please provide arg2\"\n\n\nError in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\n\n\n\nUtilisez stop() pour les erreurs plus faciles à détecter.\n\n\ncontain_covid19_stop &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes`\"))\n  \n  if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")\n\nError in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes`\n\n\n\nComme nous le voyons lorsque nous exécutons la plupart des fonctions intégrées, des messages et des avertissements peuvent apparaître dans certaines conditions. Nous pouvons les intégrer dans nos fonctions écrites en utilisant les fonctions message() et warning().\nNous pouvons également gérer les erreurs en utilisant la fonction safely() qui prend une fonction en argument et l’exécute de manière sûre. En fait, la fonction s’exécutera sans s’arrêter si elle rencontre une erreur. safely() retourne en sortie une liste avec deux objets qui sont les résultats et l’erreur qu’elle a “sautée”.\n\nNous pouvons vérifier en exécutant d’abord la fonction mean(), puis en l’exécutant avec safely().\n\nmap(linelist, mean)\n\n$case_id\n[1] NA\n\n$generation\n[1] 16.56165\n\n$date_infection\n[1] NA\n\n$date_onset\n[1] NA\n\n$date_hospitalisation\n[1] \"2014-11-03\"\n\n$date_outcome\n[1] NA\n\n$outcome\n[1] NA\n\n$gender\n[1] NA\n\n$age\n[1] NA\n\n$age_unit\n[1] NA\n\n$age_years\n[1] NA\n\n$age_cat\n[1] NA\n\n$age_cat5\n[1] NA\n\n$hospital\n[1] NA\n\n$lon\n[1] -13.23381\n\n$lat\n[1] 8.469638\n\n$infector\n[1] NA\n\n$source\n[1] NA\n\n$wt_kg\n[1] 52.64487\n\n$ht_cm\n[1] 124.9633\n\n$ct_blood\n[1] 21.20686\n\n$fever\n[1] NA\n\n$chills\n[1] NA\n\n$cough\n[1] NA\n\n$aches\n[1] NA\n\n$vomit\n[1] NA\n\n$temp\n[1] NA\n\n$time_admission\n[1] NA\n\n$bmi\n[1] 46.89023\n\n$days_onset_hosp\n[1] NA\n\n\n\nsafe_mean &lt;- safely(mean)\nlinelist %&gt;% \n  map(safe_mean)\n\n$case_id\n$case_id$result\n[1] NA\n\n$case_id$error\nNULL\n\n\n$generation\n$generation$result\n[1] 16.56165\n\n$generation$error\nNULL\n\n\n$date_infection\n$date_infection$result\n[1] NA\n\n$date_infection$error\nNULL\n\n\n$date_onset\n$date_onset$result\n[1] NA\n\n$date_onset$error\nNULL\n\n\n$date_hospitalisation\n$date_hospitalisation$result\n[1] \"2014-11-03\"\n\n$date_hospitalisation$error\nNULL\n\n\n$date_outcome\n$date_outcome$result\n[1] NA\n\n$date_outcome$error\nNULL\n\n\n$outcome\n$outcome$result\n[1] NA\n\n$outcome$error\nNULL\n\n\n$gender\n$gender$result\n[1] NA\n\n$gender$error\nNULL\n\n\n$age\n$age$result\n[1] NA\n\n$age$error\nNULL\n\n\n$age_unit\n$age_unit$result\n[1] NA\n\n$age_unit$error\nNULL\n\n\n$age_years\n$age_years$result\n[1] NA\n\n$age_years$error\nNULL\n\n\n$age_cat\n$age_cat$result\n[1] NA\n\n$age_cat$error\nNULL\n\n\n$age_cat5\n$age_cat5$result\n[1] NA\n\n$age_cat5$error\nNULL\n\n\n$hospital\n$hospital$result\n[1] NA\n\n$hospital$error\nNULL\n\n\n$lon\n$lon$result\n[1] -13.23381\n\n$lon$error\nNULL\n\n\n$lat\n$lat$result\n[1] 8.469638\n\n$lat$error\nNULL\n\n\n$infector\n$infector$result\n[1] NA\n\n$infector$error\nNULL\n\n\n$source\n$source$result\n[1] NA\n\n$source$error\nNULL\n\n\n$wt_kg\n$wt_kg$result\n[1] 52.64487\n\n$wt_kg$error\nNULL\n\n\n$ht_cm\n$ht_cm$result\n[1] 124.9633\n\n$ht_cm$error\nNULL\n\n\n$ct_blood\n$ct_blood$result\n[1] 21.20686\n\n$ct_blood$error\nNULL\n\n\n$fever\n$fever$result\n[1] NA\n\n$fever$error\nNULL\n\n\n$chills\n$chills$result\n[1] NA\n\n$chills$error\nNULL\n\n\n$cough\n$cough$result\n[1] NA\n\n$cough$error\nNULL\n\n\n$aches\n$aches$result\n[1] NA\n\n$aches$error\nNULL\n\n\n$vomit\n$vomit$result\n[1] NA\n\n$vomit$error\nNULL\n\n\n$temp\n$temp$result\n[1] NA\n\n$temp$error\nNULL\n\n\n$time_admission\n$time_admission$result\n[1] NA\n\n$time_admission$error\nNULL\n\n\n$bmi\n$bmi$result\n[1] 46.89023\n\n$bmi$error\nNULL\n\n\n$days_onset_hosp\n$days_onset_hosp$result\n[1] NA\n\n$days_onset_hosp$error\nNULL\n\n\nComme dit précédemment, bien commenter nos codes est déjà un bon moyen d’avoir de la documentation dans notre travail.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.fr.html#ressources",
    "href": "new_pages/writing_functions.fr.html#ressources",
    "title": "44  Fonctions d’écriture",
    "section": "44.8 Ressources",
    "text": "44.8 Ressources\nLien vers R pour la science des données\nCheatsheet advance R programming\nCheatsheet purr Package\nVideo-ACM talk by Hadley Wickham : Les joies de la programmation fonctionnelle (comment fonctionne map_dbl)",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Fonctions d'écriture</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html",
    "href": "new_pages/directories.fr.html",
    "title": "45  Interactions avec les répertoires",
    "section": "",
    "text": "45.1 Préparation",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#préparation",
    "href": "new_pages/directories.fr.html#préparation",
    "title": "45  Interactions avec les répertoires",
    "section": "",
    "text": "Paquet fs\nLe paquet fs est un paquet tidyverse qui facilite les interactions avec les répertoires, en améliorant certaines des fonctions base de R. Dans les sections ci-dessous, nous utiliserons souvent des fonctions de fs.\n\npacman::p_load(\n  fs, # interactions fichiers/répertoires\n  rio, # importation/exportation\n  here, # chemins d'accès relatifs aux fichiers\n  tidyverse) # gestion et visualisation des données\n\n\n\nImprimer le répertoire comme un arbre de dendrogramme\nUtilisez la fonction dir_tree() de fs.\nFournissez le chemin d’accès au dossier dans path = et décidez si vous voulez afficher un seul niveau (recurse = FALSE) ou tous les fichiers de tous les sous-niveaux (recurse = TRUE). Ci-dessous, nous utilisons here() comme raccourci pour le projet R et spécifions son sous-dossier “data”, qui contient toutes les données utilisées pour ce manuel R. Nous le paramétrons pour afficher tous les fichiers contenus dans “data” et ses sous-dossiers (par exemple “cache”, “modèles épidémiques”, “population”, “shp” et “weather”).\n\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file62445b725d52/data\n├── africa_countries.geo.json\n├── cache\n│   └── epidemic_models\n│       ├── 2015-04-30\n│       │   ├── estimated_reported_cases_samples.rds\n│       │   ├── estimate_samples.rds\n│       │   ├── latest_date.rds\n│       │   ├── reported_cases.rds\n│       │   ├── summarised_estimated_reported_cases.rds\n│       │   ├── summarised_estimates.rds\n│       │   └── summary.rds\n│       ├── epinow_res.rds\n│       ├── epinow_res_small.rds\n│       ├── generation_time.rds\n│       └── incubation_period.rds\n├── case_linelists\n│   ├── cleaning_dict.csv\n│   ├── fluH7N9_China_2013.csv\n│   ├── linelist_cleaned.rds\n│   ├── linelist_cleaned.xlsx\n│   └── linelist_raw.xlsx\n├── country_demographics.csv\n├── covid_example_data\n│   ├── covid_example_data.xlsx\n│   └── covid_shapefile\n│       ├── FultonCountyZipCodes.cpg\n│       ├── FultonCountyZipCodes.dbf\n│       ├── FultonCountyZipCodes.prj\n│       ├── FultonCountyZipCodes.sbn\n│       ├── FultonCountyZipCodes.sbx\n│       ├── FultonCountyZipCodes.shp\n│       ├── FultonCountyZipCodes.shp.xml\n│       └── FultonCountyZipCodes.shx\n├── covid_incidence.csv\n├── covid_incidence_map.R\n├── district_count_data.xlsx\n├── example\n│   ├── Central Hospital.csv\n│   ├── district_weekly_count_data.xlsx\n│   ├── fluH7N9_China_2013.csv\n│   ├── hospital_linelists.xlsx\n│   ├── linelists\n│   │   ├── 20201007linelist.csv\n│   │   ├── case_linelist20201006.csv\n│   │   ├── case_linelist_2020-10-02.csv\n│   │   ├── case_linelist_2020-10-03.csv\n│   │   ├── case_linelist_2020-10-04.csv\n│   │   ├── case_linelist_2020-10-05.csv\n│   │   └── case_linelist_2020-10-08.xlsx\n│   ├── Military Hospital.csv\n│   ├── Missing.csv\n│   ├── Other.csv\n│   ├── Port Hospital.csv\n│   └── St. Mark's Maternity Hospital (SMMH).csv\n├── facility_count_data.rds\n├── flexdashboard\n│   ├── outbreak_dashboard.html\n│   ├── outbreak_dashboard.Rmd\n│   ├── outbreak_dashboard_shiny.Rmd\n│   ├── outbreak_dashboard_test.html\n│   └── outbreak_dashboard_test.Rmd\n├── fluH7N9_China_2013.csv\n├── gis\n│   ├── africa_countries.geo.json\n│   ├── covid_incidence.csv\n│   ├── covid_incidence_map.R\n│   ├── linelist_cleaned_with_adm3.rds\n│   ├── population\n│   │   ├── sle_admpop_adm3_2020.csv\n│   │   └── sle_population_statistics_sierraleone_2020.xlsx\n│   └── shp\n│       ├── README.txt\n│       ├── sle_adm3.CPG\n│       ├── sle_adm3.dbf\n│       ├── sle_adm3.prj\n│       ├── sle_adm3.sbn\n│       ├── sle_adm3.sbx\n│       ├── sle_adm3.shp\n│       ├── sle_adm3.shp.xml\n│       ├── sle_adm3.shx\n│       ├── sle_hf.CPG\n│       ├── sle_hf.dbf\n│       ├── sle_hf.prj\n│       ├── sle_hf.sbn\n│       ├── sle_hf.sbx\n│       ├── sle_hf.shp\n│       └── sle_hf.shx\n├── godata\n│   ├── cases_clean.rds\n│   ├── contacts_clean.rds\n│   ├── followups_clean.rds\n│   └── relationships_clean.rds\n├── likert_data.csv\n├── linelist_cleaned.rds\n├── linelist_cleaned.xlsx\n├── linelist_raw.xlsx\n├── make_evd_dataset-DESKTOP-JIEUMMI.R\n├── make_evd_dataset.R\n├── malaria_app\n│   ├── app.R\n│   ├── data\n│   │   └── facility_count_data.rds\n│   ├── funcs\n│   │   └── plot_epicurve.R\n│   ├── global.R\n│   ├── malaria_app.Rproj\n│   ├── server.R\n│   └── ui.R\n├── malaria_facility_count_data.rds\n├── phylo\n│   ├── sample_data_Shigella_tree.csv\n│   ├── Shigella_subtree_2.nwk\n│   ├── Shigella_subtree_2.txt\n│   └── Shigella_tree.txt\n├── rmarkdown\n│   ├── outbreak_report.docx\n│   ├── outbreak_report.html\n│   ├── outbreak_report.pdf\n│   ├── outbreak_report.pptx\n│   ├── outbreak_report.Rmd\n│   ├── report_tabbed_example.html\n│   └── report_tabbed_example.Rmd\n├── standardization\n│   ├── country_demographics.csv\n│   ├── country_demographics_2.csv\n│   ├── deaths_countryA.csv\n│   ├── deaths_countryB.csv\n│   └── world_standard_population_by_sex.csv\n├── surveys\n│   ├── population.xlsx\n│   ├── survey_data.xlsx\n│   └── survey_dict.xlsx\n└── time_series\n    ├── campylobacter_germany.xlsx\n    └── weather\n        ├── germany_weather2002.nc\n        ├── germany_weather2003.nc\n        ├── germany_weather2004.nc\n        ├── germany_weather2005.nc\n        ├── germany_weather2006.nc\n        ├── germany_weather2007.nc\n        ├── germany_weather2008.nc\n        ├── germany_weather2009.nc\n        ├── germany_weather2010.nc\n        └── germany_weather2011.nc",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#lister-les-fichiers-dun-répertoire",
    "href": "new_pages/directories.fr.html#lister-les-fichiers-dun-répertoire",
    "title": "45  Interactions avec les répertoires",
    "section": "45.2 Lister les fichiers d’un répertoire",
    "text": "45.2 Lister les fichiers d’un répertoire\nPour lister uniquement les noms de fichiers d’un répertoire, vous pouvez utiliser dir() à partir de base R. Par exemple, cette commande liste les noms des fichiers contenus dans le sous-dossier “population” du dossier “data” d’un projet R. Le chemin de fichier relatif est fourni en utilisant here(). (dont vous trouverez plus d’informations sur la page Importer et exporter des données ).\n\n# noms de fichiers\ndir(here(\"data\", \"gis\", \"population\"))\n\n[1] \"sle_admpop_adm3_2020.csv\"                       \n[2] \"sle_population_statistics_sierraleone_2020.xlsx\"\n\n\nPour lister les chemins complets des fichiers du répertoire, vous pouvez utiliser dir_ls() de fs. Une alternative R base est list.files().\n\n# chemins d'accès aux fichiers\ndir_ls(here(\"data\", \"gis\", \"population\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file62445b725d52/data/gis/population/sle_admpop_adm3_2020.csv\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file62445b725d52/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n\n\nPour obtenir toutes les informations sur les métadonnées de chaque fichier d’un répertoire (par exemple le chemin, la date de modification, etc.), vous pouvez utiliser dir_info() de fs.\nCela peut être particulièrement utile si vous voulez extraire la date de dernière modification du fichier, par exemple si vous voulez importer la version la plus récente d’un fichier. Pour un exemple de ceci, voir la page Importer et exporter des données.\n\n# informations sur le fichier\ndir_info(here(\"data\", \"gis\", \"population\"))\n\nVoici le cadre de données renvoyé. Faites défiler vers la droite pour voir toutes les colonnes.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#informations-sur-les-fichiers",
    "href": "new_pages/directories.fr.html#informations-sur-les-fichiers",
    "title": "45  Interactions avec les répertoires",
    "section": "45.3 Informations sur les fichiers",
    "text": "45.3 Informations sur les fichiers\nPour extraire des informations de métadonnées sur un fichier spécifique, vous pouvez utiliser file_info()de fs (ou file.info()de base R).\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\n\n\n\n\n\n\nIci, nous utilisons le $ pour indexer le résultat et retourner uniquement la valeur modification_time.\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time\n\n[1] \"2024-05-08 11:03:24 CEST\"",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#vérifier-sil-existe",
    "href": "new_pages/directories.fr.html#vérifier-sil-existe",
    "title": "45  Interactions avec les répertoires",
    "section": "45.4 Vérifier s’il existe",
    "text": "45.4 Vérifier s’il existe\n\nObjets R\nVous pouvez utiliser exists() de base R pour vérifier si un objet R existe dans R (fournir le nom de l’objet entre guillemets).\n\nexists(\"linelist\")\n\n[1] FALSE\n\n\nNotez que certains paquets R base utilisent des noms d’objets génériques comme “data” en coulisse, qui apparaîtront comme VRAIS à moins que inherit = FALSE soit spécifié. C’est une des raisons pour ne pas nommer votre jeu de données “data”.\n\nexists(\"data\")\n\n[1] TRUE\n\nexists(\"data\", inherit = FALSE)\n\n[1] FALSE\n\n\nSi vous écrivez une fonction, vous devriez utiliser missing() de base R pour vérifier si un argument est présent ou non, au lieu de exists().\n\n\nRépertoires\nPour vérifier si un répertoire existe, fournissez le chemin du fichier (et son nom) à is_dir() de fs. Faites défiler vers la droite pour voir que TRUE est imprimé.\n\nis_dir(here(\"data\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file62445b725d52/data \n                                                                 TRUE \n\n\nUne alternative est file.exists() de base R.\n\n\nLes fichiers\nPour vérifier si un fichier spécifique existe, utilisez is_file() de fs. Faites défiler vers la droite pour voir que TRUE est imprimé.\n\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/RtmpINQh8o/file62445b725d52/data/case_linelists/linelist_cleaned.rds \n                                                                                                     TRUE \n\n\nUne alternative base R est file.exists().",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#créer",
    "href": "new_pages/directories.fr.html#créer",
    "title": "45  Interactions avec les répertoires",
    "section": "45.5 Créer",
    "text": "45.5 Créer\n\nRépertoires\nPour créer un nouveau répertoire (dossier), vous pouvez utiliser dir_create() de fs. Si le répertoire existe déjà, il ne sera pas écrasé et aucune erreur ne sera retournée.\n\ndir_create(here(\"data\", \"test\"))\n\nUne alternative est dir.create() de base R, qui affichera une erreur si le répertoire existe déjà. En revanche, dir_create() dans ce scénario sera silencieux.\n\n\nFichiers\nVous pouvez créer un fichier (vide) avec file_create() à partir de fs. Si le fichier existe déjà, il ne sera pas écrasé ou modifié.\n\nfile_create(here(\"data\", \"test.rds\"))\n\nUne alternative R base est file.create(). Mais si le fichier existe déjà, cette option le tronquera. Si vous utilisez file_create(), le fichier sera laissé inchangé.\n\n\nCréer si n’existe pas\nEN COURS DE CONSTRUCTION\n\n\n45.5.1 Supprimer\n\n\nObjets R\nUtilisez rm() de base R pour supprimer un objet R.\n\n\n45.5.2 Répertoires\nUtilisez dir_delete() de fs.\n\n\n45.5.3 Fichiers\nVous pouvez supprimer des fichiers avec file_delete() de fs.\n\n\n45.5.4 Exécuter d’autres fichiers\n\n\nsource()\nPour exécuter un script R à partir d’un autre script R, vous pouvez utiliser la commande source() (de base R).\n\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))\n\nCela revient à afficher le script R ci-dessus et à cliquer sur le bouton “Source” en haut à droite du script. Ceci exécutera le script mais le fera silencieusement (pas de sortie sur la console R) sauf si cela est spécifiquement prévu. Voir la page Graphiques interactifs pour des exemples d’utilisation de source() pour interagir avec un utilisateur via la console R en mode question-réponse.\n\n\n\n\n\n\n\n\n\n\n\nrender()\nrender() est une variation de source() le plus souvent utilisée pour les scripts R markdown. Vous fournissez le input = qui est le fichier R markdown, et aussi le output_format = (typiquement soit “html_document”, “pdf_document”, “word_document”, ““).\nVoir la page sur les Production de rapports avec R Markdown pour plus de détails. Consultez également la documentation de render() ici ou en entrant ?render.\n\n\nExécuter des fichiers dans un répertoire\nVous pouvez créer une boucle for et l’utiliser pour source() chaque fichier d’un répertoire, tel qu’identifié avec dir().\n\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) { # pour chaque nom de script dans le dossier \"scripts\" du projet R (avec l'extension .R)\n  source(here(\"scripts\", script))                        # source le fichier avec le nom correspondant qui existe dans le dossier scripts\n}\n\nSi vous ne voulez exécuter que certains scripts, vous pouvez les identifier par leur nom comme ceci :\n\nscripts_to_run &lt;- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}\n\nVoici une comparaison des fonctions R fs et base.\n\n\nImporter des fichiers dans un répertoire\nVoir la page Importer et exporter des données pour importer et exporter des fichiers individuels.\nConsultez également la page Importer et exporter des données pour connaître les méthodes permettant d’importer automatiquement le fichier le plus récent, en fonction d’une date figurant dans le nom du fichier ou en examinant les métadonnées du fichier.\nVoir la page Itération, boucles et listes pour un exemple avec le paquet purrr démontrant :\n\nLa division d’un cadre de données et son enregistrement dans plusieurs fichiers CSV.\n\nDivision d’un cadre de données et enregistrement de chaque partie comme une feuille séparée dans un classeur Excel.\n\nImporter plusieurs fichiers CSV et les combiner en un seul cadre de données.\n\nImporter un classeur Excel avec plusieurs feuilles et les combiner dans un cadre de données.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#base-r",
    "href": "new_pages/directories.fr.html#base-r",
    "title": "45  Interactions avec les répertoires",
    "section": "45.6 base R",
    "text": "45.6 base R\nVoir ci-dessous les fonctions list.files() et dir(), qui effectuent la même opération de listage des fichiers dans un répertoire spécifié. Vous pouvez spécifier ignore.case = ou un motif spécifique à rechercher.\n\nlist.files(path = ici(\"data\"))\n\nlist.files(path = ici(\"data\"), pattern = \".csv\")\n# dir(path = ici(\"data\"), pattern = \".csv\")\n\nlist.files(path = ici(\"data\"), pattern = \"evd\", ignore.case = TRUE)\n\nSi un fichier est actuellement “ouvert”, il s’affiche dans votre dossier avec un tilde devant, comme “~$hospital_linelists.xlsx”.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.fr.html#ressources",
    "href": "new_pages/directories.fr.html#ressources",
    "title": "45  Interactions avec les répertoires",
    "section": "45.7 Ressources",
    "text": "45.7 Ressources\nhttps://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interactions avec les répertoires</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html",
    "href": "new_pages/collaboration.fr.html",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "",
    "text": "46.1 Qu’est-ce que Git ?\nGit est un logiciel de contrôle de version qui permet de suivre les modifications dans un dossier. Il peut être utilisé comme l’option “track change” dans Word, LibreOffice ou Google docs, mais pour tous les types de fichiers. C’est l’une des options les plus puissantes et les plus utilisées pour le contrôle de version.\nPourquoi n’en ai-je jamais entendu parler? Les personnes ayant une formation de développeur développeurs apprennent couramment à utiliser un logiciel de contrôle de version (Git, Mercurial, Subversion ou autres), peu d’entre nous issus de disciplines disciplines quantitatives sont enseignés ces compétences. Par conséquent, la plupart des épidémiologistes n’en Par conséquent, la plupart des épidémiologistes n’en ont jamais entendu parler au cours de leurs études, et doivent l’apprendre à la volée.\nAttendez, j’ai entendu parler de Github, c’est la même chose? Pas exactement, mais vous les utilisez souvent ensemble, et nous vous montrerons comment faire. En bref :\nAinsi, vous pouvez utiliser le client/interface Github Desktop, qui utilise Git en arrière-plan pour gérer vos fichiers, à la fois localement sur votre ordinateur, et à distance sur un serveur Github.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#quest-ce-que-git",
    "href": "new_pages/collaboration.fr.html#quest-ce-que-git",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "",
    "text": "Git est le système de contrôle de version, un logiciel. Vous pouvez l’utiliser localement sur votre ordinateur ou pour synchroniser un dossier avec un hôte site web. Par défaut, on utilise un terminal pour donner à Git en ligne de commande.\nVous pouvez utiliser un client/interface Git pour éviter la ligne de commande et et effectuer les mêmes actions (au moins pour les actions simples et super courantes). courantes).\nSi vous souhaitez stocker votre dossier dans un site web hôte pour collaborer avec d’autres, vous pouvez créer un compte sur Github, Gitlab, Bitbucket ou autres.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#pourquoi-utiliser-le-combo-git-et-github",
    "href": "new_pages/collaboration.fr.html#pourquoi-utiliser-le-combo-git-et-github",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.2 Pourquoi utiliser le combo Git et Github ?",
    "text": "46.2 Pourquoi utiliser le combo Git et Github ?\nL’utilisation de Git facilite :\n\nL’archivage des versions documentées avec des modifications incrémentielles de sorte que vous afin que vous puissiez facilement revenir en arrière à n’importe quel état antérieur.\nAvoir des branches parallèles, c’est-à-dire des versions de développement/“de travail” avec des moyens structurés pour intégrer les changements après révision\n\nCela peut être fait localement sur votre ordinateur, même si vous ne collaborez pas avec d’autres personnes. avec d’autres personnes. Avez-vous déjà :\n\nregretté d’avoir supprimé une section du code, pour réaliser deux mois plus tard que mois plus tard que vous en aviez réellement besoin ?\nrevenir sur un projet qui avait été mis en pause et tenter de se rappeler si vous aviez fait cette modification délicate dans l’un des éléments du projet. de vous rappeler si vous aviez fait cette modification délicate dans l’un des modèles ?\naviez un fichier model_1.R et un autre fichier model_1_test.R et un fichier model_1_not_working.R pour faire des essais ?\navait un fichier report.Rmd, un fichier report_full.Rmd, un fichier report_true_final.Rmd, un fichier report_final_20210304.Rmd, un fichier report_final_20210402.Rmd et maudit vos compétences en archivage ?\n\nGit vous aidera dans tout cela, et vaut la peine d’être appris pour cette seule raison.\nCependant, il devient encore plus puissant lorsqu’il est utilisé avec un référentiel en ligne tel que Github pour soutenir des projets collaboratifs. Cela facilite :\n\nla collaboration : d’autres personnes peuvent examiner, commenter, et accepter/refuser des modifications\nLe partage de votre code, de vos données et de vos résultats, et l’invitation à faire des commentaires du public (ou en privé, avec votre équipe)\n\net évite :\n\n“Oups, j’ai oublié d’envoyer la dernière version et maintenant vous devez refaire deux jours de travail sur ce nouveau fichier”.\nMina, Henry et Oumar ont tous travaillé en même temps sur un script et doivent doivent fusionner manuellement leurs modifications\nDeux personnes tentent de modifier le même fichier sur Dropbox et Sharepoint et cela crée une erreur de synchronisation.\n\n\nCela semble compliqué, je ne suis pas un programmeur\nCela peut l’être. Les exemples d’utilisations avancées peuvent être assez effrayants. Cependant, un peu comme R, ou même Excel, vous n’avez pas besoin de devenir un expert pour profiter des avantages de l’outil. L’apprentissage d’un petit nombre de fonctions et de notions vous permet de suivre vos modifications, de synchroniser vos fichiers sur un référentiel en ligne et de collaborer avec vos collègues en très peu de temps.\nEn raison de la courbe d’apprentissage, le contexte d’urgence n’est peut-être pas le meilleur moment pour apprendre ces outils. Mais l’apprentissage peut se faire par étapes. Une fois que vous aurez acquis quelques notions, votre flux de travail peut être assez efficace et rapide. Si vous ne travaillez pas sur un projet où la collaboration avec des personnes peut-etre Git n’est pas une nécessité, mais c’est en fait un bon moment pour devenir l’utiliser en solo avant de vous lancer dans la collaboration.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#installation",
    "href": "new_pages/collaboration.fr.html#installation",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.3 Installation",
    "text": "46.3 Installation\n\nInstaller Git\nGit est le moteur qui se cache derrière les coulisses de votre ordinateur, qui suit les changements, les branches (versions), les fusions et les retours en arrière. Vous pouvez d’abord installer Git de le lien ici: https://git-scm.com/downloads.\n\n\nInstaller une interface (facultatif mais recommandé)\nGit possède son propre langage de commandes, qui peuvent être tapées dans un terminal de ligne de commande. Cependant, il existe de nombreux clients/interfaces et en tant que non-développeur, dans votre utilisation quotidienne, vous aurez rarement besoin d’interagir directement avec Git. L’interface Git fournit généralement des outils de visualisation agréables pour les modifications de fichiers ou les branches.\nDe nombreuses options existent, sur tous les systèmes d’exploitation, de plus simples aux plus complexes. Parmi les bonnes options pour les débutants, citons le volet Git de RStudio et le Github Desktop, que nous présenterons dans ce chapitre. Les options intermédiaires (plus puissantes, mais plus complexes) comprennent Source Tree, Gitkracken, Smart Git et d’autres programmes.\nTrouvez un explication rapide sur les clients Git.\nRemarque : comme les interfaces utilisent toutes Git en interne, vous pouvez en essayer plusieurs, passer de l’une à l’autre en fonction de vos besoins.\nComme indiqué ci-dessous, vous aurez occasionnellement avoir besoin d’écrire des commandes Git dans un terminal tel que le volet terminal de RStudio (un onglet adjacent à la Console R) ou le terminal Git Bash.\n\n\nCompte Github\nCréez un compte gratuit sur github.com.\nIl se peut que l’on vous propose de configurer une authentification à deux facteurs avec une application sur votre téléphone. Pour en savoir plus, consultez le document Github help documents.\nSi vous utilisez Github Desktop, vous pouvez entrer vos informations d’identification Gitub après l’installation en suivant ces étapes. Si vous ne le faites pas, les informations d’identification vous seront demandées ultérieurement lorsque vous tenterez de cloner un projet à partir de Github.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#vocabulaire-concepts-et-fonctions-de-base",
    "href": "new_pages/collaboration.fr.html#vocabulaire-concepts-et-fonctions-de-base",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.4 Vocabulaire, concepts et fonctions de base",
    "text": "46.4 Vocabulaire, concepts et fonctions de base\nComme lors de l’apprentissage de R, il y a un peu de vocabulaire à retenir pour comprendre Git. Voici les bases pour vous aider à démarrer/ tutoriel interactif. Dans les prochaines sections, nous montrerons comment utiliser les interfaces.\n\nRéférentiel\nUn référentiel Git (“repo”) est un dossier qui contient tous les sous-dossiers et fichiers de votre projet (données, code, images, etc.) et l’historique de leurs révisions. Lorsque vous commencez à suivre les changements dans le dépôt, Git créera un dossier caché qui contient toutes les informations de suivi. Un référentiel Git typique est votre dossier R Project (voir la page du manuel sur les Projets R).\nNous allons montrer comment créer (initialiser) un dépôt Gitub, Github Desktop ou Rstudio dans les sections suivantes.\n\n\nCommits\nUn commit est un snapshot du projet à un moment donné. Lorsque vous apportez un changement au projet, vous faites un nouveau commit pour suivre les modifications (le delta) apportées à vos fichiers. Par exemple, vous avez peut-être édité quelques lignes de code et mis à jour une jeu de données associé. Une fois que vos modifications sont enregistrées, vous pouvez regrouper ces changements en un seul “commit”.\nChaque commit a un ID unique (un hash). À des fins de contrôle de version, vous pouvez revenir en arrière dans votre projet en vous basant sur les commits, pars les garder relativement petits et cohérents. Vous joindrez également une brève description des modifications appelée “message de validation”.\nModifications organisées ? Mettre en scène les changements, c’est les ajouter à la zone de mise en scène en préparation pour le prochain commit. L’idée est que vous pouvez finement décider quels changements inclure dans un commit. Par exemple, si vous avez travaillé sur la spécification d’un modèle dans un un autre script, il serait judicieux d’avoir deux commits différents (ce serait plus facile au cas où vous voudriez annuler les changements sur la figure mais pas sur le modèle).\n\n\nBranches\nUne branche représente une ligne indépendante de changements dans votre repo, une version parallèle et alternative des fichiers de votre projet.\nLes branches sont utiles pour tester les modifications avant qu’elles soient incorporées dans la branche principale, qui est généralement la version principale/finale/“live” de votre projet. Lorsque vous avez fini d’expérimenter sur une branche, vous pouvez apporter les changements dans votre branche principle, en la fusionnant, ou la supprimer, si les changements n’ont pas été couronnés de succès.\nNote : vous n’avez pas besoin de collaborer avec d’autres personnes pour utiliser les branches, ni d’avoir un référentiel en ligne distant.\n\n\nDépôts locaux et distants\nCloner consiste à créer une copie d’un dépôt Git à un autre endroit.\nPar exemple, vous pouvez cloner un dépôt en ligne de Github localement sur votre ordinateur, ou commencer par un dépôt local et le cloner en ligne en ligne sur Github.\nLorsque vous avez cloné un référentiel, les fichiers du projet existent à deux endroits :\n\nle référentiel LOCAL sur votre ordinateur physique. C’est là que vous apportez les modifications réelles aux fichiers/codes.\nle référentiel ROMPU, en ligne : les versions de vos fichiers de projet dans le dépôt Github (ou sur tout autre hébergeur).\n\nPour synchroniser ces dépôts, nous allons utiliser d’autres fonctions. En effet , contrairement à Sharepoint, Dropbox ou autre logiciel de synchronisation, Git ne met pas automatiquement à jour votre dépôt local en fonction de ce qui est en ligne,ou vice-versa. C’est vous qui choisissez quand et comment synchroniser.\n\ngit fetch télécharge les nouvelles modifications depuis le dépôt distant mais ne modifie pas votre dépôt local. Pensez-y comme une vérification de l’état du dépôt distant.\ngit pull télécharge les nouvelles modifications depuis les dépôts distants et met à jour votre dépôt local.\nLorsque vous avez fait un ou plusieurs commits localement, vous pouvez utiliser git push pour faire les commits vers le dépôt distant. Ceci envoie vos modifications sur Github afin que d’autres personnes puissent les voir et les tirer s’ils le souhaitent.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#démarrer-créer-un-nouveau-dépôt",
    "href": "new_pages/collaboration.fr.html#démarrer-créer-un-nouveau-dépôt",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.5 Démarrer : créer un nouveau dépôt",
    "text": "46.5 Démarrer : créer un nouveau dépôt\nIl y a plusieurs façons de créer de nouveaux dépôts. Vous pouvez le faire à partir de la console, de Github, ou d’une interface.\nDeux approches générales sont possibles :\n\nCréer un nouveau projet R à partir d’un dépôt Github existant ou nouveau. (préféré pour les débutants), ou bien\nCréer un dépôt Github pour un projet R existant.\n\n\nFichiers de démarrage\nLorsque vous créez un nouveau référentiel, vous pouvez éventuellement créer tous les fichiers ci-dessous, ou vous pouvez les ajouter à votre référentiel à un stade ultérieur. Ils se trouvent généralement dans le dossier “racine” du référentiel.\n\nUn fichier README est un fichier que quelqu’un peut lire pour comprendre pourquoi votre projet existe et ce qu’il doit savoir pour l’utiliser. Il sera vide au début, mais vous pouvez le compléter plus tard.\nUn fichier .gitignore est un fichier texte dont chaque ligne contient des dossiers ou fichiers que Git devrait ignorer (ne pas suivre les modifications). Lisez plus sur ce sujet et voir des exemples ici.\nVous pouvez choisir une licence pour votre travail, afin que les autres personnes sachent sous quelles conditions elles peuvent utiliser ou reproduire votre travail. Pour de plus amples informations, consultez la page Creative Commons licenses.\n\n\n\nCréer un nouveau référentiel dans Github\nPour créer un nouveau dépôt, connectez-vous à Github et cherchez le bouton vert. Ce dépôt vide peut être cloné localement sur votre ordinateur (voir la section suivante).\n\n\n\n\n\n\n\n\n\nVous devez choisir si vous voulez que votre dépôt soit public (visible par tout le monde sur Internet) ou privé (seulement visible pour ceux qui ont la permission a acceder le dépôt). Cela a des implications importantes si vos données sont sensibles. Si votre référentiel est privé, vous rencontrerez certains quotas dans des circonstances particulières, par exemple si vous utilisez les actions de Github pour exécuter automatiquement votre code dans le nuage.\n\n\nClone à partir d’un dépôt Github\nVous pouvez cloner un référentiel Github existant pour créer un nouveau projet R local sur votre ordinateur.\nLe dépôt Github peut être un dépôt qui existe déjà et contient du contenu, ou un dépôt vide que vous venez de créer. Dans ce dernier cas, vous créez essentiellement le repo Github et le projet local R en même temps (voir les instructions ci-dessus).\nRemarque : si vous n’avez pas de droits de contribution sur un dépôt Github, il est possible de d’abord “forker” (creer une copie) le dépôt vers votre profil, et ensuite de procéder aux autres actions. La bifurcation est expliquée à la fin de ce chapitre, mais nous vous recommandons de lire les autres sections en premier.\nEtape 1 : Naviguez dans Github jusqu’au dépôt, cliquez sur le bouton vert “Code”. et copier l’URL HTTPS clone (voir image ci-dessous)\n\n\n\n\n\n\n\n\n\nL’étape suivante peut être effectuée dans n’importe quelle interface. Nous allons illustrer avec Rstudio et le bureau Github.\n\nDans Rstudio\nDans RStudio, démarrez un nouveau projet R en cliquant sur Fichier &gt; Nouveau projet &gt; Contrôle de version &gt; Git.\n\nLorsque vous êtes invité à saisir l’“URL du dépôt”, collez l’URL HTTPS de Github.\nAttribuez au projet R un nom court et informatif.\nChoisissez l’endroit où le nouveau projet R sera enregistré localement.\nCochez “Ouvrir dans une nouvelle session” et cliquez sur “Créer un projet”.\n\nVous êtes maintenant dans un nouveau projet RStudio local qui est un clone du dépôt Github. Ce projet local et le dépôt Github sont maintenant liés.\n\n\nDans le bureau de Github\n\nCliquez sur Fichier &gt; Cloner un référentiel.\nSélectionnez l’onglet URL\nCollez l’URL HTTPS de Github dans la première case.\nSélectionnez le dossier dans lequel vous voulez avoir votre dépôt local.\nCliquez sur “CLONE”.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNouveau repo Github à partir d’un projet R existant\nUn autre scénario de configuration est que vous avez un projet R existant avec du contenu, et que vous voulez créer un dépôt Github pour celui-ci.\n\nCréez un nouveau dépôt Github vide pour le projet (cf. instructions ci-dessus).\nClonez ce dépôt localement (voir les instructions HTTPS ci-dessus).\nCopiez tout le contenu de votre projet R (codes, données, etc.) dans ce nouveau dépôt local vide (utilisez le copier-coller, par exemple).\nOuvrez votre nouveau projet dans RStudio, et allez dans le volet Git. Les nouveaux fichiers devraient s’enregistrer comme des modifications de fichiers, désormais suivies par Git. Par conséquent, vous pouvez regrouper ces modifications sous forme de commit et les pousser (push) vers Github. Une fois poussé (pushed), le dépôt sur Github reflétera tous les fichiers.\n\nVoir la section sur le flux de travail Github ci-dessous pour plus de détails sur ce processus.\n\n\nA quoi cela ressemble-t-il maintenant ?\n\nDans RStudio\nUne fois que vous avez cloné un dépôt Github vers un nouveau projet R, vous voyez maintenant dans RStudio un onglet “Git”. Cet onglet apparaît dans le même volet de RStudio que votre environnement R :\n\n\n\n\n\n\n\n\n\nVeuillez noter les boutons encerclés dans l’image ci-dessus, puisqu’ils seront référencés plus tard (de gauche à droite) :\n\nBouton pour commettre (commit) les modifications du fichier sauvegardé dans la branche locale (cela ouvrira une nouvelle fenêtre)\nFlèche bleue pour tirer (pull, mettre à jour votre version locale de la branche avec avec les changements effectués sur la version distante/Github de cette branche)\nFlèche verte pour pousser (push, envoyer tous les commits/modifications de votre version version locale de la branche vers la version distante/Github de cette branche)\nL’onglet Git dans RStudio\nBouton pour créer une NOUVELLE branche en utilisant comme base la branche locale affichée. Vous voulez presque toujours créer une branche à partir de la branche principale (après la première extraction).\nLa branche dans laquelle vous travaillez actuellement\nLes modifications que vous avez apportées au code ou à d’autres fichiers apparaissent ci-dessous\n\n\n\ndans Github Desktop\nGithub Desktop est une application indépendante qui vous permet de gérer tous vos dépôts. Lorsque vous l’ouvrez, l’interface vous permet de choisir le dépôt sur lequel vous souhaitez travailler, puis d’effectuer les actions Git à partir de là.\n\n\n\n\n\n\n\n\n\n\n\n\n46.5.1 Flux de travail Git + Github\n\n\nAperçu du processus\nUne fois que vous avez terminé la configuration (décrite ci-dessus), vous aurez un Github qui est connecté (cloné) à un projet R local. La branche principale (créée par défaut) est la version dite “live” de tous les fichiers. Lorsque vous voulez faire des modifications, il est bon de créer une pratique de créer une nouvelle branche à partir de la branche principale (comme “créer une copie”). Il s’agit d’un flux de travail typique de Git, car la création d’une branche est facile et rapide.\nUn flux de travail typique est le suivant :\n\nAssurez-vous que votre dépôt local est à jour, mettez-le à jour si ce n’est pas\nAllez sur la branche sur laquelle vous travailliez précédemment, ou créez une nouvelle branche\nTravaillez sur les fichiers localement sur votre ordinateur, faites un ou plusieurs commits à cette branche\nMettre à jour la version distante de la branche avec vos modifications (push)\nLorsque vous êtes satisfait de votre branche, vous pouvez fusionner la version en ligne de la branche de travail avec la branche “principale” afin de créer une nouvelle branche.\n\nLes autres membres de l’équipe peuvent faire la même chose avec leurs propres branches, ou peut contribuer des commits dans votre branche de travail aussi.\nNous détaillons ci-dessous le processus, étape par étape.\nVoici un schéma que nous avons développé - il se présente sous la forme d’un tableau à double sens, ce qui devrait aider les épidémiologistes à comprendre.\n\n\n\n\n\n\n\n\n\nVoici un autre diagramme.\n*Note : jusqu’à récemment, le terme de branche “master” était utilisé, mais on parle maintenant de branche “principale” (“master”).\n\n\n\n\n\n\n\n\n\nImage source",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#créer-une-nouvelle-branche",
    "href": "new_pages/collaboration.fr.html#créer-une-nouvelle-branche",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.6 Créer une nouvelle branche",
    "text": "46.6 Créer une nouvelle branche\nLorsque vous sélectionnez une branche sur laquelle travailler, Git réinitialise votre répertoire de travail comme il était la dernière fois que vous étiez sur cette branche.\n\nDans le volet Git de Rstudio\nAssurez-vous que vous êtes dans la branche “principale”, puis cliquez sur l’icône violette pour créer une nouvelle branche (voir image ci-dessus).\n\nVous serez invité à nommer votre branche avec un nom descriptif en un mot (vous pouvez utiliser des caractères de soulignement si nécessaire).\nVous verrez que, localement, vous êtes toujours dans le même projet R, mais que vous ne travaillez plus sur la branche “principale”.\nUne fois créée, la nouvelle branche apparaîtra également sur le site Github comme une branche.\n\nVous pouvez visualiser les branches dans le volet Git de Rstudio après avoir cliqué sur “Historique” (“History”).\n\n\n\n\n\n\n\n\n\n\n\nDans le bureau de Github\nLe processus est très similaire, il vous est demandé de donner un nom à votre branche.Ensuite, il vous sera demandé de “Publier votre branche sur Github” pour que la nouvelle branche apparaisse également dans le dépôt distant.\n\n\n\n\n\n\n\n\n\n\n\nDans la console\nCe qui se passe en réalité dans les coulisses est que vous créez une nouvelle branche avec git branch, puis vous allez dans la branche avec git checkout ( i.e. dites à Git que vos prochains commits se feront là). Dans votre dépôt git :\n\ngit branch my-new-branch # Créez la nouvelle branche\ngit checkout my-new-branch # Aller sur la branche\ngit checkout -b ma-nouvelle-branche # Les deux à la fois (raccourci)\n\nPour plus d’informations sur l’utilisation de la console, voir la section sur les Commandes Git à la fin.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#valider-les-changements",
    "href": "new_pages/collaboration.fr.html#valider-les-changements",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.7 Valider les changements",
    "text": "46.7 Valider les changements\nVous pouvez maintenant modifier le code, ajouter de nouveaux fichiers, mettre à jour les ensembles de données, etc.\nChacune de vos modifications est suivie, une fois que le fichier respectif est sauvegardé. Les fichiers modifiés apparaîtront dans l’onglet Git de RStudio, dans Github Desktop, ou en utilisant la commande git status dans le terminal (voir ci-dessous).\nChaque fois que vous effectuez des modifications substantielles (par exemple, l’ajout ou la mise à jour d’une section de code), faites une pause et committez ces changements. Pensez à un commit comme un “partie” de changements liés à un objectif commun. Vous pouvez toujours continuer à réviser un fichier après y avoir apporté des modifications.\nConseil sur les commits : en général, il est préférable de faire de petits commits, qui peuvent être facilement annulées si un problème survient, pour commiter ensemble des modifications liées à un objectif commun. Pour y parvenir, vous trouverez que vous devez commiter souvent. Au début, vous allez probablement oublier de commiter souvent, mais ensuite l’habitude s’installe.\n\nDans Rstudio\nL’exemple ci-dessous montre que, depuis le dernier commit, le script R Markdown “collaboration.Rmd” a été modifié, et plusieurs images PNG ont été ajoutées.\n\n\n\n\n\n\n\n\n\nVous vous demandez peut-être ce que représentent les carrés jaunes, bleus, verts et rouges à côté de les noms de fichiers. Voici un instantané de la feuille de route RStudio cheatsheet qui explique leur signification. Notez que les changements avec des ” ?” jaunes peuvent toujours être mises en scène, validées et poussées.\n\n\n\n\n\n\n\n\n\n\nCliquez sur le bouton “Commit” dans l’onglet Git, ce qui ouvrira une nouvelle fenêtre (voir ci-dessous).\nCliquez sur le nom d’un fichier dans le cadre supérieur gauche.\nPassez en revue les modifications que vous avez apportées à ce fichier (surlignées en vert ou en rouge ci-dessous).\n“Mettez en scène” le fichier, ce qui inclura ces modifications dans le commit. Faites en cochant la case à côté du nom du fichier. Alternativement, vous pouvez mettre en surbrillance plusieurs noms de fichiers, puis cliquer sur “Stage”.\nRédigez un message de validation court mais descriptif (obligatoire).\nAppuyez sur le bouton “Commit”. Une boîte de dialogue apparaîtra, indiquant le succès ou un message d’erreur.\n\nVous pouvez maintenant effectuer d’autres modifications et d’autres livraisons, autant de fois que vous le souhaitez.\n\n\n\n\n\n\n\n\n\n\n\nDans le bureau de Github\nVous pouvez voir la liste des fichiers qui ont été modifiés sur la gauche. Si vous sélectionnez un fichier texte, vous verrez un résumé des modifications qui ont été apportées dans le volet de droite (cette vue ne fonctionnera pas sur des fichiers plus complexes comme les .docs ou les .xlsx).\nPour mettre en scène les changements, il suffit de cocher la petite case à côté des noms de fichiers. Lorsque vous avez sélectionné les fichiers que vous voulez ajouter à cette livraison, donnez un nom à la livraison, une description, puis cliquez sur le bouton commit.\n\n\n\n\n\n\n\n\n\n\n\nDans la console\nLes deux fonctions utilisées dans les coulisses sont git add pour sélectionner/établir et git commit pour effectuer la livraison.\n\ngit status # voir les changements \n\ngit add new_pages/collaboration.Rmd # sélectionner les fichiers à livrer (= mettre en scène les changements)\n\ngit commit -m \"Describe commit from Github Desktop\" # livrer les changements avec un message\n\ngit log # affiche les informations sur les commits passés\n\n\n\nModifier un commit précédent\nQue se passe-t-il si vous commettez des changements, continuez à travailler et réalisez que vous avez fait des changements qui devraient “appartenir” au commit précédent (à votre avis)? N’ayez crainte ! Vous pouvez ajouter ces changements à votre validation précédente.\nDans Rstudio, cela devrait être assez évident puisqu’il y a une case “Amend previous commit” sur la même ligne que le bouton COMMIT.\nPour une raison peu claire, la fonctionnalité n’a pas été implémentée en tant que telle dans Github Desktop, mais il existe une moyen de la contourner. Si vous avez validé mais pas encore poussé vos changements, un bouton “UNDO” apparaît juste en dessous du bouton COMMIT. Cliquez dessus et il annulera votre validation (mais conservera vos fichiers indexés et votre message de validation). Sauvegardez vos changements, ajoutez de nouveaux fichiers à la livraison si nécessaire et livrez à nouveau.\nDans la console :\n\ngit add [YOUR FILES] # Ajoute vos nouvelles modifications\n\ngit commit --amend # Modifie le commit précédent\n\ngit commit --amend -m \"An updated commit message\" # Modifie la livraison précédente ET met à jour le message de livraison.\n\nNote : réfléchissez avant de modifier des commits qui sont déjà publics et partagés avec vos collaborateurs.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#tirez-et-poussez-les-modifications-vers-github",
    "href": "new_pages/collaboration.fr.html#tirez-et-poussez-les-modifications-vers-github",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.8 Tirez et poussez les modifications vers Github",
    "text": "46.8 Tirez et poussez les modifications vers Github\n“D’abord TIREZ, ensuite POUSSER”\nC’est une bonne pratique de aller chercher et de tirez avant de commencer à travailler sur votre projet, afin de mettre à jour la version de la branche sur votre ordinateur local avec toutes les modifications qui ont été apportées dans la version distante/Github.\nTIREZ souvent. N’hésitez pas. Tirez toujours avant de pousser.\nLorsque vos modifications sont effectuées et validées et que vous êtes satisfait de l’état de votre projet, vous pouvez pousser vos commits vers la version distante/Github de votre branche.\nRincez et répétez pendant que vous travaillez sur le référentiel.\nNote: il est beaucoup plus facile de revenir sur des modifications qui ont été commises mais pas poussées (c’est-à-dire qu’elles sont toujours en cours de traitement) que de revenir sur des changements qui ont été poussés vers le dépôt distant (et peut-être déjà extraites par quelqu’un d’autre).\n\nDans Rstudio\nTIREZ - Cliquez d’abord sur l’icône “Tirez” (flèche vers le bas) qui récupère et tire en même temps.\nPOUSSER - Cliquez sur l’icône verte “Tirez” (flèche vers le haut). Il peut vous être demandé d’entrer votre nom d’utilisateur et votre mot de passe Github.La première fois, vous devrez peut-être entrer deux lignes de commande Git dans le Terminal:\n\ngit config –global utilisateur.email ” you@example.com “ (votre adresse électronique Github ), et\ngit config –global user.name “Votre nom d’utilisateur Github”\n\nPour en savoir plus sur la façon de saisir ces commandes, consultez la section ci-dessous sur les commandes Git.\nTIP: On vous demande trop souvent de fournir votre mot de passe ? Consultez les chapitres 10 & 11 de ce tutoriel pour se connecter à un référentiel en utilisant une clé SSH (plus compliqué).\n\n\nDans le bureau de Github\nCliquez sur le bouton “Récupérer l’origine” pour vérifier s’il y a de nouveaux commits sur le dépôt distant.\n\n\n\n\n\n\n\n\n\nSi Git trouve de nouveaux commits sur le dépôt distant, le bouton se se transformera en bouton “Pull”. Comme le même bouton est utilisé pour pousser et tirer, vous ne pouvez pas pousser vos modifications si vous ne tirez pas auparavant.\n\n\n\n\n\n\n\n\n\nVous pouvez aller dans l’onglet “History” (près de l’onglet “Changes”) pour voir toutes les commits (les vôtres et ceux des autres). C’est un bon moyen de savoir ce que vos collaborateurs ont fait. Vous pouvez lire le message du commit, la description s’il y en a une, et comparer le code des deux fichiers en utilisant le volet diff.\n\n\n\n\n\n\n\n\n\nUne fois que toutes les modifications distantes ont été tirées, et qu’au moins une modification locale a été validée, vous pouvez pousser en cliquant sur le même bouton.\n\n\n\n\n\n\n\n\n\n\n\nConsole\nSans surprise, les commandes sont chercher (fetch), tirez (pull) et pousser (push).\n\ngit fetch # Y a-t-il de nouveaux commits dans le répertoire distant ?\ngit pull # Apporte les commits distants dans votre branche locale\ngit push # Pousse les commits locaux de cette branche vers la branche distante\n\n\n\nJe veux tirer mais j’ai du travail local\nCela peut arriver parfois : vous avez effectué des modifications sur votre dépôt local, mais le dépôt distant a des commits que vous n’avez pas tirés.\nGit refusera de les extraire car cela pourrait écraser vos modifications. Il existe plusieurs stratégies pour conserver vos modifications, bien décrites dans Happy Git with R, parmi lesquelles les deux principales sont :\n\nlivrer vos modifications, récupérer les modifications distantes, les tirer, résoudre les conflits si nécessaire (voir la section ci-dessous), et pousser le tout en ligne\nstash vos changements, ce qui les met en quelque sorte de côté, les tirer, les déstocker (restauration), puis commit, résolution des conflits, et push.\n\nSi les fichiers concernés par les modifications distantes et les fichiers concernés par vos modifications locales ne se chevauchent pas, Git peut résoudre les conflits automatiquement.\nDans Github Desktop, cela peut être fait avec des boutons. Pour mettre en cache, allez dans Branch &gt; Stash all changes.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#fusionner-la-branche-dans-main",
    "href": "new_pages/collaboration.fr.html#fusionner-la-branche-dans-main",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.9 Fusionner la branche dans Main",
    "text": "46.9 Fusionner la branche dans Main\nSi vous avez fini de faire des changements, vous pouvez commencer le processus de fusionner ces changements dans la branche principale. En fonction de votre situation, cela peut être rapide, ou vous pouvez avoir des étapes délibérées de révision et d’approbation impliquant des coéquipiers.\n\nLocalement dans Github Desktop\nOn peut fusionner des branches localement en utilisant Github Desktop. Tout d’abord, allez dans (checkout) la branche qui sera le destinataire des commits, en d’autres termes, la branche que vous voulez mettre à jour. Ensuite, allez dans le menu Branche &gt; Fusionner en branche actuelle et cliquez. Une boîte vous permet de sélectionner la branche à partir de laquelle vous souhaitez importer.\n\n\n\n\n\n\n\n\n\n\n\nDans la console\nRevenez d’abord à la branche qui sera le destination des changements. C’est généralement master, mais cela peut être une autre branche si vous le souhaite. Fusionnez votre branche de travail dans master.\n\ngit checkout master # Retournez à master (ou à la branche que vous voulez déplacer)\ngit merge this_fancy_new_branch\n\nCette page montre un exemple plus avancé de branchement et explique un peu ce qui se passe en coulisses.\n\n\nDans Github : soumettre des demandes de pull (tirer)\nS’il est tout à fait possible de fusionner deux branches localement, ou sans en informer qui que ce soit, une fusion peut être discutée ou étudiée par plusieurs personnes avant d’être intégrée à la branche master. Pour aider à ce processus, Github propose des fonctionnalités de discussion autour de la fusion : la pull request.\nUne pull request (une “PR”) est une demande de fusion d’une branche dans une autre (en d’autres termes, une demande pour que votre branche de travail soit intégrée à la branche “principale”). Une pull request implique généralement plusieurs commits. Une pull request commence généralement une conversation et un processus de révision avant qu’elle soit acceptée et que la branche soit fusionnée. Par exemple, vous pouvez lire les discussions sur les demandes de téléchargement sur le site dplyr’s github.\nVous pouvez soumettre une demande de modification (PR) directement à partir du site Web (comme illustré ci-dessous) ou à partir de Github.\n\nAccéder au dépôt Github (en ligne)\nAffichez l’onglet “demande de retrait” et cliquez sur le bouton “New pull request”.\nChoisissez dans le menu déroulant de fusionner votre branche avec la branche principale.\nRédigez un commentaire détaillé de la Pull Request et cliquez sur “Create Pull Request”.\n\nDans l’image ci-dessous, la branche “forests” a été sélectionnée pour être fusionnée dans “main” :\n\n\n\n\n\n\n\n\n\nMaintenant vous devriez être capable de voir la pull request (image d’exemple ci-dessous) :\n\nPassez en revue l’onglet “Fichiers modifiés” pour voir comment la branche “principale” changerait si la branche était fusionnée.\nSur la droite, vous pouvez demander une révision aux membres de votre équipe en marquant leur identifiant Github. Si vous le souhaitez, vous pouvez définir les paramètres du référentiel pour qu’une révision approuvée soit nécessaire afin de fusionner avec la branche master.\nUne fois la demande de retrait est approuvée, un bouton permettant de “Merge pull request” devient actif. Cliquez dessus.\nUne fois terminé, supprimez votre branche comme expliqué ci-dessous.\n\n\n\n\n\n\n\n\n\n\n\n\nRésolution des conflits\nLorsque deux personnes modifient la ou les mêmes lignes au même moment, un conflit de fusion se produit. En effet, Git refuse de prendre une décision quant à version à conserver, mais il vous aide à trouver où se trouve le conflit. NE PANIQUEZ PAS. La plupart du temps, il est assez simple à résoudre.\nPar exemple, sur Github :\n\n\n\n\n\n\n\n\n\nAprès que la fusion ait soulevé un conflit, ouvrez le fichier dans votre éditeur préféré. Le conflit sera indiqué par une série de caractères :\n\n\n\n\n\n\n\n\n\nLe texte entre &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD et ======= provient de votre dépôt local, et celui entre ======= et &gt;&gt;&gt;&gt;&gt;&gt;&gt; de l’autre branche (qui peut être origin, main ou toute autre branche de votre choix).\nVous devez décider quelle version du code vous préférez (ou même écrire une troisième, en incluant les changements des deux côtés si cela est pertinent), effacer le reste et retirer toutes les marques que Git a ajoutées ((&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt; origin/master/your_branch_name).\nEnsuite, sauvegardez le fichier, mettez-le en scène et commitez-le : c’est le commit qui rend la version fusionnée “officielle”. N’oubliez pas de pousser (push) ensuite.\nPlus vous et vos collaborateurs tirent et poussent souvent, plus les conflits seront réduits.\n*Remarque : Si vous vous sentez à l’aise avec la console, il existe des outils plus avancés de fusionner options (par exemple, ignorer les espaces, donner la priorité à un collaborateur, etc.)\n\n\nSupprimer votre branche\nUne fois qu’une branche a été fusionnée dans master et n’est plus nécessaire, vous pouvez la supprimer.\n\n46.9.0.1 Github + Rstudio\nAllez sur le dépôt sur Github et cliquez sur le bouton pour afficher toutes les branches (à côté de la liste déroulante pour les branches). Trouvez maintenant votre branche et cliquez sur l’icône de la corbeille à côté d’elle. Lisez plus de détails sur la suppression d’une branche ici.\nAssurez-vous de supprimer également la branche localement sur votre ordinateur. Cela ne se fera pas automatiquement.\n\nDans RStudio, assurez-vous que vous êtes dans la branche Main.\nPassez à la saisie de commandes Git dans le “Terminal” de RStudio (l’onglet adjacent à la console R), et tapez : git branch -d nom_branche, où “nom_branche” est le nom de la branche à supprimer.\nRafraîchissez votre onglet Git et la branche devrait avoir disparu.\n\n\n\n46.9.0.2 Dans Github\nVérifiez simplement la branche que vous voulez supprimer ce retrouve maintenant dans le menu Branche &gt; Supprimer.\n\n\n\nForking\nVous pouvez bifurquer d’un projet si vous souhaitez contribuer mais que vous n’avez pas les droits pour le faire, ou si vous voulez simplement le modifier pour votre usage personnel. Une courte description de la bifurcation se trouve ici.\nSur Github, cliquez sur le bouton “Fork” :\n\n\n\n\n\n\n\n\n\nCeci clonera le dépôt original, mais dans votre propre profil. Donc maintenant, il y a deux versions du dépôt sur Github : l’original, que vous ne pouvez pas modifier, et la version clonée dans votre profil.\nEnsuite, vous pouvez procéder au clonage de votre version du dépôt en ligne en local sur votre ordinateur, en utilisant l’une des méthodes décrites dans les sections précédentes. Ensuite, vous pouvez créer une nouvelle branche, faire des changements, les livrer et les pousser vers votre dépôt distant.\nUne fois que vous êtes satisfait du résultat, vous pouvez créer une Pull Request à partir de Github ou de Github Desktop pour entamer la conversation avec les propriétaires/mainteneurs du dépôt d’origine.\nEt si vous avez besoin de commits plus récents du dépôt officiel?\nImaginez que quelqu’un apporte une modification critical au dépôt officiel, que vous voulez inclure dans votre version clonée. Il est possible de synchroniser votre fork avec le dépôt officiel. Cela implique l’utilisation du terminal, mais ce n’est pas trop compliqué. Vous devez surtout vous rappeler que :\n\nupstream = le dépôt officiel, celui que vous n’avez pas pu modifier\norigin = votre version du dépôt sur votre profil Github\n\nVous pouvez lire ce tutoriel ou suivre les instructions ci-dessous :\nTout d’abord, tapez dans votre terminal Git (à l’intérieur de votre repo) :\n\ngit remote -v\n\nSi vous n’avez pas encore configuré le référentiel amont, vous devriez voir deux lignes, commençant par origin. Elles montrent le dépôt distant vers lequel chercher et pousser pointent. Rappelez-vous, origin est le surnom conventionnel pour votre propre version du dépôt sur Github. Par exemple :\n\n\n\n\n\n\n\n\n\nMaintenant, ajoutez un nouveau dépôt distant :\n\ngit remote add upstream https://github.com/epirhandbook/Epi_R_handbook.git\n\nIci, l’adresse est l’adresse que Github génère lorsque vous clonez un dépôt (voir la section sur le clonage). Vous aurez maintenant quatre pointeurs distants :\n\n\n\n\n\n\n\n\n\nMaintenant que la configuration est faite, chaque fois que vous voulez obtenir les changements de le dépôt original (upstream), il suffit d’aller (checkout) dans la branche la branche que vous voulez mettre à jour et taper :\n\ngit fetch upstream # Obtenir les nouveaux commits du dépôt distant\ngit checkout la_branche_que_vous_voulez_mettre_à_jour\ngit merge upstream/the_branch_you_want_to_update # Fusionne la branche amont dans votre branche.\ngit push # Mettez à jour votre propre version du dépôt distant.\n\nS’il y a des conflits, vous devrez les résoudre, comme expliqué dans la section Résoudre les conflits.\nRésumé : forker est un clonage, mais du côté du serveur Github. Le reste des actions sont des actions typiques du flux de travail de collaboration (cloner, pousser, tirer, commettre, fusionner, soumettre des demandes de tirage…).\nRemarque : si la bifurcation est un concept et non une commande Git, elle existe aussi sur d’autres hôtes Web, comme Bitbucket.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#ce-que-nous-avons-appris",
    "href": "new_pages/collaboration.fr.html#ce-que-nous-avons-appris",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.10 Ce que nous avons appris",
    "text": "46.10 Ce que nous avons appris\nVous avez appris à :\n\nparamétrer Git pour suivre les modifications dans vos dossiers,\n\nconnecter votre référentiel local à un référentiel en ligne distant,\nlivrer les changements,\n\nsynchroniser vos dépôts local et distant.\n\nTout cela devrait vous permettre de démarrer et de répondre à la plupart de vos besoins en tant qu’épidémiologistes. Nous n’avons généralement pas un usage aussi avancé que les développeurs.\nCependant, sachez que si vous voulez (ou devez) aller plus loin, Git offre plus de puissance pour simplifier l’historique des commits, le retour en arrière d’un ou plusieurs commits, le cherry-pick des commits, etc. Tout cela peut sembler de la pure magie, mais maintenant que vous avez les bases, il est plus facile de s’appuyer dessus.\nNotez que si le volet Git de Rstudio et Github Desktop sont bons pour les débutants / l’utilisation quotidienne dans notre travail, ils n’offrent pas une interface pour certaines des fonctions intermédiaires/avancées de Git. Certaines interfaces plus complètes vous permettent d’en faire plus en pointant et en cliquant (généralement au prix d’une mise en page plus complexe).\nRappelez-vous que puisque vous pouvez utiliser n’importe quel outil à n’importe quel moment pour suivre votre dépôt, vous pouvez très facilement installer une interface pour l’essayer parfois, ou pour effectuer occasionnellement une tâche complexe moins courante, tout en préférant une interface simplifiée le reste du temps (par exemple en utilisant Github Desktop la plupart du temps, et passer à SourceTree ou Gitbash pour certaines tâches spécifiques).\n\n46.10.1 Commandes Git\n\n\nApprentissage recommandé\nPour apprendre les commandes Git à l’aide d’un tutoriel interactif, voir ce site web.\n\n\nOù entrer les commandes\nVous entrez les commandes dans un shell Git.\nOption 1 Vous pouvez ouvrir un nouveau Terminal dans RStudio. Cet onglet se trouve à côté de la Console R. Si vous ne parvenez pas à y taper du texte, cliquez sur le menu déroulant sous “Terminal” et sélectionnez “Nouveau terminal”. Tapez les dans l’espace clignotant situé devant le symbole du dollar “$”.\n\n\n\n\n\n\n\n\n\nOption 2 Vous pouvez également ouvrir un shell (un terminal pour entrer des commandes) en cliquant sur l’icône bleue “gears” dans l’onglet Git (près de l’environnement RStudio). Sélectionnez “Shell” dans le menu déroulant. Une nouvelle fenêtre s’ouvre dans laquelle vous pouvez saisir les commandes après le signe du dollar “$”.\nOption 3 Cliquez avec le bouton droit de la souris pour ouvrir “Git Bash here”, qui ouvrira le même type de terminal, ou ouvrez Git Bash depuis votre liste d’applications. Plus d’informations pour les débutants sur Git Bash, comment le trouver et quelques commandes bash dont vous aurez besoin.\n\n\nExemples de commandes\nNous présentons ci-dessous quelques commandes git courantes. Lorsque vous les utilisez, gardez à l’esprit quelle branche est active (check-out), car cela changera l’action !\nDans les commandes ci-dessous,  représente un nom de branche et  représente l’ID de hachage d’un commit spécifique.  représente un nombre. Ne tapez pas les symboles &lt; ou &gt;&gt;.\n\n\n\n\n\n\n\nCommande Git\nAction\n\n\n\n\ngit branch &lt;name&gt;\nCréer une nouvelle branche avec le nom \n\n\ngit checkout &lt;name&gt;\nBascule de la branche actuelle vers . |git checkout -b | Raccourci pour créer une nouvelle branche *et* y basculer | |git status| Voir les modifications non suivies | |git add | Mettre en scène un fichier | |git commit -m  Comptabilise les changements actuellement mis en scène dans la branche actuelle avec le message | |git fetch| Récupérer les commits du dépôt distant | |git pull| Extraire les commits du dépôt distant dans la branche actuelle | |git push| Pousse les commits locaux vers le répertoire distant | |git switch| Une alternative àgit checkoutqui est en train d'être introduite progressivement dans Git | |git merge | Fusionner la branche &lt;name&gt; dans la branche courante | |git rebase `",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.fr.html#ressources",
    "href": "new_pages/collaboration.fr.html#ressources",
    "title": "46  Contrôle de version et collaboration avec Git et Github",
    "section": "46.11 Ressources",
    "text": "46.11 Ressources\nUne grande partie de cette page a été informée de ce site “Happy Git with R” site web par Jenny Bryan. Il y a une section très utile qui vous aide à résoudre les erreurs courantes liées à Git et à R.\nLe Guide de documentation et de démarrage de Github.com guide.\nLa fiche technique de RStudio “IDE” cheatsheet qui comprend des conseils sur Git avec RStudio.\nhttps://ohi-science.org/news/github-going-back-in-time\nLes commandes Git pour les débutants\nUn tutoriel didacticiel pour apprendre les commandes Git.\nhttps://www.freecodecamp.org/news/an-introduction-to-git-for-absolute-beginners-86fa1d32ff71/ : bon pour apprendre les bases absolues pour suivre les changements dans un dossier sur votre propre ordinateur.\nDe beaux schémas pour comprendre les branches : https://speakerdeck.com/alicebartlett/git-for-humans\nTutoriels couvrant les sujets de base et plus avancés.\nhttps://tutorialzine.com/2016/06/learn-git-in-30-minutes\nhttps://dzone.com/articles/git-tutorial-commands-and-operations-in-git https://swcarpentry.github.io/git-novice/ (cours court) https://rsjakob.gitbooks.io/git/content/chapter1.html\nLe livre Pro Git est considéré comme une référence officielle. Bien que certains chapitres soient corrects, il est généralement un peu technical. C’est probablement une bonne ressource une fois que vous avez utilisé Git un peu et quand vous voulez apprendre un peu plus précisément ce qui se passe et comment aller plus loin avec Git.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Contrôle de version et collaboration avec Git et Github</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.fr.html",
    "href": "new_pages/errors.fr.html",
    "title": "47  Erreurs fréquentes{#errors}",
    "section": "",
    "text": "47.1 Interprétation des messages d’erreurs\nLes messages d’erreurs en R peuvent parfois être compliqués, c’est la raison pour laquelle Google sera votre partenaire. Recherchez le message d’erreur avec “R” et cherchez des messages récents dans StackExchange.com, stackoverflow.com, community.rstudio.com, twitter(#rstats) et d’autres forums utilisés par les programmeurs pour poser des questions et obtenir des réponses. Essayez de trouver des messages récents qui ont résolu des problèmes similaires.\nSi, après nombreuses recherches, vous ne trouvez pas de réponse à votre problème, envisagez créer un exemple reproductible (“reprex”) et poser la question vous-même. Consultez la page obtenir de l’aide pour des conseils sur comment créer et publier un exemple reproductible sur les forums.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Erreurs fréquentes{#errors}</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.fr.html#erreurs-fréquentes",
    "href": "new_pages/errors.fr.html#erreurs-fréquentes",
    "title": "47  Erreurs fréquentes{#errors}",
    "section": "47.2 Erreurs fréquentes",
    "text": "47.2 Erreurs fréquentes\nNous énumérons ci-dessous quelques erreurs courantes et les explications/solutions possibles. Certaines d’entre elles sont tirées de l’analyse de Noam Ross, qui a analysé les messages de forum les plus courants sur Stack Overflow concernant les messages d’erreur en R (voir l’analyse ici).\n\nErreurs de typographie\nError: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\"\nSi vous voyez unexpected symbol, vérifiez qu’il ne manque pas de virgules\n\n\nErreurs de packages\ncould not find function \"x\"...\nCeci signifie probablement que vous avez mal saisi le nom de la fonction, ou bien vous avez oublié d’installer ou de lancer un package.\nError in select(data, var) : unused argument (var)\nVous pensez que vous utilisez dplyr::select() mais la fonction select() a été masquée par MASS::select() - spécifiez dplyr:: ou réordonnez le chargement de votre package pour que dplyr soit après tous les autres.\nD’autres erreurs de cache communes proviennent de : plyr::summarise() et stats::filter(). Considérez l’utilisation du conflicted package.\nError in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’\nSi vous obtenez une erreur indiquant que vous devez supprimer un fichier “00LOCK”, allez dans votre bibliothèque “R” dans le répertoire de votre ordinateur (par exemple, R/win-library/) et cherchez un dossier nommé “00LOCK”. Supprimez-le manuellement et essayez d’installer à nouveau le package. Un processus d’installation précédent a probablement été interrompu, ce qui a mené à cela.\n\n\nErreurs d’objet\nNo such file or directory:\nSi vous voyez une erreur comme celle-ci lorsque vous essayez d’exporter ou d’importer : Vérifiez l’orthographe du fichier et de son chemin d’accès, et si le chemin d’accès contient des barres obliques, assurez-vous qu’il s’agit bien d’une barre oblique en avant / et non d’une barre oblique en arrière \\. Vérifiez également que vous avez utilisé la bonne extension de fichier (par exemple, .csv, .xlsx).\nobject 'x' not found \nCeci signifie que l’objet que vous référencez n’existe pas. Peut-être que le code ci-dessus ne s’est pas correctement exécuté ?\nError in 'x': subscript out of bounds\nCeci signifie que vous avez essayé d’accéder à quelque chose (un élément d’un vecteur ou d’une liste) qui n’existe pas.\n\n\nErreurs de syntaxe des fonctions\n# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`.\nL’erreur ci-dessus (argument .x is missing, with no default) est fréquente dans mutate() si vous fournissez une fonction comme recode() ou replace_na() où l’on s’attend à ce que vous fournissiez le nom de la colonne comme premier argument. Ceci est facile à oublier.\n\n\n\nErreurs de logique\nError in if\nCeci signifie probablement qu’une instruction if a été appliquée à quelque chose qui n’était ni VRAI ni FAUX.\n\n\nErreurs de facteur\n#Tried to add a value (\"Missing\") to a factor (with replace_na operating on a factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated\nSi vous voyez cette erreur concernant des niveaux de facteur invalides, vous avez probablement une colonne de la classe Factor (qui contient des niveaux prédéfinis) et vous avez essayé d’y ajouter une nouvelle valeur. Convertissez-la en classe Character avant d’ajouter une nouvelle valeur.\n\n\nErreurs graphique\nError: Insufficient values in manual scale. 3 needed but only 2 provided. ggplot() scale_fill_manual() values = c(“orange”, “purple”) … insuffisant pour le nombre de niveaux de facteurs … considérer si NA est maintenant un niveau de facteur…\nCan't add x object\nVous avez probablement un + supplémentaire à la fin d’une commande ggplot que vous devez supprimer.\n\n\nErreurs R Markdown\nSi le message d’erreur est de type Error in options[[sprintf(\"fig.%s\", i)]], vérifiez que vos options knitr en haut de chaque chunk utilisent correctement out.width = ou out.height = et pas fig.width= et fig.height=.\n\n\nAutres\nVérifiez si vous avez réorganisé les verbes dplyr en pipe et si vous n’avez pas remplacé un pipe au milieu, ou si vous n’avez pas retiré un pipe de la fin après avoir réorganisé.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Erreurs fréquentes{#errors}</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.fr.html#ressources",
    "href": "new_pages/errors.fr.html#ressources",
    "title": "47  Erreurs fréquentes{#errors}",
    "section": "47.3 Ressources",
    "text": "47.3 Ressources\nVoici un autre article de blog qui recense les R programming errors faced by beginners",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Erreurs fréquentes{#errors}</span>"
    ]
  },
  {
    "objectID": "new_pages/help.fr.html",
    "href": "new_pages/help.fr.html",
    "title": "48  Obtenir de l’aide{#help}",
    "section": "",
    "text": "48.1 Github issues\nPlusieurs packages et projets en R ont leur code sur le site Github.com. Vous pouvez communiquer directement avec les auteurs sur ce site en postant un “Issue”.\nPour en savoir plus sur comment sauvegarder vos travaux sur Github, consultez la page Collaboration et Github.\nSur Github, chaque projet est contenu dans un repository. Chaque repository contient du code, des données, des résultats, la documentation d’aide, etc. Il existe également un moyen de communiquer avec les auteurs dénommé “Issues”.\nCi-dessous, la page Github pour le package incidence2 (utilisé pour créer des courbes épidémiques). Vous pouvez voir l’onglet “Issues” surligné en jaune. Vous pouvez voir qu’il y a 5 issues ouvertes.\nUne fois dans l’onglet Issues, vous pouvez voir les questions ou issues ouvertes. Lisez-les pour vous assurer que votre question n’est pas déjà abordée. Vous pouvez ouvrir un nouveau issue en cliquant sur le bouton vert à droite. Vous aurez besoin d’un compte Github pour le faire.\nDans votre question, suivez les instructions ci-dessous pour fournir un exemple minimal et reproductible. Et soyez gentil! La plupart des personnes qui développent des packages et des projets R le font pendant leur temps libre (comme ce manuel!).\nPour en savoir plus sur la gestion des questions dans votre propre repository Github, consultez la documentation sur les issues sur Github.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Obtenir de l'aide{#help}</span>"
    ]
  },
  {
    "objectID": "new_pages/help.fr.html#exemple-reproductible",
    "href": "new_pages/help.fr.html#exemple-reproductible",
    "title": "48  Obtenir de l’aide{#help}",
    "section": "48.2 Exemple reproductible",
    "text": "48.2 Exemple reproductible\nFournir un exemple reproductible (“reprex”) est essentiel pour obtenir de l’aide lorsque vous postez un message dans un forum ou dans un issue Github. Les gens veulent vous aider, mais vous devez leur donner un exemple avec lequel ils peuvent travailler sur leur propre ordinateur. L’exemple doit :\n\nDémontrer le problème que vous avez rencontré\n\nÊtre minimal, c’est-à-dire qu’il ne doit contenir que les données et le code nécessaires à la reproduction du problème.\n\nÊtre reproductible, c’est-à-dire que tous les objets (par exemple les données) et les requêtes sur les packages (par exemple library() ou p_load()) sont inclus.\n\nAussi, assurez-vous de ne pas poster de données confidentielles avec le reprex! Vous pouvez créer des tableaux de données exemplaires, ou utiliser l’un des tableaux de données intégrés à R (entrez data() pour ouvrir une liste de ces ensembles de données).\n\nLe package reprex\nLe package reprex peut vous aider à créer un exemple reproduisible :\n\nreprex est installé avec tidyverse, donc chargez l’un ou l’autre des packages\n\n\n# installer/charger tidyverse (qui inclut reprex)\npacman::p_load(tidyverse)\n\n\nCommencez un script R qui crée votre problème, étape par étape, en commençant par le chargement des packages et des données.\n\n\n# charger les packages\npacman::p_load(\n     tidyverse,  # gestion des donnees et visualisation \n     outbreaks)  # exemple de données sur les épidémies\n\n# Liste des cas d'épidémie de grippe\noutbreak_raw &lt;- outbreaks::fluH7N9_china_2013 # récupérer les données à partir du package outbreaks \n\n# nettoyage des données\noutbreak &lt;- outbreak_raw %&gt;% \n     mutate(across(contains(\"date\"), as.Date))\n\n# graphique de l'epidémie \n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\n\nCopiez tout le code sur votre clipboard, et exécutez la commande suivante :\n\nreprex::reprex()\n\nVous verrez une fenêtre HTML apparaître dans la fenêtre viewer de RStudio. Elle contiendra l’ensemble de votre code et tous les messages, les erreurs, ou les résultats de graphique. Ce résultat est également copié sur votre presse-papier, de façon à ce que vous pouvez le poster directement dans un issue Github ou un poste de forum.\n\n\n\n\n\n\n\n\n\n\nSi vous définissez session_info = TRUE, le resultat de sessioninfo::session_info() avec votre version de R et du package R sera inclus.\n\nVous pouvez spécifier un répertoire de travail avec wd =.\n\nVous pouvez en lire plus sur les arguments et les variations possibles dans la documentation ou en saisissant ?reprex.\n\nDans l’exemple ci-dessus, la commande ggplot() ne s’est pas exécutée car l’argument date_format = n’est pas correcte - il devrait être date_labels =.\n\n\nDonnées minimales\nLes aidants doivent être en mesure d’utiliser vos données - idéalement, ils doivent pouvoir les créer avec du code.\nPour créer un ensemble de données minimales, considérez anonymer et utiliser seulement un sous-ensemble des observations.\nEN CONSTRUCTION - vous pouvez également utiliser la fonction dput() pour créer un ensemble de données minimales.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Obtenir de l'aide{#help}</span>"
    ]
  },
  {
    "objectID": "new_pages/help.fr.html#poster-sur-un-forum",
    "href": "new_pages/help.fr.html#poster-sur-un-forum",
    "title": "48  Obtenir de l’aide{#help}",
    "section": "48.3 Poster sur un forum",
    "text": "48.3 Poster sur un forum\nLisez beaucoup de messages de forum. Essayez de comprendre quels messages sont bien rédigés et lesquels ne sont pas.\n\nTout d’abord, décidez si vous devez poser la question. Avez-vous parcouru le site web du forum, en essayant divers termes de recherche, pour voir si votre question n’a pas déjà été posée ?\nChoisissez un titre informatif pour votre question (pas “Au secours ! ça ne marche pas”).\nRédigez votre question :\n\n\nPrésentez votre situation et votre problème\n\nLiez aux posts de problèmes similaires et expliquez pourquoi ils ne répondent pas à votre question\nIncluez toute information pertinente pour aider quelqu’un qui ne connaît pas le contexte de votre travail.\n\nDonnez un exemple minimal reproductible avec les informations de votre session R.\n\nUtilisez la propre orthographe, grammaire et ponctuation, et divisez votre question en paragraphes pour faciliter la lecture.\n\n\nsurveillez votre question une fois qu’elle est publiée pour pouvoir répondre à toute demande de clarification. Soyez gentil et aimable - souvent, les personnes qui répondent vous aident volontairement. Si vous avez une question complémentaire, demandez-vous si elle doit faire l’objet d’une question différente.\nMarquez la question comme ayant reçu une réponse, si vous obtenez une réponse qui répond à la demande originale. Cela permet aux autres personnes de reconnaître rapidement la solution.\n\nLisez ces articles sur comment poser une bonne question et le code de conduite de Stack overflow.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Obtenir de l'aide{#help}</span>"
    ]
  },
  {
    "objectID": "new_pages/help.fr.html#resources",
    "href": "new_pages/help.fr.html#resources",
    "title": "48  Obtenir de l’aide{#help}",
    "section": "48.4 Resources",
    "text": "48.4 Resources\nPage Tidyverse sur comment obtenir de l’aide\nAstuces pour produire un ensemble de données minimal\nDocumentation de la fonction dput",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Obtenir de l'aide{#help}</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.fr.html",
    "href": "new_pages/network_drives.fr.html",
    "title": "49  R sur les lecteurs réseau",
    "section": "",
    "text": "49.1 Aperçu\nL’utilisation de R sur des lecteurs partagés du réseau ou de “l’entreprise” peut présenter des défis supplémentaires. Cette page contient des approches, des erreurs courantes et des suggestions de dépannage tirées de notre expérience de travail sur ces questions. Cela inclut des conseils pour les situations particulièrement délicates impliquant R Markdown.\nUtilisation de R sur des lecteurs réseau : Principes généraux",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R sur les lecteurs réseau</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.fr.html#aperçu",
    "href": "new_pages/network_drives.fr.html#aperçu",
    "title": "49  R sur les lecteurs réseau",
    "section": "",
    "text": "Vous devez obtenir un accès administrateur pour votre ordinateur. Configurez RStudio spécifiquement pour qu’il s’exécute en tant qu’administrateur.\n\nEnregistrez les paquets dans une bibliothèque située sur un lecteur portant une lettre (par exemple, “C :”) lorsque cela est possible. Utilisez le moins possible une bibliothèque de paquets dont le chemin commence par “\\\".\n\nLe paquet rmarkdown ne doit pas être dans une bibliothèque de paquets “\\\", car alors il ne peut pas se connecter à TinyTex ou Pandoc.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R sur les lecteurs réseau</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.fr.html#rstudio-en-tant-quadministrateur",
    "href": "new_pages/network_drives.fr.html#rstudio-en-tant-quadministrateur",
    "title": "49  R sur les lecteurs réseau",
    "section": "49.2 RStudio en tant qu’administrateur",
    "text": "49.2 RStudio en tant qu’administrateur\nLorsque vous cliquez sur l’icône RStudio pour ouvrir RStudio, faites-le avec un clic droit. Selon votre machine, vous verrez peut-être une option “Exécuter en tant qu’administrateur”. Sinon, vous verrez peut-être une option permettant de sélectionner Propriétés (une fenêtre devrait alors apparaître avec l’option “Compatibilité”, et vous pourrez cocher la case “Exécuter en tant qu’administrateur”).\n\n49.2.1 Commandes utiles\nVous trouverez ci-dessous quelques commandes utiles lorsque vous essayez de résoudre des problèmes en utilisant R sur des lecteurs réseau.\nVous pouvez renvoyer le(s) chemin(s) des bibliothèques de paquets que R utilise. Ils seront listés dans l’ordre que R utilise pour installer/charger/rechercher les paquets. Ainsi, si vous voulez que R utilise une autre bibliothèque par défaut, vous pouvez changer l’ordre de ces chemins (voir ci-dessous).\n\n# Recherche de bibliothèques\n.libPaths() # Vos chemins de bibliothèques, listés dans l'ordre d'installation/de recherche de R. \n                              # Note : toutes les bibliothèques seront listées, mais pour en installer certaines (par exemple C :), vous devrez peut-être exécuter RStock. \n                              # devrez peut-être exécuter RStudio en tant qu'administrateur (cela n'apparaîtra pas dans le menu déroulant \n                              # menu déroulant des bibliothèques d'installation des paquets) \n\nVous pouvez vouloir changer l’ordre des bibliothèques de paquets utilisées par R. Par exemple, si R récupère un emplacement de bibliothèque qui commence par “\\\" et un autre qui commence par une lettre, par exemple”D :“. Vous pouvez ajuster l’ordre de .libPaths() avec le code suivant.\n\n# Changer l'ordre des bibliothèques\n# Ceci peut affecter la priorité de R à trouver un paquet. Par exemple, vous pouvez vouloir que votre bibliothèque C : soit listée en premier.\nmyPaths &lt;- .libPaths() # obtenir les chemins d'accès\nmyPaths &lt;- c(myPaths[2], myPaths[1]) # les commuter\n.libPaths(myPaths) # les réaffecter\n\nSi vous avez des difficultés à connecter R Markdown à Pandoc, commencez par ce code pour savoir où RStudio pense que votre installation Pandoc se trouve.\n\n# Trouver Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\") # Trouver où RStudio pense que votre installation Pandoc se trouve\n\nSi vous voulez voir à partir de quelle bibliothèque un paquet est chargé, essayez le code suivant :\n\n# Trouver un paquetage\n# donne le premier emplacement du paquet (notez l'ordre de vos bibliothèques)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\"))",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R sur les lecteurs réseau</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.fr.html#dépannage-des-erreurs-courantes",
    "href": "new_pages/network_drives.fr.html#dépannage-des-erreurs-courantes",
    "title": "49  R sur les lecteurs réseau",
    "section": "49.3 Dépannage des erreurs courantes",
    "text": "49.3 Dépannage des erreurs courantes\n“Failed to compile…tex in rmarkdown”\n* Vérifiez l’installation de TinyTex, ou installez TinyTex à l’emplacement C :. Voir la page R - les basespour savoir comment installer TinyTex.\n\n# vérifiez/installez tinytex, à l'emplacement C :.\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # devrait retourner VRAI (notez les trois deux points)\n\nLes routines Internet ne peuvent pas être chargées.\nPar exemple, Erreur dans tools::startDynamicHelp() : les routines internet ne peuvent pas être chargées.\n\nEssayez de sélectionner la version 32 bits de RStudio via Tools/Global Options.\n\nNote : si la version 32 bits n’apparaît pas dans le menu, assurez-vous que vous n’utilisez pas RStudio v1.2.\n\n\nAlternativement, essayez de désinstaller R et de le réinstaller avec une version différente (32 au lieu de 64).\n\nC : la bibliothèque n’apparaît pas comme une option lorsque j’essaie d’installer les paquets manuellement.\n\nLancez RStudio en tant qu’administrateur, cette option apparaîtra alors.\n\nPour configurer RStudio pour qu’il soit toujours exécuté en tant qu’administrateur (avantageux lorsque vous utilisez un projet R où vous ne cliquez pas sur l’icône RStudio pour l’ouvrir)… cliquez avec le bouton droit de la souris sur l’icône Rstudio.\n\nL’image ci-dessous montre comment vous pouvez sélectionner manuellement la bibliothèque dans laquelle installer un paquet. Cette fenêtre apparaît lorsque vous ouvrez le volet Packages RStudio et cliquez sur “Installer”.\n\n\n\n\n\n\n\n\n\nPandoc 1 erreur\nSi vous obtenez “pandoc error 1” lorsque vous tricotez des scripts R Markdowns sur des lecteurs réseau :\n\nSur plusieurs emplacements de bibliothèque, faites en sorte que celui qui a un lecteur avec une lettre soit listé en premier (voir les codes ci-dessus).\n\nLa solution ci-dessus a fonctionné lors du tricotage sur le lecteur local, mais lors d’une connexion Internet en réseau.\n\nVoir plus de conseils ici : https://ciser.cornell.edu/rmarkdown-knit-to-html-word-pdf/\n\nErreur Pandoc 83\nL’erreur ressemblera à quelque chose comme ceci : Impossible de trouver le fichier...rmarkdown...lua.... Cela signifie qu’il n’a pas pu trouver ce fichier.\nVoir https://stackoverflow.com/questions/58830927/rmarkdown-unable-to-locate-lua-filter-when-knitting-to-word\nPossibilités :\n\nLe paquet Rmarkdown n’est pas installé\n\nLe paquet Rmarkdown n’est pas trouvable\n\nUn problème de droits d’administration.\n\nIl est possible que R ne soit pas capable de trouver le fichier du paquet rmarkdown, donc vérifiez dans quelle bibliothèque se trouve le paquet rmarkdown (voir le code ci-dessus). Si le paquet est installé dans une bibliothèque inaccessible (par exemple, commençant par “\\\"), pensez à le déplacer manuellement vers C : ou une autre bibliothèque de lecteur nommée. Soyez conscient que le paquet rmarkdown doit pouvoir se connecter à l’installation de TinyTex, et ne peut donc pas être installé dans une bibliothèque sur un lecteur réseau.\nErreur Pandoc 61\nPar exemple : Erreur : la conversion du document pandoc a échoué avec l'erreur 61 ou Impossible d'aller chercher....\n\nEssayez d’exécuter RStudio en tant qu’administrateur (cliquez avec le bouton droit de la souris sur l’icône, sélectionnez exécuter en tant qu’administrateur, voir les instructions ci-dessus).\n\nVoir également si le paquet spécifique qui n’a pas pu être atteint peut être déplacé vers la bibliothèque C :.\n\nErreur LaTex (voir ci-dessous).\nUne erreur du type : ! Paquet pdftex.def Erreur : File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' non trouvé : utilisation de la fonction brouillon. ou Erreur : LaTeX n'a pas réussi à compiler file_name.tex..\n\nVoir https://yihui.org/tinytex/r/#debugging pour des conseils de débogage.\n\nVoir file_name.log pour plus d’informations.\n\nErreur Pandoc 127\nCela peut être un problème de RAM (espace). Redémarrez votre session R et réessayez.\nMappage de lecteurs réseau\nLe mappage d’un lecteur réseau peut être risqué. Consultez votre service informatique avant d’essayer.\nUn conseil emprunté à cette discussion du forum :\nComment ouvrir un fichier “via un lecteur réseau mappé” ?\n\nTout d’abord, vous devez connaître l’emplacement réseau auquel vous essayez d’accéder.\n\nEnsuite, dans le gestionnaire de fichiers de Windows, vous devez cliquer avec le bouton droit de la souris sur “Ce PC” dans le volet de droite, et sélectionner “Mapper un lecteur réseau”.\n\nPassez par la boîte de dialogue pour définir l’emplacement réseau de tout à l’heure comme un lecteur de lettres.\n\nMaintenant, vous avez deux façons d’accéder au fichier que vous ouvrez. L’utilisation du chemin d’accès par lettre du lecteur devrait fonctionner.\n\nErreur dans install.packages()\nSi vous obtenez une erreur qui inclut la mention d’un répertoire “verrouillé”, par exemple : `Erreur dans install.packages : ERROR : échec du verrouillage du répertoire…``\nRegardez dans votre bibliothèque de paquets et vous verrez un répertoire dont le nom commence par “00LOCK”. Essayez les astuces suivantes :\n\nSupprimez manuellement le répertoire du dossier “00LOCK” de votre bibliothèque de paquets. Essayez d’installer à nouveau le paquetage.\n\nVous pouvez aussi essayer la commande pacman::p_unlock() (vous pouvez aussi mettre cette commande dans le Rprofile pour qu’elle s’exécute à chaque fois que le projet s’ouvre). Ensuite, essayez à nouveau d’installer le paquet. Cela peut prendre plusieurs essais.\n\nEssayez d’exécuter RStudio en mode Administrateur, et essayez d’installer les paquets un par un.\n\nSi tout le reste échoue, installez le paquet dans une autre bibliothèque ou un autre dossier (par exemple Temp), puis copiez manuellement le dossier du paquet dans la bibliothèque souhaitée.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R sur les lecteurs réseau</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html",
    "href": "new_pages/data_table.fr.html",
    "title": "50  Tableau de données",
    "section": "",
    "text": "50.1 Intro aux tableaux de données\nUne table de données est une structure de données bidimensionnelle comme un cadre de données qui permet d’effectuer des opérations de regroupement complexes. La syntaxe data.table est structurée de manière à ce que les opérations puissent être effectuées sur les lignes, les colonnes et les groupes.\nLa structure est DT[i, j, by], séparée par 3 parties : les arguments i, j et by. L’argument i permet de sous-dimensionner les lignes requises, l’argument j permet d’opérer sur les colonnes et l’argument by permet d’opérer sur les colonnes par groupes.\nCette page abordera les sujets suivants :",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#intro-aux-tableaux-de-données",
    "href": "new_pages/data_table.fr.html#intro-aux-tableaux-de-données",
    "title": "50  Tableau de données",
    "section": "",
    "text": "Importation de données et utilisation de fread() et fwrite().\nSélection et filtrage des lignes en utilisant l’argument i.\nUtilisation des fonctions d’aide %like%, %chin%, %between%.\nSélection et calcul sur les colonnes à l’aide de l’argument j.\nCalculer par groupes avec l’argument by\nAjouter et mettre à jour des données dans des tableaux de données en utilisant :=",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#load-packages-and-import-data",
    "href": "new_pages/data_table.fr.html#load-packages-and-import-data",
    "title": "50  Tableau de données",
    "section": "50.2 Load packages and import data",
    "text": "50.2 Load packages and import data",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#chargement-des-paquets-et-importation-des-données",
    "href": "new_pages/data_table.fr.html#chargement-des-paquets-et-importation-des-données",
    "title": "50  Tableau de données",
    "section": "50.3 Chargement des paquets et importation des données",
    "text": "50.3 Chargement des paquets et importation des données\n\nCharger des paquets\nEn utilisant la fonction p_load() de pacman, nous chargeons (et installons si nécessaire) les paquets nécessaires à cette analyse.\n\npacman::p_load(\n  rio, # pour importer les données\n  data.table, # pour regrouper et nettoyer les données\n  tidyverse, # permet d'utiliser la fonction pipe (%&gt;%) dans ce chapitre\n  here \n  ) \n\n\n\nImporter les données\nCette page va explorer certaines des fonctions principales de data.table en utilisant la liste de cas référencée tout au long du manuel.\nNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour les suivre pas à pas, consultez les instructions de la page [Donwload book and data]. L’ensemble de données est importé à l’aide de la fonction import() du paquet rio. Voir la page [Import and export] pour les différentes manières d’importer des données. A partir de là, nous utilisons data.table() pour convertir le cadre de données en un tableau de données.\n\nlinelist &lt;- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %&gt;% data.table()\n\nLa fonction fread() est utilisée pour importer directement des fichiers délimités réguliers, tels que les fichiers .csv, vers un format de table de données. Cette fonction, et sa contrepartie, fwrite(), utilisée pour écrire les tables de données comme des fichiers délimités réguliers, sont des options très rapides et efficaces en termes de calcul pour les grandes bases de données.\nLes 20 premières lignes de linelist :\nLes commandes de base de R, telles que dim(), utilisées pour les cadres de données, peuvent également être utilisées pour les tableaux de données.\n\ndim(linelist) #donne le nombre de lignes et de colonnes du tableau de données\n\n[1] 5888   30",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#largument-i-sélection-et-filtrage-des-lignes",
    "href": "new_pages/data_table.fr.html#largument-i-sélection-et-filtrage-des-lignes",
    "title": "50  Tableau de données",
    "section": "50.4 L’argument i: sélection et filtrage des lignes",
    "text": "50.4 L’argument i: sélection et filtrage des lignes\nEn rappelant la structure DT[i, j, by], nous pouvons filtrer les lignes en utilisant soit des numéros de ligne, soit des expressions logiques. L’argument i est le premier ; par conséquent, la syntaxe DT[i] ou DT[i,] peut être utilisée.\nLe premier exemple récupère les 5 premières lignes de la table de données, le deuxième exemple sous-entend que les cas sont âgés de 18 ans ou plus, et le troisième exemple sous-entend que les cas âgés de 18 ans ou plus mais non diagnostiqués à l’hôpital central :\n\nlinelist[1:5] #renvoie la 1ère à la 5ème ligne\nlinelist[age &gt;= 18] #sous-entend les cas égaux ou supérieurs à 18 ans\nlinelist[age &gt;= 18 & hospital != \"Central Hospital\"] #subset les cas égaux ou supérieurs à 18 ans mais non diagnostiqués à Central Hospital\n\nL’utilisation de .N dans l’argument i représente le nombre total de lignes dans la table de données. Cela peut être utilisé pour effectuer un sous-ensemble sur le nombre de lignes :\n\nlinelist[.N] #renvoie la dernière ligne\nlinelist[15 :.N] #renvoie la 15ème à la dernière ligne\n\n\nUtilisation de fonctions d’aide pour le filtrage\nLe tableau de données utilise des fonctions d’aide qui facilitent le sous-ensemble des lignes. La fonction %like% est utilisée pour faire correspondre un motif dans une colonne, %chin% est utilisée pour faire correspondre un caractère spécifique, et la fonction d’aide %between% est utilisée pour faire correspondre des colonnes numériques dans une plage prédéfinie.\nDans les exemples suivants, nous : * filtrons les lignes où la variable hospital contient “Hospital”. * filtrons les lignes où le résultat est “Recover” ou “Death”. * filtrons les lignes dans la tranche d’âge 40-60 ans\n\nlinelist[hospital %like% \"Hospital\"] #filtre les lignes où la variable hospital contient \"Hospital\"\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #filtre les lignes où l'issue est \"Recover\" ou \"Death\".\nlinelist[age %between% c(40, 60)] #filtre les lignes dans la tranche d'âge 40-60\n\n#%between% doit prendre un vecteur de longueur 2, tandis que %chin% peut prendre des vecteurs de longueur &gt;= 1",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#largument-j-sélection-et-calcul-sur-les-colonnes",
    "href": "new_pages/data_table.fr.html#largument-j-sélection-et-calcul-sur-les-colonnes",
    "title": "50  Tableau de données",
    "section": "50.5 L’argument j: sélection et calcul sur les colonnes",
    "text": "50.5 L’argument j: sélection et calcul sur les colonnes\nEn utilisant la structure DT[i, j, by], nous pouvons sélectionner des colonnes en utilisant des nombres ou des noms. L’argument j est le second ; on utilise donc la syntaxe DT[, j]. Pour faciliter les calculs sur l’argument j, la colonne est enveloppée en utilisant soit list() soit .().\n\nSélection de colonnes\nLe premier exemple récupère les première, troisième et cinquième colonnes de la table de données, le deuxième exemple sélectionne toutes les colonnes à l’exception des colonnes taille, poids et sexe. Le troisième exemple utilise la terminaison .() pour sélectionner les colonnes identification du cas et résultat.\n\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] fonctionne tout aussi bien\n\n\n\nCalcul sur les colonnes\nEn combinant les arguments i et j, il est possible de filtrer les lignes et de calculer sur les colonnes. L’utilisation de .N dans l’argument j représente également le nombre total de lignes dans le tableau de données et peut être utile pour retourner le nombre de lignes après le filtrage des lignes.\nDans les exemples suivants, nous : * Comptons le nombre de cas qui sont restés plus de 7 jours à l’hôpital. * Calculer l’âge moyen des cas qui sont décédés à l’hôpital militaire. * Calculer l’écart-type, la médiane et l’âge moyen des cas qui se sont rétablis à l’hôpital central.\n\nlinelist[days_onset_hosp &gt; 7 , .N]\n\n[1] 189\n\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T supprime les valeurs N/A\n\n        V1\n     &lt;num&gt;\n1: 15.9084\n\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #cette syntaxe n'utilise pas les fonctions d'aide mais fonctionne tout aussi bien\n\n   mean_age median_age   sd_age\n      &lt;num&gt;      &lt;num&gt;    &lt;num&gt;\n1: 16.85185         14 12.93857\n\n\nN’oubliez pas que l’utilisation de la terminaison .() dans l’argument j facilite le calcul, renvoie un tableau de données et permet de nommer les colonnes.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#largument-by-calcul-par-groupes",
    "href": "new_pages/data_table.fr.html#largument-by-calcul-par-groupes",
    "title": "50  Tableau de données",
    "section": "50.6 L’argument by : calcul par groupes",
    "text": "50.6 L’argument by : calcul par groupes\nL’argument by est le troisième argument de la structure DT[i, j, by]. L’argument by accepte à la fois un vecteur de caractères et la syntaxe list() ou .(). L’utilisation de la syntaxe .() dans l’argument by permet de renommer les colonnes à la volée.\nDans les exemples suivants, nous :\n* regroupons le nombre de cas par hôpital * dans les cas de 18 ans ou plus, calculer la taille et le poids moyens des cas selon le sexe et selon qu’ils sont guéris ou décédés * dans les admissions qui ont duré plus de 7 jours, compter le nombre de cas selon le mois d’admission et l’hôpital où ils ont été admis.\n\nlinelist[, .N, .(hospital)] #le nombre de cas par hôpital\n\n                               hospital     N\n                                 &lt;char&gt; &lt;int&gt;\n1:                                Other   885\n2:                              Missing  1469\n3: St. Mark's Maternity Hospital (SMMH)   422\n4:                        Port Hospital  1762\n5:                    Military Hospital   896\n6:                     Central Hospital   454\n\nlinelist[age &gt; 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs représentent les catégories pour lesquelles les données sont manquantes\n\n   gender outcome  mean_wt  mean_ht\n   &lt;char&gt;  &lt;char&gt;    &lt;num&gt;    &lt;num&gt;\n1:      m Recover 71.90227 178.1977\n2:      f   Death 63.27273 159.9448\n3:      m   Death 71.61770 175.4726\n4:      f    &lt;NA&gt; 64.49375 162.7875\n5:      m    &lt;NA&gt; 72.65505 176.9686\n6:      f Recover 62.86498 159.2996\n7:   &lt;NA&gt; Recover 67.21429 175.2143\n8:   &lt;NA&gt;   Death 69.16667 170.7917\n9:   &lt;NA&gt;    &lt;NA&gt; 70.25000 175.5000\n\nlinelist[days_onset_hosp &gt; 7, .N, .(month = month(date_hospitalisation), hospital)]\n\n    month                             hospital     N\n    &lt;num&gt;                               &lt;char&gt; &lt;int&gt;\n 1:     5                    Military Hospital     3\n 2:     6                        Port Hospital     4\n 3:     7                        Port Hospital     8\n 4:     8 St. Mark's Maternity Hospital (SMMH)     5\n 5:     8                    Military Hospital     9\n 6:     8                                Other    10\n 7:     8                        Port Hospital    10\n 8:     9                        Port Hospital    28\n 9:     9                              Missing    27\n10:     9                     Central Hospital    10\n11:     9 St. Mark's Maternity Hospital (SMMH)     6\n12:    10                              Missing     2\n13:    10                    Military Hospital     3\n14:     3                        Port Hospital     1\n15:     4                    Military Hospital     1\n16:     5                                Other     2\n17:     5                     Central Hospital     1\n18:     5                              Missing     1\n19:     6                              Missing     7\n20:     6 St. Mark's Maternity Hospital (SMMH)     2\n21:     6                    Military Hospital     1\n22:     7                    Military Hospital     3\n23:     7                                Other     1\n24:     7                              Missing     2\n25:     7 St. Mark's Maternity Hospital (SMMH)     1\n26:     8                     Central Hospital     2\n27:     8                              Missing     6\n28:     9                                Other     9\n29:     9                    Military Hospital    11\n30:    10                        Port Hospital     3\n31:    10                                Other     4\n32:    10 St. Mark's Maternity Hospital (SMMH)     1\n33:    10                     Central Hospital     1\n34:    11                              Missing     2\n35:    11                        Port Hospital     1\n36:    12                        Port Hospital     1\n    month                             hospital     N\n\n\nData.table permet également d’enchaîner les expressions comme suit :\n\nlinelist[, .N, .(hospital)][order(-N)][1:3] #La première sélectionne tous les cas par hôpital, la deuxième ordonne les cas par ordre décroissant, la troisième sous-ensemble les 3 hôpitaux ayant le plus grand nombre de cas.\n\n            hospital     N\n              &lt;char&gt; &lt;int&gt;\n1:     Port Hospital  1762\n2:           Missing  1469\n3: Military Hospital   896\n\n\nDans ces exemples, nous partons du principe qu’une ligne du tableau de données correspond à un nouveau cas, et nous pouvons donc utiliser la fonction .N pour représenter le nombre de lignes du tableau de données. Une autre fonction utile pour représenter le nombre de cas uniques est uniqueN(), qui retourne le nombre de valeurs uniques dans une entrée donnée. Ceci est illustré ici :\n\nlinelist[, .(uniqueN(gender))] #souvenez-vous que .() dans l'argument j renvoie un tableau de données\n\n      V1\n   &lt;int&gt;\n1:     3\n\n\nLa réponse est 3, car les valeurs uniques de la colonne sexe sont m, f et N/A. Comparez avec la fonction R de base unique(), qui renvoie toutes les valeurs uniques dans une entrée donnée :\n\nlinelist[, .(unique(gender))]\n\n       V1\n   &lt;char&gt;\n1:      m\n2:      f\n3:   &lt;NA&gt;\n\n\nPour trouver le nombre de cas uniques dans un mois donné, nous écririons ce qui suit :\n\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]\n\n    month    V1\n    &lt;num&gt; &lt;int&gt;\n 1:     5    62\n 2:     6   100\n 3:     7   198\n 4:     8   509\n 5:     9  1170\n 6:    10  1228\n 7:    11   813\n 8:    12   576\n 9:     1   434\n10:     2   310\n11:     3   290\n12:     4   198",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#ajout-et-mise-à-jour-des-tables-de-données",
    "href": "new_pages/data_table.fr.html#ajout-et-mise-à-jour-des-tables-de-données",
    "title": "50  Tableau de données",
    "section": "50.7 Ajout et mise à jour des tables de données",
    "text": "50.7 Ajout et mise à jour des tables de données\nL’opérateur := est utilisé pour ajouter ou mettre à jour des données dans une table de données. L’ajout de colonnes à votre table de données peut se faire de la manière suivante :\n\nlinelist[, adult := age &gt;= 18] #ajoute une colonne\nlinelist[, c(\"child\", \"wt_lbs\") := .(age &lt; 18, wt_kg*2.204)] #pour ajouter plusieurs colonnes, il faut utiliser la syntaxe c(\"\") et list() ou .()\nlinelist[, `:=` (bmi_in_range = (bmi &gt; 16 & bmi &lt; 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #Cette méthode utilise := comme un opérateur fonctionnel `:=`.\nlinelist[, adult := NULL] #supprime la colonne\n\nDes agrégations plus complexes dépassent le cadre de ce chapitre d’introduction, mais l’idée est de fournir une alternative populaire et viable à dplyr pour regrouper et nettoyer les données. Le package data.table est un excellent package qui permet d’obtenir un code soigné et lisible.",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.fr.html#ressources",
    "href": "new_pages/data_table.fr.html#ressources",
    "title": "50  Tableau de données",
    "section": "50.8 Ressources",
    "text": "50.8 Ressources\nVoici quelques ressources utiles pour plus d’informations : * https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html * https://github.com/Rdatatable/data.table * https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf * https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/ * https://www.datacamp.com/community/tutorials/data-table-r-tutorial\nVous pouvez exécuter n’importe quelle fonction de synthèse sur des données groupées ; voir la Cheat Sheet ici pour plus d’informations : https://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf",
    "crumbs": [
      "Autres sujets",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Tableau de données</span>"
    ]
  }
]