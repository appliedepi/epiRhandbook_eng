[
  {
    "objectID": "index.es.html",
    "href": "index.es.html",
    "title": "EpiRhandbook en español",
    "section": "",
    "text": "Bienvenida",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.es.html#r-para-epidemiología-aplicada-y-salud-pública",
    "href": "index.es.html#r-para-epidemiología-aplicada-y-salud-pública",
    "title": "EpiRhandbook en español",
    "section": "R para epidemiología aplicada y salud pública",
    "text": "R para epidemiología aplicada y salud pública\nUtilización: Este manual ha sido utilizado más de 1 millón de veces por 300.000 personas en todo el mundo.\nObjetivo: Servir como breve guía de referencia para escribir código en R (en línea y versión sin conexión) con ejemplos detallados que aborden problemas epidemiológicos.\n¿Estás empezando con R? Prueba nuestros tutoriales interactivos gratuitos o el curso de introducción sincrónico, utilizado por los CDC de EE.UU., la OMS, y más de 75 agencias de salud y programas de formación de Epi de campo.\nIdiomas: Inglés (English), Francés (Français), Español, Vietnamita (Tiếng Việt), Japonés (日本), Turco (Türkçe), Portugués (Português), Ruso (Русский)\n\n\n\n\n Escrito y traducido por profesionales de la epidemiología, para profesionales de la epidemiología\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\nApplied Epi es una organización sin ánimo de lucro y un movimiento de base de epis de primera línea de todo el mundo. Escribimos en nuestro tiempo libre para ofrecer este recurso a la comunidad. Tu apoyo y comentarios son bienvenidos:\n\nVisita nuestra página web y únete a nuestra lista de contactos\n\nEmail contact@appliedepi.org, tweet @epiRhandbook o Linkedin\nEnvía problemas a nuestro repositorio Github\n\nOfrecemos formación en R impartida por instructores con décadas de experiencia en epidemiología aplicada - envíanos un correo electrónico para hablar de ello.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.es.html#how-to-use-this-handbook",
    "href": "index.es.html#how-to-use-this-handbook",
    "title": "EpiRhandbook en español",
    "section": "Cómo utilizar este manual",
    "text": "Cómo utilizar este manual\n\nNavega por las páginas del índice o utiliza el cuadro de búsqueda\nClica en los iconos “Copy” para copiar el código\n\nPuedes seguir paso a paso las lecciones utilizando nuestros [datos de ejemplo][Download handbook and data]\n\nVersión sin conexión\nConsulta las instrucciones en la página de Descargar el Manual y los datos.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.es.html#acknowledgements",
    "href": "index.es.html#acknowledgements",
    "title": "EpiRhandbook en español",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nEste manual ha sido elaborado mediante la colaboración de profesionales de la epidemiología de todo el mundo, basándonos en nuestra experiencia en organismos sanitarios locales, estatales, provinciales y nacionales, la Organización Mundial de la Salud (OMS), Médicos Sin Fronteras (MSF), sistemas hospitalarios e instituciones académicas.\nEste manual no es un producto aprobado por ninguna organización específica. Aunque nos esforzamos por ser precisos, no ofrecemos ninguna garantía sobre el contenido de este libro.\n\nColaboradores\nRedactor jefe: Neale Batra\nEquipo central del proyecto: Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay Campbell\nAutores: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin\nRevisores: Pat Keating, Annick Lenglet, Margot Charette, Danielly Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga\nEquipo de traducción al español: Juan Carlos Fernández-Merino, Juan Francisco Monteagudo, Ximena Tolosa, Luis Hernando Aguilar Ramirez, Ignacio Castro Aguirre, Esther Kukielka, Cristina Torró, Ana Fernández-Ayuso. Se ha trabajado con el traductor online DeepL, ajustando manualmente los términos médicos epidemiológicos, estadísticos e informáticos específicos. Del mismo modo se han revisado todas las páginas para corregir defectos de estilo así como aplicar los acuerdos editoriales definidos por el equipo de traducción al español.\nIllustraciones: Calder Fong\n\n\n\n\n\n\nFinanciación y apoyo\nEste libro ha sido principalmente un esfuerzo voluntario que ha requerido miles de horas de trabajo.\nEl manual recibió apoyo financiaciero de TEPHINET, la red mundial de Programas de Formación en Epidemiología de Campo (FETP) a través de una subvención para el desarrollo de capacidades de emergencia COVID-19.\nLa Red de Antiguos Alumnos de (EAN) proporcionó apoyo administrativo, con un agradecimiento especial a Annika Wendland. EPIET es el Programa Europeo de Formación en Epidemiología de Intervención.\nUn agradecimiento especial a Médicos Sin Fronteras (MSF) Centro Operativo de Ámsterdam (OCA) por su apoyo durante la elaboración de este manual.\nEsta publicación fue respaldada por el Acuerdo de Cooperación número NU2GGH001873, financiado por los Centros para el Control y la Prevención de Enfermedades a través de TEPHINET, un programa de The Task Force for Global Health. Su contenido es responsabilidad exclusiva de los autores y no representa necesariamente las opiniones oficiales de los Centros para el Control y la Prevención de Enfermedades, el Departamento de Salud y Servicios Humanos, The Task Force for Global Health, Inc. o TEPHINET.\n\n\nInspiración\nHay multitud de tutoriales y viñetas que aportaron conocimientos para el desarrollo del contenido del manual y se acreditan en sus respectivas páginas.\nDe manera más general, las siguientes fuentes han servido de inspiración para este manual:\nEl proyecto “R4Epis” (una colaboración entre MSF y RECON)\nR Epidemics Consortium (RECON)\nEl libro R for Data Science (R4DS), en español en este enlace\nbookdown: Creación de libros y documentos técnicos con R Markdown\nNetlify alberga este sitio web",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.es.html#terms-of-use-and-contribution",
    "href": "index.es.html#terms-of-use-and-contribution",
    "title": "EpiRhandbook en español",
    "section": "Condiciones de uso y contribución",
    "text": "Condiciones de uso y contribución\n\nLicencia\nEsta obra está bajo una Licencia Internacional Creative Commons Attribution-NonCommercial-ShareAlike 4.0.\nLos cursos académicos y los programas de formación en epidemiología pueden utilizar este manual con sus estudiantes - por favor díganos. Si tienes preguntas sobre el uso que se le va a dar, envía un correo electrónico a contact@appliedepi.org.\n\n\nCita sugerida\nBatra, Neale, et al. Manual de R para Epidemiología. 2021. \n\n\nContribución\nSi quieres hacer una contribución de contenido, por favor, ponte en contacto con nosotros primero a través de Github o por correo electrónico. Estamos implementando un calendario de actualizaciones y estamos creando una guía para colaboradores.\nTen en cuenta que el proyecto epiRhandbook se publica con un Código de Conducta del Colaborador . Al contribuir a este proyecto, te comprometes a respetar sus términos.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.es.html",
    "href": "new_pages/editorial_style.es.html",
    "title": "1  Notas editoriales y técnicas",
    "section": "",
    "text": "1.1 Enfoque y estilo\nEl público potencial de este libro es amplio. Seguramente será utilizado tanto por personas muy noveles con R, como por usuarios experimentados buscando los mejores consejos y prácticas. Por lo tanto, este debe ser accesible y conciso a la vez. Por ello, nuestro enfoque fue proporcionar la información suficiente para que alguien muy nuevo en R pueda aplicar y seguir el código.\nOtros puntos:",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notas editoriales y técnicas</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.es.html#approach-and-style",
    "href": "new_pages/editorial_style.es.html#approach-and-style",
    "title": "1  Notas editoriales y técnicas",
    "section": "",
    "text": "Se trata de un libro de referencia de códigos acompañado de ejemplos relativamente breves, no de un libro de texto completo sobre R o ciencia de datos\nEste es un manual de R para su uso dentro de la epidemiología aplicada - no un manual sobre los métodos o ciencia de la epidemiología aplicada\nSe trata de un documento vivo: los paquetes de R óptimos para una tarea determinada cambian a menudo, por lo que agradecemos que exista debate sobre cuáles son los más empleados en el manual\n\n\nPaquetes de R\nMuchas opciones\nUno de los aspectos más difíciles de aprender en R es saber qué paquete utilizar para una tarea determinada. Es muy común pelearse con una tarea para luego darse cuenta de que ¡hay un paquete de R que hace todo eso en una línea de código!.\nEn este manual, tratamos de ofrecerte al menos dos maneras de completar cada tarea: un método probado y comprobado (probablemente en R base o tidyverse) y un paquete especial de R que está hecho a medida para ese propósito. Queremos que tengas un par de opciones en caso de que no puedas descargar un paquete determinado o de que éste no te funcione.\nA la hora de elegir los paquetes a utilizar, hemos dado prioridad a los paquetes y enfoques de R que han sido probados y aprobados por la comunidad, que minimizan el número de paquetes utilizados en una sesión de trabajo típica, que son estables (no cambian con frecuencia) y que realizan la tarea de forma sencilla y limpia.\nEn general, este manual da prioridad a los paquetes y funciones de R de tidyverse. Tidyverse es una colección de paquetes de R diseñados para ciencia de datos que comparten la gramática y estructuras de datos subyacentes. Todos los paquetes tidyverse pueden instalarse o cargarse a través del paquete tidyverse. Más información en el sitio web de tidyverse.\nCuando es aplicable, también ofrecemos opciones de código usando R base - los paquetes y funciones que vienen con R en la instalación. Esto se debe a que somos conscientes de que parte de la audiencia de este libro podría no tener una buena conexión a internet para descargar paquetes adicionales.\nVinculación explícita de las funciones a los paquetes\nEs frustrante cuando en algunos tutoriales de R, se muestra una función (en código), pero no se sabe bien de qué paquete es. En este libro intentamos evitar esta situación.\nEn el texto explicativo, los nombres de los paquetes se escriben en negrita (por ejemplo, dplyr) y las funciones se escriben así: mutate(). Nos esforzaremos en dejar claro el paquete del que proviene una función, ya sea haciendo referencia al paquete en el texto o especificando el paquete en el código mediante esta sintaxis: dplyr::mutate(). Puede parecer redundante, pero lo hacemos a propósito.\nConsulta la página sobre fundamentos de R para saber más sobre los paquetes y las funciones.\n\n\nCódigo de estilo\nEn el manual, utilizamos con frecuencia “líneas nuevas”, haciendo que nuestro código parezca “largo”. Lo hacemos por varias razones:\n\nDe esta forma se pueden escribir comentarios explicativos con #, los cuales están situados adyacentes a cada línea de código\nEn general, el código más largo (en vertical) es más fácil de leer\nEs más fácil de leer en una pantalla estrecha (no es necesario desplazarse lateralmente)\nCon las sangrías, puede ser más fácil saber qué argumentos pertenecen a cada función\n\nComo resultado, el código que podría estar escrito:\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;%  # filas agrupadas por hospital\n  slice_max(date, n = 1, with_ties = F) # si hay un empate (de fecha), tomar la primera fila\n\n…pero se escribe así:\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% # filas agrupadas por hospital\n  slice_max(\n    date,                # mantener la fila por grupo con el valor máximo de la fecha \n    n = 1,               # mantener sólo la fila más alta\n    with_ties = F)       # si hay un empate (de fecha), tomar la primera fila\n\nEl código de R generalmente no se ve afectado por nuevas líneas o sangrías. Al escribir el código, si se inicia una nueva línea después de una coma, se aplicarán patrones de sangría automáticos.\nTambién utilizamos muchos espacios (por ejemplo, n = 1 en lugar de n=1) porque es más fácil de leer. ¡Sé amable con la gente que lee tu código!\n\n\nNomenclatura\nEn este manual, generalmente hacemos referencia a “columnas” y “filas” en lugar de “variables” y “observaciones”. Como se explica en este manual sobre “datos ordenados”, la mayoría de los conjuntos de datos estadísticos epidemiológicos se componen estructuralmente de filas, columnas y valores.\nLas variables contienen los valores que miden el mismo atributo subyacente (como el grupo de edad, el resultado o la fecha de inicio). Las observaciones contienen todos los valores medidos en la misma unidad (por ejemplo, una persona, un lugar o una muestra de laboratorio). Por lo tanto, estos aspectos pueden ser más difíciles de definir de forma tangible.\nEn los conjuntos de datos “ordenados”, cada columna es una variable, cada fila es una observación y cada celda es un único valor. Sin embargo, algunos conjuntos de datos que se encuentran no se ajustan a este molde: unos datos de formato “amplio” puede tener una variable dividida en varias columnas (véase un ejemplo en la página Pivotar datos). Del mismo modo, las observaciones pueden estar divididas en varias filas.\nLa mayor parte de este manual trata sobre la gestión y la transformación de datos, por lo que las referencias a las estructuras de datos concretas de filas y columnas son más relevantes que las observaciones y las variables más abstractas. Las excepciones se dan sobre todo en las páginas sobre análisis de datos, en las que verás más referencias a las variables y las observaciones.\n\n\nNota\nHere are the types of notes you may encounter in the handbook:\nNOTA: Esto es una nota\nCONSEJO: Esto es un consejo.\nPRECAUCIÓN: Esto es una nota de precaución.\nPELIGRO Esto es un aviso (warning).",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notas editoriales y técnicas</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.es.html#editorial-decisions",
    "href": "new_pages/editorial_style.es.html#editorial-decisions",
    "title": "1  Notas editoriales y técnicas",
    "section": "1.2 Decisiones editoriales",
    "text": "1.2 Decisiones editoriales\nA continuación, hacemos un seguimiento de las decisiones editoriales importantes en torno a la elección de paquetes y funciones. Si no estás de acuerdo o quieres ofrecer una nueva herramienta para que la consideremos, únete o inicia una conversación en nuestra página de Github.\nTabla de paquetes, funciones y otras decisiones editoriales\n\n\n\n\n\n\n\n\n\nAsunto\nConsiderado\nResultado\nBreve explicación\n\n\n\n\nEnfoque general de codificación\ntidyverse, data.table, base\ntidyverse, con una página sobre data.table, y menciones de alternativas de R base para los lectores sin internet\nlegibilidad de tidyverse, universalidad, más enseñado\n\n\nCarga de paquetes\nlibrary(),install.packages(), require(), pacman\npacman\nAcorta y simplifica el código para la mayoría de los casos de instalación/carga de paquetes múltiples\n\n\nImportación y exportación\nrio, muchos otros paquetes\nrio\nFacilidad para muchos tipos de archivos\n\n\nAgrupación para las estadísticas de síntesis\ndplyr group_by(), stats aggregate()\ndplyr group_by()\nConsecuente con el énfasis en tidyverse\n\n\nPivotar tablas\ntidyr (funciones de pivote), reshape2 (melt/cast), tidyr (spread/gather)\ntidyr (funciones de pivote)\nreshape2 se ha retirado, tidyr utiliza funciones pivot a partir de la v1.0.0\n\n\nLimpiar los nombres de las columnas\nlinelist, janitor\njanitor\nSe hace hincapié en la consolidación de los paquetes\n\n\nSemanas epidemiológicas. Epiweeks\nlubridate, aweek, tsibble, zoo\nNormalmente lubridate, los otros para casos específicos\nLa flexibilidad, la coherencia y las perspectivas de mantenimiento de los paquetes de lubridate\n\n\nEtiquetas ggplot\nlabs(), ggtitle()/ylab()/xlab()\nlabs()\nTodas las etiquetas en un solo lugar, la simplicidad\n\n\nConvertir en factor\nfactor(), forcats\nforcats\nSus diversas funciones también se convierten en factor en el mismo comando\n\n\nCurvas epidémicas\nincidence, ggplot2, EpiCurve\nincidence2 por rapidez, **ggplot2** para tareas detalladas|fiabilidad Concatenación|paste(),paste0(),str_glue(),glue()|str_glue()`\nSintaxis más sencilla que las funciones de pegado; dentro de stringr",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notas editoriales y técnicas</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.es.html#major-revisions",
    "href": "new_pages/editorial_style.es.html#major-revisions",
    "title": "1  Notas editoriales y técnicas",
    "section": "1.3 Revisiones importantes",
    "text": "1.3 Revisiones importantes\n\n\n\nFecha\nCambios mayores\n\n\n\n\n10 Mayo 2021\nLanzamiento de la versión 1.0.0",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notas editoriales y técnicas</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.es.html#session-info-r-rstudio-packages",
    "href": "new_pages/editorial_style.es.html#session-info-r-rstudio-packages",
    "title": "1  Notas editoriales y técnicas",
    "section": "1.4 Información de la sesión (R, RStudio, paquetes)",
    "text": "1.4 Información de la sesión (R, RStudio, paquetes)\nA continuación se presenta la información sobre las versiones de R, RStudio y los paquetes de R utilizados en esta versión del Manual.\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31 ucrt)\n os       Windows 11 x64 (build 22621)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       Europe/Stockholm\n date     2024-05-10\n pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.2   2023-12-11 [2] CRAN (R 4.3.2)\n digest        0.6.35  2024-03-11 [1] CRAN (R 4.3.3)\n evaluate      0.23    2023-11-01 [2] CRAN (R 4.3.2)\n fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.3.2)\n htmltools     0.5.8   2024-03-25 [1] CRAN (R 4.3.3)\n htmlwidgets   1.6.4   2023-12-06 [2] CRAN (R 4.3.2)\n jsonlite      1.8.8   2023-12-04 [2] CRAN (R 4.3.2)\n knitr         1.45    2023-10-30 [2] CRAN (R 4.3.2)\n rlang         1.1.3   2024-01-10 [2] CRAN (R 4.3.2)\n rmarkdown     2.26    2024-03-05 [1] CRAN (R 4.3.3)\n rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.3.2)\n sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.3.2)\n xfun          0.43    2024-03-25 [1] CRAN (R 4.3.3)\n\n [1] C:/Users/ngulu864/AppData/Local/R/win-library/4.3\n [2] C:/Program Files/R/R-4.3.2/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notas editoriales y técnicas</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.es.html",
    "href": "new_pages/data_used.es.html",
    "title": "2  Descargando el manual y los datos",
    "section": "",
    "text": "2.1 Descargar el manual sin conexión\nPuedes descargar la versión sin conexión de este manual. Éste es un archivo HTML que puedes ver en tu navegador web sin acceder a Internet. Si estás pensando en utilizar este manual sin conexión, debes tener en cuenta algunas cosas:\nHay dos maneras de descargar el manual:",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descargando el manual y los datos</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.es.html#download-offline-handbook",
    "href": "new_pages/data_used.es.html#download-offline-handbook",
    "title": "2  Descargando el manual y los datos",
    "section": "",
    "text": "Al abrir el archivo, las imágenes y el índice pueden tardar uno o dos minutos en cargarse.\nEste manual tiene un diseño ligeramente diferente: una página muy larga con el índice a la izquierda. Para buscar términos específicos utiliza Ctrl+f (Cmd-f)\nConsulta la página de Paquetes recomendados para ayudarte a instalar los paquetes de R adecuados antes de que pierdas la conectividad a Internet\nInstala nuestro paquete R epirhandbook que contiene todos los datos del ejemplo (el proceso de instalación se describe a continuación)\n\n\n\nUtilizando el enlace de descarga\nPara acceder rápidamente, clica con el botón derecho en este enlace y selecciona “Guardar enlace como”.\nSi es un Mac, utiliza Cmd+clic. Si es un móvil, mantén clicado el enlace y selecciona “Guardar enlace”. El manual se descargará en el dispositivo. Si aparece una pantalla con código HTML sin procesar, asegúrate de haber seguido las instrucciones anteriores o prueba la opción 2.\n\n\nUtilizando nuestro paquete R\nOfrecemos un paquete llamado epirhandbook. Este incluye la función download_book() que descarga el archivo del manual desde nuestro repositorio de Github a tu ordenador.\nEste paquete también contiene una función get_data() que descarga todos los datos del ejemplo en tu ordenador.\nEjecuta el siguiente código para instalar nuestro paquete R epirhandbook desde el repositorio de Github appliedepi. Este paquete no está en CRAN, así que utiliza la función especial p_install_gh() para instalarlo desde Github.\n\n# instalar la última versión del paquete Epi R Handbook\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nAhora, puedes cargar el paquete para utilizarlo en la sesión actual de R:\n\n# cargar el paquete para utilizarlo\npacman::p_load(epirhandbook)\n\nA continuación, ejecuta la función del paquete download_book() (con los paréntesis vacíos) para descargar el manual en tu ordenador. Suponiendo que estés en RStudio, aparecerá una ventana que te permitirá seleccionar una ubicación para guardarlo.\n\n# descargar el manual offline en la computadora\ndownload_book()",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descargando el manual y los datos</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.es.html#download-data-to-follow-along",
    "href": "new_pages/data_used.es.html#download-data-to-follow-along",
    "title": "2  Descargando el manual y los datos",
    "section": "2.2 Descarga los datos para seguir el manual",
    "text": "2.2 Descarga los datos para seguir el manual\nPara “seguir” las páginas del manual, puedes descargar los datos y los resultados de los ejemplos.\n\nUtiliza nuestro paquete para R\nEl método más sencillo para descargar todos los datos es instalar nuestro paquete epirhandbook. Contiene una función get_data() que guarda todos los datos del ejemplo en una carpeta de tu elección en tu ordenador.\nPara instalar nuestro paquete epirhandbook, ejecuta el siguiente código. Este paquete no está en CRAN, así que utiliza la función p_install_gh() para instalarlo. La entrada hace referencia a nuestra organización de Github (“appliedepi”) y al paquete epirhandbook.\nepirhandbook package.\n\n# instalae la última versión del paquete Epi R Handbook\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nAhora, carga el paquete para utilizarlo en tu sesión actual de R:\n\n# cargar el paquete para utilizarlo\npacman::p_load(epirhandbook)\n\nA continuación, utiliza la función get_data() del paquete para descargar los datos de ejemplo en tu ordenador. Ejecuta get_data(“all”) para obtener todos los datos de ejemplo, o escribe un nombre de archivo específico y una extensión entre comillas para recuperar sólo un archivo.\nLos datos ya se han descargado con el paquete, y sólo hay que transferirlos a una carpeta del ordenador. Aparecerá una ventana emergente para seleccionar la ubicación de la carpeta de almacenamiento. Te sugerimos que crees una nueva carpeta de “datos”, ya que hay unos 30 archivos (incluidos los datos de ejemplo y los resultados de ejemplo).\n\n# descargar todos los datos de ejemplos en la computadora\nget_data(\"all\")\n\n# descargar solo los datos del ejemplo listado limpio\nget_data(file = \"linelist_cleaned.rds\")\n\n\n# descargar solo un archivo específoco en la computadora\nget_data(\"linelist_cleaned.rds\")\n\nUna vez que hayas utilizado get_data() para guardar un archivo en tu ordenador, tendrás que importarlo a R. Consulta la página de importación y exportación para más detalles.\nSi lo deseas, puedes revisar todos los datos utilizados en este manual en la carpeta “data” de nuestro repositorio de Github.\n\n\nDescargar uno por uno\nEsta opción implica la descarga de los datos archivo por archivo desde nuestro repositorio de Github a través de un enlace o un comando de R específico para el archivo. Algunos tipos de archivos permiten un botón de descarga, mientras que otros pueden descargarse mediante un comando de R.\n\nLinelist\nSe trata de un brote de ébola ficticio, ampliado por el equipo del manual a partir de los datos ebola_sim de las prácticas del paquete Outbreaks.\n\nClica para descargar Linelist (con los casos) “en bruto” -raw- (.xlsx). Este listado de casos “en bruto” es una hoja de cálculo de Excel con datos desordenados. Utilízala para seguir la página de limpieza de datos y funciones básicas.\nClica para descargar Linelist “en limpio”. Utiliza este archivo para todas las demás páginas de este manual que utilizan el listado de casos. Un archivo .rds es un tipo de archivo específico de R que conserva los tipos de columnas. Esto asegura que sólo tendrás que hacer una limpieza mínima después de importar los datos a R.\n\nOtros archivos relacionados:\n\nClica para descargar el listado de casos “en limpio” como archivo Excel.\nParte de la página de limpieza utiliza un “diccionario de limpieza” (archivo .csv). Puedes cargarlo directamente en R ejecutando los siguientes comandos:\n\n\npacman::p_load(rio) # instalar/cargar el paquete rio \n\n# importar el archivo directamente desde Github\ncleaning_dict &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv\")\n\n\n\nRecuento de datos de malaria\nEstos datos son recuentos ficticios de casos de malaria por grupos de edad, centro y día. Un archivo .rds es un tipo de archivo específico de R que conserva los tipos de columnas. Esto asegura que sólo tendrás que hacer una limpieza mínima después de importar los datos a R.\nClica para descargar los datos del recuento de casos de malaria (archivo .rds)\n\n\nDatos en escala Likert\nSe trata de datos ficticios de una encuesta tipo Likert, utilizados en la página sobre Pirámides de población y escalas de Likert. Puedes cargar estos datos directamente en R ejecutando los siguientes comandos:\n\npacman::p_load(rio) # instalar/cargar el paquete rio\n\n# importar el fichero directamente de Github\nlikert_data &lt;- import(\"https://raw.githubusercontent.com/appliedepi/epirhandbook_eng/master/data/likert_data.csv\")\n\n\n\nFlexdashboard\nA continuación se encuentran los enlaces al archivo asociado a la página sobre Dashboards con R Markdown:\n\nPara descargar el código de R Markdown para el dashboard (panel de control) del brote, clica con el botón derecho en este enlace (Cmd+clic para Mac) y luego “Guardar enlace como”.\nPara descargar el código HTML del dashboard, clica con el botón derecho en este enlace (Cmd+clic para Mac) y luego “Guardar enlace como”.\n\n\n\nRastreo de contactos\nLa página de rastreo de contactos muestra el análisis de los datos de rastreo de contactos, utilizando como ejemplo datos de Go.Data. Los datos utilizados en la página pueden descargarse como archivos .rds clicando en los siguientes enlaces:\nClica para descargar los datos de la investigación de casos (archivo .rds)\nClica para descargar los datos de registro de los contactos (archivo .rds)\nClica para descargar los datos de seguimiento de los contactos (archivo .rds)\nNOTA: Los datos de rastreo de contactos estructurados de otro software (por ejemplo, KoBo, DHIS2 Tracker, CommCare) pueden tener un aspecto diferente. Si quieres contribuir con una muestra de datos alternativos o con contenido para esta página, por favor, ponte en contacto, con nosotros.\nCONSEJO: Si estás utilizando Go.Data y quieres conectarte a tu instancia de la API, consulta la página de importación y exportación (sección API) y la Comunidad de Prácticas de Go.Data.\n\n\nSIG (GIS)\nLos archivos geográficos tipo shapefile tienen varios archivos subcomponentes, cada uno con una extensión de archivo diferente. Un archivo tendrá la extensión “.shp”, pero otros tienen la extensión “.dbf”, “.prj”, etc.\nLa página de Conceptos básicos de los SIG contiene enlaces al sitio web de Humanitarian Data Exchange, donde se pueden descargar los shapefiles directamente como archivos comprimidos.\nPor ejemplo, los datos de los puntos de las instalaciones sanitarias se pueden descargar de aquí. Descarga “hotosm_sierra_leone_health_facilities_points_shp.zip”. Una vez guardado en tu ordenador, “descomprime” la carpeta. Ahí vas a encontrar varios archivos con diferentes extensiones (por ejemplo, “.shp”, “.prj”, “.shx”) todos ellos deben guardarse en la misma carpeta. A continuación, para importar en R, proporciona la ruta completa y el nombre del archivo “.shp” a st_read() del paquete sf (como se describe en la página de Conceptos básicos de los SIG).\nSi sigues la opción 1 para descargar todos los datos de ejemplo (a través de nuestro paquete epirhandbook), todos los shapefiles están incluidos en el paquete.\nTambién puedes descargar los shapefiles de la carpeta “data” de R Handbook Github (véase la subcarpeta “gis”). Sin embargo, ten en cuenta que tendrás que descargar cada subfichero individualmente en tu ordenador. En Github, clica en cada archivo individualmente y descárgalo clicando en el botón “Download”. A continuación, puedes ver cómo el shapefile “sle_adm3” consta de muchos archivos, cada uno de los cuales tendría que ser descargado de Github.\n\n\n\n\n\n\n\n\n\n\n\nÁrboles filogenéticos\nMira la página sobre árboles filogenéticos. El archivo Newick con el árbol filogenético construido a partir de la secuenciación del genoma completo de 299 muestras de Shigella sonnei y los datos de las muestras correspondientes (convertidos en un archivo de texto). Las muestras belgas y los datos resultantes han sido proporcionados amablemente por el NRC belga para Salmonella y Shigella en el marco de un proyecto dirigido por un fellow del programa ECDC EUPHEM, y también se publicarán en un manuscrito. Los datos internacionales están disponibles en bases de datos públicas (ncbi) y han sido publicados previamente.\n\nPara descargar el archivo del árbol filogenético “Shigella_tree.txt”, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”.\nPara descargar el archivo “sample_data_Shigella_tree.csv” con información adicional sobre cada muestra, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”.\nPara ver el nuevo árbol de subconjuntos creado, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”. El archivo .txt se descargará en tu ordenador.\n\nTras la descarga, se pueden importar los archivos .txt con la función read.tree() del paquete ape, como se explica en la página.\n\nape::read.tree(\"Shigella_tree.txt\")\n\n\n\nEstandarización\nConsulta la página de tasas estandarizadas. Puedes cargar los datos directamente desde nuestro repositorio de Github en Internet en tu sesión de R con los siguientes comandos:\n\n# instalar/cargar el paquete rio\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# importar demographics del país A directamente desde Github\nA_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# importar defunciones del país A directamente desde Github\nA_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# importar demographics del país B directamente desde Github\nB_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# importar defunciones del país B directamente desde Github\nB_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n##########################\n# Población de referencia#\n##########################\n# importar demographics del país B directamente desde Github\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\n\n\nSeries temporales y detección de brotes\nVéase la página sobre series temporales y detección de brotes. Utilizamos los casos de campylobacter notificados en Alemania entre 2002 y 2011, disponibles en el paquete R surveillance. (nb. este conjunto de datos ha sido adaptado del original, en el sentido de que se han eliminado 3 meses de datos de finales de 2011 para fines de demostración).\nClica para descargar Campylobacter en Alemania (.xlsx)\nTambién utilizamos datos climáticos de Alemania de 2002 a 2011 (temperatura en grados centígrados y lluvia caída en milímetros). Estos datos se descargaron de los datos del reanálisis por satélite Copernicus de la UE utilizando el paquete ecmwfr. Tendrás que descargarlos todos e importarlos con stars::read_stars() como se explica en la página de series temporales.\nClica para descargar el tiempo de Alemania 2002 (archivo .nc)\nClica para descargar el tiempo de Alemania 2003 (archivo .nc)\nClica para descargar el tiempo en Alemania 2004 (archivo .nc)\nClica para descargar el tiempo en Alemania 2005 (archivo .nc)\nClica para descargar el tiempo en Alemania 2006 (archivo .nc)\nClica para descargar el tiempo de Alemania 2007 (archivo .nc)\nClica para descargar el tiempo de Alemania 2008 (archivo .nc)\nClica para descargar el tiempo en Alemania 2009 (archivo .nc)\nClica para descargar el tiempo en Alemania 2010 (archivo .nc)\nClica para descargar el tiempo en Alemania 2011 (archivo .nc)\n\n\nAnálisis de encuestas\nPara el capítulo sobre análisis de encuestas utilizamos datos ficticios de encuestas de mortalidad basados en las plantillas de encuestas de MSF OCA. Estos datos ficticios se generaron como parte del proyecto “R4Epis”.\nClica para descargar los datos de la encuesta ficticia (.xlsx)\nClica para descargar el diccionario de datos de la encuesta ficticia (.xlsx)\nClica para descargar los datos de la población de la encuesta ficticia (.xlsx)\n\n\nShiny\nEl capítulo sobre Dashboards con Shiny demuestra la construcción de una sencilla aplicación para mostrar datos sobre la malaria.\nPara descargar los archivos R que producen la aplicación Shiny:\nPuedes clicar aquí para descargar el archivo app.R que contiene tanto la interfaz de usuario como el código del servidor para la aplicación Shiny.\nPuedes clicar aquí para descargar el archivo facility_count_data.rds que contiene datos sobre la malaria para la aplicación Shiny. Ten en cuenta que puede ser necesario almacenarlo dentro de una carpeta “data” para que las rutas de los archivos here() funcionen correctamente.\nPuedes clicar aquí para descargar el archivo global.R que debe ejecutarse antes de que se abra la aplicación, como se explica en dicho capítulo.\nPuedes clicar aquí para descargar el archivo plot_epicurve.R que es originado por global.R. Ten en cuenta que puede necesitar almacenarlo dentro de una carpeta “funcs” para que las rutas de los archivos here() funcionen correctamente.",
    "crumbs": [
      "Acerca de este libro",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descargando el manual y los datos</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html",
    "href": "new_pages/basics.es.html",
    "title": "3  Fundamentos de R",
    "section": "",
    "text": "3.1 ¿Por qué utilizar R?\nComo se indica en el sitio web de R project, éste es un lenguaje de programación y un entorno para la computación estadística y gráficos. Es muy versátil, ampliable y dirigido por la comunidad.\nCoste\nEl uso de R es gratuito. Hay una fuerte ética en la comunidad de material libre y de código abierto.\nReproducibilidad\nLa gestión y el análisis de los datos a través de un lenguaje de programación (en comparación con Excel u otra herramienta principalmente manual) mejora la reproducibilidad, facilita la detección de errores y alivia la carga de trabajo.\nComunidad\nLa comunidad de usuarios de R es enorme y colaborativa. Cada día se desarrollan nuevos paquetes y herramientas para abordar problemas cotidianos, que son examinados por la comunidad de usuarios. Por ejemplo, R-Ladies es una asociación mundial cuya misión es promover la diversidad de género en la comunidad de R, siendo una de las mayores asociaciones de usuarios de R. Es probable que tengas un grupo cerca.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#key-terms",
    "href": "new_pages/basics.es.html#key-terms",
    "title": "3  Fundamentos de R",
    "section": "3.2 Términos clave",
    "text": "3.2 Términos clave\nRStudio - RStudio es una interfaz gráfica de usuario (GUI) para facilitar el uso de R. Lee más en la sección RStudio.\nObjetos - Todo lo que se almacena en R - conjuntos de datos, variables, una lista de nombres de pueblos, un número total de población, incluso resultados como gráficos - son objetos a los que se les asigna un nombre y pueden ser referenciados en comandos posteriores. Lee más en la sección Objetos.\nFunciones - Una función es una operación de código que acepta entradas y devuelve una salida transformada. Lee más en la sección Funciones.\nPaquetes - Un paquete de R es un conjunto de funciones que se pueden compartir. Lee más en la sección Paquetes.\nScripts - Un script es un archivo que contiene una serie comandos. Lee más en la sección Scripts",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#learning",
    "href": "new_pages/basics.es.html#learning",
    "title": "3  Fundamentos de R",
    "section": "3.3 Recursos para aprender",
    "text": "3.3 Recursos para aprender\n\nRecursos en RStudio\nDocumentación de ayuda\nBusca en la pestaña “Help” de RStudio la documentación sobre los paquetes de R y funciones específicas. Esto está dentro del panel que también contiene Archivos, Gráficos y Paquetes (normalmente en el panel inferior derecho). También puedes escribir el nombre de un paquete o función en la consola de R después de un signo de interrogación para abrir la página de ayuda correspondiente. No incluyas paréntesis.\nPor ejemplo: ?filter o ?diagrammeR.\nTutoriales interactivos\nHay varias formas de aprender R de forma interactiva dentro de RStudio.\nEl propio RStudio ofrece un Tutorial que se encuentra en el paquete de R learnr. Simplemente instala este paquete y abre un tutorial a través de la nueva pestaña “Tutorial” en el panel superior derecho de RStudio (que también contiene las pestañas Environment e History).\nEl paquete de R swirl ofrece cursos interactivos en la consola de R. Instala y carga este paquete, luego ejecuta el comando swirl() (paréntesis vacío) en la consola de R. Verás que aparecen indicaciones en la consola. Responde escribiendo en la misma. Te guiará a través de un curso de tu elección.\n\n\nHojas de referencia\nHay muchas “hojas de referencias o trucos” (Cheatsheets) en PDF disponibles en el sitio web de RStudio, por ejemplo:\n\nFactores con el paquete forcats\nFechas y horarios con el paquete lubridate\nCadenas con el paquete stringr\nOperaciones iterativas con el paquete purrr\nImportación de datos\nTransformación de datos con el paquete dplyr\nR Markdown (para crear documentos como PDF, Word, Powerpoint…)\nShiny (para crear aplicaciones web interactivas)\nVisualización de datos con el paquete ggplot2\nCartografía (GIS)\nMapas interactivos con el paquete leaflet\nPython con R (paquete reticulate)\n\nEn este enlace puedes encontrar un recurso en línea, específicamente para los usuarios de Excel\n\n\nTwitter\nR tiene una vibrante comunidad en Twitter en la que puedes aprender trucos, atajos y noticias: sigue estas cuentas:\n\nSíguenos! @epiRhandbook\nR Function A Day @rfuntionaday (Es un recurso increíble)\nR para ciencia de datos @rstats4ds\nRStudio @RStudio\nTrucos de RStudio @rstudiotips\nR-Bloggers @Rbloggers\nR-ladies @RLadiesGlobal\nHadley Wickham @hadleywickham\n\nTambién:\n#epitwitter y #rstats\n\n\nRecursos gratuitos en línea\nUn texto definitivo es el libro R for Data Science de Garrett Grolemund y Hadley Wickham\nEl sitio web del proyecto R4Epis tiene como objetivo “desarrollar herramientas estandarizadas de limpieza de datos, análisis y elaboración de informes para cubrir los tipos comunes de brotes y estudios realizados en la población en un entorno de respuesta de emergencia de MSF”. Se pueden encontrar materiales de formación sobre los fundamentos de R, plantillas para informes de RMarkdown sobre brotes y encuestas, y tutoriales para ayudar a configurarlos.\n\n\nIdiomas distintos del inglés\nMateriales de RStudio en Español\nR for Data Science en español\nIntroduction à R et au tidyverse (Francais)",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#Installation",
    "href": "new_pages/basics.es.html#Installation",
    "title": "3  Fundamentos de R",
    "section": "3.4 Instalación",
    "text": "3.4 Instalación\n\nR y RStudio\nCómo instalar R\nVisita este sitio web https://www.r-project.org/ y descarga la última versión de R adecuada a tu ordenador.\nCómo instalar RStudio\nVisita este sitio web https://rstudio.com/products/rstudio/download/ y descarga la última versión gratuita de RStudio para escritorio adecuada para tu ordenador.\nPermisos \nTen en cuenta que debes instalar R y RStudio en una unidad donde tengas permisos de lectura y escritura. De lo contrario, la capacidad para instalar paquetes de R (algo frecuente) se verá afectada. Si tienes problemas, intenta abrir RStudio con el botón derecho en el icono y seleccionando “Ejecutar como administrador”. Puedes encontrar otros consejos en la página R en unidades de red.\nCómo actualizar R y RStudio\nTu versión de R se muestra al inicio de la consola de R. También puede ejecutar sessionInfo().\nPara actualizar R, puedes ir al sitio web mencionado anteriormente y vuelva a instalar R. También puede utilizar el paquete installr (en Windows) ejecutando installr::updateR(). Esto abrirá cuadros de diálogo para ayudarle a descargar la última versión de R y actualizar sus paquetes a la nueva versión de R. Puedes encontrar más detalles en la documentación de installr.\nTen en cuenta que la versión antigua de R seguirá existiendo en tu ordenador. Puedes ejecutar temporalmente una versión anterior (una “instalación” más antigua) de R clicando en “Herramientas” -&gt; “Opciones globales” en RStudio y eligiendo una versión de R. Esto puede ser útil si quieres utilizar un paquete que no ha sido actualizado para funcionar en la versión más reciente de R.\nPara actualizar RStudio, puede ir a la página web anterior y volver a descargar RStudio. Otra opción es clicar en “Ayuda” -&gt; “Buscar actualizaciones” dentro de RStudio, pero esto puede no mostrar las últimas actualizaciones.\nPara ver qué versiones de R, RStudio o paquetes se utilizaron cuando se hizo este Manual, consulta la página de Notas técnicas y editoriales.\n\n\nOtros programas que puedes necesitar instalar\n\nTinyTeX (para compilar un documento RMarkdown en PDF)\nPandoc (para compilar documentos RMarkdown)\nRTools (para construir paquetes para R)\nphantomjs (para guardar imágenes fijas de redes animadas, como cadenas de transmisión)\n\n\nTinyTex\nTinyTex es una distribución LaTeX personalizada, útil cuando se trata de producir PDFs desde R. Ver https://yihui.org/tinytex/ para más información.\nPara instalar TinyTex desde R:\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# para desinstalar TinyTeX, ejecutar tinytex::uninstall_tinytex()\n\n\n\nPandoc\nPandoc es un conversor de documentos, un software separado de R. Viene incluido con RStudio y no debería ser necesario descargarlo. Ayuda en el proceso de conversión de documentos Rmarkdown a distintos formatos como pdf o html y añade funcionalidades complejas.\n\n\nRTools\nRTools es una colección de software para construir paquetes para R\nSe instala desde este sitio web:https://cran.r-project.org/bin/windows/Rtools/\n\n\nphantomjs\nEsto se utiliza a menudo para hacer “capturas de pantalla” de las páginas web. Por ejemplo, cuando se hace una cadena de transmisión con el paquete epicontacts, se produce un archivo HTML que es interactivo y dinámico. Si deseas una imagen estática, puede ser útil utilizar el paquete webshot para automatizar este proceso. Para ello se necesita el programa externo “phantomjs”. Puedes instalar phantomjs a través del paquete webshot con el comando webshot::install_phantomjs().",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#rstudio",
    "href": "new_pages/basics.es.html#rstudio",
    "title": "3  Fundamentos de R",
    "section": "3.5 RStudio",
    "text": "3.5 RStudio\n\nOrientación de RStudio\nPrimero, abre RStudio. Como sus iconos pueden ser muy similares, asegúrate de que estás abriendo RStudio y no R.\nPara que RStudio funcione, también debes tener instalado R en el ordenador (consulta las instrucciones de instalación más arriba).\nRStudio es una interfaz (GUI) para facilitar el uso de R. Puedes pensar que R es el motor de un vehículo, que hace el trabajo crucial, y RStudio es la carrocería del vehículo (con asientos, accesorios, etc.) que te ayuda a usar el motor para avanzar. Puedes ver la hoja de trucos completa de la interfaz de usuario de RStudio (PDF) aquí\nPor defecto, RStudio muestra cuatro paneles rectangulares.\n\n\n\n\n\n\n\n\n\nCONSEJO: Si tu RStudio sólo muestra un panel izquierdo es porque aún no tiene ningún script abierto.\nEl panel Source\nEste panel de código Fuente u origen, por defecto en la parte superior izquierda, es un espacio para editar, ejecutar y guardar tus scripts. Los scripts contienen los comandos que desea ejecutar. Este panel también puede mostrar conjuntos de datos (data frames) para su visualización.\nPara los usuarios de Stata, este panel es similar a las ventanas de Do-file y del Editor de Datos.\nEl panel Console\nLa consola de R es el hogar del “motor” de R es, por defecto, el panel izquierdo o inferior izquierdo en R Studio. Aquí es donde se ejecutan realmente los comandos y aparecen las salidas no gráficas y los mensajes de error/advertencia. Puedes introducir y ejecutar directamente comandos en la Consola de R, pero ten en cuenta que estos comandos no se guardan como cuando se ejecutan comandos desde un script.\nSi estás familiarizado con Stata, la consola de R es como la ventana de comandos y también la ventana de resultados.\nEl panel Environment\nEste panel de Entorno, por defecto en la parte superior derecha, se utiliza más a menudo para ver breves resúmenes de los objetos en el Entorno R en la sesión actual. Estos objetos pueden incluir conjuntos de datos importados, modificados o creados, parámetros que hayas definido (por ejemplo, una semana epi específica para el análisis), o vectores o listas que hayas definido durante el análisis (por ejemplo, nombres de regiones). Puedes clicar en la flecha situada junto al nombre de un dataframe para ver sus variables.\nEn Stata, esto es muy similar a la ventana del Gestor de Variables.\nEste panel también contiene History donde puede ver los comandos ejecutados anteriormente. También tiene una pestaña “Tutorial” donde puedes completar tutoriales interactivos de R si tienes el paquete learnr instalado. También tiene una pestaña de “Conexiones” para las conexiones externas, y puede tener un panel “Git” si decides interactuar con Github.\nPanel Files, Plots, Packages, Help, Viewer Este panel inferior derecho incluye varias pestañas importantes. La pestaña Files (Archivos) permite navegar por las carpetas y puede utilizarse para abrir o eliminar archivos. En la pestaña Plots (Gráficos), se mostrarán todos los gráficos, incluyendo los mapas. Las salidas interactivas o HTML se mostrarán en la pestaña Viewer (Visor). El panel Packages (Paquetes) permite ver, instalar, actualizar, eliminar, cargar/descargar paquetes de R y ver qué versión del paquete tiene. En la sección de paquetes más abajo se puede aprender más sobre los paquetes. Por último, en el panel de Ayuda (Help) se mostrará la documentación y los archivos de ayuda.\nEste panel contiene los equivalentes en Stata de las ventanas Plots Manager y Project Manager.\n\n\nConfiguración de RStudio\nCambia la configuración y la apariencia de RStudio en el menú desplegable Tools (Herramientas), seleccionando Global Options (Opciones globales). Allí puede cambiar la configuración por defecto, incluyendo la apariencia/color de fondo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReiniciar\nSi se cuelga R, se puede reiniciar yendo al menú Sesión y clicando en “Restart R” (Reiniciar R)“. Esto evita la molestia de cerrar y abrir RStudio. Al hacer esto, se eliminará todo el entorno de esa sesión de R.\n\n\nAtajos de teclado\nAlgunos atajos de teclado muy útiles están abajo. Se pueden ver todos los atajos de teclado para Windows, Max y Linux en la segunda página de esta hoja de trucos de la interfaz de usuario de RStudio.\n\n\n\n\n\n\n\n\nWindows/Linux\nMac\nAcción\n\n\n\n\nEsc\nEsc\nInterrumpir el comando actual (útil si accidentalmente ejecutó un comando incompleto y no puede evitar ver “+” en la consola de R)\n\n\nCtrl+s\nCmd+s\nGuardar (script)\n\n\nTab\nTab\nAutocompletar\n\n\nCtrl + Enter\nCmd + Enter\nEjecutar la(s) línea(s) de código actual(es)\n\n\nCtrl + Mayús + C\nCmd + Shift + c\nComentar/descomentar las líneas resaltadas\n\n\nAlt + *\nOpción + *\nInsertar &lt;-\n\n\nCtrl + Shift + m\nCmd + Shift + m\nInsertar %&gt;%\n\n\nCtrl + l\nCmd + l\nLimpiar la consola de R\n\n\nCtrl + Alt + b\nCmd + Opción + b\nEjecutar desde el inicio hasta la línea actual\n\n\nCtrl + Alt + t\nCmd + Opción + t\nEjecutar la sección de código actual (R Markdown)\n\n\nCtrl + Alt + i\nCmd + Shift + r\nInsertar un trozo (chunk) de código (en R Markdown)\n\n\nCtrl + Alt + c\nCmd + Opción + c\nEjecutar el código chunk actual (R Markdown)\n\n\nflechas arriba/abajo en la consola R\nEn el mismo\nRecorrer los comandos ejecutados recientemente\n\n\nShift + flechas arriba/abajo en el script\nEn el mismo\nSeleccionar varias líneas de código\n\n\nCtrl + f\nCmd + f\nBuscar y reemplazar en el script actual\n\n\nCtrl + Mayús + f\nCmd + Shift + f\nBuscar en archivos (buscar/reemplazar en muchos scripts)\n\n\nAlt + l\nCmd + Opción + l\nPlegar el código seleccionado\n\n\nShift + Alt + l\nCmd + Shift + Opción+l Desplegar el código seleccionado\n\n\n\n\nCONSEJO: Utiliza la tecla Tab cuando escribas para activar la función de autocompletar de RStudio. Esto puede evitar errores de ortografía. Pulsa el tabulador mientras escribes para que aparezca un menú desplegable de posibles funciones y objetos, basándose en lo que escrito hasta ese momento.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#functions",
    "href": "new_pages/basics.es.html#functions",
    "title": "3  Fundamentos de R",
    "section": "3.6 Funciones",
    "text": "3.6 Funciones\nLas funciones son la pieza principal en el uso de R. Las funciones son la forma de realizar tareas y operaciones. Muchas vienen instaladas con R, mientras muchas otras están disponibles para su descarga en paquetes (explicados en la sección de paquetes), ¡E incluso, puedes escribir tus propias funciones personalizadas.\nEsta sección básica sobre las funciones explica:\n\nQué es una función y cómo funciona\nQué son los argumentos de una función\nCómo obtener ayuda para entender una función\n\nUna nota rápida sobre la sintaxis: En este manual, las funciones se escriben en código-texto con paréntesis abiertos, así: filter(). Como se explica en la sección de paquetes, las funciones se descargan dentro de los paquetes. En este manual, los nombres de los paquetes se escriben en negrita, como dplyr. A veces en el código de ejemplo puede ver el nombre de la función vinculado explícitamente al nombre de su paquete con dos dos puntos (::) como: dplyr::filter(). El propósito de esta vinculación se explica en la sección de paquetes.\n\n\nFunciones simples\nUna función es como una máquina que recibe entradas, realiza alguna acción con esas entradas y produce una salida. El resultado depende de la función.\nLas funciones suelen operar sobre algún objeto colocado dentro de los paréntesis de la función. Por ejemplo, la función sqrt() calcula la raíz cuadrada de un número:\n\nsqrt(49)\n\n[1] 7\n\n\nEl objeto proporcionado a una función también puede ser una columna de datos (véase la sección Objetos para conocer todos los tipos de objetos). Dado que R puede almacenar múltiples conjuntos de datos, tendrás que especificar tanto el set de datos como la columna. Una forma de hacerlo es utilizar la notación $ para vincular el nombre de los datos y el nombre de la columna (dataset$column). En el siguiente ejemplo, la función summary() se aplica a la columna numérica age en los datos linelist, y la salida es un resumen de los valores numéricos y faltantes de la columna.\n\n# Muestra estadísticas resumen de la columna 'age' del dataset 'linelist'\nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n\nNOTA: Entre bastidores, una función representa un código adicional complejo que ha sido envuelto para el usuario en un comando sencillo.\n\n\n\nFunciones con multiples argumentos\nLas funciones suelen pedir varias entradas, llamadas argumentos, situadas dentro del paréntesis de la función, normalmente separadas por comas.\n\nAlgunos argumentos son necesarios para que la función funcione correctamente, mientras otros son opcionales\nLos argumentos opcionales tienen una configuración por defecto\nLos argumentos pueden tomar caracteres, números, lógica (TRUE/FALSE) y otras entradas\n\nHe aquí una divertida función ficticia, llamada oven_bake(), como ejemplo de una función típica (hacer en el horno). Toma un objeto de entrada (“input”) (por ejemplo, una base de datos o en este ejemplo “masa”) y realiza operaciones en él según lo especificado por los argumentos adicionales (minutes = y temperature =). La salida (“output”) puede ir a la consola, o guardarse como un objeto utilizando el operador de asignación &lt;-.\n\n\n\n\n\n\n\n\n\nEn un ejemplo más realista, el comando age_pyramid() que aparece a continuación produce un gráfico de pirámide de edad basado en grupos de edad definidos y una columna de división binaria, como gender. La función recibe tres argumentos dentro de los paréntesis, separados por comas. Los valores suministrados a los argumentos establecen linelist como los datos (dataframe) a utilizar, age_cat5 como la columna a contar, y gender como la columna binaria a utilizar para dividir la pirámide por color según género.\n\n# Crea una pirámide de edad \nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n\n\n\n\n\n\n\n\nEl comando anterior puede escribirse de forma equivalente a la de más abajo, con un estilo más largo con una nueva línea para cada argumento. Este estilo puede ser más fácil de leer, y más fácil de escribir “comentarios” con # para explicar cada segmento de código (¡comentar en el código es considerado una buena práctica!). Para ejecutar este comando más largo puedes seleccionar todo el texto y clicar en “Ejecutar”, o simplemente colocar el cursor en la primera línea y luego clicar las teclas Ctrl y Enter simultáneamente.\n\n# Crea una pirámide de edad\nage_pyramid(\n  data = linelist,        # usa los datos de linelist\n  age_group = \"age_cat5\", # especifica la columna para los grupos de edad\n  split_by = \"gender\"     # usa la columna gender para los dos lados de la pirámide\n  )\n\n\n\n\n\n\n\n\nNo es necesario especificar la primera mitad de una asignación de argumentos (por ejemplo, data =) si los argumentos se escriben en su orden específico (especificado en la documentación de la función). El código siguiente produce exactamente la misma pirámide que la anterior, porque la función espera ese orden de los argumentos: conjunto de datos, la variable para age_group, y la variable parasplit_by` .\n\n# Esta orden produce exactamente el mismo gráfico que la anterior\nage_pyramid(linelist, \"age_cat5\", \"gender\")\n\nUn comando age_pyramid() más complejo podría incluir argumentos opcionales para:\n\nMostrar proporciones en lugar de recuentos (estableciendo proportional = TRUE cuando el valor por defecto es FALSE)\nEspecificar los dos colores a utilizar (pal = es la abreviatura de “paleta” y se suministra con un vector de dos nombres de color. Para saber cómo se hace un vector con la función c() puedes consultar la página de objetos .\n\nNOTA: En los argumentos en los que se especifican ambas partes del argumento (por ejemplo, proporcional = TRUE), no importa el orden de estos argumentos.\n\nage_pyramid(\n  linelist,                    # usa los casos de linelist\n  \"age_cat5\",                  # columna de los grupos de edad\n  \"gender\",                    # dividido por género\n  proportional = TRUE,         # porcentajes en vez de números absolutos\n  pal = c(\"orange\", \"purple\")  # colores\n  )\n\n\n\n\n\n\n\n\n\n\n\nEscribir funciones\nR es un lenguaje orientado a las funciones, por lo que deberías sentirte capacitado para escribir tus propias funciones. La creación de funciones aporta varias ventajas:\n\nFacilita la programación modular, es decir, la separación del código en partes independientes y manejables.\nSustituye el repetitivo copiar y pegar, que puede dar lugar a errores\nSe puede dar a las piezas de código nombres fáciles de recordar\n\nEn la página Escribir funciones se trata en profundidad cómo escribir funciones.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#packages",
    "href": "new_pages/basics.es.html#packages",
    "title": "3  Fundamentos de R",
    "section": "3.7 Paquetes",
    "text": "3.7 Paquetes\nLos paquetes contienen funciones.\nUn paquete de R es un conjunto de código y documentación que se puede compartir y que contiene funciones predefinidas. Los usuarios de la comunidad R desarrollan paquetes todo el tiempo atendiendo a problemas específicos, ¡es probable que alguno pueda ayudarte en tu trabajo! En tu uso de R instalarás y utilizarás cientos de paquetes.\nEn la instalación, R contiene paquetes “base” y funciones que realizan tareas elementales comunes. Pero muchos usuarios de R crean funciones especializadas, que son verificadas por la comunidad de R y que puedes descargar como paquete para tu propio uso. En este manual, los nombres de los paquetes se escriben en negrita. Uno de los aspectos más desafiantes de R es que a menudo hay muchas funciones o paquetes donde elegir para una tarea determinada.\n\nInstalar y cargar\nLas funciones están contenidas en paquetes que pueden descargarse (“instalarse”) en tu ordenador desde Internet. Una vez descargado un paquete, se almacena en tu “librería”. Puedes acceder a las funciones que contiene durante una sesión de R “cargando” el paquete.\nPiensa en R como tu librería personal: Cuando se descarga un paquete, tu librería adquiere un nuevo libro de funciones, pero cada vez que quieras utilizar una función de ese libro, debes tomar prestado (“cargar”) ese libro de tu librería.\nEn resumen: para utilizar las funciones disponibles en un paquete de R, hay que realizar dos pasos:\n\nEl paquete debe ser instalado (una vez), y\nEl paquete debe ser cargado (cada sesión de R)\n\n\nTu librería\nTu “librería” es en realidad una carpeta en tu ordenador, que contiene una carpeta para cada paquete que se ha instalado. Averigua dónde está instalado R en tu ordenador y, si es windows, busca una carpeta llamada “win-library”. Por ejemplo: R-library\\4.0 (4.0 es la versión de R - tendrás una librería diferente para cada versión de R que haya descargado).\nPuedes imprimir la ruta del archivo de tu librería introduciendo .libPaths() (paréntesis vacíos). Esto resulta especialmente importante si se trabaja con R en unidades de red.\n\n\nInstalar desde CRAN\nLo habitual es que los usuarios de R descarguen paquetes de CRAN. CRAN (Comprehensive R Archive Network) es un almacén público online de paquetes de R que han sido publicados por los miembros de la comunidad R.\n¿Te preocupan los virus y la seguridad al descargar un paquete de CRAN?. Lee este artículo sobre el tema.\n\n\nCómo instalar y cargar\nEn este manual, sugerimos utilizar el paquete pacman (abreviatura de “packages manager”). Ofrece una interesante función p_load() que instalará un paquete si es necesario y lo cargará para su uso en la sesión actual de R.\nLa sintaxis es bastante sencilla. Sólo hay que listar los nombres de los paquetes dentro de los paréntesis de p_load(), separados por comas. Este comando instalará los paquetes rio, tidyverse y here si aún no están instalados, y los cargará para su uso. Esto hace que el enfoque de p_load() sea conveniente y conciso si se comparten scripts con otros. Ten en cuenta que los nombres de los paquetes distinguen entre mayúsculas y minúsculas.\n\n# Instala (si es necesario) y carga los paquetes a utilizar\npacman::p_load(rio, tidyverse, here)\n\nFíjate que hemos utilizado la sintaxis pacman::p_load() que escribe explícitamente el nombre del paquete (pacman) antes del nombre de la función (p_load()), conectado por dos dos puntos ::. Esta sintaxis es útil porque también carga el paquete pacman (suponiendo que ya esté instalado).\nHay funciones de R base alternativas que verás a menudo. La función de R base para instalar un paquete es install.packages(). El nombre del paquete a instalar debe proporcionarse entre paréntesis entre comillas. Si deseas instalar varios paquetes en un solo comando, deben ser listados dentro de un vector de caracteres c().\nNota: este comando instala un paquete, pero no lo carga para utilizarlo en la sesión actual.\n\n# instala un solo paquete con R base\ninstall.packages(\"tidyverse\")\n\n# instala múltiples paquetes con R base\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n\nLa instalación también se puede realizar clicando en el panel “Packages” de RStudio, luego en “Install” y buscando el nombre del paquete deseado.\nLa función alternativa para cargar un paquete (después de haberlo instalado) es library(). Sólo puedes cargar un paquete a la vez (otra razón para usar p_load()). Se puede escribir el nombre del paquete con o sin comillas.\n\n# carga los paquetes para usarlos, con R base\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n\nPara comprobar si un paquete está instalado y/o cargado, puedes mirar en la pestaña de Packages de RStudio. Si el paquete está instalado, se muestra allí con el número de versión. Si su casilla está marcada, está cargado para la sesión actual.\nInstalar desde Github\nA veces, necesitas instalar un paquete que aún no está disponible en CRAN. O tal vez el paquete está disponible en CRAN pero quieres la versión de desarrollo con nuevas características que aún no se ofrecen en la versión más estable publicada en CRAN. Éstas suelen estar alojadas en el sitio web github.com en un “repositorio” de código gratuito y de acceso público. Lee más sobre Github en la página del manual sobre Control de versiones y colaboración con Git y Github.\nPara descargar los paquetes de R desde Github, puedes utilizar la función p_load_gh() de pacman, que instalará el paquete si es necesario, y lo cargará para utilizarlo en tu sesión actual de R. Las alternativas de instalación incluyen el uso de los paquetes remotes o devtools. Puedes leer más sobre todas las funciones de pacman en la documentación del paquete.\nPara instalar desde Github, tienes que proporcionar más información. Debe proporcionar:\n\nEl ID de Github del propietario del repositorio\nEl nombre del repositorio que contiene el paquete\n(opcional) El nombre de la “rama” (versión de desarrollo específica) que quieras descargar\n\nEn los ejemplos siguientes, la primera palabra entre comillas es el ID de Github del propietario del repositorio, después de la barra es el nombre del repositorio (el nombre del paquete).\n\n# instala/carga el paquete epicontacts desde su repositorio de Github\np_load_gh(\"reconhub/epicontacts\")\n\nSi quieres instalar desde una “rama” (versión) distinta de la rama principal, añade el nombre de la rama tras una “@”, después del nombre del repositorio.\n\n# instala el paquete epicontacts de la rama \"timeline\" desde Github\np_load_gh(\"reconhub/epicontacts@timeline\")\n\nSi no hay diferencia entre la versión de Github y la versión en tu ordenador, no se realizará ninguna acción. Puedes “forzar” una reinstalación usando p_load_current_gh() con el argumento update = TRUE. Puedes leer más sobre pacman en esta viñeta online\nInstalar desde ZIP o TAR\nPuedes instalar el paquete desde una URL:\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n\nO bien, descargarlo en tu ordenador en un archivo comprimido:\nOpción 1: utilizar install_local() del paquete remotes\n\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\n\nOpción 2: utilizando install.packages() de R bases, proporcionando la ruta del archivo ZIP y estableciendo type = \"source\" y repos = NULL.\n\ninstall.packages(\"~/Downloads/dplyr-master.zip\", repos=NULL, type=\"source\")\n\n\n\n\nSintaxis del código\nPara mayor claridad en este manual, las funciones van a veces precedidas por el nombre de su paquete utilizando el símbolo :: de la siguiente manera: nombre_del_paquete::nombre_de_la_función()\nUna vez cargado un paquete para una sesión, este estilo explícito no es necesario. Se puede utilizar simplemente nombre_de_la_funcion(). Sin embargo, escribir el nombre del paquete es útil cuando el nombre de una función es común y puede existir en varios paquetes (por ejemplo, plot()). Escribir el nombre del paquete también cargará el paquete si no está todavía cargado.\n\n# Este comando usa el paquete \"rio\" y su función \"import()\" para importar un dataset\nlinelist &lt;- rio::import(\"linelist.xlsx\", which = \"Sheet1\")\n\n\n\nAyuda sobre una función\nPara leer más sobre una función, se puede buscar en la pestaña Ayuda de la parte inferior derecha de RStudio. También se puede ejecutar un comando como ?nombre_de_la_funcion (escribe el nombre de la función después de un signo de cerrar interrogación) y aparecerá la página de ayuda en la pestaña de ayuda. Por último, intenta buscar otros recursos en Internet.\n\n\nActualizar paquetes\nPuedes actualizar los paquetes reinstalándolos. También puedes clicar en el botón verde “Update” en la pestaña de paquetes de RStudio para ver qué paquetes tienen nuevas versiones para instalar. Ten en cuenta que tu código antiguo puede necesitar ser actualizado si hay una revisión importante en el funcionamiento de una función.\n\n\nEliminar paquetes\nUtiliza p_delete() de pacman, o remove.packages() de utils. Alternativamente, puedes buscar la carpeta que lo contiene en tu librería y borrarla manualmente.\n\n\nDependencias\nLos paquetes a menudo dependen de otros paquetes para funcionar. Estos se llaman dependencias. Si una dependencia no está instalada, entonces el paquete que depende de ella también puede no instalarse.\nSe pueden ver las dependencias de un paquete con p_depends(), y ver qué paquetes dependen de él con p_depends_reverse()\n\n\nFunciones enmascaradas\nNo es raro que dos o más paquetes contengan el mismo nombre de función. Por ejemplo, el paquete dplyr tiene una función filter(), pero también la tiene el paquete stats. La función filter() por defecto depende del orden en que estos paquetes se cargan por primera vez en la sesión de R - el último será el predeterminado para el comando filter().\nPuedes comprobar el orden en la Pestaña de Entorno de R Studio - clica en el desplegable de “Global Evironment” (Entorno Global) y mira el orden de los paquetes. Las funciones de los paquetes más bajos en esa lista desplegable enmascararán las funciones del mismo nombre en los paquetes que aparecen más arriba en la lista desplegable. Cuando se carga por primera vez un paquete, R advertirá en la consola si se está produciendo el enmascaramiento, pero esto puede ser fácil de pasar por alto.\n\n\n\n\n\n\n\n\n\nAquí hay formas de arreglar el enmascaramiento:\n\nEspecifica el nombre del paquete en el comando. Por ejemplo, utiliza dplyr::filter()\nReordena el orden de carga de los paquetes (por ejemplo, dentro de p_load()), e iniciar una nueva sesión de R\n\n\n\nDescargar\nPara descargar (detach / unload) un paquete, utiliza este comando, con el nombre correcto del paquete y sólo dos puntos. Ten en cuenta que esto puede no resolver el enmascaramiento.\n\ndetach(package:PACKAGE_NAME_HERE, unload=TRUE)\n\n\n\nInstalar una versión anterior\nConsulta esta guía para instalar una versión anterior de un paquete concreto.\n\n\nPaquetes recomendados\nConsulta la página de Paquetes recomendados para obtener una lista de paquetes que recomendamos para la epidemiología del día a día.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#scripts",
    "href": "new_pages/basics.es.html#scripts",
    "title": "3  Fundamentos de R",
    "section": "3.8 Scripts",
    "text": "3.8 Scripts\nLos scripts son una parte fundamental de la programación. Son documentos que contienen comandos (por ejemplo, funciones para crear y modificar datos, imprimir visualizaciones, etc.). Puedes guardar un script y volver a ejecutarlo más tarde. Almacenar y ejecutar tus comandos desde un script tiene muchas ventajas (frente a teclear los comandos uno a uno en la “línea de comandos” de la consola de R):\n\nPortabilidad: puedes compartir tu trabajo con otros enviándoles tus scripts\nReproducibilidad: para que tú y los demás sepan exactamente lo que se ha hecho\nControl de versiones: para que puedas hacer un seguimiento de los cambios realizados por ti mismo o por tus colegas\nComentarios/anotaciones: para explicar a tus compañeros lo que has hecho\n\n\nComentarios\nEn un script también puedes anotar (“comentar”) alrededor de su código R. Los comentarios son útiles para explicarte a tí mismo y a otros lectores lo que está haciendo. Puedes añadir un comentario escribiendo el símbolo de almohadilla (#) y el comentario después de él. El texto comentado aparecerá en un color diferente al del código R.\nCualquier código escrito después de la # no se ejecutará. Por lo tanto, colocar un # antes del código es también una forma útil de bloquear temporalmente una línea de código (“comentar”) si no quieres borrarla). Puedes comentar varias líneas a la vez resaltándolas y clicando Ctrl+Mayús+c (Cmd+Mayús+c en Mac).\n\n# Un comentario puede ser una línea en sí mismo\n# importar datos\nlinelist &lt;- import(\"linelist_raw.xlsx\") %&gt;%   # un comentario también puede venir después del  código\n# filter(age &gt; 50)                          # También se puede utilizar para desactivar / quitar una línea de código\n  count()\n\n\nComenta lo que haces y por qué lo haces.\nDivide tu código en secciones lógicas\nAcompaña tu código con un texto describiendo paso a paso lo que está haciendo (por ejemplo, pasos numerados)\n\n\n\nEstilo\nEs importante ser consciente de tu estilo de codificación, especialmente si trabajas en equipo. Nosotros abogamos por la guía de estilo tidyverse . También hay paquetes como styler y lintr que te ayudan a ajustarte a este estilo.\nAlgunos puntos muy básicos para que tu código sea legible para los demás:\n* Al nombrar los objetos, utiliza sólo letras minúsculas, números y guiones bajos _, por ejemplo, mis_datos.\n* Utiliza espacios frecuentemene, incluso alrededor de los operadores, por ejemplo, n = 1 y edad_nueva &lt;- edad_vieja + 3.\n### Ejemplo de Script {.unnumbered}\nA continuación se muestra un ejemplo de un breve script de R. ¡Recuerda!, cuanto mejor expliques brevemente el código con los comentarios, ¡más gustará a tus colegas!\n\n\n\n\n\n\n\n\n\n\n\n\nR markdown\nUn script de R markdown es un tipo de script de R en el que el propio script se convierte en un documento de salida (PDF, Word, HTML, Powerpoint, etc.). Se trata de herramientas increíblemente útiles y versátiles que suelen utilizarse para crear informes dinámicos y automatizados. ¡Hasta este sitio web y este manual se han hecho con scripts de R markdown!\nVale la pena señalar que los usuarios principiantes de R también pueden utilizar R Markdown - ¡no te dejes intimidar! Para saber más, consulta el capítulo del manual sobre Informes con R Markdown.\n\n\n\nR notebooks\nNo hay ninguna diferencia entre escribir en Rmarkdown o R notebook. Sin embargo, la ejecución del documento difiere ligeramente. Consulta este sitio para obtener más detalles.\n\n\n\nShiny\nLas aplicaciones/sitios web de Shiny están contenidas en un script, que debe llamarse app.R. Este archivo tiene tres componentes:\n\nUna interfaz de usuario (ui)\nUna función de servidor\nUna llamada a la función shinyApp\n\nConsulta la página del manual sobre Dashboards con Shiny, o este Tutorial de Shiny\nHace tiempo, el archivo anterior se dividía en dos archivos (ui.R y server.R)\n\n\nPlegar código\nPuedes contraer porciones de código para facilitar la lectura del script.\nPara ello, crea una cabecera de texto con #, escribe tu cabecera y sigue con al menos 4 guiones (-), almohadillas (#) o iguales (=). Cuando hayas hecho esto, aparecerá una pequeña flecha en el “margen” de la izquierda (junto al número de fila). Puedes clicar en esta flecha y en el código de abajo hasta que la siguiente cabecera se pliegue y aparezca un icono de flecha doble en su lugar.\nPara expandir el código, clica de nuevo en la flecha del margen o en el icono de la flecha doble. También hay atajos de teclado como se explica en la sección de RStudio de esta página.\nAl crear cabeceras con #, también activarás el índice de contenidos en la parte inferior del script (véase más abajo) que puedes utilizar para navegar por el script. Se pueden crear subcabeceras añadiendo más símbolos #, por ejemplo # para las primarias, ## para las secundarias y ### para las terciarias.\nA continuación se muestran dos versiones de un script de ejemplo. A la izquierda está el original con cabeceras comentadas. A la derecha, se han escrito cuatro guiones después de cada cabecera, haciéndolas plegables. Dos de ellas están plegadas, y se puede ver que la Tabla de Contenidos en la parte inferior muestra cada sección.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOtras áreas de código que son automáticamente elegibles para plegarlas son las zonas entre corchetes { } como las definiciones de funciones o los bloques condicionales (sentencias if else). Puedes leer más sobre el plegado de código en el sitio de RStudio.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#working_directory",
    "href": "new_pages/basics.es.html#working_directory",
    "title": "3  Fundamentos de R",
    "section": "3.9 Directorio de trabajo",
    "text": "3.9 Directorio de trabajo\nEl directorio de trabajo (o Working Directory “WD”) es la ubicación de la carpeta raíz utilizada por R para su trabajo - donde R busca y guarda los archivos por defecto. Por defecto, guardará los nuevos archivos y resultados en esta ubicación, y buscará los archivos de datos para importar aquí también.\nEl directorio de trabajo aparece en texto gris en la parte superior de la consola de RStudio. También puedes imprimir el directorio de trabajo actual ejecutando getwd() (deja los paréntesis vacíos).\n\n\n\n\n\n\n\n\n\n\nEnfoque recomendado\nConsulta la página sobre proyectos de R para obtener detalles sobre nuestro enfoque recomendado para gestionar tu directorio de trabajo. Una forma común, eficiente y sin problemas de gestionar tu directorio de trabajo y las rutas de los archivos es combinar estos 3 elementos en un flujo de trabajo orientado a los proyectos de R:\n\nUn proyecto R para almacenar todos tus archivos (ver página sobre proyectos R)\nEl paquete here para localizar los archivos (véase la página sobre importación y exportación)\nEl paquete rio para importar/exportar archivos (véase la página sobre importación y exportación)\n\n\n\n\nMediante comandos\nHasta hace poco, a muchas personas que aprendían R se les enseñaba a comenzar sus scripts con un comando setwd(). En vez de esto, piensa mejor en un flujo de trabajo orientado al proyecto R y lee las razones para no usar setwd(). En resumen, tu trabajo se convierte en algo específico de tu ordenador, las rutas de archivo utilizadas para importar y exportar archivos se vuelven “frágiles”, y esto dificulta gravemente la colaboración y el uso de tu código en cualquier otro ordenador. Hay alternativas fáciles!\nComo se ha indicado anteriormente, aunque no recomendamos este enfoque en la mayoría de las circunstancias, puedes utilizar el comando setwd() con la ruta del archivo de la carpeta deseada entre comillas, por ejemplo:\n\nsetwd(\"C:/Documents/R Files/My analysis\")\n\nPELIGRO: Establecer un directorio de trabajo con setwd() puede ser “frágil” si la ruta del archivo es específica de un ordenador. En su lugar, utiliza rutas de archivos relativas a un directorio raíz del proyecto R (con el paquete here). \n\n\n\nManualmente\nPara establecer el directorio de trabajo manualmente (el equivalente de apuntar y clicar en setwd()), clica en el menú desplegable Session y luego “Set Working Directory” (Establecer el directorio de trabajo) y entonces “Choose Directory” (Elegir el directorio). Esto establecerá el directorio de trabajo para esa sesión específica de R. Nota: si utilizas este enfoque, tendrás que hacerlo manualmente cada vez que abras RStudio.\n\n\n\nCon un proyecto\nSi se utiliza un proyecto R, el directorio de trabajo será por defecto la carpeta raíz del proyecto R que contiene el archivo “.rproj”. Esto se aplicará si clicas en abrir el proyecto en RStudio (el archivo con extensión “.rproj”).\n\n\n\nDirectorio en Rmarkdown\nEn un script de R markdown, el directorio de trabajo por defecto es la carpeta en la que se guarda el archivo Rmarkdown (.Rmd). Si se utiliza un proyecto R y el paquete here, esto no se aplica y el directorio de trabajo será here() como se explica en la página de proyectos R.\nSi quieres cambiar el directorio de trabajo de un Rmarkdown independiente (no en un proyecto R), si utilizas setwd() sólo se aplicará a ese trozo de código específico. Para hacer el cambio para todos párrafos, edita el trozo de configuración para añadir el parámetro root.dir =, como se indica a continuación:\n\nknitr::opts_knit$set(root.dir = 'desired/directorypath')\n\nEs mucho más fácil usar Rmarkdown dentro de un proyecto R y usar el paquete here.\n\n\n\nEscribir la ruta completa\nQuizás la fuente más común de frustración para un principiante de R (al menos en una máquina Windows) es escribir una ruta de archivo para importar o exportar datos. Hay una explicación exhaustiva sobre la mejor manera de introducir las rutas de los archivos en la página de importación y exportación, pero aquí hay algunos puntos clave:\nRutas rotas\nA continuación se muestra un ejemplo de una ruta de archivo “absoluta” o de “dirección completa”. Es probable que se rompa si se utiliza en otro ordenador. Una excepción es si estás usando una unidad compartida de red.\nC:/Nombre de usuario/Documento/Software analítico/R/Proyectos/Análisis2019/datos/Marzo2019.csv\nDirección de la barra\nSi escribes una ruta de archivo, ten en cuenta la dirección de las barras inclinadas (/). Utiliza barras inclinadas (/) para separar los componentes (“data/provincial.csv”). Para los usuarios de Windows, la forma predeterminada en que se muestran las rutas de los archivos es con barras invertidas (\\) - por lo que tendrás que cambiar la dirección de cada barra. Si utilizas el paquete here, tal y como se describe en la página de proyectos de R, la dirección de la barra no es un problema.\nRutas de archivo relativas\nGeneralmente recomendamos proporcionar rutas de archivo “relativas” - es decir, la ruta relativa a la raíz de tu proyecto R. Puedes hacer esto usando el paquete here como se explica en la página de proyectos R. Una ruta de archivo relativa podría ser así:\n\n# Importa linelist csv de las subcarpetas data/linelist/clean/ del proyectoo R \nlinelist &lt;- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))\n\nIncluso si se utilizan rutas de archivo relativas dentro de un proyecto R, se pueden utilizar rutas absolutas para importar/exportar datos fuera del proyecto R.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#objects",
    "href": "new_pages/basics.es.html#objects",
    "title": "3  Fundamentos de R",
    "section": "3.10 Objetos",
    "text": "3.10 Objetos\nTodo en R es un objeto, y R es un lenguaje “orientado a objetos”. Estas secciones lo explicarán:\n\nCómo crear objetos (&lt;-)\nTipos de objetos (por ejemplo, dataframe -conjunto de datos-, vectores…)\nCómo acceder a las subpartes de los objetos (por ejemplo, las variables de unos datos)\nTipos de objetos (por ejemplo, numéricos, lógicos, enteros, dobles, caracteres, factores)\n\n\n\nTodo es un objeto\nEsta sección está adaptada del proyecto R4Epis. Todo lo que se almacena en R -conjuntos de datos (dataframe), variables, una lista de nombres de pueblos, un número total de población, incluso resultados como gráficos- son objetos a los que se asigna un nombre y a los que se puede hacer referencia en comandos posteriores.\nUn objeto existe cuando se le ha asignado un valor (véase la sección de asignación más adelante). Cuando se le asigna un valor, el objeto aparece en el Entorno -Environment- (en el panel superior derecho de RStudio). A partir de ese momento se puede operar con él, manipularlo, cambiarlo y redefinirlo.\n\n\n\nDefinición de objetos (&lt;-)\nCrea objetos asignándoles un valor con el operador &lt;-. Puedes pensar que el operador de asignación &lt;- significa: “se define como”. Los comandos de asignación suelen seguir un orden estándar:\nnombre_objeto &lt;- valor (o proceso/cálculo que produce un valor)\nPor ejemplo, es posible que desees registrar la semana de notificación epidemiológica actual como un objeto para referenciarlo posteriormente en el código. En este ejemplo, el objeto current_week se crea cuando se le asigna el valor \"2018-W10\" (las comillas hacen que sea un valor de tipo carácter). El objeto current_week aparecerá entonces en el panel de Environment de RStudio (arriba a la derecha) y podrá ser referenciado en comandos posteriores.\nVer los comandos de R y su salida en los cuadros de abajo.\n\ncurrent_week &lt;- \"2018-W10\"   # Este comando crea el objeto current_week asignándole un valor\ncurrent_week                 # Este comando muestra en la consola el valor actual del objeto current_week\n\n[1] \"2018-W10\"\n\n\nNOTA: Observa que el [1] en la consola de resultados simplemente indica que estás viendo el primer elemento de resultados\nATENCIÓN: El valor de un objeto puede sobrescribirse en cualquier momento ejecutando un comando de asignación para redefinir su valor. Por lo tanto, el orden de ejecución de los comandos es muy importante.\nEl siguiente comando redefinirá el valor de current_week:\n\ncurrent_week &lt;- \"2018-W51\"   # asigna un NUEVO valor al objeto current_week\ncurrent_week                 # muestra en la consola el valor actual del objeto current_week\n\n[1] \"2018-W51\"\n\n\nSignos de igualdad =\nTambién verás signos de igualdad en el código R:\n\nUn doble signo de igualdad == entre dos objetos o valores formula una pregunta lógica: “¿es esto igual a aquello?”.\nTambién verás signos de igualdad dentro de las funciones que se utilizan para especificar los valores de los argumentos de la función (lee sobre ellos en las secciones siguientes), por ejemplo max(edad, na.rm = TRUE).\nPuedes utilizar un único signo de igualdad = en lugar de &lt;- para crear y definir objetos, pero se desaconseja hacerlo. Puedes leer por qué se desaconseja aquí.\n\nConjuntos de datos (datasets)\nLos conjuntos de datos también son objetos (normalmente “dataframes”) y se les debe asignar un nombre cuando se importan. En el código siguiente, se crea el objeto linelist y se le asigna el valor de un archivo CSV importado con la función import() del paquete rio.\n\n# se crea linelist y se le asigna los valores del archivo CSV importado\nlinelist &lt;- import(\"my_linelist.csv\")\n\nPuedes obtener más información sobre la importación y la exportación de datos en la sección sobre importación y exportación.\nATENCIÓN: Una nota rápida sobre la denominación de los objetos:\n\nLos nombres de los objetos no deben contener espacios, debes utilizar el guión bajo (_) o un punto (.) en lugar de un espacio.\nLos nombres de los objetos distinguen entre mayúsculas y minúsculas (lo que significa que Dataset_A es diferente de dataset_A).\nLos nombres de los objetos deben empezar por una letra (no pueden empezar por un número como 1, 2 o 3).\n\nResultados\nLos resutados, como las tablas y los gráficos proporcionan un ejemplo de cómo las salidas pueden guardarse como objetos, o simplemente mostrarse en la consola sin ser guardadas. Una tabla cruzada de género y resultado utilizando la función table() de R base puede mostrarse directamente en la consola de R (sin guardarse).\n\n# solamente se muestra en la consola de R\ntable(linelist$gender, linelist$outcome)\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nPero la misma tabla puede guardarse como un objeto con nombre. Y luego, opcionalmente, se puede mostrar o imprimir.\n\n# guarda la tabla\ngen_out_table &lt;- table(linelist$gender, linelist$outcome)\n\n# la muestra en la consola (print)\ngen_out_table\n\n   \n    Death Recover\n  f  1227     953\n  m  1228     950\n\n\nColumnas\nLas columnas de unos datos también son objetos y pueden definirse, sobrescribirse y crearse como se describe a continuación en la sección sobre Columnas.\nPuedes utilizar el operador de asignación de R base para crear una nueva columna. A continuación, se crea la nueva columna bmi (Índice de masa corporal), y para cada fila el nuevo valor es el resultado de una operación matemática sobre el valor de la fila en las columnas wt_kg y ht_cm.\n\n# crea la columna \"bmi\" utilizando sintaxis de R base\nlinelist$bmi &lt;- linelist$wt_kg / (linelist$ht_cm/100)^2\n\nSin embargo, en este manual, hacemos hincapié en un enfoque diferente para definir las columnas, que utiliza la función mutate() del paquete dplyr y la canalización con el operador pipe (%&gt;%). La sintaxis es más fácil de leer y hay otras ventajas que se explican en la página sobre Limpieza de datos y funciones básicas. Puedes leer más sobre la canalización en dicha sección más abajo.\n\n# crea la columna \"bmi\" utilizando sintaxis de dplyr\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\n\n\n\nEstructura de los objetos\nLos objetos pueden ser un solo dato (por ejemplo, mi_número &lt;- 24), o pueden consistir en datos estructurados.\nEl gráfico siguiente está tomado de este tutorial de R en línea. Muestra algunas estructuras de datos comunes y sus nombres. No se incluyen en esta imagen los datos espaciales, de los que se habla en la página de fundamentos del SIG.\n\n\n\n\n\n\n\n\n\nEn epidemiología (y en particular en epidemiología de campo), lo habitual es encontrar dataframes (conjuntos de datos) y vectores:\n\n\n\n\n\n\n\n\nEstructura común\nExplicación\nEjemplo\n\n\n\n\nVectores\nUn contenedor para una secuencia de objetos singulares, todos del mismo tipo (por ejemplo, numérico, carácter).\nLas variables (columnas) en los dataframes son vectores (por ejemplo, la columna de edad en años age_years).\n\n\nDataframes\nVectores (por ejemplo, columnas) unidos que tienen todos el mismo número de filas.\nlinelist es un dataframe.\n\n\n\nTen en cuenta que para crear un vector que “está solo” (no forma parte de un dataframe) se utiliza la función c() para combinar los diferentes elementos. Por ejemplo, si se crea un vector de colores de la escala de colores del gráfico: vector_de_colores &lt;- c(\"azul\", \"rojo2\", \"naranja\", \"gris\")\n\n\n\nTipos de objeto\nTodos los objetos almacenados en R tienen un tipo (class) que indica a R cómo manejar el objeto. Hay muchos tipos de datos, pero los más comunes son:\n\n\n\nTipo\nExplicación\nEjemplos\n\n\n\n\nCharacter\nSon textos/palabras/frases “entre comillas”. No se pueden realizar operaciones matemáticas con estos objetos.\n“Los objetos de carácter están entre comillas”\n\n\nInteger\nNúmeros sólo enteros (sin decimales)\n-5, 14, o 2000\n\n\nNumeric\nSon números y pueden incluir decimales. Si están entre comillas se considerarán de tipo de caracteres.\n23.1 o 14\n\n\nFactor\nSe trata de vectores que tienen un orden determinado o jerarquía de valores\nUna variable de situación económica con valores ordenados\n\n\nDate\nUna vez que se le dice a R que ciertos datos son Fechas, estos datos pueden ser manipulados y mostrados de maneras especiales. Para más información, consulta la página sobre el trabajo con fechas.\n2018-04-12 o 15/3/1954 o miércoles 4 de enero de 1980\n\n\nLogical\nLos valores deben ser uno de los dos valores especiales TRUE o FALSE (nótese que no son “TRUE” y “FALSE” entre comillas)\nTRUE o FALSE\n\n\ndata.frame\nUn dataframe es la forma en que R almacena un ** conjunto de datos típico**. Consiste en vectores (columnas) de datos unidos, que tienen todos el mismo número de observaciones (filas).\nEl set de datos AJS de ejemplo denominado linelist_raw contiene 68 variables con 300 observaciones (filas) cada una.\n\n\ntibble\nLos tibbles son una variación de los dataframe, la principal diferencia operativa es que muestran de forma más agradable en la consola (muestran las 10 primeras filas y sólo las columnas que caben en la pantalla)\nCualquier conjunto de datos, lista o matriz puede convertirse en un tibble con as_tibble()\n\n\nList\nUna lista es como un vector, pero contiene otros objetos que pueden ser de otras tipos diferentes\nUna lista puede contener un solo número, un dataframe de datos, un vector e incluso otra lista.\n\n\n\nPuedes comprobar el tipo de un objeto escribiendo su nombre en la función class(). Nota: puede hacer referencia a una columna específica dentro de unos datos utilizando la notación $ para separar el nombre de los datos y el nombre de la columna.\n\nclass(linelist) # debe ser de tipo dataframe o tibble\n\n[1] \"data.frame\"\n\nclass(linelist$age) # debe ser de tipo numérico\n\n[1] \"numeric\"\n\nclass(linelist$gender) # debe ser de tipo carácter\n\n[1] \"character\"\n\n\nA veces, una columna puede ser convertida automáticamente por R en un tipo diferente. ¡Cuidado con esto! Por ejemplo, si tiene un vector o columna de números, pero se inserta un valor de carácter… toda la columna cambiará al tipo carácter.\n\nnum_vector &lt;- c(1,2,3,4,5) # define vector como todos números\nclass(num_vector)          # el vector es de tipo numérico\n\n[1] \"numeric\"\n\nnum_vector[3] &lt;- \"three\"   # convierte el tercer elemento en de tipo carácter\nclass(num_vector)          # el vector es ahora de tipo carácter class\n\n[1] \"character\"\n\n\nUn ejemplo común de esto es cuando se manipula unos datos para imprimir una tabla - si se hace una fila de totales y se intenta pegar porcentajes en la misma celda como números (por ejemplo, 23 (40%)), toda la columna numérica de arriba se convertirá en carácter y ya no se podrá utilizar para cálculos matemáticos. A veces, tendrás que convertir objetos o columnas a otro tipo.\n\n\n\nFunción\nAcción\n\n\n\n\nas.character()\nConvierte al tipo de carácter\n\n\nas.numeric()\nConvierte al tipo numérico\n\n\nas.integer()\nConvierte al tipo entero\n\n\nas.date()\nConvierte al tipo de fecha - Nota: ver la sección de fechas para más detalles\n\n\nfactor()\nConvierte en factor - Nota: la redefinición del orden de los niveles de valor requiere argumentos adicionales\n\n\n\nAsimismo, existen funciones de R base para comprobar si un objeto ES de un tipo específico, como is.numeric(), is.character(), is.double(), is.factor(), is.integer()\nAquí hay más material en línea sobre tipos y estructuras de datos en R.\n\n\n\nColumnas/Variables ($)\nUna columna en un dataframe es técnicamente un “vector” (véase la tabla anterior) - una serie de valores que deben ser todos del mismo tipo (ya sea carácter, numérico, lógico, etc).\nUn vector puede existir independientemente de un dataframe, por ejemplo, un vector de nombres de columnas que se desea incluir como variables explicativas en un modelo. Para crear un vector “independiente”, utiliza la función c() como se indica a continuación:\n\n# define el vector con valores de caracteres\nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# muestra los valores de este vector\nexplanatory_vars\n\n[1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\" \n\n\nLas columnas de un dataframe también son vectores y pueden ser llamadas, referenciadas, extraídas o creadas utilizando el símbolo $. El símbolo $ conecta el nombre de la columna con el nombre del dataframe. En este manual, tratamos de utilizar la palabra “columna” en lugar de “variable”.\n\n# Recuperar la longitud del vector age_years\nlength(linelist$age) # (age es una columna del dataframe linelist)\n\nAl escribir el nombre del dataframe seguido de $ también verá un menú desplegable de todas las columnas del dataframe. Puedes desplazarte por ellas con la tecla de flecha, seleccionar una con la tecla Intro y evitar errores ortográficos.\n\n\n\n\n\n\n\n\n\nCONSEJO AVANZADO: Algunos objetos más complejos (por ejemplo, una lista, o un objeto epicontacts) pueden tener múltiples niveles a los que se puede acceder a través de múltiples signos de dólar. Por ejemplo epicontacts$linelist$date_onset\n\n\n\nAcceso/índice con corchetes ([ ])\nEs posible que tengas que mirar sólo partes de los objetos, lo que también se llama “indexación”, que a menudo se hace utilizando los corchetes [ ]. El uso de $ en un dataframe para acceder a una columna también es un tipo de indexación.\n\nmy_vector &lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")  # definir el vector\nmy_vector[5]                                  # mostrar el 5º elemento\n\n[1] \"e\"\n\n\nLos corchetes también sirven para devolver partes específicas de un resultado, como la salida de una función summary():\n\n# resumen completo \nsummary(linelist$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.07   23.00   84.00      86 \n\n# Sólo el segundo elemento del resumen, nombre (usando solo conchetes simples)\nsummary(linelist$age)[2]\n\n1st Qu. \n      6 \n\n# Sólo el segundo elemento, sin nombre (usando dobles corchetes)\nsummary(linelist$age)[[2]]\n\n[1] 6\n\n# Extrae un elemento por nombre, sin mostrar el nombre\nsummary(linelist$age)[[\"Median\"]]\n\n[1] 13\n\n\nLos corchetes también funcionan en los dataframes para ver filas y columnas específicas. Puedes hacerlo utilizando la sintaxis dataframe[filas, columnas]:\n\n# Ver una fila específica (2) del dataset, con todas las columnas (¡no olvides la coma!)\nlinelist[2,]\n\n# Ver todas las filas, pero solo una columna\nlinelist[, \"date_onset\"]\n\n# Ver los valores de la fila 2 y las columnas 5 hasta la 10\nlinelist[2, 5:10] \n\n# Ver los valores desde la fila 2 y las columnas 5 hasta la 10 y 18\nlinelist[2, c(5:10, 18)] \n\n# Ver las filas 2 a la 20 y sólo unas columnas especificadas\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# Ver filas y columnas basado en ciertos criterios\n# *** ¡Observa que el nombre del dataframe también debe estar entre los criterios!\nlinelist[linelist$age &gt; 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Usa View() para ver el resultado en el Visor de Rstudio (más fácil de leer) \n# *** Fíjate que la \"V\" de la función View() está en mayúsculas\nView(linelist[2:20, \"date_onset\"])\n\n# Guarda como objeto nuevo\nnew_table &lt;- linelist[2:20, c(\"date_onset\")] \n\nTen en cuenta que también puedes lograr la indexación de filas/columnas anterior en dataframes y tibbles utilizando sintaxis de dplyr (funciones filter() para filas, y select() para columnas). Puedes leer más sobre estas funciones básicas en la página de Limpieza de datos y funciones básicas.\nPara filtrar en base al “número de fila”, puedes utilizar la función row_number() de dplyr (con paréntesis vacíos) como parte de una sentencia lógica de filtrado. A menudo se utiliza el operador %in% y un rango de números como parte de esa sentencia lógica, como se muestra a continuación. Para ver las primeras N filas, también puede utilizar la función especial head() de dplyr.\n\n# Ver las primeras 100 filas\nlinelist %&gt;% head(100)\n\n# Mostrar sólo la fila 5\nlinelist %&gt;% filter(row_number() == 5)\n\n# Ver las filas 2 hasta la 20, y tres columnas específicas (No sonnecesarias las comillas pasa los nombres de columna)\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nCuando se indexa un objeto del tipo list, los corchetes simples siempre devuelven con el tipo list, incluso si sólo se devuelve un único objeto. Los corchetes dobles, sin embargo, pueden utilizarse para acceder a un solo elemento y devolver un tipo diferente al de la lista. Los corchetes también pueden escribirse uno tras otro, como se demuestra a continuación.\nEsta explicación visual de la indexación de listas, con pimenteros, es divertida y útil.\n\n# define demo list\nmy_list &lt;- list(\n  # El primer elemento en la lista es un vector de carácter\n  hospitals = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n  # El segundo elemento en la lista es un data frame de direcciones\n  addresses   = data.frame(\n    street = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n    city   = c(\"Andover\", \"Hamilton\", \"El Paso\")\n    )\n  )\n\nEste es el aspecto de la lista cuando se muestra en la consola. Mira cómo hay dos elementos con nombre:\n\nhospital, un vector de caracteres\naddresses, un data frame de direcciones\n\n\nmy_list\n\n$hospitals\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\n$addresses\n           street     city\n1 145 Medical Way  Andover\n2  1048 Brown Ave Hamilton\n3   999 El Camino  El Paso\n\n\nAhora extraeremos información, utilizando varios métodos:\n\nmy_list[1] # este devuelve el elemento de tipo \"list\" - también se muestra el nombre del elemento\n\n$hospitals\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[1]] # este devuelve sólo el vector de carácter (sin nombrarlo) \n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[\"hospitals\"]] # también puedes indexar por nombre del elemento list\n\n[1] \"Central\"    \"Empire\"     \"Santa Anna\"\n\nmy_list[[1]][3] # este devuelve el tercer elemento del vector de carácter \"hospitals\"\n\n[1] \"Santa Anna\"\n\nmy_list[[2]][1] # este devuelve la primera columna (\"street\") del data frame address\n\n           street\n1 145 Medical Way\n2  1048 Brown Ave\n3   999 El Camino\n\n\n\n\n\nEliminar objetos\nPuedes eliminar objetos individuales de tu entorno R poniendo el nombre en la función rm() (sin comillas):\n\nrm(object_name)\n\nPuedes eliminar todos los objetos (limpiar tu espacio de trabajo) ejecutando:\n\nrm(list = ls(all = TRUE))",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#piping",
    "href": "new_pages/basics.es.html#piping",
    "title": "3  Fundamentos de R",
    "section": "3.11 Piping (%>%)",
    "text": "3.11 Piping (%&gt;%)\nDos aproximaciones para trabajar con objetos:\n\nPipes/tidyverse - pipes envía un objeto de una función a otra función - énfasis en la acción, no en el objeto\n\nDefinir objetos intermedios - se re-define un objeto una y otra vez - el énfasis está en el objeto\n\n\n\nPipes (%&gt;%)\nHay dos enfoques generales para trabajar con objetos:\n\nPipes/tidyverse - los pipes envían un objeto de función a función - el énfasis está en la acción, no en el objeto\nDefinir objetos intermedios - un objeto se redefine una y otra vez - el énfasis está en el objeto\n\nPipes\nExplicado de forma sencilla, el operador pipe (%&gt;%) pasa un resultado intermedio de una función a la siguiente. Puedes pensar en él como si dijera “entonces”. Muchas funciones pueden enlazarse con %&gt;%.\n\nLos pipes hacen hincapié en una secuencia de acciones, no en el objeto sobre el que se realizan las acciones\nLos pipes son mejores cuando hay que realizar una secuencia de acciones en un objeto\nLos pipes provienen del paquete magrittr, que se incluye automáticamente en los paquetes dplyr y tidyverse\nLos pipes pueden hacer que el código sea más limpio y fácil de leer, más intuitivo\n\nMás información sobre este enfoque en la guía de estilo de tidyverse\nHe aquí un ejemplo para comparar, utilizando funciones ficticias para “hornear un pastel”. Primero, el método pipe:\n\n# Un ejemplo falso de cómo hornear un pastel utilizando sintaxis con pipes\n\ncake &lt;- flour %&gt;%       # para definir pastel, empezar con harina, y luego...\n  add(eggs) %&gt;%   # añadir huevos\n  add(oil) %&gt;%    # añadir aceite\n  add(water) %&gt;%  # añadir agua\n  mix_together(         # mezclarlos juntos\n    utensil = spoon,\n    minutes = 2) %&gt;%    \n  bake(degrees = 350,   # hornear\n       system = \"fahrenheit\",\n       minutes = 35) %&gt;%  \n  let_cool()            # dejar que se enfríe\n\nAquí hay otro enlace que describe la utilidad de Los pipes.\nEl uso de pipes no es una función base. Para usarlos, debe estar instalado y cargado el paquete magrittr (esto se hace normalmente cargando el paquete tidyverse o dplyr que lo incluyen). Puedes leer más sobre pipes en la documentación de magrittr.\nTen en cuenta que, al igual que otros comandos de R, Los pipes se pueden utilizar para mostrar sólo el resultado, o para guardar/re-guardar un objeto, dependiendo de si el operador de asignación &lt;- está involucrado. Mira ambas cosas a continuación:\n\n# Crear o sobreescribir objetos, definiéndolo como como recuentos agregados por categoría de edad (sin mostrarlo)\nlinelist_summary &lt;- linelist %&gt;% \n  count(age_cat)\n\n\n# Muestra la tabla de recuentos en la consola, pero no la guarda\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\n%&lt;&gt;%\nSe trata de un “pipe de asignación” del paquete magrittr, que lleva un objeto hacia adelante y también redefine el objeto. Debe ser el primer operador pipe en la cadena. Es una forma abreviada. Los dos comandos siguientes son equivalentes:\n\nlinelist &lt;- linelist %&gt;%\n  filter(age &gt; 50)\n\nlinelist %&lt;&gt;% filter(age &gt; 50)\n\n\n\n\nDefinir objetos intermedios\nEste enfoque para cambiar objetos/dataframes puede ser mejor si:\n\nNecesitas manipular múltiples objetos\nHay pasos intermedios que son significativos y merecen nombres de objetos separados\n\nRiesgos:\n\nCrear nuevos objetos para cada paso significa crear muchos objetos. Si usas el equivocado, ¡puedes no darte cuenta!\nNombrar todos los objetos puede ser confuso\nLos errores pueden no ser fácilmente detectables\n\nO bien nombrar cada objeto intermedio, o sobrescribir el original, o combinar todas las funciones juntas. Todo ello conlleva sus propios riesgos.\nA continuación se muestra el mismo ejemplo de “pastel” falso que el anterior, pero utilizando este estilo:\n\n# Un ejemplo falso de cómo hornear un pastel definiendo objetos intermedios\nbatter_1 &lt;- left_join(flour, eggs)\nbatter_2 &lt;- left_join(batter_1, oil)\nbatter_3 &lt;- left_join(batter_2, water)\n\nbatter_4 &lt;- mix_together(object = batter_3, utensil = spoon, minutes = 2)\n\ncake &lt;- bake(batter_4, degrees = 350, system = \"fahrenheit\", minutes = 35)\n\ncake &lt;- let_cool(cake)\n\nCombinar todas las funciones juntas - esto es difícil de leer:\n\n# un ejemplo de combinación/anidación de múltiples funciones - difícil de leer\ncake &lt;- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = \"fahrenheit\", minutes = 35))",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#operators",
    "href": "new_pages/basics.es.html#operators",
    "title": "3  Fundamentos de R",
    "section": "3.12 Operadores y funciones clave",
    "text": "3.12 Operadores y funciones clave\nEsta sección detalla los operadores en R, como por ejemplo\n\nOperadores de definición\nOperadores relacionales (menor que, igual a ..)\nOperadores lógicos (and, or…)\nTratamiento de los valores faltantes\nOperadores y funciones matemáticas (+/-, &gt;, sum(), median(), …)\nEl operador %in%\n\n\n\nOperadores de asignación\n&lt;-\nEl operador de asignación básico en R es &lt;-. Como en nombre_objeto &lt;- valor. Este operador de asignación también se puede escribir como =. Aconsejamos de forma general el uso de &lt;- . También aconsejamos rodear tales operadores con espacios, para mejorar la legibilidad.\n&lt;&lt;-\nSi se escriben funciones, o se utiliza R de forma interactiva con scripts de origen, entonces puede ser necesario utilizar este operador de asignación &lt;&lt;- (de R base). Este operador se utiliza para definir un objeto en un entorno R superior “padre”. Mira esta referencia online.\n%&lt;&gt;%\nSe trata de un “pipe de asignación” del paquete magrittr, que canaliza un objeto hacia adelante y también redefine el objeto. Debe ser el primer operador de pipe en la cadena. Es una forma abreviada, como se muestra a continuación en dos ejemplos equivalentes:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_months = age_years * 12)\n\nLo anterior equivale a lo siguiente:\n\nlinelist %&lt;&gt;% mutate(age_months = age_years * 12)\n\n%&lt;+%\nSe utiliza para añadir datos a los árboles filogenéticos con el paquete ggtree. Consulta la página sobre árboles filogenéticos o este libro de recursos en línea.\n\n\n\nOperadores relacionales y lógicos\nLos operadores relacionales comparan valores y se utilizan a menudo al definir nuevas variables y subconjuntos de datos. Estos son los operadores relacionales más comunes en R:\n\n\n\nSignificado\nOperador\nEjemplo\nEjemplo de resultado\n\n\n\n\nIgual a\n==\n\"A\" == \"a\"\nFALSE (R distingue entre mayúsculas y minúsculas) Ten en cuenta que == (doble igual) es diferente de = (simple igual), que actúa como el operador de asignación &lt;-\n\n\nNo es igual a\n!=\n2 != 0\nTRUE\n\n\nMayor que\n&gt;\n4 &gt; 2\nTRUE\n\n\nMenor que\n&lt;\n4 &lt; 2\nFALSE\n\n\nMayor que o igual a\n&gt;=\n6 &gt;= 4\nTRUE\n\n\nMenor que o igual a\n&lt;=\n6 &lt;= 4\nFALSE\n\n\nFalta el valor\nis.na()\nis.na(7)\nFALSE (véase la página sobre Valores faltantes)\n\n\nNo falta el valor\n!is.na()\n!is.na(7)\nTRUE\n\n\n\nLos operadores lógicos o booleanos, como AND y OR, suelen utilizarse para conectar operadores relacionales y crear criterios más complicados. Las sentencias complejas pueden requerir paréntesis () para la agrupación y el orden de aplicación.\n\n\n\ngnificado |Operado\nr\n\n\n———-|——-\n—————–\n\n\nD |&\n\n\n\n|| (ba\nrra vertical)\n\n\nréntesis |( ) S\ne utiliza para agrupar criterios y aclarar el orden de las operaciones\n\n\n\nPor ejemplo, a continuación, tenemos un listado con dos variables que queremos utilizar para crear nuestra definición de caso, hep_e_rdt, un resultado de la prueba y other_cases_in_hh, que nos dirá si hay otros casos en el hogar. El comando siguiente utiliza la función case_when() para crear la nueva variable case_def tal que:\n\nlinelist_cleaned &lt;- linelist %&gt;%\n  mutate(case_def = case_when(\n    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,\n    rdt_result == \"Positive\"                                 ~ \"Confirmed\",\n    rdt_result != \"Positive\" & other_cases_in_home == \"Yes\"  ~ \"Probable\",\n    TRUE                                                     ~ \"Suspected\"\n  ))\n\n\n\n\n\n\n\n\nCriterios del ejemplo anterior\nValor resultante en la nueva variable “case_def”\n\n\n\n\nSi falta el valor de las variables rdt_result y other_cases_in_home\nNA (valor faltante)\n\n\nSi el valor de rdt_result es “Positivo”\n“Confirmado”\n\n\nSi el valor de rdt_result NO es “Positivo” Y el valor de other_cases_in_home es “Si”\n“Probable”\n\n\nSi no se cumple alguno de los criterios anteriores\n“Sospechoso”\n\n\n\nTen en cuenta que R distingue entre mayúsculas y minúsculas, por lo que “Positivo” es diferente de “positivo”…\n\n\n\nValores faltantes\nEn R, los valores faltantes (missing value) se representan con el valor especial NA (una palabra “reservada” para ello) (letras mayúsculas N y A - sin comillas). Si importas datos que registran los valores faltantes de otra manera (por ejemplo, 99, “Nulo”, o .), es posible que quieras re-codificar esos valores a NA. En la página de importación y exportación se explica cómo hacerlo.\nPara comprobar si un valor es NA, utiliza la función especial is.na(), que devuelve TRUE o FALSE.\n\nrdt_result &lt;- c(\"Positive\", \"Suspected\", \"Positive\", NA)   # dos casos positivos, uno sospechoso y uno desconocido\nis.na(rdt_result)  # Comprueba si el valor de rdt_result es NA\n\n[1] FALSE FALSE FALSE  TRUE\n\n\nPuedes leer más sobre los valores faltantes, infinitos, NULL e imposibles en la página sobre Valores faltantes]. Aprende a convertir los valores faltantes al importar datos en la página sobre Importación y exportación.\n\n\n\nMatemáticos y estadísticos\nTodos los operadores y funciones de esta página están disponibles automáticamente en R base.\n\nOperadores matemáticos\nSe utilizan a menudo para realizar sumas, divisiones, crear nuevas columnas, etc. A continuación se muestran los operadores matemáticos más comunes en R. No es importante poner espacios alrededor de los operadores.\n\n\n\nPropósito\nEjemplo en R\n\n\n\n\nsuman\n2 + 3\n\n\nresta\n2 - 3\n\n\nmultiplicación\n2 * 3\n\n\ndivisión\n30 / 5\n\n\nexponente\n2^3\n\n\norden de operaciones\n( )\n\n\n\n\n\nFunciones matemáticas\n\n\n\nPropósito\nFunción**\n\n\n\n\nredondeo\nround(x, digits = n)\n\n\nredondeo\njanitor::round_half_up(x, digits = n)\n\n\nredondeo arriba\nceiling(x)\n\n\nredondeo abajo\nfloor(x)\n\n\nvalor absoluto\nabs(x)\n\n\nraiz cuadrada\nsqrt(x)\n\n\nexponente\nexponent(x)\n\n\nlogaritmo natural\nlog(x)\n\n\nlog base 10\nlog10(x)\n\n\nlog base 2\nlog2(x)\n\n\n\nNota: para round() los dígits = especifican el número de decimales. Utiliza signif() para redondear a un número de cifras significativas.\n\n\nNotación científica\nLa probabilidad de que se utilice la notación científica depende del valor de la opción scipen.\nDe la documentación de ?options: scipen es una penalización que se aplica cuando se decide obtener valores numéricos en notación fija o exponencial. Los valores positivos se inclinan hacia la notación fija y los negativos hacia la notación científica: se preferirá la notación fija a menos que tenga más dígitos que ‘scipen’.\nSi se establece en un número bajo (por ejemplo, 0) estará “activada” siempre. Para “desactivar” la notación científica en tu sesión de R, configúrela con un número muy alto, por ejemplo:\n\n# desactiva la notación científica\noptions(scipen=999)\n\n\n\nRedondeo\nPELIGRO: round() utiliza el “redondeo del banquero” que redondea hacia arriba desde un 0,5 sólo si el número superior es par. Utiliza round_half_up() de janitor para redondear consistentemente las mitades hacia arriba al número entero más cercano. Aquí tienes esta explicación\n\n# utilizar la función de redondeo adecuada para tu trabajo\nround(c(2.5, 3.5))\n\n[1] 2 4\n\njanitor::round_half_up(c(2.5, 3.5))\n\n[1] 3 4\n\n\n\n\nFunciones estadísticas\nPRECAUCIÓN: Las funciones que aparecen a continuación incluyen por defecto los valores faltantes en los cálculos. Los valores faltantes darán como resultado una salida de NA, a menos que se especifique el argumento na.rm = TRUE. Esto se puede escribir de forma abreviada como na.rm = T.\n\n\n\nObjetivo\nFunción**\n\n\n\n\nmedia (promedio)\nmean(x, na.rm=T)\n\n\nmediana\nmedian(x, na.rm=T)\n\n\ndesviación estándar\nsd(x, na.rm=T)\n\n\ncuantiles*\nquantile(x, probs)\n\n\nsuma\nsum(x, na.rm=T)\n\n\nvalor mínimo\nmin(x, na.rm=T)\n\n\nvalor máximo\nmax(x, na.rm=T)\n\n\nrango de valores numéricos\nrange(x, na.rm=T)\n\n\nresumen**\nsummary(x)\n\n\n\nNotas:\n\n*quantile(): x es el vector numérico a examinar, y probs = es un vector numérico con probabilidades entre 0 y 1.0, por ejemplo c(0.5, 0.8, 0.85)\n**summary(): da un resumen estadístico sobre un vector numérico incluyendo la media, mediana y percentiles más comunes\n\nPELIGRO: Si proporciona un vector de números a una de las funciones anteriores, asegúrese de envolver los números dentro de c().\n\n# Si se suministran números sin procesar a una función, envolver con c()\nmean(1, 6, 12, 10, 5, 0)    # !!! INCORRECTO !!!  \n\n[1] 1\n\nmean(c(1, 6, 12, 10, 5, 0)) # CORRECTO\n\n[1] 5.666667\n\n\n\n\nOtras funciones útiles\n\n\n\n\n\n\n\n\nObjetivo\nFunción\nEjemplo**\n\n\n\n\ncrear una secuencia\nseq(de, a, por)\nseq(1, 10, 2)\n\n\nrepetir x, n veces\nrep(x, nveces)\nrep(1:3, 2) or rep(c(\"a\", \"b\", \"c\"), 3)\n\n\nsubdividir un vector numérico\ncut(x, n)\ncut(linelist$age, 5)\n\n\ntomar una muestra aleatoria\nsample(x, tamaño)\nsample(linelist$id, size = 5, replace = TRUE)\n\n\n\n\n\n\n\n%in%\nUn operador muy útil para comparar valores, y para evaluar rápidamente si un valor está dentro de un vector o dataframe.\n\nmy_vector &lt;- c(\"a\", \"b\", \"c\", \"d\")\n\n\n\"a\" %in% my_vector\n\n[1] TRUE\n\n\"h\" %in% my_vector\n\n[1] FALSE\n\n\nPara preguntar si un valor no está %in% en un vector, pon un signo de exclamación (!) delante de la declaración lógica:\n\n# para negar, pon una exclamación delante\n!\"a\" %in% my_vector\n\n[1] FALSE\n\n!\"h\" %in% my_vector\n\n[1] TRUE\n\n\n%in% es muy útil cuando se utiliza la función case_when() de dplyr. Se puede definir un vector previamente y referenciarlo después. Por ejemplo:\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist &lt;- linelist %&gt;% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age &lt; 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\n\nNota: Si quieres detectar una cadena parcial, quizás usando str_detect() de stringr, no aceptará un vector de caracteres como c(\"1\", \"Yes\", \"yes\", \"y\"). En su lugar, se le debe dar una expresión regular - una cadena condensada con barras OR, como “1|Yes|yes|y”. Por ejemplo, str_detect(hospitalized, \"1|Yes|yes|y\"). Consulta la página sobre Caracteres y cadenas para obtener más información.\nPuedes convertir un vector de caracteres en una expresión regular con este comando:\n\naffirmative &lt;- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative\n\n[1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\" \n\n# condense to \naffirmative_str_search &lt;- paste0(affirmative, collapse = \"|\")  # opción con R base\naffirmative_str_search &lt;- str_c(affirmative, collapse = \"|\")   # opción con el paquete stringr \n\naffirmative_str_search\n\n[1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\"",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/basics.es.html#errors-warnings",
    "href": "new_pages/basics.es.html#errors-warnings",
    "title": "3  Fundamentos de R",
    "section": "3.13 Errores & avisos",
    "text": "3.13 Errores & avisos\nEn esta sección se explica:\n\nLa diferencia entre errores y avisos (warnings)\nConsejos generales de sintaxis para escribir código R\nCódigo de asistencia\n\nEn las página de Errores comunes y de Obtener ayuda se pueden encontrar los errores y avisos más comunes, así como consejos para la resolución de problemas.\n\n\nError vs aviso\nCuando se ejecuta un comando, la Consola de R puede mostrarte mensajes de aviso o error en texto rojo.\n\nUna aviso significa que R ha completado su comando, pero ha tenido que dar pasos adicionales o ha producido una salida inusual de la que deberías estar al tanto.\nUn error significa que R no pudo completar su comando.\n\nBusca pistas:\n\nEl mensaje de error/advertencia suele incluir un número de línea donde está el problema.\nSi un objeto “es desconocido” o “no se encuentra”, quizás lo hayas escrito mal, hayas olvidado llamar a un paquete con library(), o hayas olvidado volver a ejecutar tu script después de hacer cambios.\n\nSi todo lo demás falla, copia el mensaje de error en Google junto con algunos términos clave; lo más probable es que a alguien le haya pasado lo mismo y ¡ya haya resuelto el problema!.\n\n\n\nConsejos generales de sintaxis\nAlgunas cosas que hay que recordar al escribir comandos en R, para evitar errores y advertencias:\n\nCierra siempre los paréntesis - consejo: cuenta el número de paréntesis de apertura “(” y de cierre “)” de cada trozo de código\nEvita los espacios en los nombres de columnas y objetos. Utiliza barras bajas ( _ ) o puntos ( . ) en su lugar\nNo olvides separar los argumentos de una función con comas\nR distingue entre mayúsculas y minúsculas, lo que significa que Variable_A es diferente de variable_A\n\n\n\n\nCódigo de asistencia\nCualquier script (RMarkdown o de otro tipo) te dará pistas cuando hayas cometido un error. Por ejemplo, si te olvidaste de escribir una coma donde se necesita, o de cerrar un paréntesis, RStudio levantará una bandera en esa línea, a la derecha del script, para avisarte.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fundamentos de R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.es.html",
    "href": "new_pages/transition_to_R.es.html",
    "title": "4  Transición a R",
    "section": "",
    "text": "4.1 Desde Excel\nLa transición de Excel directamente a R es un objetivo muy alcanzable. Puede parecer desalentador, ¡pero puedes hacerlo!\nEs cierto que alguien con grandes conocimientos de Excel puede realizar actividades muy avanzadas sólo con Excel, incluso utilizando herramientas de scripting como VBA. Excel se utiliza en todo el mundo y es una herramienta esencial para la epidemiología. Sin embargo, complementarlo con R puede mejorar y ampliar drásticamente tus flujos de trabajo.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transición a R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.es.html#from-excel",
    "href": "new_pages/transition_to_R.es.html#from-excel",
    "title": "4  Transición a R",
    "section": "",
    "text": "Beneficios\nDescubrirás que el uso de R ofrece inmensos beneficios en cuanto a ahorro de tiempo, análisis más consistentes y precisos, reproducibilidad, posibilidad de compartir y una corrección de errores más rápida. Como cualquier software nuevo, hay una “curva de aprendizaje” en la que hay que invertir tiempo para familiarizarse. Los dividendos serán significativos y se te abrirá un inmenso abanico de nuevas posibilidades con R.\nExcel es un software muy conocido que permite que un principiante pueda realizar análisis y visualizaciones simples con “apuntar y clicar” de manera sencilla. En comparación, puede llevar un par de semanas sentirse cómodo con las funciones y la interfaz de R. Sin embargo, R ha evolucionado en los últimos años para ser mucho más amigable con los principiantes.\nMuchos flujos de trabajo de Excel se basan en la memoria y en la repetición, por lo que hay muchas posibilidades de error. Además, generalmente la limpieza de datos, la metodología de análisis y las ecuaciones utilizadas están ocultas a la vista. A un nuevo colega le puede llevar mucho tiempo aprender lo que hace un libro de Excel y cómo resolver problemas que surjan. Con R, todos los pasos se escriben explícitamente en el script y pueden verse, editarse, corregirse y aplicarse fácilmente a otros conjuntos de datos.\nPara comenzar tu transición de Excel a R debes ajustar tu mentalidad en algunos aspectos importantes:\n\n\nDatos ordenados (tidy data)\nDebes utilizar datos “ordenados” (tidy), legibles por la máquina en lugar de datos desordenados “legibles por el ser humano”. Estos son los tres requisitos principales que los datos “ordenados” deben cumplir, como se explica en este tutorial sobre datos “ordenados” en R:\n\nCada variable debe tener su propia columna\nCada observación debe tener su propia fila\nCada valor debe tener su propia celda\n\nPara los usuarios de Excel: piensa en el papel que desempeñan las “tablas” de Excel para estandarizar los datos y hacer que el formato sea más predecible.\nUn ejemplo de datos “ordenados” sería el listado de casos utilizado en este manual: cada variable está contenida en una columna, cada observación (un caso) tiene su propia fila y cada valor está en una sola celda. A continuación, puede ver las primeras 50 filas del listado:\n\n\n\n\n\n\nLa principal razón por la que nos encontramos con datos no ordenados es porque muchas hojas de cálculo en Excel están diseñadas para dar prioridad a la lectura fácil por parte de los humanos, no a la lectura fácil por parte de las máquinas/el software.\nPara ayudarte a ver la diferencia, a continuación se presentan algunos ejemplos ficticios de datos no ordenados, los cuales dan prioridad a la legibilidad humana sobre la legibilidad-mecánica:\n\n\n\n\n\n\n\n\n\nProblemas: En la hoja de cálculo de arriba, hay celdas combinadas que no son fácilmente digeridas por R. No está claro qué fila debe utilizarse para la “cabecera”. A la derecha hay un diccionario basado en colores y los valores de las celdas están representados por colores, lo que tampoco es fácilmente interpretado por R (¡ni por los humanos que padecen daltonismo!). Además, se combinan diferentes informaciones en una celda (varias organizaciones asociadas que trabajan en un área, o el estado “TBC” en la misma celda que “Partner D”).\n\n\n\n\n\n\n\n\n\nProblemas:* En la hoja de cálculo anterior, hay numerosas filas y columnas vacías adicionales dentro de los datos, lo que provocará dolores de cabeza a la hora de limpiarlos con R. Además, las coordenadas GPS están repartidas en dos filas para un centro de tratamiento determinado. Y, una nota adicional, ¡las coordenadas GPS están en dos formatos diferentes!\nLos datos “ordenados” pueden no ser tan legibles para el ojo humano, pero facilitan mucho la limpieza y el análisis de los datos. Los datos ordenados pueden almacenarse en varios formatos, por ejemplo, “largos” o “anchos” (véase la página sobre Pivotar datos), pero se siguen observando los principios anteriores.\n\n\nFunciones\nPuede que la palabra “función” en R sea nueva, pero el concepto existe también en Excel y se le conoce como fórmulas. Las fórmulas en Excel también requieren una sintaxis precisa (por ejemplo, la colocación de puntos y comas y paréntesis). Lo único que hay que hacer es aprender algunas funciones nuevas y cómo funcionan en R.\n\n\nScripts\nEn lugar de clicar en los botones y arrastrar las celdas, escribirás cada paso y procedimiento en un “script” (secuencia de órdenes). Los usuarios de Excel pueden estar familiarizados con las “macros VBA”, que también emplean un enfoque de scripting (secuencia de comandos VBA).\nEl script de R consiste en instrucciones paso a paso. Esto permite que cualquier colega pueda leer el script y ver fácilmente los pasos que has dado. Esto también ayuda a depurar errores o cálculos inexactos. Consulta la sección sobre scripts del capítulo Fundamentos de R para ver algunos ejemplos.\nEste es un ejemplo de un script en R:\n\n\n\n\n\n\n\n\n\n\n\nRecursos en la migración Excel a R\nAquí hay algunos enlaces a tutoriales que te ayudarán en la transición a R desde Excel:\n\nR vs. Excel\nCurso de RStudio en R para usuarios de Excel\n\n\n\nInteracción R-Excel\nR tiene formas robustas de importar libros de Excel, trabajar con los datos, exportar/guardar archivos de Excel y trabajar con los detalles de las hojas de Excel.\nEs cierto que algunos de los formatos más estéticos de Excel pueden perderse en la traducción (por ejemplo, la cursiva, el texto lateral, etc.). Si tu flujo de trabajo requiere que pases documentos de un lado a otro entre R y Excel conservando el formato original de Excel, prueba paquetes como openxlsx.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transición a R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.es.html#from-stata",
    "href": "new_pages/transition_to_R.es.html#from-stata",
    "title": "4  Transición a R",
    "section": "4.2 Desde Stata",
    "text": "4.2 Desde Stata\n\nLlegando a R desde Stata\nA muchas personas en el campo de la epidemiología se les enseña primero a usar Stata, y puede parecer desalentador pasar a R. Sin embargo, si eres un usuario habitual de Stata, el salto a R es ciertamente más manejable de lo que podrías pensar. Si bien hay algunas diferencias clave entre Stata y R en la forma en que se pueden crear y modificar los datos, así como en la forma en que se implementan las funciones de análisis - después de aprender estas diferencias clave serás capaz de adaptar tus habilidades.\nA continuación, se presentan algunas traducciones clave entre Stata y R, que pueden ser útiles mientras revisas esta guía.\nNotas generales\n\n\n\nSTATA\nR\n\n\n\n\nSólo se puede ver y manipular unos datos a la vez\nPuedes ver y manipular varios conjuntos de datos al mismo tiempo, por lo que con frecuencia tendrás que especificar el conjunto de datos dentro del código\n\n\nComunidad en línea disponible a través de https://www.statalist.org/\nComunidad online disponible a través de RStudio, StackOverFlow y R-bloggers\n\n\nFuncionalidad de apuntar y clicar como una opción\nFuncionalidad mínima de apuntar y clicar\n\n\nAyuda para los comandos disponibles mediante el [comando] help\nAyuda disponible con la [función]? o mediante búsqueda en el panel de ayuda\n\n\nComentar el código usando * o /// o /* TEXTO * /\nComment code using #\n\n\nCasi todos los comandos son propios de Stata. Las funciones nuevas/escritas por el usuario pueden instalarse como archivos ado utilizando el [paquete] ssc install \nR se instala con las funciones base, pero el uso típico implica la instalación de otros paquetes desde CRAN (véase el capítulo sobre Fundamentos de R)\n\n\nEl análisis se suele escribir en un archivo do\nEl análisis se escribe en un script de R en el panel de fuentes de RStudio. Los scripts de R markdown son una alternativa.\n\n\n\nDirectorio de trabajo\n\n\n\nSTATA\nR\n\n\n\n\nLos directorios de trabajo implican rutas de archivo absolutas (por ejemplo, “C:/nombredeusuario/documentos/proyectos/datos/”)\nLos directorios de trabajo pueden ser absolutos, o relativos a la carpeta raíz del proyecto utilizando el paquete here (ver Importar y exportar)\n\n\nVer el directorio de trabajo actual con pwd\nUtiliza getwd() o here() (si utilizas el paquete here), con paréntesis vacíos\n\n\nEstablecer el directorio de trabajo con cd “ubicación de la carpeta”\nUsar setwd(\"ubicación de la carpeta\"), o set_here(\"ubicación de la carpeta\"), si utilizas el paquete here)\n\n\n\nImportación y visualización de datos\n\n\n\nSTATA\nR\n\n\n\n\nComandos específicos por tipo de archivo\nUsar import() del paquete rio para casi todos los tipos de archivos. Existen funciones específicas como alternativas (véase Importar y exportar)\n\n\nLa lectura de los archivos csv se realiza mediante la importación delimitada “nombrearchivo.csv”\nUsar import(\"nombredearchivo.csv\")\n\n\nLa lectura de los archivos xslx se realiza mediante la importación de excel “nombre de archivo.xlsx”\nUsar import(\"nombredearchivo.xlsx\")\n\n\nExaminar sus datos en una nueva ventana utilizando el comando browse\nVer unos datos en el panel de origen de RStudio utilizando View(datos). Es necesario especificar el nombre de los datos a la función en R porque se pueden mantener varios conjuntos de datos al mismo tiempo. Atención a la “V” mayúscula en esta función\n\n\nObtener una visión general de alto nivel de su set de datos utilizando summarize, que proporciona los nombres de las variables y la información básica\nObtener una visión general de los datos mediante summary(datos)\n\n\n\nManipulación básica de datos\n\n\n\nSTATA\nR\n\n\n\n\nLas columnas de los datos suelen denominarse “variables”\nMás a menudo se denominan “columnas” o a veces “vectores” o “variables”\n\n\nNo es necesario especificar los datos\nEn cada uno de los siguientes comandos, es necesario especificar los datos - véase la página sobre Limpieza de datos y funciones básicas para ver ejemplos\n\n\nLas nuevas variables se crean con el comando generate varname =\nGenerar nuevas variables utilizando la función mutate(varname = ). Consultar la página sobre Limpieza de datos y funciones básicas para obtener detalles sobre todas las funciones de dplyr que aparecen a continuación.\n\n\nLas variables se renombran mediante rename nombre_antiguo nombre_nuevo\nLas columnas pueden renombrarse mediante la función rename(nombre_antiguo = nombre_nuevo)\n\n\nLas variables se eliminan con drop variable\nLas columnas pueden eliminarse mediante la función select() con el nombre de la columna detrás de un signo menos, entre paréntesis\n\n\nLas variables factoriales se pueden etiquetar utilizando una serie de comandos como label define\nEl etiquetado de los valores puede hacerse convirtiendo la columna en tipo Factor y especificando los niveles. Mira en la página sobre Factores. Los nombres de las columnas no suelen estar etiquetados como en Stata.\n\n\n\nAnálisis descriptivo\n\n\n\n\n\n\n\nSTATA\nR\n\n\n\n\nTabular los recuentos de una variable mediante el tab variable\nProporcionar los datos y el nombre de la columna al comando table() como table(conjunto_de_datos\\(nombre_columna). Alternativamente, utilizar count(varname) del paquete **dplyr**, como se explica en [Agrupar datos](#grouping-data)\nLa tabulación cruzada de dos variables en una tabla de 2x2 se realiza con **tab** *variable1 variable2* | Utilizar `table(datos\\)nombre_variable1, datos$nombre_variable2 o count(nombre_variable1, nombre_variable2)`\n\n\n\nAunque esta lista ofrece una visión general de los fundamentos de la traducción de los comandos de Stata a R, no es exhaustiva. Hay muchos otros grandes recursos para los usuarios de Stata que podrían ser de interés en tu transición a R:\n\nhttps://dss.princeton.edu/training/RStata.pdf\n\nhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.html\n\nhttp://r4stats.com/books/r4stata/",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transición a R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.es.html#from-sas",
    "href": "new_pages/transition_to_R.es.html#from-sas",
    "title": "4  Transición a R",
    "section": "4.3 Desde SAS",
    "text": "4.3 Desde SAS\n\nPasar de SAS a R\nSAS se utiliza habitualmente en las agencias de salud pública y en los campos de investigación académica. Aunque la transición a un nuevo lenguaje no suele ser un proceso sencillo, entender las diferencias clave entre SAS y R puede ayudarte a empezar a navegar por el nuevo lenguaje utilizando el lenguaje de partida. A continuación se describen las principales traducciones en materia de gestión de datos y análisis descriptivo entre SAS y R.\nNotas generales\n\n\n\nSAS\nR\n\n\n\n\nComunidad en línea disponible a través del Servicio de Atención al Cliente de SAS\nComunidad online disponible a través de RStudio, StackOverFlow y R-bloggers\n\n\nAyuda para los comandos disponibles mediante help [comando]\nAyuda disponible usando mediante [función]? o buscando en el panel de ayuda\n\n\nComentar el código usando * TEXTO ; o /* TEXTO */\nComentar el código usando #\n\n\nCasi todos los comandos están incorporados. Los usuarios pueden escribir nuevas funciones utilizando macros SAS, SAS/IML, SAS Component Language (SCL) y, más recientemente, los procedimientos Proc Fcmp y Proc Proto\nR se instala con las funciones base, pero el uso típico implica la instalación de otros paquetes desde CRAN (véase la página sobre Fundamentos de R)\n\n\nEl análisis suele realizarse escribiendo un programa SAS en la ventana del Editor.\nAnálisis escrito en un script de R en el panel de fuentes de RStudio. Los scripts de R markdown son una alternativa.\n\n\n\nDirectorio de trabajo\n\n\n\nSAS\nR\n\n\n\n\nLos directorios de trabajo pueden ser absolutos o relativos a la carpeta raíz del proyecto, definiendo la carpeta raíz con %let rootdir=/ruta raíz; %include \"&rootdir/subfoldername/archivo\"\nLos directorios de trabajo pueden ser absolutos, o relativos a la carpeta raíz del proyecto utilizando el paquete here (ver Importar y exportar)\n\n\nVer el directorio de trabajo actual con %put %sysfunc(getoption(work));\nUtilizar getwd() o here() (si utilizas el paquete here), con paréntesis vacíos\n\n\nEstablecer el directorio de trabajo con libname \"ubicación de la carpeta\"\nUtiliza setwd(\"ubicación de la carpeta\"), o set_here(\"ubicación de la carpeta\") si utilizas el paquete here\n\n\n\nImportación y visualización de datos\n\n\n\nSAS\nR\n\n\n\n\nUtiliza el procedimiento Proc Import o la sentencia Data Step Infile.\nUtiliza import() del paquete rio para casi todos los tipos de archivos. Existen funciones específicas como alternativas (véase Importar y exportar)\n\n\nLa lectura de los archivos csv se realiza mediante Proc Import datafile=\"nombre de archivo.csv\" out=nombre de archivo dbms=CSV; run; O mediante la sentencia Data Step Infile\nUtiliza import(“nombredearchivo.csv”)\n\n\nLa lectura de los archivos xslx se realiza utilizando Proc Import datafile=\"filename.xlsx\" out=work.filename dbms=xlsx; run; O utilizando la sentencia [Data Step Infile\nUse](http://support.sas.com/techsup/technote/ts673.pdf)\n\n\nExaminar los datos en una nueva ventana abriendo la ventana del Explorador y seleccionar la biblioteca deseada y los datos\nVer unos datos en el panel de RStudio utilizando View(datos). Se necesita especificar el nombre del set de datos a la función en R porque se pueden mantener múltiples conjuntos de datos al mismo tiempo. Atención a la “V” mayúscula en esta función\n\n\n\nManipulación básica de datos\n\n\n\nSAS\nR\n\n\n\n\nLas columnas de los datos suelen denominarse “variables”\nMás a menudo se denominan “columnas” o a veces “vectores” o “variables”\n\n\nNo es necesario ningún procedimiento especial para crear una variable. Las nuevas variables se crean simplemente escribiendo el nombre de la nueva variable, seguido de un signo igual, y luego una expresión para el valor\nGenerar nuevas variables utilizando la función mutate(). Consulta la página sobre Limpieza de datos y funciones básicas para obtener detalles sobre todas las funciones de dplyr que aparecen a continuación.\n\n\nLas variables se renombran utilizando rename *nombre_antiguo=nuevo_nombre*.\nLas columnas pueden renombrarse mediante la función rename(nuevo_nombre = nombre_antiguo)\n\n\nLas variables se guardan con **keep**=nombre de la variable\nLas columnas pueden seleccionarse mediante la función select() con el nombre de la columna entre paréntesis\n\n\nLas variables se eliminan con **drop**=nombre de la variable\nLas columnas pueden eliminarse mediante la función select() con el nombre de la columna detrás de un signo menos, entre paréntesis\n\n\nLas variables factoriales pueden etiquetarse en el mediante la sentencia Label\nEl etiquetado de los valores puede hacerse convirtiendo la columna en una de tipo Factor y especificando los niveles. Véase la página sobre Factores. Los nombres de las columnas no se suelen etiquetar.\n\n\nLos registros se seleccionan utilizando la sentencia Where o If. Las condiciones de selección múltiple se separan con el comando “and”.\nLos registros se seleccionan mediante la función filter() con múltiples condiciones de selección separadas por un operador AND (&) o una coma\n\n\nLos datos se combinan utilizando la sentencia Merge. Los datos que se van a combinar deben ordenarse primero mediante el procedimiento Proc Sort.\nEl paquete dplyr ofrece algunas funciones para fusionar conjuntos de datos. Para más detalles, consulta la página de Unir datos.\n\n\n\nAnálisis descriptivo\n\n\n\nSAS\nR\n\n\n\n\nObtener una visión general de los datos mediante el procedimiento Proc Summary, que proporciona los nombres de las variables y las estadísticas descriptivas\nObtener una visión general de tus datos mediante summary(datos) o skim(datos) del paquete skimr\n\n\nTabular los recuentos de una variable utilizando proc freq data=Dataset; Tables varname; Run;\nVéase la página sobre tablas descriptivas. Las opciones incluyen table() de R base, y tabyl() del paquete janitor, entre otras. Ten en cuenta que tendrás que especificar los datos y el nombre de la columna, ya que R mantiene múltiples conjuntos de datos.\n\n\nLa tabulación cruzada de dos variables en una tabla 2x2 se realiza con proc freq data=Dataset; Tables rowvar* colvar; Run;\nDe nuevo, se puedes utilizar table(), tabyl() u otras opciones como se describe en la página de tablas descriptivas.\n\n\n\nAlgunos recursos útiles:\nR for SAS and SPSS Users (2011)\nSAS and R, Second Edition (2014)",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transición a R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.es.html#inter-data",
    "href": "new_pages/transition_to_R.es.html#inter-data",
    "title": "4  Transición a R",
    "section": "4.4 Interoperabilidad de los datos",
    "text": "4.4 Interoperabilidad de los datos\n\nConsulta la página de importación y exportación para obtener detalles sobre cómo el paquete rio puede importar y exportar los archivos .dta de STATA, los archivos .xpt y .sas7bdat de SAS, los archivos .por y .sav de SPSS, y muchos otros.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transición a R</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.es.html",
    "href": "new_pages/packages_suggested.es.html",
    "title": "5  Paquetes recomendados",
    "section": "",
    "text": "5.1 Paquetes desde CRAN\n######################################################\n# Listado de paquetes útiles para epidemiología en R #\n######################################################\n\n# Este código usa la función p_load() del paquete \"pacman\", \n# la cual instala el paquete si todavía no está instalado y en caso de no ser necesaria la instalación, procede a cargar el paquete. \n\n\n# Asegúrate que el paquete \"pacman\" está instalado\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# Paquetes disponibles desde CRAN\n#################################\npacman::p_load(\n     \n     # Aprendiendo R\n     ###############\n     learnr,   # tutoriales interactivos en tu panel de R Studio\n     swirl,    # tutoriales interactivos en tu consola de R\n        \n     # Manejo de archivos y proyecto \n     ###############################\n     here,     # describir ruta de archivo dentro de la carpeta principal del proyecto\n     rio,      # importación/exportación de múltiples tipos de datos\n     openxlsx, # importación/exportación de libros con múltiples hojas de excel\n     \n     # Manejo e instalación de paquetes\n     ##################################\n     pacman,   # instalación/carga de paquetes\n     renv,     # manejo de versiones de paquetes para trabajar con grupos colaborativos.\n     remotes,  # instalación de paquetes desde github\n     \n     # Manejo general de datos\n     #########################\n     tidyverse,    # incluye múltiples paquetes para el tratamiento de datos en formato tidy y presentación de los mismos.\n          #dplyr,      # manejo de datos\n          #tidyr,      # manejo de datos\n          #ggplot2,    # visualización de datos\n          #stringr,    # trabajo con cadenas y caracteres\n          #forcats,    # trabajo con factores\n          #lubridate,  # trabajo con fechas\n          #purrr       # iteraciones y trabajo con listas\n     linelist,     # limpiar linelists\n     naniar,       # trabajo con valores perdidos\n     \n     # Estadística  \n     ############\n     janitor,      # tablas y limpieza de datos\n     gtsummary,    # hacer tablas descriptivas con valores estadísticos\n     rstatix,      # realización rápida de test estadísticos y tablas descriptivas\n     broom,        # pasar a formato tidy los resultados de las regresiones\n     lmtest,       # realizar test de likelihood-ratio\n     easystats,\n          # parameters, # alternativa para pasar a formato tidy los resultados de las regresiones \n          # see,        # alternativa para visualizar forest plots \n     \n     # Realización de modelos epidémicos\n     ###################################\n     epicontacts,  # analizar cadenas de transmisión\n     EpiNow2,      # estimación de Rt \n     EpiEstim,     # estimación de Rt\n     projections,  # proyecciones de incidencia\n     incidence2,   # hacer curvas epidémicas y manejar datos de incidencia\n     i2extras,     # Funciones extra para el paquete incidence2 \n     epitrix,      # funciones útiles para epidemiología\n     distcrete,    # Distribuciones discretas de demora o retardo\n     \n     # plots - general\n     #################\n     #ggplot2,         # incluido en tidyverse\n     cowplot,          # combinar plots  \n     # patchwork,      # alternativa para combinar plots    \n     RColorBrewer,     # escalas de color\n     ggnewscale,       # para añadir capas de color adicionales\n     \n     # plots - tipos específicos\n     ########################\n     DiagrammeR,       # diagramas empleando lenguaje DOT\n     incidence2,       # curvas epidémicas\n     gghighlight,      # destacar un subgrupo\n     ggrepel,          # etiquetas inteligentes (smart labels)\n     plotly,           # gráficos interactivos\n     gganimate,        # gráficos animados\n\n     \n     # gis\n     ######\n     sf,               # manejo de datos espaciales usando el formato Simple Features\n     tmap,             # producción sencilla de mapas, tanto estáticos como interactivos\n     OpenStreetMap,    # añadir una base con un mapa de OSM a un mapa en ggplot\n     spdep,            # estadística espacial\n     \n     # reportes rutinarios\n     #################\n     rmarkdown,        # producción de archivos PDF, Word, Powerpoint y HTML\n     reportfactory,    # auto-organización de los trabajos realizados en R Markdown \n     officer,          # powerpoints\n     \n     # dashboards\n     ############\n     flexdashboard,    # convierte código de R Markdown en un dashboard\n     shiny,            # aplicaciones web interactivas\n     \n     # tablas for para presentaciones\n     #########################\n     knitr,            # generación de reportes y tablas HTML con R Markdown \n     flextable,        # tablas HTML tables\n     #DT,              # tablas HTML (alternativa)\n     #gt,              # tablas HTML (alternativa)\n     #huxtable,        # tablas HTML (alternativa) \n     \n     # filogenética\n     ###############\n     ggtree,           # visualización and anotación de árboles\n     ape,              # análisis de filogenética y evolución\n     treeio            # visualización de archivos filogenéticos\n \n)",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Paquetes recomendados</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.es.html#packages-from-github",
    "href": "new_pages/packages_suggested.es.html#packages-from-github",
    "title": "5  Paquetes recomendados",
    "section": "5.2 Paquetes desde Github",
    "text": "5.2 Paquetes desde Github\nA continuación se muestran los comandos para instalar dos paquetes directamente desde los repositorios de Github.\n\nLa versión de desarrollo de epicontacts tiene la capacidad de hacer árboles de transmisión con un eje temporal-x\nEl paquete epirhandbook contiene todos los datos de ejemplo de este manual y puede utilizarse para descargar la versión sin conexión del manual.\n\n\n# Paquetes para descargar desde Github (no disponibles en CRAN)\n##########################################################\n\n# Version en desarrollo de epicontacts (para cadenas de transmisión con eje temporal en el eje x)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# El paquete de este manual, el cual incluye todos los datos empleados en los ejemplos \npacman::p_install_gh(\"appliedepi/epirhandbook\")",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Paquetes recomendados</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.es.html",
    "href": "new_pages/r_projects.es.html",
    "title": "6  Proyectos en R",
    "section": "",
    "text": "6.1 Uso sugerido\nUna forma común, eficiente y sencilla de utilizar R es combinar 3 elementos. Un proyecto de trabajo concreto se aloja dentro de un proyecto R. Cada uno de los tres elementos anteriores se describe a continuación.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Proyectos en R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.es.html#suggested-use",
    "href": "new_pages/r_projects.es.html#suggested-use",
    "title": "6  Proyectos en R",
    "section": "",
    "text": "Un proyecto en R\n\n\nUn entorno de trabajo autónomo con carpetas para datos, scripts, salidas (outputs), etc\n\n\nEl paquete here, el cual se utiliza para indicar las rutas relativas de los archivos\n\n\nLas rutas de los archivos se escriben en relación con la ubicación de la carpeta raíz del proyecto R - véase Importar y exportar para más información\n\n\nEl paquete rio para importar/exportar -import() y export() manejan cualquier tipo de archivo por su extensión (por ejemplo, .csv, .xlsx, .png)",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Proyectos en R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.es.html#creating-an-r-project",
    "href": "new_pages/r_projects.es.html#creating-an-r-project",
    "title": "6  Proyectos en R",
    "section": "6.2 Creación de un proyecto R",
    "text": "6.2 Creación de un proyecto R\nPara crear un proyecto R, selecciona “New proyect” en el menú File (Archivo).\n\nSi quieres crear una nueva carpeta para el proyecto, selecciona “New directory” e indica dónde quieres crear la carpeta.\nSi deseas crear el proyecto dentro de una carpeta existente, cliquea en “Existing Directory” e indica la carpeta.\nSi quieres clonar un repositorio de Github, selecciona la tercera opción “Version Control” y luego “Git”. Consulta la página Control de versiones y colaboración con Git y Github para más detalles.\n\n\n\n\n\n\n\n\n\n\nEl proyecto R que has creado estará en una carpeta que contiene un archivo .Rproj. Este archivo es un acceso directo y probablemente la forma más directa de abrir tu proyecto. También puedes abrir un proyecto seleccionando “Open Project” en el menú File. Alternativamente, en el extremo superior derecho de RStudio verás un icono de R projects y un menú desplegable de proyectos disponibles.\nPara salir de un proyecto R, abre un nuevo proyecto o cierra el proyecto actual (Archivo - Cerrar proyecto).\n\nCambiar de proyecto\nPara cambiar entre proyectos, clica en el icono de R projects en el menú desplegable en la parte superior derecha de RStudio. Verás las opciones de Cerrar proyecto, Abrir proyecto y una lista de proyectos recientes.\n\n\n\n\n\n\n\n\n\n\n\nAjustes\nGeneralmente se aconseja que inicies RStudio cada vez con una “pizarra limpia” - es decir, con tu espacio de trabajo no arrastrado de la sesión anterior. Esto significará que los objetos y resultados de una sesión no persistirán en la siguiente sesión (deberás volver a crearlos al ejecutar tus scripts). Esto es bueno, porque te obligará a escribir mejores scripts y evitar errores a largo plazo.\nPara configurar RStudio para que haga “borrón y cuenta nueva” cada vez que se inicie:\n\nSelecciona “Project Options” en el menú Tools (Herramientas).\nEn la pestaña “General”, configura RStudio para que no restaure .RData en el espacio de trabajo al iniciar, y para que no guarde el espacio de trabajo en .RData al salir.\n\n\n\nOrganización\nEs habitual tener subcarpetas en tu proyecto. Piensa en tener carpetas como “datos”, “scripts”, “figuras” y “presentaciones”. Puedes añadir carpetas de la forma típica en que añadirías una nueva carpeta en tu ordenador. Alternativamente, puedes ver en la página sobre interacciones con directorios para aprender a crear nuevas carpetas con los comandos de R.\n\n\nControl de versiones\nConsidera utilizar un sistema de control de versiones. Podría ser algo tan simple como tener fechas en los nombres de los scripts (por ejemplo, “transmission_analysis_2020-10-03.R”) y una carpeta de “archivado”. También es buena idea tener un texto de cabecera agregando al comienzo de cada script una descripción, etiquetas, autores y un registro de cambios.\nUn método más complicado implicaría utilizar Github o una plataforma similar para el control de versiones. Consulta la página sobre Control de versiones y colaboración con Git y Github.\nUn consejo es que puedes realizas búsquedas en todo un proyecto o carpeta utilizando la herramienta “Buscar en archivos” (menú Edición). Puedes buscar e incluso reemplazar líneas de script en varios archivos.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Proyectos en R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.es.html#examples",
    "href": "new_pages/r_projects.es.html#examples",
    "title": "6  Proyectos en R",
    "section": "6.3 Ejemplos",
    "text": "6.3 Ejemplos\nA continuación se muestran algunos ejemplos de importación/exportación/guardado utilizando here() desde un proyecto R. Lea más sobre el uso del paquete here en la página de importación y exportación.\nImportación de linelist_raw.xlsx desde la carpeta “data” de tu proyecto R\n\nlinelist &lt;- import(here(\"data\", \"linelist_raw.xlsx\"))\n\nExportar linelist de objetos de R como “my_linelist.rds” a la carpeta “clean” dentro de la carpeta “data” de tu proyecto R.\n\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\n\nGuardando el último gráfico creado como “epicurve_2021-02-15.png” dentro de la carpeta “epicurves” en la carpeta “outputs” de tu proyecto R.\n\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Proyectos en R</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.es.html#resources",
    "href": "new_pages/r_projects.es.html#resources",
    "title": "6  Proyectos en R",
    "section": "6.4 Recursos",
    "text": "6.4 Recursos\nPágina web de RStudio sobre uso de proyectos R",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Proyectos en R</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html",
    "href": "new_pages/importing.es.html",
    "title": "7  Importación y exportación",
    "section": "",
    "text": "7.1 Resumen\nCuando importas unos “datos” en R, generalmente estás creando un nuevo objeto data frame en tu entorno de R y definiéndolo como un archivo importado (por ejemplo, Excel, CSV, TSV, RDS) que será guardado en tu disco en una determinada ruta/dirección.\nPuedes importar/exportar muchos tipos de archivos, incluidos los creados por otros programas estadísticos (SAS, STATA, SPSS). También puedes conectarte a bases de datos relacionales.\nR tiene incluso sus propios formatos de datos:",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#overview",
    "href": "new_pages/importing.es.html#overview",
    "title": "7  Importación y exportación",
    "section": "",
    "text": "Un archivo RDS (.rds) almacena un único objeto R, como un dataframe. Son útiles para almacenar datos limpios, ya que mantienen los tipos de columnas de R. Lee más en esta sección.\nUn archivo RData (.Rdata) puede utilizarse para almacenar múltiples objetos, o incluso un espacio de trabajo R completo. Lee más en esta sección.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#the-rio-package",
    "href": "new_pages/importing.es.html#the-rio-package",
    "title": "7  Importación y exportación",
    "section": "7.2 El paquete rio",
    "text": "7.2 El paquete rio\nEl paquete de R que recomendamos es: rio. El nombre “rio” es una abreviatura de “R I/O” (input/output).\nSus funciones import() y export() pueden manejar muchos tipos de archivos diferentes (por ejemplo, .xlsx, .csv, .rds, .tsv). Cuando se proporciona una ruta de archivo a cualquiera de estas funciones (incluyendo la extensión del archivo como “.csv”), rio leerá la extensión y utilizará la herramienta correcta para importar o exportar el archivo.\nLa alternativa al uso de rio es utilizar funciones de muchos otros paquetes, cada uno de los cuales es específico para un tipo de archivo. Por ejemplo, read.csv() (R base), read.xlsx() (paquete openxlsx), y write_csv() (paquete readr), etc. Estas alternativas pueden ser difíciles de recordar, mientras que usar import() y export() de rio es fácil.\nLas funciones import() y export() de rio utilizan el paquete y la función adecuados para un archivo determinado, basándose en su extensión. Al final de esta página puedes ver una tabla completa de los paquetes/funciones que utiliza rio en segundo plano. También puede utilizarse para importar archivos de STATA, SAS y SPSS, entre otras docenas de tipos de archivos.\nLa importación/exportación de shapefiles requiere otros paquetes, como se detalla en la página sobre Conceptos básicos de los SIG (Sistemas de Información Geográfica).",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#here",
    "href": "new_pages/importing.es.html#here",
    "title": "7  Importación y exportación",
    "section": "7.3 El paquete here",
    "text": "7.3 El paquete here\nEl paquete here y su función here() facilitan la tarea de decirle a R dónde encontrar y guardar tus archivos - en esencia, construye rutas de archivos.\nUtilizado junto con un proyecto R, here te permite describir la ubicación de los archivos en tu proyecto R en relación con el directorio raíz de los proyectos de R (la carpeta de nivel superior). Esto es útil cuando el proyecto R puede ser compartido o accedido por múltiples personas/ordenadores. Evita las complicaciones debidas a las rutas de archivos únicas en diferentes ordenadores (por ejemplo, \"C:/Users/Laura/Documents...\" al “comenzar” la ruta de archivos en un lugar común a todos los usuarios (la raíz del proyecto R).\nAsí es como funciona here() dentro de un proyecto R:\n\nCuando, dentro del proyecto R, se carga por primera vez el paquete here, se coloca un pequeño archivo llamado “.here” en la carpeta raíz de tu proyecto R como un “punto de referencia” o “ancla”\nEn tus scripts, para referenciar un archivo en las subcarpetas del proyecto R, se utiliza la función here() para construir la ruta del archivo en relación con ese ancla\nPara construir la ruta de los archivos, escribe los nombres de las carpetas más allá de la raíz, entre comillas, separados por comas, y finalmente termina con el nombre y la extensión del archivo, como se muestra a continuación\nLas rutas de here() pueden utilizarse tanto para la importación como para la exportación\n\nPor ejemplo, a continuación, la función import() recibe una ruta de archivo construida con here().\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\nEl comando here(\"data\", \"linelists\", \"ebola_linelist.xlsx\") en realidad está proporcionando la ruta completa del archivo que es única para el ordenador del usuario:\n\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\"\nLo bueno es que el comando here() puede ejecutarse en cualquier ordenador que acceda al proyecto R.\nCONSEJO: Si no estás seguro de dónde está la raíz “.here”, ejecuta la función here() con los paréntesis vacíos.\nLee más sobre el paquete here en este enlace.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#file-paths",
    "href": "new_pages/importing.es.html#file-paths",
    "title": "7  Importación y exportación",
    "section": "7.4 Rutas de los archivos",
    "text": "7.4 Rutas de los archivos\nAl importar o exportar datos, debes proporcionar una ruta de archivo. Puedes hacerlo de tres maneras:\n\nRecomendado: proporcionar una ruta de archivo “relativa” con el paquete here\nProporcionar la ruta “completa” / “absoluta” del archivo\nSeleccionar manualmente los archivos\n\n\nRutas de archivos “relativas”\nEn R, las rutas de archivo “relativas” consisten en la ruta de archivo relativa a la raíz de un proyecto R. Permiten rutas de archivo más simples que pueden funcionar en diferentes ordenadores (por ejemplo, si el proyecto R está en una unidad compartida o se envía por correo electrónico). Como se ha descrito anteriormente las rutas de archivo relativas se facilitan mediante el uso del paquete here.\nA continuación se muestra un ejemplo de una ruta de archivo relativa construida con here(). Suponemos que el trabajo está en un proyecto R que contiene una subcarpeta “data” y dentro de ella una subcarpeta “linelists”, en la que está el archivo .xlsx de interés.\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\n\n\nRutas “absolutas”\nLas rutas absolutas o “completas” de los archivos pueden proporcionarse a funciones como import(), pero son “frágiles”, ya que son únicas para el ordenador específico del usuario y, por tanto, no se recomiendan.\nA continuación se muestra un ejemplo de ruta absoluta de archivos, donde en el ordenador de Laura hay una carpeta “analysis”, una subcarpeta “data” y dentro de ésta una subcarpeta “linelists”, en la que se encuentra el archivo .xlsx de interés.\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")\n\nHay que tener en cuenta algunas cosas sobre las rutas absolutas de los archivos:\n\nEvita utilizar rutas absolutas de archivos, ya que el script no funcionará si se ejecuta en un ordenador diferente\n\nUtiliza barras inclinadas (/), como en el ejemplo anterior (nota: esto NO es el valor predeterminado para las rutas de archivos de Windows)\nLas rutas de archivos que comienzan con barras dobles (por ejemplo, “//…”) probablemente no serán reconocidas por R y producirán un error. Considera la posibilidad de trasladar tu trabajo a una unidad “con nombre” o que comience con una letra (por ejemplo, “J:” o “C:”). Consulta la página sobre interacciones con directorios para obtener más detalles sobre esta cuestión.\n\nUn escenario en el que las rutas absolutas de los archivos pueden ser apropiadas es cuando se quiere importar un archivo desde una unidad compartida que tiene la misma ruta de archivo completa para todos los usuarios.\nCONSEJO: Para convertir rápidamente las barras inclinadas \\ a /, resalta el código de interés, usa Ctrl+f (en Windows), marca la casilla de opción para “En selección”, y luego usa la funcionalidad de reemplazo para convertirlos.\n\n\n\nSelección manual\nPuedes importar datos manualmente mediante uno de estos métodos:\n\nEn el panel de entorno de RStudio, cliquea en “Import Dataset”, y selecciona el tipo de datos\nCliquea en File / Import dataset / (selecciona el tipo de datos)\nPara codificar la selección manual, utiliza el comando de file.choose() (dejando los paréntesis vacíos) para provocar la aparición de una ventana emergente que permita al usuario seleccionar manualmente el archivo de su ordenador. Por ejemplo:\n\n\n# Selección manual de un archivo. Cuando se ejecute este comando, aparecerá una ventana EMERGENTE.\n\n# La ruta del archivo seleccionado será suministrada al comando import().\n\nmy_data &lt;- import(file.choose())\n\nCONSEJO: La ventana emergente puede aparecer DETRÁS de la ventana de RStudio.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#import-data",
    "href": "new_pages/importing.es.html#import-data",
    "title": "7  Importación y exportación",
    "section": "7.5 Importar datos",
    "text": "7.5 Importar datos\nUtilizar import() es bastante sencillo. Simplemente escribe la ruta del archivo (incluyendo el nombre y la extensión del archivo) entre comillas. Si utilizas here() para construir la ruta del archivo, sigue las instrucciones anteriores. A continuación se muestran algunos ejemplos:\nPara importar un archivo csv que se encuentra en tu “directorio de trabajo” o en la carpeta raíz del proyecto R:\n\nlinelist &lt;- import(\"linelist_cleaned.csv\")\n\nPara importar la primera hoja de un archivo de Excel que se encuentra en las subcarpetas “data” y “linelists” del proyecto R (la ruta del archivo construida con here()):\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\n\nPara importar un data frame (un archivo .rds) utilizando una ruta de archivo absoluta:\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")\n\n\nHojas de Excel específicas\nPor defecto, si proporcionas un archivo de Excel (.xlsx) a import(), se importará la primera hoja del libro. Si deseas importar una hoja específica, incluye el nombre de la hoja con el argumento which =. Por ejemplo:\n\nmy_data &lt;- import(\"my_excel_file.xlsx\", which = \"Sheetname\")\n\nUtilizando el método here() para proporcionar una vía relativa a import(), también podés importar una hoja específica añadiendo el argumento which = después del paréntesis de cierre de la función here().\n\n# Demostración: importación de una hoja de Excel específica al utilizar rutas relativas con el paquete 'here'\nlinelist_raw &lt;- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  \n\nPara exportar un dataframe de R a una hoja de Excel específica y que el resto del archivo de Excel permanezca sin cambios, tendrás que importar, editar y exportar con un paquete alternativo destinado a este fin, como openxlsx. Vea más información en la página sobre las interacciones con directorios o en esta página de github.\nSi tu libro de Excel es .xlsb (libro de Excel en formato binario) es posible que no puedas importarlo con rio. Considera la posibilidad de volver a guardarlo como .xlsx, o de utilizar un paquete como readxlsb, creado para este fin.\n\n\n\nValores faltantes\nEs posible que desees designar qué valor(es) de tus datos se debe(n) considerar como faltantes (missing values). Como se explica en la página sobre Valores faltantes, el valor en R para los valores faltantes es NA, pero tal vez los datos que vas a importar utiliza 99, “Missing”, o simplemente el espacio de caracteres vacíos “” en su lugar.\nUtiliza el argumento na = en import() y proporciona el(los) valor(es) entre comillas (incluso si son números). Puedes especificar varios valores incluyéndolos dentro de un vector, utilizando c() como se muestra a continuación.\nAquí, el valor “99” en los datos importados se considera valor faltante y se convierte en NA en R.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\n\nAquí, cualquiera de los valores “Missing”, “” (celda vacía), o ” ” (un solo espacio) en los datos importados se convierten en NA en R.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))\n\n\n\n\nSaltar filas\nSi querés evitar la importación de una fila de datos, puedes hacerlo con el argumento skip = utilizando import() de rio en un archivo .xlsx o .csv. Debes proporcionar el número de filas que deseas omitir.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\", skip = 1)  # no importa la fila de cabecera\n\nDesafortunadamente, skip = sólo acepta un valor entero, no un rango (por ejemplo, “2:10” no funciona). Para omitir la importación de filas específicas que no son consecutivas desde el principio, considera la posibilidad de importar varias veces y utilizar bind_rows() de dplyr. Mira en el ejemplo siguiente cómo se omite sólo la fila 2.\n\n\nGestionar una segunda fila de cabecera\nA veces, tus datos pueden tener una segunda fila de cabecera, por ejemplo, si se trata de una fila de “diccionario de datos”, como se muestra a continuación. Esta situación puede ser problemática porque puede hacer que todas las columnas se importen como de tipo “carácter”.\nA continuación se muestra un ejemplo de este tipo de de datos (en el que la primera fila es el diccionario de datos).\n\n\n\n\n\n\n\nEliminar la segunda fila de la cabecera\nPara eliminar la segunda fila de la cabecera, tendrás que importar los datos dos veces.\n\nImportar los datos para almacenar los nombres correctos de las columnas\nImportar los datos de nuevo, saltándose las dos primeras filas (cabecera y segunda fila) 3)Vincular los nombres correctos en el dataframe reducido\n\nEl argumento exacto utilizado para vincular los nombres de las columnas correctas depende del tipo de archivo de datos (.csv, .tsv, .xlsx, etc.). Esto se debe a que rio utiliza una función diferente para los distintos tipos de archivos (véase la tabla anterior).\nPara los archivos de Excel: (col_names =)\n\n# importa por primera vez; almacena los nombres de las columnas\nlinelist_raw_names &lt;- import(\"linelist_raw.xlsx\") %&gt;% names()  # guarda los nombres de columna\n\n# importa por segunda vez; omite la fila 2, y asigna los nombres de las columnas al argumento col_names =\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n\nPara archivos CSV: (col.names =)\n\n# primera importación; almacena los nombres de las columnas\nlinelist_raw_names &lt;- import(\"linelist_raw.csv\") %&gt;% names() # save true column names\n\n# nota: el argumento para archivos csv es 'col.names = '\nlinelist_raw &lt;- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n\nOpción alternativa - cambiar los nombres de las columnas utilizando un comando separado\n\n# asigna/reescribe cabecesas usando la función 'colnames()' de R base\ncolnames(linelist_raw) &lt;- linelist_raw_names\n\n\n\nHacer un diccionario de datos\nBonus! Si tienes una segunda fila que es un diccionario de datos, puedes crear fácilmente un diccionario de datos propio a partir de ella. Este consejo está adaptado de este post.\n\ndict &lt;- linelist_2headers %&gt;%             # linelist con como primera fila\n  head(1) %&gt;%                             # mantener sólo los nombres de las columnas y la primera fila del diccionario \n  pivot_longer(cols = everything(),       # pivotar todas las columnas a formato largo\n               names_to = \"Column\",       # asignar nuevos nombres de columnas\n               values_to = \"Description\")\n\n\n\n\n\n\n\n\n\nCombinar las dos filas de la cabecera\nEn algunos casos, cuando los datos crudos tienen dos filas de cabecera (o, más concretamente, la segunda fila de datos es una cabecera secundaria), es posible que desees “combinarlas” o añadir los valores de la segunda fila de cabecera a la primera fila de cabecera.\nEl comando siguiente definirá los nombres de las columnas del dataframe como la combinación del primer encabezado (verdadero) con el valor inmediatamente inferior (en la primera fila).\n\nnames(my_data) &lt;- paste(names(my_data), my_data[1, ], sep = \"_\")\n\n\n\n\n\nHojas de Google\nPuedes importar datos de una hoja de cálculo de Google en línea con el paquete googlesheet4 y autenticando tu acceso al archivo.\n\npacman::p_load(\"googlesheets4\")\n\nA continuación, se importa y guarda una hoja de Google de demostración. Este comando puede solicitar la autentificación de tu cuenta de Google. Sigue las indicaciones y las ventanas emergentes de tu navegador web para conceder a los paquetes de la API de Tidyverse permisos para editar, crear y eliminar sus hojas de cálculo en Google Drive.\nLa hoja que aparece a continuación es “visible para cualquiera con el enlace” y puedes intentar importarla.\n\nGsheets_demo &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\n\nLa hoja también puede importarse utilizando sólo el ID de la hoja, así es una url más corta:\n\nGsheets_demo &lt;- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")\n\nOtro paquete, googledrive ofrece funciones útiles para escribir, editar y eliminar hojas de Google. Por ejemplo, utilizando las funciones gs4_create() y sheet_write() que se encuentran en este paquete.\nAquí hay otros tutoriales útiles en línea:\ntutorial básico de importación de hojas de Google\ntutorial más detallado\ninteracción entre googlesheets4 y tidyverse",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#multiple-files---import-export-split-combine",
    "href": "new_pages/importing.es.html#multiple-files---import-export-split-combine",
    "title": "7  Importación y exportación",
    "section": "7.6 Múltiples archivos - importar, exportar, dividir, combinar",
    "text": "7.6 Múltiples archivos - importar, exportar, dividir, combinar\nConsulta la página sobre Iteración, bucles y listas para ver ejemplos de cómo importar y combinar múltiples archivos, o múltiples archivos de Excel. Esa página también tiene ejemplos sobre cómo dividir un dataframe en partes y exportar cada uno por separado, o como hojas específicas en un archivo de Excel.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#import_github",
    "href": "new_pages/importing.es.html#import_github",
    "title": "7  Importación y exportación",
    "section": "7.7 Importar desde Github",
    "text": "7.7 Importar desde Github\nImportar datos directamente de Github a R puede ser muy fácil o puede requerir algunos pasos - dependiendo del tipo de archivo. A continuación se presentan algunos enfoques:\n\nCSV files\nEs fácil importar un archivo .csv directamente desde Github a R con un comando de R.\n\nVe al repositorio de Github, localiza el archivo de interés y clica sobre él\nCliquea en el botón “Raw” (entonces verás los datos csv “crudos”, como se muestra a continuación)\nCopia la URL (dirección web)\nPega la URL entre comillas dentro del comando de R import()\n\n\n\n\n\n\n\n\n\n\n\n\nXLSX files\nEs posible que no puedas ver los datos “en crudo” (raw) de algunos archivos (por ejemplo, .xlsx, .rds, .nwk, .shp)\n\nVe al repositorio de Github, localica el archivo de interés y clica sobre él\nCliquea en el botón “Download”, como se muestra a continuación\nGuarda el archivo en tu ordenador e impórtalo en R\n\n\n\n\n\n\n\n\n\n\n\n\nShapefiles\nLos shapefiles tienen muchos archivos subcomponentes, cada uno con una extensión diferente. Un archivo tendrá la extensión “.shp”, pero otros tienen “.dbf”, “.prj”, etc. Para descargar un shapefile de Github, tendrás que descargar cada uno de los archivos subcomponentes individualmente, y guardarlos en la misma carpeta de tu ordenador. En Github, cliquea en cada archivo individualmente y descárgalos clicando en el botón “Download”.\nUna vez guardado en tu ordenador, puedes importar el archivo shape como se muestra en la página de Conceptos básicos de los SIG utilizando st_read() del paquete sf. Sólo tienes que proporcionar la ruta del archivo y el nombre del archivo “.shp”, siempre que los demás archivos relacionados estén en la misma carpeta de tu ordenador.\nA continuación, se puede ver cómo el shapefile “sle_adm3” consta de muchos archivos, cada uno de los cuales debe descargarse de Github.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#manual-data-entry",
    "href": "new_pages/importing.es.html#manual-data-entry",
    "title": "7  Importación y exportación",
    "section": "7.8 Grabación manual de datos",
    "text": "7.8 Grabación manual de datos\n\nEntrada por filas\nUtiliza la función tribble() del paquete tibble de tidyverse (referencia online de tibble).\nObserva que las cabeceras de las columnas comienzan con una tilde (~). Observa también que cada columna debe contener sólo un tipo de datos (carácter, numérico, etc.). Puedes utilizar tabulaciones, espacios y nuevas filas para que la entrada de datos sea más intuitiva y legible. Los espacios no importan entre los valores, pero cada fila está representada por una nueva línea de código. Por ejemplo:\n\n# crea el dataset manualmente por filas\nmanual_entry_rows &lt;- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )\n\nY ahora mostramos el nuevo conjunto de datos:\n\n\n\n\n\n\n\n\nEntrada por columnas\nDado que un dataframe consiste en vectores (columnas verticales), el enfoque básico para la creación manual de dataframes en R espera que definas cada columna y luego las unas. Esto puede ser contrario a la intuición en epidemiología, ya que normalmente pensamos en nuestros datos como una observación por filas (como arriba).\n\n# define cada vector (columna vertical) por separado, cada uno con su propio nombre\nPatientID &lt;- c(235, 452, 778, 111)\nTreatment &lt;- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     &lt;- c(1, 0, 1, 0)\n\nPRECAUCIÓN: Todos los vectores deben tener la misma longitud (el mismo número de valores).\nA continuación, los vectores pueden unirse mediante la función data.frame():\n\n# combina las columnas en un data frame, referenciando los nombres de vectores\nmanual_entry_cols &lt;- data.frame(PatientID, Treatment, Death)\n\nY ahora mostramos el nuevo conjunto de datos:\n\n\n\n\n\n\n\n\nPegar desde el portapapeles\nSi copias los datos de otro lugar y los tienes en el portapapeles, puedes probar una de las dos formas siguientes:\nCon el paquete clipr, puedes utilizar read_clip_tbl() para importar como un dataframe, o simplemente read_clip() para importar como un vector de caracteres. En ambos casos, deja los paréntesis vacíos.\n\nlinelist &lt;- clipr::read_clip_tbl()  # importar portapapeles actual como data frame\nlinelist &lt;- clipr::read_clip()      # importar como vector de caracteres\n\nTambién puedes exportar fácilmente al portapapeles de tu sistema con clipr. Consulta la sección siguiente sobre Exportación.\nAlternativamente, pueder utilizar la función read.table() de R base con file = \"clipboard\") para importar como un dataframe:\n\ndf_from_clipboard &lt;- read.table(\n  file = \"clipboard\",  # especifica esto como \"portapapeles\"\n  sep = \"t\",           # el separador puede ser un tabulador, o una coma, etc.\n  header=TRUE)         # si hay una fila de cabecera",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#import-most-recent-file",
    "href": "new_pages/importing.es.html#import-most-recent-file",
    "title": "7  Importación y exportación",
    "section": "7.9 Importar el archivo más reciente",
    "text": "7.9 Importar el archivo más reciente\nA menudo puedes recibir actualizaciones diarias de tus datos. En este caso, querrás escribir un código que importe el archivo más reciente. A continuación presentamos dos maneras de abordar esto:\n\nSeleccionar el archivo en función de la fecha del nombre del archivo\nSeleccionar el archivo en función de los metadatos del archivo (última modificación)\n\n\nFechas en el nombre del archivo\nEste enfoque se basa en tres premisas:\n\nConfías en las fechas en los nombres de los archivos\nLas fechas son numéricas y aparecen generalmente en el mismo formato (por ejemplo, año, mes y día)\nNo hay otros números en el nombre del archivo\n\nTe explicaremos paso a paso y te mostraremos todos los pasos combinados al final.\nEn primer lugar, utiliza dir() de R base para extraer sólo los nombres de los archivos de la carpeta de interés. Consulta la página sobre interacciones con directorios para obtener más detalles sobre dir(). En este ejemplo, la carpeta de interés es la carpeta “linelists” dentro de la carpeta “example” dentro de “data” dentro del proyecto R.\n\nlinelist_filenames &lt;- dir(here(\"data\", \"example\", \"linelists\")) # obtiene los nombres de ficheros de la carpeta\nlinelist_filenames                                              # los muestra\n\n[1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n[3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n[5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n[7] \"case_linelist20201006.csv\"    \n\n\nUna vez que tengas este vector de nombres, puedes extraer las fechas de ellos aplicando str_extract() de stringr utilizando esta expresión regular. Este comando extrae cualquier número en el nombre del archivo (incluyendo cualquier otro carácter en el medio como guiones o barras). Puedes leer más sobre stringr en la página Caracteres y cadenas.\n\nlinelist_dates_raw &lt;- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extraer números y caracteres entre ellos\nlinelist_dates_raw  # imprimer en la consola (print)\n\n[1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"20201006\"  \n\n\nSuponiendo que las fechas estén escritas en general con el mismo formato de fecha (por ejemplo, Año, Mes y Día) y que los años tengan 4 dígitos, puedes utilizar las funciones de conversión de lubridate (ymd(), dmy() o mdy()) para convertirlas en fechas. Para estas funciones, no importan los guiones, espacios o barras, sino el orden de los números. Lee más en la página Trabajando con fechas.\n\nlinelist_dates_clean &lt;- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean\n\n[1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"2020-10-06\"\n\n\nLa función de R base wich.max() puede utilizarse para devolver la posición del índice (por ejemplo, 1ª, 2ª, 3ª, …) del valor máximo de la fecha. El último archivo se identifica correctamente como el sexto archivo - “case_linelist_2020-10-08.xlsx”.\n\nindex_latest_file &lt;- which.max(linelist_dates_clean)\nindex_latest_file\n\n[1] 6\n\n\nSi condensamos todos estos comandos, el código completo podría ser como el siguiente. Observa que el . en la última línea es un marcador de posición para el objeto canalizado en ese punto de la secuencia de pipes. En ese punto el valor es simplemente el número 6. Esto se coloca entre corchetes dobles para extraer el sexto elemento del vector de nombres de archivo producido por dir().\n\n# load packages\npacman::p_load(\n  tidyverse,         # gestión de datos\n  stringr,           # trabajar con cadenas/caracteres\n  lubridate,         # trabajar con fechas\n  rio,               # importar / exportar\n  here,              # rutas relativas \n  fs)                # interacciones de directorio\n\n# extraer el nombre del último archivo\nlatest_file &lt;- dir(here(\"data\", \"example\", \"linelists\")) %&gt;%  # nombres de archivos de la subcarpeta \"linelists\"    \n  str_extract(\"[0-9].*[0-9]\") %&gt;%                  # extraer fechas (números)\n  ymd() %&gt;%                                        # convertir los números en fechas (asumiendo el formato año-mes-día)\n  which.max() %&gt;%                                 # obtener el índice de la fecha máxima (último archivo)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              #  devuelve el nombre del archivo del último linelist\n\nlatest_file  # mostrar el nombre del último archivo\n\n[1] \"case_linelist_2020-10-08.xlsx\"\n\n\nAhora puedes utilizar este nombre para terminar la ruta relativa del archivo, con here():\n\nhere(\"data\", \"example\", \"linelists\", latest_file) \n\nY ahora puedes importar el último archivo:\n\n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # importar \n\n\n\nUtiliza la información del archivo\nSi tus archivos no tienen fechas en sus nombres (o no te fías de esas fechas), puedes intentar extraer la última fecha de modificación de los metadatos del archivo. Utiliza las funciones del paquete fs para examinar la información de los metadatos de cada archivo, que incluye la fecha y hora de la última modificación y la ruta del archivo.\nA continuación, proporcionamos la carpeta de interés a dir_info() de fs. En este caso, la carpeta de interés está en el proyecto R en la carpeta “data”, la subcarpeta “example”, y su subcarpeta “linelists”. El resultado es un dataframe con una línea por cada archivo y columnas para modification_time, path, etc. Puedes ver un ejemplo visual de esto en la página sobre interacciones con directorios.\nPodemos ordenar este dataframe de archivos por la columna modification_time, y luego mantener sólo la fila superior (último archivo) con la función head() de R base. A continuación, podemos extraer la ruta de este último archivo sólo con la función dplyr pull() en la columna path. Finalmente podemos pasar esta ruta de archivo a import(). El archivo importado se guarda como latest_file.\n\nlatest_file &lt;- dir_info(here(\"data\", \"example\", \"linelists\")) %&gt;%  # recoger información de todos los archivos en el directorio\n  arrange(desc(modification_time)) %&gt;%      # ordenar por tiempo de modificación\n  head(1) %&gt;%                               # mantener sólo el archivo superior (más reciente)\n  pull(path) %&gt;%                            # extraer sólo la ruta del archivo\n  import()                                  # importar el archivo",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#import_api",
    "href": "new_pages/importing.es.html#import_api",
    "title": "7  Importación y exportación",
    "section": "7.10 APIs",
    "text": "7.10 APIs\nUna “Interfaz de Programación Automatizada” (API) puede utilizarse para solicitar datos directamente de un sitio web. Las API son un conjunto de reglas que permiten que una aplicación de software interactúe con otra. El cliente (tu) envía una “solicitud” y recibe una “respuesta” con contenido. Los paquetes de R httr y jsonlite pueden facilitar este proceso.\nCada sitio web habilitado para la API tendrá su propia documentación y detalles con los que hay que familiarizarse. Algunos sitios están disponibles públicamente y cualquiera puede acceder a ellos. Otros, como las plataformas con ID de usuario y credenciales, requieren autenticación para acceder a sus datos.\nObviamente es necesario disponer de una conexión a Internet para importar datos a través de la API. Te daremos ejemplos breves de uso de las API para importar datos, y presentaremos enlaces a otros recursos.\nNota: recuerda que los datos pueden estar publicados* en un sitio web sin una API, que puede ser más fácil de recuperar. Por ejemplo, un archivo CSV publicado puede ser accesible simplemente proporcionando la URL del sitio a import() como se describe en la sección sobre la importación desde Github.*\n\nPetición HTTP\nEl intercambio de la API se realiza normalmente a través de una solicitud HTTP. HTTP es el Protocolo de Transferencia de Hipertexto, y es el formato subyacente de una solicitud/respuesta entre un cliente y un servidor. La entrada y la salida exactas pueden variar en función del tipo de API, pero el proceso es el mismo: una “Solicitud” (a menudo Solicitud HTTP) del usuario, que suele contener una consulta, seguida de una “Respuesta”, que contiene información de estado sobre la solicitud y posiblemente el contenido solicitado.\nEstos son algunos de los componentes de una petición HTTP:\n\nLa URL completa de la API\nEl “Método” (o “Verbo”)\nHeaders (Encabezados)\nBody (Cuerpo)\n\nEl “método” de la petición HTTP es la acción que se quiere realizar. Los dos métodos HTTP más comunes son GET y POST, pero otros pueden ser PUT, DELETE, PATCH, etc. Cuando se importan datos a R lo más probable es que se utilice GET.\nDespués de la solicitud, tu ordenador recibirá una “respuesta” en un formato similar al que se envió, incluyendo la URL, el estado HTTP (¡status 200 es lo que quieres!), el tipo de archivo, el tamaño y el contenido deseado. A continuación, tendrá que analizar esta respuesta y convertirla en un dataframe viable dentro de su entorno R.\n\n\nPaquetes\nEl paquete httr funciona bien para manejar peticiones HTTP en R. Requiere poco conocimiento previo de las APIs de la web y puede ser utilizado por personas menos familiarizadas con la terminología de desarrollo de software. Además, si la respuesta HTTP es .json, puede utilizar jsonlite para analizar la respuesta.\n\n# cargar paquetes\npacman::p_load(httr, jsonlite, tidyverse)\n\n\n\nDatos de acceso público\nA continuación se muestra un ejemplo de solicitud HTTP, tomado de un tutorial de Trafford Data Lab. Este sitio tiene varios otros recursos para aprender y ejercicios de API.\nEscenario: Queremos importar una lista de establecimientos de comida rápida en la ciudad de Trafford, Reino Unido. Se puede acceder a los datos desde la API de la Food Standards Agency (Agencia de Normas Alimentarias), que proporciona datos de calificación de higiene alimentaria para el Reino Unido.\nEstos son los parámetros de nuestra solicitud:\n\nVerbo HTTP: GET\nURL del punto de la API: http://api.ratings.food.gov.uk/Establishments\nParámetros seleccionados: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityId\nCabeceras: “x-api-version”, 2\nFormato(s) de datos: JSON, XML\nDocumentación: http://api.ratings.food.gov.uk/help\n\nEl código R sería el siguiente:\n\n# preparar la petición\npath &lt;- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest &lt;- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# Comprobar si hay error con el servidor (\"200\" es el correcto!)\nrequest$status_code\n\n# enviar la solicitud, analizar la respuesta y convertirla en un data frame\nresponse &lt;- content(request, as = \"text\", encoding = \"UTF-8\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%\n  pluck(\"establishments\") %&gt;%\n  as_tibble()\n\nAhora puedes limpiar y utilizar el dataframe response, que contiene una fila por establecimiento de comida rápida.\n\n\nSe requiere autenticación\nAlgunas APIs requieren autenticación - para que se demuestre quién eres y poder acceder a datos restringidos. Para importar estos datos, es posible que tengas que utilizar primero un método POST para proporcionar un nombre de usuario, una contraseña o un código. Esto devolverá un token de acceso, que puede ser utilizado para posteriores solicitudes del método GET para obtener los datos deseados.\nA continuación se muestra un ejemplo de consulta de datos de Go.Data, que es una herramienta de investigación de brotes. Go.Data utiliza una API para todas las interacciones entre la interfaz de la web y las aplicaciones de los smartphones utilizadas para la captura de datos. Go.Data se utiliza en todo el mundo. Se requiere autenticación, dado que los datos de los brotes son sensibles y sólo debes poder acceder a los datos de tu brote.\nA continuación se muestra un ejemplo de código R que utiliza httr y jsonlite para conectarse a la API de Go.Data para importar datos sobre el seguimiento de los contactos de tu brote.\n\n# establecer credenciales para la autorización\nurl &lt;- \"https://godatasampleURL.int/\"           # url correcta de Go.Data\nusername &lt;- \"username\"                          # usuario Go.Data válido \npassword &lt;- \"password\"                          # contraseña válida \noutbreak_id &lt;- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # ID de brote de Go.Data\n\n# obtener token de acceso\nurl_request &lt;- paste0(url,\"api/oauth/token?access_token=123\") # definir URL base de la solicitud\n\n# preparar la petición\nresponse &lt;- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # utiliza el nombre de usuario/contraseña guardado  arriba para autorizar                               \n    password = password),                                       \n    encode = \"json\")\n\n# ejecutar la petición y analizar la respuesta\ncontent &lt;-\n  content(response, as = \"text\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%          # acoplar el JSON anidado\n  glimpse()\n\n# Guardar el token de acceso de la respuesta\naccess_token &lt;- content$access_token    # guardar el token de acceso para permitir las siguientes llamadas a la API\n\n# importar contactos del brote\n# Utilizar el token de acceso \nresponse_contacts &lt;- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # petición GET\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts &lt;- content(response_contacts, as = \"text\")         # # convertir JSON a texto\n\ncontacts &lt;- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # acoplar JSON a tibble\n\nPRECAUCIÓN: Si estás importando grandes cantidades de datos desde una API que requiere autenticación, es posible que se agote el tiempo de espera. Para evitarlo, recupera el access_token antes de cada solicitud GET de la API y prueba a utilizar filtros o límites en la consulta. \nCONSEJO: La función fromJSON() del paquete jsonlite no se ajuste completamente la primera vez que se ejecuta, por lo que es probable que todavía tengas elementos de la lista en tu tibble resultante. Tendrás que ajustar aún más ciertas variables, dependiendo de lo jerarquizado que esté tu .json. Para ver más información sobre esto, consulta la documentación del paquete jsonlite, como la función flatten(). \nPara más detalles, mira la documentación en el Explorador de LoopBack, la página de Rastreo de Contactos o los consejos de la API en el repositorio Github de Go.Data\nPuedes leer más sobre el paquete httr aquí\nEsta sección también se inspiró en este tutorial y este otro tutorial.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#export",
    "href": "new_pages/importing.es.html#export",
    "title": "7  Importación y exportación",
    "section": "7.11 Exportar",
    "text": "7.11 Exportar\n\nCon el paquete rio\nCon rio, puedes utilizar la función export() de forma muy similar a import(). Primero indica el nombre del objeto de R que deseas guardar (por ejemplo, linelist) y luego escribe entre comillas la ruta de acceso al archivo donde deseas guardarlo, incluyendo el nombre y la extensión de archivo deseados. Por ejemplo:\nEsto guarda el dataframe linelist como un archivo de Excel en el directorio de trabajo/carpeta raíz del proyecto R:\n\nexport(linelist, \"my_linelist.xlsx\") # lo guardará en el directorio de trabajo\n\nSe puede guardar el mismo dataframe como un archivo csv cambiando la extensión. Por ejemplo, también lo guardamos en una ruta de archivo construida con here():\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))\n\n\n\nAl portapapeles\nPara exportar un dataframe al “portapapeles” de tu ordenador (para luego pegarlo en otro software como Excel, Google Spreadsheets, etc.) puedes utilizar write_clip() del paquete clipr.\n\n# exporta el data frame linelist al portapapeles de tu sistema\nclipr::write_clip(linelist)",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#import_rds",
    "href": "new_pages/importing.es.html#import_rds",
    "title": "7  Importación y exportación",
    "section": "7.12 Archivos RDS",
    "text": "7.12 Archivos RDS\nAdemás de .csv, .xlsx, etc., también puedes exportar/guardar dataframes de R como archivos .rds. Este es un formato de archivo específico de R, y es muy útil si sabes que vas a trabajar con los datos exportados de nuevo en R.\nLos tipos de columnas se conservan, por lo que no hay que volver a hacer la limpieza cuando se importan (con un archivo Excel o incluso CSV esto puede ser un dolor de cabeza). También es un archivo más pequeño, lo que es útil para la exportación e importación si tu conjunto de datos es grande.\nPor ejemplo, si trabajas en un equipo de epidemiología y necesitas enviar archivos a un equipo de SIG para la elaboración de mapas, y ellos también utilizan R, ¡sólo tienes que enviarles el archivo .rds! Así se conservan todos los tipos de columnas y ellos tienen menos trabajo que hacer.\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#import_rdata",
    "href": "new_pages/importing.es.html#import_rdata",
    "title": "7  Importación y exportación",
    "section": "7.13 Archivos Rdata y listas de datos",
    "text": "7.13 Archivos Rdata y listas de datos\nLos archivos .Rdata pueden almacenar múltiples objetos de R - por ejemplo, múltiples dataframes, resultados de modelos, listas, etc. Esto puede ser muy útil para consolidar o compartir muchos de tus datos para un proyecto determinado.\nEn el siguiente ejemplo, se almacenan múltiples objetos R dentro del archivo exportado “my_objects.Rdata”:\n\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\n\nNota: si estás intentando importar una lista, utiliza import_list() de rio para importarla con la estructura y el contenido originales completos.\n\nrio::import_list(\"my_list.Rdata\")",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#saving-plots",
    "href": "new_pages/importing.es.html#saving-plots",
    "title": "7  Importación y exportación",
    "section": "7.14 Guardar gráficos",
    "text": "7.14 Guardar gráficos\nLas instrucciones sobre cómo guardar los gráficos, como los creados por ggplot(), se discuten en profundidad en la página de Conceptos básicos de ggplot.\nEn resumen, ejecuta ggsave(\"my_plot_filepath_and_name.png\") después de obtener tu gráfico. Puedes proporcionar un gráfico guardado con plot = argumento, o sólo especificar la ruta de archivo de destino (con extensión de archivo) para guardar el gráfico mostrado más recientemente. También puedes controlar el ancho width =, la altura height =, las unidades units = y los puntos por pulgada dpi =.\nLa forma de guardar un gráfico de red, como un árbol de transmisión, se aborda en la página Cadenas de transmisión.",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.es.html#resources-1",
    "href": "new_pages/importing.es.html#resources-1",
    "title": "7  Importación y exportación",
    "section": "7.15 Recursos",
    "text": "7.15 Recursos\nEl manual de importación y exportación de datos de R\nCapítulo de R 4 Data Science en español sobre la importación de datos\ndocumentación de ggsave()\nA continuación se muestra una tabla, extraída de la viñeta online de rio. Para cada tipo de datos muestra: la extensión de archivo esperada, el paquete que rio utiliza para importar o exportar los datos, y si esta funcionalidad está incluida en la versión instalada de rio.\n\n\n\n\n\n\n\n\n\n\nFormato\nExtensión típica\nPaquete importación\nPaquete exportación\nInstalado por defecto\n\n\n\n\nDatos separados por comas\n.csv\ndata.table fread()\ndata.table\nYes\n\n\nDatos separados por pipe\n.psv\ndata.table fread()\ndata.table\nYes\n\n\nDatos separados por tabul\n.tsv\ndata.table fread()\ndata.table\nYes\n\n\nSAS\n.sas7bdat\nhaven\nhaven\nYes\n\n\nSPSS\n.sav\nhaven\nhaven\nYes\n\n\nStata\n.dta\nhaven\nhaven\nYes\n\n\nSAS\nXPORT\n.xpt\nhaven\nhaven\n\n\nSPSS Portable\n.por\nhaven\n\nYes\n\n\nExcel\n.xls\nreadxl\n\nYes\n\n\nExcel\n.xlsx\nreadxl\nopenxlsx\nYes\n\n\nSyntaxis R\n.R\nbase\nbase\nYes\n\n\nObjetos R guardados\n.RData, .rda\nbase\nbase\nYes\n\n\nObjetos R serializados\n.rds\nbase\nbase\nYes\n\n\nEpiinfo\n.rec\nforeign\n\nYes\n\n\nMinitab\n.mtp\nforeign\n\nYes\n\n\nSystat\n.syd\nforeign\n\nYes\n\n\n“XBASE”\ndatabase files\n.dbf\nforeign\nforeign\n\n\nFormato de archivo Weka Attribute-Relation\n.arff\nforeign\nforeign\nYes\n\n\nFormato de intercambio de datos\n.dif\nutils\n\nYes\n\n\nDatos de Fortran\nno recognized extension\nutils\n\nYes\n\n\nFormato de ancho fijo\n.fwf\nutils\nutils\nYes\n\n\ndatos separados por comas gzip\n.csv.gz\nutils\nutils\nYes\n\n\nCSVY (CSV + cabecera de metadatos YAML)\n.csvy\ncsvy\ncsvy\nNo\n\n\nEViews\n.wf1\nhexView\n\nNo\n\n\nFormato de intercambio Feather R/Python\n.feather\nfeather\nfeather\nNo\n\n\nAlmacenamiento rápido\n.fst\nfst\nfst\nNo\n\n\nJSON\n.json\njsonlite\njsonlite\nNo\n\n\nMatlab\n.mat\nrmatio\nrmatio\nNo\n\n\nHoja de cálculo OpenDocument\n.ods\nreadODS\nreadODS\nNo\n\n\nTablas HTML\n.html\nxml2\nxml2\nNo\n\n\nDocumentos XML\n.xml\nxml2\nxml2\nNo\n\n\nYAML\n.yml\nyaml\nyaml\nNo\n\n\nPortapapeles por defecto es tsv\n\nclipr\nclipr\nNo",
    "crumbs": [
      "Aspectos básicos",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Importación y exportación</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html",
    "href": "new_pages/cleaning.es.html",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "",
    "text": "Funciones principales\nEste manual hace hincapié en el uso de las funciones de la familia de paquetes de R tidyverse. Las funciones esenciales que se muestran en esta página se enumeran a continuación.\nMuchas de estas funciones pertenecen al paquete dplyr, que proporciona funciones “verbales” para resolver los retos de la manipulación de datos (el nombre hace una referencia a unos alicates - plier - de dataframes). dplyr forma parte de la familia de paquetes de R tidyverse (que también incluye ggplot2, tidyr, stringr, tibble, purrr, magrittr y forcats, entre otros).\nSi quieres ver cómo se comparan estas funciones con los comandos de Stata o SAS, consulta la página sobre la transición a R.\nPuedes encontrar una gestión de datos alternativa en el paquete R data.table con operadores como := y el uso frecuente de corchetes [ ]. Este enfoque y la sintaxis se explican brevemente en la página Data.Table.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#cleaning-pipeline",
    "href": "new_pages/cleaning.es.html#cleaning-pipeline",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.1 Limpieza de pipes",
    "text": "8.1 Limpieza de pipes\nEsta página recorre los pasos típicos de limpieza, añadiéndolos secuencialmente a una cadena de pipes de limpieza.\nEn el análisis epidemiológico y el procesamiento de datos, los pasos de limpieza se realizan a menudo de forma secuencial, enlazados entre sí. En R, esto se manifiesta a menudo como una “tubería” de limpieza, en la que los datos en bruto se pasan o se “canalizan” de un paso de limpieza a otro.\nEstas cadenas utilizan las funciones de dplyr y el operador %&gt;% de magrittr. Esta tubería comienza con los datos “en bruto” (“linelist_raw.xlsx”) y termina con un dataframe de R “limpio” (linelist) que se puede utilizar, guardar, exportar, etc.\nEn un proceso de limpieza, el orden de los pasos es importante. Los pasos de limpieza pueden incluir:\n\nImportación de datos\nLimpieza o cambio de los nombres de las columnas\nde-duplicación\nCreación y transformación de columnas (por ejemplo, recodificación o normalización de valores)\nFiltrado o añadido de filas",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#load-packages",
    "href": "new_pages/cleaning.es.html#load-packages",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.2 Carga de paquetes",
    "text": "8.2 Carga de paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,        # importación/exportación de múltiples tipos de datos\n  here,       # ruta relativa de los archivos\n  janitor,    # limpieza de datos y tablas\n  lubridate,  # trabajar con fechas\n  epikit,     # función age_categories()\n  tidyverse   # gestión y visualización de datos \n  \n\n)",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#import-data-1",
    "href": "new_pages/cleaning.es.html#import-data-1",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.3 Importar datos",
    "text": "8.3 Importar datos\n\nImportar\nAquí importamos el archivo Excel de la lista de casos “en bruto” utilizando la función import() del paquete rio. El paquete rio maneja con flexibilidad muchos tipos de archivos (por ejemplo, .xlsx, .csv, .tsv, .rds. Consulta la página sobre importación y exportación para obtener más información y consejos sobre situaciones inusuales (por ejemplo, omitir filas, establecer valores que faltan, importar hojas de Google, etc).\nPara continuar, cliquea para descargar linelist “en crudo” (como archivo .xlsx).\nSi tu conjunto de datos es grande y tarda mucho en importarse, puede ser útil que el comando de importación esté separado de la cadena de pipes y que el “crudo” se guarde como un archivo distinto. Esto también permite comparar fácilmente las versiones original y limpia.\nA continuación, importamos el archivo de Excel sin procesar y lo guardamos como el dataframe linelist_raw. Suponemos que el archivo se encuentra en tu directorio de trabajo o en la raíz del proyecto R, por lo que no se especifican subcarpetas en la ruta del archivo.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\")\n\nPuedes ver las primeras 50 filas del dataframe a continuación. Nota: la función base de R head(n) te permite ver sólo las primeras n filas en la consola de R.\n\n\n\n\n\n\n\n\nRevisar\nPuedes utilizar la función skim() del paquete skimr para obtener una visión general de todo el dataframe (véase la página sobre tablas descriptivas para más información). Las columnas se resumen por clase o tipo, como, por ejemplo, carácter, numérico. Nota: “POSIXct” es un tipo de fecha cruda (ver Trabajar con fechas.\n\nskimr::skim(linelist_raw)\n\n\n\n\nData summary\n\n\nName\nlinelist_raw\n\n\nNumber of rows\n6611\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n17\n\n\nnumeric\n8\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n137\n0.98\n6\n6\n0\n5888\n0\n\n\ndate onset\n293\n0.96\n10\n10\n0\n580\n0\n\n\noutcome\n1500\n0.77\n5\n7\n0\n2\n0\n\n\ngender\n324\n0.95\n1\n1\n0\n2\n0\n\n\nhospital\n1512\n0.77\n5\n36\n0\n13\n0\n\n\ninfector\n2323\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2323\n0.65\n5\n7\n0\n2\n0\n\n\nage\n107\n0.98\n1\n2\n0\n75\n0\n\n\nage_unit\n7\n1.00\n5\n6\n0\n2\n0\n\n\nfever\n258\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n258\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n258\n0.96\n2\n3\n0\n2\n0\n\n\naches\n258\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n258\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n844\n0.87\n5\n5\n0\n1091\n0\n\n\nmerged_header\n0\n1.00\n1\n1\n0\n1\n0\n\n\n…28\n0\n1.00\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n7\n1.00\n16.60\n5.71\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nlon\n7\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n7\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nrow_num\n0\n1.00\n3240.91\n1857.83\n1.00\n1647.50\n3241.00\n4836.50\n6481.00\n\n\nwt_kg\n7\n1.00\n52.69\n18.59\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n7\n1.00\n125.25\n49.57\n4.00\n91.00\n130.00\n159.00\n295.00\n\n\nct_blood\n7\n1.00\n21.26\n1.67\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n158\n0.98\n38.60\n0.95\n35.20\n38.30\n38.80\n39.20\n40.80\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ninfection date\n2322\n0.65\n2012-04-09\n2015-04-27\n2014-10-04\n538\n\n\nhosp date\n7\n1.00\n2012-04-20\n2015-04-30\n2014-10-15\n570\n\n\ndate_of_outcome\n1068\n0.84\n2012-05-14\n2015-06-04\n2014-10-26\n575",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#column-names",
    "href": "new_pages/cleaning.es.html#column-names",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.4 Nombres de columnas",
    "text": "8.4 Nombres de columnas\nEn R, los nombres de las columnas son la “cabecera” o el valor “superior” de una columna. Se utilizan para referirse a las columnas en el código, y sirven como etiqueta por defecto en las figuras.\nOtros programas estadísticos, como SAS y STATA, utilizan “etiquetas” que coexisten como versiones impresas más largas de los nombres de columna más cortos. Aunque R ofrece la posibilidad de añadir etiquetas de columna a los datos, no es una práctica que sea muy utilizada. Para hacer que los nombres de las columnas sean “fáciles de imprimir” para las figuras, normalmente se ajusta su visualización dentro de los comandos de gráficas que crean las salidas (por ejemplo, los títulos de los ejes o de las leyendas de una gráfica, o las cabeceras de las columnas en una tabla impresa - véase la sección de escalas de la página de consejos de ggplot y las páginas de Tablas para la presentación). Si deseas asignar etiquetas de columna en los datos, lee más online aquí y aquí.\nComo los nombres de las columnas de R se utilizan con mucha frecuencia, deben tener una sintaxis “limpia”. Sugerimos lo siguiente:\n\nNombres cortos\nSin espacios (sustituir por barras bajas _ )\nSin caracteres inusuales (&, #, &lt;, &gt;, …)\nNomenclatura de estilo similar (por ejemplo, todas las columnas de fecha nombradas como date_onset, date_report, date_death…)\n\nLos nombres de las columnas de linelist_raw se muestran a continuación utilizando names() de R base. Podemos ver que inicialmente\n\nAlgunos nombres contienen espacios (por ejemplo, infection date)\nSe utilizan diferentes patrones de nomenclatura para las fechas (date onset vs. infection date)\nDebe haber habido una cabecera fusionada en las dos últimas columnas del .xlsx. Lo sabemos porque el nombre de dos columnas fusionadas (“merged_header”) fue asignado por R a la primera columna, y a la segunda columna se le asignó un nombre de marcador de posición “…28” (ya que entonces estaba vacía y es la columna 28).\n\n\nnames(linelist_raw)\n\n [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\"          \n\n\nNOTA: Para hacer referencia a un nombre de columna que incluya espacios, rodea el nombre con tildes, por ejemplo: linelist$` '\\x60infection date\\x60'`. Ten en cuenta que, en tu teclado, la tilde (`) es diferente de la comilla simple (’). \n\nLimpieza automática\nLa función clean_names() del paquete janitor estandariza los nombres de las columnas y los hace únicos haciendo lo siguiente:\n\nConvierte todos los nombres para que estén compuestos sólo por barras bajas, números y letras\nLos caracteres acentuados se transliteran a ASCII (por ejemplo, la o alemana con diéresis se convierte en “o”, la “ñ” española se convierte en “n”)\nSe puede especificar la preferencia de mayúsculas para los nuevos nombres de columna utilizando case = argumento (“snake” es el valor por defecto, las alternativas incluyen “sentence”, “title”, “small_camel”…)\nPuedes especificar sustituciones de nombres concretos proporcionando un vector replace = argumento (por ejemplo, replace = c(onset = \"date_of_onset\"))\nAquí puedes encontrar una viñeta en línea sobre dicho paquete.\n\nA continuación, el proceso de limpieza comienza utilizando clean_names() sobre linelist_raw.\n\n# enlaza el conjunto de datos con un pipe a la función clean_names(), y el resultado lo guarda como \"linelist\"  \nlinelist &lt;- linelist_raw %&gt;% \n  janitor::clean_names()\n\n# ver los nombres de las columnas\nnames(linelist)\n\n [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\"            \n\n\nNOTA: El nombre de la última columna “…28” se ha cambiado por “x28”. \n\n\nLimpieza manual de nombres\nA menudo es necesario renombrar las columnas manualmente, incluso después del paso de estandarización anterior. A continuación, el renombramiento se realiza utilizando la función rename() del paquete dplyr, como parte de una cadena de pipes. rename() utiliza el estilo NUEVO = ANTIGUO - el nombre nuevo de la columna se escribe antes que el antiguo.\nA continuación, se añade un comando de renombramiento a la tubería de limpieza. Se han añadido espacios estratégicamente para alinear el código y facilitar la lectura.\n\n# CADENA DE LIMPIEZA CON 'PIPE' (comienza con los datos crudos y \n# mediante pipes encadena una serie de pasos de limpieza#\n##################################################################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # estandariza los nombres de las columnas\n    janitor::clean_names() %&gt;% \n    \n    # manualmente re-nombra columnas\n           # nombre NUEVO         # nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)\n\nAhora puedes ver que los nombres de las columnas han cambiado:\n\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nRenombrar por posición de columna\nTambién puedes renombrar por la posición de la columna, en lugar del nombre de la columna, por ejemplo:\n\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)\n\n\n\nRenombrar mediante select() y summarise()\nComo método abreviado, también puedes cambiar el nombre de las columnas dentro de las funciones de dplyr select() y summarise(). select() se utiliza para mantener sólo ciertas columnas (y se muestra más adelante en esta página). summarise() se muestra en las páginas Agrupar datos y Tablas descriptivas. Estas funciones también utilizan el formato nombre_nuevo = nombre_antiguo. He aquí un ejemplo:\n\nlinelist_raw %&gt;% \n  select(# nombre NUEVO         # nombre ANTIGUO\n         date_infection       = `infection date`,    # renombra y MANTIENE estas colunas\n         date_hospitalisation = `hosp date`)\n\n\n\n\nOtros retos\n\nNombres de columnas de Excel vacíos\nR no puede tener columnas de conjuntos de datos que no tengan nombres de columnas (cabeceras). Así, si importa unos datos de Excel con datos pero sin cabeceras de columna, R rellenará las cabeceras con nombres como “…1” o “…2”. El nombre asignado representa el número de la columna (por ejemplo, si la cuarta columna de los datos no tiene cabecera, R la nombrará “…4”).\nPuedes limpiar estos nombres manualmente haciendo referencia a su número de posición (véase el ejemplo anterior), o a su nombre asignado (linelist_raw$...1).\n\n\nNombres de columnas y celdas fusionadas de Excel\nLas celdas combinadas en un archivo de Excel son una ocurrencia común cuando se reciben datos. Como se explica en Transición a R, las celdas combinadas pueden ser agradables para la lectura humana de los datos, pero no son “datos ordenados” y causan muchos problemas para la lectura de los datos por parte de las máquinas. R no puede ajustar las celdas combinadas.\nRecuerda a las personas que introducen los datos que los datos legibles para el ser humano no son lo mismo que los datos legibles para la máquina. Esfuérzate en formar a los usuarios sobre los principios de los datos ordenados. Si es posible, intenta cambiar los procedimientos para que los datos lleguen en un formato ordenado y sin celdas fusionadas.\n\nCada variable debe tener su propia columna.\nCada observación debe tener su propia fila.\nCada valor debe tener su propia celda.\n\nAl utilizar la función import() de rio, el valor de una celda combinada se asignará a la primera celda y las siguientes estarán vacías.\nUna solución para tratar las celdas combinadas es importar los datos con la función readWorkbook() del paquete openxlsx. Establece el argumento fillMergedCells = TRUE. Esto da el valor en una celda fusionada a todas las celdas dentro del rango de fusión.\n\nlinelist_raw &lt;- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)\n\nPELIGRO: Si los nombres de las columnas se fusionan con readWorkbook(), terminarás con nombres de columnas duplicados, que tendrás que arreglar manualmente - ¡R no funciona bien con nombres de columnas duplicados! Puedes renombrarlas haciendo referencia a su posición (por ejemplo, la columna 5), como se explica en la sección de limpieza manual de nombres de columnas.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#select-or-re-order-columns",
    "href": "new_pages/cleaning.es.html#select-or-re-order-columns",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.5 Seleccionar o reordenar columnas",
    "text": "8.5 Seleccionar o reordenar columnas\nUtiliza select() de dplyr para seleccionar las columnas que deseas conservar y para especificar su orden en el dataframe.\nATENCIÓN: En los ejemplos siguientes, el dataframe linelist se modifica con select() y se muestra, pero no se guarda. Esto es a efectos de demostración. Los nombres de las columnas modificadas se imprimen pasando el dataframe a names().\nAquí están TODOS los nombres de las columnas en linelist en este punto de la cadena de limpieza:\n\nnames(linelist)\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nMantener las columnas\nSelecciona sólo las columnas que desees conservar\nEscribe sus nombres en el comando select(), sin comillas. Aparecerán en el dataframe en el orden que indiques. Ten en cuenta que si incluyes una columna que no existe, R devolverá un error (véase el uso de any_of() más adelante para evitar un error de este tipo).\n\n# linelist se enlaza con pipe al comando select(), y names() imprime (en consola) sólo los nombres de columna\nlinelist %&gt;% \n  select(case_id, date_onset, date_hospitalisation, fever) %&gt;% \n  names()  # display the column names\n\n[1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n[4] \"fever\"               \n\n\n\n\nFunciones de ayuda “tidyselect”\nEstas funciones de ayuda existen para facilitar la especificación de las columnas a conservar, descartar o transformar. Provienen del paquete tidyselect, que se incluye en tidyverse y se basa en la forma en que se seleccionan las columnas en las funciones de dplyr.\nPor ejemplo, si deseas reordenar las columnas, everything() es una función útil para indicar “todas las demás columnas no mencionadas”. El comando siguiente mueve las columnas date_onset y date_hospitalisation al principio (izquierda) de los datos, pero mantiene todas las demás columnas después. Fíjate en que everything() se escribe con paréntesis vacíos:\n\n# mueve date_onset y date_hospitalisation al principio\nlinelist %&gt;% \n  select(date_onset, date_hospitalisation, everything()) %&gt;% \n  names()\n\n [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\nAquí hay otras funciones de ayuda “tidyselect” que también funcionan dentro de las funciones de dplyr como select(), across() y summarise():\n\neverything() - todas las demás columnas no mencionadas\nlast_col() - la última columna\nwhere() - aplica una función a todas las columnas y selecciona las que son TRUE\ncontains() - columnas que contienen una cadena de caracteres\n\nejemplo: select(contains(\"time\"))\n\nstarts_with() - coincide con un prefijo especificado\n\nejemplo: select(starts_with(\"date_\"))\n\nends_with() - coincide con un sufijo especificado\n\nejemplo: select(ends_with(\"_post))\n\nmatches() - para aplicar una expresión regular (regex)\n\nejemplo: select(matches(\"[pt]al\"))\n\nnum_range() - un rango numérico como x01, x02, x03\nany_of() - coincide con la columna SI existe pero no devuelve ningún error si no se encuentra\n\nejemplo: select(any_of(date_onset, date_death,     cardiac_arrest))\n\n\nAdemás, utiliza operadores normales como c() para listar varias columnas, : para columnas consecutivas, ! para opuestas, & para “Y” y | para “O”.\nUtiliza where() para especificar criterios lógicos para las columnas. Si escribes una función dentro de where(), no incluyas los paréntesis vacíos de la función. El comando siguiente selecciona las columnas de tipo Numeric.\n\n# selecciona las columnas que son de clase Numeric\nlinelist %&gt;% \n  select(where(is.numeric)) %&gt;% \n  names()\n\n[1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"     \n[6] \"ht_cm\"      \"ct_blood\"   \"temp\"      \n\n\nUtiliza contains() para seleccionar sólo las columnas en las que el nombre de la columna contiene una cadena de caracteres especificada. ends_with() y starts_with() proporcionan más matices.\n\n# selecciona las columnas que contienen ciertos caracteres\nlinelist %&gt;% \n  select(contains(\"date\")) %&gt;% \n  names()\n\n[1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n[4] \"date_outcome\"        \n\n\nLa función matches() funciona de forma similar a contains(), pero puede escribirse en una expresión regular (mira la página sobre Caracteres y cadenas), como varias cadenas separadas por barras “O” dentro de los paréntesis:\n\n# selecciona por multiples coincidencias de caracteres\nlinelist %&gt;% \n  select(matches(\"onset|hosp|fev\")) %&gt;%   # note the OR symbol \"|\"\n  names()\n\n[1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n[4] \"fever\"               \n\n\nATENCIÓN: Si has escrito un nombre de columna y no existen datos para ella, puede devolver un error y detener tu código. Considera el uso de any_of() para citar columnas que pueden o no existir, especialmente útil en selecciones negativas (eliminar). \nSólo existe una de estas columnas, pero no se produce ningún error y el código continúa sin detener su cadena de limpieza.\n\nlinelist %&gt;% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %&gt;% \n  names()\n\n[1] \"date_onset\"\n\n\n\n\nEliminar columnas\nIndica qué columnas se van a eliminar colocando el símbolo “-” delante del nombre de la columna (por ejemplo, select(-outcome)), o un vector de nombres de columnas (como se indica a continuación). Todas las demás columnas se mantendrán.\n\nlinelist %&gt;% \n  select(-c(date_onset, fever:vomit)) %&gt;% # remove date_onset and all columns from fever to vomit\n  names()\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n [7] \"gender\"               \"hospital\"             \"lon\"                 \n[10] \"lat\"                  \"infector\"             \"source\"              \n[13] \"age\"                  \"age_unit\"             \"row_num\"             \n[16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n[19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[22] \"x28\"                 \n\n\nTambién puedes eliminar una columna utilizando la sintaxis de R base, definiéndola como NULL. Por ejemplo:\n\nlinelist$date_onset &lt;- NULL   # borra columnas con sentencias de R base \n\n\n\nIndependiente\nselect() también puede utilizarse como un comando independiente (no en una cadena de pipes). En este caso, el primer argumento es el dataframe original sobre el que se va a operar.\n\n# Crea un linelist nuevo con las columnas id y age-related\nlinelist_age &lt;- select(linelist, case_id, contains(\"age\"))\n\n# muestra los nombres de las columnas\nnames(linelist_age)\n\n[1] \"case_id\"  \"age\"      \"age_unit\"\n\n\n\nAñadir a la cadena de pipes\nEn linelist_raw, hay algunas columnas que no necesitamos: row_num, merged_header y x28. Las eliminamos con un comando select() en la cadena de pipes de limpieza:\n\n# CADENA DE LIMPIEZA CON 'PIPE' (comienza con los datos crudos y \n# mediante pipes encadena una serie de pasos de limpieza#\n##################################################################################\n\n# comienza la cadena de limpieza con un pipe\n############################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # sintaxis para estandarizar los nombres de columnas\n    janitor::clean_names() %&gt;% \n    \n    # renombrar manualment las columnas\n           # nombre NUEVO         # nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # a\n    #####################################################\n\n    # quitar una columna\n    select(-c(row_num, merged_header, x28))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#deduplication",
    "href": "new_pages/cleaning.es.html#deduplication",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.6 De-duplicación",
    "text": "8.6 De-duplicación\nConsulta la página sobre de-duplicación para ver la cantidad de opciones sobre cómo eliminar las duplicidades (de-duplicar). Aquí sólo se presenta un ejemplo muy sencillo de de-duplicación de filas.\nEl paquete dplyr ofrece la función distinct(). Esta función examina cada fila y reduce el dataframe con sólo filas únicas. Es decir, elimina las filas que están 100% duplicadas.\nAl evaluar las filas duplicadas, tiene en cuenta un rango de columnas - por defecto considera todas las columnas. Como se muestra en la página de de-duplicación, puedes ajustar este rango de columnas para que la singularidad de las filas sólo se evalúe con respecto a determinadas columnas.\nEn este sencillo ejemplo, simplemente añadimos el comando vacío distinct() a la cadena de pipes. Esto garantiza que no haya filas que estén 100% duplicadas de otras filas (evaluadas en todas las columnas).\nComenzamos con nrow(linelist) filas en linelist.\n\nlinelist &lt;- linelist %&gt;% \n  distinct()\n\nDespués de la de-duplicación hay nrow(linelist) filas. Las filas eliminadas habrían sido 100% duplicados de otras filas.\nA continuación, se añade el comando distinct() a la cadena de pipes de limpieza:\n\n# CADENA DE LIMPIEZA CON 'PIPE' (comienza con los datos crudos y \n# mediante pipes encadena una serie de pasos de limpieza#\n##################################################################################\n\n# comienza la cadena de limpieza con un pipe\n############################################\n\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # sintaxis para estandarizar los nombres de columnas\n    janitor::clean_names() %&gt;% \n    \n    # renombrar manualment las columnas\n           # nombre NUEVO       # nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # quitar una columna\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # ARRIBA SE ENCUENTRAN LOS PASOS DE LIMPIEZA ANTERIORES YA DISCUTIDOS\n    #####################################################################\n    \n    # de-duplicar\n    distinct()",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#column-creation-and-transformation",
    "href": "new_pages/cleaning.es.html#column-creation-and-transformation",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.7 Creación y transformación de columnas",
    "text": "8.7 Creación y transformación de columnas\nRecomendamos utilizar la función mutate() de dplyr para añadir una nueva columna, o para modificar una existente.\nA continuación se muestra un ejemplo de creación de una nueva columna con mutate(). La sintaxis es: mutate(nombre_nueva_columna = valor o transformación)\nEn Stata, esto es similar al comando generate, pero también se puede utilizar mutate() de R para modificar una columna existente.\n\nNuevas columnas\nEl comando más básico de mutate() para crear una nueva columna podría tener este aspecto. Crea una nueva columna new_col donde el valor en cada fila es 10.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(new_col = 10)\n\nTambién puedes referenciar valores en otras columnas, para realizar cálculos. A continuación, se crea una nueva columna bmi para mantener el Índice de Masa Corporal (BMI) de cada caso - calculado mediante la fórmula BMI = kg/m^2, utilizando la columnas ht_cm y wt_kg.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\nSi creas varias columnas nuevas, separa cada una con una coma y una nueva línea. A continuación se muestran ejemplos de nuevas columnas, incluidas las que consisten en valores de otras columnas combinadas mediante str_glue() del paquete stringr (véase la página sobre Caracteres y cadenas.\n\nnew_col_demo &lt;- linelist %&gt;%                       \n  mutate(\n    new_var_dup    = case_id,             # columna nueva = duplicar/copiar otra columna existente\n    new_var_static = 7,                   # columna nueva = todos los valores iguales\n    new_var_static = new_var_static + 5,  # se puede sobreescribir una columna y puede ser un cálculo con otras variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # columna nueva = pegar valores de otras columnas\n    ) %&gt;% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # muestra solo columnas nuevas, sólo por mostrarlas\n\nRevisa las columnas nuevas. A efectos de demostración, sólo se muestran las columnas nuevas y las utilizadas para crearlas:\n\n\n\n\n\n\nCONSEJO: Una variación de mutate() es la función transmute(). Esta función añade una nueva columna al igual que mutate(), pero también elimina todas las demás columnas que no se mencionan dentro de sus paréntesis. \n\n# OCULTO AL LECTOR\n# quita las columnas de prueba creadas más arriba\n# linelist &lt;- linelist %&gt;% \n#   select(-contains(\"new_var\"))\n\n\n\nConvertir el tipo de columna\nLas columnas que contienen valores que son fechas, números o valores lógicos (TRUE/FALSE) sólo se comportarán como se espera si están correctamente clasificadas. Hay una diferencia entre “2” de tipo carácter y 2 de tipo numérico!\nHay formas de establecer el tipo de la columna durante los comandos de importación, pero esto suele ser engorroso. Consulta la sección sobre los tipos de objeto en Fundamentos de R para saber más sobre la conversión de los tipos de objetos y columnas.\nEn primer lugar, vamos a realizar algunas comprobaciones en las columnas importantes para ver si son del tipo correcto. También vimos esto al principio cuando ejecutamos skim().\nActualmente, el tipo de la columna age es un carácter. Para realizar análisis cuantitativos, ¡necesitamos que estos números sean reconocidos como numéricos!.\n\nclass(linelist$age)\n\n[1] \"character\"\n\n\nEl tipo de la columna date_onset ¡también es un carácter! Para realizar los análisis, ¡estas fechas deben ser reconocidas como fechas!\n\nclass(linelist$date_onset)\n\n[1] \"character\"\n\n\nPara resolver esto, utiliza la capacidad de mutate() para redefinir una columna mediante una transformación. Definimos la columna como ella misma, pero convertida a un tipo diferente. He aquí un ejemplo básico, convirtiendo o asegurando que la columna age sea de tipo Numeric:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age = as.numeric(age))\n\nDe forma similar, puedes utilizar as.character() y as.logical(). Para convertir al tipo Factor, puedes utilizar factor() de R base o as_factor() de forcats. Lee más sobre esto en la página de Factores.\nHay que tener cuidado al convertir al tipo Fecha. En la página Trabajar con fechas se explican varios métodos. Normalmente, los valores de fecha en el fichero crudo deben estar todos en el mismo formato para que la conversión funcione correctamente (por ejemplo, “MM/DD/AAAA”, o “DD MM AAAA”). Después de convertir al tipo Fecha, comprueba tus datos para confirmar que cada valor se ha convertido correctamente.\n\n\nDatos agrupados\nSi tu dataframe ya está agrupado (véase la página sobre Agrupar datos), mutate() puede comportarse de forma diferente que si el dataframe no está agrupado. Cualquier función de resumen, como mean(), median(), max(), etc. calculará con datos agrupados, no con filas de registros individualizados.\n\n# edad normalizada para hacer la media de TODAS las filas\nlinelist %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# edad normalizada para hacer la media por grupo de hospital\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\nLee más sobre el uso de mutate() sobre dataframes agrupados en esta documentación mutate de tidyverse.\n\n\nTransformar múltiples columnas\nA menudo, para escribir un código conciso, se desea aplicar la misma transformación a varias columnas a la vez. Se puede aplicar una transformación a varias columnas a la vez utilizando la función across() del paquete dplyr (también contenido en el paquete tidyverse). across() se puede utilizar con cualquier función de dplyr, pero se suele utilizar dentro de select(), mutate(), filter() o summarise(). Mira cómo se aplica a summarise() en la página sobre Tablas descriptivas.\nEspecificar los argumentos de las columnas .cols = y la(s) función(es) a aplicar a .fns =. Cualquier argumento adicional a la función .fns puede incluirse después de una coma, todavía dentro de across().\n\nSelección de columnas con across()\nEspecificar las columnas de .cols =. Puedes nombrarlas individualmente, o utilizar funciones de ayuda “tidyselect”. Especifica la función en .fns =. Ten en cuenta que, utilizando el modo de función mostrado a continuación, la función se escribe sin sus paréntesis ().\nAquí la transformación as.character() se aplica a columnas específicas nombradas dentro de across().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n\nLas funciones de ayuda “tidyselect” están disponibles para ayudarle a especificar las columnas. Se detallan más arriba en la sección sobre Selección y reordenación de columnas, e incluyen: everything(), last_col(), where(), starts_with(), ends_with(), contains(), matches(), num_range() y any_of().\nEste es un ejemplo de cómo se pueden cambiar todas las columnas al tipo carácter:\n\n#cambiar todas las columnas a clase character\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = everything(), .fns = as.character))\n\nConvertir en caracteres todas las columnas cuyo nombre contenga la cadena “date” (fíjate en la colocación de comas y paréntesis):\n\n#cambiar todas las columnas que contienen \"date\" a clase character\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\n\nA continuación, un ejemplo de mutación de las columnas que actualmente son de tipo POSIXct (un tipo datetime cruda que muestra etiquetas) - en otras palabras, donde la función is.POSIXct() evalúa a TRUE. Entonces queremos convertirlas con la función as.Date() en columnas de tipo Date normal.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))\n\n\nTen en cuenta que dentro de across() también utilizamos la función where() como is.POSIXct está evaluando a TRUE o FALSE.\nTen en cuenta que is.POSIXct() es del paquete lubridate. Otras funciones “is” similares como is.character(), is.numeric(), e is.logical() son de R base\n\n\n\nfunciones across()\nPuedes leer la documentación de ayuda con detalles sobre cómo proporcionar funciones a across() escribiendo ?across: hay varias formas de especificar la(s) función(es) a realizar en una columna e incluso puedes definir tus propias funciones:\n\nPuedes escribir el nombre de la función sola (por ejemplo, mean o as.character)\nPuedes escribir la función en estilo purrr (por ejemplo, ~ mean(.x, na.rm = TRUE)) (mira esta página)\nPuedes especificar varias funciones escribiendo una lista (por ejemplo, list(mean = mean, n_miss = ~ sum(is.na(.x))). * Si proporcionas varias funciones, se devolverán varias columnas transformadas por cada columna de entrada, con nombres únicos con formato col_fn. Puedes ajustar cómo se nombran las columnas nuevas con el argumento .names = utilizando la sintaxis glue (mira la página sobre Caracteres y cadenas) donde {.col} y {.fn} son la abreviatura de la columna de entrada y la función.\n\nAquí hay algunos recursos en línea sobre el uso de across(): pensamientos/razones del creador Hadley Wickham\n\n\n\ncoalesce()\nEsta función de dplyr encuentra el primer valor no missing en cada posición. Rellena los valores que faltan con el primer valor disponible en el orden que especifiques.\nAquí hay un ejemplo fuera del contexto de un dataframe: Supongamos que tienes dos vectores, uno que contiene el pueblo de detección del paciente y otro que contiene el pueblo de residencia del paciente. Puedes utilizar coalesce para elegir el primer valor no ausente de cada índice:\n\nvillage_detection &lt;- c(\"a\", \"b\", NA,  NA)\nvillage_residence &lt;- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage &lt;- coalesce(village_detection, village_residence)\nvillage    # print\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\nEsto funciona de la misma manera si se proporcionan columnas del dataframe: para cada fila, la función asignará el nuevo valor de la columna con el primer valor que no falte en las columnas proporcionadas (en el orden indicado).\n\nlinelist &lt;- linelist %&gt;% \n  mutate(village = coalesce(village_detection, village_residence))\n\nEste es un ejemplo de operación “por filas”. Para cálculos más complicados por filas, consulta la sección siguiente sobre cálculos por filas.\n\n\nMatemáticas acumulativas\nSi deseas que una columna refleje acumulados la sum/mean/min/max, etc., tal y como se ha evaluado en las filas de un dataframe hasta ese punto, utiliza las siguientes funciones:\ncumsum() devuelve la suma acumulada, como se muestra a continuación:\n\nsum(c(2,4,15,10))     # devuelve sólo un número\n\n[1] 31\n\ncumsum(c(2,4,15,10))  # devuelve la suma acumulativa de cada paso\n\n[1]  2  6 21 31\n\n\nEsto se puede utilizar en un dataframe al crear una nueva columna. Por ejemplo, para calcular el número acumulado de casos por día en un brote, considere un código como este:\n\ncumulative_case_counts &lt;- linelist %&gt;%  # begin with case linelist\n  count(date_onset) %&gt;%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\n\nA continuación se muestran las 10 primeras filas:\n\nhead(cumulative_case_counts, 10)\n\n   date_onset n cumulative_cases\n1  2012-04-15 1                1\n2  2012-05-05 1                2\n3  2012-05-08 1                3\n4  2012-05-31 1                4\n5  2012-06-02 1                5\n6  2012-06-07 1                6\n7  2012-06-14 1                7\n8  2012-06-21 1                8\n9  2012-06-24 1                9\n10 2012-06-25 1               10\n\n\nConsulta la página sobre curvas epidémicas para saber cómo representar la incidencia acumulada con epicurve.\nVéase también:\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall()\n\n\nUtilizando R base\nPara definir una nueva columna (o redefinir una columna) utilizando R base, escribe el nombre del dataframe, conectado con $, a la nueva columna (o la columna a modificar). Utiliza el operador de asignación &lt;- para definir el nuevo valor o valores. Recuerda que al usar R base debes especificar siempre el nombre del dataframe antes del nombre de la columna (por ejemplo, dataframe$column). Este es un ejemplo de creación de la columna bmi usando R base:\n\nlinelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)\n\n\n\nAñadir a la cadena de pipes\nA continuación, se añade una nueva columna a la cadena de pipes y se convierten algunos tipos.\n\n# CADENA DE LIMPIEZA CON 'PIPE' (comienza con los datos crudos y \n# mediante pipes encadena una serie de pasos de limpieza\n##################################################################################\n\n# comienza la cadena de limpieza con un pipe\n############################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # estandarizar los nombres de columnas\n    janitor::clean_names() %&gt;% \n    \n    # renombrar manualmente las columnas\n           # nombre NUEVO       # nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # quitar columna\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicar\n    distinct() %&gt;% \n \n    # ARRIBA SE ENCUENTRAN LOS PASOS DE LIMPIEZA ANTERIORES DISCUTIDOS\n    ##################################################################\n    # añadir una columna nueva\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;% \n  \n    # convertir el tipo de datos de las columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#re-code-values",
    "href": "new_pages/cleaning.es.html#re-code-values",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.8 Recodificar valores",
    "text": "8.8 Recodificar valores\nA continuación, se presentan algunos escenarios en los que es necesario recodificar (cambiar) los valores:\n\npara editar un valor específico (por ejemplo, una fecha con un año o formato incorrecto)\npara conciliar valores que no se escriben igual\npara crear una nueva columna de valores categóricos\npara crear una nueva columna de categorías numéricas (por ejemplo, categorías de edad)\n\n\nValores específicos\nPara cambiar los valores manualmente puedes utilizar la función recode() dentro de la función mutate().\nImagínate que hay una fecha sin sentido en los datos (por ejemplo, “2014-14-15”): podrías corregir la fecha manualmente en los datos originales, o bien, podrías escribir el cambio en la serie de comandos de limpieza a través de mutate() y recode(). Esto último es más transparente y reproducible para cualquier otra persona que quiera entender o repetir su análisis.\n\n# corregir valores incorrectos          # valor antiguo   # valor nuevo\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\n\nLa línea mutate() anterior puede leerse como: “mutar la columna date_onset para que sea igual a la columna date_onset recodificada de forma que el VALOR ANTIGUO se cambie por el NUEVO VALOR”. Ten en cuenta que este patrón (VIEJO = NUEVO) para recode() es el opuesto a la mayoría de los patrones de R (nuevo = viejo). La comunidad de desarrollo de R está trabajando en la revisión de esto.\nAquí hay otro ejemplo de recodificación de múltiples valores dentro de una columna.\nEn linelist hay que limpiar los valores de la columna “hospital”. Hay varias grafías diferentes y muchos valores que faltan.\n\ntable(linelist$hospital, useNA = \"always\")  # imprimir la tabla de todos los valores únicos, incluidos los que faltan  \n\n\n                     Central Hopital                     Central Hospital \n                                  11                                  457 \n                          Hospital A                           Hospital B \n                                 290                                  289 \n                    Military Hopital                    Military Hospital \n                                  32                                  798 \n                    Mitylira Hopital                    Mitylira Hospital \n                                   1                                   79 \n                               Other                         Port Hopital \n                                 907                                   48 \n                       Port Hospital St. Mark's Maternity Hospital (SMMH) \n                                1756                                  417 \n  St. Marks Maternity Hopital (SMMH)                                 &lt;NA&gt; \n                                  11                                 1512 \n\n\nEl comando recode() de abajo redefine la columna “hospital” como la columna actual “hospital”, pero con los cambios especificados en la recodificación. ¡No olvides las comas después de cada uno!\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\n\nAhora vemos que se han corregido y consolidado las grafías de la columna hospital:\n\ntable(linelist$hospital, useNA = \"always\")\n\n\n                    Central Hospital                           Hospital A \n                                 468                                  290 \n                          Hospital B                    Military Hospital \n                                 289                                  910 \n                               Other                        Port Hospital \n                                 907                                 1804 \nSt. Mark's Maternity Hospital (SMMH)                                 &lt;NA&gt; \n                                 428                                 1512 \n\n\nCONSEJO: El número de espacios antes y después de un signo de igualdad no importa. Haz que tu código sea más fácil de leer alineando el signo = para todas o la mayoría de las filas. Además, considera la posibilidad de añadir una fila de comentarios con hash (#) para aclarar a los futuros lectores qué lado es VIEJO y qué lado es NUEVO. \nCONSEJO: A veces existe un valor con caracteres en blanco en unos datos (no reconocido como valor Missing - NA de R. Puedes hacer referencia a este valor con dos comillas sin espacio intermedio (““). \n\n\nPor lógica\nA continuación, demostramos cómo recodificar los valores de una columna utilizando lógica y condiciones:\n\nUso de replace(), ifelse() e if_else() para una lógica simple\nUso de case_when() para una lógica más compleja\n\n\n\nLógica simple\n\nsustituir con replace()\nPara recodificar con criterios lógicos simples, puedes utilizar replace() dentro de mutate(). replace() es una función de R base. Utiliza una condición lógica para especificar las filas a cambiar. La sintaxis general es:\nmutate(col_to_change = replace(col_a_cambiar, criterio para filas, nuevo valor)).\nUna situación frecuente es utilizar replace() para cambiar sólo un valor en una fila, utilizando un identificador de fila único. A continuación, el género se cambia a “Mujer” en la fila donde la columna case_id es “2195”.\n\n# Ejemplo: cambiar el género de una observación específica a \"Female\" \nlinelist &lt;- linelist %&gt;% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\n\nAbajo se puede ver un ejemplo equivalente utilizando la sintaxis de R base y los paréntesis de indexación [ ]. Se lee como “Cambia el valor de la columna gender del dataframe linelist a ‘Female’” (para las filas en las que la columna case_id de linelist tiene el valor ‘2195’).\n\nlinelist$gender[linelist$case_id == \"2195\"] &lt;- \"Female\"\n\n\n\nifelse() e if_else()\nOtra herramienta para la lógica simple es ifelse() y su compañero if_else(). Sin embargo, en la mayoría de los casos para la recodificación es más claro utilizar case_when() (detallado a continuación). Estos comandos “if else” son versiones simplificadas de una sentencia de programación if y else. La sintaxis general es:\nifelse(condición, valor a devolver si la condición evalúa como TRUE, valor a devolver si la condición evalúa como FALSE)\nA continuación, se define la columna source_known. Su valor en una fila determinada se establece como “known” si no falta el valor de la fila en la columna source. Si falta el valor en source, el valor de source_known se establece como “unknown”.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n\nif_else() es una versión especial de dplyr que maneja fechas. Ten en cuenta que, si el valor “verdadero” es una fecha, el valor “falso” también debe calificar una fecha, de ahí que se utilice el valor especial NA_real_ en lugar de simplemente NA.\n\n# Crear una columna de fecha de muerte, que es NA si el paciente no ha muerto.\nlinelist &lt;- linelist %&gt;% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))\n\nEvita encadenar muchos comandos ifelse… ¡utilza case_when() en su lugar! case_when() es mucho más fácil de leer y cometerás menos errores.\n\n\n\n\n\n\n\n\n\nFuera del contexto de un dataframe, si deseas que un objeto utilizado en su código cambie su valor, considere el uso de switch() de R base.\n\n\n\nLógica compleja\nUtiliza case_when() de dplyr si estás recodificando en muchos grupos nuevos, o si necesita utilizar sentencias lógicas complejas para recodificar valores. Esta función evalúa si cada fila del dataframe cumple los criterios especificados y asigna el nuevo valor correcto.\nLos comandos case_when() consisten en sentencias que tienen un lado derecho (RHS) y un lado izquierdo (LHS) separados por una “tilde” ~ (cola de chancho). Los criterios lógicos están en el lado izquierdo y los valores de conformidad están en el lado derecho de cada sentencia. Las declaraciones están separadas por comas.\nPor ejemplo, aquí utilizamos las columnas age y age_unit para crear una columna age_years:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # si la edad se da en años\n            age_unit == \"months\" ~ age/12,    # si la edad se da en meses\n            is.na(age_unit)      ~ age))      # si falta la unidad de edad, asumir años\n                                              # cualquier otra circunstancia, asignar NA (missing)\n\nA medida que se evalúa cada fila de los datos, los criterios se aplican/evalúan en el orden en que se escriben las sentencias case_when(), de arriba a abajo. Si el criterio superior se evalúa como TRUE para una fila determinada, se asigna el valor RHS, y los criterios restantes ni siquiera se prueban para esa fila. Por lo tanto, es mejor escribir los criterios más específicos primero y los más generales al final. A una fila de datos que no cumpla ninguno de los criterios del RHS se le asignará NA.\nEn esta línea, en su declaración final, coloca TRUE en el lado izquierdo, lo que capturará cualquier fila que no cumpla ninguno de los criterios anteriores. Al lado derecho de esta declaración se le podría asignar un valor como “¡comprobado!” o faltante.\nA continuación se muestra otro ejemplo de case_when() utilizado para crear una nueva columna con la clasificación del paciente, según una definición de caso para los casos confirmados y sospechosos:\n\nlinelist &lt;- linelist %&gt;% \n     mutate(case_status = case_when(\n          \n          # si el paciente se somete a una prueba de laboratorio y es positiva,\n          # entonces se marca como un caso confirmado  \n          ct_blood &lt; 20                   ~ \"Confirmed\",\n          \n          # si el paciente no tiene un resultado de laboratorio positivo,\n          # si el paciente tiene una \"fuente\" (vínculo epidemiológico) Y tiene fiebre, \n          # entonces se marca como caso sospechoso\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # cualquier otro paciente que no haya sido tratado anteriormente \n          # se marca para su seguimiento\n          TRUE                            ~ \"To investigate\"))\n\nPELIGRO: Los valores del lado derecho deben ser todos del mismo tipo: numéricos, de caracteres, de fecha, lógicos, etc. Para asignar faltantes (NA), puede ser necesario utilizar variaciones especiales de NA como NA_character_, NA_real_ (para numérico o POSIX), y as.Date(NA). Lee más en Trabajar con fechas. \n\n\nValores faltantes\nA continuación, se presentan funciones especiales para el tratamiento de los valores faltantes en el contexto de la limpieza de datos.\nConsulta la página sobre Valores faltantes para obtener consejos más detallados sobre la identificación y el tratamiento de los valores faltantes. Por ejemplo, la función is.na() que comprueba lógicamente la ausencia de datos.\nreplace_na()\nPara cambiar los valores faltantes (NA) por un valor específico, como “Missing”, utiliza la función de dplyr replace_na() dentro de mutate(). Ten en cuenta que se utiliza de la misma manera que recodificar anteriormente - el nombre de la variable debe repetirse dentro de replace_na().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\n\nfct_explicit_na()\nEsta es una función del paquete forcats. El paquete forcats maneja columnas del tipo Factor. Los factores son la forma en que R maneja valores ordenados como c(\"First\", \"Second\", \"Third\") o para establecer el orden en que los valores (por ejemplo, hospitales) aparecen en las tablas y gráficos. Vea la página sobre Factores.\nSi tus datos son del tipo Factor y tratas de convertir NA en “Missing” utilizando replace_na(), obtendrás este error: invalid factor level, NA generated (nivel de factor no válido, NA generado). Has intentado añadir “Missing” como valor, cuando no estaba definido como un posible nivel del factor, y ha sido rechazado.\nLa forma más fácil de resolver esto es utilizar la función fct_explicit_na() de forcats que convierte una columna en factor de tipo, y convierte los valores NA en el carácter “(Missing)”.\n\nlinelist %&gt;% \n  mutate(hospital = fct_explicit_na(hospital))\n\nUna alternativa más lenta sería añadir el nivel del factor utilizando fct_expand() y luego convertir los valores que faltan.\nna_if()\nPara convertir un valor específico en NA, utiliza na_if() de dplyr. El comando siguiente realiza la operación opuesta a replace_na(). En el siguiente ejemplo, cualquier valor de “Missing” en la columna hospital se convierte en NA.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n\nNota: na_if() no puede utilizarse para criterios lógicos (por ejemplo, “todos los valores &gt; 99”) - utiliza replace() o case_when() para ello:\n\n# Convierte las temperaturas superiores a 40 en NA \nlinelist &lt;- linelist %&gt;% \n  mutate(temp = replace(temp, temp &gt; 40, NA))\n\n# Convierte las fechas de inicio anteriores al 1 de enero de 2000 en missing\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = replace(date_onset, date_onset &gt; as.Date(\"2000-01-01\"), NA))\n\n\n\nDiccionario de limpieza\nUtiliza el paquete R matchmaker y su función match_df() para limpiar un dataframe con un diccionario de limpieza.\n\nCrear un diccionario de limpieza con 3 columnas:\n\nUna columna “desde” (el valor incorrecto)\n\nUna columna “para” (el valor correcto)\n\nUna columna que especifica la columna a la que se aplicarán los cambios (o “.global” para aplicarlo a todas las columnas)\n\n\nNota: Las entradas del diccionario .global serán anuladas por las entradas del diccionario específico de la columna.\n\n\n\n\n\n\n\n\n\n\nImporta el archivo del diccionario a R. Este ejemplo puede descargarse a través de las instrucciones de la página Descargar manual y datos.\n\n\ncleaning_dict &lt;- import(\"cleaning_dict.csv\")\n\n\nPasa linelist crudas a match_df(), especificando en dictionary = el dataframe del diccionario de limpieza. El argumento from = debe ser el nombre de la columna del diccionario que contiene los valores “originales”, el argumento by = debe ser la columna del diccionario que contiene los correspondientes valores “nuevos”, y la tercera columna enumera la columna en la que se realizará el cambio. Utilice .global en la columna by = para aplicar un cambio en todas las columnas. Una cuarta columna del diccionario order se puede utilizar para especificar el orden del factor de los nuevos valores.\n\n\nlinelist &lt;- linelist %&gt;%     # proporcionar o canalizar el conjunto de datos\n     matchmaker::match_df(\n          dictionary = cleaning_dict,  # nombre de tu diccionario\n          from = \"from\",               # columna con los valores a reemplazar (por defecto es col 1)\n          to = \"to\",                   # columna con los valores finales (por defecto es col 2)\n          by = \"col\"                   # columna con los nombres de las columnas (por defecto es col 3)\n  )\n\nAhora desplázate a la derecha para ver cómo han cambiado los valores - en particular el gender (de minúsculas a mayúsculas), y todas las columnas de síntomas se han transformado de sí/no a 1/0.\n\n\n\n\n\n\nTen en cuenta que los nombres de las columnas en el diccionario de limpieza deben corresponder a los nombres en este punto de tu script de limpieza. Consulta esta referencia en línea para el paquete linelist para obtener más detalles.\n\nAñadir a la cadena de pipes\nA continuación, se añaden algunas columnas y transformaciones de columna nuevas a la cadena de pipes.\n\n# CADENA DE LIMPIEZA (comienza con los datos en bruto y enlaza con pipes los pasos de limpieza)\n#######################################################################################################\n\n# Comienza la cadena de pipes de limpieza\n#########################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # sintaxis para estandarizar los nombres de las columnas\n    janitor::clean_names() %&gt;% \n    \n    # renombrar manualmente las columnas\n           # Nombre NUEVO         # Nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # eliminar columna\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicar\n    distinct() %&gt;% \n  \n    # añadir columna\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convertir el tipo de columnas\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # añadir columna: retraso en la hospitalización\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n   # ARRIBA ESTÁN LOS PASOS DE LIMPIEZA YA DISCUTIDOS\n   ###################################################\n\n    # limpiar los valores de la columna hospital\n    mutate(hospital = recode(hospital,\n                      # ANTIGUO = NUEVO\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # crear la columna age_years (A partir de age y age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#num_cats",
    "href": "new_pages/cleaning.es.html#num_cats",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.9 Categorías numéricas",
    "text": "8.9 Categorías numéricas\nAquí describimos algunos enfoques especiales para crear categorías a partir de columnas numéricas. Algunos ejemplos comunes son las categorías de edad, los grupos de valores de laboratorio, etc. Aquí discutiremos:\n\nage_categories(), del paquete epikit\n\ncut(), de R base\ncase_when()\n\nruptura de cuantiles con quantile() y ntile()\n\n\nRevisión de la distribución\nPara este ejemplo crearemos una columna age_cat utilizando la columna age_years.\n\n#check the class of the linelist variable age\nclass(linelist$age_years)\n\n[1] \"numeric\"\n\n\nEn primer lugar, examina la distribución de tus datos, para hacer los puntos de corte apropiados. Consulta la página sobre Conceptos básicos de ggplot.\n\n# examine the distribution\nhist(linelist$age_years)\n\n\n\n\n\n\n\n\n\nsummary(linelist$age_years, na.rm=T)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.04   23.00   84.00     107 \n\n\nATENCIÓN: A veces, las variables numéricas se importarán como tipo “carácter”. Esto ocurre si hay caracteres no numéricos en algunos de los valores, por ejemplo, una entrada de “2 meses” para la edad, o (dependiendo de la configuración de su configuración local de R) si se utiliza una coma en el lugar de los decimales (por ejemplo, “4,5” para significar cuatro años y medio). \n\n\n\nage_categories()\nCon el paquete epikit, puedes utilizar la función age_categories() para categorizar y etiquetar fácilmente las columnas numéricas (nota: esta función puede aplicarse también a las variables numéricas no relacionadas con la edad). Además, la columna de salida es automáticamente un factor ordenado.\nAquí están las entradas requeridas:\n\nUn vector numérico (columna)\nEl argumento + breakers = ` - proporciona un vector numérico de puntos de ruptura para los nuevos grupos\n\nPrimero, el ejemplo más sencillo:\n\n# Ejemplo simple\n################\npacman::p_load(epikit)                    # cargar paquete\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(             # crear una columna nueva\n      age_years,                            # columna numérica para hacer grupos\n      breakers = c(0, 5, 10, 15, 20,        # puntos de ruptura\n                   30, 40, 50, 60, 70)))\n\n# mostrar la tabla\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    27     7   107 \n\n\nLos valores de ruptura que especificas son por defecto los límites inferiores - es decir, están incluidos en el grupo “superior” / los grupos están “abiertos” en la parte inferior/izquierda. Como se muestra a continuación, puedes añadir 1 a cada valor de ruptura para conseguir grupos que estén abiertos por la parte superior/derecha.\n\n# Incluir los extremos superiores para las mismas categorías\n############################################################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# mostrar tabla\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  &lt;NA&gt; \n 1469  1195  1040   770  1149   547   231    70    24     6   107 \n\n\nPuedes ajustar cómo se muestran las etiquetas con el separator =. El valor predeterminado es “-”\nPuedes ajustar cómo se manejan los números superiores, con el argumento ceiling =. Para establecer un corte superior establezca ceiling = TRUE. En este uso, el valor de ruptura más alto proporcionado es un “techo” y no se crea una categoría “XX+”. Cualquier valor por encima del valor de corte más alto (o hasta el límite upper =, si está definido) se categoriza como NA. A continuación, se muestra un ejemplo con ceiling = TRUE, de modo que no hay categoría de XX+ y los valores por encima de 70 (el valor de ruptura más alto) se asignan como NA.\n\n# Con ceiling fijado en TRUE\n############################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# mostrar tabla\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    28   113 \n\n\nAlternativamente, en lugar de los breakers =, puedes proporcionar todos los lower =, upper =, and by =:\n\nlower = El número más bajo que se quiere considerar - por defecto es 0\nupper = El número más alto que quiere que se considere\n\nby = El número de años entre los grupos\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# mostrar tabla\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  &lt;NA&gt; \n 2450  1875  1216   597   251    78    27     6     1     0     0   107 \n\n\nConsulta la página de ayuda de la función para más detalles (escribe ?age_categories en la consola de R).\n\n\n\ncut()\ncut() es una alternativa a age_categories() de R base, pero creo que verás por qué age_categories() se desarrolló para simplificar este proceso. Algunas diferencias notables de age_categories() son:\n\nNo es necesario instalar/cargar otro paquete\nPuedes especificar si los grupos están abiertos/cerrados a la derecha/izquierda\nDebes proporcionar etiquetas precisas\nSi quieres que el 0 se incluya en el grupo más bajo debes especificarlo\n\nLa sintaxis básica dentro de cut() es proporcionar primero la columna numérica que se va a cortar (age_years), y luego el argumento breaks, que es un vector numérico c() de puntos de ruptura. Utilizando cut(), la columna resultante es un factor ordenado.\nPor defecto, la categorización se produce de manera que el lado derecho/superior es “abierto” e inclusivo (y el lado izquierdo/inferior es “cerrado” o exclusivo). Este es el comportamiento opuesto al de la función age_categories(). Las etiquetas por defecto utilizan la notación “(A, B]”, lo que significa que A no está incluido pero B sí. Invierte este comportamiento proporcionando el argumento right = TRUE.\nAsí, por defecto, ¡los valores “0” se excluyen del grupo más bajo, y se categorizan como NA! Los valores “0” podrían ser codificados para los bebés como edad 0, así que ¡ten cuidado! Para cambiar esto, añade el argumento include.lowest = TRUE para que cualquier valor “0” se incluya en el grupo más bajo. La etiqueta generada automáticamente para la categoría más baja será entonces “[A],B]”. Ten en cuenta que si incluye el argumento include.lowest = TRUE y right = TRUE, la inclusión extrema se aplicará ahora al valor del punto de ruptura y a la categoría más altos, no a los más bajos.\nPuedes proporcionar un vector de etiquetas personalizadas utilizando el argumento labels =. Como se escriben manualmente, ¡ten mucho cuidado de que sean precisas! Comprueba el trabajo utilizando una tabulación cruzada, como se describe a continuación.\nA continuación se muestra un ejemplo de cut() aplicado a age_years para crear la nueva variable age_cat:\n\n# Crear una nueva variable, cortando la variable numérica age\n# Se excluye el corte inferior pero se incluye el superior en cada categoría\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # # incluye 0 en el grupo más bajo\n      ))\n\n# tabular el número de observaciones por grupo\ntable(linelist$age_cat, useNA = \"always\")\n\n\n   [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100] \n    1469     1195     1040      770     1149      778       94        6 \n    &lt;NA&gt; \n     107 \n\n\n¡Comprueba tu trabajo! Verifica que cada valor de edad fue asignado a la categoría correcta cruzando las columnas numéricas y de categoría. Examina la asignación de los valores límite (por ejemplo, 15, si las categorías vecinas son 10-15 y 16-20).\n\n# Tabulación cruzada de las columnas numéricas y categóricas. \ntable(\"Numeric Values\" = linelist$age_years,   # nombres especificados en la tabla para mayor claridad.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # no olvides examinar los valores NA\n\n                    Categories\nNumeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70]\n  0                    136      0       0       0       0       0       0\n  0.0833333333333333     1      0       0       0       0       0       0\n  0.25                   2      0       0       0       0       0       0\n  0.333333333333333      6      0       0       0       0       0       0\n  0.416666666666667      1      0       0       0       0       0       0\n  0.5                    6      0       0       0       0       0       0\n  0.583333333333333      3      0       0       0       0       0       0\n  0.666666666666667      3      0       0       0       0       0       0\n  0.75                   3      0       0       0       0       0       0\n  0.833333333333333      1      0       0       0       0       0       0\n  0.916666666666667      1      0       0       0       0       0       0\n  1                    275      0       0       0       0       0       0\n  1.5                    2      0       0       0       0       0       0\n  2                    308      0       0       0       0       0       0\n  3                    246      0       0       0       0       0       0\n  4                    233      0       0       0       0       0       0\n  5                    242      0       0       0       0       0       0\n  6                      0    241       0       0       0       0       0\n  7                      0    256       0       0       0       0       0\n  8                      0    239       0       0       0       0       0\n  9                      0    245       0       0       0       0       0\n  10                     0    214       0       0       0       0       0\n  11                     0      0     220       0       0       0       0\n  12                     0      0     224       0       0       0       0\n  13                     0      0     191       0       0       0       0\n  14                     0      0     199       0       0       0       0\n  15                     0      0     206       0       0       0       0\n  16                     0      0       0     186       0       0       0\n  17                     0      0       0     164       0       0       0\n  18                     0      0       0     141       0       0       0\n  19                     0      0       0     130       0       0       0\n  20                     0      0       0     149       0       0       0\n  21                     0      0       0       0     158       0       0\n  22                     0      0       0       0     149       0       0\n  23                     0      0       0       0     125       0       0\n  24                     0      0       0       0     144       0       0\n  25                     0      0       0       0     107       0       0\n  26                     0      0       0       0     100       0       0\n  27                     0      0       0       0     117       0       0\n  28                     0      0       0       0      85       0       0\n  29                     0      0       0       0      82       0       0\n  30                     0      0       0       0      82       0       0\n  31                     0      0       0       0       0      68       0\n  32                     0      0       0       0       0      84       0\n  33                     0      0       0       0       0      78       0\n  34                     0      0       0       0       0      58       0\n  35                     0      0       0       0       0      58       0\n  36                     0      0       0       0       0      33       0\n  37                     0      0       0       0       0      46       0\n  38                     0      0       0       0       0      45       0\n  39                     0      0       0       0       0      45       0\n  40                     0      0       0       0       0      32       0\n  41                     0      0       0       0       0      34       0\n  42                     0      0       0       0       0      26       0\n  43                     0      0       0       0       0      31       0\n  44                     0      0       0       0       0      24       0\n  45                     0      0       0       0       0      27       0\n  46                     0      0       0       0       0      25       0\n  47                     0      0       0       0       0      16       0\n  48                     0      0       0       0       0      21       0\n  49                     0      0       0       0       0      15       0\n  50                     0      0       0       0       0      12       0\n  51                     0      0       0       0       0       0      13\n  52                     0      0       0       0       0       0       7\n  53                     0      0       0       0       0       0       4\n  54                     0      0       0       0       0       0       6\n  55                     0      0       0       0       0       0       9\n  56                     0      0       0       0       0       0       7\n  57                     0      0       0       0       0       0       9\n  58                     0      0       0       0       0       0       6\n  59                     0      0       0       0       0       0       5\n  60                     0      0       0       0       0       0       4\n  61                     0      0       0       0       0       0       2\n  62                     0      0       0       0       0       0       1\n  63                     0      0       0       0       0       0       5\n  64                     0      0       0       0       0       0       1\n  65                     0      0       0       0       0       0       5\n  66                     0      0       0       0       0       0       3\n  67                     0      0       0       0       0       0       2\n  68                     0      0       0       0       0       0       1\n  69                     0      0       0       0       0       0       3\n  70                     0      0       0       0       0       0       1\n  72                     0      0       0       0       0       0       0\n  73                     0      0       0       0       0       0       0\n  76                     0      0       0       0       0       0       0\n  84                     0      0       0       0       0       0       0\n  &lt;NA&gt;                   0      0       0       0       0       0       0\n                    Categories\nNumeric Values       (70,100] &lt;NA&gt;\n  0                         0    0\n  0.0833333333333333        0    0\n  0.25                      0    0\n  0.333333333333333         0    0\n  0.416666666666667         0    0\n  0.5                       0    0\n  0.583333333333333         0    0\n  0.666666666666667         0    0\n  0.75                      0    0\n  0.833333333333333         0    0\n  0.916666666666667         0    0\n  1                         0    0\n  1.5                       0    0\n  2                         0    0\n  3                         0    0\n  4                         0    0\n  5                         0    0\n  6                         0    0\n  7                         0    0\n  8                         0    0\n  9                         0    0\n  10                        0    0\n  11                        0    0\n  12                        0    0\n  13                        0    0\n  14                        0    0\n  15                        0    0\n  16                        0    0\n  17                        0    0\n  18                        0    0\n  19                        0    0\n  20                        0    0\n  21                        0    0\n  22                        0    0\n  23                        0    0\n  24                        0    0\n  25                        0    0\n  26                        0    0\n  27                        0    0\n  28                        0    0\n  29                        0    0\n  30                        0    0\n  31                        0    0\n  32                        0    0\n  33                        0    0\n  34                        0    0\n  35                        0    0\n  36                        0    0\n  37                        0    0\n  38                        0    0\n  39                        0    0\n  40                        0    0\n  41                        0    0\n  42                        0    0\n  43                        0    0\n  44                        0    0\n  45                        0    0\n  46                        0    0\n  47                        0    0\n  48                        0    0\n  49                        0    0\n  50                        0    0\n  51                        0    0\n  52                        0    0\n  53                        0    0\n  54                        0    0\n  55                        0    0\n  56                        0    0\n  57                        0    0\n  58                        0    0\n  59                        0    0\n  60                        0    0\n  61                        0    0\n  62                        0    0\n  63                        0    0\n  64                        0    0\n  65                        0    0\n  66                        0    0\n  67                        0    0\n  68                        0    0\n  69                        0    0\n  70                        0    0\n  72                        1    0\n  73                        3    0\n  76                        1    0\n  84                        1    0\n  &lt;NA&gt;                      0  107\n\n\nRe-etiquetado de los valores NA\nPuedes asignar a los valores NA una etiqueta como “Missing”. Como la nueva columna es del tipo Factor (valores restringidos), no puedes simplemente mutarla con replace_na(), ya que este valor será rechazado. En su lugar, utilice fct_explicit_na() de forcats como se explica en la página de Factores.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # cut() crea age_cat, automáticamente de clase Factor           \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # hacer explícitos los valores que faltan\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # puedes especificar la etiqueta\n  )    \n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat = fct_explicit_na(age_cat, na_level = \"Missing age\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n# tabla para ver los recuentos\ntable(linelist$age_cat, useNA = \"always\")\n\n\n        0-4         5-9       10-14       15-19       20-29       30-49 \n       1227        1223        1048         827        1216         848 \n      50-69      70-100 Missing age        &lt;NA&gt; \n        105           7         107           0 \n\n\nRealiza rápidamente pausas y etiquetas\nPara una forma rápida de hacer rupturas y etiquetar vectores, utiliza algo como lo siguiente. Consulta la página de fundamentos de R para obtener referencias sobre seq() y rep().\n\n# Crear puntos de ruptura de 0 a 90 por 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Crear etiquetas para las categorías anteriores, asumiendo la configuración por defecto de cut()\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# comprobar que ambos vectores tienen la misma longitud\nlength(age_seq) == length(age_labels)\n\nLee más sobre cut() en la página de ayuda escribiendo ?cut en la consola de R.\n\n\nRoturas cuartílicas\nEn el entendimiento común, los “cuartiles” o “percentiles” suelen referirse a un valor por debajo del cual cae una proporción de valores. Por ejemplo, el percentil 95 de las edades en linelist sería la edad por debajo de la cual cae el 95% de las edades.\nSin embargo, en el lenguaje común, “cuartiles” y “deciles” también pueden referirse a los grupos de datos divididos por igual en 4 o 10 grupos (Ten en cuenta que habrá un punto de ruptura más que un grupo).\nPara obtener los puntos de ruptura de los cuartiles, se puede utilizar quantile() del paquete stats de R base. Se proporciona un vector numérico (por ejemplo, una columna en unos datos) y un vector de valores de probabilidad numérica que van de 0 a 1,0. Los puntos de ruptura se devuelven como un vector numérico. Explore los detalles de las metodologías estadísticas escribiendo ?quantile.\n\nSi el vector numérico de entrada tiene valores faltantes, es mejor establecer na.rm = TRUE\nEstablecer names = FALSE para obtener un vector numérico sin nombre\n\n\nquantile(linelist$age_years,               # especificar el vector numérico con el que se va a trabajar\n  probs = c(0, .25, .50, .75, .90, .95),   # especificar los percentiles deseados\n  na.rm = TRUE)                            # ignorar los valores perdidos \n\n 0% 25% 50% 75% 90% 95% \n  0   6  13  23  33  41 \n\n\nPuedes utilizar los resultados de quantile() como puntos de ruptura en age_categories() o cut(). A continuación creamos una nueva columna deciles utilizando cut() donde los puntos de ruptura se definen utilizando quantiles() en age_years. A continuación, mostramos los resultados utilizando tabyl() de janitor para que puedas ver los porcentajes (véase la página de tablas descriptivas). Observa cómo no son exactamente el 10% en cada grupo.\n\nlinelist %&gt;%                                # comienza con linelist\n  mutate(deciles = cut(age_years,           # crea una nueva columna con deciles de la columna age_years\n    breaks = quantile(                      # define puntos de corte usando quantile()\n      age_years,                               # opera sobre age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 a 1.0 por 0.1\n      na.rm = TRUE),                           # ignora los valores perdidos\n    include.lowest = TRUE)) %&gt;%             # para cut() incluye age 0\n  janitor::tabyl(deciles)                   # pipe para mostrar la tabla\n\n deciles   n    percent valid_percent\n   [0,2] 748 0.11319613    0.11505922\n   (2,5] 721 0.10911017    0.11090601\n   (5,7] 497 0.07521186    0.07644978\n  (7,10] 698 0.10562954    0.10736810\n (10,13] 635 0.09609564    0.09767728\n (13,17] 755 0.11425545    0.11613598\n (17,21] 578 0.08746973    0.08890940\n (21,26] 625 0.09458232    0.09613906\n (26,33] 596 0.09019370    0.09167820\n (33,84] 648 0.09806295    0.09967697\n    &lt;NA&gt; 107 0.01619249            NA\n\n\n\n\nGrupos de tamaño uniforme\nOtra herramienta para hacer grupos numéricos es la función ntile() de dplyr, que intenta dividir los datos en n grupos de tamaño uniforme - pero ten en cuenta que, a diferencia de quantile(), el mismo valor podría aparecer en más de un grupo. Proporcione el vector numérico y luego el número de grupos. Los valores de la nueva columna creada son sólo “números” de grupo (por ejemplo, del 1 al 10), no el rango de valores en sí mismo como cuando se utiliza cut().\n\n# crea grupos con ntile()\nntile_data &lt;- linelist %&gt;% \n  mutate(even_groups = ntile(age_years, 10))\n\n# crea una tabla de recuentos y proporciones por grupo\nntile_table &lt;- ntile_data %&gt;% \n  janitor::tabyl(even_groups)\n  \n# adjunta los valores mínimo/máximo para demostrar los rangos\nntile_ranges &lt;- ntile_data %&gt;% \n  group_by(even_groups) %&gt;% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `min = min(age_years, na.rm = T)`.\nℹ In group 11: `even_groups = NA`.\nCaused by warning in `min()`:\n! no non-missing arguments to min; returning Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# combina e imprime - ten en cuenta que los valores están presentes en varios grupos\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")\n\n even_groups   n    percent valid_percent min  max\n           1 651 0.09851695    0.10013844   0    2\n           2 650 0.09836562    0.09998462   2    5\n           3 650 0.09836562    0.09998462   5    7\n           4 650 0.09836562    0.09998462   7   10\n           5 650 0.09836562    0.09998462  10   13\n           6 650 0.09836562    0.09998462  13   17\n           7 650 0.09836562    0.09998462  17   21\n           8 650 0.09836562    0.09998462  21   26\n           9 650 0.09836562    0.09998462  26   33\n          10 650 0.09836562    0.09998462  33   84\n          NA 107 0.01619249            NA Inf -Inf\n\n\n\n\n\ncase_when()\nEs posible utilizar la función case_when() de dplyr para crear categorías a partir de una columna numérica, pero es más fácil utilizar age_categories() de epikit o cut() porque éstas crearán un factor ordenado automáticamente.\nSi utilizas case_when(), por favor, revise el uso adecuado como se ha descrito anteriormente en la sección Re-codificar valores de esta página. También Ten en cuenta que todos los valores del lado derecho deben ser del mismo tipo. Por lo tanto, si quiere NA en el lado derecho debes escribir “Missing” o utilizar el valor especial NA_character_.\n\n\nAñadir a la cadena de pipes\nA continuación, se añade el código para crear dos columnas categóricas de edad a la cadena de pipes de limpieza:\n\n# CADENA DE LIMPIEZA (comienza con los datos en bruto y enlaza con pipes los pasos de limpieza)\n################################################################################################\n\n# Comienza la cadena de pipes de limpieza\n#########################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # sintaxis para estandarizar los nombres de las columnas\n    janitor::clean_names() %&gt;% \n    \n    # renombrar manualmente las columnas\n           # Nombre NUEVO         # Nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # eliminar columna\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicar\n    distinct() %&gt;% \n\n    # añadir columna\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convertir el tipo de columnas\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # añadir columna: retraso en la hospitalización\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # limpiar los valores de la columna hospital\n    mutate(hospital = recode(hospital,\n                      # ANTIGUO = NUEVO\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # crear la columna age_years (A partir de age y age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    # ARRIBA ESTÁN LOS PASOS DE LIMPIEZA YA DISCUTIDOS\n    ###################################################   \n    mutate(\n          # categorías de edad: personalizadas\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # categorías de edad: 0 a 85 por 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#add-rows",
    "href": "new_pages/cleaning.es.html#add-rows",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.10 Añadir filas",
    "text": "8.10 Añadir filas\n\nUno a uno\nAñadir filas una a una manualmente es tedioso pero puede hacerse con add_row() de dplyr. Recuerda que cada columna debe contener valores de un solo tipo (ya sea carácter, numérico, lógico, etc.). Así que añadir una fila requiere matizar para mantener esto.\n\nlinelist &lt;- linelist %&gt;% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)\n\nUtiliza .before y .after. para especificar la ubicación de la fila que deseas añadir. .before = 3 pondrá la nueva fila antes de la tercera fila actual. El comportamiento por defecto es añadir la fila al final. Las columnas no especificadas se dejarán vacías (NA).\nEl nuevo número de fila puede parecer extraño (“…23”) pero los números de fila de las filas preexistentes han cambiado. Por lo tanto, si utiliza el comando dos veces, examine/pruebe la inserción cuidadosamente.\nSi uno de los tipos que proporcionas está desactivado, verás un error como este:\nError: Can't combine ..1$infection date &lt;date&gt; and ..2$infection date &lt;character&gt;.\n(al insertar una fila con un valor de fecha, recuerde envolver la fecha en la función as.Date() como as.Date(\"2020-10-10\")).\n\n\nUnir filas\nPara combinar conjuntos de datos uniendo las filas de un dataframe al final de otro dataframe, puedes utilizar bind_rows() de dplyr. Esto se explica con más detalle en la página Unir datos.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#filter-rows",
    "href": "new_pages/cleaning.es.html#filter-rows",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.11 Filtrar filas",
    "text": "8.11 Filtrar filas\nUn paso típico de limpieza después de haber limpiado las columnas y recodificado los valores es filtrar el dataframe para filas específicas usando el verbo dplyr filter().\nDentro de filter(), especifique la lógica que debe ser TRUE para que se mantenga una fila en los datos. A continuación, mostramos cómo filtrar filas basándose en condiciones lógicas simples y complejas.\n\n\nFiltro simple\nEste sencillo ejemplo redefine el dataframe linelist en sí mismo, habiendo filtrado las filas para que cumplan una condición lógica. Sólo se conservan las filas en las que la declaración lógica dentro de los paréntesis se evalúa como TRUE.\nEn este ejemplo, la sentencia lógica es gender == \"f\", que pregunta si el valor de la columna gender es igual a “f” (distingue entre mayúsculas y minúsculas).\nAntes de aplicar el filtro, el número de filas de linelist es nrow(linelist).\n\nlinelist &lt;- linelist %&gt;% \n  filter(gender == \"f\")   # mantener sólo las filas en las que gender es igual a \"f\"\n\nDespués de aplicar el filtro, el número de filas de linelist is linelist %&gt;% filter(gender == \"f\") %&gt;% nrow().\n\n\nFiltrar los valores faltantes\nEs bastante común querer filtrar las filas que tienen valores faltantes. Resiste la tentación de escribir filter(!is.na(column) & !is.na(column)) y utiliza en su lugar la función de tidyr que está hecha a medida para este propósito: drop_na(). Si se ejecuta con paréntesis vacíos, elimina las filas con cualquier valor que falte. Como alternativa, puedes proporcionar los nombres de las columnas específicas que deben evaluarse para comprobar si faltan, o utilizar las funciones de ayuda “tidyselect” descritas anteriormente.\n\nlinelist %&gt;% \n  drop_na(case_id, age_years)  # eliminar las filas con valores perdidos para case_id o age_years\n\nConsulta la página sobre Valores faltantes para conocer muchas técnicas para analizar y gestionar los datos ausentes.\n\n\nFiltrar por número de fila\nEn un dataframe o tibble, cada fila suele tener un “número de fila” que (cuando se ve en R Viewer) aparece a la izquierda de la primera columna. No es en sí misma una columna real en los datos, pero puede utilizarse en una sentencia filter().\nPara filtrar en base al “número de fila”, puedes utilizar la función row_number() de dplyr con paréntesis abiertos como parte de una sentencia lógica de filtrado. A menudo se utiliza el operador %in% y un rango de números como parte de esa sentencia lógica, como se muestra a continuación. Para ver las primeras N filas, también puedes utilizar la función especial head() de dplyr.\n\n# Ver las 100 primeras filas\nlinelist %&gt;% head(100)     #  o usar tail() para ver las n últimas filas\n\n# Mostrar sólo la fila 5\nlinelist %&gt;% filter(row_number() == 5)\n\n# Ver las filas 2 a 20, y sólo tres columnas específicas\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nTambién puedes convertir los números de fila en una verdadera columna pasando su dataframe a la función rownames_to_column() de tibble (no escribas nada en los paréntesis).\n\n\n\nFiltro complejo\nSe pueden construir sentencias lógicas más complejas utilizando paréntesis ( ), OR |, negación ! , %in%, y operadores AND &. Un ejemplo es el siguiente:\nNota: Puedes utilizar el operador ! delante de un criterio lógico para negarlo. Por ejemplo, !is.na(column) se evalúa como verdadero si el valor de la columna no falta. Del mismo modo, !column %in% c(\"a\", \"b\", \"c\") es verdadero si el valor de la columna no está en el vector.\n\nExaminar los datos\nA continuación, se muestra un sencillo comando de una línea para crear un histograma de las fechas de inicio. Vea que un segundo brote más pequeño de 2012-2013 también está incluido en este conjunto de datos sin procesar. Para nuestros análisis, queremos eliminar las entradas de este brote anterior.\n\nhist(linelist$date_onset, breaks = 50)\n\n\n\n\n\n\n\n\n\n\n¿Cómo manejan los filtros los valores numéricos y de fecha que faltan?\n¿Podemos simplemente filtrar por date_onset a las filas posteriores a junio de 2013? Precaución. La aplicación del código filter(date_onset &gt; as.Date(\"2013-06-01\")) eliminaría todas las filas de la epidemia posterior con una fecha de inicio ausente!\nPELIGRO: Filtrar a mayor que (&gt;) o menor que (&lt;) una fecha o número puede eliminar cualquier fila con valores faltantes (NA). Esto se debe a que NA es tratado como infinitamente grande y pequeño. \n(Consulta la página sobre el trabajando con fechas para obtener más información sobre el trabajo con fechas y el paquete lubridate)\n\n\nDiseñar el filtro\nExamina una tabulación cruzada para asegurarte de que excluimos sólo las filas correctas:\n\ntable(Hospital  = linelist$hospital,                     # nombre del hospital\n      YearOnset = lubridate::year(linelist$date_onset),  # año de date_onset\n      useNA     = \"always\")                              # mostrar los valores perdidos\n\n                                      YearOnset\nHospital                               2012 2013 2014 2015 &lt;NA&gt;\n  Central Hospital                        0    0  351   99   18\n  Hospital A                            229   46    0    0   15\n  Hospital B                            227   47    0    0   15\n  Military Hospital                       0    0  676  200   34\n  Missing                                 0    0 1117  318   77\n  Other                                   0    0  684  177   46\n  Port Hospital                           9    1 1372  347   75\n  St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n  &lt;NA&gt;                                    0    0    0    0    0\n\n\n¿Qué otros criterios podemos filtrar para eliminar el primer brote (en 2012 y 2013) de los datos? Vemos que:\n\nLa primera epidemia en 2012 y 2013 ocurrió en el Hospital A, el Hospital B, y que también hubo 10 casos en el Hospital del Puerto.\nLos hospitales A y B no tuvieron casos en la segunda epidemia, pero Port Hospital sí.\n\nQueremos excluir:\n\nLas filas con inicio en 2012 y 2013 en cualquiera de los hospitales A, B o Port nrow(linelist %&gt;% filter(hospital %in% c(\"Hospital A\", \"Hospital B\") | date_onset &lt; as.Date(\"2013-06-01\"))) :\n\nExcluir nrow(linelist %&gt;% filter(date_onset &lt; as.Date(\"2013-06-01\"))) filas con inicio en 2012 y 2013 * Excluir nrow(linelist %&gt;% filter(hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) filas de los hospitales A y B con fechas de inicio ausentes\n\nNo excluir nrow(linelist %&gt;% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) otras filas con fechas de inicio ausentes.\n\n\nComenzamos con un listado de nrow(linelist). Aquí está nuestro filtro:\n\nlinelist &lt;- linelist %&gt;% \n  # conservar las filas donde el inicio sea posterior al 1 de junio de 2013 O en las que falte el inicio y se trate de un hospital distinto del Hospital A o B\n  filter(date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)\n\n[1] 6019\n\n\nCuando volvemos a hacer la tabulación cruzada, vemos que los hospitales A y B se eliminan por completo, y los 10 casos del Port Hospital de 2012 y 2013 se eliminan, y todos los demás valores son los mismos, tal y como queríamos.\n\ntable(Hospital  = linelist$hospital,                     # nombre del hospital\n      YearOnset = lubridate::year(linelist$date_onset),  # año de date_onset\n      useNA     = \"always\")                              # mostrar los valores perdidos\n\n                                      YearOnset\nHospital                               2014 2015 &lt;NA&gt;\n  Central Hospital                      351   99   18\n  Military Hospital                     676  200   34\n  Missing                              1117  318   77\n  Other                                 684  177   46\n  Port Hospital                        1372  347   75\n  St. Mark's Maternity Hospital (SMMH)  322   93   13\n  &lt;NA&gt;                                    0    0    0\n\n\nSe pueden incluir varias sentencias dentro de un comando de filtrado (separadas por comas), o siempre se puede canalizar a un comando filter() separado para mayor claridad.\nNota: algunos lectores pueden notar que sería más fácil filtrar sólo por date_hospitalisation porque es 100% completo sin valores faltantes. Esto es cierto. Pero date_onset se utiliza para demostrar un filtro complejo.\n\n\n\nIndependiente\nEl filtrado también puede realizarse como un comando independiente (no como parte de una cadena de pipes). Como otros verbos de dplyr, en este caso el primer argumento debe ser el propio conjunto de datos.\n\n# dataframe &lt;- filter(dataframe, condición(es) para las filas a conservar)\n\nlinelist &lt;- filter(linelist, !is.na(case_id))\n\nTambién puedes utilizar R base para hacer un subconjunto utilizando corchetes que reflejen las [filas, columnas] que deseas conservar.\n\n# dataframe &lt;- dataframe[condiciones para filas, condiciones para columnas] (en blanco significa todas)\n\nlinelist &lt;- linelist[!is.na(case_id), ]\n\n\n\nRevisar rápidamente los registros\nA menudo se quiere revisar rápidamente unos pocos registros, para sólo unas pocas columnas. La función View() de R base imprimirá un dataframe para su visualización en su RStudio.\nMira el listado en RStudio:\n\nView(linelist)\n\nAquí hay dos ejemplos de visualización de celdas específicas (filas específicas y columnas específicas):\nCon las funciones filter() y select() de dplyr :\nDentro de View(), canaliza los datos a filter() para mantener ciertas filas, y luego a select() para mantener ciertas columnas. Por ejemplo, para revisar las fechas de inicio y hospitalización de 3 casos específicos:\n\nView(linelist %&gt;%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %&gt;%\n       select(date_onset, date_hospitalisation))\n\nPuedes lograr lo mismo con la sintaxis de R base, utilizando los corchetes [ ] para el subconjunto que deseas ver.\n\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\n\n\nAñadir a la cadena de pipes\n\n# CADENA DE LIMPIEZA (comienza con los datos en bruto y enlaza con pipes los pasos de limpieza)\n################################################################################################\n\n# Comienza la cadena de pipes de limpieza\n#########################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # sintaxis para estandarizar los nombres de las columnas\n    janitor::clean_names() %&gt;% \n    \n    # renombrar manualmente las columnas\n           # Nombre NUEVO         # Nombre ANTIGUO\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # eliminar columna\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicar\n    distinct() %&gt;% \n\n    # añadir columna\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convertir el tipo de columnas\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # añadir columna: retraso en la hospitalización\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # limpiar los valores de la columna hospital\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # crear la columna age_years (A partir de age y age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    mutate(\n          # categorías de edad: personalizada\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # categorías de edad: 0 a 85 por 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %&gt;% \n    \n   # ARRIBA ESTÁN LOS PASOS DE LIMPIEZA YA DISCUTIDOS\n   ###################################################\n    filter(\n          # mantener sólo las filas en las que no falta case_id\n          !is.na(case_id),  \n          \n          # también filtrar para mantener sólo el segundo brote\n          date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#row-wise-calculations",
    "href": "new_pages/cleaning.es.html#row-wise-calculations",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.12 Cálculos por filas",
    "text": "8.12 Cálculos por filas\nSi deseas realizar un cálculo dentro de una fila, puedes utilizar rowwise() de dplyr. Consulta esta viñeta en línea sobre los cálculos por filas. Por ejemplo, este código aplica rowwise() y luego crea una nueva columna que suma el número de las columnas de síntomas especificadas que tienen valor “yes”, para cada fila Las columnas se especifican dentro de sum() por su nombre dentro de un vector c(). rowwise() es esencialmente un tipo especial de group_by(), por lo que es mejor utilizar ungroup() cuando hayas terminado (página sobre Agrupar datos).\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %&gt;% \n  ungroup() %&gt;% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display\n\n# A tibble: 5,888 × 6\n   fever chills cough aches vomit num_symptoms\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;\n 1 no    no     yes   no    yes              2\n 2 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 3 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 4 no    no     no    no    no               0\n 5 no    no     yes   no    yes              2\n 6 no    no     yes   no    yes              2\n 7 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 8 no    no     yes   no    yes              2\n 9 no    no     yes   no    yes              2\n10 no    no     yes   no    no               1\n# ℹ 5,878 more rows\n\n\nAl especificar la columna a evaluar, puedes utilizar las funciones de ayuda “tidyselect” descritas en la sección select() de esta página. Sólo tiene que hacer un ajuste (porque no las está utilizando dentro de una función de dplyr como select() o summarise()).\nEspecifica los criterios de la columna dentro de la función c_across() de dplyr. Esto se debe a que c_across (documentación) está diseñada para trabajar con rowwise() específicamente. Por ejemplo, el siguiente código:\n\nUtiliza rowwise() para que la siguiente operación (sum()) se aplique dentro de cada fila (no sumando columnas enteras)\nCrea una nueva columna num_NA_dates, definida para cada fila como el número de columnas (con nombre que contiene “date”) para las que is.na() se evaluó como TRUE (son valores faltantes).\nungroup() para eliminar los efectos de rowwise() en los pasos siguientes\n\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %&gt;% \n  ungroup() %&gt;% \n  select(num_NA_dates, contains(\"date\")) # for display\n\n# A tibble: 5,888 × 5\n   num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n          &lt;int&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n 2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n 3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n 4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n 5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n\n\nTambién podrías proporcionar otras funciones, como max() para obtener la fecha más reciente o más reciente de cada fila:\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %&gt;% \n  ungroup() %&gt;% \n  select(latest_date, contains(\"date\"))  # for display\n\n# A tibble: 5,888 × 5\n   latest_date date_infection date_onset date_hospitalisation date_outcome\n   &lt;date&gt;      &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n 2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n 3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n 4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n 5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.es.html#arrange-and-sort",
    "href": "new_pages/cleaning.es.html#arrange-and-sort",
    "title": "8  Limpieza de datos y funciones básicas",
    "section": "8.13 Ordenar y clasificar",
    "text": "8.13 Ordenar y clasificar\nUtiliza la función arrange() de dplyr para ordenar las filas por los valores de las columnas.\nLista las columnas en el orden en que deben ser ordenadas. Especifica .by_group = TRUE si deseas que la ordenación se realice primero por cualquier agrupación aplicada a los datos (véase la página sobre Agrupar datos).\nPor defecto, la columna se ordenará en orden “ascendente” (que se aplica a las columnas numéricas y también a las de caracteres). Puedes ordenar una variable en orden “descendente” envolviéndola con desc().\nLa ordenación de los datos con arrange() es particularmente útil cuando se hacen Tablas para presentaciones, utilizando slice() para tomar las filas “superiores” por grupo, o estableciendo el orden de los niveles de los factores por orden de aparición.\nPor ejemplo, para ordenar las filas de nuestro linelist por hospital y luego por date_onset (fecha de inicio) en orden descendente, utilizaríamos:\n\nlinelist %&gt;% \n   arrange(hospital, desc(date_onset))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Limpieza de datos y funciones básicas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html",
    "href": "new_pages/dates.es.html",
    "title": "9  Trabajando con Fechas",
    "section": "",
    "text": "9.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#preparation",
    "href": "new_pages/dates.es.html#preparation",
    "title": "9  Trabajando con Fechas",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de paquetes necesaria para esta página. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre los Fundamentos de R para obtener más información sobre los paquetes de R.\n\n# Ccomprueba si el paquete está instalado, lo instala si es necesario y lo carga para la sesión actual.\n\n\npacman::p_load(\n  lubridate, # paquete general para manejar y convertir fechas  \n  parsedate, # tiene una función para \"adivinar\" fechas desordenadas\n  aweek, # otra opción para convertir fechas en semanas, y semanas en fechas\n  zoo, # funciones adicionales de fecha/hora\n  here,       # gestión de archivos\n  tidyverse, # gestión y visualización de datos  \n  rio) # importación/exportación de datos\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso a paso, consulta las instrucciones en la página de descarga de manuales y datos. Asumimos que el archivo está en el directorio de trabajo, por lo que no se especifican subcarpetas en esta ruta de archivo.\n\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#current-date",
    "href": "new_pages/dates.es.html#current-date",
    "title": "9  Trabajando con Fechas",
    "section": "9.2 Fecha actual",
    "text": "9.2 Fecha actual\nPuedes obtener la fecha actual del “sistema” o la fecha-hora del sistema de tu ordenador haciendo lo siguiente con R base.\n\n# obtener la fecha del sistema - esta es de tipo DATE (FECHA)\nSys.Date()\n\n[1] \"2024-05-10\"\n\n# obtener la hora del sistema - esta es de tipo DATETIME (FECHAHORA)\nSys.time()\n\n[1] \"2024-05-10 04:57:18 CEST\"\n\n\nCon el paquete lubridate también se pueden devolver con today() y now(), respectivamente. date() devuelve la fecha y la hora actuales con los nombres del día de la semana y del mes.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#convert-to-date",
    "href": "new_pages/dates.es.html#convert-to-date",
    "title": "9  Trabajando con Fechas",
    "section": "9.3 Convertir en fecha",
    "text": "9.3 Convertir en fecha\nDespués de importar unos datos a R, los valores de las columnas de fecha pueden tener el aspecto de “1989/12/30”, “05/06/2014” o “13 Ene 2020”. En estos casos, es probable que R siga tratando estos valores como valores de carácter. Hay que decirle a R que estos valores son fechas… y cuál es el formato de la fecha (qué parte es Día, cuál es Mes, cuál es Año, etc).\nUna vez dicho esto, R convierte estos valores al tipo Date. En segundo plano, R almacenará las fechas como números (el número de días desde su fecha “origen” 1 Ene 1970). No interactuarás con el número de la fecha a menudo, pero esto permite a R tratar las fechas como variables continuas y permitir operaciones especiales como el cálculo de la distancia entre las fechas.\nPor defecto, los valores del tipo Date en R se muestran como AAAA-MM-DD. Más adelante en esta sección discutiremos cómo cambiar la visualización de los valores de fecha.\nA continuación presentamos dos enfoques para convertir una columna de valores de carácter al tipo Date.\nCONSEJO:: Puedes comprobar el tipo actual de una columna con la función class()de R base, como class(linelist$date_onset).\n\nR base\nas.Date() es la función estándar de R base para convertir un objeto o una columna en el tipo Date (nótese la “D” en mayúscula).\nEl uso de as.Date() requiere que:\n\nSe especifique el formato existente de la fecha de carácter en bruto o la fecha de origen si se suministran las fechas como números (véase la sección sobre las fechas de Excel)\nSi se utiliza en una columna de caracteres, todos los valores de fecha deben tener el mismo formato exacto (si no es el caso, pruebe con parse_date() del paquete parsedate)\n\nEn primer lugar, comprueba el tipo de la columna con class() de R base . Si no estás seguro o estás confundido sobre el tipo de datos (por ejemplo, ve “POSIXct”, etc.) puede ser más fácil convertir primero la columna al tipo Character con as.character(), y luego convertirla al tipo Date.\nEn segundo lugar, dentro de la función as.Date(), utiliza el argumento format = para indicar a R el formato actual de los componentes de la fecha con caracteres - qué caracteres se refieren al mes, al día y al año, y cómo están separados. Si sus valores ya están en uno de los formatos de fecha estándar de R (“AAAA-MM-DD” o “AAAA/MM/DD”) el argumento format = no es necesario.\nPara usar format =, escribe una cadena de caracteres (entre comillas) que represente el formato actual de la fecha utilizando las abreviaturas especiales “strptime” que aparecen a continuación. Por ejemplo, si las fechas de caracteres están actualmente en el formato “DD/MM/AAAA”, como “24/04/1968”, entonces usarías format = \"%d/%m/%Y\" para convertir los valores en fechas. Es necesario poner el formato entre comillas. ¡Y no olvides las barras o guiones!.\n\n# Convertir a tipo fecha\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))\n\nLa mayoría de las abreviaturas de strptime se enumeran a continuación. Puedes ver la lista completa ejecutando ?strptime.\n%d = Número del día del mes (5, 17, 28, etc.) %j = Número del día del año (día juliano 001-366) %a = Día de la semana abreviado (lunes, martes, miércoles, etc.) %A = Día de la semana completo (lunes, martes, etc.) %w = Número del día de la semana (0-6, el domingo es 0) %u = Número del día de la semana (1-7, el lunes es 1) %W = Número de la semana (00-53, el lunes es el comienzo de la semana) %U = Número de la semana (01-53, el domingo es el comienzo de la semana) %m = Número del mes (p. ej. 01, 02, 03, 04) %b = Mes abreviado (enero, febrero, etc.) %B = Mes completo (enero, febrero, etc.) %y = Año de 2 dígitos (p. ej. 89) %Y = Año de 4 dígitos (p. ej. 1989) %h = Horas (reloj de 24 horas) %m = Minutos %s = Segundos %z = Desplazamiento respecto a GMT %Z = Huso horario (carácter)\nCONSEJO: El argumento format = de as.Date() no le dice a R el formato que quiere que tengan las fechas, sino cómo identificar las partes de la fecha tal y como son antes de ejecutar el comando.\nCONSEJO: Asegúrate que en el argumento format = se utiliza el mismo separador de partes de fechas (por ejemplo, /, -, o espacio) que está en tus fechas.\nUna vez que los valores están en el tipo Fecha, R los mostrará por defecto en el formato estándar, que es AAAA-MM-DD.\n\n\nlubridate\nLa conversión de objetos de carácter a fechas puede facilitarse utilizando el paquete lubridate. Se trata de un paquete tidyverse diseñado para hacer que el trabajo con fechas y horas sea más sencillo y consistente que en R base. Por estas razones, el paquete lubridate se considera a menudo el estándar de oro para las fechas y la hora, y se recomienda siempre que se trabaje con ellas.\nEl paquete lubridate proporciona varias funciones de ayuda diferentes diseñadas para convertir objetos de caracteres en fechas de una manera intuitiva y más indulgente que especificando el formato en as.Date(). Estas funciones son específicas para el formato de fecha aproximado, pero permiten una variedad de separadores, y sinónimos para las fechas (por ejemplo, 01 vs Jan vs Enero) - se denominan según las abreviaturas de los formatos de fecha.\n\n# instalar/cargar lubridate \npacman::p_load(lubridate)\n\nLa flexibilidad de la función ymd() convierte de forma flexible los valores de fecha suministrados como año, luego mes y luego día.\n\n# leer la fecha en formato año-mes-día\nymd(\"2020-10-11\")\n\n[1] \"2020-10-11\"\n\nymd(\"20201011\")\n\n[1] \"2020-10-11\"\n\n\nLa función mdy() convierte de forma flexible los valores de fecha suministrados como mes, luego día y luego año.\n\n# leer la fecha en formato mes-día-año\nmdy(\"10/11/2020\")\n\n[1] \"2020-10-11\"\n\nmdy(\"Oct 11 20\")\n\n[1] \"2020-10-11\"\n\n\nLa función dmy() convierte de forma flexible los valores de fecha suministrados como día, luego mes y luego año.\n\n# leer la fecha en formato día-mes-año\ndmy(\"11 10 2020\")\n\n[1] \"2020-10-11\"\n\ndmy(\"11 October 2020\")\n\n[1] \"2020-10-11\"\n\n\n\n\n\n\nSi se utilizan pipes, la conversión de una columna de caracteres a fechas con lubridate podría tener este aspecto:\n\nlinelist &lt;- linelist %&gt;%\n  mutate(date_onset = lubridate::dmy(date_onset))\n\nUna vez completado, puedes ejecutar class() para verificar el tipo de la columna\n\n# Comprueba el tio de columna\nclass(linelist$date_onset)  \n\nUna vez que los valores están en el tipo Fecha, R los mostrará por defecto en el formato estándar, que es AAAA-MM-DD.\nTen en cuenta que las funciones anteriores funcionan mejor con años de 4 dígitos. Los años de 2 dígitos pueden producir resultados inesperados, ya que lubridate intenta adivinar el siglo.\nPara convertir un año de 2 dígitos en un año de 4 dígitos (todos en el mismo siglo) puedes convertirlo a tipo carácter y luego combinar los dígitos existentes con un prefijo usando str_glue() del paquete stringr. Ver Caracteres y cadenas. A continuación, convierte a fecha.\n\ntwo_digit_years &lt;- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")\n\n2015\n2015\n2016\n2017\n\n\n\n\nCombinar columnas\nPuedes utilizar las funciones de lubridate make_date() y make_datetime() para combinar varias columnas numéricas en una columna de fecha. Por ejemplo, si tiene columnas numéricas onset_day, onset_month y onset_year en el dataframe linelist:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#excel-dates",
    "href": "new_pages/dates.es.html#excel-dates",
    "title": "9  Trabajando con Fechas",
    "section": "9.4 Fechas en Excel",
    "text": "9.4 Fechas en Excel\nEn el fondo, la mayoría de los programas informáticos almacenan las fechas como números. R almacena las fechas desde un origen del 1 de enero de 1970. Así, si ejecutas as.numeric(as.Date(\"1970-01-01\")) obtendrás 0.\nMicrosoft Excel almacena las fechas con un origen dependiendo del sistema operativo, del 30 de diciembre de 1899 (Windows) o del 1 de enero de 1904 (Mac). Consulta esta guía de Microsoft para obtener más información.\nLas fechas de Excel suelen importarse a R como estos valores numéricos en lugar de como caracteres. Si los datos que has importado de Excel muestran las fechas como números o caracteres como “41369”… utiliza as.Date() (o la función as_date() de lubridate) para convertirlas, pero en lugar de suministrar un “formato” como el anterior, suministra la fecha de origen de Excel al argumento origin = .\nEsto no funcionará si la fecha de Excel se almacena en R como de tipo carácter, ¡así que asegúrate de que el número es de tipo numérico!.\nNOTA: Debes proporcionar la fecha de origen en el formato de fecha por defecto de R (“AAAA-MM-DD”).\n\n# Un ejemplo de proporcionar la \"fecha de origen\" de Excel al convertir fechas numéricas de Excel\ndata_cleaned &lt;- data %&gt;% \n  mutate(date_onset = as.numeric(date_onset)) %&gt;%   # asegura que la clase es numérica\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convierte a fecha usando el origen de Excel",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#messy-dates",
    "href": "new_pages/dates.es.html#messy-dates",
    "title": "9  Trabajando con Fechas",
    "section": "9.5 Fechas desordenadas",
    "text": "9.5 Fechas desordenadas\nLa función parse_date() del paquete parsedate intenta leer una columna de fecha “desordenada” que contiene fechas en muchos formatos diferentes y convertir las fechas a un formato estándar. Puedes leer más en línea sobre guess_dates().\nPor ejemplo parse_date() vería un vector de las siguientes fechas de caracteres “03 Ene 2018”, “07/03/1982”, y “08/20/85” y las convertiría al tipo Date como 2018-01-03, 1982-03-07, y 1985-08-20.\n\nparsedate::parse_date(c(\"03 Jany 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))\n\n[1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n\n\n\n# Un ejemplo usando guess_dates en la columna date_onset\nlinelist &lt;- linelist %&gt;%                 # el conjunto de datos se llama linelist\n  mutate(\n    date_onset = parsedate::parse_date(date_onset))  # parse_date() del paquete \"parsedate\"",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#working-with-date-time-class",
    "href": "new_pages/dates.es.html#working-with-date-time-class",
    "title": "9  Trabajando con Fechas",
    "section": "9.6 Trabajar con el tipo fecha-hora",
    "text": "9.6 Trabajar con el tipo fecha-hora\nComo se mencionó anteriormente, R también soporta un tipo datetime - una columna que contiene información de fecha y hora. Al igual que con el tipo Date, a menudo es necesario convertirlas de objetos character a objetos datetime.\n\nConvertir fechas con horas\nUn objeto datetime estándar se formatea con la fecha en primer lugar, seguida de un componente de tiempo - por ejemplo, 01 Ene 2020, 16:30. Al igual que con las fechas, hay muchas maneras de formatearlas, y hay numerosos niveles de precisión (horas, minutos, segundos) que se pueden suministrar.\nPor suerte, también existen funciones de ayuda de lubridate para ayudar a convertir estas cadenas en objetos datetime. Estas funciones son extensiones de las funciones de ayuda a la fecha, con _h (sólo se suministran las horas), _hm (se suministran las horas y los minutos), o _hms (se suministran las horas, los minutos y los segundos) añadidas al final (por ejemplo, dmy_hms()). Se pueden utilizar como se indica:\nConvertir datetime con sólo horas a objeto datetime\n\nymd_h(\"2020-01-01 16hrs\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\nymd_h(\"2020-01-01 4PM\")\n\n[1] \"2020-01-01 16:00:00 UTC\"\n\n\nConvertir datetime con horas y minutos a objeto datetime\n\ndmy_hm(\"01 January 2020 16:20\")\n\n[1] \"2020-01-01 16:20:00 UTC\"\n\n\nConvertir datetime con horas, minutos y segundos a objeto datetime\n\nmdy_hms(\"01 January 2020, 16:20:40\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nPuedes indicar la zona horaria, pero se ignora. Consulta la sección más adelante en esta página sobre las zonas horarias.\n\nmdy_hms(\"01 January 2020, 16:20:40 PST\")\n\n[1] \"2020-01-20 16:20:40 UTC\"\n\n\nCuando se trabaja con un dataframe, las columnas de fecha y hora pueden combinarse para crear una columna de fecha y hora utilizando str_glue()del paquete stringr y una función apropiada de lubridate. Consulta la página sobre Caracteres y cadenas para obtener detalles sobre stringr.\nEn este ejemplo, el dataframe linelist tiene una columna con formato “horas:minutos”. Para convertirla en una fecha, hay que seguir algunos pasos:\n\nCrea una columna de tiempo de admisión “limpia” con los valores faltantes rellenados con la mediana de la columna. Hacemos esto porque lubridate no opera con valores faltantes. Combínala con la columna date_hospitalisation y utiliza la función ymd_hm() para convertirla.\n\n\n# paquetes\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission es una columna en horas:minutos\nlinelist &lt;- linelist %&gt;%\n  \n  ## cuando no se da la hora de admisión, asigna la mediana del tiempo de admisión\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # si falta el hora\n      median(time_admission),        # asignar la mediana\n      time_admission                 # si no falta la hora mantenerla \n  ) %&gt;%\n  \n    # utilizar str_glue() para combinar las columnas de fecha y hora para crear una columna de caracteres\n    # y luego usar ymd_hm() para convertirla en fecha-hora\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %&gt;% \n      ymd_hm()\n  )\n\n\n\nConvertir sólo horas\nSi tus datos contienen sólo un carácter de tiempo (horas y minutos), puedes convertirlos y manipularlos como tiempos utilizando strptime() desde R base. Por ejemplo, para obtener la diferencia entre dos de estos horas:\n\n# hora cruda de tipo carácter\ntime1 &lt;- \"13:45\" \ntime2 &lt;- \"15:20\"\n\n# Horas convertidas a una clase fecha\ntime1_clean &lt;- strptime(time1, format = \"%H:%M\")\ntime2_clean &lt;- strptime(time2, format = \"%H:%M\")\n\n# La diferencia es de tipo \"difftime\" por defecto, aquí convertida a horas numéricas \nas.numeric(time2_clean - time1_clean)   # diferencia en horas\n\n[1] 1.583333\n\n\nSin embargo, ten en cuenta que si no se proporciona un valor de fecha, se asume que la fecha es hoy. Para combinar una cadena de fecha y una cadena de hora, observa cómo se usa stringr en la sección anterior. Puedes leer más sobre strptime() aquí.\nPara convertir números de un solo dígito a dos dígitos (por ejemplo, para “rellenar” las horas o los minutos con ceros a la izquierda para conseguir 2 dígitos), consulta la sección “Longitud de relleno” de la página Caracteres y cadenas.\n\n\nExtraer fracciones de hora\nPuedes extraer elementos de una hora con hour(), minute(), o second() de lubridate.\nHe aquí un ejemplo de extracción de la hora y posterior clasificación como parte del día. Comenzamos con la columna time_admission, que es de tipo Carácter en formato “HH:MM”. En primer lugar, se utiliza strptime() como se ha descrito anteriormente para convertir los caracteres en tipo datetime. A continuación, se extrae la hora con hour(), devolviendo un número del 0 al 24. Por último, se crea una columna time_period utilizando la lógica con case_when() para clasificar las filas en Mañana/Tarde/Anochecer/Noche en función de su hora de entrada.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %&gt;%\n  mutate(time_period = case_when(\n    hour_admit &gt; 06 & hour_admit &lt; 12 ~ \"Morning\",\n    hour_admit &gt;= 12 & hour_admit &lt; 17 ~ \"Afternoon\",\n    hour_admit &gt;= 17 & hour_admit &lt; 21 ~ \"Evening\",\n    hour_admit &gt;=21 | hour_admit &lt;= 6 ~ \"Night\"))\n\nPara saber más sobre case_when(), consulta la página sobre Limpieza de datos y funciones básicas.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#working-with-dates-1",
    "href": "new_pages/dates.es.html#working-with-dates-1",
    "title": "9  Trabajando con Fechas",
    "section": "9.7 Trabajar con fechas",
    "text": "9.7 Trabajar con fechas\nlubridate también puede utilizarse para otras funciones, como la extracción de aspectos de una fecha/hora, realización de cálculos aritméticos de fechas o cálculo de intervalos de fechas\nAquí definimos una fecha que se utilizará para los ejemplos:\n\n# crear un objeto de clase Date\nexample_date &lt;- ymd(\"2020-03-01\")\n\n\nExtraer los componentes de la fecha\nPuedes extraer aspectos comunes como el mes, el día, el día de la semana:\n\nmonth(example_date)  # número del mes\n\n[1] 3\n\nday(example_date)    # día (número) del mes\n\n[1] 1\n\nwday(example_date)   # número de día de la semana (1-7)\n\n[1] 1\n\n\nTambién puede extraer componentes de tiempo de un objeto o columna datetime. Esto puede ser útil si quieres ver la distribución de los tiempos de admisión.\n\nexample_datetime &lt;- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # extraer la hora\nminute(example_datetime)   # extraer el minuto\nsecond(example_datetime)   # extraer el segundo\n\nHay varias opciones para recuperar las semanas. Consulta la sección sobre semanas epidemiológicas más abajo.\nTen en cuenta que si deseas mostrar una fecha de una forma determinada (por ejemplo, “enero de 2020” o “jueves 20 de marzo” o “semana 20 de 1977”) puedes hacerlo de forma más flexible, tal y como se describe en la sección sobre Visualización de fechas.\n\n\nFecha matemática\nPuedes añadir ciertos números de días o semanas utilizando su respectiva función de lubridate.\n\n# añadir 3 días a esta fecha\nexample_date + days(3)\n\n[1] \"2020-03-04\"\n\n# añade 7 semanas y resta dos días a esta fecha\nexample_date + weeks(7) - days(2)\n\n[1] \"2020-04-17\"\n\n\n\n\nIntervalos de fechas\nLa diferencia entre las fechas se puede calcular mediante:\n\nAsegúrate que ambas fechas son del mismo tipo\nUtiliza la resta para devolver la diferencia “difftime” entre las dos fechas\nSi es necesario, convierte el resultado en tipo numéricoa para realizar los cálculos matemáticos posteriores\n\nA continuación se calcula y muestra el intervalo entre dos fechas. Se pueden encontrar intervalos utilizando el símbolo de resta “menos” en los valores que son de tipo Fecha. Ten en cuenta, sin embargo, que el tipo del valor devuelto es “difftime”, como se muestra a continuación, y debe ser convertido a numérico.\n\n# encontrar el intervalo entre esta fecha y el 20 de febrero de 2020 \noutput &lt;- example_date - ymd(\"2020-02-20\")\noutput    # imprimir\n\nTime difference of 10 days\n\nclass(output)\n\n[1] \"difftime\"\n\n\nPara realizar operaciones posteriores sobre un “difftime”, conviértelo en numérico con as.numeric().\nTodo esto puede unirse para trabajar con datos, por ejemplo:\n\npacman::p_load(lubridate, tidyverse)   # load packages\n\nlinelist &lt;- linelist %&gt;%\n  \n  # convertir la fecha de inicio de los objetos carácter a fecha especificando el formato dmy\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %&gt;%\n  \n  # filtrar todos los casos sin inicio en marzo\n  filter(month(date_onset) == 3) %&gt;%\n    \n  # encontrar la diferencia de días entre el inicio y la hospitalización\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n\nEn un contexto de dataframe, si falta alguna de las fechas anteriores, la operación fallará para esa fila. El resultado será un NA en lugar de un valor numérico. Cuando utilices esta columna para los cálculos, asegúrate de establecer el argumento na.rm = en TRUE. Por ejemplo:\n\n# Calcular la mediana del número de días hasta la hospitalización para todos los casos de los que se dispone de datos\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#date-display",
    "href": "new_pages/dates.es.html#date-display",
    "title": "9  Trabajando con Fechas",
    "section": "9.8 Visualización de fechas",
    "text": "9.8 Visualización de fechas\nUna vez que las fechas son del tipo correcto, a menudo se desea mostrarlas de forma diferente, por ejemplo para que se muestren como “lunes 05 de enero” en lugar de “2018-01-05”. También puedes querer ajustar la visualización para agrupar las filas por los elementos de fecha mostrados, por ejemplo, para agrupar por mes-año.\n\nformat()\nAjusta la visualización de la fecha con la función format() de R base. Esta función acepta una cadena de caracteres (entre comillas) que especifica el formato de salida deseado en las abreviaturas strptime “%” (la misma sintaxis que se utiliza en as.Date()). A continuación se muestran las abreviaturas más comunes.\nNota: el uso de format() convertirá los valores al tipo Character, por lo que generalmente se utiliza hacia el final de un análisis o sólo para fines de visualización. Puedes ver la lista completa ejecutando ?strptime.\n%d = Número del día del mes (5, 17, 28, etc.) %j = Número del día del año (día juliano 001-366) %a = Día de la semana abreviado (lunes, martes, miércoles, etc.) %A = Día de la semana completo (lunes, martes, etc.) %w = Número del día de la semana (0-6, el domingo es 0) %u = Número del día de la semana (1-7, el lunes es 1) %W = Número de la semana (00-53, el lunes es el comienzo de la semana) %U = Número de la semana (01-53, el domingo es el comienzo de la semana) %m = Número del mes (p. ej. 01, 02, 03, 04) %b = Mes abreviado (enero, febrero, etc.) %B = Mes completo (enero, febrero, etc.) %y = Año de 2 dígitos (p. ej. 89) %Y = Año de 4 dígitos (p. ej. 1989) %h = Horas (reloj de 24 horas) %m = Minutos %s = Segundos %z = Desplazamiento respecto a GMT %Z = Huso horario (carácter)\nUn ejemplo de formato de la fecha de hoy:\n\n# # fecha de hoy, con formato\nformat(Sys.Date(), format = \"%d %B %Y\")\n\n[1] \"10 May 2024\"\n\n# forma sencilla de obtener la fecha y hora completas (formato por defecto)\ndate()\n\n[1] \"Fri May 10 04:57:19 2024\"\n\n# formato combinado de fecha, hora y zona horaria usando la función str_glue() \nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")\n\nFriday, May 10 2024, +0000  UTC, 04:57:19\n\n# Utilizar format para mostrar las semanas\nformat(Sys.Date(), \"%Y Week %W\")\n\n[1] \"2024 Week 19\"\n\n\nTen en cuenta que si utilizas str_glue(), dentro de las comillas dobles ” sólo debes utilizar comillas simples (como arriba).\n\n\nMes-Año\nPara convertir una columna de fecha al formato mes-año, te sugerimos que utilice la función as.yearmon() del paquete zoo. Esto convierte la fecha al tipo “yearmon” y mantiene el orden correcto. Por el contrario, usar format(columna, \"%Y %B\") convertirá al tipo Carácter y ordenará los valores alfabéticamente (incorrectamente).\nA continuación, se crea una nueva columna yearmonth a partir de la columna date_onset, utilizando la función as.yearmon()`. La ordenación por defecto (correcta) de los valores resultantes se muestra en la tabla.\n\n# crear una columna nueva\ntest_zoo &lt;- linelist %&gt;% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# imprimir tabla\ntable(test_zoo$yearmon)\n\n\nApr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 \n       7       64      100      226      528     1070     1112      763 \nDec 2014 Jan 2015 Feb 2015 Mar 2015 Apr 2015 \n     562      431      306      277      186 \n\n\nPor el contrario, se puede ver cómo sólo utilizando format() se consigue el formato de visualización deseado, pero no el orden correcto.\n\n# crear una columna nueva\ntest_format &lt;- linelist %&gt;% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# imprimir tabla\ntable(test_format$yearmon)\n\n\nApr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 \n       7      186      528      562      306      431      226      100 \nMar 2015 May 2014 Nov 2014 Oct 2014 Sep 2014 \n     277       64      763     1112     1070 \n\n\nNota: si estás trabajando con ggplot() y quieres ajustar sólo cómo se muestran las fechas, puede ser suficiente proporcionar un formato strptime al argumento date_labels = en scale_x_date() - puedes utilizar \"%b %Y\" o \"%Y %b\". Consulta la página de consejos de ggplot.\nzoo también ofrece la función as.yearqtr(), y puedes usar scale_x_yearmon() cuando uses ggplot().",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#dates_epi_wks",
    "href": "new_pages/dates.es.html#dates_epi_wks",
    "title": "9  Trabajando con Fechas",
    "section": "9.9 Semanas epidemiológicas",
    "text": "9.9 Semanas epidemiológicas\n\nlubridate\nConsulta la página sobre Agrupar datos para ver ejemplos más extensos de agrupación de datos por fecha. A continuación describimos brevemente la agrupación de datos por semanas.\nGeneralmente recomendamos utilizar la función floor_date() de lubridate, con el argumento unit = \"week\". Esto redondea la fecha hacia abajo al “inicio” de la semana, como se define por el argumento week_start =. El inicio de la semana por defecto es el 1 (para los lunes), pero se puede especificar cualquier día de la semana como inicio (por ejemplo, el 7 para los domingos). floor_date() es versátil y se puede utilizar para redondear hacia abajo a otras unidades de tiempo estableciendo unit = “second”, “minute”, “hour”, “day”, “month”, o “year”.\nEl valor devuelto es la fecha de inicio de la semana, en tipo Date. El tipo Date es útil a la hora de representar los datos, ya que serán fácilmente reconocidos y ordenados correctamente por ggplot().\nSi sólo tienes interés en ajustar las fechas para que se muestren por semanas en un gráfico, consulta la sección de esta página sobre Visualización de fechas. Por ejemplo, al representar una epicurva puedes formatear la visualización de la fecha proporcionando la nomenclatura strptime “%” deseada. Por ejemplo, utiliza “%Y-%W” o “%Y-%U” para devolver el año y el número de semana (dado el comienzo de la semana del lunes o del domingo, respectivamente).\n\n\nRecuentos semanales\nConsulta la página sobre Agrupar datos para obtener una explicación detallada de la agrupación de datos con count(), group_by(), and summarise(). A continuación se muestra un breve ejemplo.\n\nCrear una nueva columna “semana” con mutate(), utilizando floor_date() con unit = \"week\"\nObtener el recuento de filas (casos) por semana con count(); filtra los casos a los que les falte la fecha\nTermina con complete() de tidyr para asegurarte que todas las semanas aparecen en los datos - incluso las que no tienen filas/casos. Por defecto, los valores de recuento para cualquier fila “nueva” son NA, pero puedes hacerlos 0 con el argumento fill =, que espera una lista con nombre (abajo, n es el nombre de la columna de recuentos).\n\n\n# Hacer un conjunto de datos agregados con los recuentos semanales de casos\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%             # eliminar los casos sin fecha de inicio\n  mutate(weekly_cases = floor_date(   # crear columna nueva, semana de inicio\n    date_onset,\n    unit = \"week\")) %&gt;%            \n  count(weekly_cases) %&gt;%           # agrupar datos por semana y contar filas por grupo (crea columna 'n')\n  tidyr::complete(                  # asegúrar que todas las semanas están presentes, incluso aquellas en las que no se ha notificado ningún caso\n    weekly_cases = seq.Date(          # redefinir la columna \"weekly_cases\" como una secuencia completa,\n      from = min(weekly_cases),       # desde la fecha mínima\n      to = max(weekly_cases),         # hasta la fecha máxima\n      by = \"week\"),                   # por semanas\n    fill = list(n = 0))             # rellenar los NA de la columna n con 0\n\nAquí están las primeras filas del dataframe resultante:\n\n\n\n\n\n\n\n\nAlternativas a Epiweek\nTen en cuenta que lubridate también tiene las funciones week(), epiweek(), e isoweek(), cada una de las cuales tiene fechas de inicio ligeramente diferentes y otros matices. Sin embargo, en términos generales, floor_date() debería ser todo lo que necesitas. Puedes leer más detalles de estas funciones introduciendo ?week en la consola o leyendo la documentación aquí.\nPuedes usar del paquete aweek para establecer semanas epidemiológicas. Puedes leer más sobre él en el sitio web de RECON. Tiene las funciones date2week() y week2date() en las que se puede establecer el día de inicio de la semana con week_start = \"Monday\". Este paquete es el más fácil si se desea obtener resultados del tipo “week” (por ejemplo, “2020-W12”). Otra ventaja de aweek es que cuando date2week() se aplica a una columna de fecha, la columna devuelta (formato de semana) es automáticamente del tipo Factor e incluye niveles para todas las semanas en el lapso de tiempo (esto evita el paso extra de complete() descrito anteriormente). Sin embargo, aweek no tiene la funcionalidad de redondear fechas a otras unidades de tiempo como meses, años, etc.\nOtra alternativa para las series temporales que también funciona bien para mostrar un formato de “semana” (“2020 W12”) es yearweek() del paquete tsibble, como se demuestra en la página sobre series temporales y detección de brotes.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#converting-datestime-zones",
    "href": "new_pages/dates.es.html#converting-datestime-zones",
    "title": "9  Trabajando con Fechas",
    "section": "9.10 Conversión de fechas/zonas horarias",
    "text": "9.10 Conversión de fechas/zonas horarias\nCuando los datos están presentes en diferentes husos horarios, a menudo puede ser importante normalizar estos datos en un huso horario unificado. Esto puede suponer un reto adicional, ya que el componente de zona horaria de los datos debe codificarse manualmente en la mayoría de los casos.\nEn R, cada objeto datetime tiene un componente de zona horaria. Por defecto, todos los objetos datetime llevarán la zona horaria local para el ordenador que se está utilizando - esto es generalmente específico para una ubicación en lugar de una zona horaria, ya que las zonas horarias a menudo cambian en los lugares debido al horario de verano. No es posible compensar con precisión las zonas horarias sin un componente de tiempo de una fecha, ya que el evento que representa una columna de fecha no puede ser atribuido a un tiempo específico, y por lo tanto los cambios de tiempo medidos en horas no pueden ser razonablemente contabilizados.\nPara tratar las zonas horarias, hay una serie de funciones de ayuda en lubridate que pueden utilizarse para cambiar la zona horaria de un objeto datetime de la zona horaria local a una zona horaria diferente. Las zonas horarias se establecen atribuyendo una zona horaria válida de la base de datos tz al objeto datetime. Aquí se puede encontrar una lista de éstas - si la ubicación que se está utilizando en los datos no está en esta lista, las grandes ciudades cercanas en la zona horaria están disponibles y sirven para el mismo propósito.\n\n# asignar la hora actual a una columna\ntime_now &lt;- Sys.time()\ntime_now\n\n[1] \"2024-05-10 04:57:20 CEST\"\n\n# usa with_tz() para asignar una nueva zona horaria a la columna, mientras CAMBIA la hora del reloj\ntime_london_real &lt;- with_tz(time_now, \"Europe/London\")\n\n# use force_tz() para asignar una nueva zona horaria a la columna, y MANTIENE la hora del reloj\ntime_london_local &lt;- force_tz(time_now, \"Europe/London\")\n\n# siempre y cuando el equipo que se utilizó para ejecutar este código NO TIENE la hora de Londres,\n# habrá una diferencia en los tiempos \n# (el número de horas de diferencia entre la zona horaria del ordenador y Londres)\ntime_london_real - time_london_local\n\nTime difference of -1 hours\n\n\nEsto puede parecer muy abstracto, y a menudo no es necesario si el usuario no está trabajando en distintas zonas horarias.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#lagging-and-leading-calculations",
    "href": "new_pages/dates.es.html#lagging-and-leading-calculations",
    "title": "9  Trabajando con Fechas",
    "section": "9.11 Cálculos de retardo y de avance",
    "text": "9.11 Cálculos de retardo y de avance\nlead() y lag() son funciones del paquete dplyr que ayudan a encontrar los valores anteriores (retardados) o posteriores (principales) en un vector, normalmente un vector numérico o de fechas. Esto es útil cuando se hacen cálculos de cambio/diferencia entre unidades de tiempo.`\nSupongamos que se quiere calcular la diferencia de casos entre una semana actual y la anterior. Los datos se proporcionan inicialmente en recuentos semanales, como se muestra a continuación.\n\n\n\n\n\n\nAl utilizar lag() o lead(), el orden de las filas en el dataframe es muy importante. - presta atención a si tus fechas/números son ascendentes o descendentes\nEn primer lugar, crea una nueva columna que contenga el valor de la semana anterior (retardada).\n\nControla el número de unidades hacia atrás/adelante con n = (debe ser un entero no negativo)\nUtiliza default = para definir el valor colocado en las filas no existentes (por ejemplo, la primera fila para la que no hay un valor retardado). Por defecto es NA.\nUtiliza order_by = TRUE si tus filas no están ordenadas por su columna de referencia\n\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\n\n\n\n\n\n\n\nA continuación, crea una nueva columna que sea la diferencia entre las dos columnas de los casos:\n\ncounts &lt;- counts %&gt;% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)\n\n\n\n\n\n\n\nPuedes leer más sobre lead() y lag() en esta documentación aquí o introduciendo ?lag en tu consola.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/dates.es.html#resources-2",
    "href": "new_pages/dates.es.html#resources-2",
    "title": "9  Trabajando con Fechas",
    "section": "9.12 Recursos",
    "text": "9.12 Recursos\nPágina de lubridate** tidyverse\nPágina de lubridate RStudio cheatsheet\nR for Data Science en español sobre [fechas y horas]https://es.r4ds.hadley.nz/fechas-y-horas.html\nTutorial en línea\nFormatos de fecha]",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Trabajando con Fechas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html",
    "href": "new_pages/characters_strings.es.html",
    "title": "10  Caracteres y cadenas",
    "section": "",
    "text": "10.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#preparation-1",
    "href": "new_pages/characters_strings.es.html#preparation-1",
    "title": "10  Caracteres y cadenas",
    "section": "",
    "text": "Cargar paquetes\nInstala o carga el paquete stringr y otros paquetes de tidyverse.\n\n# install/load packages\npacman::p_load(\n  stringr,    # muchas funciones para el manejo de cadenas\n  tidyverse,  # para manipulación opcional de datos\n  tools)      # alternativa para convertir a mayúsculas y minúsculas\n\n\n\nImportar datos\nImportar datos\nEn esta página haremos referencia de vez en cuando a la lista limpia de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - consulta la página de importación y exportación para más detalles).\n\n# importar casos de linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#unite-split-and-arrange",
    "href": "new_pages/characters_strings.es.html#unite-split-and-arrange",
    "title": "10  Caracteres y cadenas",
    "section": "10.2 Unir, dividir y ordenar",
    "text": "10.2 Unir, dividir y ordenar\nEsta sección abarca:\n\nUso de str_c(), str_glue(), y unite() para combinar cadenas\nUso de str_order() para ordenar las cadenas\nUso de str_split() y separate() para dividir cadenas\n\n\n\nCombinar cadenas\nPara combinar o concatenar varias cadenas en una sola, sugerimos utilizar str_c de stringr. Si tienes valores de caracteres distintos para combinar, simplemente proporciónalos como argumentos únicos, separados por comas.\n\nstr_c(\"String1\", \"String2\", \"String3\")\n\n[1] \"String1String2String3\"\n\n\nEl argumento sep = inserta un valor de carácter entre cada uno de los argumentos proporcionados (por ejemplo, insertando una coma, un espacio o una nueva línea \"\\n\")\n\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")\n\n[1] \"String1, String2, String3\"\n\n\nEl argumento collapse = es relevante si estás introduciendo múltiples vectores como argumentos a str_c(). Se utiliza para separar los elementos de lo que sería un vector de salida, de forma que el vector de salida sólo tenga un elemento de carácter largo.\nEl ejemplo siguiente muestra la combinación de dos vectores en uno (nombres y apellidos). Otro ejemplo similar podría ser el de las jurisdicciones y su número de casos. En este ejemplo:\n\nEl valor sep = aparece entre cada nombre y apellido\nEl valor de collapse = aparece entre cada persona\n\n\nfirst_names &lt;- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  &lt;- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep aparece entre las respectivas cadenas de entrada, mientras que collapse aparece entre los elementos producidos\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")\n\n[1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n\n\nNota: Dependiendo del contexto de visualización deseado, al imprimir una cadena combinada de este tipo con nuevas líneas, puede ser necesario envolver toda la frase en cat() para que las nuevas líneas se impriman correctamente:\n\n# Para que las nuevas líneas se impriman correctamente, puede ser necesario envolver la frase en cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))\n\nabdul hussein;\nfahruk akinleye;\njanice okeke\n\n\n\n\n\nCadenas dinámicas\nUtiliza str_glue() para insertar código R dinámico en una cadena. Se trata de una función muy útil para crear títulos o pies de gráfico dinámicos, como se muestra a continuación.\n\nTodo el contenido va entre comillas dobles str_glue(\"\")\nCualquier código dinámico o referencias a valores predefinidos se colocan entre llaves {} dentro de las comillas dobles. Puede haber muchas llaves en el mismo comando str_glue().\nPara usar las comillas de caracteres ’’ dentro de la función, utiliza comillas simples dentro de las comillas dobles que las rodean (por ejemplo, al proporcionar el formato de la fecha - véase el ejemplo siguiente)\nConsejo: Puedes utilizar \\n para forzar una nueva línea\nConsejo: Utiliza format() para ajustar la visualización de la fecha, y utiliza Sys.Date() para mostrar la fecha actual\n\nUn ejemplo sencillo, de un título de gráfico dinámico:\n\nstr_glue(\"Data include {nrow(linelist)} cases and are current to {format(Sys.Date(), '%d %b %Y')}.\")\n\nData include 5888 cases and are current to 10 May 2024.\n\n\nUn formato alternativo es utilizar marcadores de posición dentro de los paréntesis y definir el código en argumentos separados al final de la función str_glue(), como se indica a continuación. Esto puede mejorar la legibilidad del código si el texto es largo.\n\nstr_glue(\"Linelist as of {current_date}.\\nLast case hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %&gt;% filter(is.na(date_onset)))\n         )\n\nLinelist as of 10 May 2024.\nLast case hospitalized on 30 Apr 2015.\n256 cases are missing date of onset and not shown\n\n\nExtraer de un dataframe\nA veces, es útil extraer datos de un dataframe y pegarlos secuencialmente. A continuación se muestra un ejemplo de dataframe. Lo utilizaremos para hacer una declaración resumida sobre las jurisdicciones y los recuentos de casos nuevos y totales.\n\n# crear data frame de casos\ncase_table &lt;- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\n\n\n\n\n\n\n\nUtiliza str_glue_data(), que está hecho especialmente para obtener datos de las filas del dataframe:\n\ncase_table %&gt;% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")\n\nZone 1: 3 (40 total cases)\nZone 2: 0 (4 total cases)\nZone 3: 7 (25 total cases)\nZone 4: 0 (10 total cases)\nZone 5: 15 (103 total cases)\n\n\nCombinar cadenas a través de las filas\nSi estás intentando “enrollar” valores en una columna del dataframe, por ejemplo, combinar valores de varias filas en una sola fila pegándolos con un separador, consulta la sección “combinación de valores” de la página de De-duplicación.\nDataframe a una línea\nPuedes hacer que la declaración aparezca en una línea utilizando str_c() (especificando el dataframe y los nombres de las columnas), y proporcionando los argumentos sep = y collapse =.\n\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")\n\n[1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\nPodría añadir el texto “Nuevos casos:” fijado al principio de la frase envolviéndolo con un str_c() separado (si “Nuevos casos:” estuviera dentro del str_c() original aparecería varias veces).\n\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))\n\n[1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\n\n\n\n\nUnir columnas\nDentro de un dataframe, la unión de valores de caracteres de varias columnas puede lograrse con unite() de tidyr. Esto es lo contrario de separate().\nIndica el nombre de la nueva columna (que contendrá los valores unidos) y, a continuación, indica los nombres de las columnas que deseas unir.\n\nPor defecto, el separador utilizado en la columna unida es el guión bajo _, pero puede cambiarse con el argumento sep =.\nremove = elimina las columnas del dataframe que queremos unir (TRUE por defecto)\nna.rm = elimina los valores perdidos (NA) al realizar la unión (FALSE por defecto)\n\nA continuación, definimos un mini-dataframe con el que hacer una demostración:\n\ndf &lt;- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # paciente 1\n                \"chills, aches, pains\",        # paciente 2 \n                \"fever\",                       # paciente 3\n                \"vomiting, diarrhoea\",         # paciente 4\n                \"bleeding from gums, fever\",   # paciente 5\n                \"rapid pulse, headache\"),      # paciente 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\n\n\ndf_split &lt;- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")\n\nWarning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\n\n\nEste es el dataframe de ejemplo:\n\n\n\n\n\n\nA continuación, unimos las tres columnas de síntomas:\n\ndf_split %&gt;% \n  unite(\n    col = \"all_symptoms\",         # nombre de la nueva columna unida\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # columnas a unir\n    sep = \", \",                   # separador a utilizar en la columna unida\n    remove = TRUE,                # si es TRUE, elimina las columnas de entrada del data frame\n    na.rm = TRUE                  # si es TRUE, los valores perdidos se eliminan antes de unirlos\n  )\n\n  case_ID                all_symptoms outcome\n1       1     jaundice, fever, chills Recover\n2       2        chills, aches, pains   Death\n3       3                       fever   Death\n4       4         vomiting, diarrhoea Recover\n5       5 bleeding, from, gums, fever Recover\n6       6      rapid, pulse, headache Recover\n\n\n\n\n\nDividir\nPara dividir una cadena basada en un patrón, utiliza str_split(). Esta función evalúa las cadenas y devuelve una lista de vectores de caracteres formada por los valores recién divididos.\nEl ejemplo que sigue evalúa una cadena y la divide en tres. Por defecto, devuelve un objeto de tipo list con un elemento (un vector de caracteres) por cada cadena proporcionada inicialmente. Si simplify = TRUE devuelve una matriz de caracteres.\nEn este ejemplo, se proporciona una cadena y la función devuelve una lista con un elemento: un vector de caracteres con tres valores.\n\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n\nSi se guarda la salida, puedes acceder al enésimo valor dividido con la sintaxis de corchetes. Para acceder a un valor específico puedes utilizar una sintaxis como esta: the_returned_object[[1]][2], que accedería al segundo valor de la primera cadena evaluada (“fever”). Consulta la página de fundamentos de R para obtener más detalles sobre el acceso a los elementos.\n\npt1_symptoms &lt;- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extracts 2nd value from 1st (and only) element of the list\n\n[1] \" fever\"\n\n\nSi se proporcionan varias cadenas mediante str_split(), habrá más de un elemento en la lista devuelta.\n\nsymptoms &lt;- c(\"jaundice, fever, chills\",     # paciente 1\n              \"chills, aches, pains\",        # paciente 2 \n              \"fever\",                       # paciente 3\n              \"vomiting, diarrhoea\",         # paciente 4\n              \"bleeding from gums, fever\",   # paciente 5\n              \"rapid pulse, headache\")       # paciente 6\n\nstr_split(symptoms, \",\")                     # divide los síntomas de cada paciente\n\n[[1]]\n[1] \"jaundice\" \" fever\"   \" chills\" \n\n[[2]]\n[1] \"chills\" \" aches\" \" pains\"\n\n[[3]]\n[1] \"fever\"\n\n[[4]]\n[1] \"vomiting\"   \" diarrhoea\"\n\n[[5]]\n[1] \"bleeding from gums\" \" fever\"            \n\n[[6]]\n[1] \"rapid pulse\" \" headache\"  \n\n\nPara devolver una “matriz de caracteres” en su lugar, que puede ser útil si se crean columnas de dataframes, establece el argumento simplify = TRUE como se muestra a continuación:\n\nstr_split(symptoms, \",\", simplify = TRUE)\n\n     [,1]                 [,2]         [,3]     \n[1,] \"jaundice\"           \" fever\"     \" chills\"\n[2,] \"chills\"             \" aches\"     \" pains\" \n[3,] \"fever\"              \"\"           \"\"       \n[4,] \"vomiting\"           \" diarrhoea\" \"\"       \n[5,] \"bleeding from gums\" \" fever\"     \"\"       \n[6,] \"rapid pulse\"        \" headache\"  \"\"       \n\n\nTambién puedes ajustar el número de divisiones a crear con el argumento n =. Por ejemplo, esto restringe el número de divisiones a 2. De este modo, cualquier otra coma permanece dentro del segundo valor.\n\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)\n\n     [,1]                 [,2]            \n[1,] \"jaundice\"           \" fever, chills\"\n[2,] \"chills\"             \" aches, pains\" \n[3,] \"fever\"              \"\"              \n[4,] \"vomiting\"           \" diarrhoea\"    \n[5,] \"bleeding from gums\" \" fever\"        \n[6,] \"rapid pulse\"        \" headache\"     \n\n\nNota - los mismos resultados se pueden conseguir con str_split_fixed(), en la que no se da el argumento simplify, sino que se debe designar el número de columnas (n).\n\nstr_split_fixed(symptoms, \",\", n = 2)\n\n\n\nDividir columnas\nSi estás intentando dividir una columna de un dataframe, es mejor utilizar la función separate() de dplyr. Se utiliza para dividir una columna de caracteres en otras columnas.\nDigamos que tenemos un dataframe simple df (definido y unido en la sección de unir columnas) que contiene una columna case_ID, una columna de caracteres con muchos síntomas y una columna de resultados. Nuestro objetivo es separar la columna de symptoms en varias columnas, cada una de las cuales contiene un síntoma.\n\n\n\n\n\n\nAsumiendo que los datos son enlazados con pipe en separate(), primero proporciona la columna a separar. A continuación, proporcione en = como un vector c() que contiene los nombres de las nuevas columnas, como se muestra a continuación.\n\nsep = el separador, puede ser un carácter, o un número (interpretado como la posición del carácter a dividir)\nremove = FALSE por defecto, elimina la columna de entrada\nconvert = FALSE por defecto, hará que las cadenas “NA”s se conviertan en NA\nextra = controla lo que sucede si hay más valores creados por la separación que nuevas columnas nombradas.\nextra = \"warn\" significa que verá una advertencia, pero quitará los valores en exceso (el valor por defecto)\nextra = \"drop\" significa que los valores sobrantes se eliminarán sin previo aviso\nextra = \"merge\" sólo dividirá hasta el número de nuevas columnas listadas en into - esta configuración preservará todos tus datos\n\nA continuación se muestra un ejemplo con extra = \"merge\" - no se pierde ningún dato. Se definen dos nuevas columnas pero cualquier tercer síntoma se deja en la segunda columna nueva:\n\n# terceros síntomas combinados en la segunda columna nueva\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1          sym_2 outcome\n1       1           jaundice  fever, chills Recover\n2       2             chills   aches, pains   Death\n3       3              fever           &lt;NA&gt;   Death\n4       4           vomiting      diarrhoea Recover\n5       5 bleeding from gums          fever Recover\n6       6        rapid pulse       headache Recover\n\n\nCuando se utiliza el extra = \"drop\" por defecto a continuación, se da una advertencia pero se pierden los terceros síntomas:\n\n# terceros síntomas se pierden\ndf %&gt;% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")\n\nWarning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].\n\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].\n\n\n  case_ID              sym_1      sym_2 outcome\n1       1           jaundice      fever Recover\n2       2             chills      aches   Death\n3       3              fever       &lt;NA&gt;   Death\n4       4           vomiting  diarrhoea Recover\n5       5 bleeding from gums      fever Recover\n6       6        rapid pulse   headache Recover\n\n\nPRECAUCIÓN: Si no proporcionas suficientes valores into en las nuevas columnas, tus datos pueden quedar truncados. \n\n\n\nOrdenar alfabéticamente\nSe pueden ordenar varias cadenas por orden alfabético. str_order() devuelve el orden, mientras que str_sort() devuelve las cadenas en ese orden.\n\n# cadenas\nhealth_zones &lt;- c(\"Alba\", \"Takota\", \"Delta\")\n\n# devuelve el orden alfabético\nstr_order(health_zones)\n\n[1] 1 3 2\n\n# devuelve las cadenas en orden alfabético\nstr_sort(health_zones)\n\n[1] \"Alba\"   \"Delta\"  \"Takota\"\n\n\nPara utilizar un alfabeto diferente, añade el argumento locale =. Mira lista completa de locales introduciendo stringi::stri_locale_list() en la consola de R.\n\n\n\nfunciones R base\nEs común ver las funciones de R base paste() y paste0(), que concatenan vectores después de convertir todas las partes en caracteres. Actúan de forma similar a str_c() pero la sintaxis es posiblemente más complicada - en los paréntesis cada parte está separada por una coma. Las partes son o bien texto de carácter (entre comillas) o bien objetos de código predefinidos (sin comillas). Por ejemplo:\n\nn_beds &lt;- 10\nn_masks &lt;- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")\n\n[1] \"Regional hospital needs 10 beds and 20 masks.\"\n\n\nSe pueden especificar los argumentos sep = y collapse =. paste() es simplemente paste0() con un sep = ” ” por defecto (un espacio).",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#clean-and-standardise",
    "href": "new_pages/characters_strings.es.html#clean-and-standardise",
    "title": "10  Caracteres y cadenas",
    "section": "10.3 Limpiar y normalizar",
    "text": "10.3 Limpiar y normalizar\n\n\nCambiar mayúsculas\nA menudo hay que alterar las mayúsculas y minúsculas de un valor de cadena, por ejemplo los nombres de las jurisdicciones. Utiliza str_to_upper(), str_to_lower(), y str_to_title(), de stringr, como se muestra a continuación:\n\nstr_to_upper(\"California\")\n\n[1] \"CALIFORNIA\"\n\nstr_to_lower(\"California\")\n\n[1] \"california\"\n\n\nUsando R base, lo anterior también se puede lograr con toupper(), tolower().\nMayúsculas en el título\nSe puede transformar la cadena para que cada palabra esté en mayúsculas con str_to_title():\n\nstr_to_title(\"go to the US state of california \")\n\n[1] \"Go To The Us State Of California \"\n\n\nUtiliza toTitleCase() del paquete de tools para lograr una capitalización más matizada (palabras como “a”, “el” y “de” no se escriben en mayúsculas).\n\ntools::toTitleCase(\"This is the US state of california\")\n\n[1] \"This is the US State of California\"\n\n\nTambién puedes utilizar str_to_sentence(), que sólo pone en mayúsculas la primera letra de la cadena.\n\nstr_to_sentence(\"the patient must be transported\")\n\n[1] \"The patient must be transported\"\n\n\n\n\nLongitud de la cadena\nUtiliza str_pad() para añadir caracteres a una cadena, con una longitud mínima. Por defecto se añaden espacios, pero también puedes rellenar con otros caracteres utilizando el argumento pad =.\n\n# ICD codes of differing length\nICD_codes &lt;- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# ICD codes padded to 7 characters on the right side\nstr_pad(ICD_codes, 7, \"right\")\n\n[1] \"R10.13 \" \"R10.819\" \"R17    \"\n\n# Pad with periods instead of spaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")\n\n[1] \"R10.13.\" \"R10.819\" \"R17....\"\n\n\nPor ejemplo, para rellenar números con ceros a la izquierda (como en el caso de las horas o los minutos), puedes rellenar el número hasta una longitud mínima de 2 con pad = “0”.\n\n# Añadir ceros a la izquierda a dos dígitos (por ejemplo, para horas/minutos)\nstr_pad(\"4\", 2, pad = \"0\") \n\n[1] \"04\"\n\n# ejemplo usando una columna numérica llamada \"hours\"\n# hours &lt;- str_pad(hours, 2, pad = \"0\")\n\n\n\nTruncar\nstr_trunc() establece una longitud máxima para cada cadena. Si una cadena supera esta longitud, se trunca (acorta) y se incluye una elipsis (…) para indicar que la cadena era antes más larga. Ten en cuenta que la elipsis se cuenta en la longitud. Los caracteres de la elipsis pueden cambiarse con el argumento ellipsis =. El argumento opcional side =especifica dónde aparecerá la elipsis dentro de la cadena truncada (“left”, “right”, o “center”).\n\noriginal &lt;- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")\n\n[1] \"Symp...ing\"\n\n\n\n\nNormalizar la longitud\nUtiliza str_trunc() para establecer una longitud máxima y, a continuación, utiliza str_pad() para ampliar las cadenas muy cortas hasta esa longitud truncada. En el ejemplo siguiente, se establece 6 como longitud máxima (se trunca un valor), y luego se rellena un valor muy corto para alcanzar la longitud de 6.\n\n# ICD codes of differing length\nICD_codes   &lt;- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# truncar a una longitud máxima de 6\nICD_codes_2 &lt;- str_trunc(ICD_codes, 6)\nICD_codes_2\n\n[1] \"R10.13\" \"R10...\" \"R17\"   \n\n# expandir a longitud mínima de 6\nICD_codes_3 &lt;- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3\n\n[1] \"R10.13\" \"R10...\" \"R17   \"\n\n\n\n\nEliminar los espacios en blanco iniciales y finales\nUtiliza str_trim() para eliminar los espacios, las nuevas líneas (\\n) o los tabuladores (\\t) de los lados de una cadena de entrada. Añade \"right\" \"left\", o \"both\" al comando para especificar qué lado recortar (por ejemplo, str_trim(x, \"right\").\n\n# ID numbers with excess spaces on right\nIDs &lt;- c(\"provA_1852  \", # dos espacios de más\n         \"provA_2345\",   # dero espacios de más\n         \"provA_9460 \")  # un espacio de más\n\n# IDs trimmed to remove excess spaces on right side only\nstr_trim(IDs)\n\n[1] \"provA_1852\" \"provA_2345\" \"provA_9460\"\n\n\n\n\nEliminar los espacios en blanco repetidos en una cadena\nUtiliza str_squish() para eliminar los espacios repetidos que aparecen dentro de una cadena. Por ejemplo, para convertir espacios dobles en espacios simples. También elimina espacios, nuevas líneas o tabulaciones en el exterior de la cadena como str_trim().\n\n# el original contiene espacios de más dentro de la cadena\nstr_squish(\"  Pt requires   IV saline\\n\") \n\n[1] \"Pt requires IV saline\"\n\n\nEscribe ?str_trim, ?str_pad en tu consola de R para ver más detalles.\n\n\nconvertir en párrafos\nUtiliza str_wrap() para convertir un texto largo no estructurado en un párrafo estructurado con una longitud de línea fija. Proporciona la longitud de caracteres ideal para cada línea, y aplica un algoritmo para insertar nuevas líneas () dentro del párrafo, como se ve en el ejemplo siguiente.\n\npt_course &lt;- \"Inicio de los síntomas 1/4/2020 vómitos escalofríos fiebre. La paciente consultó a un curandero tradicional en su pueblo natal el 2/4/2020. El 5/4/2020 los síntomas empeoraron y fue ingresada en la clínica Lumta. Se tomó una muestra y fue trasladada al hospital regional el 6/4/2020. La paciente murió en el hospital regional el 7/4/2020\"\n\nstr_wrap(pt_course, 40)\n\n[1] \"Inicio de los síntomas 1/4/2020 vómitos\\nescalofríos fiebre. La paciente consultó\\na un curandero tradicional en su pueblo\\nnatal el 2/4/2020. El 5/4/2020 los\\nsíntomas empeoraron y fue ingresada en\\nla clínica Lumta. Se tomó una muestra\\ny fue trasladada al hospital regional\\nel 6/4/2020. La paciente murió en el\\nhospital regional el 7/4/2020\"\n\n\nLa función base cat() puede envolver el comando anterior para imprimir la salida, mostrando las nuevas líneas añadidas.\n\ncat(str_wrap(pt_course, 40))\n\nInicio de los síntomas 1/4/2020 vómitos\nescalofríos fiebre. La paciente consultó\na un curandero tradicional en su pueblo\nnatal el 2/4/2020. El 5/4/2020 los\nsíntomas empeoraron y fue ingresada en\nla clínica Lumta. Se tomó una muestra\ny fue trasladada al hospital regional\nel 6/4/2020. La paciente murió en el\nhospital regional el 7/4/2020",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#handle-by-position",
    "href": "new_pages/characters_strings.es.html#handle-by-position",
    "title": "10  Caracteres y cadenas",
    "section": "10.4 Manipular por posición",
    "text": "10.4 Manipular por posición\n\nExtraer por posición de carácter\nUtiliza str_sub() para devolver sólo una parte de una cadena. La función toma tres argumentos principales:\n\nel(los) vector(es) de caracteres\nposición de inicio\nposición final\n\nAlgunas notas sobre los números de posición:\n\nSi un número de posición es positivo, la posición se cuenta a partir del extremo izquierdo de la cadena.\nSi un número de posición es negativo, se cuenta a partir del extremo derecho de la cadena.\nLos números de posición son inclusivos.\nLas posiciones que se extienden más allá de la cadena serán truncadas (eliminadas).\n\nA continuación se muestran algunos ejemplos aplicados a la cadena “pneumonia”:\n\n# empieza y termina tercero por la izquierda (3ª letra por la izquierda)\nstr_sub(\"pneumonia\", 3, 3)\n\n[1] \"e\"\n\n# 0 no está presente\nstr_sub(\"pneumonia\", 0, 0)\n\n[1] \"\"\n\n# 6ª por la izquierda, hasta la 1ª por la derecha\nstr_sub(\"pneumonia\", 6, -1)\n\n[1] \"onia\"\n\n# 5º por la derecha, al 2º por la derecha\nstr_sub(\"pneumonia\", -5, -2)\n\n[1] \"moni\"\n\n# 4º por la izquierda hasta una posición fuera de la cadena\nstr_sub(\"pneumonia\", 4, 15)\n\n[1] \"umonia\"\n\n\n\n\nExtraer por posición de palabra\nPara extraer la enésima ‘palabra’, utiliza word(), también de stringr. Proporciona la(s) cadena(s), luego la primera y la última posición de la palabra a extraer.\nPor defecto, se asume que el separador entre ‘palabras’ es un espacio, a menos que se indica lo contrario con sep = (por ejemplo, sep = \"_\" cuando las palabras están separadas por barra baja.\n\n# cadenas a evaluar\nchief_complaints &lt;- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extraer de la 1ª a la 3ª palabra de cada cadena\nword(chief_complaints, start = 1, end = 3, sep = \" \")\n\n[1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\" \n\n\n\n\nSustituir por posición de carácter\nstr_sub() emparejado con el operador de asignación (&lt;-) puede utilizarse para modificar una parte de una cadena:\n\nword &lt;- \"pneumonia\"\n\n# convertir el tercer y cuarto carácter en X \nstr_sub(word, 3, 4) &lt;- \"XX\"\n\n# imprimir\nword\n\n[1] \"pnXXmonia\"\n\n\nUn ejemplo aplicado a varias cadenas (por ejemplo, una columna). Obsérvese la ampliación de la longitud de “HIV”.\n\nwords &lt;- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convierte el tercer y cuarto carácter en X \nstr_sub(words, 3, 4) &lt;- \"XX\"\n\nwords\n\n[1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\"        \n\n\n\n\nEvaluar la longitud\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nComo alternativa, utiliza nchar() de R base",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#patterns",
    "href": "new_pages/characters_strings.es.html#patterns",
    "title": "10  Caracteres y cadenas",
    "section": "10.5 Patrones",
    "text": "10.5 Patrones\nMuchas funciones de stringr trabajan para detectar, localizar, extraer, hacer coincidir, reemplazar y dividir basándose en un patrón especificado.\n\n\nDetectar un patrón\nUtiliza str_detect() como se indica a continuación para detectar la presencia/ausencia de un patrón dentro de una cadena. Primero proporciona la cadena o vector en la que a buscar (string =), y luego el patrón a buscar (pattern =). Ten en cuenta que, por defecto, la búsqueda distingue entre mayúsculas y minúsculas.\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")\n\n[1] TRUE\n\n\nSe puede incluir el argumento negate = y ponerlo a TRUE si se quiere saber si el patrón NO está presente.\n\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)\n\n[1] FALSE\n\n\nPara ignorar las mayúsculas y minúsculas, envuelve el patrón dentro de regex(), y dentro de regex() añade el argumento ignore_case = TRUE (o T como abreviatura).\n\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))\n\n[1] TRUE\n\n\nCuando str_detect() se aplica a un vector de caracteres o a una columna de un dataframe, devolverá TRUE o FALSE para cada uno de los valores.\n\n# un vector/columna de ocupaciones \noccupations &lt;- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# Detectar la presencia del patrón \"teach\" en cada cadena - la salida es un vector de TRUE/FALSE\nstr_detect(occupations, \"teach\")\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nSi necesitas contar los TRUE, simplemente sum() la salida. Esto cuenta el número de TRUE.\n\nsum(str_detect(occupations, \"teach\"))\n\n[1] 1\n\n\nPara buscar con varios términos, inclúyelos separados por barras (|) dentro del argumento pattern =, como se muestra a continuación:\n\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))\n\n[1] 3\n\n\nSi necesitas construir una larga lista de términos de búsqueda, puedes combinarlos usando str_c() y sep = |, luego definir que esto es un objeto de caracteres, y luego referenciar el vector más adelante de manera más sucinta. El ejemplo siguiente incluye posibles términos de búsqueda de ocupación para proveedores médicos de primera línea.\n\n# términos de búsqueda\noccupation_med_frontline &lt;- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline\n\n[1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\n\n\nEste comando devuelve el número de ocupaciones que contienen alguno de los términos de búsqueda para proveedores médicos de primera línea (occupation_med_frontline):\n\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))\n\n[1] 2\n\n\nFunciones de búsqueda de cadenas en R base\ngrepl() de R base funciona de forma similar a str_detect(), en el sentido de que busca coincidencias con un patrón y devuelve un vector lógico. La sintaxis básica es grepl(patrón,  cadenas_de_búsqueda, ignore.case = FALSE, ...). Una ventaja es que el argumento ignore.case es más fácil de escribir (no hay necesidad de involucrar la función regex()).\nAsimismo, las funciones sub() y gsub()de R base actúan de forma similar a str_replace(). Su sintaxis básica es: gsub(patrón, reemplazo, cadenas_de_búsqueda, ignore.case = FALSE). sub() reemplazará la primera instancia del patrón, mientras que gsub() reemplazará todas las instancias del patrón.\n\nConvertir comas en puntos\nHe aquí un ejemplo de uso de gsub() para convertir comas en puntos en un vector de números. Esto podría ser útil si tus datos proceden de otras partes del mundo que no sean Estados Unidos o Gran Bretaña.\ngsub() internamente actúa primero sobre lengths convirtiendo cualquier punto en sin espacio ““. El carácter de punto”.” tiene que ser “escapado” con dos barras inclinadas para significar realmente un punto, porque “.” en regex significa “cualquier carácter”. A continuación, el resultado (con sólo comas) se pasa a la función externa gsub() en la que las comas se sustituyen por puntos.\n\nlengths &lt;- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # buscar comas     \n                replacement = \".\",            # sustituir por puntos\n                x = gsub(\"\\\\.\", \"\", lengths)  # vector con otros puntos eliminados (puntos escapados)\n                )\n           )                                  # convertir el resultado en numérico\n\n\n\n\nSustituir todo\nUtiliza str_replace_all() como herramienta de “búsqueda y sustitución”. Primero, proporcione las cadenas a evaluar a string =, luego el patrón a reemplazar a pattern =, y luego el valor de reemplazo a replacement =. El ejemplo siguiente reemplaza todas las instancias de “dead” con “deceased”. Ten en cuenta que esto distingue entre mayúsculas y minúsculas.\n\noutcome &lt;- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")\n\n[1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\"\n\n\nNotas:\n\nPara sustituir un patrón por NA, utiliza str_replace_na().\nLa función str_replace() reemplaza sólo la primera instancia del patrón dentro de cada cadena evaluada.\n\n\n\n\nDetectar con lógica\nDentro de case_when()\nstr_detect() se utiliza a menudo dentro de case_when() (de dplyr). Digamos que ocupaciones es una columna en linelist. La función mutate() de abajo crea una nueva columna llamada is_educator utilizando la lógica condicional a través de case_when(). Mira la página sobre limpieza de datos para aprender más sobre case_when().\n\ndf &lt;- df %&gt;% \n  mutate(is_educator = case_when(\n    # búsqueda de términos dentro de la ocupación, sin distinción entre mayúsculas y minúsculas\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # todos los demás\n    TRUE                                               ~ \"Not an educator\"))\n\nComo recordatorio, puede ser importante añadir criterios de exclusión a la lógica condicional (negate = F):\n\ndf &lt;- df %&gt;% \n  # el valor de la nueva columna is_educator se basa en la lógica condicional\n  mutate(is_educator = case_when(\n    \n    # la columna de ocupación debe cumplir 2 criterios para que se le asigne \"Educador\":\n    # debe tener un término de búsqueda Y NO cualquier término de exclusión\n    \n    # debe tener un término de búsqueda\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # Y NO debe tener un término de exclusión\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # Todas las filas que no cumplan los criterios anteriores\n    TRUE                                            ~ \"Not an educator\"))\n\n\n\n\nLocalizar la posición de un patrón\nPara localizar la primera posición de un patrón, utiliza str_locate(). Esta función da como resultado una posición inicial y una final.\n\nstr_locate(\"I wish\", \"sh\")\n\n     start end\n[1,]     5   6\n\n\nAl igual que otras funciones str, existe una versión “_all” (str_locate_all()) que devolverá las posiciones de todas las instancias del patrón dentro de cada cadena. La salida es una lista.\n\nphrases &lt;- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # posición de la *primera* instancia del patrón\n\n     start end\n[1,]     6   6\n[2,]     3   3\n[3,]     1   1\n[4,]     4   4\n\nstr_locate_all(phrases, \"h\" ) # posición de *cada* instancia del patrón\n\n[[1]]\n     start end\n[1,]     6   6\n\n[[2]]\n     start end\n[1,]     3   3\n\n[[3]]\n     start end\n[1,]     1   1\n[2,]     4   4\n\n[[4]]\n     start end\n[1,]     4   4\n\n\n\n\n\nExtraer una coincidencia\nstr_extract_all() devuelve los patrones coincidentes en sí mismos, lo que resulta muy útil cuando se han ofrecido varios patrones mediante condiciones “OR”. Por ejemplo, buscando en el vector de cadenas de ocupaciones (véase la pestaña anterior) cualquiera “enseñ”, “profesor” o “tutor”.\nstr_extract_all() devuelve una lista que contiene todas las coincidencias de cada cadena evaluada. Mira a continuación cómo la ocupación 3 tiene dos coincidencias de patrón dentro de ella.\n\nstr_extract_all(occupations, \"teach|prof|tutor\")\n\n[[1]]\ncharacter(0)\n\n[[2]]\n[1] \"prof\"\n\n[[3]]\n[1] \"teach\" \"tutor\"\n\n[[4]]\n[1] \"tutor\"\n\n[[5]]\ncharacter(0)\n\n[[6]]\ncharacter(0)\n\n[[7]]\ncharacter(0)\n\n[[8]]\ncharacter(0)\n\n[[9]]\ncharacter(0)\n\n[[10]]\ncharacter(0)\n\n\nstr_extract() extrae sólo la primera coincidencia en cada cadena evaluada, produciendo un vector de caracteres con un elemento por cada cadena evaluada. Devuelve NA cuando no hay coincidencias. Los NAs pueden ser eliminados envolviendo el vector devuelto con na.exclude(). Observa cómo la segunda de las coincidencias de la ocupación 3 no se muestra.\n\nstr_extract(occupations, \"teach|prof|tutor\")\n\n [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA     \n[10] NA     \n\n\n\n\n\nSubconjunto y recuento\nLas funciones alineadas incluyen str_subset() y str_count().\nstr_subset() devuelve los valores reales que contienen el patrón:\n\nstr_subset(occupations, \"teach|prof|tutor\")\n\n[1] \"university professor\"           \"primary school teacher & tutor\"\n[3] \"tutor\"                         \n\n\nstr_count() devuelve un vector de números: el número de veces que aparece un término de búsqueda en cada valor evaluado.\n\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))\n\n [1] 0 1 2 1 0 0 0 0 0 0\n\n\n\n\n\nGrupos Regex\nEN CONSTRUCCIÓN",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#special-characters",
    "href": "new_pages/characters_strings.es.html#special-characters",
    "title": "10  Caracteres y cadenas",
    "section": "10.6 Caracteres especiales",
    "text": "10.6 Caracteres especiales\nBarra invertida \\ como código de escape\nLa barra invertida \\ se utiliza para “escapar” del significado del siguiente carácter. De este modo, se puede utilizar una barra invertida para que una comilla aparezca dentro de otras comillas (\\\") - la comilla del medio no “romperá” las comillas circundantes.\nNota - por lo tanto, si quieres mostrar una barra invertida, debes escapar su significado con otra barra invertida. Así que debes escribir dos barras invertidas \\\\ para mostrar una.\nCaracteres especiales\n\n\n\n\n\n\n\nCarácter especial\nRepresenta\n\n\n\n\n\"\\\\\"\nbarra invertida\n\n\n\"\\n\"\nuna nueva línea\n\n\n\"\\\"\"\ncomillas dobles dentro de comillas dobles\n\n\n'\\''\ncomillas simples dentro de comillas simples\n\n\n\"\\“| acento grave”| retorno carro“| tab”| tab vertical“`\nretroceso\n\n\n\nEjecuta ?\"'\" en la consola de R para mostrar una lista completa de estos caracteres especiales (aparecerá en el panel de ayuda de RStudio).",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#regular-expressions-regex",
    "href": "new_pages/characters_strings.es.html#regular-expressions-regex",
    "title": "10  Caracteres y cadenas",
    "section": "10.7 Expresiones regulares (regex)",
    "text": "10.7 Expresiones regulares (regex)",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#regex-and-special-characters",
    "href": "new_pages/characters_strings.es.html#regex-and-special-characters",
    "title": "10  Caracteres y cadenas",
    "section": "10.8 Regex y caracteres especiales",
    "text": "10.8 Regex y caracteres especiales\nLas expresiones regulares, o “regex”, son un lenguaje conciso para describir patrones en las cadenas. Si no está familiarizado con él, una expresión regular puede parecer un lenguaje extraño. Aquí tratamos de desmitificar un poco este lenguaje.\nGran parte de esta sección está adaptada de este tutorial y de esta hoja de trucos. Aquí adaptamos selectivamente sabiendo que este manual podría ser visto por personas sin acceso a internet para ver los otros tutoriales.\nUna expresión regular se aplica a menudo para extraer patrones específicos de texto “no estructurado”, por ejemplo, notas médicas, quejas principales, historial del paciente u otras columnas de texto libre en un dataframe.\nHay cuatro herramientas básicas que se pueden utilizar para crear una expresión regular básica:\n\nJuegos de caracteres\nMetacaracteres\nCuantificadores\nGrupos\n\nJuegos de caracteres\nLos conjuntos de caracteres, son una forma de expresar las opciones de la lista para una coincidencia de caracteres, entre paréntesis. Así, cualquier coincidencia se activará si cualquiera de los caracteres dentro de los paréntesis se encuentra en la cadena. Por ejemplo, para buscar vocales se podría utilizar este conjunto de caracteres “[aeiou]”. Otros conjuntos de caracteres comunes son:\n\n\n\nCaracteres\nCoinciden con\n\n\n\n\n\"[A-Z]\"\nuna letra mayúscula\n\n\n\"[a-z]\"\nuna letra minúscula\n\n\n\"[0-9]\"\nun dígito\n\n\n[:alnum:]\nun carácter alfanumérico\n\n\n[:digit:]\nun dígito numérico\n\n\n[:alpha:]\nuna letra (mayúscula o minúscula)\n\n\n[:upper:]\nuna letra mayúscula\n\n\n[:lower:]\nuna letra minúscula\n\n\n\nLos conjuntos de caracteres pueden combinarse dentro de un paréntesis (¡sin espacios!), como \"[A-Za-z]\" (cualquier letra mayúscula o minúscula), u otro ejemplo \"[t-z0-5]\" (de la t a la z en minúscula o del número 0 al 5).\nMeta caracteres\nLos metacaracteres son la abreviatura de los juegos de caracteres. A continuación se enumeran algunos de los más importantes:\n\n\n\n\n\n\n\nMeta carácter\nCoincide con\n\n\n\n\n\"\\\\s\"\nun solo espacio\n\n\n\"\\\\w\"\ncualquier carácter alfanumérico (A-Z, a-z, o 0-9)\n\n\n\"\\\\d\"\ncualquier dígito numérico (0-9)\n\n\n\nCuantificadores\nNormalmente no se desea buscar una coincidencia en un solo carácter. Los cuantificadores le permiten designar la longitud de las letras/números para permitir la coincidencia.\nLos cuantificadores son números escritos entre corchetes { } después del carácter que cuantifican, por ejemplo,\n\n\"A{2}\" devolverá instancias de dos letras A mayúsculas.\n\"A{2,4}\" devolverá instancias de entre dos y cuatro letras A mayúsculas (¡no ponga espacios!).\n\"A{2,}\" devolverá instancias de dos o más letras A mayúsculas.\n\"A+\" devolverá instancias de una o más letras A mayúsculas (grupo extendido hasta que se encuentre un carácter diferente).\nPreceder con un asterisco * para devolver cero o más coincidencias (útil si no está seguro de que el patrón está presente)\n\nUtilizando el símbolo + como cuantificador, la coincidencia se producirá hasta que se encuentre un carácter diferente. Por ejemplo, esta expresión devolverá todas las palabras (caracteres alfa: \"[A-Za-z]+\"\n\n# cadena de prueba para cuantificadores\ntest &lt;- \"A-AA-AAA-AAAA\"\n\nCuando se utiliza un cuantificador de {2}, sólo se devuelven los pares de A consecutivos. Se identifican dos pares dentro de AAAA.\n\nstr_extract_all(test, \"A{2}\")\n\n[[1]]\n[1] \"AA\" \"AA\" \"AA\" \"AA\"\n\n\nCuando se utiliza un cuantificador de {2,4}, se devuelven grupos de A consecutivos de dos a cuatro.\n\nstr_extract_all(test, \"A{2,4}\")\n\n[[1]]\n[1] \"AA\"   \"AAA\"  \"AAAA\"\n\n\nCon el cuantificador +, se devuelven grupos de uno o más:\n\nstr_extract_all(test, \"A+\")\n\n[[1]]\n[1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\n\n\nPosición relativa\nExpresan los requisitos de lo que precede o sigue a un patrón. Por ejemplo, para extraer frases, “dos números que van seguidos de un punto” (\"\"). (?&lt;=\\.)\\s(?=[A-Z])\n\nstr_extract_all(test, \"\")\n\n[[1]]\n [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\n\n\n\n\n\nDefinición posición\nCoincide con\n\n\n\n\n\"(?&lt;=b)a\"\n“a” que está precedida con una “b”\n\n\n\"(?&lt;!b)a\"\n“a” que NO está precedida con una “b”\n\n\n\"a(?=b)\"\n“a” que se sigue de una “b”\n\n\n\"a(?!b)\"\n“a” que NO se sigue de una “b”\n\n\n\nGrupos\nLa captura de grupos en su expresión regular es una forma de tener una salida más organizada al momento de la extracción.\nEjemplos de Regex\nA continuación se presenta un texto libre para los ejemplos. Intentaremos extraer información útil del mismo utilizando un término de búsqueda de expresión regular.\n\npt_note &lt;- \"Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute.\"\n# \"El paciente llegó a la sala de urgencias del Broward Hospital a las 18:00 horas del 6/12/2005. \n# Se presentó con dolor abdominal irradiado desde el cuadrante LR. La piel estaba pálida, fría y húmeda.\n# Su temperatura era de 99,8 grados Farinheit. El pulso era de 100 lpm y filiforme. La frecuencia respiratoria era de 29 por minuto\"\n\nEsta expresión coincide con todas las palabras (cualquier carácter hasta llegar a un no carácter como un espacio):\n\nstr_extract_all(pt_note, \"[A-Za-z]+\")\n\n[[1]]\n [1] \"Patient\"     \"arrived\"     \"at\"          \"Broward\"     \"Hospital\"   \n [6] \"emergency\"   \"ward\"        \"at\"          \"on\"          \"Patient\"    \n[11] \"presented\"   \"with\"        \"radiating\"   \"abdominal\"   \"pain\"       \n[16] \"from\"        \"LR\"          \"quadrant\"    \"Patient\"     \"skin\"       \n[21] \"was\"         \"pale\"        \"cool\"        \"and\"         \"clammy\"     \n[26] \"Patient\"     \"temperature\" \"was\"         \"degrees\"     \"farinheit\"  \n[31] \"Patient\"     \"pulse\"       \"rate\"        \"was\"         \"bpm\"        \n[36] \"and\"         \"thready\"     \"Respiratory\" \"rate\"        \"was\"        \n[41] \"per\"         \"minute\"     \n\n\nLa expresión \"[0-9]{1,2}\" coincide con números consecutivos de 1 o 2 dígitos. También podría escribirse \"\\\\d{1,2}\", o \"[:digit:]{1,2}\".\n\nstr_extract_all(pt_note, \"[0-9]{1,2}\")\n\n[[1]]\n [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\"\n\n\n\n\n\n\nPuedes ver una lista útil de expresiones regex y consejos en la página 2 de esta hoja de trucos\nMira también este tutorial.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/characters_strings.es.html#resources-3",
    "href": "new_pages/characters_strings.es.html#resources-3",
    "title": "10  Caracteres y cadenas",
    "section": "10.9 Recursos",
    "text": "10.9 Recursos\nPuedes encontrar una hoja de referencia para las funciones de stringr aquí\nPuedes encontrar una viñeta sobre stringr aquí",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Caracteres y cadenas</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html",
    "href": "new_pages/factors.es.html",
    "title": "11  Factores",
    "section": "",
    "text": "11.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#preparation-2",
    "href": "new_pages/factors.es.html#preparation-2",
    "title": "11  Factores",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,           # importar/exportar\n  here,          # rutas de archivos\n  lubridate,     # trabajar con fechas\n  forcats,       # factores\n  aweek,         # crear epiweeks con niveles automáticos de factores  \n  janitor,       # tablas\n  tidyverse      # gestión y visualización de datos\n  )\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa sus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).\n\n# importar tu set de datos\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\n\n\n11.1.1 Nueva variable categórica {#fct_newcat .unnumbered}\nPara mostrarlo en esta página utilizaremos un escenario común - la creación de una nueva variable categórica.\nTen en cuenta que si conviertes una columna numérica en una de tipo factor, no podrás calcular estadísticas numéricas sobre ella.\n\nCrear columna\nUtilizamos la columna existente days_onset_hosp (días desde el inicio de los síntomas hasta el ingreso en el hospital) y creamos una nueva columna delay_cat clasificando cada fila en una de varias categorías. Lo hacemos con la función dplyr case_when(), que aplica secuencialmente criterios lógicos (lado derecho) a cada fila y devuelve el valor correspondiente del lado izquierdo para la nueva columna delay_cat. Puedes leer más sobre case_when() en Limpieza de datos y funciones básicas.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = case_when(\n    # criteria                                   # valor nuevo si TRUE\n    days_onset_hosp &lt; 2                        ~ \"&lt;2 days\",\n    days_onset_hosp &gt;= 2 & days_onset_hosp &lt; 5 ~ \"2-5 days\",\n    days_onset_hosp &gt;= 5                       ~ \"&gt;5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  \n\n\n\nOrden de valores por defecto\nTal y como se creó con case_when(), la nueva columna delay_cat es una columna categórica de tipo Character - aún no es un factor. Así, en una tabla de frecuencias, vemos que los valores únicos aparecen en un orden alfanumérico por defecto - un orden que no tiene mucho sentido intuitivo:\n\ntable(linelist$delay_cat, useNA = \"always\")\n\n\n &lt;2 days  &gt;5 days 2-5 days     &lt;NA&gt; \n    2990      602     2040      256 \n\n\nDel mismo modo, si hacemos un gráfico de barras, los valores también aparecen en este orden en el eje x (ver la página de conceptos básicos de ggplot para más información sobre ggplot2 - el paquete de visualización más común en R).\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#convert-to-factor",
    "href": "new_pages/factors.es.html#convert-to-factor",
    "title": "11  Factores",
    "section": "11.2 Convertir en factor",
    "text": "11.2 Convertir en factor\nPara convertir una columna numérica o de caracteres en una de tipo factor, puedes utilizar cualquier función del paquete forcats (muchas se detallan a continuación). Las convertirán en otra de tipo factor y luego también realizarán o permitirán cierto ordenamiento de los niveles - por ejemplo usando fct_relevel() permite especificar manualmente el orden de los niveles. La función as_factor() simplemente convierte el tipo sin ninguna otra capacidad.\nLa función factor() de R base convierte una columna en factor y permite especificar manualmente el orden de los niveles, como un vector de caracteres a su argumento levels =.\nA continuación utilizamos mutate() y fct_relevel() para convertir la columna delay_cat de tipo carácter a tipo factor. La columna delay_cat se crea en la sección de preparación anterior.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat))\n\nLos “valores” únicos de esta columna se consideran ahora “niveles” del factor. Los niveles tienen un orden, que puede imprimirse con la función de levels(), o alternativamente verse en una tabla de recuento mediante table() de R base o tabyl() de janitor. Por defecto, el orden de los niveles será alfanumérico, como antes. Ten en cuenta que NA no es un nivel de factor.\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"&gt;5 days\"  \"2-5 days\"\n\n\nLa función fct_relevel() tiene la utilidad adicional de permitir especificar manualmente el orden de los niveles. Simplemente escribe los valores de nivel en orden, entre comillas, separados por comas, como se muestra a continuación. Ten en cuenta que la ortografía debe coincidir exactamente con los valores. Si deseas crear niveles que no existen en los datos, utiliza fct_expand() en su lugar).\n\nlinelist &lt;- linelist %&gt;%\n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))\n\nAhora podemos ver que los niveles están ordenados, como se especificó en el comando anterior, en un orden sensato.\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nAhora el orden de la gráfica también tiene un sentido más intuitivo.\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#add-or-drop-levels",
    "href": "new_pages/factors.es.html#add-or-drop-levels",
    "title": "11  Factores",
    "section": "11.3 Añadir o quitar niveles",
    "text": "11.3 Añadir o quitar niveles\n\n11.3.1 Añadir {#fct_add .unnumbered}\nSi necesitas añadir niveles a un factor, puedes hacerlo con fct_expand(). Basta con escribir el nombre de la columna seguido de los nuevos niveles (separados por comas). Al tabular los valores, podemos ver los nuevos niveles y los recuentos de cero. Puedes utilizar table() de R base, o tabyl() de janitor:\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %&gt;% \n  tabyl(delay_cat)   # imprimir tabla\n\n                      delay_cat    n    percent valid_percent\n                        &lt;2 days 2990 0.50781250     0.5308949\n                       2-5 days 2040 0.34646739     0.3622159\n                        &gt;5 days  602 0.10224185     0.1068892\n       Not admitted to hospital    0 0.00000000     0.0000000\n Transfer to other jurisdiction    0 0.00000000     0.0000000\n                           &lt;NA&gt;  256 0.04347826            NA\n\n\nNota: existe una función especial de forcats para añadir fácilmente valores faltantes (NA) como nivel. Véase la sección sobre valores faltantes más adelante.\n\n\nQuitar\nSi utilizas fct_drop(), los niveles “no utilizados” con recuento cero se eliminarán del conjunto de niveles. Los niveles que hemos añadido anteriormente (“No admitido en un hospital”) existen como nivel, pero ninguna fila tiene realmente esos valores. Por tanto, se eliminarán aplicando fct_drop() a nuestra columna de factores:\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_drop(delay_cat)) %&gt;% \n  tabyl(delay_cat)\n\n delay_cat    n    percent valid_percent\n   &lt;2 days 2990 0.50781250     0.5308949\n  2-5 days 2040 0.34646739     0.3622159\n   &gt;5 days  602 0.10224185     0.1068892\n      &lt;NA&gt;  256 0.04347826            NA",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#ajustar-el-orden-de-los-niveles-fct_adjust",
    "href": "new_pages/factors.es.html#ajustar-el-orden-de-los-niveles-fct_adjust",
    "title": "11  Factores",
    "section": "11.4 Ajustar el orden de los niveles {#fct_adjust}",
    "text": "11.4 Ajustar el orden de los niveles {#fct_adjust}\nEl paquete forcats ofrece funciones útiles para ajustar fácilmente el orden de los niveles de un factor (después de haber definido una columna como de tipo factor):\nEstas funciones pueden aplicarse a una columna de factores en dos contextos:\n\nA la columna del dataframe, como es habitual, para que la transformación esté disponible para cualquier uso posterior de los datos\nDentro de un gráfico, para que el cambio se aplique sólo dentro del gráfico\n\n\nManualmente\nEsta función se utiliza para ordenar manualmente los niveles de los factores. Si se utiliza en una columna no factorial, la columna se convertirá primero en de tipo factor.\nDentro del paréntesis, indica primero el nombre de la columna del factor y, a continuación, escribe\n\nTodos los niveles en el orden deseado (como un vector de caracteres c()), o\nUn nivel y se corrige la colocación utilizando el argumento after =\n\nHe aquí un ejemplo de redefinición de la columna delay_cat (que ya es de tipo Factor) y especificando todo el orden de niveles deseado.\n\n# redefinir el orden de los niveles\nlinelist &lt;- linelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\")))\n\nSi sólo quieres mover un nivel, puedes especificarlo sólo en fct_relevel() y dar un número al argumento after =para indicar en qué lugar del orden debe estar. Por ejemplo, el comando siguiente desplaza “&lt;2 días” a la segunda posición:\n\n# redefinir el orden de los niveles\nlinelist %&gt;% \n  mutate(delay_cat = fct_relevel(delay_cat, \"&lt;2 days\", after = 1)) %&gt;% \n  tabyl(delay_cat)\n\n\n\nDentro de un gráfico\nLos comandos forcats pueden utilizarse para establecer el orden de los niveles en el dataframe, o sólo dentro de un gráfico. Al utilizar el comando para “envolver” el nombre de la columna dentro del comando ggplot(), puedes invertir/nivelar/etc. la transformación sólo se aplicará dentro de ese gráfico.\nA continuación, se crean dos gráficos con ggplot() (véase la página de conceptos básicos de ggplot). En el primero, la columna delay_cat se asigna al eje x del gráfico, con su orden de nivel por defecto como en linelist de datos. En el segundo ejemplo se envuelve dentro de fct_relevel() y se cambia el orden en el gráfico.\n\n# orden por defecto alfanumérico  - sin ajuste dentro de ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Orden por nivel de factor ajustado en ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"&lt;2 days\", \"2-5 days\", \"&gt;5 days\"))))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTen en cuenta que el título del eje x por defecto es ahora bastante complicado - puedes sobrescribir este título con el argumento de ggplot2 labs().\n\n\nInvertir\nEs bastante común que se quiera invertir el orden de los niveles. Basta con envolver el factor con fct_rev().\nTen en cuenta que si deseas revertir sólo una leyenda del gráfico pero no los niveles reales del factor, puedes hacerlo con guides() (ver consejos de ggplot).\n\n\nPor frecuencia\nPara ordenar por la frecuencia con que el valor aparece en los datos, utiliza fct_infreq(). Cualquier valor que falte (NA) se incluirá automáticamente al final, a menos que se convierta en un nivel explícito (véase esta sección). Puedes invertir el orden envolviendo más con fct_rev().\nEsta función puede utilizarse dentro de ggplot(), como se muestra a continuación.\n\n# ordenados por frecuencia\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# frecuencia inversa\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor apariencia\nUtiliza fct_inorder() para establecer el orden de los niveles para que coincida con el orden de aparición en los datos, empezando por la primera fila. Esto puede ser útil si primero organizas cuidadosamente arrange() los datos en el dataframe, y luego utiliza esto para establecer el orden de los factores.\nComo me he alejado un poco de las configuraciones del libro original, he renombrado el metapaquete r4ds que utilizamos para instalar las dependencias del libro a r4dses e hice algo de limpieza en el DESCRIPCIÓN, .Rbuildignore y eliminé algunos archivos que ya no eran necesarios. El resultado fue obtener cero errores, advertencias y notas al ejecutar devtools::check().\nEs importante mencionar que el repositorio del libro es, en parte, un paquete R, y el comando devtools::install_github(\"cienciadedatos/r4ds\") instalará las dependencias del libro mediante leyendo el archivo DESCRIPTION del.\n\n\nPor estadística resumida de otra columna\nPuedes utilizar fct_reorder() para ordenar los niveles de una columna por una estadística de resumen de otra columna. Visualmente, esto puede dar lugar a gráficos agradables en los que las barras/puntos ascienden o descienden de forma constante a través del gráfico.\nEn los ejemplos siguientes, el eje x es delay_cat, y el eje y es la columna numérica ct_blood (valor de umbral de ciclo). Los gráficos de caja muestran la distribución del valor CT por grupo delay_cat. Queremos ordenar los gráficos de caja en orden ascendente por mediana del grupo CT.\nEn el primer ejemplo de abajo, se utiliza el orden por defecto de los niveles alfa-numéricos. Se puede ver que las alturas de los gráficos de caja están mezcladas y no en ningún orden particular. En el segundo ejemplo, la columna delay_cat (asignada al eje x) se ha envuelto en fct_reorder(), la columna ct_blood se da como segundo argumento, y la “mediana” se da como tercer argumento (también podría usar “max”, “mean”, “min”, etc). Por lo tanto, el orden de los niveles de delay_cat reflejará ahora los valores ascendentes de la mediana del CT de cada grupo de delay_cat. Esto se refleja en el segundo gráfico: los gráficos de caja se han reordenado de forma ascendente. Observa cómo NA (missing) aparecerá al final, a menos que se convierta en un nivel explícito.\n\n# boxplots ordenados por niveles del factor original\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by original alpha-numeric levels\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordenados por la mediana del valor CT\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObserva que en este ejemplo no se requieren pasos previos a la llamada a ggplot() - la agrupación y los cálculos se realizan internamente en el comando ggplot.\n\n\nPor valor “final”\nUtiliza fct_reorder2() para los gráficos de líneas agrupadas. Ordena los niveles (y, por tanto, la leyenda) para que se alineen con la ordenación vertical de las líneas en el “final” del gráfico. Técnicamente hablando, “ordena por los valores-y asociados a los valores-x más grandes”.\nPor ejemplo, si tienes líneas que muestran los recuentos de casos por hospital a lo largo del tiempo, puedes aplicar fct_reorder2() al argumento color =dentro de aes(), de forma que el orden vertical de los hospitales que aparecen en la leyenda se alinee con el orden de las líneas en el extremo terminal del gráfico. Lee más en la documentación en línea.\n\nepidemic_data &lt;- linelist %&gt;%         # comenzar con linelist   \n    filter(date_onset &lt; as.Date(\"2014-09-21\")) %&gt;%    # fecha de corte, para mayor claridad visual\n    count(                                            # obtener recuentos de casos por semana y por hospital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # iniciar gráfico\n  geom_line(                                        # hacer líneas\n    aes(\n      x = epiweek,                                  # eje-x epiweek\n      y = n,                                        # la altura es el número de casos por semana\n      color = fct_reorder2(hospital, epiweek, n)))+ # datos agrupados y coloreados por hospital, con orden de factor por altura al final del gráfico\n  labs(title = \"Factor levels (and legend display) by line height at end of plot\",\n       color = \"Hospital\")                          # cambiar el título de la leyenda",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#valores-faltantes-fct_missing",
    "href": "new_pages/factors.es.html#valores-faltantes-fct_missing",
    "title": "11  Factores",
    "section": "11.5 Valores faltantes {#fct_missing}",
    "text": "11.5 Valores faltantes {#fct_missing}\nSi hay valores NA en lu columna de factores, puede convertirlos fácilmente a un nivel con nombre como “Missing” con fct_explicit_na(). Los valores NA se convierten por defecto en “(Missing)” al final del orden de los niveles. Puedes ajustar el nombre del nivel con el argumento na_level =.\nA continuación, esta operación se realiza en la columna delay_cat y se imprime una tabla con tabyl() con NA convertido en “Missing delay”.\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %&gt;% \n  tabyl(delay_cat)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing\n  delay\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\n     delay_cat    n    percent\n      2-5 days 2040 0.34646739\n       &lt;2 days 2990 0.50781250\n       &gt;5 days  602 0.10224185\n Missing delay  256 0.04347826",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#combine-levels",
    "href": "new_pages/factors.es.html#combine-levels",
    "title": "11  Factores",
    "section": "11.6 Combinar niveles",
    "text": "11.6 Combinar niveles\n\nManualmente\nPuedes ajustar las visualizaciones de los niveles manualmente con fct_recode(). Es como la función recode() de dplyr (véase Limpieza de datos y funciones básicas), pero permite la creación de nuevos niveles de factores. Si utilizas la función simple recode() en un factor, los nuevos valores recodificados serán rechazados a menos que ya hayan sido establecidos como niveles permitidos.\nEsta herramienta también puede utilizarse para “combinar” niveles, asignando a varios niveles el mismo valor recodificado. Sólo hay que tener cuidado de no perder información. Considere la posibilidad de realizar estos pasos de combinación en una nueva columna (sin sobreescribir la columna existente).\nfct_recode() tiene una sintaxis diferente a la de recode(). recode() utiliza OLD = NEW, mientras que fct_recode() utiliza NEW = OLD.\nLos niveles actuales de delay_cat son:\n\nlevels(linelist$delay_cat)\n\n[1] \"&lt;2 days\"  \"2-5 days\" \"&gt;5 days\" \n\n\nLos nuevos niveles se crean utilizando la sintaxis fct_recode(column, \"new\" = \"old\", \"new\" = \"old\", \"new\" = \"old\") y se imprimen:\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"&lt;2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 2 days 2990 0.50781250     0.5308949\n      2 to 5 days 2040 0.34646739     0.3622159\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\nAquí se combinan manualmente con fct_recode(). Obsérvese que no se produce ningún error en la creación de un nuevo nivel “Menos de 5 días”.\n\nlinelist %&gt;% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"&lt;2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \"&gt;5 days\")) %&gt;% \n  tabyl(delay_cat)\n\n        delay_cat    n    percent valid_percent\n Less than 5 days 5030 0.85427989     0.8931108\n More than 5 days  602 0.10224185     0.1068892\n             &lt;NA&gt;  256 0.04347826            NA\n\n\n\n\nReducir a “Otros”\nPuedes utilizar fct_other() para asignar manualmente niveles de factor a un nivel “Otro”. A continuación, todos los niveles de la columna hospital, aparte de “Port Hospital” y “Central Hospital”, se combinan en “Otros”. Puedes proporcionar el vector keep =, o drop = para mantener o eliminarlo. Puedes cambiar la visualización del nivel “Otro” con other_level =.\n\nlinelist %&gt;%    \n  mutate(hospital = fct_other(                      # ajustar niveles\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # mantenerlos separados\n    other_level = \"Other Hospital\")) %&gt;%            # Todos los demás como \"Other Hospital\"\n  tabyl(hospital)                                   # imprimir tabla\n\n         hospital    n    percent\n Central Hospital  454 0.07710598\n    Port Hospital 1762 0.29925272\n   Other Hospital 3672 0.62364130\n\n\n\n\nReducir por frecuencia\nPuedes combinar los niveles del factor menos frecuente automáticamente utilizando fct_lump().\nPara “agrupar” muchos niveles de baja frecuencia en un grupo “Otros”, puedes hacer una de las siguientes cosas:\n\nEstablecer con n = el número de grupos que deseas conservar. Los n niveles más frecuentes se mantendrán, y todos los demás se combinarán en “Otros”.\nFijar con prop = la proporción de frecuencia del umbral para los niveles por encima de los cuales deseas mantener. Todos los demás valores se combinarán en “Otros”.\n\nPuedes cambiar la visualización del nivel “Otros” con other_level =. A continuación, todos los hospitales excepto los dos más frecuentes se combinan en “Other hospitals”.\n\nlinelist %&gt;%    \n  mutate(hospital = fct_lump(                       # ajustar niveles\n    hospital,\n    n = 2,                                          # mantener los 2 niveles superiores\n    other_level = \"Other Hospital\")) %&gt;%            # todos los demás como  \"Other Hospital\"\n  tabyl(hospital)                                   # imprimir tabla\n\n       hospital    n   percent\n        Missing 1469 0.2494905\n  Port Hospital 1762 0.2992527\n Other Hospital 2657 0.4512568",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#show-all-levels",
    "href": "new_pages/factors.es.html#show-all-levels",
    "title": "11  Factores",
    "section": "11.7 Mostrar todos los niveles",
    "text": "11.7 Mostrar todos los niveles\nUna de las ventajas del uso de factores es la estandarización del aspecto de las leyendas de los gráficos y de las tablas, independientemente de los valores que estén realmente presentes en unos datos.\nSi estás preparando muchas figuras (por ejemplo, para varias jurisdicciones), querrás que las leyendas y las tablas aparezcan de forma idéntica incluso con distintos niveles de cumplimentación o de composición de los datos.\n\nEn los gráficos\nEn una figura ggplot(), basta con añadir el argumento drop = FALSE en la función scale_xxxx() correspondiente. Se mostrarán todos los niveles de los factores, independientemente de si están presentes en los datos. Si sus niveles de columna de factores se muestran con fill =, entonces en scale_fill_discrete() incluye drop = FALSE, como se muestra a continuación. Si sus niveles se muestran con x = (al eje-x) color = o size =, deberás establecer esto con scale_color_discrete() o scale_size_discrete() según corresponda.\nEste ejemplo es un gráfico de barras apiladas de la categoría de edad, por hospital. Añadiendo scale_fill_discrete(drop = FALSE) se garantiza que todos los grupos de edad aparezcan en la leyenda, aunque no estén presentes en los datos.\n\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # mostrar todos los grupos de edad en la leyenda, incluso los que no están presentes\n  labs(\n    title = \"All age groups will appear in legend, even if not present in data\")\n\n\n\n\n\n\n\n\n\n\nEn tablas\nTanto table() de R base como tabyl() de janitor mostrarán todos los niveles de los factores (incluso los no utilizados).\nSi utilizas count() o summarise() de dplyr para hacer una tabla, añade el argumento .drop = FALSE para incluir los recuentos de todos los niveles del factor, incluso los no utilizados.\nPuedes leer más en la página de tablas descriptivas, o en la documentación de scale_discrete, o en la documentación de count(). Puedes ver otro ejemplo en la página de rastreo de contactos.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#epiweeks",
    "href": "new_pages/factors.es.html#epiweeks",
    "title": "11  Factores",
    "section": "11.8 Epiweeks",
    "text": "11.8 Epiweeks\nPor favor, consulta la extensa discusión sobre cómo crear semanas epidemiológicas en la página de Agrupar datos.\\ Consulta también la página Trabajar con fechas para obtener consejos sobre cómo crear y dar formato a las semanas epidemiológicas.\n\nEpiweeks en un gráfico\nSi tu objetivo es crear epiweeks para mostrarlos en un gráfico, puedes hacerlo simplemente con floor_date() de lubridate, como se explica en la página de Agrupar datos. Los valores devueltos serán del tipo Date con el formato YYYY-MM-DD. Si utilizas esta columna en un gráfico, las fechas se ordenarán correctamente de forma natural, y no tendrá que preocuparse de los niveles o de la conversión al tipo Factor. Mira el histograma ggplot() de las fechas de inicio más abajo.\nEn este enfoque, se puede ajustar la visualización de las fechas en un eje con scale_x_date(). Consulta la página sobre curvas epidémicas para obtener más información. Puedes especificar un formato de visualización “strptime” al argumento date_labels = de scale_x_date(). Estos formatos utilizan marcadores de posición “%” y se tratan en la página Trabajar con fechas. Utiliza “%Y” para representar un año de 4 dígitos, y “%W” o “%U” para representar el número de la semana (semana del lunes o del domingo respectivamente).\n\nlinelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %&gt;%  # crear columna week (semana)\n  ggplot()+                                                  # iniciar ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histograma de la fecha de inicio\n  scale_x_date(date_labels = \"%Y-W%W\")                       # ajustar la distribución de fechas para que sea YYYY-WWw\n\n\n\n\n\n\n\n\n\n\nEpiweeks en los datos\nSin embargo, si tu propósito al factorizar no es hacer gráficos, puedes enfocar esto de dos maneras:\n\nPara un control preciso de la visualización, convierte la columna de la semana-epi lubrificada (AAAA-MM-DD) al formato de visualización deseado (AAAA-WWw) dentro del propio dataframe, y luego conviértala en tipo Factor.\n\nEn primer lugar, utiliza format() para convertir la visualización de la fecha de YYYY-MM-DD a YYYY-Www (consulta la página Trabajar con fechas). En este proceso el tipo será convertida a carácter. A continuación, convierta de carácter a tipo Factor con factor().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # crear epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convertirla para mostrar (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convertir en factor\n\n# Mostrar niveles\nlevels(linelist$epiweek_formatted)\n\n [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\"\n [7] \"2014-W19\" \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\"\n[13] \"2014-W25\" \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\"\n[19] \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\" \"2014-W35\" \"2014-W36\"\n[25] \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\" \"2014-W41\" \"2014-W42\"\n[31] \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\" \"2014-W48\"\n[37] \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\"\n[43] \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\"\n[49] \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\"\n[55] \"2015-W15\" \"2015-W16\"\n\n\nPELIGRO: Si colocas las semanas por delante de los años (“Www-YYY”) (“%W-%Y”), la ordenación por defecto del nivel alfanumérico será incorrecta (por ejemplo, 01-2015 estará antes que 35-2014). Podría ser necesario ajustar manualmente el orden, lo que sería un proceso largo y doloroso. \n\nPara una visualización rápida por defecto, utiliza el paquete aweek y su función date2week(). Puedes establecer el día de comienzo con week_start =, y si estableces factor = TRUE entonces la columna de salida es un factor ordenado. Como ventaja, el factor incluye niveles para todas las semanas posibles en el lapso - incluso si no hay casos esa semana.\n\n\ndf &lt;- linelist %&gt;% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)\n\nConsulta la página Trabajar con fechas para obtener más información sobre aweek. También ofrece la función inversa week2date().",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/factors.es.html#resources-4",
    "href": "new_pages/factors.es.html#resources-4",
    "title": "11  Factores",
    "section": "11.9 Recursos",
    "text": "11.9 Recursos\nPágina de R for Data Science en español sobre factores viñeta del paquete aweek",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.es.html",
    "href": "new_pages/pivoting.es.html",
    "title": "12  Pivotar datos",
    "section": "",
    "text": "12.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pivotar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.es.html#preparation-3",
    "href": "new_pages/pivoting.es.html#preparation-3",
    "title": "12  Pivotar datos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,          # Importación de ficheros\n  here,         # Localizador de archivos\n  kableExtra,   # Build and manipulate complex tables\n  tidyverse)    # gestión de datos + gráficos ggplot2\n\n\n\nImportar datos\n\n\nRecuento de casos de malaria\nEn esta página, utilizaremos unos datos ficticios de casos diarios de malaria, por centro y grupo de edad. Si quieres seguirlo, clica aquí para descargarlo (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).\n\n# Import data\ncount_data &lt;- import(\"malaria_facility_count_data.rds\")\n\nA continuación se muestran las primeras 50 filas.\n\n\n\n\n\n\n\n\nListado de casos de Linelist\nEn la parte posterior de esta página, también utilizaremos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aqui para descargar linelist “limpio” (como archivo .rds). Importa tus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - mira la página de importación y exportación para más detalles).\n\n# importar tus datos\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pivotar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.es.html#wide-to-long",
    "href": "new_pages/pivoting.es.html#wide-to-long",
    "title": "12  Pivotar datos",
    "section": "12.2 De ancho a largo",
    "text": "12.2 De ancho a largo\n\n\n\n\n\n\n\n\n\n\n\n“Formato ancho”\nLos datos suelen introducirse y almacenarse en un formato “amplio”, en el que las características o respuestas de un sujeto se almacenan en una sola fila. Aunque esto puede ser útil para la presentación, no es ideal para algunos tipos de análisis.\nTomemos como ejemplo el set de datos count_data importado en la sección “Preparación”. Puedes ver que cada fila representa un “centro-día”. Los recuentos de casos reales (las columnas más a la derecha) se almacenan en un formato “ancho”, de modo que la información de cada grupo de edad en un día determinado del centro se almacena en una sola fila.\n\n\n\n\n\n\nCada observación de este conjunto de datos se refiere a los recuentos de paludismo en una de las 65 instalaciones en una fecha determinada, que va desde count_data$data_date %\\&gt;% min() hasta count_data$data_date %\\&gt;% max(). Estas instalaciones están situadas en una Province (Norte) y cuatro District (Spring, Bolo, Dingo y Barnard). Los datos proporcionan los recuentos globales de malaria, así como los recuentos específicos por edad en cada uno de los tres grupos de edad: &lt;4 años, 5-14 años y 15 años o más.\nLos datos “anchos” como éste no se ajustan a las normas de “datos ordenados”, porque los encabezados de las columnas no representan realmente “variables”, sino que representan valores de una hipotética variable “grupo de edad”.\nEste formato puede ser útil para presentar la información en una tabla, o para introducir datos (por ejemplo, en Excel) a partir de formularios de informes de casos. Sin embargo, en la etapa de análisis, estos datos normalmente deben ser transformados a un formato “largo” más alineado con los estándares de “datos ordenados”. El paquete ggplot2, en particular, funciona mejor cuando los datos están en un formato “largo”.\nLa visualización de los recuentos totales de malaria a lo largo del tiempo no plantea ninguna dificultad con los datos en su formato actual:\n\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)\n\n\n\n\n\n\n\n\nSin embargo, ¿qué pasaría si quisiéramos mostrar las contribuciones relativas de cada grupo de edad a este recuento total? En este caso, necesitamos asegurarnos de que la variable de interés (grupo de edad), aparezca en el conjunto de datos en una sola columna que pueda pasarse a {ggplot2} el argumento aes() de “mapping aesthetics”.\n\n\n\npivot_longer()\nLa función pivot_longer() de tidyr hace que los datos sean “largos”. tidyr forma parte de los paquetes tidyverse .\nAcepta un rango de columnas para transformar (especificado a cols =). Por lo tanto, puede operar sólo en una parte de unos datos. Esto es útil para los datos de la malaria, ya que sólo queremos pivotar las columnas de recuento de casos.\nEn este proceso, terminará con dos “nuevas” columnas - una con las categorías (los antiguos nombres de las columnas), y otra con los valores correspondientes (por ejemplo, recuento de casos). Puedes aceptar los nombres por defecto para estas nuevas columnas, o puede especificar otros con names_to = y values_to = respectivamente.\nVeamos pivot_longer() en acción…\n\n\nPivoteo estándar\nQueremos utilizar la función pivot_longer() de tidyr para convertir los datos “anchos” en un formato “largo”. Concretamente, para convertir las cuatro columnas numéricas con datos sobre los recuentos de malaria en dos nuevas columnas: una que contenga los grupos de edad y otra que contenga los valores correspondientes.\n\ndf_long &lt;- count_data %&gt;% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n\nObserva que el dataframe recién creado (df_long) tiene más filas (12.152 frente a 3.038); se ha hecho más largo. De hecho, es precisamente cuatro veces más largo, porque cada fila de los datos originales representa ahora cuatro filas en df_long, una para cada una de las observaciones de recuento de malaria (&lt;4 años, 5-14 años, 15 años+ y total).\nAdemás de ser más largo, el nuevo conjunto de datos tiene menos columnas (8 frente a 10), ya que los datos que antes se almacenaban en cuatro columnas (las que empiezan por el prefijo malaria_) se almacenan ahora en dos.\nDado que los nombres de estas cuatro columnas comienzan con el prefijo malaria_, podríamos haber hecho uso de la práctica función “tidyselect” starts_with() para conseguir el mismo resultado (véase la página Limpieza de datos y funciones básicas para conocer más sobre estas funciones de ayuda).\n\n# proporcionar a la columna una función de ayuda tidyselect\ncount_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid name    value\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    11\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    12\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    23\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malari…    46\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    11\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    10\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…     5\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malari…    26\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     8\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malari…     5\n# ℹ 12,142 more rows\n\n\no por posición:\n\n# proporcionar columnas por posición\ncount_data %&gt;% \n  pivot_longer(\n    cols = 6:9\n  )\n\no por rango de nombres:\n\n# proporcionar rango de columnas consecutivas\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\n\nEstas dos nuevas columnas reciben los nombres por defecto de name y value, pero podemos cambiar estos valores por defecto para proporcionar nombres más significativos, que pueden ayudar a recordar lo que se almacena dentro, utilizando los argumentos names_to y values_to. Utilicemos los nombres age_group y counts:\n\ndf_long &lt;- \n  count_data %&gt;% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long\n\n# A tibble: 12,152 × 8\n   location_name data_date  submitted_date Province District newid age_group    \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;        \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_…\n 4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot  \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_…\n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot  \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_…\n# ℹ 12,142 more rows\n# ℹ 1 more variable: counts &lt;int&gt;\n\n\nAhora podemos pasar este nuevo conjunto de datos a {ggplot2}, y asignar la nueva columna count al eje-y y la nueva columna age_group al argumento fill = (el color interno de la columna). Esto mostrará los recuentos de malaria en un gráfico de barras apilado, por grupo de edad:\n\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nExamina esta nueva gráfica y compárala con la que hemos creado antes: ¿qué ha fallado?\nNos hemos encontrado con un problema común al manejar los datos de vigilancia: hemos incluido también los recuentos totales de la columna malaria_tot, por lo que la magnitud de cada barra en el gráfico es el doble de lo que debería ser.\nPodemos manejar esto de varias maneras. Podríamos simplemente filtrar estos totales en los datos antes de pasarlo a ggplot():\n\ndf_long %&gt;% \n  filter(age_group != \"malaria_tot\") %&gt;% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\n\n\n\n\n\n\n\n\nComo alternativa, podríamos haber excluido esta variable al ejecutar pivot_longer(), manteniéndola así en set de datos como una variable independiente. Observa cómo se “expanden” sus valores para llenar las nuevas filas.\n\ncount_data %&gt;% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # no incluye la columna de totales\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\n# A tibble: 9,114 × 9\n   location_name data_date  submitted_date Province District malaria_tot newid\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt; &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1\n 4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2\n 7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3\n10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4\n# ℹ 9,104 more rows\n# ℹ 2 more variables: age_group &lt;chr&gt;, counts &lt;int&gt;\n\n\n\n\nPivotear datos de múltiples tipos\nEl ejemplo anterior funciona bien en situaciones en las que todas las columnas que se quieren “pivotar más” son del mismo tipo (carácter, numérico, lógico…).\nSin embargo, habrá muchos casos en los que, en el trabajo de campo, se trabaje con datos preparados por personas no especializadas y que sigan su propia lógica no estándar - como señaló Hadley Wickham (haciendo referencia a Tolstoi) en su artículo seminal sobre los principios de Tidy Data: “Como las familias, los conjuntos de datos ordenados son todos iguales, pero cada conjunto de datos desordenado es desordenado a su manera”.\nUn problema particularmente común que encontrarás será la necesidad de pivotar columnas que contienen diferentes tipos de datos. Este pivote resultará en el almacenamiento de estos diferentes tipos de datos en una sola columna, lo cual no es una buena situación. Se pueden seguir varios enfoques para separar el desorden que esto crea, pero hay un paso importante que puedes seguir usando pivot_longer() para evitar crear tal situación tu mismo.\nTomemos una situación en la que ha habido una serie de observaciones en diferentes pasos de tiempo para cada uno de los tres elementos A, B y C. Ejemplos de estos elementos podrían ser individuos (por ejemplo, contactos de un caso de ébola que se rastrean cada día durante 21 días) o puestos de salud de aldeas remotas que se supervisan una vez al año para garantizar que siguen funcionando. Utilicemos el ejemplo del rastreo de contactos. Imaginemos que los datos se almacenan de la siguiente manera:\n\n\n\n\n\n\nComo puede verse, los datos son un poco complicados. Cada fila almacena información sobre un elemento, pero con la serie temporal cada vez más alejada hacia la derecha a medida que avanza el tiempo. Además, los tipos de columnas alternan entre valores de fecha y caracteres.\nUn ejemplo particularmente malo que encontró este autor fue el de los datos de vigilancia del cólera, en el que se añadieron 8 nuevas columnas de observaciones cada día en el transcurso de 4 años. El simple hecho de abrir el archivo de Excel en el que se almacenaban estos datos me llevó más de 10 minutos en mi ordenador portátil.\nPara trabajar con estos datos, necesitamos transformar el dataframe a formato largo, pero manteniendo la separación entre una columna date y una columna de character (estado), para cada observación de cada elemento. Si no lo hacemos, podríamos terminar con una mezcla de tipos de variables en una sola columna (un gran “no-no” cuando se trata de gestión de datos y de datos ordenados):\n\ndf %&gt;% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\")\n  )\n\n# A tibble: 18 × 3\n   id    observation value     \n   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;     \n 1 A     obs1_date   2021-04-23\n 2 A     obs1_status Healthy   \n 3 A     obs2_date   2021-04-24\n 4 A     obs2_status Healthy   \n 5 A     obs3_date   2021-04-25\n 6 A     obs3_status Unwell    \n 7 B     obs1_date   2021-04-23\n 8 B     obs1_status Healthy   \n 9 B     obs2_date   2021-04-24\n10 B     obs2_status Healthy   \n11 B     obs3_date   2021-04-25\n12 B     obs3_status Healthy   \n13 C     obs1_date   2021-04-23\n14 C     obs1_status Missing   \n15 C     obs2_date   2021-04-24\n16 C     obs2_status Healthy   \n17 C     obs3_date   2021-04-25\n18 C     obs3_status Healthy   \n\n\nArriba, nuestro pivote ha fusionado fechas y caracteres en una sola columna de value. R reaccionará convirtiendo toda la columna en tipo carácter, y se pierde la utilidad de las fechas.\nPara evitar esta situación, podemos aprovechar la estructura sintáctica de los nombres de las columnas originales. Hay una estructura de nombres común, con el número de observación, un guión bajo, y luego “estado” o “fecha”. Podemos aprovechar esta sintaxis para mantener estos dos tipos de datos en columnas separadas después del pivote.\nPara ello:\n\nProporcionar un vector de caracteres al argumento names_to =, siendo el segundo elemento (\".value\"). Este término especial indica que las columnas pivotadas se dividirán basándose en un carácter de su nombre…\nTambién se debe proporcionar el carácter de “división” al argumento names_sep =. En este caso, es el guión bajo “_“.\n\nAsí, la denominación y división de las nuevas columnas se basa en el guión bajo de los nombres de las variables existentes.\n\ndf_long &lt;- \n  df %&gt;% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  \n1 A     obs1        2021-04-23 Healthy\n2 A     obs2        2021-04-24 Healthy\n3 A     obs3        2021-04-25 Unwell \n4 B     obs1        2021-04-23 Healthy\n5 B     obs2        2021-04-24 Healthy\n6 B     obs3        2021-04-25 Healthy\n7 C     obs1        2021-04-23 Missing\n8 C     obs2        2021-04-24 Healthy\n9 C     obs3        2021-04-25 Healthy\n\n\nToques finales:\nTen en cuenta que la columna de fecha es actualmente de tipo carácter - podemos convertirla fácilmente en tipo fecha utilizando las funciones mutate() y as_date() descritas en la página Trabajar con fechas.\nTambién podemos convertir la columna de observation a un formato numeric eliminando el prefijo “obs” y convirtiendo a numérico. Podemos hacer esto con str_remove_all() del paquete stringr (véase la página Caracteres y cadenas).\n\ndf_long &lt;- \n  df_long %&gt;% \n  mutate(\n    date = date %&gt;% lubridate::as_date(),\n    observation = \n      observation %&gt;% \n      str_remove_all(\"obs\") %&gt;% \n      as.numeric()\n  )\n\ndf_long\n\n# A tibble: 9 × 4\n  id    observation date       status \n  &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;  \n1 A               1 2021-04-23 Healthy\n2 A               2 2021-04-24 Healthy\n3 A               3 2021-04-25 Unwell \n4 B               1 2021-04-23 Healthy\n5 B               2 2021-04-24 Healthy\n6 B               3 2021-04-25 Healthy\n7 C               1 2021-04-23 Missing\n8 C               2 2021-04-24 Healthy\n9 C               3 2021-04-25 Healthy\n\n\nY ahora, podemos empezar a trabajar con los datos en este formato, por ejemplo, trazando un mosaico de calor descriptivo:\n\nggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\" = \"red\", \n        \"Missing\" = \"orange\")\n  )",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pivotar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.es.html#long-to-wide",
    "href": "new_pages/pivoting.es.html#long-to-wide",
    "title": "12  Pivotar datos",
    "section": "12.3 De largo a ancho",
    "text": "12.3 De largo a ancho\n\n\n\n\n\n\n\n\n\nEn algunos casos, es posible que queramos convertir unos datos a un formato ancho. Para ello, podemos utilizar la función pivot_wider().\nUn caso de uso típico es cuando queremos transformar los resultados de un análisis en un formato que sea más digerible para el lector (como una tabla para su presentación). Por lo general, se trata de transformar unos datos en el que la información de un sujeto está repartida en varias filas en un formato en el que esa información se almacena en una sola fila.\n\nDatos\nPara esta sección de la página, utilizaremos la lista de casos (véase la sección Preparación), que contiene una fila por caso.\nAquí están las primeras 50 filas:\n\n\n\n\n\n\nSupongamos que queremos conocer los recuentos de individuos en los diferentes grupos de edad, por género:\n\ndf_wide &lt;- \n  linelist %&gt;% \n  count(age_cat, gender)\n\ndf_wide\n\n   age_cat gender   n\n1      0-4      f 640\n2      0-4      m 416\n3      0-4   &lt;NA&gt;  39\n4      5-9      f 641\n5      5-9      m 412\n6      5-9   &lt;NA&gt;  42\n7    10-14      f 518\n8    10-14      m 383\n9    10-14   &lt;NA&gt;  40\n10   15-19      f 359\n11   15-19      m 364\n12   15-19   &lt;NA&gt;  20\n13   20-29      f 468\n14   20-29      m 575\n15   20-29   &lt;NA&gt;  30\n16   30-49      f 179\n17   30-49      m 557\n18   30-49   &lt;NA&gt;  18\n19   50-69      f   2\n20   50-69      m  91\n21   50-69   &lt;NA&gt;   2\n22     70+      m   5\n23     70+   &lt;NA&gt;   1\n24    &lt;NA&gt;   &lt;NA&gt;  86\n\n\nEsto nos da un largo conjunto de datos que es genial para producir visualizaciones en ggplot2, pero no es ideal para la presentación en una tabla:\n\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))\n\n\n\n\n\n\n\n\n\n\nPivote ancho\nPor lo tanto, podemos utilizar pivot_wider() para transformar los datos en un formato mejor para incluirlos como tablas en nuestros informes.\nEl argumento names_from especifica la columna from que genera la columna nueva names, mientras que el argumento values_from especifica la columna from de la que tomar los values para rellenar las celdas. El argumento id_cols = es opcional, pero se puede proporcionar un vector de nombres de columnas que no deben ser pivotadas, y que por tanto identificarán cada fila.\n\ntable_wide &lt;- \n  df_wide %&gt;% \n  pivot_wider(\n    id_cols = age_cat,\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide\n\n# A tibble: 9 × 4\n  age_cat     f     m  `NA`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 0-4       640   416    39\n2 5-9       641   412    42\n3 10-14     518   383    40\n4 15-19     359   364    20\n5 20-29     468   575    30\n6 30-49     179   557    18\n7 50-69       2    91     2\n8 70+        NA     5     1\n9 &lt;NA&gt;       NA    NA    86\n\n\nEsta tabla es mucho más fácil de leer y, por tanto, mejor para incluirla en nuestros informes. Se puede convertir en una tabla bonita con varios paquetes, como flextable y knitr. Este proceso se elabora en la página Tablas para presentaciones.\n\ntable_wide %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% # adds row and column totals\n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 10, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nage_cat\nf\nm\nNA\nTotal\n\n\n\n\n0-4\n640\n416\n39\n1095\n\n\n5-9\n641\n412\n42\n1095\n\n\n10-14\n518\n383\n40\n941\n\n\n15-19\n359\n364\n20\n743\n\n\n20-29\n468\n575\n30\n1073\n\n\n30-49\n179\n557\n18\n754\n\n\n50-69\n2\n91\n2\n95\n\n\n70+\nNA\n5\n1\n6\n\n\nNA\nNA\nNA\n86\n86\n\n\nTotal\n2807\n2803\n278\n5888",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pivotar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.es.html#fill",
    "href": "new_pages/pivoting.es.html#fill",
    "title": "12  Pivotar datos",
    "section": "12.4 Rellenar",
    "text": "12.4 Rellenar\nEn algunas situaciones después de pivotar, y más comúnmente después de unir con bind, nos quedan huecos en algunas celdas que nos gustaría rellenar.\n\n\nDatos\nPor ejemplo, toma dos conjuntos de datos, cada uno con observaciones para el número de medición, el nombre del centro y el recuento de casos en ese momento. Sin embargo, el segundo conjunto de datos también tiene la variable Year.\n\ndf1 &lt;- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 \n\n# A tibble: 9 × 3\n  Measurement Facility Cases\n        &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1           1 Hosp 1      66\n2           2 Hosp 1      26\n3           3 Hosp 1       8\n4           1 Hosp 2      71\n5           2 Hosp 2      62\n6           3 Hosp 2      70\n7           1 Hosp 3      47\n8           2 Hosp 3      70\n9           3 Hosp 3      38\n\ndf2 &lt;- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2\n\n# A tibble: 3 × 4\n   Year Measurement Facility Cases\n  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1  2000           1 Hosp 4      82\n2  2001           2 Hosp 4      87\n3  2002           3 Hosp 4      46\n\n\nCuando realizamos un bind_rows() para unir los dos conjuntos de datos, la variable Year se rellena con NA para aquellas filas en las que no había información previa (es decir, el primer conjunto de datos):\n\ndf_combined &lt;- \n  bind_rows(df1, df2) %&gt;% \n  arrange(Measurement, Facility)\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66    NA\n 2           1 Hosp 2      71    NA\n 3           1 Hosp 3      47    NA\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26    NA\n 6           2 Hosp 2      62    NA\n 7           2 Hosp 3      70    NA\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8    NA\n10           3 Hosp 2      70    NA\n11           3 Hosp 3      38    NA\n12           3 Hosp 4      46  2002\n\n\n\n\n\nfill()\nEn este caso, Year es una variable útil para incluir, especialmente si queremos explorar las tendencias a lo largo del tiempo. Por lo tanto, utilizamos fill() para rellenar esas celdas vacías, especificando la columna a rellenar y la dirección (en este caso hacia arriba):\n\ndf_combined %&gt;% \n  fill(Year, .direction = \"up\")\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 1      66  2000\n 2           1 Hosp 2      71  2000\n 3           1 Hosp 3      47  2000\n 4           1 Hosp 4      82  2000\n 5           2 Hosp 1      26  2001\n 6           2 Hosp 2      62  2001\n 7           2 Hosp 3      70  2001\n 8           2 Hosp 4      87  2001\n 9           3 Hosp 1       8  2002\n10           3 Hosp 2      70  2002\n11           3 Hosp 3      38  2002\n12           3 Hosp 4      46  2002\n\n\nAlternativamente, podemos reordenar los datos para que tengamos que rellenar en sentido descendente:\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  arrange(Measurement, desc(Facility))\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47    NA\n 3           1 Hosp 2      71    NA\n 4           1 Hosp 1      66    NA\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70    NA\n 7           2 Hosp 2      62    NA\n 8           2 Hosp 1      26    NA\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38    NA\n11           3 Hosp 2      70    NA\n12           3 Hosp 1       8    NA\n\ndf_combined &lt;- \n  df_combined %&gt;% \n  fill(Year, .direction = \"down\")\n\ndf_combined\n\n# A tibble: 12 × 4\n   Measurement Facility Cases  Year\n         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1           1 Hosp 4      82  2000\n 2           1 Hosp 3      47  2000\n 3           1 Hosp 2      71  2000\n 4           1 Hosp 1      66  2000\n 5           2 Hosp 4      87  2001\n 6           2 Hosp 3      70  2001\n 7           2 Hosp 2      62  2001\n 8           2 Hosp 1      26  2001\n 9           3 Hosp 4      46  2002\n10           3 Hosp 3      38  2002\n11           3 Hosp 2      70  2002\n12           3 Hosp 1       8  2002\n\n\nAhora tenemos unos datos útiles para representarlos gráficamente:\n\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\n\n\n\n\n\n\n\n\nPero es menos útil para presentarlo en una tabla, así que practiquemos la conversión de este largo y desordenado dataframe en un dataframe ancho y ordenado:\n\ndf_combined %&gt;% \n  pivot_wider(\n    id_cols = c(Measurement, Facility),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  arrange(Facility) %&gt;% \n  janitor::adorn_totals(c(\"row\", \"col\")) %&gt;% \n  knitr::kable() %&gt;% \n  kableExtra::row_spec(row = 5, bold = TRUE) %&gt;% \n  kableExtra::column_spec(column = 5, bold = TRUE) \n\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\nTotal\n\n\n\n\n1\nHosp 1\n66\nNA\nNA\n66\n\n\n2\nHosp 1\nNA\n26\nNA\n26\n\n\n3\nHosp 1\nNA\nNA\n8\n8\n\n\n1\nHosp 2\n71\nNA\nNA\n71\n\n\n2\nHosp 2\nNA\n62\nNA\n62\n\n\n3\nHosp 2\nNA\nNA\n70\n70\n\n\n1\nHosp 3\n47\nNA\nNA\n47\n\n\n2\nHosp 3\nNA\n70\nNA\n70\n\n\n3\nHosp 3\nNA\nNA\n38\n38\n\n\n1\nHosp 4\n82\nNA\nNA\n82\n\n\n2\nHosp 4\nNA\n87\nNA\n87\n\n\n3\nHosp 4\nNA\nNA\n46\n46\n\n\nTotal\n-\n266\n245\n162\n673\n\n\n\n\n\n\n\n\nN.B. En este caso, tuvimos que especificar que sólo se incluyeran las tres variables Facility, Year, y Cases, ya que la variable adicional Measurement interferiría en la creación de la tabla:\n\ndf_combined %&gt;% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %&gt;% \n  knitr::kable()\n\n\n\n\nMeasurement\nFacility\n2000\n2001\n2002\n\n\n\n\n1\nHosp 4\n82\nNA\nNA\n\n\n1\nHosp 3\n47\nNA\nNA\n\n\n1\nHosp 2\n71\nNA\nNA\n\n\n1\nHosp 1\n66\nNA\nNA\n\n\n2\nHosp 4\nNA\n87\nNA\n\n\n2\nHosp 3\nNA\n70\nNA\n\n\n2\nHosp 2\nNA\n62\nNA\n\n\n2\nHosp 1\nNA\n26\nNA\n\n\n3\nHosp 4\nNA\nNA\n46\n\n\n3\nHosp 3\nNA\nNA\n38\n\n\n3\nHosp 2\nNA\nNA\n70\n\n\n3\nHosp 1\nNA\nNA\n8",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pivotar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/pivoting.es.html#resources-5",
    "href": "new_pages/pivoting.es.html#resources-5",
    "title": "12  Pivotar datos",
    "section": "12.5 Recursos",
    "text": "12.5 Recursos\nAquí hay un tutorial útil",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pivotar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html",
    "href": "new_pages/grouping.es.html",
    "title": "13  Agrupar datos",
    "section": "",
    "text": "13.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#preparation-4",
    "href": "new_pages/grouping.es.html#preparation-4",
    "title": "13  Agrupar datos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código (chunk) muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,       # para importar datos\n  here,      # para identificar las carpetas donde se encuentran\n  tidyverse, # para limpiar, manipular y dibujar los datos (incluye dplyr)\n  janitor)   # para añadir totales en las filas y columnas\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguirlo, clica para descargar linelist “limpio” (como archivo .rds). Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.\n#{r, eval=F} #linelist &lt;- import(\"linelist_cleaned.rds\") #\nLas primeras 50 filas de linelist:",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#grouping",
    "href": "new_pages/grouping.es.html#grouping",
    "title": "13  Agrupar datos",
    "section": "13.2 Agrupar",
    "text": "13.2 Agrupar\nLa función group_by() de dplyr agrupa las filas por los valores únicos de la columna que se le especifica. Si se especifican varias columnas, las filas se agrupan por las combinaciones únicas de valores entre las columnas. Cada valor único (o combinación de valores) constituye un grupo. Los cambios posteriores en los datos o los cálculos pueden realizarse en el contexto de cada grupo.\nPor ejemplo, el siguiente comando toma linelist y agrupa las filas por valores únicos en la columna outcome, guardando la salida como un nuevo dataframe ll_by_outcome. La(s) columna(s) de agrupación se colocan dentro de los paréntesis de la función group_by().\n\nll_by_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\nTen en cuenta que no hay ningún cambio perceptible en los datos después de ejecutar group_by(), hasta que se aplique otro verbo de dplyr como mutate(), summarise(), o arrange() en el dataframe “agrupado”.\nSin embargo, puedes “ver” las agrupaciones imprimiendo el dataframe. Al imprimir un dataframe agrupado, verás que se ha transformado en un objeto de clase tibble que, al imprimirse, muestra qué agrupaciones se han aplicado y cuántos grupos están -escritos justo encima de la fila de cabecera.\n\n# print para ver los grupos que están activos\nll_by_outcome\n\n# A tibble: 5,888 × 30\n# Groups:   outcome [3]\n   case_id generation date_infection date_onset date_hospitalisation\n   &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;              \n 1 5fe599           4 2014-05-08     2014-05-13 2014-05-15          \n 2 8689b7           4 NA             2014-05-13 2014-05-14          \n 3 11f8ea           2 NA             2014-05-16 2014-05-18          \n 4 b8812a           3 2014-05-04     2014-05-18 2014-05-20          \n 5 893f25           3 2014-05-18     2014-05-21 2014-05-22          \n 6 be99c8           3 2014-05-03     2014-05-22 2014-05-23          \n 7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29          \n 8 369449           4 2014-05-28     2014-06-02 2014-06-03          \n 9 f393b4           4 NA             2014-06-05 2014-06-06          \n10 1389ca           4 NA             2014-06-05 2014-06-07          \n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_outcome &lt;date&gt;, outcome &lt;chr&gt;, gender &lt;chr&gt;,\n#   age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;,\n#   hospital &lt;chr&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;,\n#   wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;,\n#   cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;,\n#   bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\nGrupos únicos\nLos grupos creados reflejan cada combinación única de valores en las columnas de agrupación.\nPara ver los grupos y el número de filas en cada grupo, pasa los datos agrupados a tally(). Para ver sólo los grupos únicos sin recuento puedes pasárselos a group_keys().\nMira a continuación que hay tres valores únicos en el resultado de la columna outcome: “Death”, “Recover”, y NA. Fíjate que hubo nrow(linelist %\\&gt;% filter(outcome == \"Death\")) muertes, nrow(linelist %\\&gt;% filter(outcome == \"Recover\")) recuperaciones, y nrow(linelist %\\&gt;% filter(is.na(outcome)) sin resultado registrado.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally()\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\nSe puede agrupar por más de una columna. A continuación, el dataframe se agrupa por outcome y gender, y luego se cuenta. Observa cómo cada combinación única de outcome y gender se registra como su propio grupo, incluyendo los valores faltantes para cualquier columna.\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally()\n\n# A tibble: 9 × 3\n# Groups:   outcome [3]\n  outcome gender     n\n  &lt;chr&gt;   &lt;chr&gt;  &lt;int&gt;\n1 Death   f       1227\n2 Death   m       1228\n3 Death   &lt;NA&gt;     127\n4 Recover f        953\n5 Recover m        950\n6 Recover &lt;NA&gt;      80\n7 &lt;NA&gt;    f        627\n8 &lt;NA&gt;    m        625\n9 &lt;NA&gt;    &lt;NA&gt;      71\n\n\n\n\nColumnas nuevas\nTambién puedes crear una nueva columna de agrupación dentro de la sentencia group_by(). Esto equivale a llamar a mutate() antes de group_by(). Para una tabulación rápida este estilo puede ser útil, pero para una mayor claridad en el código mejor crear esta columna en su propio paso mutate() y luego canalizarla a group_by().\n\n# agrupar datos en base a una columna binaria creada *dentro* del comando group_by()\nlinelist %&gt;% \n  group_by(\n    age_class = ifelse(age &gt;= 18, \"adult\", \"child\")) %&gt;% \n  tally(sort = T)\n\n# A tibble: 3 × 2\n  age_class     n\n  &lt;chr&gt;     &lt;int&gt;\n1 child      3618\n2 adult      2184\n3 &lt;NA&gt;         86\n\n\n\n\nAñadir/descartar columnas de agrupación\nPor defecto, si ejecutas group_by() sobre datos que ya están agrupados, se eliminarán los grupos antiguos y se aplicarán los nuevos. Si deseas añadir nuevos grupos a los existentes, incluye el argumento .add = TRUE.\n\n# Agrupado por outcome (resultado)\nby_outcome &lt;- linelist %&gt;% \n  group_by(outcome)\n\n# Además añadir agrupación por género \nby_outcome_gender &lt;- by_outcome %&gt;% \n  group_by(gender, .add = TRUE)\n\n** Mantener todos los grupos**\nSi se agrupa en una columna de tipo factor, puede haber niveles del factor que no estén presentes en los datos. Si agrupas en esta columna, por defecto esos niveles no presentes se descartan y no se incluyen como grupos. Para cambiar esto de manera que todos los niveles aparezcan como grupos (incluso si no están presentes en los datos), escribe .drop = FALSE en su comando group_by().",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#un-group",
    "href": "new_pages/grouping.es.html#un-group",
    "title": "13  Agrupar datos",
    "section": "13.3 Des-agrupar",
    "text": "13.3 Des-agrupar\nLos datos que han sido agrupados permanecerán agrupados hasta que sean específicamente desagrupados mediante ungroup(). Si se olvida desagrupar, puede dar lugar a cálculos incorrectos. A continuación se muestra un ejemplo de eliminación de todas las agrupaciones:\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup()\n\nTambién puedes eliminar la agrupación sólo para columnas específicas, colocando el nombre de la columna dentro de ungroup().\n\nlinelist %&gt;% \n  group_by(outcome, gender) %&gt;% \n  tally() %&gt;% \n  ungroup(gender) # eliminar la agrupación por género, dejar la agrupación por resultado\n\nNOTA: El verbo count() desagrupa automáticamente los datos después del recuento.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#group_summarise",
    "href": "new_pages/grouping.es.html#group_summarise",
    "title": "13  Agrupar datos",
    "section": "13.4 Resumir",
    "text": "13.4 Resumir\nVéase la sección dplyr de la página Tablas descriptivas para una descripción detallada de cómo producir tablas de resumen con summarise(). Aquí abordamos brevemente cómo cambia su comportamiento cuando se aplica a datos agrupados.\nLa función dplyr summarise() (o summarize()) toma un dataframe y lo convierte en un nuevo dataframe de resumen, con columnas que contienen los estadísticos de resumen que definas. En un dataframe sin agrupar, las estadísticas de resumen se calcularán a partir de todas las filas. La aplicación de summarise() a los datos agrupados produce esas estadísticas de resumen para cada grupo.\nLa sintaxis de summarise() es tal que se proporciona el nombre de la(s) nueva(s) columna(s) de resumen, un signo de igualdad y, a continuación, una función estadística para aplicar a los datos, como se muestra a continuación. Por ejemplo, min(), max(), median(), o sd(). Dentro de la función estadística, indica la columna con la que se va a operar y cualquier argumento relevante (por ejemplo, na.rm = TRUE). Puedes utilizar sum() para contar el número de filas que cumplen un criterio lógico (con doble igual ==).\nA continuación se muestra un ejemplo de summarise() aplicado sin datos agrupados. Las estadísticas devueltas se producen a partir del set de datos completo.\n\n# estadísticas resumidas de linelist sin agrupar\nlinelist %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))\n\n  n_cases mean_age max_age min_age n_males\n1    5888 16.01831      84       0    2803\n\n\nPor el contrario, a continuación se muestra la misma sentencia summarise() aplicada a los datos agrupados. Las estadísticas se calculan para cada grupo de outcome. Observa cómo se trasladan las columnas de agrupación al nuevo dataframe.\n\n# estadísticas resumidas de linelist agrupados\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))\n\n# A tibble: 3 × 6\n  outcome n_cases mean_age max_age min_age n_males\n  &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;int&gt;\n1 Death      2582     15.9      76       0    1228\n2 Recover    1983     16.1      84       0     950\n3 &lt;NA&gt;       1323     16.2      69       0     625\n\n\nSUGERENCIA: La función summarise funciona tanto con la ortografía del Reino Unido como con la de EE.UU. - summarise() y summarize() llaman a la misma función.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#counts-and-tallies",
    "href": "new_pages/grouping.es.html#counts-and-tallies",
    "title": "13  Agrupar datos",
    "section": "13.5 Counts y tallies",
    "text": "13.5 Counts y tallies\ncount() y tally() proporcionan una funcionalidad similar pero son diferentes. Lee más sobre la distinción entre tally() y count() aquí\n\ntally()\ntally() es la abreviatura de summarise(n = n()), y no agrupa los datos. Por lo tanto, para lograr recuentos agrupados debe seguir un comando group_by(). Puedes añadir sort = TRUE para ver primero los grupos más grandes.\n\nlinelist %&gt;% \n  tally()\n\n     n\n1 5888\n\n\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  tally(sort = TRUE)\n\n# A tibble: 3 × 2\n  outcome     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Death    2582\n2 Recover  1983\n3 &lt;NA&gt;     1323\n\n\n\n\ncount()\nEn cambio, count() hace lo siguiente:\n\naplica group_by() a la(s) columna(s) especificada(s)\naplica summarise() y devuelve la columna n con el número de filas por grupo\naplica ungroup()\n\n\nlinelist %&gt;% \n  count(outcome)\n\n  outcome    n\n1   Death 2582\n2 Recover 1983\n3    &lt;NA&gt; 1323\n\n\nAl igual que con group_by() puedes crear una nueva columna dentro del comando count():\n\nlinelist %&gt;% \n  count(age_class = ifelse(age &gt;= 18, \"adult\", \"child\"), sort = T)\n\n  age_class    n\n1     child 3618\n2     adult 2184\n3      &lt;NA&gt;   86\n\n\nPuedes llamar varias veces a count(), con la funcionalidad “combinada”. Por ejemplo, para resumir el número de hospitales presentes para cada género, ejecuta lo siguiente. Ten en cuenta que el nombre de la columna final se ha cambiado de “n” por defecto para mayor claridad (con name  =).\n\nlinelist %&gt;% \n   # producir recuentos por grupos únicos de resultado-género\n  count(gender, hospital) %&gt;% \n  # reunir filas por género (3) y contar el número de hospitales por género (6)\n  count(gender, name = \"hospitals per gender\" ) \n\n  gender hospitals per gender\n1      f                    6\n2      m                    6\n3   &lt;NA&gt;                    6\n\n\n\n\nAñadir recuentos\nA diferencia de count() y summarise(), puedes utilizar add_count() para añadir una nueva columna n con los recuentos de filas por grupo conservando todas las demás columnas del dataframe.\nEsto significa que el número de recuentos de un grupo, en la nueva columna n, se imprimirá en cada fila del grupo. Para fines de demostración, añadimos esta columna y luego reordenamos las columnas para facilitar la visualización. Consulta la sección siguiente sobre filtrar por tamaño del grupo para ver otro ejemplo.\n\nlinelist %&gt;% \n  as_tibble() %&gt;%                   # convertir a tibble para una mejor impresión  \n  add_count(hospital) %&gt;%           # añadir la columna n con los recuentos por hospital\n  select(hospital, n, everything()) # reordenar para fines de demostración\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\nAñadir totales\nPara añadir fácilmente filas o columnas del total de la suma después de utilizar tally() o count(), consulta la sección de janitor de la página Tablas descriptivas. Este paquete ofrece funciones como adorn_totals() y adorn_percentages() para añadir totales y convertirlos para mostrar porcentajes. A continuación se muestra un breve ejemplo:\n\nlinelist %&gt;%                                  # listado de casos\n  tabyl(age_cat, gender) %&gt;%                  # tabulación cruzada de los recuentos de dos columnas\n  adorn_totals(where = \"row\") %&gt;%             # añadir una fila de totales\n  adorn_percentages(denominator = \"col\") %&gt;%  # convertir a proporciones con denominador de columna\n  adorn_pct_formatting() %&gt;%                  # convertir proporciones a porcentajes\n  adorn_ns(position = \"front\") %&gt;%            # mostrar como \"count (percent)\"\n  adorn_title(                                # ajustar títulos\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\nPara añadir filas de totales más complejas que incluyan estadísticas de resumen distintas de las sumas, consulta esta sección de la página Tablas descriptivas.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#grouping-by-date",
    "href": "new_pages/grouping.es.html#grouping-by-date",
    "title": "13  Agrupar datos",
    "section": "13.6 Agrupar por fechas",
    "text": "13.6 Agrupar por fechas\nAl agrupar datos por fecha, debes tener (o crear) una columna para la unidad de fecha de interés - por ejemplo “día”, “epiweek”, “mes”, etc. Puedes crear esta columna utilizando floor_date() de lubridate, como se explica en la sección Semanas epidemiológicas de la página Trabajar con fechas. Una vez que tengas esta columna, puedes utilizar count() de dplyr para agrupar las filas por esos valores de fecha únicos y lograr recuentos agregados.\nUn paso adicional común para las situaciones de fechas, es “rellenar” cualquier fecha en la que no haya datos. Utiliza complete() de tidyr para que la serie de fechas agregadas esté completa, incluyendo todas las unidades de fecha posibles dentro del rango. Sin este paso, una semana sin casos reportados podría no aparecer en tus datos.\nDentro de complete() redefine la columna de fecha como una secuencia de fechas seq.Date() desde el mínimo hasta el máximo - así las fechas se expanden. Por defecto, los valores del recuento de casos en cualquier nueva fila “expandida” serán NA. Puedes establecerlos a 0 utilizando el argumento fill = de complete(), que espera una lista con nombre (si la columna de recuentos se llama n, escribe fill = list(n = 0). Consulta ?complete para obtener más detalles y la página Trabajar con fechas para ver un ejemplo.\n\nCasos por día\nAquí hay un ejemplo de agrupación de casos en días sin usar complete(). Obsérvese que las primeras filas omiten las fechas sin casos.\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%        # eliminar los que no tienen date_onset\n  count(date_onset)              # contar el número de filas por fecha única\n\n\n\n\n\n\n\nA continuación añadimos el comando complete() para asegurarnos de que todos los días del rango están representados.\n\ndaily_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%                 # eliminar los que no tienen date_onset\n  count(date_onset) %&gt;%                   # contar el número de filas por fecha única\n  complete(                               # asegurar que aparecen todos los días aunque no haya casos\n    date_onset = seq.Date(                # redefinir el conjunto de fechas como una secuencia diaria de fechas\n      from = min(date_onset, na.rm=T), \n      to = max(date_onset, na.rm=T),\n      by = \"day\"),\n    fill = list(n = 0))                   # establecer que las nuevas filas rellenadas muestren 0 en la columna n (no NA por defecto)\n\n\n\n\n\n\n\n\n\nCasos por semana\nSe puede aplicar el mismo principio para las semanas. Primero crea una nueva columna que sea la semana del caso utilizando floor_date() con unit = \"week\". A continuación, utiliza count() como en el caso anterior para obtener los recuentos de casos semanales. Termina con complete() para asegurarte de que todas las semanas están representadas, incluso si no contienen casos.\n\n# Make dataset of weekly case counts\nweekly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;%                 # eliminar los que no tienen date_onset\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %&gt;%  # nueva columna de semana de inicio\n  count(week) %&gt;%                         # agrupar los datos por semana y contar las filas por grupo\n  complete(                               # asegurar que aparecen todos los días aunque no haya casos\n    week = seq.Date(                      # redefinir el conjunto de fechas como una secuencia diaria de fechas\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))                   # establecer que las nuevas filas rellenadas muestren 0 en la columna n (no NA por defecto) \n\nAquí están las primeras 50 filas del dataframe resultante:\n\n\n\n\n\n\n\n\nCasos por mes\nPara agregar casos en meses, vuelve a utilizar floor_date() del paquete lubridate, pero con el argumento unit = \"months\". Esto redondea cada fecha hacia abajo al día 1 de su mes. La salida será el tipo Date. Ten en cuenta que en el paso complete() también utilizamos by = \"months\".\n\n# Make dataset of monthly case counts\nmonthly_counts &lt;- linelist %&gt;% \n  drop_na(date_onset) %&gt;% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %&gt;%  # nueva columna, 1º del mes de inicio\n  count(month) %&gt;%                          # recuento de casos por mes\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # incluir todos los meses sin casos declarados\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))\n\n\n\n\n\n\n\n\n\nRecuentos diarios en semanas\nPara agregar los recuentos diarios en recuentos semanales, utiliza floor_date() igual queo arriba. Sin embargo, utiliza group_by() y summarize() en lugar de count() porque necesita sum() los recuentos de casos diarios en lugar de limitarse a contar el número de filas por semana.\n\nDaily counts into months\nPara agregar los recuentos diarios en recuentos por meses, utiliza floor_date() con unit = \"month\" como en el caso anterior. Sin embargo, utiliza group_by() y summarize() en lugar de count() porque necesitasum()los recuentos de casos diarios en lugar de limitarse a contar el número de filas por mes.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#arranging-grouped-data",
    "href": "new_pages/grouping.es.html#arranging-grouped-data",
    "title": "13  Agrupar datos",
    "section": "13.7 Ordenar los datos agrupados",
    "text": "13.7 Ordenar los datos agrupados\nEl verbo arrange() de dplyr para ordenar las filas de un dataframe se comporta igual cuando los datos están agrupados, a menos que se establezca el argumento .by_group =TRUE. En este caso, las filas se ordenan primero por las columnas de agrupación y luego por cualquier otra columna que se especifique en arrange().",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#filter-on-grouped-data",
    "href": "new_pages/grouping.es.html#filter-on-grouped-data",
    "title": "13  Agrupar datos",
    "section": "13.8 Filtrar sobre datos agrupados",
    "text": "13.8 Filtrar sobre datos agrupados\n\nfilter()\nCuando se aplica junto con funciones que evalúan el dataframe (como max(), min(), mean()), estas funciones se aplicarán ahora a los grupos. Por ejemplo, si deseas filtrar y mantener las filas en las que los pacientes están por encima de la edad media, esto se aplicará ahora por grupo, filtrando para mantener las filas por encima de la edad media del grupo.\n\n\nClasificar filas por grupo\nLa función slice() de dplyr, que filtra las filas según su posición en los datos, también puede aplicarse por grupo. Recuerda que debes tener en cuenta la ordenación de los datos dentro de cada grupo para obtener la “rebanada” deseada.\nPor ejemplo, para recuperar sólo los últimos 5 ingresos de cada hospital:\n\nAgrupar linelist por columna hospital\n\nOrdenar los registros por date_hospitalisation de más reciente a la más antigua dentro de cada grupo de hospitales\nClasificar para recuperar las 5 primeras filas de cada hospital\n\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  arrange(hospital, date_hospitalisation) %&gt;%\n  slice_head(n = 5) %&gt;% \n  arrange(hospital) %&gt;%                            # para mostrar\n  select(case_id, hospital, date_hospitalisation)  # para mostrar\n\n# A tibble: 30 × 3\n# Groups:   hospital [6]\n   case_id hospital          date_hospitalisation\n   &lt;chr&gt;   &lt;chr&gt;             &lt;date&gt;              \n 1 20b688  Central Hospital  2014-05-06          \n 2 d58402  Central Hospital  2014-05-10          \n 3 b8f2fd  Central Hospital  2014-05-13          \n 4 acf422  Central Hospital  2014-05-28          \n 5 275cc7  Central Hospital  2014-05-28          \n 6 d1fafd  Military Hospital 2014-04-17          \n 7 974bc1  Military Hospital 2014-05-13          \n 8 6a9004  Military Hospital 2014-05-13          \n 9 09e386  Military Hospital 2014-05-14          \n10 865581  Military Hospital 2014-05-15          \n# ℹ 20 more rows\n\n\nslice_head() - selecciona n filas de la parte superior slice_tail() - selecciona n filas del final slice_sample() - selecciona aleatoriamente n filas slice_min() - selecciona n filas con los valores más altos en order_by =columna, usa with_ties = TRUE para mantener los empates slice_max() - selecciona n filas con los valores más bajos en order_by =columna, utiliza with_ties = TRUE para mantener los empates\nConsulta la página de De-duplicación para ver más ejemplos y detalles sobre slice().\n\n\nFiltro por tamaño de grupo\nLa función add_count() añade una columna n a los datos originales dando el número de filas en el grupo de esa fila.\nA continuación, add_count() se aplica a la columna hospital, por lo que los valores de la nueva columna n reflejan el número de filas del grupo de hospitales de esa fila. Observe cómo se repiten los valores de la columna n. En el ejemplo siguiente, el nombre de la columna n podría cambiarse utilizando name = dentro de add_count(). Para fines de demostración reordenamos las columnas con select().\n\nlinelist %&gt;% \n  as_tibble() %&gt;% \n  add_count(hospital) %&gt;%          # añadir \"número de filas admitidas en el mismo hospital que esta fila\" \n  select(hospital, n, everything())\n\n# A tibble: 5,888 × 31\n   hospital                       n case_id generation date_infection date_onset\n   &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;    \n 1 Other                        885 5fe599           4 2014-05-08     2014-05-13\n 2 Missing                     1469 8689b7           4 NA             2014-05-13\n 3 St. Mark's Maternity Hosp…   422 11f8ea           2 NA             2014-05-16\n 4 Port Hospital               1762 b8812a           3 2014-05-04     2014-05-18\n 5 Military Hospital            896 893f25           3 2014-05-18     2014-05-21\n 6 Port Hospital               1762 be99c8           3 2014-05-03     2014-05-22\n 7 Missing                     1469 07e3e8           4 2014-05-22     2014-05-27\n 8 Missing                     1469 369449           4 2014-05-28     2014-06-02\n 9 Missing                     1469 f393b4           4 NA             2014-06-05\n10 Missing                     1469 1389ca           4 NA             2014-06-05\n# ℹ 5,878 more rows\n# ℹ 25 more variables: date_hospitalisation &lt;date&gt;, date_outcome &lt;date&gt;,\n#   outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;, age_years &lt;dbl&gt;,\n#   age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, infector &lt;chr&gt;,\n#   source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;, ct_blood &lt;dbl&gt;, fever &lt;chr&gt;,\n#   chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;, vomit &lt;chr&gt;, temp &lt;dbl&gt;,\n#   time_admission &lt;chr&gt;, bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\nDe este modo, resulta fácil filtrar los casos que fueron hospitalizados en un hospital “pequeño”, por ejemplo, un hospital que admitió a menos de 500 pacientes:\n\nlinelist %&gt;% \n  add_count(hospital) %&gt;% \n  filter(n &lt; 500)",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#mutate-on-grouped-data",
    "href": "new_pages/grouping.es.html#mutate-on-grouped-data",
    "title": "13  Agrupar datos",
    "section": "13.9 Mutate con datos agrupados",
    "text": "13.9 Mutate con datos agrupados\nPara conservar todas las columnas y filas (no resumir) y añadir una nueva columna que contenga estadísticas de grupo, utiliza mutate() después de group_by() en lugar de summarise().\nEsto es útil si se desea obtener estadísticas de grupo en los datos originales con todas las demás columnas presentes, por ejemplo, para los cálculos que comparan una fila con su grupo.\nPor ejemplo, este código calcula la diferencia entre la demora en el ingreso de una fila y la demora media de su hospital. Los pasos son:\n\nAgrupar los datos por hospital\nUtiliza la columna days_onset_hosp (retraso hasta la hospitalización) para crear una nueva columna que contenga el retraso medio en el hospital de esa fila\nCalcular la diferencia entre las dos columnas\n\nSeleccionamos (select()) sólo ciertas columnas para mostrarlas, con fines de demostración.\n\nlinelist %&gt;% \n  # agrupar datos por hospital (aún no hay cambios en linelist)\n  group_by(hospital) %&gt;% \n  \n  # nuevas columnas\n  mutate(\n    # media de días hasta el ingreso por hospital (redondeada a 1 decimal)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # diferencia entre la demora de la fila y la demora media en su hospital (redondeada a 1 decimal)\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %&gt;%\n  \n  # seleccionar sólo ciertas filas - con fines de demostración/visualización\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)\n\n# A tibble: 5,888 × 5\n# Groups:   hospital [6]\n   case_id hospital              days_onset_hosp group_delay_admit diff_to_group\n   &lt;chr&gt;   &lt;chr&gt;                           &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 5fe599  Other                               2               2             0  \n 2 8689b7  Missing                             1               2.1          -1.1\n 3 11f8ea  St. Mark's Maternity…               2               2.1          -0.1\n 4 b8812a  Port Hospital                       2               2.1          -0.1\n 5 893f25  Military Hospital                   1               2.1          -1.1\n 6 be99c8  Port Hospital                       1               2.1          -1.1\n 7 07e3e8  Missing                             2               2.1          -0.1\n 8 369449  Missing                             1               2.1          -1.1\n 9 f393b4  Missing                             1               2.1          -1.1\n10 1389ca  Missing                             2               2.1          -0.1\n# ℹ 5,878 more rows",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#select-on-grouped-data",
    "href": "new_pages/grouping.es.html#select-on-grouped-data",
    "title": "13  Agrupar datos",
    "section": "13.10 Seleccionar sobre datos agrupados",
    "text": "13.10 Seleccionar sobre datos agrupados\nEl verbo select() funciona con datos agrupados, pero las columnas de agrupación siempre se incluyen (aunque no se mencionen en select()). Si no deseas estas columnas de agrupación, utiliza primero ungroup().",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/grouping.es.html#resources-6",
    "href": "new_pages/grouping.es.html#resources-6",
    "title": "13  Agrupar datos",
    "section": "13.11 Recursos",
    "text": "13.11 Recursos\nA continuación, algunos recursos útiles para obtener más información:\nPuedes realizar cualquier función de resumen sobre datos agrupados; consulta la hoja de trucos de transformación de datos de RStudio\nLa página de Data Carpentry sobre dplyr\nLas páginas de referencia de tidyverse sobre group_by() y agrupación\nEsta página sobre Manipulación de datos\nResumir con condiciones en dplyr",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Agrupar datos</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.es.html",
    "href": "new_pages/joining_matching.es.html",
    "title": "14  Unir datos",
    "section": "",
    "text": "14.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Unir datos</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.es.html#preparation-5",
    "href": "new_pages/joining_matching.es.html#preparation-5",
    "title": "14  Unir datos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,            # importar y exportar\n  here,           # localizar archivos \n  tidyverse,      # gestión y visualización de datos\n  RecordLinkage,  # coincidencias probabilísticas\n  fastLink        # coincidencias probabilísticas\n)\n\n\n\nImportar datos\nPara empezar, importamos la lista de casos limpiada de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar el listado “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).\n\n# importar el listado de casos\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.\n\n\n\n\n\n\n\n\n\nDatos de los ejemplos\nEn la sección de unión que sigue, utilizaremos los siguientes datos:\n\nUna versión “en miniatura” de casos de linelist, que contiene sólo las columnas case_id, date_onset, y hospital, y sólo las 10 primeras filas\nUn dataframe separado llamado hosp_info, que contiene más detalles sobre cada hospital\n\nEn la sección sobre el emparejamiento probabilístico, utilizaremos dos pequeños conjuntos de datos diferentes. El código para crear esos conjuntos de datos se da en esa sección.\n\n“Miniatura” de casos de linelist\nA continuación se muestra la lista de casos en miniatura, que contiene sólo 10 filas y sólo las columnas case_id, date_onset, y hospital.\n\nlinelist_mini &lt;- linelist %&gt;%                 # empezar con linelist original\n  select(case_id, date_onset, hospital) %&gt;%   # seleccionar columnas\n  head(10)                                    # sólo las 10 primeras filas\n\n\n\n\n\n\n\n\n\ndataframe de información hospitalaria\nA continuación se muestra el código para crear un dataframe separado con información adicional sobre siete hospitales (la población de captación y el nivel de atención disponible). Obsérvese que el nombre “Hospital Militar” pertenece a dos hospitales diferentes: uno de nivel primario que atiende a 10000 residentes y otro de nivel secundario que atiende a 50280 residentes.\n\n# Crear el Data frame de información hospitalaria\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)\n\nAquí está este dataframe:\n\n\n\n\n\n\n\n\n\n\nPre-limpieza\nLas uniones tradicionales (no probabilísticas) distinguen entre mayúsculas y minúsculas y requieren coincidencias de caracteres exactas entre los valores de los dos dataframes. Para mostrar algunos de los pasos de limpieza que puedes necesitar antes de iniciar una unión, ahora limpiaremos y alinearemos los datos linelist_mini y hosp_info.\nIdentificar las diferencias\nNecesitamos que los valores de la columna hosp_name en el dataframe hosp_info coincidan con los valores de la columna hospital en el dataframe linelist_mini.\nAquí están los valores del dataframe linelist_mini, impresos con la función de R base unique():\n\nunique(linelist_mini$hospital)\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n\n\ny aquí están los valores del dataframe hosp_info:\n\nunique(hosp_info$hosp_name)\n\n[1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"      \n[5] \"ignace\"           \"sisters\"         \n\n\nPuedes ver que, aunque algunos de los hospitales existen en ambos dataframes, hay muchas diferencias en la ortografía.\nAlinear los valores\nComenzamos limpiando los valores del dataframe hosp_info. Como se explica en la página Limpieza de datos y funciones básicas, podemos recodificar los valores con criterios lógicos utilizando la función case_when() de dplyr. Para los cuatro hospitales que existen en ambos dataframes, cambiamos los valores para alinearlos con los valores de linelist_mini. Para los demás hospitales dejamos los valores como están (TRUE ~ hosp_name).\nPRECAUCIÓN: Normalmente, al limpiar se debe crear una nueva columna (por ejemplo, hosp_name_clean), pero para facilitar la demostración mostramos la modificación de la antigua columna \n\nhosp_info &lt;- hosp_info %&gt;% \n  mutate(\n    hosp_name = case_when(\n      # criterio                         # valor nuevo\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\n\nLos nombres de los hospitales que aparecen en ambos dataframes están alineados. Hay dos hospitales en hosp_info que no están presentes en linelist_mini - nos ocuparemos de ellos más adelante, en la unión.\n\nunique(hosp_info$hosp_name)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Port Hospital\"                       \n[4] \"St. Mark's Maternity Hospital (SMMH)\"\n[5] \"ignace\"                              \n[6] \"sisters\"                             \n\n\nAntes de una unión, a menudo es más fácil convertir en una columna todas a minúsculas o todas a mayúsculas. Si necesitas convertir todos los valores de una columna a MAYÚSCULAS o minúsculas, utiliza mutate() y envuelva la columna con una de estas funciones de stringr, como se muestra en la página sobre Caracteres y cadenas.\nstr_to_upper()\nstr_to_upper()\nstr_to_title()",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Unir datos</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.es.html#dplyr-joins",
    "href": "new_pages/joining_matching.es.html#dplyr-joins",
    "title": "14  Unir datos",
    "section": "14.2 Uniones en dplyr",
    "text": "14.2 Uniones en dplyr\nEl paquete dplyr ofrece varias funciones de unión. dplyr está incluido en el paquete tidyverse. Estas funciones de unión se describen a continuación, con casos de uso sencillos.\nMuchas gracias a https://github.com/gadenbuie por los gifs informativos.\n\n\nSintaxis general\nLos comandos de unión pueden ejecutarse como comandos independientes para unir dos dataframes en un nuevo objeto, o pueden utilizarse dentro de una cadena de pipes (%&gt;%) para fusionar un dataframe en otro mientras se limpia o se modifica de alguna manera.\nEn el siguiente ejemplo, la función left_join() se utiliza como un comando independiente para crear un nuevo dataframe joined_data. Las entradas son los dataframes 1 y 2 (df1 y df2). El primer dataframe es el dataframe de referencia, y el segundo se une a él.\nEl tercer argumento by = es donde se especifican las columnas de cada dataframe que se utilizarán para alinear las filas de los dos dataframes. Si los nombres de estas columnas son diferentes, proporciónelos dentro de un vector c() como se muestra a continuación, donde las filas se emparejan sobre la base de valores comunes entre la columna ID en df1 y la columna identifier en df2.\n\n# Unión basada en valores comunes entre la columna \"ID\" (primer data frame) y la columna \"identifier  (segundo data frame)\njoined_data &lt;- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\n\nSi las columnas by de ambos dataframes tienen exactamente el mismo nombre, puedes proporcionar sólo este nombre, entre comillas.\n\n# Unión basada en valores comunes en la columna \"ID\" en ambos data frames\njoined_data &lt;- left_join(df1, df2, by = \"ID\")\n\nSi estás uniendo los dataframes basándote en valores comunes en varios campos, enumera estos campos dentro del vector c(). Este ejemplo une filas si los valores de tres columnas de cada conjunto de datos se alinean exactamente.\n\n# unión basada en el mismo nombre, apellido y edad\njoined_data &lt;- left_join(df1, df2, by = c(\"name\" = \"firstname\", \"surname\" = \"lastname\", \"Age\" = \"age\"))\n\nLos comandos de unión también pueden ejecutarse dentro de una cadena de pipes. Esto modificará el dataframe que se está canalizando.\nEn el ejemplo siguiente, df1 se pasa por los pipes, df2 se une a él y, por tanto, dfse modifica y se redefine.\n\ndf1 &lt;- df1 %&gt;%\n  filter(date_onset &lt; as.Date(\"2020-03-05\")) %&gt;% # limpieza miscelánea\n  left_join(df2, by = c(\"ID\" = \"identifier\"))    # unión df2 a df1\n\nATENCIÓN: ¡Las uniones son específicas para cada caso! Por lo tanto, es útil convertir todos los valores a minúsculas o mayúsculas antes de la unión. Consulta la página sobre caracteres/cadenas. \n\n\n\nUniones izquierda y derecha\nUna unión a la izquierda o a la derecha se utiliza habitualmente para añadir información a un dataframe: la nueva información se añade sólo a las filas que ya existían en el dataframe de referencia. Estas uniones son comunes en el trabajo epidemiológico, ya que se utilizan para añadir información de unos datos a otro.\nAl utilizar estas uniones, el orden de escritura de los dataframes en el comando es importante*.\n\nEn una unión a la izquierda, el primer dataframe escrito es el de base\nEn una unión a la derecha, el segundo dataframe escrito es el de base\n\nSe conservan todas las filas del dataframe de referencia. La información del otro dataframe (secundario) se une al dataframe de referencia sólo si hay una coincidencia a través de la(s) columna(s) del identificador. Además:\n\nLas filas del dataframe secundario que no coinciden se eliminan.\nSi hay muchas filas de la línea de base que coinciden con una fila del dataframe secundarios (muchos a uno), la información secundaria se añade a cada fila de la línea de base que coincide.\nSi una fila del de base coincide con varias filas del dataframe secundario (uno a varios), se dan todas las combinaciones, lo que significa que se pueden añadir nuevas filas al dataframe devuelto.\n\nEjemplos animados de uniones a la izquierda y a la derecha (fuente de la imagen)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjemplo\nA continuación se muestra el resultado de un left_join() de hosp_info (dataframe secundario, ver aquí) en linelist_mini (dataframe de referencia, ver aquí). linelist_mini original tiene filas nrow(linelist_mini). Se muestra linelist_mini modificada. Observa lo siguiente:\n\nSe han añadido dos nuevas columnas, catchment_pop y level en la parte izquierda de linelist_mini\nSe mantienen todas las filas originales del dataframe de referencia linelist_mini\nCualquier fila original de linelist_mini para “Hospital Militar” está duplicada porque coincide con dos filas en el dataframe secundario, por lo que se devuelven ambas combinaciones\nLa columna del identificador de la unión del set de datos secundario (hosp_name) ha desaparecido porque es redundante con la columna del identificador primario (hospital)\nCuando una fila de referencia no coincide con ninguna fila secundaria (por ejemplo, cuando el hospital is “Other” or “Missing”), NA (en blanco) rellena las columnas del dataframe secundario\nSe eliminaron las filas del dataframe secundario que no coincidían con el dataframe de referencia (hospitales “sisters” e “ignace”)\n\n\nlinelist_mini %&gt;% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in left_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n“¿Debo usar una unión a la derecha o a la izquierda?”\nPara responder a la pregunta anterior, hay que tener claro “¿qué dataframe debe conservar todas sus filas?” - Utiliza éste como base. Una unión a la izquierda conserva todas las filas del primer dataframe escrito en el comando, mientras que una unión a la derecha conserva todas las filas del segundo dataframe.\nLos dos comandos de abajo consiguen el mismo resultado - 10 filas de hosp_info unidas en base a linelist_mini, pero utilizan diferentes uniones. El resultado es que el orden de las columnas variará en función de si hosp_info llega por la derecha (en la unión izquierda) o llega por la izquierda (en la unión derecha). El orden de las filas también puede cambiar en consecuencia. Pero ambas consecuencias pueden ser tratadas posteriormente, utilizando select() para reordenar las columnas o arrange() para ordenar las filas.\n\n# Los dos comandos siguientes obtienen los mismos datos, pero con filas y columnas ordenadas de forma diferente\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\nEste es el resultado de hosp_info en linelist_mini a través de una unión a la izquierda (nuevas columnas entrando por la derecha)\n\n\nWarning in left_join(linelist_mini, hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nEste es el resultado de hosp_info en linelist_mini a través de una unión a la derecha (nuevas columnas entrando desde la izquierda)\n\n\nWarning in right_join(hosp_info, linelist_mini, by = c(hosp_name = \"hospital\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 4 of `x` matches multiple rows in `y`.\nℹ Row 5 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nConsidera también si tu caso de uso está dentro de una cadena de pipes (%&gt;%). Si los datos del pipe son la base, es probable que utilices una unión izquierda para añadir datos a ella.\n\n\n\n\nUnión completa\nUna unión completa (Full join) es la más inclusiva de las uniones: devuelve todas las filas de ambos dataframes.\nSi hay filas presentes en una y no en la otra (donde no se encontró ninguna coincidencia), el dataframe las incluirá y se hará más largo. Los valores faltantes NA se utilizan para rellenar los huecos creados. A medida que se une, observa el número de columnas y filas con cuidado para solucionar el problema de las coincidencias de mayúsculas y minúsculas y de los caracteres exactos.\nEl dataframe de “base” es el que se escribe primero en el comando. El ajuste de esto no afectará a los registros devueltos por la unión, pero puede afectar al orden de las columnas resultantes, al orden de las filas y a las columnas de los identificadores que se conservan.\n\n\n\n\n\n\n\n\n\nEjemplo animado de una unión completa (fuente de la imagen)\nEjemplo\nA continuación se muestra la salida de un full_join() de hosp_info (originalmente nrow(hosp_info), view here) into linelist_mini (originalmente nrow(linelist_mini), view here). Nota lo siguiente:\n\nSe mantienen todas las filas de la base (linelist_mini)\nSe conservan las filas de los datos secundarios que no coinciden con la de base (“ignace” y “sisters”), con los valores de las columnas correspondientes de la de base case_id y onset rellenados con los valores que faltan\n\nDel mismo modo, se conservan las filas de los datos de referencia que no coinciden con el secundario (“Otros” y “Falta”), y las columnas secundarias catchment_pop y level se rellenan con los valores que faltan\nEn el caso de coincidencias de uno a muchos o de muchos a uno (por ejemplo, filas para “Hospital Militar”), se devuelven todas las combinaciones posibles (alargando el conjunto de datos final)\n\nSólo se mantiene la columna del identificador de la línea de base (hospital)\n\n\nlinelist_mini %&gt;% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in full_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nUnión interna\nUna unión interna es la más restrictiva de las uniones: sólo devuelve las filas que coinciden en ambos dataframes. Esto significa que el número de filas en el dataframe de referencia puede reducirse. El ajuste de qué dataframe es el de “base” (escrito en primer lugar en la función) no afectará a las filas que se devuelven, pero sí al orden de las columnas, al orden de las filas y a las columnas de los identificadores que se conservan.\n\n\n\n\n\n\n\n\n\nEjemplo animado de una unión interna (fuente de la imagen)\nEjemplo\nA continuación se muestra la salida de un inner_join() de linelist_mini (base) con hosp_info (secundario). Observa lo siguiente:\n\nSe eliminan las filas del de base que no coinciden con los datos secundarios (filas en las que el hospital es “Missing” u “Other”) * Asimismo, se eliminan las filas del dataframe secundario que no tenían ninguna coincidencia en la de base (filas en las que hosp_name es “sisters” o “ignace”)\nSólo se conserva la columna del identificador del de base (hospital)\n\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\n\nSemi-unión\nUna semi-unión join es una “unión filtrada” que utiliza otro conjunto de datos no para añadir filas o columnas, sino para realizar un filtrado.\nUn semi-join mantiene todas las observaciones en el dataframe de referencia que tienen una coincidencia con el dataframe secundario (pero no añade nuevas columnas ni duplica ninguna fila para las coincidencias múltiples). Lee más sobre estas uniones de “filtrado” aquí.\n\n\n\n\n\n\n\n\n\nEjemplo animado de una semiunión (fuente de la imagen)\nComo ejemplo, el siguiente código devuelve las filas del dataframe hosp_info que tienen coincidencias en linelist_mini basadas en el nombre del hospital.\n\nhosp_info %&gt;% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n                             hosp_name catchment_pop     level\n1                    Military Hospital         40500 Secondary\n2                    Military Hospital         10000   Primary\n3                        Port Hospital         50280 Secondary\n4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary\n\n\n\n\n\nAnti unión\nLa anti unión es otra “unión filtrada” que devuelve las filas del dataframe de referencia que no tienen una coincidencia en el dataframe secundario.\nLee más sobre el filtrado de las uniones aquí.\nLos anti-join son útiles para la identificación de registros que no están presentes en otro dataframe, la solución de problemas de ortografía en un join (revisión de registros que deberían haber coincidido) y el examen de registros que fueron excluidos después de otro join.\nAl igual que con right_join() y left_join(), el dataframe de base (que aparece primero) es importante. Las filas devueltas son sólo las del dataframe de referencia. Observa en el siguiente gif que la fila del dataframe secundario (fila púrpura 4) no se devuelve a pesar de que no coincide con la línea de base.\n\n\n\n\n\n\n\n\n\nEjemplo animado de una anti-unión (fuente de la imagen)\n\nEjemplo de anti_join() sencillo\nPara un ejemplo sencillo, encontremos los hospitales de hosp_info que no tienen ningún caso en linelist_mini. Enumeramos primero hosp_info, como dataframe de referencia. Se devuelven los hospitales que no están presentes en linelist_mini.\n\nhosp_info %&gt;% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\n\n\n\n\n\n\n\n\n\nEjemplo de anti_join() complejo\nPara otro ejemplo, digamos que ejecutamos un inner_join() entre linelist_mini y hosp_info. Esto devuelve sólo un subconjunto de los registros originales de linelist_mini, ya que algunos no están presentes en hosp_info.\n\nlinelist_mini %&gt;% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\nWarning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 5 of `x` matches multiple rows in `y`.\nℹ Row 4 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\nPara revisar los registros de linelist_mini que fueron excluidos durante el inner join, podemos ejecutar un anti-join con la misma configuración (linelist_mini como base).\n\nlinelist_mini %&gt;% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n\n\n\n\n\n\n\nPara ver los registros de hosp_info que se excluyeron en la unión interna, también podríamos ejecutar una anti unión con hosp_info como dataframe de referencia.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Unir datos</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.es.html#probabalistic-matching",
    "href": "new_pages/joining_matching.es.html#probabalistic-matching",
    "title": "14  Unir datos",
    "section": "14.3 Emparejamiento probabilístico",
    "text": "14.3 Emparejamiento probabilístico\nSi no dispones de un identificador único común a todos los conjuntos de datos para unirlos, considera la posibilidad de utilizar un algoritmo de coincidencia probabilística. Este algoritmo buscaría coincidencias entre los registros basándose en la similitud (por ejemplo, la distancia de cadena de Jaro-Winkler o la distancia numérica). A continuación se muestra un ejemplo sencillo utilizando el paquete fastLink .\nCargar paquetes\n\npacman::p_load(\n  tidyverse,      # manipulación y visualización de datos\n  fastLink        # correspondencia de registros\n  )\n\nA continuación se presentan dos pequeños conjuntos de datos de ejemplo que utilizaremos para demostrar la correspondencia probabilística (cases y test_results):\nAquí está el código utilizado para hacer estos conjuntos de datos:\n\n# crear un set de datos\n\ncases &lt;- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults &lt;- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )\n\nEl dataset cases tiene 9 registros de pacientes que están a la espera de los resultados de las pruebas.\n\n\n\n\n\n\nEl set de datos test_results tiene 14 registros y contiene la columna resultado, que queremos añadir a los registros en cases basado en la coincidencia probabilística de registros.\n\n\n\n\n\n\n\nCorrespondencia probabilística\nLa función fastLink() del paquete fastLink puede utilizarse para aplicar un algoritmo de coincidencia. Esta es la información básica. Puedes leer más detalles escribiendo ?fastLink en tu consola.\n\nDefine los dos dataframes para la comparación con los argumentos dfA =y dfB =\nEn varnames = indica todos los nombres de columnas que se utilizarán para la comparación. Todos ellos deben existir tanto en dfA como en dfB.\nEn stringdist.match = escribe columnas de las que están en varnames para ser evaluadas en la cadena “distance”.\nEn numeric.match = dar columnas de las que están en varnames para ser evaluadas en la distancia numérica.\nLos valores faltantes se ignoran\nPor defecto, cada fila de cualquiera de los dos dataframes coincide como máximo con una fila del otro dataframe. Si deseas ver todas las coincidencias evaluadas, establece dedupe.matches = FALSE. La deduplicación se realiza mediante la solución de asignación lineal de Winkler.\n\nSugerencia: divide una columna de fecha en tres columnas numéricas separadas utilizando day(), month(), and year() del paquete lubridate\nEl umbral por defecto para las coincidencias es de 0,94 (threshold.match =), pero puedes ajustarlo más alto o más bajo. Si defines el umbral, ten en cuenta que los umbrales más altos podrían producir más falsos negativos (filas que no coinciden y que en realidad deberían coincidir) y, del mismo modo, un umbral más bajo podría producir más falsos positivos.\nA continuación, los datos se emparejan según la distancia de las cadenas en las columnas de nombre y distrito, y según la distancia numérica para el año, el mes y el día de nacimiento. Se establece un umbral de coincidencia del 95% de probabilidad.\n\nfl_output &lt;- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nDeduping the estimated matches.\nGetting the match patterns for each estimated match.\n\n\nRevisar los coincidentes\nDefinimos el objeto devuelto por fastLink() como fl_output. Es de tipo list, y en realidad contiene varios dataframes dentro de él, detallando los resultados de la coincidencia. Uno de estos dataframes es matches, que contiene las coincidencias más probables entre cases y results. Puedes acceder a este dataframe “coincidencias” con fl_output$matches. A continuación, se guarda como my_matches para facilitar el acceso posterior.\nCuando se imprime my_matches, se ven dos vectores de columnas: los pares de números de fila/índices (también llamados “rownames”) en cases (“inds.a”) y en results (“inds.b”) que representan las mejores coincidencias. Si falta un número de fila de un dataframe, entonces no se ha encontrado ninguna coincidencia en el otro dataframe con el umbral de coincidencia especificado.\n\n# imprimir coincidencias\nmy_matches &lt;- fl_output$matches\nmy_matches\n\n  inds.a inds.b\n1      1      1\n2      2      2\n3      3      3\n4      4      4\n5      8      8\n6      7      9\n7      6     10\n8      5     12\n\n\nCosas a tener en cuenta:\n\nLas coincidencias se produjeron a pesar de las ligeras diferencias en la ortografía del nombre y las fechas de nacimiento:\n\n“Tony B. Smith” coincide con “Anthony B Smith”\n“María Rodríguez” coincide con “Marialisa Rodrigues”\n“Betty Chase” coincide con “Elizabeth Chase”\n“Olivier Laurent De Bordeaux” coincide con “Oliver Laurent De Bordow” (se ignora la fecha de nacimiento que falta)\n\nUna fila de cases (para “Blessing Adebayo”, fila 9) no tuvo una buena coincidencia en results, por lo que no está presente en my_matches.\n\nUnión en base a las coincidencias probabilísticas\nPara utilizar estas coincidencias para unir los resultados a los casos, una estrategia es:\n\nUtilizar left_join() para unir my_matches a cases (haciendo coincidir rownames en cases con “inds.a” en my_matches)\nA continuación, utiliza otro left_join() para unir results a cases (haciendo coincidir los “inds.b” recién adquiridos en cases con los rownames en results)\n\nAntes de las uniones, debemos limpiar los tres dataframes:\n\nTanto dfA como dfB deben tener sus números de fila (“rowname”) convertidos en una columna propia.\nLas dos columnas de my_matches se convierten en tipo carácter, por lo que pueden unirse a las filas\n\n\n# Limpiar los datos antes de unirlos\n####################################\n\n# convertir filas casos en una columna \ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\n# convertir filas de test_results en una columna\nresults_clean &lt;- results %&gt;% rownames_to_column()  \n\n# convertir todas las columnas del set de datos coincidentes en caracteres, para que puedan ser unidas a los nombres\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n\n\n# Unir las coincidencias a dfA, luego añadir dfB\n################################################\n# la columna \"inds.b\" se añade a dfA\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# se añade(n) columna(s) de dfB \ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\nComo se realiza utilizando el código anterior, el dataframe resultante complete contendrá todas las columnas tanto de cases como de results. A muchas de ellas se les añadirán los sufijos “.x” e “.y”, ya que de lo contrario los nombres de las columnas estarían duplicados.\n\n\n\n\n\n\nAlternativamente, para conseguir sólo los 9 registros “originales” en los casos con la(s) nueva(s) columna(s) de results, usa select() en results antes de las uniones, de forma que sólo contenga los nombres y las columnas que deseas añadir a cases (por ej. la columna result).\n\ncases_clean &lt;- cases %&gt;% rownames_to_column()\n\nresults_clean &lt;- results %&gt;%\n  rownames_to_column() %&gt;% \n  select(rowname, result)    # selecciona solo ciertas columnas \n\nmatches_clean &lt;- my_matches %&gt;%\n  mutate(across(everything(), as.character))\n\n# uniones\ncomplete &lt;- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete &lt;- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\n\n\n\n\n\n\n\nSi deseas subconjuntar cualquiera de los dos conjuntos de datos sólo con las filas que coincidan, puedes utilizar los siguientes códigos:\n\ncases_matched &lt;- cases[my_matches$inds.a,]  # Filas en casos que coinciden con una fila en resultados\nresults_matched &lt;- results[my_matches$inds.b,]  # Filas en resultados que coinciden con una fila de los casos\n\nO, para ver sólo las filas que no coinciden:\n\ncases_not_matched &lt;- cases[!rownames(cases) %in% my_matches$inds.a,]  # Filas los casos que NO coinciden con una fila de resultados\nresults_not_matched &lt;- results[!rownames(results) %in% my_matches$inds.b,]  # Filas de resultados que NO coinciden con una fila de casos\n\n\n\nDe-duplicación probabilística\nLa coincidencia probabilística también puede utilizarse para de-duplicar unos datos. Consulta la página sobre de-duplicación para conocer otros métodos de de-duplicación.\nAquí comenzamos con el conjunto de datos cases, pero ahora lo llamamos cases_dup, ya que tiene 2 filas adicionales que podrían ser duplicados de filas anteriores: Ver “Tony” con “Anthony”, y “Marialisa Rodrigues” con “Maria Rodriguez”.\n\n\n\n\n\n\nEjecuta fastLink() como antes, pero compara el dataframe cases_dup consigo mismo. Cuando los dos dataframes proporcionados son idénticos, la función asume que se quiere de-duplicar. Observa que no especificamos stringdist.match = o numeric.match = como hicimos anteriormente.\n\n## Ejecutar fastLink en el mismo conjunto de datos\ndedupe_output &lt;- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)\n\n\n==================== \nfastLink(): Fast Probabilistic Record Linkage\n==================== \n\nIf you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\ndfA and dfB are identical, assuming deduplication of a single data set.\nSetting return.all to FALSE.\n\nCalculating matches for each variable.\nGetting counts for parameter estimation.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nRunning the EM algorithm.\nGetting the indices of estimated matches.\n    Parallelizing calculation using OpenMP. 1 threads out of 8 are used.\nCalculating the posterior for each pair of matched observations.\nGetting the match patterns for each estimated match.\n\n\nAhora, puedes revisar los duplicados potenciales con getMatches(). Proporciona el dataframe como dfA = y dfB =, y proporciona la salida de la función fastLink() como fl.out =. fl.out debe ser del tipo fastLink.dedupe, o en otras palabras, el resultado de fastLink().\n\n## Ejecutar getMatches()\ncases_dedupe &lt;- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\n\nVéase la columna de la derecha, que indica los IDs duplicados: las dos últimas filas se identifican como probables duplicados de las filas 2 y 3.\n\n\n\n\n\n\nPara devolver los números de fila de las filas que probablemente sean duplicadas, puede contar el número de filas por valor único en la columna dedupe.ids, y luego filtrar para mantener sólo aquellas con más de una fila. En este caso, esto deja las filas 2 y 3.\n\ncases_dedupe %&gt;% \n  count(dedupe.ids) %&gt;% \n  filter(n &gt; 1)\n\n  dedupe.ids n\n1          2 2\n2          3 2\n\n\nPara inspeccionar las filas completas de los probables duplicados, pon el número de fila en este comando:\n\n# muestra la fila 2 y todos sus posibles duplicados\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   \n\n   gender   first middle  last   yr mon day district dedupe.ids\n2       M Anthony     B. Smith 1970   9  19    River          2\n10      M    Tony     B. Smith 1970   9  19    River          2",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Unir datos</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.es.html#binding-and-aligning",
    "href": "new_pages/joining_matching.es.html#binding-and-aligning",
    "title": "14  Unir datos",
    "section": "14.4 Enlazamiento y alineación",
    "text": "14.4 Enlazamiento y alineación\nOtro método para combinar dos dataframes es “unirlos”. También se puede pensar en esto como “anexar” o “añadir” filas o columnas.\nEn esta sección también se discutirá cómo “alinear” el orden de las filas de un dataframe con el orden de otro dataframe. Este tema se discute más adelante en la sección sobre Vinculación de columnas.\n\nEnlazar filas\nPara unir las filas de un dataframe con el fondo de otro dataframe, utiliza bind_rows() de dplyr. Es muy inclusivo, por lo que cualquier columna presente en cualquiera de los dataframes se incluirá en la salida. Algunas notas:\n\nA diferencia de la versión de R base de R row.bind(), bind_rows() de dplyr no requiere que el orden de las columnas sea el mismo en ambos dataframes. Siempre que los nombres de las columnas se escriban de forma idéntica, las alineará correctamente.\nPuedes especificar opcionalmente el argumento .id =. Proporcionar un nombre de columna de caracteres. Esto producirá una nueva columna que sirve para identificar de qué dataframe procede originalmente cada fila.\nPuedes utilizar bind_rows() en una lista de dataframes de estructura similar para combinarlos en un dataframe. Mira un ejemplo en la página Iteración, bucles y listas que implica la importación de múltiples listas de líneas con purrr.\n\nUn ejemplo común de vinculación de filas es vincular una fila “total” a una tabla descriptiva hecha con la función summarise() de dplyr. A continuación, creamos una tabla de recuentos de casos y valores medianos de TC por hospital con una fila de totales.\nLa función summarise() se utiliza en los datos agrupados por hospital para devolver un dataframe resumido por hospital. Pero la función summarise() no produce automáticamente una fila de “totales”, así que la creamos resumiendo los datos de nuevo, pero con los datos no agrupados por hospital. Esto produce un segundo dataframe de una sola fila. A continuación, podemos unir estos dataframes para obtener la tabla final.\nMira otros ejemplos trabajados como éste en las páginas de Tablas descriptivas y Tablas para presentaciones.\n\n# Crear tabla principal\n#######################\nhosp_summary &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;%                        # Agrupar los datos por hospitales\n  summarise(                                    # Crear nuevas columnas resumen de indicadores de interés\n    cases = n(),                                  # Número de filas por grupo hospital-resultado     \n    ct_value_med = median(ct_blood, na.rm=T))     # mediana del valor CT por grupo\n\nEste es el dataframe de hosp_summary:\n\n\n\n\n\n\nCrea un dataframe con las estadísticas “totales” (no agrupadas por hospital). Esto devolverá una sola fila.\n\n# crear totales\n###############\ntotals &lt;- linelist %&gt;% \n  summarise(\n    cases = n(),                               # Número de filas para todo el conjunto de datos      \n    ct_value_med = median(ct_blood, na.rm=T))  # Mediana de CT para todo el conjunto de datos\n\nY a continuación está el dataframe totals. Observa que sólo hay dos columnas. Estas columnas también están en hosp_summary, pero hay una columna en hosp_summary que no está en totals (hospital).\n\n\n\n\n\n\nAhora podemos unir las filas con bind_rows().\n\n# Unir los data frames\ncombined &lt;- bind_rows(hosp_summary, totals)\n\nAhora podemos ver el resultado. Observa cómo en la última fila se rellena un valor NA vacío para la columna hospital que no estaba en hosp_summary. Como se explica en la página de Tablas para presentaciones, podrías “rellenar” esta celda con “Total” utilizando replace_na().\n\n\n\n\n\n\n\n\nEnlazar columnas\nExiste una función similar de dplyr bind_cols() que se puede utilizar para combinar dos dataframes de forma lateral. Ten en cuenta que las filas se emparejan entre sí por posición (no como una unión anterior) - por ejemplo, la fila 12 en cada dataframe se alineará.\nComo ejemplo, unimos varias tablas de resumen. Para ello, también mostramos cómo reordenar el orden de las filas de un dataframe para que coincida con el orden de otro dataframe, con match().\nAquí definimos case_info como un dataframe resumido de los casos del listado, por hospital, con el número de casos y el número de muertes.\n\n# Información de casos\ncase_info &lt;- linelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\n\n\n\n\n\n\n\nY digamos que aquí hay un dataframe diferente contact_fu que contiene información sobre el porcentaje de contactos expuestos investigados y “seguidos”, de nuevo por hospital.\n\ncontact_fu &lt;- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)\n\n\n\n\n\n\n\nObserva que los hospitales son los mismos, pero están en diferente orden en cada dataframe. La solución más sencilla sería utilizar un left_join() en la columna hospitals, pero también podría utilizar bind_cols() con un paso adicional.\n\nUtiliza match() para alinear la ordenación\nDebido a que los órdenes de las filas son diferentes, un simple comando bind_cols() daría lugar a un desajuste de los datos. Para solucionarlo podemos utilizar match() de R base para alinear las filas de un dataframe en el mismo orden que en otro. Asumimos para este enfoque que no hay valores duplicados en ninguno de los dos dataframes.\nCuando utilizamos match(), la sintaxis es match(TARGET ORDER VECTOR, DATA FRAME COLUMN TO CHANGE), donde el primer argumento es el orden deseado (ya sea un vector independiente, o en este caso una columna en un dataframe), y el segundo argumento es la columna del dataframe que se reordenará. La salida de match() es un vector de números que representa el ordenamiento correcto de las posiciones. Puedes obtener más información con ?match.\n\nmatch(case_info$hospital, contact_fu$hospital)\n\n[1] 4 2 3 6 5 1\n\n\nPuedes utilizar este vector numérico para reordenar el dataframe - colócalo dentro de los subcorchetes [ ] antes de la coma. Lee más sobre la sintaxis del subconjunto de corchetes en la página de Fundamentos de R. El comando de abajo crea un nuevo dataframe, definido como el anterior en el que las filas están ordenadas en el vector numérico de arriba.\n\ncontact_fu_aligned &lt;- contact_fu[match(case_info$hospital, contact_fu$hospital),]\n\n\n\n\n\n\n\nAhora podemos unir las columnas del dataframe, con el orden correcto de las filas. Ten en cuenta que algunas columnas están duplicadas y será necesario limpiarlas con rename(). Lee más sobre bind_rows() aquí.\n\nbind_cols(case_info, contact_fu)\n\nNew names:\n• `hospital` -&gt; `hospital...1`\n• `hospital` -&gt; `hospital...4`\n\n\n# A tibble: 6 × 6\n  hospital...1                     cases deaths hospital...4 investigated per_fu\n  &lt;chr&gt;                            &lt;int&gt;  &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt; \n1 Central Hospital                   454    193 St. Mark's … 80%          60%   \n2 Military Hospital                  896    399 Military Ho… 82%          25%   \n3 Missing                           1469    611 Missing      &lt;NA&gt;         &lt;NA&gt;  \n4 Other                              885    395 Central Hos… 78%          20%   \n5 Port Hospital                     1762    785 Port Hospit… 64%          75%   \n6 St. Mark's Maternity Hospital (…   422    199 Other        55%          80%   \n\n\nUna alternativa en R base a bind_cols es cbind(), que realiza la misma operación.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Unir datos</span>"
    ]
  },
  {
    "objectID": "new_pages/joining_matching.es.html#resources-7",
    "href": "new_pages/joining_matching.es.html#resources-7",
    "title": "14  Unir datos",
    "section": "14.5 Recursos",
    "text": "14.5 Recursos\nLas páginas de tidyverse sobre join\nLa página de R for Data Science sobre datos relacionales\nLa página de tidyverse en dplyr en la encuadernación\nUna viñeta sobre fastLink en la página de Github del paquete\nPublicación que describe la metodología de fastLink\nPublicación que describe el paquete RecordLinkage",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Unir datos</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html",
    "href": "new_pages/deduplication.es.html",
    "title": "15  De-duplicación",
    "section": "",
    "text": "15.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html#preparation-6",
    "href": "new_pages/deduplication.es.html#preparation-6",
    "title": "15  De-duplicación",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  tidyverse,   # funciones de de-duplicación, agrupación y troceado\n  janitor,     # función para revisar duplicados\n  stringr)      # para búsquedas de cadenas, se puede utilizar en valores \"móviles\"\n\n\n\nImportar datos\nPara la demostración, utilizaremos unos datos de ejemplo que se crea con el código R que aparece a continuación.\nLos datos son registros de encuentros telefónicos COVID-19, incluyendo encuentros con contactos y con casos. Las columnas incluyen recordID (generado por ordenador), personID, name, date del encuentro, time del encuentro, purpose del encuentro (para entrevistar como caso o como contacto), y symptoms_ever (si la persona en ese encuentro declaró haber tenido síntomas alguna vez).\nEste es el código para crear el set de datos obs:\n\nobs &lt;- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %&gt;% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))\n\n\nEste es el dataframe\nUtiliza los cuadros de filtro de la parte superior para revisar los encuentros de cada persona.\n\n\n\n\n\n\nHay que tener en cuenta algunas cosas al revisar los datos:\n\nLos dos primeros registros están 100% duplicados, incluido el recordID de registro duplicado (¡debe ser un fallo informático!)\nLas dos segundas filas están duplicadas, en todas las columnas excepto en recordID\nVarias personas tuvieron múltiples encuentros telefónicos, en diversas fechas y horas, y como contactos y/o casos\nEn cada encuentro se preguntaba a la persona si había tenido alguna vez síntomas, y parte de esta información falta.\n\nY aquí hay un resumen rápido de las personas y los propósitos de sus encuentros, usando tabyl() de janitor:\n\nobs %&gt;% \n  tabyl(name, purpose)\n\n    name case contact\n    adam    1       2\n  amrish    1       3\n   brian    1       2\n  mariah    1       2\n natalie    1       0\n  nikhil    0       2\n  raquel    0       2\n   smita    0       1",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html#deduplication-1",
    "href": "new_pages/deduplication.es.html#deduplication-1",
    "title": "15  De-duplicación",
    "section": "15.2 De-duplicación",
    "text": "15.2 De-duplicación\nEsta sección describe cómo revisar y eliminar filas duplicadas en un dataframe. También muestra cómo manejar los elementos duplicados en un vector.\n\n\nExaminar las filas duplicadas\nPara revisar rápidamente las filas que tienen duplicados, puedes utilizar get_dupes() del paquete janitor. Por defecto, se revisan todas las columnas cuando se evalúan los duplicados - las filas devueltas por la función están 100% duplicadas considerando los valores de todas las columnas.\nEn el dataframe obs, las dos primeras filas están 100% duplicadas - tienen el mismo valor en cada columna (incluyendo la columna recordID, que se supone que es única - debe ser algún fallo informático). El dataframe devuelto incluye automáticamente una nueva columna dupe_count en el lado derecho, que muestra el número de filas con esa combinación de valores duplicados.\n\n# 100% de duplicados en todas las columnas\nobs %&gt;% \n  janitor::get_dupes()\n\n\n\n\n\n\n\nVer los datos originales\nSin embargo, si decidimos ignorar recordID, las filas 3 y 4 también están duplicadas entre sí. Es decir, tienen los mismos valores en todas las columnas excepto en recordID. Puedes especificar las columnas que se van a ignorar en la función mediante el símbolo - menos.\n\n# Duplicados cuando no se tiene en cuenta la columna recordID\nobs %&gt;% \n  janitor::get_dupes(-recordID)        # si hay varias columnas, envolverlas en c()\n\n\n\n\n\n\n\nTambién puedes especificar positivamente las columnas a considerar. A continuación, sólo se devuelven las filas que tienen los mismos valores en las columnas name y purpose. Observa cómo “amrish” tiene ahora dupe_count igual a 3 para reflejar sus tres encuentros de “contacto”.\n*Desplázate a la izquierda para ver más filas**\n\n# duplicados basados SOLO en las columnas name y purpose\nobs %&gt;% \n  janitor::get_dupes(name, purpose)\n\n\n\n\n\n\n\nVer los datos originales.\nPara más detalles, consulta ?get_dupes o esta referencia en línea\n\n\n\nMantener sólo filas únicas\nPara mantener sólo las filas únicas de un dataframe, utiliza distinct() de dplyr (como se muestra en la página Limpieza de datos y funciones básicas). Las filas duplicadas se eliminan de forma que sólo se conserva la primera de dichas filas. Por defecto, “primero” significa el rownumber más alto (orden de filas de arriba a abajo). Sólo se mantienen las filas únicas.\nEn el ejemplo siguiente, ejecutamos distinct() de forma que la columna recordID se excluye de la consideración - así se eliminan dos filas duplicadas. La primera fila (para “adam”) estaba 100% duplicada y ha sido eliminada. También la fila 3 (para “amrish”) estaba duplicada en todas las columnas excepto en recordID (que no se tiene en cuenta), por lo que también se ha eliminado. El set de datos obs tiene ahora nrow(obs)-2 filas, no nrow(obs)).\nDesplázate a la izquierda para ver el dataframe completo\n\n# añadido a una cadena de pipes (ej: limpieza de datos)\nobs %&gt;% \n  distinct(across(-recordID), # reduce el data frame a sólo filas únicas (mantiene la primera de cualquier duplicado)\n           .keep_all = TRUE) \n\n# si fuera de pipes, incluir los datos como primer argumento \n# distinct(obs)\n\n\n\n\n\n\n\nPRECAUCIÓN: Si se utiliza distinct() en datos agrupados, la función se aplicará a cada grupo.\nDe-duplicar en base a columnas específicas\nTambién puedes especificar las columnas que serán la base de la De-duplicación. De esta manera, la De-duplicación sólo se aplica a las filas que están duplicadas dentro de las columnas especificadas. A menos que establece .keep_all = TRUE, todas las columnas no mencionadas se eliminarán.\nEn el ejemplo siguiente, la De-duplicación sólo se aplica a las filas que tienen valores idénticos para las columnas name y purpose. Por lo tanto, “brian” sólo tiene 2 filas en lugar de 3: su primer encuentro como “contacto” y su único encuentro como “caso”. Para ajustar que se mantenga el último encuentro de brian de cada propósito, Mira el apartado Cortar dentro de los grupos.\nDesplázate a la izquierda para ver el dataframe completo\n\n# añadido a una cadena de pipes (ej: limpieza de datos)\nobs %&gt;% \n  distinct(name, purpose, .keep_all = TRUE) %&gt;%  # mantiene filas únicas por nombre y propósito, conserva todas las columnas\n  arrange(name)                                  # organiza para facilitar la visualización\n\n\n\n\n\n\n\nVer los datos originales.\n\n\n\nDe-duplicar elementos en un vector\nLa función duplicated() de R base evaluará un vector (columna) y devolverá un vector lógico de la misma longitud (TRUE/FALSE). La primera vez que aparezca un valor, devolverá FALSE (no es un duplicado), y las siguientes veces que aparezca ese valor devolverá TRUE. Nótese que NA se trata igual que cualquier otro valor.\n\nx &lt;- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)\n\n [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nPara devolver sólo los elementos duplicados, se pueden utilizar paréntesis para subconjuntar el vector original:\n\nx[duplicated(x)]\n\n[1]  1 NA  4  4  1  2\n\n\nPara devolver sólo los elementos únicos, utiliza unique() de R base. Para eliminar los NA de la salida, anida na.omit() dentro de unique().\n\nunique(x)           # alternativamente, usa x[!duplicated(x)]\n\n[1]  1  2 NA  4  5\n\nunique(na.omit(x))  # elimina NAs \n\n[1] 1 2 4 5\n\n\n\n\n\nUtilizando R base\nPara devolver las filas duplicadas\nEn R base, también se puede ver qué filas están 100% duplicadas en un dataframe df con el comando duplicated(df) (devuelve un vector lógico de las filas).\nAsí, también puedes utilizar el subconjunto base [ ] en el dataframe para ver las filas duplicadas con df[duplicated(df),] (¡no olvides la coma, que significa que quieres ver todas las columnas!)\nPara devolver filas únicas\nVer las notas anteriores. Para ver las filas únicas se añade el negador lógico ! delante de la función duplicated(): df[!duplicated(df),]\nPara devolver las filas que son duplicados de sólo ciertas columnas\nSubconjunta el df que está dentro de los paréntesis de duplicated(), para que esta función opere sólo en ciertas columnas del df. Para especificar las columnas, proporciona los números o nombres de las columnas después de una coma (recuerda que todo esto está dentro de la función duplicated()).\n¡Asegúrate también de mantener la coma , fuera, después de la función duplicated()!\nPor ejemplo, para evaluar sólo las columnas 2 a 5 en busca de duplicados: df[!duplicated(df[, 2:5]),] Para evaluar sólo las columnas name y purpose en busca de duplicados: df[!duplicated(df[, c(\"name\", \"purpose)]),]",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html#slicing",
    "href": "new_pages/deduplication.es.html#slicing",
    "title": "15  De-duplicación",
    "section": "15.3 Recortar",
    "text": "15.3 Recortar\nPara “recortar” un dataframe con un filtro de filas por su número de fila/posición. Esto resulta especialmente útil si tiene varias filas por grupo funcional (por ejemplo, por “persona”) y sólo quieres conservar una o algunas de ellas.\nLa función básica slice() acepta números y devuelve filas en esas posiciones. Si los números proporcionados son positivos, sólo se devuelven éstos. Si son negativos, no se devuelven esas filas. Los números deben ser todos positivos o todos negativos.\n\nobs %&gt;% slice(4)  # devuelve la 4ª fila\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n\n\nobs %&gt;% slice(c(2,4))  #  devuelve las filas 2 y 4\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        1        1   adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2        3        2 amrish 2020-01-02 14:20         1 contact            No\n\n#obs %&gt;% slice(c(2:4))  # devuelve las filas 2 a 4\n\nVer los datos originales.\nExisten diversas variantes: Se les debe proporcionar una columna y un número de filas a devolver (a n =).\n\nslice_min() y slice_max() mantienen sólo la(s) fila(s) con el valor(es) mínimo o máximo de la columna especificada. Esto también funciona para devolver el “min” y el “max” de los factores ordenados.\nslice_head() y slice_tail() - mantienen sólo la primera o la última fila.\nslice_sample() - mantener sólo una muestra aleatoria de las filas.\n\n\nobs %&gt;% slice_max(encounter, n = 1)  # devuelve las filas con el mayor número de encuentros\n\n  recordID personID   name       date  time encounter purpose symptoms_ever\n1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n2       13        3 mariah 2020-01-06 08:32         3 contact            No\n3       16        5  brian 2020-01-07 07:59         3    case            No\n\n\nUtiliza los argumentos n = o prop = para especificar el número o la proporción de filas que deben conservarse. Si no se utiliza la función en una cadena de tuberías, proporciona primero el argumento datos (por ejemplo, slice(datos, n = 2)). Para más información, consulta con ?slice.\nOtros argumentos:\n.order_by = utilizado en slice_min() y slice_max() esta es una columna para ordenar por antes de recortarlas. with_ties = TRUE por defecto, lo que significa que se mantienen los empates. .preserve = FALSE por defecto. Si es TRUE, la estructura de agrupación se recalcula después del recorte. weight_by = Opcional, columna numérica para ponderar por (un número mayor tiene más probabilidades de ser muestreado). También replace = para saber si el muestreo se realiza con/sin reemplazo.\nCONSEJO: Al utilizar slice_max() y slice_min(), asegúrate de especificar/escribir el n = (por ejemplo, n = 2, no simplemente 2). De lo contrario, puedes obtener un error Error: …is not empty.. \nNOTA: Es posible que encuentres la función top_n(), que ha sido sustituida por las funciones slice. \n\n\nRecortar con grupos\nLas funciones slice_*() pueden ser muy útiles si se aplican a un dataframe agrupado porque la operación de recorte se realiza en cada grupo por separado. Utiliza la función group_by() junto con slice() para agrupar los datos y tomar un corte de cada grupo.\nEsto es útil para la De-duplicación si tienes varias filas por persona pero sólo quieres mantener una de ellas. Primero se utiliza group_by() con columnas clave que son las mismas por persona, y luego se utiliza una función slice en una columna que será diferente entre las filas agrupadas.\nEn el ejemplo siguiente, para mantener sólo el último encuentro por persona, agrupamos las filas por nombre y luego utilizamos slice_max() con n = 1 en la columna de date. Ten en cuenta que Para aplicar una función como `slice_max() en las fechas, la columna de fecha debe ser de tipo Date.\nPor defecto, los “empates” (por ejemplo, la misma fecha en este escenario) se mantienen, y todavía obtendríamos múltiples filas para algunas personas (por ejemplo, adam). Para evitar esto, establecemos with_ties = FALSE. Sólo obtendremos una fila por persona.\nPRECACUCIÓN: Si utilizas arrange(), especifica .by_group = TRUE para que los datos se ordenen dentro de cada grupo.\nPELIGRO: Si with_ties = FALSE, se mantiene la primera fila de un empate. Esto puede ser engañoso. Mira cómo para Mariah, ella tiene dos encuentros en su última fecha (6 de enero) y el primero (el más temprano) se mantuvo. Es probable que queramos mantener tu último encuentro en ese día. Mira cómo “romper” estos vínculos en el siguiente ejemplo. \n\nobs %&gt;% \n  group_by(name) %&gt;%       # agrupar las filas por 'name'\n  slice_max(date,          # mantener fila por grupo con valor máximo de fecha \n            n = 1,         # mantener sólo la fila más alta \n            with_ties = F) # si hay un empate (de fecha), tomar la primera fila\n\n\n\n\n\n\n\nArriba, por ejemplo, podemos ver que sólo se conservó la fila de Amrish del 5 de enero, y sólo se conservó la fila de Brian del 7 de enero. Ver los datos originales.\nRomper los “empates”\nSe pueden ejecutar múltiples sentencias de recorte para “romper empates”. En este caso, si una persona tiene varios encuentros en tu última fecha, se mantiene el encuentro con la última hora (se utiliza lubridate::hm() para convertir los caracteres de tiempo en tipo tiempo, ordenable). Observa ahora cómo, la única fila que se mantiene para “Mariah” el 6 de enero es el encuentro 3 de las 08:32, no el encuentro 2 de las 07:25.\n\n# Ejemplo de múltiples sentencias de corte para \"romper empates\"\nobs %&gt;%\n  group_by(name) %&gt;%\n  \n  # PRIMERO - cortar por la fecha más reciente\n  slice_max(date, n = 1, with_ties = TRUE) %&gt;% \n  \n  # SEGUNDO - si hay empate, seleccionar la fila con la hora más tardía; prohibidos los empates\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)\n\n\n\n\n\n\n\nEn el ejemplo anterior, también habría sido posible realizar un recorte por número de encuentro, pero mostramos el corte por fecha y hora a modo de ejemplo.\nCONSEJO: Para utilizar slice_max() o slice_min() en una columna “carácter”, ¡mútala a un tipo de factor ordenado!\nVer los datos originales.\n\n\n\nMantener todos pero marcados\nSi deseas conservar todos los registros pero marcar sólo algunos para tu análisis, considera un enfoque de dos pasos utilizando un número de registro/encuentro único:\n\nReduce/recorta el dataframe original a sólo las filas para el análisis. Guarda/conserva este dataframe reducido.\nEn el dataframe original, marca las filas según corresponda con case_when(), basándose en si tu identificador único de registro (recordID en este ejemplo) está presente en el dataframe reducido.\n\n\n# 1. Definir data frame de filas a mantener para el análisis\nobs_keep &lt;- obs %&gt;%\n  group_by(name) %&gt;%\n  slice_max(encounter, n = 1, with_ties = FALSE) # Conservar sólo el último encuentro por persona\n\n\n# 2.  Marcar el data frame original\nobs_marked &lt;- obs %&gt;%\n\n   # crear nueva columna dup_record\n  mutate(dup_record = case_when(\n    \n    # si el registro está en el data frame obs_keep\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # todos los demás marcados como \" Ignore \" para fines de análisis\n    TRUE                            ~ \"Ignore\"))\n\n# imprimir\nobs_marked\n\n   recordID personID    name       date  time encounter purpose symptoms_ever\n1         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n2         1        1    adam 2020-01-01 09:00         1 contact          &lt;NA&gt;\n3         2        2  amrish 2020-01-02 14:20         1 contact            No\n4         3        2  amrish 2020-01-02 14:20         1 contact            No\n5         4        3  mariah 2020-01-05 12:00         1    case            No\n6         5        2  amrish 2020-01-05 16:10         3    case           Yes\n7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes\n8         7        5   brian 2020-01-05 15:20         1 contact            No\n9         8        6   smita 2020-01-05 14:20         1 contact           Yes\n10        9        7  raquel 2020-01-05 12:30         1 contact          &lt;NA&gt;\n11       10        2  amrish 2020-01-02 10:24         2 contact           Yes\n12       11        1    adam 2020-01-05 09:40         2    case            No\n13       12        3  mariah 2020-01-06 07:25         2 contact            No\n14       13        3  mariah 2020-01-06 08:32         3 contact            No\n15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes\n16       15        5   brian 2020-01-06 15:31         2 contact           Yes\n17       16        5   brian 2020-01-07 07:59         3    case            No\n18       17        7  raquel 2020-01-07 11:13         2 contact            No\n19       18        8 natalie 2020-01-07 17:12         1    case            No\n     dup_record\n1        Ignore\n2        Ignore\n3        Ignore\n4        Ignore\n5        Ignore\n6  For analysis\n7        Ignore\n8        Ignore\n9  For analysis\n10       Ignore\n11       Ignore\n12 For analysis\n13       Ignore\n14 For analysis\n15 For analysis\n16       Ignore\n17 For analysis\n18 For analysis\n19 For analysis\n\n\n\n\n\n\n\n\nVer los datos originales.\n\n\n\nCalcular la exhaustividad de las filas\nCrea una columna que contenga una métrica para la exhaustividad/completitud de la fila (que no tenga valores faltantes). Esto podría ser útil a la hora de decidir qué filas se priorizan sobre otras al de-duplicar/repartir.\nEn este ejemplo, las columnas “clave” sobre las que se quiere medir la integridad se guardan en un vector de nombres de columnas.\nA continuación se crea la nueva columna key_completeness con mutate(). El nuevo valor de cada fila se define como una fracción calculada: el número de valores no ausentes en esa fila entre las columnas clave, dividido por el número de columnas clave.\nEsto implica la función rowSums() de R base. También se utiliza . , que dentro del piping se refiere al dataframe en ese punto (en este caso, se está subconjuntando con corchetes []).\n*Desplázate a la derecha para ver más filas**.\n\n# crear una columna \"key variable\" de exhaustividad\n# esta es una *proporción* de las columnas designadas como \"key_cols\" que tienen valores no ausentes\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %&gt;% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) \n\n\n\n\n\n\n\nVer los datos originales.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html#str_rollup",
    "href": "new_pages/deduplication.es.html#str_rollup",
    "title": "15  De-duplicación",
    "section": "15.4 Combinación de valores",
    "text": "15.4 Combinación de valores\nEsta sección describe:\n\nCómo “combinar” valores de varias filas en una sola fila, con algunas variaciones\nUna vez que se hayan “combinado” los valores, cómo sobrescribir/priorizar los valores en cada celda\n\nEsta sección utiliza los datos de ejemplo de la sección Preparación.\n\n\nCombinar los valores en una fila\nEl código de ejemplo que se muestra a continuación utiliza group_by() y summarise() para agrupar las filas por persona, y luego pega todos los valores únicos dentro de las filas agrupadas. Así, se obtiene una fila de resumen por persona. Algunas notas:\n\nSe añade un sufijo a todas las nuevas columnas (“_roll” en este ejemplo)\nSi quieres mostrar sólo los valores únicos por celda, entonces envuelve el na.omit() con unique()\nna.omit() elimina los valores NA, pero si no se desea se puede eliminar con paste0(.x)…\n\n\n# valores \"móviles\" en una fila por grupo (por \"personID\") \ncases_rolled &lt;- obs %&gt;% \n  \n  # crear grupos por nombre\n  group_by(personID) %&gt;% \n  \n    # ordenar las filas dentro de cada grupo (por ejemplo, por fecha)\n  arrange(date, .by_group = TRUE) %&gt;% \n  \n    # Para cada columna, pegar todos los valores dentro de las filas agrupadas, separados por \";\"\n  summarise(\n    across(everything(),                           # aplicar a todas las columnas\n           ~paste0(na.omit(.x), collapse = \"; \"))) # se define la función que combina los valores que no son valores NA\n\nEl resultado es una fila por grupo (ID), con entradas ordenadas por fecha y pegadas. Desplázate a la izquierda para ver más filas\n\n\n\n\n\n\nVer los datos originales.\nEsta variación sólo muestra valores únicos:\n\n# Variación - muestra sólo valores únicos\ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                                   # aplicar a todas las columnas\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # se define la función que combina los valores que no son valores NA\n\n\n\n\n\n\n\nEsta variación añade un sufijo a cada columna. En este caso, “_roll” para indicar que se ha combinado (roll):\n\n# Variación - sufijo añadido a los nombres de columna \ncases_rolled &lt;- obs %&gt;% \n  group_by(personID) %&gt;% \n  arrange(date, .by_group = TRUE) %&gt;% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll se añade a los nombres de columna\n\n\n\n\n\n\n\n\n\n\nSobrescribir valores/jerarquía\nSi luego quieres evaluar todos los valores combinados, y mantener sólo un valor específico (por ejemplo, el “mejor” o el “máximo” valor), puedes utilizar mutate() a través de las columnas deseadas, para implementar case_when(), que utiliza str_detect() del paquete stringr para buscar secuencialmente patrones de cadena y sobrescribir el contenido de la celda.\n\n# LIMPIAR CASOS\n###############\ncases_clean &lt;- cases_rolled %&gt;% \n    \n    # limpia las vars Yes-No-Unknown: sustituye el texto por el valor \"más alto\" presente en la cadena\n    mutate(across(c(contains(\"symptoms_ever\")),                     # opera en las columnas especificadas (Y/N/U)\n             list(mod = ~case_when(                                 # añade el sufijo \"_mod\" a las nuevas cols; implementa case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # si se detecta \" Yes \", entonces el valor de la celda se convierte en yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # entonces, si se detecta \"No\", el valor de la celda se convierte en no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # entonces, si se detecta \" Unknown \", el valor de la celda se convierte en Unknown\n               TRUE                        ~ as.character(.x)))),   # entonces, si cualquier otra cosa si mantiene tal cual\n      .keep = \"unused\")                                             # las columnas antiguas se eliminan, dejando sólo las columnas _mod\n\nAhora puedes ver en la columna symptoms_ever que si la persona ALGUNA vez dijo “Sí” a los síntomas, entonces sólo se muestra “Sí”.\n\n\n\n\n\n\nVer los datos originales.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html#probabilistic-de-duplication",
    "href": "new_pages/deduplication.es.html#probabilistic-de-duplication",
    "title": "15  De-duplicación",
    "section": "15.5 De-duplicación probabilística",
    "text": "15.5 De-duplicación probabilística\nA veces, puedes querer identificar duplicados “probables” basándote en la similitud (por ejemplo, la “distancia” de la cadena) en varias columnas como el nombre, la edad, el sexo, la fecha de nacimiento, etc. Puedes aplicar un algoritmo de coincidencia probabilística para identificar duplicados probables.\nConsulta la página sobre la unión de datos para obtener una explicación sobre este método. La sección sobre Coincidencia probabilística contiene un ejemplo de aplicación de estos algoritmos para comparar un dataframe consigo mismo, realizando así una De-duplicación probabilística.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/deduplication.es.html#resources-8",
    "href": "new_pages/deduplication.es.html#resources-8",
    "title": "15  De-duplicación",
    "section": "15.6 Recursos",
    "text": "15.6 Recursos\nGran parte de la información de esta página está adaptada de estos recursos y viñetas en línea:\ndatanovia\nReferencia de dplyr tidyverse\nViñeta janitor de CRAN",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>De-duplicación</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.es.html",
    "href": "new_pages/iteration.es.html",
    "title": "16  Iteración, bucles y listas",
    "section": "",
    "text": "16.1 Preparación",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteración, bucles y listas</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.es.html#preparation-7",
    "href": "new_pages/iteration.es.html#preparation-7",
    "title": "16  Iteración, bucles y listas",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n     rio,         # importación/exportación\n     here,        # localizador de ficheros\n     purrr,       # iteración\n     grates,      # scales in ggplot\n     tidyverse    # gestión y visualización de datos\n)\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).\n\n# importar el listado de casos\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteración, bucles y listas</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.es.html#for-loops",
    "href": "new_pages/iteration.es.html#for-loops",
    "title": "16  Iteración, bucles y listas",
    "section": "16.2 bucles for",
    "text": "16.2 bucles for\n\nbucles for en R\nLos bucles for no se resaltan mucho en R, pero son comunes en otros lenguajes de programación. Como principiante, pueden ser útiles para aprender y practicar, ya que son más fáciles de “explorar”, “depurar”, y de otra manera comprender exactamente lo que está sucediendo para cada iteración, especialmente cuando todavía no te sientes cómodo escribiendo tus propias funciones.\nPuedes pasar rápidamente de los bucles for a la iteración con funciones mapeadas con purrr (véase la sección siguiente).\n\n\nComponentes básicos\nUn bucle for tiene tres partes fundamentales:\n\nLa secuencia de elementos a iterar\nLas operaciones a realizar por cada elemento de la secuencia\nEl contenedor de los resultados (opcional)\n\nLa sintaxis básica es: for (para cada elemento de la secuencia) {hacer operaciones con el elemento}. Fíjate en los paréntesis y las llaves. Los resultados pueden ser impresos en la consola, o almacenados en un objeto R contenedor.\nA continuación se muestra un sencillo ejemplo de bucle for.\n\nfor (num in c(1,2,3,4,5)) {  # La SECUENCIA está definida (números de 1 a 5) y el bucle se abre con \"{\"\n  print(num + 2)             # Las OPERACIONES (añadir dos a cada elemento de la secuencia e imprimirlos en la consola)\n}                            # El bucle se cierra con \"}\"                            \n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n\n                             # No hay CONTENEDOR\" en este ejemplo\n\n\n\nSecuencia\nEsta es la parte “for” de un bucle for - las operaciones se ejecutarán “para” (for) cada elemento de la secuencia. La secuencia puede ser una serie de valores (por ejemplo, nombres de jurisdicciones, enfermedades, nombres de columnas, elementos de listas, etc.), o puede ser una serie de números consecutivos (por ejemplo, 1,2,3,4,5). Cada enfoque tiene sus propias utilidades, que se describen a continuación.\nLa estructura básica de una declaración de secuencia es el elemento en el vector.\n\nPuedes escribir cualquier carácter o palabra en lugar de “item” (por ejemplo, “i”, “num”, “hosp”, “district”, etc.). El valor de este “elemento” cambia con cada iteración del bucle, pasando por cada valor del vector.\nEl vector puede ser de valores de caracteres, nombres de columnas, o quizás una secuencia de números - estos son los valores que cambiarán con cada iteración. Puedes utilizarlos dentro de las operaciones del bucle for utilizando el término “item”.\n\nEjemplo: secuencia de valores de caracteres\nEn este ejemplo, se realiza un bucle para cada valor de un vector de caracteres predefinido de nombres de hospitales.\n\n# crea un vector con los nombres de los hospitales\nhospital_names &lt;- unique(linelist$hospital)\nhospital_names # imprimir\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n[6] \"Central Hospital\"                    \n\n\nHemos elegido el término hosp para representar los valores del vector nombres_de_hospital. Para la primera iteración del bucle, el valor de hosp será hospital_names[1]]. Para la segunda iteración del bucle será hospital_names[2]]. Y así sucesivamente…\n\n# un 'bucle for' con secuencia de caracteres\n\nfor (hosp in hospital_names){       # secuencia\n  \n       # OPERACIONES AQUÍ\n  }\n\nEjemplo: secuencia de nombres de columnas\nSe trata de una variación de la secuencia de caracteres anterior, en la que se extraen los nombres de un objeto R existente y se convierten en el vector. Por ejemplo, los nombres de las columnas de un dataframe. Convenientemente, en el código de operaciones del bucle for, los nombres de las columnas se pueden utilizar para indexar (subconjuntar) tu dataframe original\nA continuación, la secuencia son los names() (nombres de columnas) del dataframe linelist. El nombre de nuestro “elemento” es col, que representará el nombre de cada columna a medida que avanzan los bucles.\nA modo de ejemplo, incluimos código de operaciones dentro del bucle for, que se ejecuta para cada valor de la secuencia. En este código, los valores de la secuencia (nombres de las columnas) se utilizan para indexar (subconjuntar) linelist, una por una. Como se enseñó en la página de fundamentos de R, se utilizan dobles ramificaciones [[ ]] para el subconjunto. La columna resultante se pasa a is.na(), y luego a sum() para producir el número de valores de la columna que faltan. El resultado se imprime en la consola: un número por cada columna.\nUna nota sobre la indexación con los nombres de las columnas - ¡cuando se refiera a la propia columna ¡no escribas simplemente “col”! ya que representa sólo el nombre de la columna de caracteres! Para referirse a la columna completa debe utilizar el nombre de la columna como un índice en linelist a través de linelist[[col]].\n\nfor (col in names(linelist)){        # el bucle se ejecuta para cada columna de linelist; nombre de columna representado por \"col\" \n  \n  # Ejemplo de código de operaciones - imprimir el número de valores peridos en la columna\n  print(sum(is.na(linelist[[col]])))   # linelist está indexada por el valor actual de \"col\"\n     \n}\n\n[1] 0\n[1] 0\n[1] 2087\n[1] 256\n[1] 0\n[1] 936\n[1] 1323\n[1] 278\n[1] 86\n[1] 0\n[1] 86\n[1] 86\n[1] 86\n[1] 0\n[1] 0\n[1] 0\n[1] 2088\n[1] 2088\n[1] 0\n[1] 0\n[1] 0\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 149\n[1] 765\n[1] 0\n[1] 256\n\n\nSecuencia de números\nEn este enfoque, la secuencia es una serie de números consecutivos. Por lo tanto, el valor del “ítem” no es un valor de carácter (por ejemplo, “Hospital Central” o “fecha_de_inicio”), sino que es un número. Esto es útil para hacer un bucle a través de los dataframes, ya que puedeS utilizar el número del “ítem” dentro del bucle for para indexar el dataframe por número de fila.\nPor ejemplo, digamos que quiereS recorrer cada fila de tu dataframe y extraer cierta información. Sus “elementos” serían números de fila numéricos. A menudo, los “elementos” en este caso se escriben como i.\nEl proceso del bucle for podría explicarse en palabras como “para cada elemento de una secuencia de números desde 1 hasta el número total de filas de mi dataframe, haz X”. Para la primera iteración del bucle, el valor del “elemento” i sería 1. Para la segunda iteración, i sería 2, etc.\nAquí está el aspecto de la secuencia en código: for (i in 1:nrow(linelist)) {CODIGO DE OPERACIONES} donde i representa el “elemento” y 1:nrow(linelist) produce una secuencia de números consecutivos desde 1 hasta el número de filas en linelist.\n\nfor (i in 1:nrow(linelist)) {  # utilizar en un data frame\n  # OPERACIONES AQUÍ\n}  \n\nSi quieres que la secuencia sea numérica, pero partes de un vector (no de un dataframe), utiliza el atajo seq_along() para devolver una secuencia de números para cada elemento del vector. Por ejemplo, for (i en seq_along(nombres_de_hospital) {Código_de_operaciones}.\nEl código siguiente devuelve en realidad números, que se convertirían en el valor deien tu respectivo bucle.\n\nseq_along(hospital_names)  # use on a named vector\n\n[1] 1 2 3 4 5 6\n\n\nUna ventaja de usar números en la secuencia es que es fácil usar también el númeroipara indexar un contenedor que almacene las salidas del bucle. Hay un ejemplo de esto en la sección de Operaciones más abajo.\n\n\nOperaciones\nEste es el código dentro de las llaves { } del bucle for. Quieres que este código se ejecute para cada “elemento” de la secuencia. Por lo tanto, ¡ten cuidado de que cada parte de tu código que cambia por el “ítem” esté correctamente codificado de manera que realmente cambie! Por ejemplo, recuerda usar [[ ]] para la indexación.\nEn el ejemplo siguiente, iteramos por cada fila de linelist. Los valores de género y edad de cada fila se pegan juntos y se almacenan en el vector de caracteres contenedor cases_demographics. Observa cómo también utilizamos la indexación [[i]] para guardar la salida del bucle en la posición correcta en el vector “contenedor”.\n\n# crear un contenedor para almacenar los resultados - un vector de caracteres\ncases_demographics &lt;- vector(mode = \"character\", length = nrow(linelist))\n\n# el bucle for\nfor (i in 1:nrow(linelist)){\n  \n  # OPERACIONES\n  # extraer valores de linelist para la fila i, usando paréntesis para indexarlos\n  row_gender  &lt;- linelist$gender[[i]]\n  row_age     &lt;- linelist$age_years[[i]]    # ¡no olvidar indexar!\n     \n  # combinar género-edad y almacenar en el vector contenedor en la ubicación indexada\n  cases_demographics[[i]] &lt;- str_c(row_gender, row_age, sep = \",\") \n\n}  # fin del bucle for\n\n\n# mostrar las 10 primeras filas del contenedor\nhead(cases_demographics, 10)\n\n [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\"\n\n\n\n\nContenedor\nA veces los resultados de tu bucle for se imprimirán en la consola o en el panel de gráficos de RStudio. Otras veces, querrás almacenar los resultados en un “contenedor” para su uso posterior. Dicho contenedor puede ser un vector, un dataframe o incluso una lista.\nLo más eficiente es crear el contenedor de los resultados antes de comenzar el bucle for. En la práctica, esto significa crear un vector vacío, un dataframe o una lista. Estos pueden ser creados con las funciones vector() para vectores o listas, o con matrix() y data.frame() para un dataframe.\nVector vacío\nUtiliza vector() y especifica el mode = en función del tipo esperado de objetos que vas a insertar - ya sea “double” (para contener números), “carácter” o “lógico”. También debes establecer la length = (longitud) por adelantado. Esta debe ser la longitud de tu secuencia de bucle for.\nDigamos que quieres almacenar la mediana de la demora hasta el ingreso para cada hospital. Utilizarís “double” y establecerías que la longitud fuera el número de salidas esperadas (el número de hospitales únicos en el set de datos).\n\ndelays &lt;- vector(\n  mode = \"double\",                            # esperamos almacenar números\n  length = length(unique(linelist$hospital))) # el número de hospitales únicos en el conjunto de datos\n\nDataframe vacío\nPuedes hacer un dataframe vacío especificando el número de filas y columnas de esta manera:\n\ndelays &lt;- data.frame(matrix(ncol = 2, nrow = 3))\n\nLista vacía\nEs posible que desees almacenar algunos gráficos creados por un bucle for en una lista. Una lista es como un vector, pero contiene otros objetos R dentro de ella que pueden ser de diferente tipo. Los elementos de una lista pueden ser un solo número, un dataframe, un vector e incluso otra lista.\nEn realidad, se inicializa una lista vacía utilizando el mismo comando vector() que el anterior, pero con mode = \"list\". Especifica la longitud como quieras.\n\nplots &lt;- vector(mode = \"list\", length = 16)\n\n\n\nImpresión\nTen en cuenta que para imprimir desde dentro de un bucle for probablemente tendrás que envolver explícitamente con la función print(). En este ejemplo, la secuencia es un vector de caracteres explícito, que se utiliza para subsumir linelist en un hospital. Los resultados no se almacenan en un contenedor, sino que se imprimen en la consola con la función print().\n\nfor (hosp in hospital_names){ \n     hospital_cases &lt;- linelist %&gt;% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}\n\n[1] 885\n[1] 1469\n[1] 422\n[1] 1762\n[1] 896\n[1] 454\n\n\n###Probar tu bucle for {.unnumbered}\nPara probar tu bucle, puedes ejecutar un comando para hacer una asignación temporal del “elemento”, como i &lt;- 10 o hosp &lt;- \"Central Hospital \". Haz esto fuera del bucle y luego ejecuta tu código de operaciones solamente (el código dentro de las llaves) para ver si se producen los resultados esperados.\n\n\nBucles con gráficos\nPara reunir los tres componentes (contenedor, secuencia y operaciones) vamos a intentar trazar una epicurva para cada hospital (véase la página sobre curvas epidémicas).\nPodemos hacer una bonita epicurva de todos los casos por género utilizando el paquete incidence2 como se indica a continuación:\n\n# crear objeto 'incidence' \noutbreak &lt;- incidence2::incidence(   \n     x = linelist,                   # dataframe - linelist completo\n     date_index = \"date_onset\",      # columna de fecha\n     interval = \"week\",              # agregar recuentos semanales\n     groups = \"gender\")                # agrupar valores por género\n     #na_as_group = TRUE)             # los valores perdidos de género tienen su grupo propio\n\n# trazar curva epidemiológica\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # Fill colour of bars by gender\n       color = \"black\"      # Contour colour of bars\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n\n\n\n\n\n\n\n\nPara producir un gráfico separado para cada caso del hospital, podemos poner este código de epicurva dentro de un bucle for.\nEn primer lugar, guardamos un vector con los nombres únicos de los hospitales, hospital_names. El bucle for se ejecutará una vez para cada uno de estos nombres: for (hosp in hospital_names). En cada iteración del bucle for, el nombre actual del hospital del vector se representará como hosp para tu uso dentro del bucle.\nDentro de las operaciones del bucle, puedes escribir el código R de forma normal, pero utilizando el “elemento” (hosp en este caso) sabiendo que tu valor será cambiante. Dentro de este bucle:\n\nSe aplica un filter() a linelist, de forma que la columna hospital debe ser igual al valor actual de hosp\nEl objeto de incidencia se crea en linelist filtradas\nSe crea una gráfica del hospital actual, con un título autoajustable que utiliza hosp\nEl gráfico del hospital actual se guarda temporalmente y luego se imprime\nEl bucle sigue adelante para repetirse con el siguiente hospital de hospital_names\n\n\n# crear un vector con los nombres de los hospitales\nhospital_names &lt;- unique(linelist$hospital)\n\n# para cada nombre (\"hosp\") en hospital_names, crear e imprimir la curva epidémica\nfor (hosp in hospital_names) {\n     \n     # crear objeto de incidencia específico para el hospital actual\n     outbreak_hosp &lt;- incidence2::incidence(\n          x = linelist %&gt;% filter(hospital == hosp),   # se filtra linelist para el hospital actual\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\"#,\n          #na_as_group = TRUE\n     )\n     \n     # Crea y guarda la gráfica. El título se ajusta automáticamente al hospital actual\n      plot_hosp &lt;- ggplot(outbreak_hosp, # incidence object name\n                         aes(x = date_index, #axes\n                             y = count, \n                             fill = gender), # fill colour by gender\n                         color = \"black\"      # colour of bar contour\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #title\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # With older versions of R, remove the # before na_as_group and use this plot command instead.\n    # plot_hosp &lt;- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     # imprime el gráfico para el hospital actual\n     print(plot_hosp)\n     \n} # finaliza el bucle for cuando se ha ejecutado para cada hospital en hospital_names \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeguimiento del progreso de un bucle\nUn bucle con muchas iteraciones puede funcionar durante muchos minutos o incluso horas. Por lo tanto, puede ser útil imprimir el progreso en la consola de R. La sentencia if de abajo puede colocarse dentro de las operaciones del bucle para imprimir cada 100 números. Sólo tiene que ajustarla para que i sea el “elemento” de tu bucle.\n\n# bucle con código para imprimir el progreso cada 100 iteraciones\nfor (i in seq_len(nrow(linelist))){\n\n  # imprimir progreso\n  if(i %% 100==0){    # El operador %% es el resto\n    print(i)\n\n}",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteración, bucles y listas</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.es.html#iter_purrr",
    "href": "new_pages/iteration.es.html#iter_purrr",
    "title": "16  Iteración, bucles y listas",
    "section": "16.3 purrr y listas",
    "text": "16.3 purrr y listas\nOtro enfoque de las operaciones iterativas es el paquete purrr - es el enfoque tidyverse de la iteración.\nSi tienes que realizar la misma tarea varias veces, probablemente merezca la pena crear una solución generalizada que puedas utilizar en muchas entradas. Por ejemplo, producir gráficos para múltiples jurisdicciones, o importar y combinar muchos archivos.\nTambién hay algunas otras ventajas de purrr - puedes usarlo con pipes %&gt;%, que maneja los errores mejor que los bucles for normales, ¡y la sintaxis es bastante limpia y simple! Si estás utilizando un bucle for, probablemente puedas hacerlo de forma más clara y sucinta con purrr!\nTen en cuenta que purrr es una herramienta de programación funcional. Es decir, las operaciones que se van a aplicar de forma iterativa están envueltas en funciones. Consulta la página Escribir funciones para aprender a escribir tus propias funciones.\npurrr también se basa casi por completo en listas y vectores, así que piensa en ello como si aplicaras una función a cada elemento de esa lista/vector.\n\nCargar paquetes\npurrr forma parte de tidyverse, por lo que no es necesario instalar/cargar un paquete aparte.\n\npacman::p_load(\n     rio,         # importación/exportación\n     here,        # localizador de ficheros\n     tidyverse,    # gestión y visualización de datos\n     writexl,     # escribe un fichero Excel con múltiples hojas\n     readxl       # importa Excel con múltiples hojas\n)\n\n\n\nmap()\nUna de las funciones principales de purrr es map(), que “mapea” (aplica) una función a cada elemento de entrada de una lista/vector que has proporcionado.\nLa sintaxis básica es map(.x = SECUENCIA, .f = FUNCIÓN, OTROS ARGUMENTOS). Con un poco más de detalle:\n\n.x = son las entradas sobre las que se aplicará iterativamente la función .f - por ejemplo, un vector de nombres de jurisdicciones, columnas de un dataframe o una lista de dataframes\n.f = es la función a aplicar a cada elemento de la entrada .x - puede ser una función como print() que ya existe, o una función personalizada que tu definas. La función se suele escribir después de una tilde ~ (detalles más abajo).\n\nAlgunas notas más sobre la sintaxis:\n\nSi la función no necesita especificar más argumentos, puede escribirse sin paréntesis y sin tilde (por ejemplo, .f = mean). Para proporcionar argumentos que tendrán el mismo valor en cada iteración, escríbelos dentro de map() pero fuera del argumento .f =, como por ejemplo na.rm = T en map(.x = mi_lista, .f = mean, na.rm=T).\nPuedes utilizar .x (o simplemente . ) dentro de la función .f = como marcador de posición para el valor .x de esa iteración\nUtiliza la sintaxis con tilde (~) para tener un mayor control sobre la función - escribe la función de forma normal con paréntesis, como por ejemplo: map(.x = mi_lista, .f = \\~mean(., na.rm = T)). Utiliza esta sintaxis sobre todo si el valor de un argumento va a cambiar en cada iteración, o si es el propio valor .x (véanse los ejemplos siguientes)\n\nLa salida al usar map() es una lista - una lista es un tipo de objeto como un vector pero cuyos elementos pueden ser de tipo diferente. Por lo tanto, una lista producida por map() podría contener muchos dataframes, o muchos vectores, muchos valores individuales, ¡o incluso muchas listas! Existen versiones alternativas de map() que se explican a continuación y que producen otros tipos de salidas (por ejemplo, map_dfr() para producir un dataframe, map_chr() para producir vectores de caracteres y map_dbl() para producir vectores numéricos).\n\nEjemplo: importar y combinar hojas de Excel\nHagamos una demostración con una tarea epidemiológica común: - Quieres importar un libro de Excel con datos de casos, pero los datos están divididos en diferentes hojas en el libro. ¿Cómo puedes importar y combinar eficazmente las hojas en un dataframe?\nSupongamos que nos envían el siguiente libro de Excel. Cada hoja contiene casos de un determinado hospital.\n\n\n\n\n\n\n\n\n\nEste es un enfoque que utiliza map():\n\nmap() la función import() para que se ejecute para cada hoja de Excel\nCombinar los dataframes importados en uno solo utilizando bind_rows()\nA lo largo del proceso, conserva el nombre original de la hoja para cada fila, almacenando esta información en una nueva columna en el dataframe final\n\nEn primer lugar, tenemos que extraer los nombres de las hojas y guardarlos. Proporcionamos la ruta del archivo de Excel a la función excel_sheets() del paquete readxl, que extrae los nombres de las hojas. Los almacenamos en un vector de caracteres llamado sheet_names.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\nAquí están los nombres:\n\nsheet_names\n\n[1] \"Central Hospital\"              \"Military Hospital\"            \n[3] \"Missing\"                       \"Other\"                        \n[5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\n\n\nAhora que tenemos este vector de nombres, map() puede proporcionarlos uno a uno a la función import(). En este ejemplo, los sheet_names son .x e import() es la función .f.\nRecuerda de la página de importación y exportación que cuando se utiliza en libros de Excel, import() puede aceptar el argumento which = especificando la hoja a importar. Dentro de la función .f en import(), proporcionamos which = .x, cuyo valor cambiará con cada iteración a través del vector `sheet_names - primero “Hospital Central”, luego “Military Hospital”, etc.\nHay que tener en cuenta que, como hemos utilizado map(), los datos de cada hoja de Excel se guardarán como un dataframe separado dentro de una lista. Queremos que cada uno de estos elementos de la lista (dataframes) tenga un elemento names, así que antes de pasar sheet_names a map() lo pasamos a través de set_names() de purrr, lo que asegura que cada elemento de la lista obtenga el nombre apropiado.\nGuardamos la lista de salida como combined.\n\ncombined &lt;- sheet_names %&gt;% \n  purrr::set_names() %&gt;% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\n\nCuando inspeccionamos la salida, vemos que los datos de cada hoja de Excel se guardan en la lista con un nombre. Esto es bueno, pero no hemos terminado.\n\n\n\n\n\n\n\n\n\nPor último, utilizamos la función bind_rows() (de dplyr) que acepta la lista de dataframes de estructura similar y los combina en un dataframe. Para crear una nueva columna a partir de los nombres de los elementos de la lista, utilizamos el argumento .id =y le proporcionamos el nombre deseado para la nueva columna.\nA continuación se muestra toda la secuencia de comandos:\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # extrae los nombres de las hojas\n \ncombined &lt;- sheet_names %&gt;%                                     # comienza con los nombres de las hojas\n  purrr::set_names() %&gt;%                                        # establece sus nombres\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %&gt;%  # iterativamente, importa, guarda en una lista\n  bind_rows(.id = \"origin_sheet\") # combina la lista de data frames, preservando el origen en la nueva columna  \n\n¡Y ahora tenemos un dataframe con una columna que contiene la hoja de origen!\n\n\n\n\n\n\n\n\n\nHay variaciones de map() que debes conocer. Por ejemplo, map_dfr() devuelve un dataframe, no una lista. Por lo tanto, podríamos haberla utilizado para la tarea anterior y no haber tenido que enlazar filas. Pero entonces no habríamos podido capturar de qué hoja (hospital) procedía cada caso.\nOtras variaciones son map_chr(), map_dbl(). Estas funciones son muy útiles por dos razones. En primer lugar, convierten automáticamente la salida de una función iterativa en un vector (no en una lista). En segundo lugar, pueden controlar explícitamente el tipo en el que vuelven los datos - te aseguras de que tus datos vuelven como un vector de caracteres con map_chr(), o vector numérico con map_dbl(). Volveremos a esto más adelante en la sección.\nLas funciones map_at() y map_if() también son muy útiles para la iteración - ¡permiten especificar en qué elementos de una lista se debe iterar! Funcionan simplemente aplicando un vector de índices/nombres (en el caso de map_at()) o una prueba lógica (en el caso de map_if()).\nUtilicemos un ejemplo en el que no queremos leer la primera hoja de datos del hospital. Usamos map_at() en lugar de map(), y especificamos el argumento .at = a c(-1) que significa no usar el primer elemento de .x. Alternativamente, puedes proporcionar un vector de números positivos, o nombres, a .at = para especificar qué elementos usar.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined &lt;- sheet_names %&gt;% \n     purrr::set_names() %&gt;% \n     # exclude the first sheet\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))\n\nTen en cuenta que el nombre de la primera hoja seguirá apareciendo como un elemento de la lista de salida, pero es sólo un nombre de un solo carácter (no un dataframe). Tendrás que eliminar este elemento antes de vincular las filas. Veremos cómo eliminar y modificar los elementos de la lista en una sección posterior.\n\n\n\nDividir los datos y exportar\nA continuación, damos un ejemplo de cómo dividir unos datos en partes y luego utilizar la iteración map() para exportar cada parte como una hoja de Excel separada, o como un archivo CSV separado.\n\nDividir los datos\nDigamos que tenemos una lista de casos de casos completa como un dataframe, y ahora queremos crear un listado separado para cada hospital y exportar cada una como un archivo CSV separado. A continuación, hacemos los siguientes pasos:\nUtiliza group_split() (de dplyr) para dividir el dataframe del listado por valores únicos en la columna hospital. La salida es una lista que contiene un dataframe por cada subconjunto de un hospital.\n\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital)\n\nPodemos ejecutar View(linelist_split) y ver que esta lista contiene 6 dataframes (“tibbles”), cada uno de los cuales representa los casos de un hospital.\n\n\n\n\n\n\n\n\n\nSin embargo, ten en cuenta que los dataframes de la lista no tienen nombres por defecto. Queremos que cada uno de ellos tenga un nombre, y luego utilizar ese nombre al guardar el archivo CSV.\nUn enfoque para extraer los nombres es utilizar pull() (de dplyr) para extraer la columna hospital de cada dataframe de la lista. Luego, para estar seguros, convertimos los valores a caracteres y luego usamos unique() para obtener el nombre de ese dataframe en particular. Todos estos pasos se aplican a cada dataframe mediante map().\n\nnames(linelist_split) &lt;- linelist_split %&gt;%   # Asigna a los nombres de los marcos de datos listados \n     # Extrae los nombres haciendo lo siguiente a cada data frame: \n     map(.f = ~pull(.x, hospital)) %&gt;%        # Extraer la columna hospital\n     map(.f = ~as.character(.x)) %&gt;%          # Convertir a carácter, por si acaso\n     map(.f = ~unique(.x))                    # Toma el nombre único del hospital\n\nAhora podemos ver que cada uno de los elementos de la lista tiene un nombre. Se puede acceder a estos nombres mediante names(linelist_split).\n\n\n\n\n\n\n\n\n\n\nnames(linelist_split)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Missing\"                             \n[4] \"Other\"                               \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\n\nMás de una columna group_split()\nSi deseas dividir linelist por más de una columna de agrupación, por ejemplo, para producir un listado de subconjuntos por la intersección de hospital Y género, necesitarás un enfoque diferente para nombrar los elementos de la lista. Esto implica recoger las “claves de grupo” únicas utilizando group_keys() de dplyr - se devuelven como un dataframe. Luego puedes combinar las claves de grupo en valores con unite() como se muestra a continuación, y asignar estos nombres conglomerados a linelist_split.\n\n# divide linelist por combinaciones únicas de hospital-género\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital, gender)\n\n# extrae group_keys() como un dataframe\ngroupings &lt;- linelist %&gt;% \n     group_by(hospital, gender) %&gt;%       \n     group_keys()\n\ngroupings      # muestra agrupaciones únicas \n\n# A tibble: 18 × 2\n   hospital                             gender\n   &lt;chr&gt;                                &lt;chr&gt; \n 1 Central Hospital                     f     \n 2 Central Hospital                     m     \n 3 Central Hospital                     &lt;NA&gt;  \n 4 Military Hospital                    f     \n 5 Military Hospital                    m     \n 6 Military Hospital                    &lt;NA&gt;  \n 7 Missing                              f     \n 8 Missing                              m     \n 9 Missing                              &lt;NA&gt;  \n10 Other                                f     \n11 Other                                m     \n12 Other                                &lt;NA&gt;  \n13 Port Hospital                        f     \n14 Port Hospital                        m     \n15 Port Hospital                        &lt;NA&gt;  \n16 St. Mark's Maternity Hospital (SMMH) f     \n17 St. Mark's Maternity Hospital (SMMH) m     \n18 St. Mark's Maternity Hospital (SMMH) &lt;NA&gt;  \n\n\nAhora combinamos las agrupaciones juntas, separadas por guiones, y las asignamos como los nombres de los elementos de la lista en linelist_split. Esto requiere algunas líneas adicionales, ya que sustituimos NA por “Missing”, utilizamos unite() de dplyr para combinar los valores de las columnas juntos (separados por guiones), y luego los convertimos en un vector sin nombre para poder utilizarlos como nombres de linelist_split.\n\n# Combinar en un valor de nombre \nnames(linelist_split) &lt;- groupings %&gt;% \n     mutate(across(everything(), replace_na, \"Missing\")) %&gt;%  # sustituye NA por \"Missing\" en todas las columnas\n     unite(\"combined\", sep = \"-\") %&gt;%                          # Unir todos los valores de columna en uno\n     setNames(NULL) %&gt;% \n     as_vector() %&gt;% \n     as.list()\n\n\n\n\nExportar como hojas de Excel\nPara exportar los listados del hospital como un libro de Excel con un listado por hoja, podemos simplemente proporcionar la lista con nombre linelist_split a la función write_xlsx() del paquete writexl. Esto tiene la capacidad de guardar un libro de Excel con múltiples hojas. Los nombres de los elementos de la lista se aplican automáticamente como los nombres de las hojas.\n\nlinelist_split %&gt;% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))\n\nAhora puedes abrir el archivo de Excel y ver que cada hospital tiene tu propia hoja.\n\n\n\n\n\n\n\n\n\n\n\nExportar como archivos CSV\nEs un comando un poco más complejo, pero también puedes exportar cada listado por hospital como un archivo CSV separado, con un nombre de archivo específico para el hospital.\nDe nuevo utilizamos map(): tomamos el vector de nombres de elementos de la lista (mostrado arriba) y utilizamos map() para iterar a través de ellos, aplicando export() (del paquete rio, véase la página Importar y exportar) en el dataframe de lista linelist_split que tiene ese nombre. También utilizamos el nombre para crear un nombre de archivo único. Así es como funciona:\n\nComenzamos con el vector de nombres de caracteres, pasado a map() como .x\nLa función .f es export(), que requiere un dataframe y una ruta de archivo para escribirlo\nLa entrada .x (el nombre del hospital) se utiliza dentro de .f para extraer/indexar ese elemento específico de la lista linelist_split. Esto hace que sólo se proporcione un dataframe a la vez a export().\nPor ejemplo, cuando map() itera por “Military Hospital”, entonces linelist_split[.x]] es en realidad linelist_split[[\"Military Hospital\"]], devolviendo así el segundo elemento de linelist_split - que son todos los casos del Military Hospital.\nLa ruta del archivo proporcionada a export() es dinámica mediante el uso de str_glue() (ver página de caracteres y cadenas):\nhere() se utiliza para obtener la base de la ruta del archivo y especificar la carpeta “data” (nótese las comillas simples para no interrumpir las comillas dobles de str_glue())\nA continuación, una barra /, y luego de nuevo el .x que imprime el nombre actual del hospital para que el archivo sea identificable\nPor último, la extensión “.csv” que export() utiliza para crear un archivo CSV\n\n\nnames(linelist_split) %&gt;%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))\n\n¡Ahora puedes ver que cada archivo se guarda en la carpeta “data” del proyecto R “Epi_R_handbook”.”!\n\n\n\n\n\n\n\n\n\n\n\n\nFunciones personalizadas\nPuedes crear tu propia función para proporcionar a map().\nDigamos que queremos crear curvas epidémicas para los casos de cada hospital. Para hacer esto usando purrr, nuestra función .f puede ser ggplot() y las extensiones con + como de costumbre. Como la salida de map() es siempre una lista, los gráficos se almacenan en una lista. Como son gráficos, pueden ser extraídas y trazadas con la función ggarrange() del paquete ggpubr (documentación).\n\n# cargar paquete para graficar elementos de la lista\npacman::p_load(ggpubr)\n\n## mapear a través del vector de 6 \"nombres\" de hospital (creado anteriormente)\n# usar la función ggplot especificada\n# la salida es una lista con 6 ggplots\n\nhospital_names &lt;- unique(linelist$hospital)\n\nmy_plots &lt;- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %&gt;% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# imprimir los ggplots (se almacenan en una lista)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\nSi este código de map() parece demasiado desordenado, se puede conseguir el mismo resultado guardando el comando específico de ggplot() como una función personalizada definida por el usuario, por ejemplo podemos llamarla make_epicurve()). Esta función se utiliza entonces dentro de la función map(). .x se sustituirá iterativamente por el nombre del hospital, y se utilizará como hosp_name en la función make_epicurve(). Véase la página sobre Escribir funciones.\n\n# Crear función\nmake_epicurve &lt;- function(hosp_name){\n  \n  ggplot(data = linelist %&gt;% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n\n\n# mapear\nmy_plots &lt;- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# imprimir los ggplots (se almacenan en una lista)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\nMapear una función a través de las columnas\nOtro caso de uso común es asignar una función a varias columnas. A continuación, map() la función t.test() a través de columnas numéricas del dataframe linelist, comparando los valores numéricos por género.\nRecuerda de la página sobre Test estadísticos simples que t.test() puede tomar entradas en un formato de fórmula, como t.test(columna numérica ~ columna binaria). En este ejemplo, hacemos lo siguiente:\n\nLas columnas numéricas de interés se seleccionan del listado - éstas se convierten en las entradas .x de map()\nLa función t.test() se suministra como la función .f, que se aplica a cada columna numérica\nDentro del paréntesis de t.test():\n\nel primer ~ precede al .f que map() iterará sobre el .x\nel .x representa la columna actual que se suministra a la función t.test()\nel segundo ~ es parte de la ecuación del test-t descrita anteriormente\nla función t.test() espera una columna binaria en el lado derecho de la ecuación. Suministramos el vector linelist$gender de forma independiente y estática (Ten en cuenta que no se incluye en select()).\n\n\nmap() devuelve una lista, por lo que la salida es una lista de resultados del test-t, un elemento de la lista por cada columna numérica analizada.\n\n# Results are saved as a list\nt.test_results &lt;- linelist %&gt;% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %&gt;%  # mantener sólo algunas columnas numéricas para mapear a través de\n  map(.f = ~t.test(.x ~ linelist$gender))        # función t.test, con ecuación NUMERIC ~ CATEGORICAL\n\nEste es el aspecto de la lista t.test_results cuando se abre (view) en RStudio. Hemos resaltado las partes que son importantes para los ejemplos de esta página.\n\nPuedes ver en la parte superior que toda la lista se llama t.test_results y tiene cinco elementos. Esos cinco elementos se denominan age, wt_km, ht_cm, ct_blood, temp después de cada variable que se utilizó en una prueba t con el gender de linelist.\nCada uno de esos cinco elementos son a su vez listas, con elementos dentro de ellas como p.value y conf.int. Algunos de estos elementos, como p.value, son números individuales, mientras que otros, como conf.int, constan de dos o más elementos (mean in group f y mean in group m).\n\n\n\n\n\n\n\n\n\n\nNota: Recuerda que si deseas aplicar una función sólo a determinadas columnas de un dataframe, puedes utilizar simplemente mutate() y across(), como se explica en la página Limpieza de datos y funciones básicas. A continuación se muestra un ejemplo de aplicación de as.character() sólo a las columnas “age”. Observa la colocación de los paréntesis y las comas.\n\n# convertir columnas cuyo nombre contenga \" age \" de clase Carácter\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  \n\n\n\nExtraer de las listas\nComo map() produce una salida del tipo List, dedicaremos algún tiempo a discutir cómo extraer datos de las listas utilizando las funciones purrr que las acompañan. Para mostrar esto, utilizaremos la lista t.test_results de la sección anterior. Esta es una lista de 5 listas - cada una de las 5 listas contiene los resultados de una prueba t entre una columna del dataframe linelist y su columna binaria gender. Consulta la imagen de la sección anterior para ver la estructura de la lista.\n\nNombres de elementos\nPara extraer los nombres de los elementos en sí, basta con utilizar names() de R base. En este caso, utilizamos names() en t.test_results para devolver los nombres de cada sublista, que son los nombres de las 5 variables a las que se les realizaron test-t.\n\nnames(t.test_results)\n\n[1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\"    \n\n\n\n\nElementos por nombre o posición\nPara extraer los elementos de la lista por su nombre o su posición se pueden utilizar paréntesis [[ ]] como se describe en la página de fundamentos de R. A continuación, utilizamos corchetes dobles para indexar la lista t.test_results y mostrar el primer elemento, que son los resultados del test-t sobre age.\n\nt.test_results[[1]] # primer elemento por posición\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\nt.test_results[[1]][\"p.value\"] # devolver elemento llamado \"p. value\" del primer elemento    \n\n$p.value\n[1] 2.350374e-96\n\n\nSin embargo, a continuación mostraremos el uso de las sencillas y flexibles funciones de purrr map() y pluck() para lograr los mismos resultados.\n\n\npluck()\npluck() extrae elementos por nombre o por posición. Por ejemplo, para extraer los resultados del test-t para la edad, puedes utilizar pluck() así:\n\nt.test_results %&gt;% \n  pluck(\"age\")        # alternativamente, usa pluck(1)\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\n\nIndexa niveles más profundos especificando los niveles adicionales con comas. A continuación se extrae el elemento denominado “p.value” de la lista age dentro de la lista t.test_results. También puedes utilizar números en lugar de nombres de caracteres.\n\nt.test_results %&gt;% \n  pluck(\"age\", \"p.value\")\n\n[1] 2.350374e-96\n\n\nPuedes extraer estos elementos internos de todos los elementos de primer nivel utilizando map() para ejecutar la función pluck() en cada elemento de primer nivel. Por ejemplo, el siguiente código extrae los elementos “p.value” de todas las listas dentro de t.test_results. La lista de resultados del test-t es el .x que se itera, pluck() es la función .f que se itera, y el valor “p-value” se proporciona a la función.\n\nt.test_results %&gt;%\n  map(pluck, \"p.value\")   # devuelve los valores-p\n\n$age\n[1] 2.350374e-96\n\n$wt_kg\n[1] 2.664367e-182\n\n$ht_cm\n[1] 3.515713e-144\n\n$ct_blood\n[1] 0.4473498\n\n$temp\n[1] 0.5735923\n\n\nComo otra alternativa, map() ofrece una forma abreviada en la que puedes escribir el nombre del elemento entre comillas, y lo extraerá. Si utilizas map() la salida será una lista, mientras que si utilizas map_chr() será un vector de caracteres con nombre y si utilizas map_dbl() será un vector numérico con nombre.\n\nt.test_results %&gt;% \n  map_dbl(\"p.value\")   # devuelve los valores-p como un vector numérico con nombre\n\n          age         wt_kg         ht_cm      ct_blood          temp \n 2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01 \n\n\nPuedes leer más sobre pluck() en la documentación purrr. Tiene una función hermana chuck() que devolverá un error en lugar de NULL si no existe un elemento.\n\n\n\nConvertir una lista en un dataframe\nEste es un tema complejo - Mira la sección de Recursos para tutoriales más completos. Sin embargo, vamos a mostrar la conversión de la lista de resultados del test-t en un dataframe. Crearemos un dataframe con columnas para la variable, su valor-p y las medias de los dos grupos (hombres y mujeres).\nEstos son algunos de los nuevos enfoques y funciones que se utilizarán:\n\nLa función tibble() se utilizará para crear un tibble (como un dataframe)\n\nRodeamos la función tibble() con corchetes { } para evitar que todo el t.test_results se almacene como la primera columna tibble\n\nDentro de tibble(), cada columna se crea explícitamente, de forma similar a la sintaxis de mutate():\n\nEl . representa t.test_results\nPara crear una columna con los nombres de las variables del test-t (los nombres de cada elemento de la lista) utilizamos names() como se ha descrito anteriormente\nPara crear una columna con los valores p utilizamos map_dbl() como se ha descrito anteriormente para extraer los elementos p.value y convertirlos en un vector numérico\n\n\n\nt.test_results %&gt;% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }\n\n# A tibble: 5 × 2\n  variables         p\n  &lt;chr&gt;         &lt;dbl&gt;\n1 age       2.35e- 96\n2 wt_kg     2.66e-182\n3 ht_cm     3.52e-144\n4 ct_blood  4.47e-  1\n5 temp      5.74e-  1\n\n\nPero ahora vamos a añadir columnas que contengan las medias de cada grupo (hombres y mujeres).\nTendríamos que extraer el elemento estimate, pero éste contiene en realidad dos elementos en su interior (media en el grupo f y media en el grupo m). Por lo tanto, no se puede simplificar en un vector con map_chr() o map_dbl(). En su lugar, utilizamos map(), que usado dentro de tibble() creará una columna de tipo lista dentro del tibble! ¡Sí, esto es posible!\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}\n\n# A tibble: 5 × 3\n  variables         p means       \n  &lt;chr&gt;         &lt;dbl&gt; &lt;named list&gt;\n1 age       2.35e- 96 &lt;dbl [2]&gt;   \n2 wt_kg     2.66e-182 &lt;dbl [2]&gt;   \n3 ht_cm     3.52e-144 &lt;dbl [2]&gt;   \n4 ct_blood  4.47e-  1 &lt;dbl [2]&gt;   \n5 temp      5.74e-  1 &lt;dbl [2]&gt;   \n\n\nUna vez que tengas esta columna de lista, hay varias funciones de tidyr (parte de tidyverse) que te ayudan a “rectangular” o “desanidar” estas columnas de “lista anidada”. Lee más sobre ellas aquí, o ejecutando vignette(\"rectangle\"). En resumen:\n\nunnest_wider() - da a cada elemento de una lista-columna tu propia columna\nunnest_longer() - da a cada elemento de una lista-columna tu propia fila\nhoist() - actúa como unnest_wider() pero se especifica qué elementos se van a anular\n\nA continuación, pasamos el tibble a unnest_wider() especificando la columna means del tibble (que es una lista anidada). El resultado es que means se sustituyen por dos nuevas columnas, cada una de las cuales refleja los dos elementos que había antes en cada celda means.\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %&gt;% \n  unnest_wider(means)\n\n# A tibble: 5 × 4\n  variables         p `mean in group f` `mean in group m`\n  &lt;chr&gt;         &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 age       2.35e- 96              12.7              19.6\n2 wt_kg     2.66e-182              45.8              59.6\n3 ht_cm     3.52e-144             109.              142. \n4 ct_blood  4.47e-  1              21.2              21.2\n5 temp      5.74e-  1              38.6              38.6\n\n\n\n\nDescartar, conservar y compactar listas\nDado que el trabajo con purrr implica a menudo listas, exploraremos brevemente algunas funciones de purrr para modificar listas. Consulta la sección de Recursos para ver tutoriales más completos sobre las funciones de purrr.\n\nlist_modify() tiene muchos usos, uno de los cuales puede ser eliminar un elemento de la lista\nkeep() conserva los elementos especificados a .p =, o cuando una función suministrada a .p = evalúa a TRUE\ndiscard() elimina los elementos especificados a .p, o cuando una función suministrada a .p = evalúa a TRUE\ncompact() elimina todos los elementos vacíos\n\nAquí hay algunos ejemplos que utilizan la lista combined creada en la sección anterior sobre el uso de map() para importar y combinar múltiples archivos (contiene 6 dataframes de listas de casos):\nLos elementos pueden ser eliminados por su nombre con list_modify() y estableciendo el nombre igual a NULL.\n\ncombined %&gt;% \n  list_modify(\"Central Hospital\" = NULL)   # elimina el elemento de la lista por su nombre\n\nTambién puedes eliminar elementos por criterio, proporcionando una ecuación “predicada” a .p = (una ecuación que evalúa a TRUE o FALSE). Coloca una tilde ~ antes de la función y utiliza .x para representar el elemento de la lista. Utilizando keep() se conservarán los elementos de la lista que se evalúen como TRUE. A la inversa, si se utiliza discard() se eliminarán los elementos de la lista que se evalúen como TRUE.\n\n# conserva sólo los elementos de lista con más de 500 filas\ncombined %&gt;% \n  keep(.p = ~nrow(.x) &gt; 500)  \n\nEn el siguiente ejemplo, los elementos de la lista se descartan si tu tipo no son dataframes.\n\n# Descarta los elementos de la lista que no sean data frames\ncombined %&gt;% \n  discard(.p = ~class(.x) != \"data.frame\")\n\nSu función de predicado también puede hacer referencia a elementos/columnas dentro de cada elemento de la lista. Por ejemplo, a continuación, se descartan los elementos de la lista cuya media de la columna ct_blood sea superior a 25.\n\n# Conserva sólo los elementos de la lista en los que la media de la columna ct_blood es superior a 25\ncombined %&gt;% \n  discard(.p = ~mean(.x$ct_blood) &gt; 25)  \n\nEste comando eliminaría todos los elementos vacíos de la lista:\n\n# Elimina todos los elementos vacíos de la lista\ncombined %&gt;% \n  compact()\n\n\n\npmap()\nESTA SECCIÓN ESTÁ EN CONSTRUCCIÓN",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteración, bucles y listas</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.es.html#apply-functions",
    "href": "new_pages/iteration.es.html#apply-functions",
    "title": "16  Iteración, bucles y listas",
    "section": "16.4 Funciones Apply",
    "text": "16.4 Funciones Apply\nLa familia de funciones “apply” es una alternativa de R base a purrr para operaciones iterativas. Puedes leer más sobre ellas aquí.",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteración, bucles y listas</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.es.html#resources-9",
    "href": "new_pages/iteration.es.html#resources-9",
    "title": "16  Iteración, bucles y listas",
    "section": "16.5 Recursos",
    "text": "16.5 Recursos\nBucles for en Data Carpentry\nLa página de R for Data Science en español sobre la iteración\nViñeta sobre escritura/lectura de archivos Excel\nUn tutorial de purrr por jennybc\nOtro tutorial de purrr por Rebecca Barter\nUn tutorial de purrr sobre map, pmap e imap\nhoja de trucos -cheatsheet- de purrr\nconsejos y trucos de purrr guardar y descartar",
    "crumbs": [
      "Gestión de datos",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Iteración, bucles y listas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html",
    "href": "new_pages/tables_descriptive.es.html",
    "title": "17  Tablas descriptivas",
    "section": "",
    "text": "17.1 Preparación",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#preparation-8",
    "href": "new_pages/tables_descriptive.es.html#preparation-8",
    "title": "17  Tablas descriptivas",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,          # Importación de ficheros\n  here,         # localizador de ficheros\n  skimr,        # obtener una visión general de los datos\n  tidyverse,    # gestión de datos + gráficos ggplot2 \n  gtsummary,    # resumen estadístico y tests\n  rstatix,      # resumen estadístico y pruebas estadísticas\n  janitor,      # añadir totales y porcentajes a las tablas\n  scales,       # convertir fácilmente proporciones en porcentajes  \n  flextable     # convertir tablas en imágenes bonitas\n  )\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).\n\n# importar el listado de casos\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#browse-data",
    "href": "new_pages/tables_descriptive.es.html#browse-data",
    "title": "17  Tablas descriptivas",
    "section": "17.2 Visualizar datos",
    "text": "17.2 Visualizar datos\n\nPaquete skimr\nUtilizando el paquete skimr, puedes obtener una visión detallada y estéticamente agradable de cada una de las variables de tu conjunto de datos. Lee más sobre skimr en su página de github.\nA continuación, se aplica la función skim() a todo el dataframe linelist. Se produce una visión general del dataframe y un resumen de cada columna (por tipo).\n\n## obtener información sobre cada variable de un conjunto de datos \nskim(linelist)\n\n\n\n\nData summary\n\n\nName\nlinelist\n\n\nNumber of rows\n5888\n\n\nNumber of columns\n30\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n4\n\n\nfactor\n2\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n0\n1.00\n6\n6\n0\n5888\n0\n\n\noutcome\n1323\n0.78\n5\n7\n0\n2\n0\n\n\ngender\n278\n0.95\n1\n1\n0\n2\n0\n\n\nage_unit\n0\n1.00\n5\n6\n0\n2\n0\n\n\nhospital\n0\n1.00\n5\n36\n0\n6\n0\n\n\ninfector\n2088\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2088\n0.65\n5\n7\n0\n2\n0\n\n\nfever\n249\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n249\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n249\n0.96\n2\n3\n0\n2\n0\n\n\naches\n249\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n249\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n765\n0.87\n5\n5\n0\n1072\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_infection\n2087\n0.65\n2014-03-19\n2015-04-27\n2014-10-11\n359\n\n\ndate_onset\n256\n0.96\n2014-04-07\n2015-04-30\n2014-10-23\n367\n\n\ndate_hospitalisation\n0\n1.00\n2014-04-17\n2015-04-30\n2014-10-23\n363\n\n\ndate_outcome\n936\n0.84\n2014-04-19\n2015-06-04\n2014-11-01\n371\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nage_cat\n86\n0.99\nFALSE\n8\n0-4: 1095, 5-9: 1095, 20-: 1073, 10-: 941\n\n\nage_cat5\n86\n0.99\nFALSE\n17\n0-4: 1095, 5-9: 1095, 10-: 941, 15-: 743\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n0\n1.00\n16.56\n5.79\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nage\n86\n0.99\n16.07\n12.62\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nage_years\n86\n0.99\n16.02\n12.64\n0.00\n6.00\n13.00\n23.00\n84.00\n\n\nlon\n0\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n0\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nwt_kg\n0\n1.00\n52.64\n18.58\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n0\n1.00\n124.96\n49.52\n4.00\n91.00\n129.00\n159.00\n295.00\n\n\nct_blood\n0\n1.00\n21.21\n1.69\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n149\n0.97\n38.56\n0.98\n35.20\n38.20\n38.80\n39.20\n40.80\n\n\nbmi\n0\n1.00\n46.89\n55.39\n-1200.00\n24.56\n32.12\n50.01\n1250.00\n\n\ndays_onset_hosp\n256\n0.96\n2.06\n2.26\n0.00\n1.00\n1.00\n3.00\n22.00\n\n\n\n\n\nTambién puedes utilizar la función summary(), de R base, para obtener información completta sobre unos datos, pero esta salida puede ser más difícil de leer que utilizando skimr. Por eso no se muestra a continuación esta salida, para ahorrar espacio de la página.\n\n## obtener información sobre cada variable de un conjunto de datos \nsummary(linelist)\n\n\n\nEstadísticas resumidas\nPuedes utilizar las funciones de R base para producir estadísticas de resumen sobre una columna numérica. Puedes producir la mayoría de las estadísticas de resumen útiles para una columna numérica utilizando summary(), como se indica a continuación. Ten en cuenta que también debe especificarse el nombre del dataframe, como se muestra a continuación.\n\nsummary(linelist$age_years)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.02   23.00   84.00      86 \n\n\nPuedes acceder y guardar una parte específica de la misma con los corchetes de índice [ ]:\n\nsummary(linelist$age_years)[[2]]            # devuelve sólo el 2º elemento\n\n[1] 6\n\n# equivalente, alternativa a la anterior por nombre de elemento\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \n\nPuedes mostrar estadísticas individuales con funciones de R base como max(), min(), median(), mean(), quantile(), sd(), y range(). Consulta la página de Fundamentos de R para obtener una lista completa.\nPRECAUCIÓN: Si tus datos contienen valores faltantes, R quiere que lo sepas y por ello mostrará NA a menos que se especifique en las funciones matemáticas anteriores que quieres que R ignore los valores faltantes, mediante el argumento na.rm = TRUE.\nPuedes utilizar la función get_summary_stats() de rstatix para producir las estadísticas de resumen en un formato de dataframe. Esto puede ser útil para realizar operaciones posteriores o trazar los números. Consulta la página Tests estadísticos simples para obtener más detalles sobre el paquete rstatix y sus funciones.\n\nlinelist %&gt;% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # columnas para calcular\n    type = \"common\")                    # estadísticas resumidas \n\n# A tibble: 5 × 10\n  variable     n   min   max median   iqr  mean     sd    se    ci\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#tbl_janitor",
    "href": "new_pages/tables_descriptive.es.html#tbl_janitor",
    "title": "17  Tablas descriptivas",
    "section": "17.3 paquete janitor",
    "text": "17.3 paquete janitor\nLos paquetes janitor ofrecen la función tabyl() para producir tabulaciones y tabulaciones cruzadas, que pueden ser “adornadas” o modificadas con funciones de ayuda para mostrar porcentajes, proporciones, recuentos, etc.\nA continuación, enlazamos el dataframe linelist con pipe a las funciones de limpieza e imprimimos el resultado. Si lo deseas, también puedes guardar las tablas resultantes con el operador de asignación &lt;-.\n\nTabyl simple\nEl uso por defecto de tabyl() en una columna específica produce los valores únicos, los recuentos y sus proporciones por columna. Las proporciones pueden tener muchos dígitos. Puedes ajustar el número de decimales con adorn_rounding() como se describe a continuación.\n\nlinelist %&gt;% tabyl(age_cat)\n\n age_cat    n     percent valid_percent\n     0-4 1095 0.185971467   0.188728025\n     5-9 1095 0.185971467   0.188728025\n   10-14  941 0.159816576   0.162185453\n   15-19  743 0.126188859   0.128059290\n   20-29 1073 0.182235054   0.184936229\n   30-49  754 0.128057065   0.129955188\n   50-69   95 0.016134511   0.016373664\n     70+    6 0.001019022   0.001034126\n    &lt;NA&gt;   86 0.014605978            NA\n\n\nComo puedes ver arriba, si hay valores que faltan se muestran en una fila etiquetada como NA. Puedes suprimirlos con show_na = FALSE. Si no hay valores faltantes, esta fila no aparecerá. Si hay valores faltantes, todas las proporciones se dan como crudas (el denominador incluye los recuentos de NA) y “válidas” (el denominador excluye los recuentos de NA).\nSi la columna es de tipo factor y sólo hay ciertos niveles en sus datos, todos los niveles seguirán apareciendo en la tabla. Puedes suprimir esta característica especificando show_missing_levels = FALSE. Lee más en la página de Factores.\n\n\nTabulación cruzada\nLos recuentos de tabulación cruzada se consiguen añadiendo una o más columnas adicionales dentro de tabyl(). Ten en cuenta que ahora sólo se muestran los recuentos - Las proporciones y porcentajes se pueden añadir con los pasos adicionales que se muestran a continuación.\n\nlinelist %&gt;% tabyl(age_cat, gender)\n\n age_cat   f   m NA_\n     0-4 640 416  39\n     5-9 641 412  42\n   10-14 518 383  40\n   15-19 359 364  20\n   20-29 468 575  30\n   30-49 179 557  18\n   50-69   2  91   2\n     70+   0   5   1\n    &lt;NA&gt;   0   0  86\n\n\n\n\n“Adornando” el tabyl\nUtiliza las funciones de “adorno” de janitor para añadir totales o convertir a proporciones, porcentajes, o ajustar la visualización de otro modo. A menudo, enlazarás el tabyl con pipe a través de varias de estas funciones.\n\n\n\n\n\n\n\nFunción\nResultado\n\n\n\n\nadorn_totals()\nAñade los totales (where = “row”, “col”, o “both”). Establecer name = para el “Total”.\n\n\nadorn_percentages()\nConvierte los recuentos en proporciones, con denominator = “row”, “col”, o “all”\n\n\nadorn_pct_formatting()\nConvierte las proporciones en porcentajes. Especifica los digits =. Elimina el símbolo “%” con affix_sign = FALSE.\n\n\nadorn_rounding()\nPara redondear proporciones a digits =. Para redondear porcentajes utiliza adorn_pct_formatting() con digits =.\n\n\nadorn_ns()\nAñade recuentos a una tabla de proporciones o porcentajes. indica la position = “rear” para mostrar los recuentos entre paréntesis, o “front” para poner los porcentajes entre paréntesis.\n\n\nadorn_title()\nAñade una cadena mediante los argumentos row_name = y/o col_name =\n\n\n\nSe consciente del orden en que se aplican las funciones anteriores. A continuación, algunos ejemplos.\nUna simple tabla unidireccional con porcentajes en lugar de las proporciones por defecto.\n\nlinelist %&gt;%               # lista de casos\n  tabyl(age_cat) %&gt;%       # tabular recuentos y proporciones por categoría de edad\n  adorn_pct_formatting()   # convertir proporciones en porcentajes\n\n age_cat    n percent valid_percent\n     0-4 1095   18.6%         18.9%\n     5-9 1095   18.6%         18.9%\n   10-14  941   16.0%         16.2%\n   15-19  743   12.6%         12.8%\n   20-29 1073   18.2%         18.5%\n   30-49  754   12.8%         13.0%\n   50-69   95    1.6%          1.6%\n     70+    6    0.1%          0.1%\n    &lt;NA&gt;   86    1.5%             -\n\n\nUna tabulación cruzada con un total de filas y porcentajes de filas.\n\nlinelist %&gt;%                                  \n  tabyl(age_cat, gender) %&gt;%                  # recuentos por edad y sexo\n  adorn_totals(where = \"row\") %&gt;%             # añadir fila con totales\n  adorn_percentages(denominator = \"row\") %&gt;%  # convertir recuentos en proporciones\n  adorn_pct_formatting(digits = 1)            # convertir proporciones en porcentajes\n\n age_cat     f     m    NA_\n     0-4 58.4% 38.0%   3.6%\n     5-9 58.5% 37.6%   3.8%\n   10-14 55.0% 40.7%   4.3%\n   15-19 48.3% 49.0%   2.7%\n   20-29 43.6% 53.6%   2.8%\n   30-49 23.7% 73.9%   2.4%\n   50-69  2.1% 95.8%   2.1%\n     70+  0.0% 83.3%  16.7%\n    &lt;NA&gt;  0.0%  0.0% 100.0%\n   Total 47.7% 47.6%   4.7%\n\n\nUna tabulación cruzada ajustada para que aparezcan tanto los recuentos como los porcentajes.\n\nlinelist %&gt;%                                  # lista de casos\n  tabyl(age_cat, gender) %&gt;%                  # tabulación cruzada de recuentos\n  adorn_totals(where = \"row\") %&gt;%             # añadir una fila de totales\n  adorn_percentages(denominator = \"col\") %&gt;%  # convertir a proporciones\n  adorn_pct_formatting() %&gt;%                  # convertir a porcentajes\n  adorn_ns(position = \"front\") %&gt;%            # mostrar como: \"casos (porcent)\"\n  adorn_title(                                # ajustar títulos\n    row_name = \"Age Category\",\n    col_name = \"Gender\")\n\n                      Gender                            \n Age Category              f              m          NA_\n          0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n          5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n        10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n        15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n        20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n        30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n        50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n          70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n         &lt;NA&gt;     0   (0.0%)     0   (0.0%)  86  (30.9%)\n        Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)\n\n\n\n\nImpresión del tabyl\nPor defecto, el tabyl se imprimirá en crudo en la consola de R.\nAlternativamente, puedes pasar el tabyl a flextable o un paquete similar para imprimirlo como una imagen “bonita” en el visor de RStudio, que podría exportarse como .png, .jpeg, .html, etc. Esto se discute en la página Tablas para presentaciones. Ten en cuenta que si imprimes de esta manera y utilizas adorn_titles(), debes especificar placement = \"combined\".\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% # esto es necesario para imprimir como imagen\n  flextable::flextable() %&gt;%    # convertir a imagen bonita\n  flextable::autofit()          # formatear a una línea por fila  \n\nAge Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1,095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1,095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%)941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%)743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1,073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%)754 (12.8%)50-692  (0.1%)91  (3.2%)2  (0.7%)95  (1.6%)70+0  (0.0%)5  (0.2%)1  (0.4%)6  (0.1%)0  (0.0%)0  (0.0%)86 (30.9%)86  (1.5%)\n\n\n\n\nUso en otras tablas\nPuedes utilizar las funciones adorn_() de janitor en otras tablas, como las creadas por summarise() y count() de dplyr, o table() de R base. Por ejemplo:\n\nlinelist %&gt;% \n  count(hospital) %&gt;%   # función dplyr\n  adorn_totals()        # función janitor\n\n                             hospital    n\n                     Central Hospital  454\n                    Military Hospital  896\n                              Missing 1469\n                                Other  885\n                        Port Hospital 1762\n St. Mark's Maternity Hospital (SMMH)  422\n                                Total 5888\n\n\n\n\nGuardar el tabyl\nSi conviertes la tabla en una imagen “bonita” con un paquete como flextable, puedes guardarla con funciones de ese paquete - como save_as_html(), save_as_word(), save_as_ppt(), y save_as_image() de flextable (como se discute más ampliamente en la página Tablas para presentaciones). A continuación, la tabla se guarda como un documento de Word, en el que se puede seguir editando a mano.\n\nlinelist %&gt;%\n  tabyl(age_cat, gender) %&gt;% \n  adorn_totals(where = \"col\") %&gt;% \n  adorn_percentages(denominator = \"col\") %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\") %&gt;% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %&gt;% \n  flextable::flextable() %&gt;%                     # convertir a imagen\n  flextable::autofit() %&gt;%                       # asegurar sólo una línea por fila\n  flextable::save_as_docx(path = \"tabyl.docx\")   # guardar como documento Word en la carpeta\n\n\n\n\n\n\n\n\n\n\n\n\nEstadísticas\nPuedes aplicar a las tabyl tests estadísticos como chisq.test() o fisher.test() del paquete stats, como se muestra a continuación. Ten en cuenta que los valores faltantes no están permitidos, por lo que se excluyen de la tabulación con show_na = FALSE.\n\nage_by_outcome &lt;- linelist %&gt;% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)\n\n\n    Pearson's Chi-squared test\n\ndata:  age_by_outcome\nX-squared = 6.4931, df = 7, p-value = 0.4835\n\n\nConsulta la página sobre Tests estadísticos sencillos para obtener más código y consejos sobre estadística.\n\n\nOtros consejos\n\nIncluye el argumento na.rm = TRUE para excluir los valores faltantes de cualquiera de los cálculos anteriores.\nSi aplicas cualquier función de ayuda adorn_*() a tablas no creadas por tabyl(), puedes especificar una(s) columna(s) particular(es) para aplicarlas como adorn_percentage(,,,c(cases,deaths)) (especifícalos en el cuarto argumento sin nombre). La sintaxis no es sencilla. Considera la posibilidad de utilizar summarise() en su lugar.\nPuedes leer más detalles en la página de janitor y en esta viñeta de tabyl.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#dplyr-package",
    "href": "new_pages/tables_descriptive.es.html#dplyr-package",
    "title": "17  Tablas descriptivas",
    "section": "17.4 paquete dplyr",
    "text": "17.4 paquete dplyr\ndplyr forma parte de los paquetes tidyverse y es una herramienta de gestión de datos muy común. La creación de tablas con las funciones de dplyr summarise() y count() es un enfoque útil para calcular estadísticas de resumen, resumir por grupos o pasar tablas a ggplot().\nsummarise() crea un nuevo dataframe de resumen. Si los datos no están agrupados, se producirá un dataframe de una fila con las estadísticas de resumen especificadas de todo el dataframe. Si los datos están agrupados, el nuevo dataframe tendrá una fila por grupo (véase la página Agrupar datos).\nDentro del paréntesis de summarise(), se proporcionan los nombres de cada nueva columna de resumen, seguidos de un signo de igualdad y de una función estadística a aplicar.\nSUGERENCIA: La función summarise funciona tanto con la ortografía británica como con la estadounidense (summarise() y summarize()). \n\nObtener recuentos\nLa función más sencilla de aplicar dentro de summarise() es n(). Deja los paréntesis vacíos para contar el número de filas.\n\nlinelist %&gt;%                 # comienza con linelist\n  summarise(n_rows = n())    # devuelve un nuevo dataframe de resumen con la columna n_rows\n\n  n_rows\n1   5888\n\n\nEsto se vuelve más interesante si hemos agrupado los datos de antemano.\n\nlinelist %&gt;% \n  group_by(age_cat) %&gt;%     # agrupa los datos por valores únicos en la columna age_cat\n  summarise(n_rows = n())   # devuelve el número de filas *por grupo\n\n# A tibble: 9 × 2\n  age_cat n_rows\n  &lt;fct&gt;    &lt;int&gt;\n1 0-4       1095\n2 5-9       1095\n3 10-14      941\n4 15-19      743\n5 20-29     1073\n6 30-49      754\n7 50-69       95\n8 70+          6\n9 &lt;NA&gt;        86\n\n\nEl comando anterior se puede acortar utilizando la función count() en su lugar. count() hace lo siguiente:\n\nAgrupa los datos por las columnas que se le proporcionan\nLos resume con n() (creando la columna n)\nDesagrupa los datos\n\n\nlinelist %&gt;% \n  count(age_cat)\n\n  age_cat    n\n1     0-4 1095\n2     5-9 1095\n3   10-14  941\n4   15-19  743\n5   20-29 1073\n6   30-49  754\n7   50-69   95\n8     70+    6\n9    &lt;NA&gt;   86\n\n\nPuedes cambiar el nombre de la columna de recuentos de la n por defecto a otra cosa especificando a name =.\nLos recuentos tabulados de dos o más columnas de agrupación se siguen devolviendo en formato “largo”, con los recuentos en la columna n. Consulta la página sobre Pivotar datos para conocer los formatos de datos “long” y “wide”.\n\nlinelist %&gt;% \n  count(age_cat, outcome)\n\n   age_cat outcome   n\n1      0-4   Death 471\n2      0-4 Recover 364\n3      0-4    &lt;NA&gt; 260\n4      5-9   Death 476\n5      5-9 Recover 391\n6      5-9    &lt;NA&gt; 228\n7    10-14   Death 438\n8    10-14 Recover 303\n9    10-14    &lt;NA&gt; 200\n10   15-19   Death 323\n11   15-19 Recover 251\n12   15-19    &lt;NA&gt; 169\n13   20-29   Death 477\n14   20-29 Recover 367\n15   20-29    &lt;NA&gt; 229\n16   30-49   Death 329\n17   30-49 Recover 238\n18   30-49    &lt;NA&gt; 187\n19   50-69   Death  33\n20   50-69 Recover  38\n21   50-69    &lt;NA&gt;  24\n22     70+   Death   3\n23     70+ Recover   3\n24    &lt;NA&gt;   Death  32\n25    &lt;NA&gt; Recover  28\n26    &lt;NA&gt;    &lt;NA&gt;  26\n\n\n\n\nMostrar todos los niveles\nSi estás tabulando una columna de tipo factor, puedes asegurarte de que se muestren todos los niveles (no sólo los niveles con valores en los datos) añadiendo .drop = FALSE en el comando summarise() o count().\nEsta técnica es útil para estandarizar sus tablas/gráficos. Por ejemplo, si está creando cifras para varios subgrupos, o creando repetidamente la cifra para informes de rutina. En cada una de estas circunstancias, la presencia de valores en los datos puede fluctuar, pero puedes definir niveles que permanezcan constantes.\nPara más información, consulta la página sobre factores.\n\n\nProporciones\nLas proporciones pueden añadirse pasando la tabla por mutate() para crear una nueva columna. Define la nueva columna como la columna de recuentos (n por defecto) dividida por la sum() de la columna de recuentos (esto producirá una proporción).\nTen en cuenta que en este caso, sum() en el comando mutate() producirá la suma de toda la columna n para utilizarla como denominador de la proporción. Como se explica en la página Agrupar datos, si sum() se utiliza en datos agrupados (por ejemplo, si el comando mutate() sigue inmediatamente a un comando group_by()), producirá sumas por grupo. Como se acaba de indicar, count() termina sus acciones desagrupando. Por lo tanto, en este escenario obtenemos proporciones de columnas completas.\nPara mostrar fácilmente los porcentajes, puedes envolver la proporción en la función percent() del paquete scales (Ten en cuenta que se convierte en tipo carácter).\n\nage_summary &lt;- linelist %&gt;% \n  count(age_cat) %&gt;%                     # agrupa y cuenta por sexo (produce la columna \"n\")\n  mutate(                                # crea porcentaje de columna - mira el denominador\n    percent = scales::percent(n / sum(n))) \n\n# imprime\nage_summary\n\n  age_cat    n percent\n1     0-4 1095  18.60%\n2     5-9 1095  18.60%\n3   10-14  941  15.98%\n4   15-19  743  12.62%\n5   20-29 1073  18.22%\n6   30-49  754  12.81%\n7   50-69   95   1.61%\n8     70+    6   0.10%\n9    &lt;NA&gt;   86   1.46%\n\n\nA continuación se presenta un método para calcular las proporciones dentro de los grupos. Se basa en diferentes niveles de agrupación de datos que se aplican y eliminan selectivamente. En primer lugar, los datos se agrupan en función del outcome mediante group_by(). A continuación, se aplica count(). Esta función agrupa además los datos por age_cat y devuelve los recuentos para cada combinación de outcome-age-cat. Es importante destacar que, al finalizar tu proceso, count() también desagrupa la agrupación age_cat, por lo que la única agrupación de datos que queda es la agrupación original por outcome. Por lo tanto, el paso final del cálculo de las proporciones (denominador sum(n)) sigue estando agrupado por outcome.\n\nage_by_outcome &lt;- linelist %&gt;%                  # comienza con linelist\n  group_by(outcome) %&gt;%                         # agrupa por resultado \n  count(age_cat) %&gt;%                            # agrupa y cuenta por age_cat, y luego elimina la agrupación age_cat\n  mutate(percent = scales::percent(n / sum(n))) # calcula el porcentaje - observa que el denominador es por grupo de resultados\n\n\n\n\n\n\n\n\n\nGráficas\nMostrar una tabla “larga” como la anterior con ggplot() es relativamente sencillo. Los datos están naturalmente en formato “largo”, que es aceptado naturalmente por ggplot(). Mira más ejemplos en las páginas Conceptos básicos de ggplot y consejos de ggplot.\n\nlinelist %&gt;%                      # comienza con linelist\n  count(age_cat, outcome) %&gt;%     # agrupa y tabula los recuentos en dos columnas\n  ggplot()+                       # pasa el nuevo data frame a ggplot\n    geom_col(                     # crea un gráfico de barras\n      mapping = aes(   \n        x = outcome,              # asigna el resultado al eje x\n        fill = age_cat,           # mapea age_cat al relleno\n        y = n))                   # mapea la columna de recuentos `n` a la altura\n\n\n\n\n\n\n\n\n\n\nEstadísticas resumidas\nUna de las principales ventajas de dplyr y de summarise() es la capacidad de producir resúmenes estadísticos más avanzados como median(), mean(), max(), min(), sd() (desviación estándar) y percentiles. También puedes utilizar sum() para mostrar el número de filas que cumplen ciertos criterios lógicos. Al igual que en el caso anterior, estas salidas pueden producirse para todo el conjunto de dataframes o por grupos.\nLa sintaxis es la misma: dentro de los paréntesis de summarise() se proporcionan los nombres de cada nueva columna de resumen, seguidos de un signo de igualdad y de una función estadística para aplicar. Dentro de la función estadística, indica la(s) columna(s) con la(s) que se va a operar y cualquier argumento relevante (por ejemplo, na.rm = TRUE para la mayoría de las funciones matemáticas).\nTambién puedes utilizar sum() para mostrar el número de filas que cumplen un criterio lógico. La expresión que contiene se cuenta si se evalúa como TRUE. Por ejemplo:\n\nsum(age_years &lt; 18, na.rm=T)\n\nsum(gender == \"male\", na.rm=T)\n\nsum(response %in% c(\"Likely\", \"Very Likely\"))\n\nA continuación, se resumen los datos de linelist para describir los días de retraso desde el inicio de los síntomas hasta el ingreso en el hospital (columna days_onset_hosp), por hospital.\n\nsummary_table &lt;- linelist %&gt;%                                        # comienza con linelist, y guarda como nuevo objeto\n  group_by(hospital) %&gt;%                                             # agrupa todos los cálculos por hospital\n  summarise(                                                         # sólo se devolverán las siguientes columnas de resumen\n    cases       = n(),                                                # número de filas por grupo\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # retraso máximo\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # retraso medio, redondeado\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # desviación estándar de los retrasos, redondeada\n    delay_3     = sum(days_onset_hosp &gt;= 3, na.rm = T),               # número de filas con retraso de 3 o más días\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convierte la columna de retrasos definida anteriormente en porcentaje \n  )\n\nsummary_table  # print\n\n# A tibble: 6 × 7\n  hospital               cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n  &lt;chr&gt;                  &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;      \n1 Central Hospital         454        12        1.9      1.9     108 24%        \n2 Military Hospital        896        15        2.1      2.4     253 28%        \n3 Missing                 1469        22        2.1      2.3     399 27%        \n4 Other                    885        18        2        2.2     234 26%        \n5 Port Hospital           1762        16        2.1      2.2     470 27%        \n6 St. Mark's Maternity …   422        18        2.1      2.3     116 27%        \n\n\nAlgunos consejos:\n\nUtilizar sum() con una sentencia lógica para “contar” las filas que cumplen ciertos criterios (==)\nTen en cuenta el uso de na.rm = TRUE dentro de funciones matemáticas como sum(), de lo contrario se mostrará NA si hay algún valor faltante\nUtiliza la función percent() del paquete scales para convertir fácilmente a porcentajes\nAjusta la accuracy = (precisión) a 0,1 o 0,01 para garantizar 1 o 2 decimales respectivamente\nUtilizar round() de R base para especificar los decimales\nPara calcular estas estadísticas en todo el set de datos, utiliza summarise() sin group_by()\nPuedes crear columnas para los propósitos de cálculos posteriores (por ejemplo, denominadores) que eventualmente se eliminan de tu dataframe con select().\n\n\n\nEstadísticas condicionales\nEs posible que desees producir estadísticas condicionales, por ejemplo, el máximo de filas que cumplen ciertos criterios. Esto se puede hacer sub-configurando la columna con corchetes [ ]. El ejemplo siguiente devuelve la temperatura máxima de los pacientes clasificados con o sin fiebre. Sin embargo, ten en cuenta que puede ser más adecuado añadir otra columna al comando group_by() y pivot_wider() (como se demuestra a continuación).\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )\n\n# A tibble: 6 × 3\n  hospital                             max_temp_fvr max_temp_no\n  &lt;chr&gt;                                       &lt;dbl&gt;       &lt;dbl&gt;\n1 Central Hospital                             40.4        38  \n2 Military Hospital                            40.5        38  \n3 Missing                                      40.6        38  \n4 Other                                        40.8        37.9\n5 Port Hospital                                40.6        38  \n6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9\n\n\n\n\nPegar valores\nLa función str_glue() de stringr es útil para combinar valores de varias columnas en una nueva columna. En este contexto, se suele utilizar después del comando summarise().\nEn la página Caracteres y cadenas, se discuten varias opciones para combinar columnas, incluyendo unite(), y paste0(). En este caso de uso, abogamos por str_glue() porque es más flexible que unite() y tiene una sintaxis más sencilla que paste0().\nA continuación, el dataframe de summary_table (creado anteriormente) se muta de manera que las columnas delay_mean y delay_sd se combinan, se añade el formato de paréntesis a la nueva columna y se eliminan sus respectivas columnas antiguas.\nLuego, para hacer la tabla más presentable, se añade una fila de totales con adorn_totals() de janitor (que ignora las columnas no numéricas). Por último, utilizamos select() de dplyr para reordenar y renombrar los nombres de las columnas.\nAhora puedes pasar a flextable e imprimir la tabla a Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc. (ver la página de Tablas para presentaciones).\n\nsummary_table %&gt;% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %&gt;%  # combina y formatea otros valores\n  select(-c(delay_mean, delay_sd)) %&gt;%                       # elimina dos columnas antiguas         \n  adorn_totals(where = \"row\") %&gt;%                            # añade el total de la fila\n  select(                                                    # ordena y renombra las cols\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )\n\n                        Hospital Name Cases Max delay Mean (sd) Delay 3+ days\n                     Central Hospital   454        12 1.9 (1.9)           108\n                    Military Hospital   896        15 2.1 (2.4)           253\n                              Missing  1469        22 2.1 (2.3)           399\n                                Other   885        18   2 (2.2)           234\n                        Port Hospital  1762        16 2.1 (2.2)           470\n St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116\n                                Total  5888       101         -          1580\n % delay 3+ days\n             24%\n             28%\n             27%\n             26%\n             27%\n             27%\n               -\n\n\n\nPercentiles\nLos percentiles y cuartiles en dplyr merecen una mención especial. Para mostrar los cuantiles, utiliza quantile() con los valores predeterminados o especifica el valor o los valores que deseas con probs =.\n\n# obtiene valores de percentil de edad por defecto (0%, 25%, 50%, 75%, 100%)\nlinelist %&gt;% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               0\n2               6\n3              13\n4              23\n5              84\n\n# obtiene valores de percentil de edad especificados manualmente (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               1\n2              13\n3              23\n4              48\n\n\nSi deseas mostrar cuantiles por grupo, puedes encontrar salidas largas y menos útiles si simplemente añades otra columna a group_by(). Por lo tanto, prueba este enfoque en su lugar: crea una columna para cada nivel de cuantil deseado.\n\n# obtiene valores de percentil de edad especificados manualmente (5%, 50%, 75%, 98%)\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )\n\n# A tibble: 6 × 5\n  hospital                               p05   p50   p75   p98\n  &lt;chr&gt;                                &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Central Hospital                         1    12    21  48  \n2 Military Hospital                        1    13    24  45  \n3 Missing                                  1    13    23  48.2\n4 Other                                    1    13    23  50  \n5 Port Hospital                            1    14    24  49  \n6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\n\n\nAunque summarise() de dplyr ofrece ciertamente un control más fino, puedes encontrar que todas las estadísticas de resumen que necesitas pueden producirse con get_summary_stat() del paquete rstatix. Si se opera con datos agrupados, if mostrará 0%, 25%, 50%, 75% y 100%. Si se aplica a datos no agrupados, puedes especificar los percentiles con probs = c(.05, .5, .75, .98).\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 6 × 8\n  hospital                         variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;chr&gt;                            &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Central Hospital                 age        445     0     6    12    21     58\n2 Military Hospital                age        884     0     6    14    24     72\n3 Missing                          age       1441     0     6    13    23     76\n4 Other                            age        873     0     6    13    23     69\n5 Port Hospital                    age       1739     0     6    14    24     68\n6 St. Mark's Maternity Hospital (… age        420     0     7    12    22     84\n\n\n\nlinelist %&gt;% \n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 1 × 7\n  variable     n  `0%` `25%` `50%` `75%` `100%`\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 age       5802     0     6    13    23     84\n\n\n\n\n\nResumir datos agregados\nSi comienza con datos agregados, al utilizar n() devuelve el número de filas, no la suma de los recuentos agregados. Para obtener sumas, utiliza sum() en la columna de recuentos de los datos.\nPor ejemplo, digamos que se empieza con el dataframe de recuentos que se muestra a continuación, llamado linelist_agg - muestra en formato “largo” los recuentos de casos por resultado y género.\nA continuación creamos este dataframe de ejemplo de recuentos de casos de linelist por resultado y sexo (se eliminan los valores faltantes para mayor claridad).\n\nlinelist_agg &lt;- linelist %&gt;% \n  drop_na(gender, outcome) %&gt;% \n  count(outcome, gender)\n\nlinelist_agg\n\n  outcome gender    n\n1   Death      f 1227\n2   Death      m 1228\n3 Recover      f  953\n4 Recover      m  950\n\n\nPara sumar los recuentos (en la columna n) por grupo, puedes utilizar summarise() pero establecer la nueva columna igual a sum(n, na.rm=T)`. Para añadir un elemento condicional a la operación de suma, puedes utilizar la sintaxis del subconjunto [ ] en la columna de recuentos.\n\nlinelist_agg %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))\n\n# A tibble: 2 × 4\n  outcome total_cases male_cases female_cases\n  &lt;chr&gt;         &lt;int&gt;      &lt;int&gt;        &lt;int&gt;\n1 Death          2455       1228         1227\n2 Recover        1903        950          953\n\n\n\n\nacross() varias columnas\nPuedes utilizar summarise() en varias columnas utilizando across(). Esto facilita la vida cuando se desea calcular las mismas estadísticas para muchas columnas. Escribe across() dentro de summarise() y especifica lo siguiente:\n\n.cols = como un vector de nombres de columnas c() o funciones de ayuda “tidyselect” (explicadas más adelante)\n.fns = la función a realizar (sin paréntesis) - puedes proporcionar varias dentro de una list()\n\nA continuación, mean() se aplica a varias columnas numéricas. Se nombra explícitamente un vector de columnas a .cols = y se especifica una única función mean (sin paréntesis) a .fns =. Cualquier argumento adicional para la función (por ejemplo, na.rm=TRUE) se proporciona después de .fns =, separado por una coma.\nPuede ser difícil conseguir el orden correcto de los paréntesis y las comas cuando se utiliza across(). Recuerda que dentro de across() debes incluir las columnas, las funciones y cualquier argumento extra necesario para las funciones.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # columnas\n                   .fns = mean,                               # function\n                   na.rm=T))                                  # argumentos extra\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `outcome = \"Death\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 3 × 5\n  outcome age_years  temp wt_kg ht_cm\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Death        15.9  38.6  52.6  125.\n2 Recover      16.1  38.6  52.5  125.\n3 &lt;NA&gt;         16.2  38.6  53.0  125.\n\n\nSe pueden ejecutar varias funciones a la vez. A continuación se proporcionan las funciones mean y sd a .fns = dentro de una list(). Tienes la oportunidad de proporcionar nombres de caracteres (por ejemplo, “mean” y “sd”) que se añaden en los nuevos nombres de columna.\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # columnas\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiples functiones \n                   na.rm=T))                                 # argumentos extra\n\n# A tibble: 3 × 9\n  outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 Death             15.9         12.3      38.6   0.962       52.6     18.4\n2 Recover           16.1         13.0      38.6   0.997       52.5     18.6\n3 &lt;NA&gt;              16.2         12.8      38.6   0.976       53.0     18.9\n# ℹ 2 more variables: ht_cm_mean &lt;dbl&gt;, ht_cm_sd &lt;dbl&gt;\n\n\nAquí están esas funciones de ayuda “tidyselect” que puedes proporcionar a .cols = para seleccionar columnas:\n\neverything() - todas las demás columnas no mencionadas\nlast_col() - la última columna\nwhere() - aplica una función a todas las columnas y selecciona las que son TRUE\nstarts_with() - coincide con un prefijo especificado. Ejemplo: starts_with(\"date\")\nends_with() - coincide con un sufijo especificado. Ejemplo: ends_with(\"_end\")\ncontains() - columnas que contienen una cadena de caracteres. Ejemplo: contains(\"time\")\nmatches() - para aplicar una expresión regular (regex). Ejemplo: contains(\"[pt]al\")\nnum_range() -\nany_of() - coincide con el nombre de la columna. Es útil si el nombre puede no existir. Ejemplo: any_of(date_onset, date_death, cardiac_arrest)\n\nPor ejemplo, para producir la media de cada columna numérica utiliza where() y proporciona la función as.numeric() (sin paréntesis). Todo esto queda dentro del comando across().\n\nlinelist %&gt;% \n  group_by(outcome) %&gt;% \n  summarise(across(\n    .cols = where(is.numeric),  # todas las columnas numéricas del data frame\n    .fns = mean,\n    na.rm=T))\n\n# A tibble: 3 × 12\n  outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6\n2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6\n3 &lt;NA&gt;          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6\n# ℹ 2 more variables: bmi &lt;dbl&gt;, days_onset_hosp &lt;dbl&gt;\n\n\n\n\nPivote más ancho\nSi prefieres tu tabla en formato “ancho” puedes transformarla utilizando la función pivot_wider() de tidyr. Es probable que tengas que renombrar las columnas con rename(). Para más información, consulta la página sobre Pivotar datos.\nEl ejemplo siguiente comienza con la tabla “larga” age_by_outcome de la sección de proporciones. La creamos de nuevo y la imprimimos, para mayor claridad:\n\nage_by_outcome &lt;- linelist %&gt;%                  # comienza con linelist\n  group_by(outcome) %&gt;%                         # agrupa por resultado \n  count(age_cat) %&gt;%                            # agrupa y cuenta por age_cat, y luego elimina la agrupación age_cat\n  mutate(percent = scales::percent(n / sum(n))) # calcula el porcentaje - observa que el denominador es por grupo de resultados\n\n\n\n\n\n\n\nPara pivotar más ampliamente, creamos las nuevas columnas a partir de los valores de la columna existente age_cat (estableciendo names_from = age_cat). También especificamos que los nuevos valores de la tabla provendrán de la columna existente n, con values_from = n. Las columnas no mencionadas en nuestro comando de pivoteo (outcome) permanecerán sin cambios en el extremo izquierdo.\n\nage_by_outcome %&gt;% \n  select(-percent) %&gt;%   # mantiene sólo los recuentos para simplificar\n  pivot_wider(names_from = age_cat, values_from = n)  \n\n# A tibble: 3 × 10\n# Groups:   outcome [3]\n  outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Death     471   476     438     323     477     329      33     3    32\n2 Recover   364   391     303     251     367     238      38     3    28\n3 &lt;NA&gt;      260   228     200     169     229     187      24    NA    26\n\n\n\n\nTotal de filas\nCuando summarise() opera con datos agrupados no produce automáticamente estadísticas “totales”. A continuación, se presentan dos enfoques para añadir una fila de totales:\n\nadorn_totals() de janitor\nSi tu tabla consiste sólo en recuentos o proporciones/porcentajes que pueden sumarse en un total, entonces puedes añadir totales de suma usando adorn_totals() de janitor como se describe en la sección anterior. Ten en cuenta que esta función sólo puede sumar las columnas numéricas - si deseas calcular otras estadísticas de resumen total, mira el siguiente enfoque con dplyr.\nA continuación, linelist se agrupa por género y se resume en una tabla que describe el número de casos con resultado conocido, los fallecidos y los recuperados. Al pasar la tabla por adorn_totals() se añade una fila total en la parte inferior que refleja la suma de cada columna. Las funciones posteriores adorn_*() ajustan la visualización como se indica en el código.\n\nlinelist %&gt;% \n  group_by(gender) %&gt;%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Número de filas del grupo en las que no falta el resultado\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Número de filas en el grupo donde el resultado es Death\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Número de filas del grupo en las que el resultado es Recovered\n  ) %&gt;% \n  adorn_totals() %&gt;%                                # Adorna fila total (sumas de cada columna numérica)\n  adorn_percentages(\"col\") %&gt;%                      # Obtiene las proporciones de las columnas\n  adorn_pct_formatting() %&gt;%                        # Convierte las proporciones a porcentajes\n  adorn_ns(position = \"front\")                      # Muestra % y recuentos (con los recuentos delante)\n\n gender  known_outcome        n_death      n_recover\n      f 2,180  (47.8%) 1,227  (47.5%)   953  (48.1%)\n      m 2,178  (47.7%) 1,228  (47.6%)   950  (47.9%)\n   &lt;NA&gt;   207   (4.5%)   127   (4.9%)    80   (4.0%)\n  Total 4,565 (100.0%) 2,582 (100.0%) 1,983 (100.0%)\n\n\n\n\nsummarise() en los datos “totales” y luego bind_rows()\nSi tu tabla consta de estadísticas de resumen como median(), mean(),, etc., el enfoque adorn_totals() mostrado anteriormente no será suficiente. En tu lugar, para obtener los estadísticos de resumen de todo el set de datos debe calcularlos con un comando summarise() separado y luego vincular los resultados a la tabla de resumen agrupada original. Para hacer el enlace puedes utilizar bind_rows() de dplyr descrito en la página de unión de datos. A continuación se muestra un ejemplo:\nSe puede hacer una tabla resumen de resultados por hospital con group_by() y summarise() así:\n\nby_hospital &lt;- linelist %&gt;% \n  filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%  # Elimina los casos en los que falta el resultado o el hospital\n  group_by(hospital, outcome) %&gt;%                      # Agrupa los datos\n  summarise(                                           # Crea nuevas columnas de resumen de los indicadores de interés\n    N = n(),                                            # Número de filas por grupo de hospital-resultado    \n    ct_value = median(ct_blood, na.rm=T))               # Valor mediano de CT por grupo\n  \nby_hospital # print table\n\n# A tibble: 10 × 4\n# Groups:   hospital [5]\n   hospital                             outcome     N ct_value\n   &lt;chr&gt;                                &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n 1 Central Hospital                     Death     193       22\n 2 Central Hospital                     Recover   165       22\n 3 Military Hospital                    Death     399       21\n 4 Military Hospital                    Recover   309       22\n 5 Other                                Death     395       22\n 6 Other                                Recover   290       21\n 7 Port Hospital                        Death     785       22\n 8 Port Hospital                        Recover   579       21\n 9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\n\n\nPara obtener los totales, ejecuta el mismo comando summarise() pero agrupando los datos sólo por resultado (no por hospital), de la siguiente manera:\n\ntotals &lt;- linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Agrupado sólo por resultado, no por hospital        \n      summarise(\n        N = n(),                                       # Estas estadísticas son ahora sólo por resultado     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # imprimir tabla\n\n# A tibble: 2 × 3\n  outcome     N ct_value\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;\n1 Death    1971       22\n2 Recover  1469       22\n\n\nPodemos unir estos dos dataframes. Ten en cuenta que by_hospital tiene 4 columnas, mientras que totals tiene 3 columnas. Al utilizar bind_rows(), las columnas se combinan por nombre, y cualquier espacio extra se rellena con NA (por ejemplo, los valores de la columna hospital para las dos nuevas filas de totals). Después de enlazar las filas, convertimos estos espacios vacíos en “Total” utilizando replace_na() (véase la página de limpieza de datos y funciones básicas).\n\ntable_long &lt;- bind_rows(by_hospital, totals) %&gt;% \n  mutate(hospital = replace_na(hospital, \"Total\"))\n\nAquí está la nueva tabla con las filas “Total” en la parte inferior.\n\n\n\n\n\n\nEsta tabla tiene un formato “largo”, que puede ser lo que quieres. Opcionalmente, puedes pivotar esta tabla más ampliamente para hacerla más legible. Mira la sección sobre pivoteo más amplio arriba, y la página Pivotar datos. También puedes añadir más columnas, y organizarla de forma agradable. Este código está abajo.\n\ntable_long %&gt;% \n  \n  # Pivotar más ancho y formato\n  #############################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivota de largo a ancho\n    values_from = c(ct_value, N),                       # los nuevos valores proceden de las columnas ct y count\n    names_from = outcome) %&gt;%                           # los nuevos nombres de columna proceden de outcomes\n  mutate(                                              # Añade nuevas columnas\n    N_Known = N_Death + N_Recover,                               # número con resultado conocido\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentaje de casos que murieron (a 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # porcentaje de casos que se recuperaron (a 1 decimal)\n  select(                                              # Reordena las columnas\n    hospital, N_Known,                                   # columnas iniciales\n    N_Recover, Pct_Recover, ct_value_Recover,            # columnas de recuperados\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # columnas de fallecidos\n  arrange(N_Known)                                  # Ordenar las filas de menor a mayor (fila Total en la parte inferior)\n\n# A tibble: 6 × 8\n# Groups:   hospital [6]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n6 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;\n\n\nY luego puedes imprimir esto muy bien como una imagen - abajo está la salida impresa con flextable. Puedes leer más en profundidad sobre este ejemplo y cómo lograr esta tabla “bonita” en la página Tablas para presentaciones.\n\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#tbl_gt",
    "href": "new_pages/tables_descriptive.es.html#tbl_gt",
    "title": "17  Tablas descriptivas",
    "section": "17.5 Paquete gtsummary",
    "text": "17.5 Paquete gtsummary\nSi deseas imprimir tus estadísticas de resumen en un gráfico bonito y listo para tu publicación, puedes utilizar el paquete gtsummary y tu función tbl_summary(). El código puede parecer complejo al principio, pero los resultados se ven muy bien y se imprimen en tu panel de RStudio Viewer como una imagen HTML. Lea esta viñeta.\nTambién puedes añadir los resultados de las pruebas estadísticas a las tablas de gtsummary. Este proceso se describe en la sección gtsummary de la página Tests estadísticos simples.\nPara introducir tbl_summary() mostraremos primero el comportamiento más básico, que realmente produce una tabla grande y bonita. Luego, examinaremos en detalle cómo hacer ajustes y tablas más a medida.\n\nTabla resumen\nEl comportamiento por defecto de tbl_summary() es bastante increíble: toma las columnas que proporcionas y crea una tabla de resumen en un solo comando. La función imprime las estadísticas apropiadas para el tipo de columna: mediana y rango intercuartil (IQR) para las columnas numéricas, y recuentos (%) para las columnas categóricas. Los valores faltantes se convierten en “Missing”. Se añaden notas a pie de página para explicar las estadísticas, mientras que el N total se muestra en la parte superior.\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;%  # mantiene sólo las columnas de interés\n  tbl_summary()                                                  # por defecto\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n13 (6, 23)\n\n\n    Unknown\n86\n\n\ngender\n\n\n\n\n    f\n2,807 (50%)\n\n\n    m\n2,803 (50%)\n\n\n    Unknown\n278\n\n\noutcome\n\n\n\n\n    Death\n2,582 (57%)\n\n\n    Recover\n1,983 (43%)\n\n\n    Unknown\n1,323\n\n\nfever\n4,549 (81%)\n\n\n    Unknown\n249\n\n\ntemp\n38.80 (38.20, 39.20)\n\n\n    Unknown\n149\n\n\nhospital\n\n\n\n\n    Central Hospital\n454 (7.7%)\n\n\n    Military Hospital\n896 (15%)\n\n\n    Missing\n1,469 (25%)\n\n\n    Other\n885 (15%)\n\n\n    Port Hospital\n1,762 (30%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n422 (7.2%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\nAjustes\nAhora explicaremos cómo trabaja la función y cómo hacer los ajustes. Los argumentos clave se detallan a continuación:\nby = Puedes estratificar tu tabla por una columna (por ejemplo, por resultado), creando una tabla de dos vías.\nstatistic =  Usa una ecuación para especificar qué estadísticas mostrar y cómo mostrarlas. La ecuación tiene dos lados, separados por una tilde ~. En el lado derecho, entre comillas, está la visualización estadística deseada, y en el izquierdo están las columnas a las que se aplicará esa visualización.\n\nEl lado derecho de la ecuación utiliza la sintaxis de str_glue() de stringr (véase Caracteres y cadenas), con la cadena de visualización deseada entre comillas y los propios estadísticos entre llaves. Puedes incluir estadísticas como “n” (para los recuentos), “N” (para el denominador), “mean”, “median”, “sd”, “max”, “min”, percentiles como “p##” como “p25”, o porcentaje del total como “p”. Consulta ?tbl_summary para obtener más detalles.\nPara el lado izquierdo de la ecuación, puedes especificar las columnas por su nombre (por ejemplo, age o c(age, gender)) o utilizando ayudantes como all_continuous(), all_categorical(), contains(), starts_with(), etc.\n\nUn ejemplo sencillo de una ecuación statistic = podría ser como el siguiente, para imprimir sólo la media de la columna age_years:\n\nlinelist %&gt;% \n  select(age_years) %&gt;%         # mantiene sólo las columnas de interés \n  tbl_summary(                  # crea tabla resumen\n    statistic = age_years ~ \"{mean}\") # imprime la media de edad\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n16\n\n\n    Unknown\n86\n\n\n\n1 Mean\n\n\n\n\n\n\n\n\n\nUna ecuación un poco más compleja podría tener el aspecto de \"({min}, {max})\", incorporando los valores máximo y mínimo entre paréntesis y separados por una coma:\n\nlinelist %&gt;% \n  select(age_years) %&gt;%                       # conserva sólo las columnas de interés  \n  tbl_summary(                                # crea tabla resumen\n    statistic = age_years ~ \"({min}, {max})\") # imprime min y max de edad\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,8881\n\n\n\n\nage_years\n(0, 84)\n\n\n    Unknown\n86\n\n\n\n1 (Range)\n\n\n\n\n\n\n\n\n\nTambién puedes diferenciar la sintaxis para columnas separadas o tipos de columnas. En el ejemplo más complejo de abajo, el valor proporcionado a statistc = es una lista que indica que para todas las columnas continuas la tabla debe imprimir la media con la desviación estándar entre paréntesis, mientras que para todas las columnas categóricas debe imprimir el n, el denominador y el porcentaje.\ndigits =\nAjusta los dígitos y el redondeo. Opcionalmente, se puede especificar que sea sólo para columnas continuas (como a continuación).\nlabel =\nAjustar cómo debe mostrarse el nombre de la columna. Proporciona el nombre de la columna y la etiqueta deseada separados por una tilde. El valor por defecto es el nombre de la columna.\nmissing_text =\nAjustar cómo se muestran los valores faltantes. El valor por defecto es “Unknown”.\ntype = Se utiliza para ajustar cuántos niveles de la estadística se muestran. La sintaxis es similar a statistic = en el sentido de que se proporciona una ecuación con columnas a la izquierda y un valor a la derecha. Dos escenarios comunes incluyen:\n\ntype = all_categorical() ~ \"categorical\" Fuerza a las columnas dicotómicas (por ejemplo, fever sí/no) a mostrar todos los niveles en lugar de sólo la fila “sí”\ntype = all_continuous() ~ \"continuous2\" Permite estadísticas de varias líneas por variable, como se muestra en una sección posterior\n\nEn el siguiente ejemplo, cada uno de estos argumentos se utiliza para modificar la tabla resumen original:\n\nlinelist %&gt;% \n  select(age_years, gender, outcome, fever, temp, hospital) %&gt;% # conserva sólo las columnas de interés\n  tbl_summary(     \n    by = outcome,                                               # estratifica toda la tabla por resultado\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # estadísticas y formato de las columnas continuas\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # estadísticas y formato para columnas categóricas\n    digits = all_continuous() ~ 1,                              # redondeo para columnas continuas\n    type   = all_categorical() ~ \"categorical\",                 # fuerza la visualización de todos los niveles categóricos\n    label  = list(                                              # muestra las etiquetas de las columnas\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # cómo deben mostrarse los valores perdidos\n  )\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\n\n\n\n\nAge (years)\n15.9 (12.3)\n16.1 (13.0)\n\n\n    Missing\n32\n28\n\n\nGender\n\n\n\n\n\n\n    f\n1,227 / 2,455 (50%)\n953 / 1,903 (50%)\n\n\n    m\n1,228 / 2,455 (50%)\n950 / 1,903 (50%)\n\n\n    Missing\n127\n80\n\n\nfever\n\n\n\n\n\n\n    no\n458 / 2,460 (19%)\n361 / 1,904 (19%)\n\n\n    yes\n2,002 / 2,460 (81%)\n1,543 / 1,904 (81%)\n\n\n    Missing\n122\n79\n\n\nTemperature\n38.6 (1.0)\n38.6 (1.0)\n\n\n    Missing\n60\n55\n\n\nHospital\n\n\n\n\n\n\n    Central Hospital\n193 / 2,582 (7.5%)\n165 / 1,983 (8.3%)\n\n\n    Military Hospital\n399 / 2,582 (15%)\n309 / 1,983 (16%)\n\n\n    Missing\n611 / 2,582 (24%)\n514 / 1,983 (26%)\n\n\n    Other\n395 / 2,582 (15%)\n290 / 1,983 (15%)\n\n\n    Port Hospital\n785 / 2,582 (30%)\n579 / 1,983 (29%)\n\n\n    St. Mark's Maternity Hospital (SMMH)\n199 / 2,582 (7.7%)\n126 / 1,983 (6.4%)\n\n\n\n1 Mean (SD); n / N (%)\n\n\n\n\n\n\n\n\n\n\n\nEstadísticas de varias líneas para variables continuas\nSi deseas imprimir varias líneas de estadísticas para variables continuas, puedes indicarlo estableciendo type = a “continuous2”. Puedes combinar todos los elementos mostrados anteriormente en una tabla eligiendo qué estadísticas quiere mostrar. Para ello, debes indicar a la función que deseas obtener una tabla escribiendo el tipo como “continuous2”. El número de valores faltantes se muestra como “Desconocido”.\n\nlinelist %&gt;% \n  select(age_years, temp) %&gt;%                      # conserva sólo las columnas de interés\n  tbl_summary(                                     # crea tabla resumen\n    type = all_continuous() ~ \"continuous2\",       # indica que quieres imprimir múltiples estadísticas  \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # línea 1: media y DE\n      \"{median} ({p25}, {p75})\",                   # línea 2: mediana y RIQ\n      \"{min}, {max}\")                               # línea 3: mín. y máx.\n    )\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5,888\n\n\n\n\nage_years\n\n\n\n\n    Mean (SD)\n16 (13)\n\n\n    Median (IQR)\n13 (6, 23)\n\n\n    Range\n0, 84\n\n\n    Unknown\n86\n\n\ntemp\n\n\n\n\n    Mean (SD)\n38.56 (0.98)\n\n\n    Median (IQR)\n38.80 (38.20, 39.20)\n\n\n    Range\n35.20, 40.80\n\n\n    Unknown\n149\n\n\n\n\n\n\n\n\nHay muchas otras formas de modificar estas tablas, incluyendo la adición de valores p, el ajuste del color y los títulos, etc. Muchas de ellas se describen en la documentación (escribe ?tbl_summary en la Consola), y algunas se dan en la sección de Tests estadísticos sencillos.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#base-r-1",
    "href": "new_pages/tables_descriptive.es.html#base-r-1",
    "title": "17  Tablas descriptivas",
    "section": "17.6 R base",
    "text": "17.6 R base\nPuedes utilizar la función table() para tabular y cruzar las columnas. A diferencia de las opciones anteriores, debes especificar el dataframe cada vez que haga referencia a un nombre de columna, como se muestra a continuación.\nATENCIÓN: Los valores NA (missing) no se tabularán a menos que se incluya el argumento useNA = \"always\" (que también podría establecerse como “no” o “ifany”). .\nCONSEJO: Puedes utilizar el %$% de magrittr para eliminar la necesidad de repetir las llamadas al dataframe dentro de las funciones de R base. Por ejemplo, lo siguiente podría escribirse linelist %$% table(outcome, useNA = \"always\") \n\ntable(linelist$outcome, useNA = \"always\")\n\n\n  Death Recover    &lt;NA&gt; \n   2582    1983    1323 \n\n\nSe pueden cruzar varias columnas enumerándolas una tras otra, separadas por comas. Opcionalmente, se puede asignar a cada columna un “nombre” como Outcome = linelist$outcome.\n\nage_by_outcome &lt;- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # guarda la tabla como objeto\nage_by_outcome   # imprime la tabla\n\n       \n        Death Recover &lt;NA&gt;\n  0-4     471     364  260\n  5-9     476     391  228\n  10-14   438     303  200\n  15-19   323     251  169\n  20-29   477     367  229\n  30-49   329     238  187\n  50-69    33      38   24\n  70+       3       3    0\n  &lt;NA&gt;     32      28   26\n\n\n\nProporciones\nPara producir las proporciones, pasa la tabla anterior a la función prop.table(). Utiliza el argumento margins = para especificar si deseas que las proporciones sean de filas (1), de columnas (2) o de toda la tabla (3). Para mayor claridad, eniazamos la tabla con pipe a la función round() de R base, especificando 2 dígitos.\n\n# obtiene las proporciones de la tabla definida anteriormente, por filas, redondeadas\nprop.table(age_by_outcome, 1) %&gt;% round(2)\n\n       \n        Death Recover &lt;NA&gt;\n  0-4    0.43    0.33 0.24\n  5-9    0.43    0.36 0.21\n  10-14  0.47    0.32 0.21\n  15-19  0.43    0.34 0.23\n  20-29  0.44    0.34 0.21\n  30-49  0.44    0.32 0.25\n  50-69  0.35    0.40 0.25\n  70+    0.50    0.50 0.00\n  &lt;NA&gt;   0.37    0.33 0.30\n\n\n\n\nTotales\nPara añadir los totales de filas y columnas, pasa la tabla a addmargins(). Esto funciona tanto para recuentos como para proporciones.\n\naddmargins(age_by_outcome)\n\n       \n        Death Recover &lt;NA&gt;  Sum\n  0-4     471     364  260 1095\n  5-9     476     391  228 1095\n  10-14   438     303  200  941\n  15-19   323     251  169  743\n  20-29   477     367  229 1073\n  30-49   329     238  187  754\n  50-69    33      38   24   95\n  70+       3       3    0    6\n  &lt;NA&gt;     32      28   26   86\n  Sum    2582    1983 1323 5888\n\n\n\n\nConvertir en dataframe\nConvertir un objeto table() directamente en un dataframe no es sencillo. A continuación se muestra un enfoque:\n\nCrea la tabla, sin utilizar useNA = \"always\". En su lugar, convierte los valores NA en “(Missing)” con fct_explicit_na() de forcats.\nAñade los totales (opcional) pasando por addmargins()\nPipe a la función R base as.data.frame.matrix()\nEnviar la tabla a la función rownames_to_column() de tibble, especificando el nombre de la primera columna\nImprime, visualiza o exporta según desees. En este ejemplo utilizamos flextable() del paquete flextable como se describe en la página Tablas para presentaciones. Esto imprimirá en el panel de visualización de RStudio como una bonita imagen HTML.\n\n\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %&gt;% \n  addmargins() %&gt;% \n  as.data.frame.matrix() %&gt;% \n  tibble::rownames_to_column(var = \"Age Category\") %&gt;% \n  flextable::flextable()\n\nAge CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_descriptive.es.html#resources-10",
    "href": "new_pages/tables_descriptive.es.html#resources-10",
    "title": "17  Tablas descriptivas",
    "section": "17.7 Recursos",
    "text": "17.7 Recursos\nGran parte de la información de esta página está adaptada de estos recursos y viñetas en línea:\ngtsummary\ndplyr",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tablas descriptivas</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html",
    "href": "new_pages/stat_tests.es.html",
    "title": "18  Tests estadísticos sencillos",
    "section": "",
    "text": "18.1 Preparación",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html#preparation-9",
    "href": "new_pages/stat_tests.es.html#preparation-9",
    "title": "18  Tests estadísticos sencillos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos la función p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes ya instalados con el comando library() de R base Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,          # Importación de ficheros\n  here,         # localizador de ficheros\n  skimr,        # obtener una visión general de los datos\n  tidyverse,    # gestión de datos + gráficos ggplot2, \n  gtsummary,    # resumen estadístico y pruebas\n  rstatix,      # estadísticas\n  corrr,        # análisis de correlación para variables numéricas\n  janitor,      # añadir totales y porcentajes a las tablas\n  flextable     # conversión de tablas a HTML\n  )\n\n\n\nImportar datos\nImportaremos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (archivo linelist_cleaned.rds). Importa tus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).\n\n# importar linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html#base-r-2",
    "href": "new_pages/stat_tests.es.html#base-r-2",
    "title": "18  Tests estadísticos sencillos",
    "section": "18.2 ** R base**",
    "text": "18.2 ** R base**\nPuedes utilizar las funciones de ** R base** para realizar pruebas estadísticas. Los comandos son relativamente sencillos y los resultados se imprimen en la consola de R para su visualización. Sin embargo, las salidas suelen ser listas y, por lo tanto, son más difíciles de manipular en el caso que se desee utilizar los resultados en operaciones posteriores.\n\nTests-T\nUn test-t, también llamado “Test t de Student” o “Prueba t de Student”, se utiliza normalmente para determinar si existe una diferencia significativa entre las medias de alguna variable numérica entre dos grupos. Aquí mostraremos la sintaxis para hacer esta prueba dependiendo de si las columnas se encuentran o no en el mismo dataframe.\nSintaxis 1: Esta es la sintaxis cuando las columnas numéricas y categóricas están en el mismo dataframe. Sitúa la columna numérica en el lado izquierdo de la ecuación y la columna categórica en el lado derecho. Especifica los datos en data =. Opcionalmente, establece paired = TRUE, conf.level = (0.95 por defecto), y alternative = (ya sea “two.sided”, “less”, o “greater”). Escribe ?t.test para obtener más detalles.\n\n## comparar la edad media por grupo de resultados con un test-t\nt.test(age_years ~ gender, data = linelist)\n\n\n    Welch Two Sample t-test\n\ndata:  age_years by gender\nt = -21.344, df = 4902.3, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.571920 -6.297975\nsample estimates:\nmean in group f mean in group m \n       12.60207        19.53701 \n\n\nSintaxis 2: Puedes comparar dos vectores numéricos separados utilizando esta sintaxis alternativa. Por ejemplo, si las dos columnas están en dataframes diferentes.\n\nt.test(df1$age_years, df2$age_years)\n\nTambién se puede utilizar una prueba t de Student para determinar si la media de una muestra es significativamente diferente de algún valor específico. Aquí realizamos una prueba t de una muestra con la media poblacional conocida/hipotética como mu =:\n\nt.test(linelist$age_years, mu = 45)\n\n\n\nPrueba de Shapiro-Wilk\nEl test de Shapiro-Wilk puede utilizarse para determinar si una muestra procede de una población distribuida normalmente (un supuesto en muchas otras pruebas y análisis, como la prueba t). Sin embargo, sólo puede utilizarse en una muestra de entre 3 y 5000 observaciones. Para muestras más grandes puede ser útil un gráfico de cuantiles.\n\nshapiro.test(linelist$age_years)\n\n\n\nTest de suma de rangos de Wilcoxon\nEl test de suma de rangos de Wilcoxon, también llamada test U de Mann-Whitney, se utiliza a menudo para ayudar a determinar si dos muestras numéricas proceden de la misma distribución cuando tus poblaciones no se distribuyen normalmente o tienen una varianza desigual.\n\n## comparar la distribución de edad por grupo de resultados con un test de wilcox\nwilcox.test(age_years ~ outcome, data = linelist)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age_years by outcome\nW = 2501868, p-value = 0.8308\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nTest de Kruskal-Wallis\nEl test de Kruskal-Wallis es una extensión del test de suma de rangos de Wilcoxon. Puede utilizarse para comprobar las diferencias en la distribución de más de dos muestras. Cuando sólo se utilizan dos muestras, los resultados son idénticos a los del test de suma de rangos de Wilcoxon.\n\n## comparar la distribución de edad por grupo de resultados con un test de kruskal-wallis\nkruskal.test(age_years ~ outcome, linelist)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  age_years by outcome\nKruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308\n\n\n\n\nTest de Chi-cuadrado\nEl test de Chi-cuadrado de Pearson se utiliza para comprobar las diferencias significativas entre grupos categóricos.\n\n## comparar las proporciones en cada grupo con un test de chi-cuadrado\nchisq.test(linelist$gender, linelist$outcome)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  linelist$gender and linelist$outcome\nX-squared = 0.0011841, df = 1, p-value = 0.9725",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html#rstatix-package",
    "href": "new_pages/stat_tests.es.html#rstatix-package",
    "title": "18  Tests estadísticos sencillos",
    "section": "18.3 Paquete rstatix",
    "text": "18.3 Paquete rstatix\nEl paquete rstatix ofrece la posibilidad de ejecutar pruebas estadísticas y recuperar los resultados en un formato “amigable”. Los resultados se encuentran automáticamente en un dataframe para que puedan realizar operaciones posteriores con los resultados. También es fácil agrupar los datos que se pasan a las funciones, de modo que las estadísticas se ejecutan para cada grupo.\n\nEstadísticas resumidas\nLa función get_summary_stats() es una forma rápida de generar estadísticas de resumen. Únicamente tienes que tienes que seleccionar tu dataframe al aplicar esta función así como especificar las columnas que deseas analizar. Si no se especifica ninguna columna, las estadísticas se calculan para todas ellas.\nPor defecto, la función devuelve una gama completa de estadísticas de resumen: n, max, min, mediana, cuartil 25%, cuartil 75%, IQR, desviación absoluta mediana (mad), media, desviación estándar, error estándar y un intervalo de confianza de la media.\n\nlinelist %&gt;%\n  rstatix::get_summary_stats(age, temp)\n\n# A tibble: 2 × 13\n  variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166\n2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\nPuedes especificar un subconjunto de estadísticas de resumen a calcular proporcionando uno de los siguientes valores a type =: “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.\nTambién puede utilizarse con datos agrupados, de forma que se devuelva una fila por cada variable de agrupación:\n\nlinelist %&gt;%\n  group_by(hospital) %&gt;%\n  rstatix::get_summary_stats(age, temp, type = \"common\")\n\n# A tibble: 12 × 11\n   hospital     variable     n   min   max median   iqr  mean     sd    se    ci\n   &lt;chr&gt;        &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Central Hos… age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n 2 Central Hos… temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n 3 Military Ho… age        884   0    72     14    18    16.1 12.4   0.417 0.818\n 4 Military Ho… temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n 5 Missing      age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n 6 Missing      temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n 7 Other        age        873   0    69     13    17    16.0 12.5   0.422 0.828\n 8 Other        temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n 9 Port Hospit… age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n10 Port Hospit… temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n11 St. Mark's … age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n12 St. Mark's … temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095\n\n\nPor último, también se puede utilizar rstatix para realizar las siguientes pruebas estadísticas:\n\n\nTest-T\nUtiliza una sintaxis de fórmula para especificar las columnas numéricas y categóricas:\n\nlinelist %&gt;% \n  t_test(age_years ~ gender)\n\n# A tibble: 1 × 10\n  .y.   group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_… f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****        \n\n\nUtiliza ~ 1 y especifica mu = para un test-T de una muestra. Esto también puede hacerse por grupo.\n\nlinelist %&gt;% \n  t_test(age_years ~ 1, mu = 30)\n\n# A tibble: 1 × 7\n  .y.       group1 group2         n statistic    df     p\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 age_years 1      null model  5802     -84.2  5801     0\n\n\nSi procede, las pruebas estadísticas pueden realizarse por grupos, como se muestra a continuación:\n\nlinelist %&gt;% \n  group_by(gender) %&gt;% \n  t_test(age_years ~ 1, mu = 18)\n\n# A tibble: 3 × 8\n  gender .y.       group1 group2         n statistic    df         p\n* &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n3 &lt;NA&gt;   age_years 1      null model   192     -3.80   191 1.96e-  4\n\n\n\n\nPrueba de Shapiro-Wilk\nComo ya se ha dicho, el tamaño de la muestra debe estar entre 3 y 5000.\n\nlinelist %&gt;% \n  head(500) %&gt;%            # las 500 primeras filas de la lista de casos, sólo como ejemplo\n  shapiro_test(age_years)\n\n# A tibble: 1 × 3\n  variable  statistic        p\n  &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 age_years     0.917 6.67e-16\n\n\n\n\nPrueba de suma de rangos de Wilcoxon\n\nlinelist %&gt;% \n  wilcox_test(age_years ~ gender)\n\n# A tibble: 1 × 9\n  .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n* &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****        \n\n\n\n\nPrueba de Kruskal-Wallis\nTambién conocida como la prueba U de Mann-Whitney.\n\nlinelist %&gt;% \n  kruskal_test(age_years ~ outcome)\n\n# A tibble: 1 × 6\n  .y.           n statistic    df     p method        \n* &lt;chr&gt;     &lt;int&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis\n\n\n\n\nPrueba de Chi-cuadrado\nLa función para la prueba de chi-cuadrado funciona con tablas, así que primero creamos una tabulación cruzada. Hay muchas formas de crear una tabulación cruzada (véase Tablas descriptivas), pero aquí utilizamos tabyl() de janitor y eliminamos la columna más a la izquierda de las etiquetas de valores antes de pasarla a chisq_test().\n\nlinelist %&gt;% \n  tabyl(gender, outcome) %&gt;% \n  select(-1) %&gt;% \n  chisq_test()\n\n# A tibble: 1 × 6\n      n statistic     p    df method          p.signif\n* &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;   \n1  5888      3.53 0.473     4 Chi-square test ns      \n\n\nSe pueden ejecutar muchas más funciones y pruebas estadísticas con las funciones de rstatix. Consulta la documentación de rstatix o escribiendo ?rstatix.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html#stats_gt",
    "href": "new_pages/stat_tests.es.html#stats_gt",
    "title": "18  Tests estadísticos sencillos",
    "section": "18.4 Paquete gtsummary",
    "text": "18.4 Paquete gtsummary\nUtilizaa gtsummary si quieres añadir los resultados de una prueba estadística a una tabla estéticamente presentada, creada con este paquete (como se describe en la sección gtsummary del capítulo Tablas descriptivas).\nLa realización de pruebas estadísticas de comparación con tbl_summary se lleva a cabo añadiendo la función add_p a una tabla y especificando qué prueba utilizar. Es posible obtener p-valores corregidos para múltiples pruebas utilizando la función add_q. Ejecuta ?tbl_summary para obtener más detalles.\n\nPrueba de Chi-cuadrado\nCompara las proporciones de una variable categórica en dos grupos. La prueba estadística por defecto de add_p(), cuando se aplica a una variable categórica es realizar una prueba de independencia de chi-cuadrado con corrección de continuidad, pero si algúna celda de valores esperados es inferior a 5, se utiliza una prueba exacta de Fisher.\n\nlinelist %&gt;% \n  select(gender, outcome) %&gt;%    # mantiene las variables de interés\n  tbl_summary(by = outcome) %&gt;%  # produce la tabla resumen y especifica la variable de agrupación\n  add_p()                        # especifica qué test realizar\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\ngender\n\n\n\n\n&gt;0.9\n\n\n    f\n1,227 (50%)\n953 (50%)\n\n\n\n\n    m\n1,228 (50%)\n950 (50%)\n\n\n\n\n    Unknown\n127\n80\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\nTests-T\nCompara la diferencia de medias de una variable continua en dos grupos. Por ejemplo, hace la comparación de la media de edad por resultado del paciente.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%             # mantiene las variables de interés\n  tbl_summary(                               # produce la tabla resumen\n    statistic = age_years ~ \"{mean} ({sd})\", # especifica qué estadísticas mostrar\n    by = outcome) %&gt;%                        # especifica la variable de agrupación\n  add_p(age_years ~ \"t.test\")                # especifica qué prueba realizar\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n16 (12)\n16 (13)\n0.6\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n\n\n\n\n\n\n\n\n\nTest de suma de rangos de Wilcoxon\nCompara la distribución de una variable continua en dos grupos. Por defecto se utiliza la prueba de suma de rangos de Wilcoxon y la mediana (IQR) cuando se comparan dos grupos. Sin embargo, para datos no distribuidos normalmente o para comparar varios grupos, la prueba de Kruskal-wallis es más apropiada.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # mantiene las variables de interés\n  tbl_summary(                                         # produce la tabla resumen\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # especifica que estadistica mostrar (esta es por defecto asi que puede quitarse)\n    by = outcome) %&gt;%                                  # especifica la variable de agrupación\n  add_p(age_years ~ \"wilcox.test\")                     # especifica qué prueba realizar (por defecto así que se pueden dejar los paréntesis vacíos)\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Wilcoxon rank sum test\n\n\n\n\n\n\n\n\n\n\n\nTest de Kruskal-Wallis\nSe usa para comparar la distribución de una variable continua en dos o más grupos, independientemente de que los datos se distribuyan normalmente.\n\nlinelist %&gt;% \n  select(age_years, outcome) %&gt;%                       # mantiene las variables de interés\n  tbl_summary(                                         # produce la tabla resumen\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # especifica que estadistica mostrar (por defecto asi que puede quitarse)\n    by = outcome) %&gt;%                                  # especifica la variable de agrupación\n  add_p(age_years ~ \"kruskal.test\")                    # especifica qué test realizar\n\n1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nDeath, N = 2,5821\nRecover, N = 1,9831\np-value2\n\n\n\n\nage_years\n13 (6, 23)\n13 (6, 23)\n0.8\n\n\n    Unknown\n32\n28\n\n\n\n\n\n1 Median (IQR)\n\n\n2 Kruskal-Wallis rank sum test",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html#correlations",
    "href": "new_pages/stat_tests.es.html#correlations",
    "title": "18  Tests estadísticos sencillos",
    "section": "18.5 Correlaciones",
    "text": "18.5 Correlaciones\nLa correlación entre variables numéricas puede investigarse con el paquete corrr de tidyverse. Permite calcular las correlaciones mediante los test de Pearson, tau de Kendall o rho de Spearman. El paquete crea una tabla y también tiene una función para representar automáticamente los valores.\n\ncorrelation_tab &lt;- linelist %&gt;% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %&gt;%   # keep numeric variables of interest\n  correlate()      # mantiene las variables numéricas de interés\n\ncorrelation_tab    # imprimir\n\n# A tibble: 6 × 7\n  term            generation      age ct_blood days_onset_hosp    wt_kg    ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 generation        NA       -2.22e-2  0.179         -0.288    -0.0302  -0.00942\n2 age               -0.0222  NA        0.00849       -0.000635  0.833    0.877  \n3 ct_blood           0.179    8.49e-3 NA             -0.600    -0.00636  0.0181 \n4 days_onset_hosp   -0.288   -6.35e-4 -0.600         NA         0.0153  -0.00953\n5 wt_kg             -0.0302   8.33e-1 -0.00636        0.0153   NA        0.884  \n6 ht_cm             -0.00942  8.77e-1  0.0181        -0.00953   0.884   NA      \n\n## eliminar entradas duplicadas (la tabla anterior está reflejada) \ncorrelation_tab &lt;- correlation_tab %&gt;% \n  shave()\n\n## ver la tabla de correlaciones \ncorrelation_tab\n\n# A tibble: 6 × 7\n  term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 generation        NA       NA        NA              NA       NA        NA\n2 age               -0.0222  NA        NA              NA       NA        NA\n3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n\n## representar correlaciones \nrplot(correlation_tab)",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/stat_tests.es.html#resources-11",
    "href": "new_pages/stat_tests.es.html#resources-11",
    "title": "18  Tests estadísticos sencillos",
    "section": "18.6 Recursos",
    "text": "18.6 Recursos\nGran parte de la información de esta página está adaptada de los siguientes recursos y viñetas en línea:\ngtsummary\ndplyr\ncorrr\ncorrelaciones en sthda",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Tests estadísticos sencillos</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html",
    "href": "new_pages/regression.es.html",
    "title": "19  Regresión univariante y multivariable",
    "section": "",
    "text": "19.1 Preparación",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html#preparation-10",
    "href": "new_pages/regression.es.html#preparation-10",
    "title": "19  Regresión univariante y multivariable",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para realizar los análisis. En este manual se hace énfasis en en el empleo de p_load() de pacman, que instala el paquete si es necesario y lo carga para tu uso. Los paquetes ya instalados también pueden cargarse empleando library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,          # Importación de ficheros\n  here,         # Localizador de ficheros\n  tidyverse,    # gestión de datos + gráficos ggplot2, \n  stringr,      # manipular cadenas de texto \n  purrr,        # bucle sobre objetos de forma ordenada\n  gtsummary,    # resumen estadístico y tests \n  broom,        # ordenar resultados de regresiones\n  lmtest,       # pruebas de razón de verosimilitud\n  parameters,   # alternativa para ordenar los resultados de las regresiones\n  ver           # alternativa para visualizar gráficos de bosque\n  )\n\nInstalling package into 'C:/Users/ngulu864/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: package 'ver' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'ver'\n\n\nWarning in pacman::p_load(rio, here, tidyverse, stringr, purrr, gtsummary, : Failed to install/load:\nver\n\n\n\n\nImportar datos\nImportaremos los datos de casos de una epidemia de ébola simulada. Para seguir el proceso, clica aquí para descargar la base de datos linelist “limpia” (como archivo .rds). Importa tus datos con la función import() del paquete rio (la cual acepta múltiples tipos de archivos como .xlsx, .rds, .csv - Checa la página de importación y exportación para más detalles).\n\n# importar linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas de la base de datos linelist.\n\n\n\n\n\n\n\n\nDatos limpios\n\nAlmacenar las variables explicativas\nAlmacenamos en un vector de caracteres los nombres de las columnas explicativas. Esto se explicará más adelante.\n\n## definir las variables de interés\nexplanatory_vars &lt;- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n\n\nConvertir a 1’s y 0’s\nA continuación convertimos las columnas explicativas de “sí”/“no”, “m”/“f”, y “muerto”/“vivo” a 1 / 0, para cumplir con las expectativas de los modelos de regresión logística. Para hacer esto de manera eficiente, utilizaremos across() de dplyr para transformar varias columnas a la vez. La función que aplicamos a cada columna es case_when() (también de dplyr) que aplica la lógica para convertir los valores especificados en 1’s y 0’s. Mira las secciones sobre across() y case_when() en la página de Limpieza de datos y funciones básicas).\nNota: el “.” que aparece a continuación representa la columna que está siendo procesada por across() en ese momento.\n\n## convertir variables dicotómicas a 0/1\nlinelist &lt;- linelist %&gt;%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## para cada columna listada y \"outcome\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recodifica hombre, yes y defunción a 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0,           ## mujer, no y recuperado a 0\n      TRUE                            ~ NA_real_)    ## de lo contrario, lo establece como faltante\n    )\n  )\n\n\n\nEliminar las filas con valores perdidos\nPara eliminar las filas con valores perdidos, se puede utilizar la función drop_na() de tidyr. Sin embargo, sólo queremos hacer esto para las filas a las que les faltan valores en las columnas de interés.\nLo primero que debemos hacer es asegurarnos de que nuestro vector explanatory_vars incluye la columna age (age habría producido un error en la operación anterior case_when(), que sólo era para variables dicotómicas). A continuación, escribimos un pipe uniendo linelist con drop_na() para eliminar cualquier fila con valores perdidos en la columna outcome o en cualquiera de las columnas explanatory_vars.\nAntes de ejecutar el código, podemos comprobar el número de filas inicial de linelist empleando nrow(linelist).\n\n## añadir age_category a las variables explicativas \nexplanatory_vars &lt;- c(explanatory_vars, \"age_cat\")\n\n## eliminar las filas con información no disponible para las variables de interés \nlinelist &lt;- linelist %&gt;% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))\n\nPodremos checar el número de filas que quedan en linelist tras la operación empleando nrow(linelist).",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html#univariate",
    "href": "new_pages/regression.es.html#univariate",
    "title": "19  Regresión univariante y multivariable",
    "section": "19.2 Univariante",
    "text": "19.2 Univariante\nAl igual que en la página sobre Tablas descriptivas, en función de la tarea que vayas a realizar, podremos elegir que función emplear. A continuación presentamos dos opciones para realizar análisis univariantes:\n\nPuedes utilizar las funciones disponibles en R base para imprimir rápidamente los resultados en la consola. Después, puedes utilizar el paquete broom para convertir esos outputs a formato tidy.\nPuedes utilizar el paquete gtsummary para modelar y obtener resultados en tablas listas para su publicación.\n\n\n\nR base\n\nRegresión lineal\nLa función lm() de R base realiza una regresión lineal, evaluando la relación entre la respuesta numérica y las variables explicativas que se supone tienen una relación lineal.\nPara ello, proporciona la ecuación como una fórmula, con los nombres de las columnas de respuesta y explicativa separados por una tilde ~. Además, especifica la base de datos a data =. Finalmente, define los resultados del modelo como un objeto R, para poder utilizarlos más tarde.\n\nlm_results &lt;- lm(ht_cm ~ age, data = linelist)\n\nA continuación, puedes ejecutar summary() en los resultados del modelo para ver los coeficientes (estimaciones), el valor P, los residuos y otras medidas.\n\nsummary(lm_results)\n\n\nCall:\nlm(formula = ht_cm ~ age, data = linelist)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-128.579  -15.854    1.177   15.887  175.483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  69.9051     0.5979   116.9   &lt;2e-16 ***\nage           3.4354     0.0293   117.2   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.75 on 4165 degrees of freedom\nMultiple R-squared:  0.7675,    Adjusted R-squared:  0.7674 \nF-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: &lt; 2.2e-16\n\n\nTambién se puede utilizar la función tidy() del paquete broom para obtener los resultados en una tabla. Lo que nos dicen los resultados es que por cada año de aumento de la edad la altura aumenta 3,5 cm y esto es estadísticamente significativo.\n\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    69.9     0.598       117.       0\n2 age             3.44    0.0293      117.       0\n\n\nTambién podemos utilizar esta regresión para añadirla a un ggplot, para hacer esto, primero juntamos los puntos de los datos observados y la línea ajustada en un dataframe utilizando la función augment() de broom.\n\n## extraer los puntos de regresión y los datos observados en un conjunto de datos\npoints &lt;- augment(lm_results)\n\n## representar los datos utilizando la edad como eje-x \nggplot(points, aes(x = age)) + \n  ## añadir puntos para la altura\n  geom_point(aes(y = ht_cm)) + \n  ## añadir la recta de regresión \n  geom_line(aes(y = .fitted), colour = \"red\")\n\n\n\n\n\n\n\n\nTambién es posible añadir una recta de regresión lineal en ggplot utilizando la función geom_smooth().\n\n## añade tus datos a un gráfico \n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## mostrar puntos\n  geom_point() + \n  ## añadir una regresión lineal \n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nConsulta la sección de recursos al final de este capítulo para consultar tutoriales más detallados.\n\n\nRegresión logística\nLa función glm() del paquete stats (parte de R base) se utiliza para ajustar los modelos lineales generalizados (GLM).\nglm() puede utilizarse para la regresión logística univariante y multivariable (por ejemplo, para obtener Odds Ratios). Aquí están las partes principales:\n\n# argumentos para glm()\nglm(formula, family, data, weights, subset, ...)\n\n\nformula = El modelo se proporciona a glm() como una ecuación, con el resultado a la izquierda y las variables explicativas a la derecha de una tilde ~.\nfamily = Determina el tipo de modelo a ejecutar. Para la regresión logística, utiliza family = \"binomial\", para poisson utiliza family = \"poisson\". Otros ejemplos se encuentran en la tabla siguiente.\ndata = Especifica tu base de datos.\n\nSi es necesario, también puede especificar la función de enlace mediante la sintaxis family = familytype(link = \"linkfunction\")). Puedes leer más en la documentación sobre otras familias y argumentos opcionales como weights = y subset = (?glm).\n\n\n\nFamilia\nFunción de enlace por defecto\n\n\n\n\n\"binomial\"\n(link = \"logit\")\n\n\n\"gaussian\"\n(link = \"identity\")\n\n\n\"Gamma\"\n(link = \"inverse\")\n\n\n\"inverse.gaussian\"\n(link = \"1/mu^2\")\n\n\n\"poisson\"\n(link = \"log\")\n\n\n\"quasi\"\n(link = \"identity\", variance = \"constant\")\n\n\n\"quasibinomial\"\n(link = \"logit\")\n\n\n\"quasipoisson\"\n(link = \"log\")\n\n\n\nCuando se ejecuta glm() lo más habitual es guardar los resultados como un objeto R. A continuación, se pueden mostrar los resultados en la consola utilizando summary() como se muestra a continuación, o realizar otras operaciones con los resultados (por ejemplo, exponenciar).\nSi necesitas ejecutar una regresión binomial negativa, puede utilizar el paquete MASS; el cual contiene la función glm.nb() que utiliza la misma sintaxis que glm().\nPara un recorrido por diferentes regresiones, consulta la página de estadísticas de UCLA.\n\n\nUnivariante glm()\nEn este ejemplo estamos evaluando la asociación entre diferentes categorías de edad y el resultado de muerte (codificado como 1 en la sección anterior “Preparación”). A continuación se muestra un modelo univariante de outcome por age_cat. Guardamos la salida del modelo como model y luego la imprimimos con summary() en la consola. Observa que las estimaciones proporcionadas son las probabilidades logarítmicas (log odds) y que el nivel de referencia es el primer nivel del factor age_cat (“0-4”).\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   0.233738   0.072805   3.210  0.00133 **\nage_cat5-9   -0.062898   0.101733  -0.618  0.53640   \nage_cat10-14  0.138204   0.107186   1.289  0.19726   \nage_cat15-19 -0.005565   0.113343  -0.049  0.96084   \nage_cat20-29  0.027511   0.102133   0.269  0.78765   \nage_cat30-49  0.063764   0.113771   0.560  0.57517   \nage_cat50-69 -0.387889   0.259240  -1.496  0.13459   \nage_cat70+   -0.639203   0.915770  -0.698  0.48518   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\nPara modificar el nivel de referencia de una variable determinada, asegúrate de que la columna es del tipo Factor y mueve el nivel deseado a la primera posición con fct_relevel() (véase la página sobre Factores). Por ejemplo, a continuación tomamos la columna age_cat y establecemos “20-29” como línea de base antes de conectar mediante pipes el dataframe modificado con glm().\n\nlinelist %&gt;% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %&gt;% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %&gt;% \n  summary()\n\n\nCall:\nglm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.26125    0.07163   3.647 0.000265 ***\nage_cat0-4   -0.02751    0.10213  -0.269 0.787652    \nage_cat5-9   -0.09041    0.10090  -0.896 0.370220    \nage_cat10-14  0.11069    0.10639   1.040 0.298133    \nage_cat15-19 -0.03308    0.11259  -0.294 0.768934    \nage_cat30-49  0.03625    0.11302   0.321 0.748390    \nage_cat50-69 -0.41540    0.25891  -1.604 0.108625    \nage_cat70+   -0.66671    0.91568  -0.728 0.466546    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5705.1  on 4159  degrees of freedom\nAIC: 5721.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nImprimir resultados\nEn la mayoría de los casos, para su empleo posterior, es necesario hacer modificaciones a los resultados obtenidos anteriormente. La función tidy() del paquete broom es útil de cara a hacer más presentables los resultados de nuestros modelos.\nAquí demostramos cómo combinar los resultados del modelo con una tabla de recuento.\n\nObtén las estimaciones de log odds ratio exponenciadas y los intervalos de confianza pasando el modelo a tidy() y estableciendo exponentiate = TRUE y conf.int = TRUE.\n\n\nmodel &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %&gt;% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%        # exponenciar y producir ICs\n  mutate(across(where(is.numeric), round, digits = 2))  # redondear todas las columnas numéricas\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, digits = 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nA continuación, se muestra el objeto tibble model resultante:\n\n\n\n\n\n\n\nCombina estos resultados del modelo con una tabla de recuentos. A continuación, creamos la tabla cruzada de recuentos con la función tabyl() de janitor, como se explica en la página de tablas descriptivas.\n\n\ncounts_table &lt;- linelist %&gt;% \n  janitor::tabyl(age_cat, outcome)\n\n\n\n\n\n\n\n\n\n\n\nEste es el aspecto de este dataframe counts_table:\n\n\n\n\n\n\nAhora podemos unir counts_table y los resultados del model horizontalmente con bind_cols() (dplyr). Recuerda que con bind_cols() las filas de los dos dataframes deben estar perfectamente alineadas. En este código, como estamos enlazando mediante pipes, utilizamos . para representar el objeto counts_table mientras lo enlazamos con el modelo. Para terminar el proceso, utilizamos select() para elegir las columnas deseadas y determinar su orden, y finalmente aplicamos la función round() de R base en todas las columnas numéricas para especificar 2 decimales.\n\ncombined &lt;- counts_table %&gt;%           # comienza con la tabla de recuentos\n  bind_cols(., model) %&gt;%              # combina con los resultados de la regresión \n  select(term, 2:3, estimate,          # selecciona y reordena las columnas\n         conf.low, conf.high, p.value) %&gt;% \n  mutate(across(where(is.numeric), round, digits = 2)) ## redondea a 2 decimales\n\nEste es el aspecto del dataframe combinado, impreso de forma agradable como una imagen con una función de flextable. En Tablas para presentación se explica cómo personalizar dichas tablas con flextable, o bien puede utilizar otros paquetes como knitr o GT.\n\ncombined &lt;- combined %&gt;% \n  flextable::qflextable()\n\n\n\nLoops con múltiples modelos univariantes\nA continuación presentamos un método que utiliza glm() y tidy(). Para un enfoque más sencillo, véase la sección sobre gtsummary.\nPara ejecutar los modelos en varias variables de exposición para producir odds ratios univariantes (es decir, sin controlar entre sí), se puede utilizar el enfoque siguiente. Utiliza str_c() de stringr para crear fórmulas univariantes (véase Caracteres y cadenas), ejecuta la regresión glm() en cada fórmula, pasa cada resultado de glm() a tidy() y finalmente junta todos los resultados de los modelos resultantes con bind_rows() de tidyr. Este enfoque utiliza map() del paquete purrr para iterar - véase la página sobre Iteración, bucles y listas para más información sobre esta herramienta.\n\nCrea un vector de nombres de columnas de las variables explicativas. Ya lo tenemos como explanatory_vars de la sección de preparación de esta página.\nUtiliza str_c() para crear múltiples fórmulas de cadena, con el resultado a la izquierda, y un nombre de columna de explanatory_vars a la derecha. El punto . sustituye al nombre de la columna en explanatory_vars.\n\n\nexplanatory_vars %&gt;% str_c(\"outcome ~ \", .)\n\n[1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\" \n[4] \"outcome ~ cough\"   \"outcome ~ aches\"   \"outcome ~ vomit\"  \n[7] \"outcome ~ age_cat\"\n\n\n\nPasa estas fórmulas de cadena a map() y establece ~glm() como la función a aplicar a cada entrada. Dentro de glm(), establece la fórmula de regresión como as.formula(.x), donde .x se sustituirá por la fórmula de cadena definida en el paso anterior. map() realizará un bucle sobre cada una de las fórmulas de cadena, ejecutando regresiones para cada una.\nLos resultados de este primer map() se pasan a un segundo comando map(), que aplica tidy() a los resultados de la regresión.\nPor último, la salida de la segunda función map() (una lista de dataframes ordenados) se condensa con bind_rows(), dando lugar a un dataframe con todos los resultados univariantes.\n\n\nmodels &lt;- explanatory_vars %&gt;%       # comienza con las variables de interés\n  str_c(\"outcome ~ \", .) %&gt;%         # combina cada variable en una fórmula (\"resultado ~ variable de interés\")\n  \n  # iterar a través de cada fórmula univariante\n  map(                               \n    .f = ~glm(                       # pasa las fórmulas una a una a glm()\n      formula = as.formula(.x),      # dentro de glm(), la fórmula de cadena es .x\n      family = \"binomial\",           # especifica el tipo de glm (logístico)\n      data = linelist)) %&gt;%          # conjunto de datos\n  \n  # ordenar cada uno de los resultados de regresión glm anteriores\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponenciación \n      conf.int = TRUE)) %&gt;%          # devuelve los intervalos de confianza\n  \n  # colapsar la lista de resultados de regresión en un marco de datos\n  bind_rows() %&gt;% \n  \n  # redondear todas las columnas numéricas\n  mutate(across(where(is.numeric), round, digits = 2))\n\nEsta vez, el objeto final models es más largo porque ahora representa los resultados combinados de varias regresiones univariantes. Clica para ver todas las filas de model.\n\n\n\n\n\n\nComo antes, podemos crear una tabla de recuentos a partir de linelist para cada variable explicativa, vincularla a models y hacer una bonita tabla. Comenzamos con las variables, e iteramos a través de ellas con map(). Iteramos a través de una función definida por el usuario que implica la creación de una tabla de recuentos con funciones dplyr. Luego se combinan los resultados y se vinculan con los resultados del modelo models.\n\n## para cada variable explicativa\nuniv_tab_base &lt;- explanatory_vars %&gt;% \n  map(.f = \n    ~{linelist %&gt;%                ## comienza con linelist\n        group_by(outcome) %&gt;%     ## agrupa los datos por resultado\n        count(.data[[.x]]) %&gt;%    ## produce recuentos para la variable de interés\n        pivot_wider(              ## extiende a formato ancho (como en tabulación cruzada)\n          names_from = outcome,\n          values_from = n) %&gt;% \n        drop_na(.data[[.x]]) %&gt;%         ## elimina las filas que faltan\n        rename(\"variable\" = .x) %&gt;%      ## cambia la columna de la variable de interés a \"variable\"\n        mutate(variable = as.character(variable))} ## convierte a carácter, de lo contrario las variables no dicotómicas (categóricas) aparecen como factor y no se pueden combinar\n      ) %&gt;% \n  \n  ## colapsar la lista de resultados de conteo en un dataframe\n  bind_rows() %&gt;% \n  \n  ## combinar con los resultados de la regresión \n  bind_cols(., models) %&gt;% \n  \n  ## conservar sólo las columnas de interés \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %&gt;% \n  \n  ## redondear decimales\n  mutate(across(where(is.numeric), round, digits = 2))\n\nA continuación se muestra el aspecto del dataframe. Consulta la página sobre Tablas para presentación para obtener ideas sobre cómo convertir esta tabla en una bonita tabla HTML (por ejemplo, con flextable).\n\n\n\n\n\n\n\n\n\n\nPaquete gtsummary\nA continuación presentamos el uso de tbl_uvregression() del paquete gtsummary. Al igual que en la página sobre Tablas descriptivas, las funciones de gtsummary hacen un buen trabajo a la hora de realizar estadísticas y producir outputs con aspecto profesional. Esta función produce una tabla de resultados de regresión univariante.\nSeleccionamos sólo las columnas necesarias de linelist (variables explicativas y la variable de resultado) y las introducimos en tbl_uvregression(). Vamos a ejecutar una regresión univariante en cada una de las columnas que definimos como explanatory_vars en la sección de preparación de datos (sexo, fiebre, escalofríos, tos, dolores, vómitos y age_cat).\nDentro de la propia función, proporcionamos el method = como glm (sin comillas), la columna de resultado y = (outcome), especificamos a method.args = que queremos ejecutar la regresión logística a través de family = binomial, y le decimos que exponencie los resultados.\nLa salida es HTML y contiene el recuento de cada variable.\n\nuniv_tab &lt;- linelist %&gt;% \n  dplyr::select(explanatory_vars, outcome) %&gt;% ## selecciona las variables de interés\n\n  tbl_uvregression(                         ## produce una tabla univariante\n    method = glm,                           ## define la regresión que se desea ejecutar (modelo lineal generalizado)\n    y = outcome,                            ## define la variable de resultado\n    method.args = list(family = binomial),  ## define el tipo de glm que se quiere ejecutar (logístico)\n    exponentiate = TRUE                     ## exponencia para producir odds ratios (en lugar de log odds)\n  )\n\n## ver la tabla de resultados univariantes\nuniv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nHay muchas modificaciones que se pueden hacer al output de esta tabla, como ajustar las etiquetas de texto, poner en negrita las filas por tu valor p, etc. Puedes consultar tutoriales aquí y en internet.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html#stratified",
    "href": "new_pages/regression.es.html#stratified",
    "title": "19  Regresión univariante y multivariable",
    "section": "19.3 Estratificado",
    "text": "19.3 Estratificado\nActualmente, el análisis estratificado para gtsummary se está desarrollando. Esta página se actualizará a su debido tiempo.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html#multivariable",
    "href": "new_pages/regression.es.html#multivariable",
    "title": "19  Regresión univariante y multivariable",
    "section": "19.4 Multivariable",
    "text": "19.4 Multivariable\nPara el análisis multivariable, volvemos a presentar dos enfoques:\n\nglm() y tidy()\n\nPaquete gtsummary\n\nEl flujo de trabajo es similar para cada uno de ellos, siendo diferente el último paso al elaborar una tabla final.\n\nRealizar análisis multivariable\nAquí utilizamos glm() pero en este caso, añadiremos más variables al lado derecho de la ecuación, separadas por símbolos de suma (+).\nPara ejecutar el modelo con todas nuestras variables explicativas ejecutaríamos:\n\nmv_reg &lt;- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)\n\n\nCall:\nglm(formula = outcome ~ gender + fever + chills + cough + aches + \n    vomit + age_cat, family = \"binomial\", data = linelist)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   0.069054   0.131726   0.524    0.600\ngender        0.002448   0.065133   0.038    0.970\nfever         0.004309   0.080522   0.054    0.957\nchills        0.034112   0.078924   0.432    0.666\ncough         0.138584   0.089909   1.541    0.123\naches        -0.070705   0.104078  -0.679    0.497\nvomit         0.086098   0.062618   1.375    0.169\nage_cat5-9   -0.063562   0.101851  -0.624    0.533\nage_cat10-14  0.136372   0.107275   1.271    0.204\nage_cat15-19 -0.011074   0.113640  -0.097    0.922\nage_cat20-29  0.026552   0.102780   0.258    0.796\nage_cat30-49  0.059569   0.116402   0.512    0.609\nage_cat50-69 -0.388964   0.262384  -1.482    0.138\nage_cat70+   -0.647443   0.917375  -0.706    0.480\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5712.4  on 4166  degrees of freedom\nResidual deviance: 5700.2  on 4153  degrees of freedom\nAIC: 5728.2\n\nNumber of Fisher Scoring iterations: 4\n\n\nSi quieres incluir dos variables y una interacción entre ellas puede separarlas con un asterisco * en lugar de un +. Si sólo especifica la interacción, sepáralas con dos puntos :. Por ejemplo:\n\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n\nOpcionalmente, puedes utilizar este código para aprovechar el vector predefinido de nombres de columnas y volver a crear el comando anterior utilizando str_c(). Esto puede ser útil si los nombres de sus variables explicativas cambian, o si no quieres escribirlas todos de nuevo.\n\n## ejecutar una regresión con todas las variables de interés \nmv_reg &lt;- explanatory_vars %&gt;%  ## comienza con el vector de nombres de columnas explicativas\n  str_c(collapse = \"+\") %&gt;%     ## combina todos los nombres de las variables de interés separados por un más\n  str_c(\"outcome ~ \", .) %&gt;%    ## combina los nombres de las variables de interés con el resultado en forma de fórmula\n  glm(family = \"binomial\",      ## define el tipo de glm como logístico,\n      data = linelist)          ## se establece el conjunto de datos\n\n\nConstruir el modelo\nPuedes construir tu modelo paso a paso, guardando varios modelos que incluyan determinadas variables explicativas. Puedes comparar estos modelos con pruebas de razón de verosimilitud utilizando lrtest() del paquete lmtest, como se indica a continuación:\nNOTA: El uso de anova(model1, model2, test = \"Chisq\") de R base produce los mismos resultados \n\nmodel1 &lt;- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 &lt;- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)\n\nLikelihood ratio test\n\nModel 1: outcome ~ age_cat\nModel 2: outcome ~ age_cat + gender\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)\n1   8 -2852.6                    \n2   9 -2852.6  1 2e-04     0.9883\n\n\nOtra opción es tomar el objeto que contiene el modelo y aplicar la función step() del paquete stats. Especifica qué dirección de selección de variables deseas utilizar al construir el modelo.\n\n## escoger un modelo usando selección hacia adelante basada en AIC\n## también se puede hacer \"hacia atrás\" o \"ambos\" ajustando la dirección\nfinal_mv_reg &lt;- mv_reg %&gt;%\n  step(direction = \"forward\", trace = FALSE)\n\nPara mayor claridad, también puedes desactivar la notación científica en tu sesión de R.\n\noptions(scipen=999)\n\nComo se describe en la sección sobre el análisis univariante, pasamos la salida del modelo a tidy() para exponenciar las probabilidades logarítmicas y los IC. Finalmente, redondeamos todas las columnas numéricas a dos decimales. Haz scroll para ver el resultado.\n\nmv_tab_base &lt;- final_mv_reg %&gt;% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %&gt;%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## redonda\n\nEste es el aspecto del dataframe resultante:\n\n\n\n\n\n\n\n\n\n\nCombinar regresiones univariantes y multivariables\n\nCombinar con gtsummary\nEl paquete gtsummary proporciona la función tbl_regression(), que toma los resultados de una regresión (glm() en este caso) y produce una bonita tabla resumen.\n\n## mostrar la tabla de resultados de la regresión final \nmv_tab &lt;- tbl_regression(final_mv_reg, exponentiate = TRUE)\n\nVeamos la tabla:\n\nmv_tab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n1.15\n0.96, 1.37\n0.12\n\n\naches\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n\n\n\n\n\n\n\n\n    0-4\n—\n—\n\n\n\n\n    5-9\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nTambién puedes combinar varias tablas producidas por gtsummary con la función tbl_merge(). En este ejemplo combinaremos los resultados multivariables con los resultados univariantes de gtsummary que creamos anteriormente:\n\n## combinar con resultados univariantes \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combina\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # establece los nombres de las cabeceras\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nUnivariate\nMultivariable\n\n\nN\nOR1\n95% CI1\np-value\nOR1\n95% CI1\np-value\n\n\n\n\ngender\n4,167\n1.00\n0.88, 1.13\n&gt;0.9\n1.00\n0.88, 1.14\n&gt;0.9\n\n\nfever\n4,167\n1.00\n0.85, 1.17\n&gt;0.9\n1.00\n0.86, 1.18\n&gt;0.9\n\n\nchills\n4,167\n1.03\n0.89, 1.21\n0.7\n1.03\n0.89, 1.21\n0.7\n\n\ncough\n4,167\n1.15\n0.97, 1.37\n0.11\n1.15\n0.96, 1.37\n0.12\n\n\naches\n4,167\n0.93\n0.76, 1.14\n0.5\n0.93\n0.76, 1.14\n0.5\n\n\nvomit\n4,167\n1.09\n0.96, 1.23\n0.2\n1.09\n0.96, 1.23\n0.2\n\n\nage_cat\n4,167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    0-4\n\n\n—\n—\n\n\n—\n—\n\n\n\n\n    5-9\n\n\n0.94\n0.77, 1.15\n0.5\n0.94\n0.77, 1.15\n0.5\n\n\n    10-14\n\n\n1.15\n0.93, 1.42\n0.2\n1.15\n0.93, 1.41\n0.2\n\n\n    15-19\n\n\n0.99\n0.80, 1.24\n&gt;0.9\n0.99\n0.79, 1.24\n&gt;0.9\n\n\n    20-29\n\n\n1.03\n0.84, 1.26\n0.8\n1.03\n0.84, 1.26\n0.8\n\n\n    30-49\n\n\n1.07\n0.85, 1.33\n0.6\n1.06\n0.85, 1.33\n0.6\n\n\n    50-69\n\n\n0.68\n0.41, 1.13\n0.13\n0.68\n0.40, 1.13\n0.14\n\n\n    70+\n\n\n0.53\n0.07, 3.20\n0.5\n0.52\n0.07, 3.19\n0.5\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nCombinar con dplyr\nUna forma alternativa de combinar los resultados univariables y multivariables de glm()/tidy() es con las funciones join de dplyr.\n\nUnimos los resultados univariantes obtenidos anteriormente (univ_tab_base, que contiene los recuentos) con los resultados multivariables en formato tidy de mv_tab_base.\nUtilizamos select() para mantener sólo las columnas que queremos, especificar su orden y renombrarlas\nEmpleamos round() con dos decimales en todas las columnas que sean de tipo “Double”.\n\n\n## combine univariate and multivariable tables \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %&gt;% \n  ## choose columns and rename them\n  select( # new name =  old name\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %&gt;% \n  mutate(across(where(is.double), round, 2))   \n\n# A tibble: 20 × 11\n   characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval\n   &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          909  1168    1.28        1.18         1.4       0   \n 2 gender               916  1174    1           0.88         1.13      0.97\n 3 (Intercept)          340   436    1.28        1.11         1.48      0   \n 4 fever               1485  1906    1           0.85         1.17      0.99\n 5 (Intercept)         1472  1877    1.28        1.19         1.37      0   \n 6 chills               353   465    1.03        0.89         1.21      0.68\n 7 (Intercept)          272   309    1.14        0.97         1.34      0.13\n 8 cough               1553  2033    1.15        0.97         1.37      0.11\n 9 (Intercept)         1636  2114    1.29        1.21         1.38      0   \n10 aches                189   228    0.93        0.76         1.14      0.51\n11 (Intercept)          931  1144    1.23        1.13         1.34      0   \n12 vomit                894  1198    1.09        0.96         1.23      0.17\n13 (Intercept)          338   427    1.26        1.1          1.46      0   \n14 age_cat5-9           365   433    0.94        0.77         1.15      0.54\n15 age_cat10-14         273   396    1.15        0.93         1.42      0.2 \n16 age_cat15-19         238   299    0.99        0.8          1.24      0.96\n17 age_cat20-29         345   448    1.03        0.84         1.26      0.79\n18 age_cat30-49         228   307    1.07        0.85         1.33      0.58\n19 age_cat50-69          35    30    0.68        0.41         1.13      0.13\n20 age_cat70+             3     2    0.53        0.07         3.2       0.49\n# ℹ 4 more variables: mv_or &lt;dbl&gt;, mvv_ci_low &lt;dbl&gt;, mv_ci_high &lt;dbl&gt;,\n#   mv_pval &lt;dbl&gt;",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html#forest-plot",
    "href": "new_pages/regression.es.html#forest-plot",
    "title": "19  Regresión univariante y multivariable",
    "section": "19.5 Forest plot",
    "text": "19.5 Forest plot\nEsta sección muestra cómo producir un gráfico con los resultados de tu regresión. Hay dos opciones, puedes construir un gráfico tú mismo usando ggplot2 o usar un metapaquete llamado easystats (un paquete que incluye muchos paquetes).\nConsulta la página sobre Conceptos básicos de ggplot si no estás familiarizado con el paquete de gráficos ggplot2.\n\n\nPaquete ggplot2\nPuedes construir un gráfico de bosque con ggplot() trazando elementos de los resultados de la regresión multivariable. Añade las capas de los gráficos utilizando estos “geoms”:\n\nAñadimos estimaciones con geom_point()\nAñadimos intervalos de confianza con geom_errorbar()\nPloteamos una línea vertical en OR = 1 con geom_vline()\n\nAntes de empezar a plotear, es posible que sea necesario utilizar fct_relevel() del paquete forcats para establecer el orden de las variables/niveles en el eje y. De no establecer un orden en las variables, ggplot() podría mostrar las variables en orden alfanumérico, lo que no funcionaría bien para los valores de categoría de edad (“30” aparecería antes de “5”). Mira la página sobre Factores para más detalles.\n\n## eliminar el término de intercepción de los resultados multivariantes\nmv_tab_base %&gt;% \n  \n  # establece el orden de los niveles que aparecerán en el eje-y\n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %&gt;%\n  \n  # eliminar la fila \"intercept\" del gráfico\n  filter(term != \"(Intercept)\") %&gt;% \n  \n  ## gráfico con la variable en el eje y y la estimación (OR) en el eje-x\n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## muestra la estimación como un punto\n  geom_point() + \n  \n  ## añadir una barra de error para los intervalos de confianza\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## mostrar como línea discontinua dónde está OR = 1 como referencia\n  geom_vline(xintercept = 1, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nPaquetes easystats\nUna alternativa, si no deseas el nivel de precisión y control que proporciona ggplot2, es utilizar la combinación de paquetes easystats.\nLa función model_parameters() del paquete parameters hace el equivalente de la función tidy() del paquete broom. El paquete see acepta esos resultados y crea por defecto un forest plot, dándo como output un objeto ggplot().\n\npacman::p_load(easystats)\n\n## eliminar el término de intercepción de los resultados multivariantes\nfinal_mv_reg %&gt;% \n  model_parameters(exponentiate = TRUE) %&gt;% \n  plot()",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/regression.es.html#resources-12",
    "href": "new_pages/regression.es.html#resources-12",
    "title": "19  Regresión univariante y multivariable",
    "section": "19.6 Recursos",
    "text": "19.6 Recursos\nEl contenido de esta página se ha basado en estos recursos y viñetas:\nRegresión lineal en R\ngtsummary\nPágina de estadísticas de la UCLA\nregresión escalonada sthda",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión univariante y multivariable</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html",
    "href": "new_pages/missing_data.es.html",
    "title": "20  Valores faltantes",
    "section": "",
    "text": "20.1 Preparación",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#preparation-11",
    "href": "new_pages/missing_data.es.html#preparation-11",
    "title": "20  Valores faltantes",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de de R base Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,           # importación/exportación\n  tidyverse,     # gestión y visualización de datos\n  naniar,        # evaluación y visualización de datos faltantes\n  mice           # imputación de datos faltantes\n)\n\n##hastaqui\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpioa” (como archivo .rds). Importa tus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).\n\n# importar linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas de linelist.\n\n\n\n\n\n\n\n\nConvertir valores faltantes en la importación\nAl importar los datos, ten en cuenta los valores que deben clasificarse como faltantes. Por ejemplo, 99, 999, “Missing”, celdas en blanco (““) o celdas con un espacio vacío (” “). Puedes convertirlos en NA (la versión de R de los valores faltantes) con el comando de importación de datos. Consulta la sección de datos faltantes de la página de Importación para obtener más detalles, ya que la sintaxis exacta varía según el tipo de archivo.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#missing-values-in-r",
    "href": "new_pages/missing_data.es.html#missing-values-in-r",
    "title": "20  Valores faltantes",
    "section": "20.2 Valores faltantes en R",
    "text": "20.2 Valores faltantes en R\nA continuación, exploramos las formas en que se presenta y evalúa los datos faltantes en R, junto con algunos valores y funciones adyacentes.\n\nNA\nEn R, los valores faltantes se representan con un valor reservado (especial): NA. Ten en cuenta que se escribe sin comillas. “NA” es diferente y es sólo un valor de carácter normal (también una letra de los Beatles de la canción Hey Jude).\nTus datos pueden tener otras formas de representar la falta de información, como “99”, o “Missing”, o “Desconocido” - incluso puedes tener el valor de carácter vacío “” que parece “en blanco”, o un solo espacio ” “. Se consciente de ello y considera la posibilidad de convertirlos en NA durante la importación o durante la limpieza de datos con na_if().\nEn tu limpieza de datos, también puedes convertir en el otro sentido - cambiando todos los NA a “Missing” o similar con replace_na() o con fct_explicit_na() para los factores.\n\n\nVersiones de NA\nLa mayoría de las veces, NA representa un valor que falta y todo funciona bien. Sin embargo, en algunas circunstancias puedes encontrar la necesidad de variaciones de NA específicas para un tipo de objeto (carácter, numérico, etc.). Esto será poco frecuente, pero debes tenerlo en cuenta.\nEl escenario típico para esto es cuando se crea una nueva columna con la función dplyr case_when(). Como se describe en la página de Limpieza de datos y funciones básicas, esta función evalúa cada fila del dataframe, valora si las filas cumplen con los criterios lógicos especificados (lado derecho del código), y asigna el nuevo valor correcto (lado izquierdo del código). Importante: todos los valores del lado derecho deben ser del mismo tipo.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # Crear nueva columna \"age_year \" a partir de la columna \"age\"\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,       # si la edad se da en años, asigna el valor original\n    age_unit == \"months\" ~ age/12,    # si la edad se da en meses, se divide por 12\n    is.na(age_unit)      ~ age,       # si falta age_unit, asume años\n    TRUE                 ~ NA_real_)) # cualquier otra circunstancia, asigna valor faltante\n\nSi deseas NA en el lado derecho, es posible que tengas que especificar una de las opciones especiales de NA que se indican a continuación. Si los otros valores del lado derecho son caracteres, considera usar “Missing” en su lugar o, de lo contrario, usa NA_character_. Si todos son numéricos, utiliza NA_real_. Si todos son fechas o lógicos, puedes utilizar NA.\n\nNA - utilizar para fechas o TRUE/FALSE lógico\nNA_character_ - utilizar para caracteres\nNA_real_ - uso para numérico\n\nDe nuevo, no es probable que te encuentres con estas variaciones a menos que estés utilizando case_when() para crear una nueva columna. Consulta la documentación de R sobre NA para obtener más información.\n\n\nNULL\nNULL es otro valor reservado en R. Es la representación lógica de una declaración que no es ni verdadera ni falsa. Es devuelto por expresiones o funciones cuyos valores son indefinidos. Generalmente no asignes NULL como valor, a menos que escribas funciones o si escribes una aplicación Shiny para devolver NULL en escenarios específicos.\nLa nulidad puedes evaluarse con is.null() y la conversión puedes hacerse con as.null().\nVéase esta entrada del blog sobre la diferencia entre NULL y NA.\n\n\nNaN\nLos valores imposibles se representan con el valor especial NaN. Un ejemplo de esto es cuando se fuerza a R a dividir 0 entre 0. Puedes evaluar esto con is.nan(). También puedes encontrar funciones complementarias incluyendo is.infinite() y is.finite().\n\n\nInf\nInf representa un valor infinito, como cuando se divide un número por 0.\nComo ejemplo de cómo podría afectar esto a tu trabajo: digamos que tienes un vector/columna z que contiene estos valores: z &lt;- c(1, 22, NA, Inf, NaN, 5)\nSi deseas utilizar max() en la columna para encontrar el valor más alto, puedes utilizar el na.rm = TRUE para eliminar el NA del cálculo, pero el Inf y elNaN permanecen y se devolverá Inf. Para resolver esto, puedes utilizar los corchetes [ ] y is.finite() para subconjuntar de manera que sólo se utilicen valores finitos para el cálculo: max(z[is.finite(z)]).\n\nz &lt;- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # devuelve NA\nmax(z, na.rm=T)                  # devuelve Inf\nmax(z[is.finite(z)])             # devuelve 22\n\n\n\nEjemplos\n\n\n\n\n\n\n\nComando R\nResultado\n\n\n\n\n5 / 0\nInf\n\n\n0 / 0\nNaN\n\n\n5 / NA\nNA\n\n\n5 / Inf |0NA - 5|NAInf / 5|Infclass(NA)| \"logical\"class(NaN)| \"numeric\"class(Inf)| \"numeric\"class(NULL)`\n“NULL”\n\n\n\n“NAs introduced by coercion” es un mensaje de aviso común. Esto puede ocurrir si se intenta hacer una conversión ilegal como insertar un valor de carácter en un vector que de otra manera es numérico.\n\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))\n\nWarning: NAs introduced by coercion\n\n\n[1] 10 20 NA 40\n\n\nNULL se ignora en un vector.\n\nmy_vector &lt;- c(25, NA, 10, NULL)  # define el vector\nmy_vector                         # lo imprime\n\n[1] 25 NA 10\n\n\nLa varianza de un número da como resultado NA.\n\nvar(22)\n\n[1] NA",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#useful-functions",
    "href": "new_pages/missing_data.es.html#useful-functions",
    "title": "20  Valores faltantes",
    "section": "20.3 Funciones útiles",
    "text": "20.3 Funciones útiles\nLas siguientes funciones de R base son muy útiles a la hora de evaluar o manejar los valores faltantes:\n\nis.na() y !is.na()\nUtiliza is.na() para identificar los valores que faltan, o utiliza su opuesto (con ! delante) para identificar los valores que no faltan. Ambos devuelven un valor lógico (TRUE o FALSE). Recuerda que puedes sum() el vector resultante para contar el número de TRUE, por ejemplo, sum(is.na(linelist$date_outcome)).\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n\n!is.na(my_vector)\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\nsum(is.na(my_vector))\n\n[1] 2\n\n\n\n\nna.omit()\nEsta función, si se aplica a un dataframe, eliminará las filas con valores faltantes. También es de R base. Si se aplica a un vector, eliminará los valores NA del vector al que se aplica. Por ejemplo:\n\nna.omit(my_vector)\n\n[1]  1  4 56  5 22\nattr(,\"na.action\")\n[1] 4 6\nattr(,\"class\")\n[1] \"omit\"\n\n\n\n\ndrop_na()\nEsta es una función tidyr que es útil en un proceso de limpieza de datos. Si se ejecuta con los paréntesis vacíos, elimina las filas con valores faltantes. Si se especifican los nombres de las columnas en los paréntesis, se eliminarán las filas con valores faltantes en esas columnas. También puedes utilizar la sintaxis “tidyselect” para especificar las columnas.\n\nlinelist %&gt;% \n  drop_na(case_id, date_onset, age) # drops rows missing values for any of these columns\n\n\n\nna.rm = TRUE\nCuando se ejecuta una función matemática como max(), min(), sum() o mean(), si hay algún valor NA presente el valor devuelto será NA. Este comportamiento por defecto es intencionado, para que avise si falta algún dato.\nPuedes evitarlo eliminando los valores faltantes del cálculo. Para ello, incluye el argumento na.rm = TRUE (“na.rm” significa “eliminar NA”).\n\nmy_vector &lt;- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     \n\n[1] NA\n\nmean(my_vector, na.rm = TRUE)\n\n[1] 17.6",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#assess-missingness-in-a-data-frame",
    "href": "new_pages/missing_data.es.html#assess-missingness-in-a-data-frame",
    "title": "20  Valores faltantes",
    "section": "20.4 Evaluar la ausencia de datos en un dataframe",
    "text": "20.4 Evaluar la ausencia de datos en un dataframe\nPuedes utilizar el paquete naniar para evaluar y visualizar la falta de datos del dataframe linelist.\n\n# instala y/o carga el paquete\npacman::p_load(naniar)\n\n\nCuantificación de la ausencia de datos\nPara encontrar el porcentaje de todos los valores que faltan utiliza pct_miss(). Utiliza n_miss() para obtener el número de valores faltantes.\n\n# Porcentaje de TODOS los valores del dataframe que faltan\npct_miss(linelist)\n\n[1] 6.688745\n\n\nLas dos funciones siguientes devuelven el porcentaje de filas con algún valor ausente, o que están totalmente completas, respectivamente. Recuerda que NA significa que falta, y que \"\" o \" \" no se contarán como faltantes.\n\n# Porcentaje de filas en las que falta algún valor\npct_miss_case(linelist)   # usa n_complete() para los recuentos\n\n[1] 69.12364\n\n\n\n# Porcentaje de filas que están completas (no faltan valores) \npct_complete_case(linelist) # usa n_complete() para los recuentos\n\n[1] 30.87636\n\n\n\n\nVisualización de faltantes\nLa función gg_miss_var() mostrará el número (o el %) de valores faltantes en cada columna. Algunos matices:\n\nPuedes añadir un nombre de columna (no entre comillas) al argumento facet = para ver el gráfico por grupos\nPor defecto, se muestran los recuentos en lugar de los porcentajes, cámbialo con show_pct = TRUE\nPuedes añadir etiquetas de eje y de título como para un ggplot() normal con + labs(...)\n\n\ngg_miss_var(linelist, show_pct = TRUE)\n\n\n\n\n\n\n\n\nAquí los datos están conectados con %&gt;% en la función. El argumento facet = también se utiliza para dividir los datos.\n\nlinelist %&gt;% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n\n\n\n\n\n\n\n\nPuedes utilizar vis_miss() para visualizar el dataframe como un mapa de calor, mostrando si cada valor falta o no. También puedes select() determinadas columnas del dataframe y proporcionar sólo esas columnas a la función.\n\n# Gráfico de valores faltantes en todo el dataframe\nvis_miss(linelist)\n\n\n\n\n\n\n\n\n\n\nExplorar y visualizar las relaciones de datos faltantes\n¿Cómo se visualiza algo que no existe? Por defecto, ggplot() elimina los puntos con valores faltantes de los gráficos.\nnaniar ofrece una solución mediante geom_miss_point(). Al crear un gráfico de dispersión de dos columnas, los registros con uno de los valores ausentes y el otro valor presente se muestran estableciendo los valores ausentes en un 10% más bajo que el valor más bajo de la columna, y coloreándolos de forma distinta.\nEn el gráfico de dispersión que aparece a continuación, los puntos rojos son registros en los que el valor de una columna está presente pero falta el valor de la otra columna. Esto permite ver la distribución de los valores que faltan en relación con los valores que no faltan.\n\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\n\n\n\n\n\n\n\n\nPara evaluar la ausencia en el dataframe estratificado por otra columna, puedes utilizar gg_miss_fct(), que devuelve un mapa de calor del porcentaje de ausencia en el dataframe por una columna de factor/categoría (o fecha):\n\ngg_miss_fct(linelist, age_cat5)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat5 = (function (x) ...`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\nℹ The deprecated feature was likely used in the naniar package.\n  Please report the issue at &lt;https://github.com/njtierney/naniar/issues&gt;.\n\n\n\n\n\n\n\n\n\nEsta función también se puede utilizar con una columna de fechas para ver cómo ha cambiado la falta de datos en el tiempo:\n\ngg_miss_fct(linelist, date_onset)\n\nWarning: Removed 29 rows containing missing values or values outside the scale range\n(`geom_tile()`).\n\n\n\n\n\n\n\n\n\n\n\n“Sombra” de las columnas\nOtra forma de visualizar la ausencia de valores en una columna es mediante una segunda columna que sea como una “sombra” de esta que puede crear naniar. bind_shadow() crea una columna binaria NA/no NA para cada columna existente, y vincula todas estas nuevas columnas al conjunto de datos original con el apéndice “_NA”. Esto duplica el número de columnas - ver más abajo:\n\nshadowed_linelist &lt;- linelist %&gt;% \n  bind_shadow()\n\nnames(shadowed_linelist)\n\n [1] \"case_id\"                 \"generation\"             \n [3] \"date_infection\"          \"date_onset\"             \n [5] \"date_hospitalisation\"    \"date_outcome\"           \n [7] \"outcome\"                 \"gender\"                 \n [9] \"age\"                     \"age_unit\"               \n[11] \"age_years\"               \"age_cat\"                \n[13] \"age_cat5\"                \"hospital\"               \n[15] \"lon\"                     \"lat\"                    \n[17] \"infector\"                \"source\"                 \n[19] \"wt_kg\"                   \"ht_cm\"                  \n[21] \"ct_blood\"                \"fever\"                  \n[23] \"chills\"                  \"cough\"                  \n[25] \"aches\"                   \"vomit\"                  \n[27] \"temp\"                    \"time_admission\"         \n[29] \"bmi\"                     \"days_onset_hosp\"        \n[31] \"case_id_NA\"              \"generation_NA\"          \n[33] \"date_infection_NA\"       \"date_onset_NA\"          \n[35] \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n[37] \"outcome_NA\"              \"gender_NA\"              \n[39] \"age_NA\"                  \"age_unit_NA\"            \n[41] \"age_years_NA\"            \"age_cat_NA\"             \n[43] \"age_cat5_NA\"             \"hospital_NA\"            \n[45] \"lon_NA\"                  \"lat_NA\"                 \n[47] \"infector_NA\"             \"source_NA\"              \n[49] \"wt_kg_NA\"                \"ht_cm_NA\"               \n[51] \"ct_blood_NA\"             \"fever_NA\"               \n[53] \"chills_NA\"               \"cough_NA\"               \n[55] \"aches_NA\"                \"vomit_NA\"               \n[57] \"temp_NA\"                 \"time_admission_NA\"      \n[59] \"bmi_NA\"                  \"days_onset_hosp_NA\"     \n\n\nEstas “sombras” de las columnas pueden utilizarse para trazar la proporción de valores que faltan, por cualquier otra columna.\nPor ejemplo, el siguiente gráfico muestra la proporción de registros que carecen de days_onset_hosp (número de días desde el inicio de los síntomas hasta la hospitalización), según el valor de ese registro en date_hospitalisation. Esencialmente, se está trazando la densidad de la columna del eje x, pero estratificando los resultados (color = ) por una columna de sombra de interés. Este análisis funciona mejor si el eje-x es una columna numérica o de fecha.\n\nggplot(data = shadowed_linelist,          # dataframe con columnas sombreadas\n  mapping = aes(x = date_hospitalisation, # columna numérica o de fecha\n                colour = age_years_NA)) + # columna de sombra de interés\n  geom_density()                          # representa las curvas de densidad\n\n\n\n\n\n\n\n\nTambién puedes utilizar estas columnas “sombra” para estratificar un resumen estadístico, como se muestra a continuación:\n\nlinelist %&gt;%\n  bind_shadow() %&gt;%                # crea la columna a mostrar\n  group_by(date_outcome_NA) %&gt;%    # columna sombreada para estratificar\n  summarise(across(\n    .cols = age_years,             # variable de interés para los cálculos\n    .fns = list(\"mean\" = mean,     # estadísticas a calcular\n                \"sd\" = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # otros argumentos para los cálculos estadísticos\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `date_outcome_NA = !NA`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 2 × 6\n  date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min\n  &lt;fct&gt;                    &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 !NA                       16.0         12.6          158.             0\n2 NA                        16.2         12.9          167.             0\n# ℹ 1 more variable: age_years_max &lt;dbl&gt;\n\n\nA continuación se muestra una forma alternativa de trazar la proporción de los valores de una columna que faltan a lo largo del tiempo. No implica naniar. Este ejemplo muestra el porcentaje de observaciones semanales que faltan).\n\nAgrega los datos en una unidad de tiempo útil (días, semanas, etc.), resumiendo la proporción de observaciones con NA (y cualquier otro valor de interés)\nRepresenta la proporción que falta como una línea usando ggplot()\n\nA continuación, tomamos linelist, añadimos una nueva columna para la semana, agrupamos los datos por semana y luego calculamos el porcentaje de registros de esa semana en los que falta el valor. (Nota: si se desea el porcentaje de 7 días el cálculo sería ligeramente diferente).\n\noutcome_missing &lt;- linelist %&gt;%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %&gt;%   # crea una nueva columna semana\n  group_by(week) %&gt;%                                             # agrupa las filas por semana\n  summarise(                                                     # resume cada semana\n    n_obs = n(),                                                  # número de registros\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),        # número de registros en los que falta el valor\n    outcome_p_miss  = outcome_missing / n_obs,                    # proporción de registros en los que falta el valor\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),           # número de registros como fallecidos\n    outcome_p_dead  = outcome_dead / n_obs) %&gt;%                   # proporción de registros como fallecidos\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %&gt;%         # pivota a formato largo todas las columnas excepto semana, para ggplot\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # conserva sólo los valores de proporciones\n\nEntonces, representamos la proporción que falta como una línea, por semana. Si no estás familiarizado con el paquete de gráficas ggplot2, consulta la página de fundamentos de ggplot.\n\nggplot(data = outcome_missing)+\n    geom_line(\n      mapping = aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#using-data-with-missing-values",
    "href": "new_pages/missing_data.es.html#using-data-with-missing-values",
    "title": "20  Valores faltantes",
    "section": "20.5 Uso de datos con valores faltantes",
    "text": "20.5 Uso de datos con valores faltantes\n\nFiltrar las filas con valores faltantes\nPara eliminar rápidamente las filas con valores faltantes, utiliza la función dplyr drop_na().\nlinelist original tiene nrow(linelist) filas. El número ajustado de filas se muestra a continuación:\n\nlinelist %&gt;% \n  drop_na() %&gt;%     # elimina las filas con CUALQUIER valor faltante\n  nrow()\n\n[1] 1818\n\n\nPuedes especificar que se eliminen las filas que faltan en determinadas columnas:\n\nlinelist %&gt;% \n  drop_na(date_onset) %&gt;% # elimina las filas en las que falta date_onset  \n  nrow()\n\n[1] 5632\n\n\nPuedes listar las columnas una tras otra, o utilizar las funciones de ayuda “tidyselect”:\n\nlinelist %&gt;% \n  drop_na(contains(\"date\")) %&gt;% # elimina las filas a las que faltan valores en cualquier columna \"fecha\" \n  nrow()\n\n[1] 3029\n\n\n\n\n\nManejo de NA en ggplot()\nA menudo es conveniente informar del número de valores excluidos de un gráfico en un pie de foto. A continuación se muestra un ejemplo:\nEn ggplot(), puedes añadir labs() y dentro de él un caption =. En el pie, puedes usar str_glue() del paquete stringr para pegar los valores juntos en una frase de forma dinámica para que se ajusten a los datos. Un ejemplo es el siguiente:\n\nObserva el uso de \\n para una nueva línea.\nTen en cuenta que si varias columnas contribuyen a que los valores no se muestren (por ejemplo, la edad o el sexo si se reflejan en el gráfico), deberás filtrar también esas columnas para calcular correctamente el número no mostrado.\n\n\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  \n\nA veces, puede ser más fácil guardar la cadena como un objeto en comandos anteriores al comando ggplot(), y simplemente referenciar el objeto de cadena nombrado dentro de str_glue().\n\n\n\nNA en los factores\nSi tu columna de interés es un factor, utiliza fct_explicit_na() del paquete forcats para convertir los valores NA en un valor de carácter. Mira más detalles en la página de Factores. Por defecto, el nuevo valor es “(Missing)” pero puede ajustarse mediante el argumento na_level =.\n\npacman::p_load(forcats)   # load package\n\nlinelist &lt;- linelist %&gt;% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)\n\n[1] \"f\"       \"m\"       \"Missing\"",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#imputation",
    "href": "new_pages/missing_data.es.html#imputation",
    "title": "20  Valores faltantes",
    "section": "20.6 Imputación",
    "text": "20.6 Imputación\nA veces, al analizar los datos, será importante “rellenar los huecos” e imputar los datos que faltan Aunque siempre se puede analizar simplemente unos datos después de eliminar todos los valores que faltan, esto puede causar problemas de muchas maneras. He aquí dos ejemplos:\n\nAl eliminar todas las observaciones con valores faltantes o las variables con una gran cantidad de valores faltantes, podría reducir su potencia o la capacidad para realizar algunos tipos de análisis. Por ejemplo, como descubrimos antes, sólo una pequeña fracción de las observaciones de nuestro conjunto de datos de linelist no tiene valores faltantes en todas nuestras variables. Si elimináramos la mayor parte de nuestro conjunto de datos, perderíamos mucha información. Además, la mayoría de nuestras variables tienen una cierta cantidad de valores faltantes; para la mayoría de los análisis, probablemente no sea razonable eliminar todas las variables que tienen muchos valores faltantes.\nDependiendo de la razón por la que faltan datos, el análisis de los datos que no faltan podría conducir a resultados sesgados o engañosos. Por ejemplo, como hemos sabido antes, nos faltan datos de algunos pacientes sobre si han tenido algunos síntomas importantes como fiebre o tos. Pero, como una posibilidad, tal vez esa información no se registró para las personas que obviamente no estaban muy enfermas. En ese caso, si elimináramos estas observaciones, estaríamos excluyendo a algunas de las personas más sanas de nuestro conjunto de datos, lo que podría sesgar los resultados.\n\nEs importante pensar en la razón por la que pueden faltar datos, además de ver cuántos faltan. Esto puede ayudarte a decidir la importancia de imputar los datos que faltan, así como el método de imputación de los datos que faltan que pueda ser mejor en esa situación.\n\nTipos de datos faltantes\nA continuación se presentan tres tipos generales de datos faltantes:\n\nFalta completamente al azar (MCAR Missing Completely at Random). Esto significa que no existe ninguna relación entre la probabilidad de que falten datos y cualquiera de las otras variables de los datos. La probabilidad de que falte es la misma para todos los casos. Pero, si tienes una fuerte razón para creer que tus datos son MCAR, analizar sólo los datos no ausentes sin imputar no sesgará los resultados (aunque puede perder algo de potencia). [PENDIENTE: considerar la discusión de las pruebas estadísticas para MCAR].\nFalta al azar (MAR Missing at Random). Este nombre es, en realidad, un poco engañoso, ya que MAR significa que los datos faltan de forma sistemática y predecible en función del resto de la información que se tiene. Por ejemplo, puede que todas las observaciones de nuestro conjunto de datos con un valor ausente de fiebre no se hayan registrado porque se asumió que todos los pacientes con escalofríos y dolores tenían fiebre, por lo que nunca se les tomó la temperatura. Si es cierto, podríamos predecir fácilmente que cada observación que falta con escalofríos y dolores también tiene fiebre y utilizar esta información para imputar nuestros datos que faltan. En la práctica, esto es más bien un espectro. Quizá si un paciente tiene escalofríos y dolores, es más probable que también tenga fiebre si no se le toma la temperatura, pero no siempre. Esto sigue siendo predecible aunque no sea perfectamente predecible. Este es un tipo común de valores faltantes\nDesaparición no aleatoria (MNAR Missing not at Random). A veces, también se denomina Falta no aleatoria (NMAR). Esto supone que la probabilidad de que falte un valor NO es sistemática ni predecible utilizando el resto de la información que tenemos, pero tampoco falta al azar. En esta situación, los datos faltan por razones desconocidas o por razones de las que no se tiene ninguna información. Por ejemplo, en nuestro conjunto de datos puede faltar información sobre la edad porque algunos pacientes muy mayores no saben o se niegan a decir su edad. En esta situación, los datos que faltan sobre la edad están relacionados con el propio valor (y, por tanto, no son aleatorios) y no son predecibles en función del resto de la información que tenemos. El MNAR es complejo y, a menudo, la mejor manera de afrontarlo es intentar recopilar más datos o información sobre el motivo por el que faltan los datos en lugar de intentar imputarlos.\n\nEn general, la imputación de datos MCAR suele ser bastante sencilla, mientras que la MNAR es muy difícil, si no imposible. Muchos de los métodos comunes de imputación de datos asumen MAR.\n\n\nPaquetes útiles\nAlgunos paquetes útiles para la imputación de valores faltantes son Mmisc, missForest (que utiliza bosques aleatorios para imputar los valores faltantes) y mice (Imputación multivariada por ecuaciones encadenadas). Para esta sección sólo utilizaremos el paquete mice, que implementa una variedad de técnicas. El mantenedor del paquete mice ha publicado un libro en línea sobre la imputación Flexible de valores faltantes.\nEste es el código para cargar el paquete mice :\n\npacman::p_load(mice)\n\n\n\nImputación de la media\nA veces, si estás haciendo un análisis simple o tienes una razón de peso para pensar que puede asumir MCAR, puedes simplemente establecer los valores numéricos que faltan a la media de esa variable. Tal vez podamos asumir que las mediciones de temperatura que faltan en nuestro conjunto de datos eran MCAR o eran simplemente valores normales. Aquí está el código para crear una nueva variable que reemplaza los valores de temperatura faltantes con el valor medio de la temperatura en nuestro conjunto de datos. Sin embargo, en muchas situaciones reemplazar los datos con la media puede conducir a un sesgo, así que ten cuidado.\n\nlinelist &lt;- linelist %&gt;%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\n\nTambién puedes realizar un proceso similar para sustituir los datos categóricos por un valor específico. Para nuestro conjunto de datos, imagina que sabes que todas las observaciones con un valor faltante para tu resultado (que puede ser “Muerte” o “Recuperación”) son en realidad personas que han muerto (nota: esto no es realmente cierto para este conjunto de datos):\n\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))\n\n\n\nImputación de la regresión\nUn método algo más avanzado consiste en utilizar algún tipo de modelo estadístico para predecir cuál es el valor que falta y sustituirlo por el valor predicho. Este es un ejemplo de creación de valores predichos para todas las observaciones en las que falta la temperatura, pero no la edad ni la fiebre, mediante una simple regresión lineal que utiliza el estado de la fiebre y la edad en años como predictores. En la práctica, es conveniente utilizar un modelo mejor que este tipo de enfoque simple.\n\nsimple_temperature_model_fit &lt;- lm(temp ~ fever + age_years, data = linelist)\n\n# utilizando nuestro modelo simple de temperatura para predecir valores sólo para las observaciones en las que falta temp.\npredictions_for_missing_temps &lt;- predict(simple_temperature_model_fit,\n                                        newdata = linelist %&gt;% filter(is.na(temp))) \n\nO bien, utilizando el mismo enfoque de modelización a través del paquete mice para crear valores imputados para las observaciones de temperatura que faltan:\n\nmodel_dataset &lt;- linelist %&gt;%\n  select(temp, fever, age_years)  \n\ntemp_imputed &lt;- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)\n\nWarning: Number of logged events: 1\n\ntemp_imputed_values &lt;- temp_imputed$imp$temp\n\nEste es el mismo tipo de enfoque de algunos métodos más avanzados, como el uso del paquete missForest para sustituir los datos que faltan por valores predichos. En ese caso, el modelo de predicción es un bosque aleatorio en lugar de una regresión lineal. También se pueden utilizar otros tipos de modelos para hacer esto. Sin embargo, aunque este enfoque funciona bien con MCAR, debes tener un poco de cuidado si crees que MAR o MNAR describen con más precisión tu situación. La calidad de tu imputación dependerá de lo bueno que sea tu modelo de predicción e incluso con un modelo muy bueno la variabilidad de los datos imputados puede estar subestimada.\n\n\nLOCF y BOCF\nLa última observación trasladada (LOCF) y la observación de referencia trasladada (BOCF) son métodos de imputación para datos de series temporales/longitudinales. La idea es tomar el valor observado anterior como reemplazo de los datos que faltan. Cuando faltan varios valores sucesivamente, el método busca el último valor observado.\nLa función fill() del paquete tidyr puede utilizarse para la imputación LOCF y BOCF (sin embargo, otros paquetes como HMISC, zoo y data.table también incluyen métodos para hacerlo). Para mostrar la sintaxis de fill(), crearemos un sencillo conjunto de datos de series temporales que contenga el número de casos de una enfermedad para cada trimestre de los años 2000 y 2001. Sin embargo, falta el valor del año para los trimestres posteriores al primero, por lo que tendremos que imputarlos. La unión fill() también se demuestra en la página Pivotar datos.\n\n#crear nuestro conjunto de datos sencillo\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n#imputar los valores del año que faltan:\ndisease %&gt;% fill(year)\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nNota: asegúrate de que tus datos están correctamente ordenados antes de utilizar la función fill(). fill() rellena por defecto “hacia abajo”, pero también puedes imputar valores en diferentes direcciones cambiando el parámetro .direction. Podemos hacer unos datos similares en el que el valor del año se registra sólo al final del año y falta para los trimestres anteriores:\n\n#creando nuestro conjunto de datos ligeramente diferente\ndisease &lt;- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n#imputando los valores del año que faltan en la dirección \" up\":\ndisease %&gt;% fill(year, .direction = \"up\")\n\n# A tibble: 8 × 3\n  quarter  year cases\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Q1       2000 66013\n2 Q2       2000 69182\n3 Q3       2000 53175\n4 Q4       2000 21001\n5 Q1       2001 46036\n6 Q2       2001 58842\n7 Q3       2001 44568\n8 Q4       2001 50197\n\n\nEn este ejemplo, LOCF y BOCF son claramente lo correcto, pero en situaciones más complicadas puede ser más difícil decidir si estos métodos son apropiados. Por ejemplo, es posible que falten valores de laboratorio para un paciente del hospital después del primer día. A veces, esto puede significar que los valores de laboratorio no cambiaron… ¡pero también podría significar que el paciente se recuperó y sus valores serían muy diferentes después del primer día! Utiliza estos métodos con precaución.\n\n\nImputación múltiple\nEl libro en línea que mencionamos antes, escrito por el autor del paquete mice contiene una explicación detallada de la imputación múltiple y de los motivos por los que conviene utilizarla. Pero, aquí hay una explicación básica del método:\nCuando se realiza una imputación múltiple, se crean múltiples conjuntos de datos con los valores faltantes imputados a valores de datos plausibles (dependiendo de los datos de tu investigación, puedes querer crear más o menos de estos conjuntos de datos imputados, pero el paquete mice establece el número por defecto en 5). La diferencia es que, en lugar de un valor único y específico, cada valor imputado se extrae de una distribución estimada (por lo que incluye cierta aleatoriedad). Como resultado, cada uno de estos conjuntos de datos tendrá valores imputados ligeramente diferentes (sin embargo, los datos no ausentes serán los mismos en cada uno de estos conjuntos de datos imputados). Todavía se utiliza algún tipo de modelo predictivo para hacer la imputación en cada uno de estos nuevos conjuntos de datos (mice tiene muchas opciones para los métodos de predicción, incluyendo Predictive Mean Matching, regresión logística y random forest), pero el paquete mice puede encargarse de muchos de los detalles del modelado.\nEntonces, una vez que hayas creado estos nuevos conjuntos de datos imputados, puedes aplicar cualquier modelo estadístico o análisis que estuviera planeando hacer para cada uno de estos nuevos conjuntos de datos imputados y juntar los resultados de estos modelos. Esto funciona muy bien para reducir el sesgo tanto en MCAR como en muchas configuraciones de MAR y a menudo resulta en estimaciones de error estándar más precisas.\nHe aquí un ejemplo de aplicación del proceso de Imputación Múltiple para predecir la temperatura en nuestro conjunto de datos de linelist utilizando una edad y un estado de fiebre (nuestro conjunto de datos modelo simplificado de arriba):\n\n# imputando valores faltantes para todas las variables de nuestro model_dataset, y creando 10 nuevos conjuntos de datos imputados\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) \n\nWarning: Number of logged events: 1\n\nmodel_fit &lt;- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))\n\n         term     estimate    std.error    statistic        df       p.value\n1 (Intercept) 3.703143e+01 0.0270863456 1.367162e+03  26.83673  1.583113e-66\n2   age_years 3.867829e-05 0.0006090202 6.350905e-02 171.44363  9.494351e-01\n3    feveryes 1.978044e+00 0.0193587115 1.021785e+02 176.51325 5.666771e-159\n\n\nEn este caso, utilizamos el método de imputación por defecto de mice, que es el de Coincidencia de Medias Predictivas. A continuación, utilizamos estos conjuntos de datos imputados para estimar por separado y luego agrupar los resultados de las regresiones lineales simples en cada uno de estos conjuntos de datos. Hay muchos detalles que hemos pasado por alto y muchas configuraciones que puedes ajustar durante el proceso de Imputación Múltiple mientras utilizas el paquete mice. Por ejemplo, no siempre tendrá datos numéricos y podría necesitar utilizar otros métodos de imputación (puedes seguir utilizando el paquete mice para muchos otros tipos de datos y métodos). Pero, para un análisis más robusto cuando los datos faltantes son una preocupación significativa, la Imputación Múltiple es una buena solución que no siempre es mucho más trabajo que hacer un análisis de caso completo.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/missing_data.es.html#resources-13",
    "href": "new_pages/missing_data.es.html#resources-13",
    "title": "20  Valores faltantes",
    "section": "20.7 Recursos",
    "text": "20.7 Recursos\nViñeta sobre el paquete naniar\nGalería de visualizaciones de valores faltantes\nLibro en línea sobre imputación múltiple en R por el mantenedor del paquete mice",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Valores faltantes</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.es.html",
    "href": "new_pages/standardization.es.html",
    "title": "21  Tasas estandarizadas",
    "section": "",
    "text": "21.1 Resumen\nHay dos formas principales de estandarizar: la estandarización directa y la indirecta. Supongamos que queremos estandarizar la tasa de mortalidad por edad y sexo para el país A y el país B, y comparar las tasas estandarizadas entre estos países.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tasas estandarizadas</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.es.html#overview-1",
    "href": "new_pages/standardization.es.html#overview-1",
    "title": "21  Tasas estandarizadas",
    "section": "",
    "text": "Para la estandarización directa, tendrás que conocer el número de la población de riesgo y el número de defunciones para cada estrato de edad y sexo, para el país A y el país B. Un estrato en nuestro ejemplo podría ser el de las mujeres entre 15-44 años.\nPara la estandarización indirecta, sólo es necesario conocer el número total de defunciones y la estructura por edad y sexo de cada país. Por tanto, esta opción es factible si no se dispone de tasas de mortalidad específicas por edad y sexo o de cifras de población. La estandarización indirecta es, además, preferible en caso de números pequeños por estrato, ya que las estimaciones en la estandarización directa estarían influenciadas por una variación sustancial del muestreo.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tasas estandarizadas</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.es.html#preparation-12",
    "href": "new_pages/standardization.es.html#preparation-12",
    "title": "21  Tasas estandarizadas",
    "section": "21.2 Preparación",
    "text": "21.2 Preparación\nPara mostrar cómo se realiza la estandarización, utilizaremos recuentos ficticios de la población y de las defunciones del país A y del país B, por edad (en categorías de 5 años) y por sexo (femenino, masculino). Para que los datos estén listos para su uso, realizaremos los siguientes pasos de preparación:\n\nCargar paquetes\nCargar datos\nUnir los datos de población y mortalidad de los dos países\nPivotar largo para que haya una fila por estrato de edad y sexo\nLimpiar la población de referencia (población estándar mundial) y unirla a los datos del país\n\nEn tu caso, los datos pueden tener un formato diferente. Tal vez esos datos sean por provincia, ciudad u otra zona de captación. Puede que tengas una fila para cada defunció e información sobre la edad y el sexo de cada una (o de una proporción significativa) de estas defunciones. En este caso, consulta las páginas sobre Agrupar de datos, Pivotar de datos y Tablas descriptivas para crear unos datos con recuentos de eventos y población por estrato de edad y sexo.\nTambién necesitamos una población de referencia, la población estándar. Para los fines de este ejercicio utilizaremos la world_standard_population_by_sex. La población estándar mundial se basa en las poblaciones de 46 países y se elaboró en 1960. Hay muchas poblaciones “estándar”; por ejemplo, el sitio web del NHS de Escocia ofrece bastante información sobre la población estándar europea, la población estándar mundial y la población estándar de Escocia.\n\n\nCargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n       rio,                 # importar/exportar datos\n     here,                # localizar archivos\n     stringr,             # limpieza de caracteres y cadenas\n     frailtypack,         # necesario para dsr, para modelos frailty\n     dsr,                 # estandarizar tasas\n     PHEindicatormethods, # alternativa para la estandarización de tasas\n     tidyverse)           # gestión y visualización de datos\n\nPRECAUCIÓN: Si tienes una versión más reciente de R, el paquete dsr no puede descargarse directamente de CRAN. Sin embargo, todavía está disponible en el archivo CRAN. Puedes instalar y utilizar éste.\nPara los que no son usuarios de Mac:\n\npackageurl &lt;- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n\n\n# Otra solución que puede funcionar\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\n\nPara los usuarios de Mac:\n\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")\n\n\n\nCargar los datos de población\nConsulta la página de descargando el manual y los datos para obtener instrucciones sobre cómo descargar todos los datos de ejemplo del manual. Puedes importar los datos de la página de estandarización directamente a R desde nuestro repositorio de Github ejecutando los siguientes comandos import():\n\n# importa los datos demográficos del país A directamente de Github\nA_demo &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics.csv\")\n\n# importa las defunciones del país A directamente de Github\nA_deaths &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryA.csv\")\n\n# importa los datos demográficos del país B directamente de Github\nB_demo &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics_2.csv\")\n\n# importa las defunciones del país B directamente de Github\nB_deaths &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryB.csv\")\n\n# importa la población estándar mundial directamente de Github\nstandard_pop_data &lt;- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\nEn primer lugar, cargamos los datos demográficos (recuentos de hombres y mujeres por categoría de edad de 5 años) de los dos países que vamos a comparar, “Country A” y “Country B”.\n\n# País A\nA_demo &lt;- import(\"country_demographics.csv\")\n\n\n\n\n\n\n\n\n# País B\nB_demo &lt;- import(\"country_demographics_2.csv\")\n\n\n\n\n\n\n\n\n\nCargar datos de defunciones\nConvenientemente, también tenemos los recuentos de las defunciones durante el período de interés, por edad y sexo. Los recuentos de cada país están en un archivo separado, que se muestra a continuación.\nDefunciones en Country A\n\n\n\n\n\n\nDefunciones en Country B\n\n\n\n\n\n\n\n\nPoblaciones y defunciones limpias\nNecesitamos unir y transformar estos datos de la siguiente manera:\n\nCombinar las poblaciones de los países en un solo conjunto de datos y hacer un pivote “largo” para que cada estrato de edad y sexo sea una fila\nCombinar los recuentos de defunciones por país en un solo conjunto de datos y hacer un pivote “largo” para que cada estrato de edad y sexo sea una fila\nUnir las defunciones a las poblaciones\n\nEn primer lugar, combinamos los datos de las poblaciones de los países, los pivotamos “largo” y realizamos una pequeña limpieza. Para más detalles, consulta la página sobre pivotar datos.\n\npop_countries &lt;- A_demo %&gt;%  # comienza con el conjunto de datos del país A\n     bind_rows(B_demo) %&gt;%        # une las filas, porque las columnas tienen el mismo nombre\n     pivot_longer(                       # pivota a lo largo\n          cols = c(m, f),                   # columnas para combinar en una sola\n          names_to = \"Sex\",                 # nombre de la nueva columna que contiene la categoría (\"m\" o \"f\") \n          values_to = \"Population\") %&gt;%     # nombre de la nueva columna que contiene los valores numéricos pivotados\n     mutate(Sex = recode(Sex,            # valores recodificados para mayor claridad\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\n\nLos datos de población combinados tienen ahora este aspecto (clica para ver los países A y B):\n\n\n\n\n\n\nY ahora realizamos operaciones similares en los dos conjuntos de datos de defunciones.\n\ndeaths_countries &lt;- A_deaths %&gt;%    # comienza con el conjunto de datos de defunciones del país A\n     bind_rows(B_deaths) %&gt;%        # une las filas con el conjunto de datos B, porque las cols tienen el mismo nombre\n     pivot_longer(                  # pivota a lo largo\n          cols = c(Male, Female),        # columna a transformar en una sola\n          names_to = \"Sex\",              # nombre de la nueva columna que contiene la categoría (\"m\" o \"f\")  \n          values_to = \"Deaths\") %&gt;%      # nombre para la nueva columna que contiene los valores numéricos pivotados\n     rename(age_cat5 = AgeCat)      # renombra para mayor claridad\n\nLos datos de las defunciones tienen ahora este aspecto, y contienen datos de ambos países:\n\n\n\n\n\n\nAhora unimos los datos de defunciones y población basándonos en las columnas comunes Country, age_cat5, y Sex. Esto añade la columna Deaths.\n\ncountry_data &lt;- pop_countries %&gt;% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\n\nAhora podemos clasificar Sex, age_cat5, y Country como factores y establecer el orden de los niveles utilizando la función fct_relevel() del paquete forcats, como se describe en la página sobre Factores. Ten en cuenta que la clasificación de los niveles de los factores no cambia visiblemente los datos, pero el comando arrange() los ordena por Country, age category, y sex.\n\ncountry_data &lt;- country_data %&gt;% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %&gt;% \n          \n  arrange(Country, age_cat5, Sex)\n\n\n\n\n\n\n\nPRECAUCIÓN: Si tienes pocas defunciones por estrato, considera la posibilidad de utilizar categorías de 10 o 15 años, en lugar de categorías de 5 años para la edad.\n\n\nCarga de la población de referencia\nPor último, para la estandarización directa, importamos la población de referencia (la “población estándar” mundial por sexo)\n\n# Población de referencia\nstandard_pop_data &lt;- import(\"world_standard_population_by_sex.csv\")\n\n\n\n\n\n\n\n\n\n\nPoblación de referencia limpia\nLos valores de la categoría de edad en los dataframes country_data y standard_pop_data tendrán que estar alineados.\nActualmente, los valores de la columna age_cat5 del dataframe standard_pop_data contienen la palabra “years” y “plus”, mientras que los del dataframe country_data no. Tendremos que hacer coincidir los valores de la categoría de edad. Usamos str_replace_all() del paquete stringr, como se describe en la página sobre Caracteres y cadenas, para reemplazar estos patrones sin espacio \"\".\nAdemás, el paquete dsr espera que en la población estándar, la columna que contiene los recuentos se llame \"pop\". Así que cambiaremos el nombre de esa columna.\n\n# Elimina una cadena específica de los valores de columna\nstandard_pop_clean &lt;- standard_pop_data %&gt;%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),   # elimina \"year\"\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),    # elimina \"plus\"\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %&gt;%   # elimina \" \" space\n     \n     rename(pop = WorldStandardPopulation)   # cambia el nombre de la columna por \"pop\", ya que es lo que espera el paquete dsr\n\nPRECAUCIÓN: Si intentas utilizar str_replace_all() para eliminar un símbolo de suma, no funcionará porque es un símbolo especial. “Escapa” de los símbolos especiales poniendo dos barras invertidas delante, como en str_replace_call(columna, \"\\\\+\", \"\"). \n\n\nCrear un conjunto de datos con una población estándar\nPor último, el paquete PHEindicatormethods, que se detalla a continuación, espera que las poblaciones estándar se unan a los recuentos de eventos y poblaciones del país. Por lo tanto, crearemos un conjunto de datos all_data con ese fin.\n\nall_data &lt;- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))\n\nEste conjunto de datos completo tiene el siguiente aspecto:",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tasas estandarizadas</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.es.html#dsr-package",
    "href": "new_pages/standardization.es.html#dsr-package",
    "title": "21  Tasas estandarizadas",
    "section": "21.3 paquete dsr",
    "text": "21.3 paquete dsr\nA continuación mostramos el cálculo y la comparación de tasas estandarizadas directamente utilizando el paquete dsr. El paquete dsr permite calcular y comparar tasas estandarizadas directamente (¡no hay tasas estandarizadas indirectamente!).\nEn la sección de preparación de datos, hemos creado conjuntos de datos separados para los recuentos de países y la población estándar:\n\nel objeto country_data, que es una tabla de población con el número de habitantes y el número de defunciones por estrato por país\nel objeto standard_pop_clean, que contiene el número de población por estrato para nuestra población de referencia, la población estándar mundial\n\nUtilizaremos estos conjuntos de datos separados para el enfoque dsr.\n\n\nTasas estandarizadas\nA continuación, calculamos las tasas por país directamente estandarizadas por edad y sexo. Utilizamos la función dsr().\nCabe destacar que dsr() espera un dataframe para las poblaciones de los países y los recuentos de eventos (defunciones), y un dataframe separado con la población de referencia. También espera que en este conjunto de datos de la población de referencia el nombre de la columna de la unidad de tiempo sea “pop” (lo aseguramos en la sección de preparación de datos).\nHay muchos argumentos, como se anota en el código siguiente. En particular, el event = se establece en la columna Deaths, y fu = (“seguimiento”) con la columna Population. Establecemos los subgrupos de comparación como la columna Country y estandarizamos en base a age_cat5 y Sex. A estas dos últimas columnas no se les asigna un argumento con nombre concreto. Consulta ?dsr para obtener más detalles.\n\n# Calcula las tasas estandarizadas por el método directo por país por edad y sexo\nmortality_rate &lt;- dsr::dsr(\n     data = country_data,  # especifica el objeto que contiene el número de defunciones por estrato\n     event = Deaths,       # columna que contiene el número de defunciones por estrato \n     fu = Population,      # columna que contiene el número de habitantes por estrato\n     subgroup = Country,   # unidades que queremos comparar\n     age_cat5,             # otras columnas - las tasas se estandarizarán por éstas\n     Sex,\n     refdata = standard_pop_clean, # conjunto de datos de la población de referencia, con la columna llamada pop\n     method = \"gamma\",      # método para calcular el IC del 95%\n     sig = 0.95,            # nivel de significación\n     mp = 100000,           # queremos tasas por 100.000 habitantes\n     decimals = 2)          # número de decimales)\n\n\n# Imprimir la salida como una tabla HTML de aspecto agradable\nknitr::kable(mortality_rate) # muestra la tasa de mortalidad antes y después de la estandarización directa\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubgroup\nNumerator\nDenominator\nCrude Rate (per 1e+05)\n95% LCL (Crude)\n95% UCL (Crude)\nStd Rate (per 1e+05)\n95% LCL (Std)\n95% UCL (Std)\n\n\n\n\nA\n11344\n86790567\n13.07\n12.83\n13.31\n23.57\n23.08\n24.06\n\n\nB\n9955\n52898281\n18.82\n18.45\n19.19\n19.33\n18.46\n20.22\n\n\n\n\n\nArriba, vemos que mientras Country A tenía una tasa de mortalidad bruta más baja que Country B, ahora tiene una tasa estandarizada más alta después de la estandarización directa por edad y sexo.\n\n\n\nRazón de tasas estandarizadas\n\n# Calcular el RR\nmortality_rr &lt;- dsr::dsrr(\n     data = country_data, # específica el objeto que contiene el número de defunciones por estrato\n     event = Deaths,      # columna que contiene el número de defunciones por estrato \n     fu = Population,     # columna que contiene el número de población por estrato\n     subgroup = Country,  # unidades que queremos comparar\n     age_cat5,\n     Sex,                 # características por las que queremos estandarizar  \n     refdata = standard_pop_clean, # población de referencia, con números en la columna llamada pop\n     refgroup = \"B\",      # referencia para la comparación\n     estimate = \"ratio\",  # tipo de estimación\n     sig = 0.95,          # nivel de significación\n     mp = 100000,         # queremos tasas por 100.000 habitantes\n     decimals = 2)        # número de decimales\n\n# Imprimir tabla\nknitr::kable(mortality_rr) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Ratio (RR)\n95% LCL (RR)\n95% UCL (RR)\n\n\n\n\nA\nB\n23.57\n1.22\n1.17\n1.27\n\n\nB\nB\n19.33\n1.00\n0.94\n1.06\n\n\n\n\n\nLa tasa de mortalidad estandarizada es 1,22 veces mayor en Country A en comparación con Country B (IC del 95%: 1,17-1,27).\n\n\n\nDiferencia de tasas estandarizadas\n\n# Calcular la DR\nmortality_rd &lt;- dsr::dsrr(\n     data = country_data,       # específica el objeto que contiene el número de defunciones por estrato\n     event = Deaths,            # columna que contiene el número de defunciones por estrato \n     fu = Population,           # columna que contiene el número de población por estrato\n     subgroup = Country,        # unidades que queremos comparar\n     age_cat5,                  # características por las que queremos estandarizar\n     Sex,                        \n     refdata = standard_pop_clean, # población de referencia, con números en la columna llamada pop\n     refgroup = \"B\",            # referencia para la comparación\n     estimate = \"difference\",   # tipo de estimación\n     sig = 0.95,                # nivel de significación\n     mp = 100000,               # queremos tasas por 100.000 habitantes\n     decimals = 2)              # número de decimales\n\n# Imprimir tabla\nknitr::kable(mortality_rd) \n\n\n\n\n\n\n\n\n\n\n\n\nComparator\nReference\nStd Rate (per 1e+05)\nRate Difference (RD)\n95% LCL (RD)\n95% UCL (RD)\n\n\n\n\nA\nB\n23.57\n4.24\n3.24\n5.24\n\n\nB\nB\n19.33\n0.00\n-1.24\n1.24\n\n\n\n\n\nEl país A tiene 4,24 defunciones adicionales por cada 100.000 habitantes (IC del 95%: 3,24-5,24) en comparación con el país A.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tasas estandarizadas</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.es.html#standard_phe",
    "href": "new_pages/standardization.es.html#standard_phe",
    "title": "21  Tasas estandarizadas",
    "section": "21.4 Paquete PHEindicatormethods",
    "text": "21.4 Paquete PHEindicatormethods\nOtra forma de calcular las tasas estandarizadas es con el paquete PHEindicatormethods. Este paquete permite calcular las tasas estandarizadas tanto directa como indirectamente. Mostraremos ambos métodos.\nEn esta sección se utilizará el dataframe all_data creado al final de la sección Preparación. Este dataframe incluye las poblaciones de los países, los eventos de defunciones y la población de referencia mundial estándar. Puedes verlo aquí.\n\n\nTasas estandarizadas directamente\nA continuación, primero agrupamos los datos por país y luego los pasamos a la función phe_dsr() para obtener directamente las tasas estandarizadas por país.\nCabe destacar que la población de referencia (estándar) puede proporcionarse como una columna dentro del dataframe específico del país o como un vector separado. Si se proporciona dentro del dataframe específico del país, hay que establecer stdpoptype = \"field\". Si se proporciona como un vector, hay que establecer stdpoptype = \"vector\". En este último caso, hay que asegurarse de que el orden de las filas por estratos es similar tanto en el dataframe específico del país como en la población de referencia, ya que los registros se emparejarán por posición. En nuestro ejemplo siguiente, proporcionamos la población de referencia como una columna dentro del dataframe específico del país.\nConsulta la ayuda de ?phr_dsr o los enlaces de la sección Referencias para obtener más información.\n\n# Calcula las tasas estandarizadas por el método directo por país por edad y sexo\nmortality_ds_rate_phe &lt;- all_data %&gt;%\n     group_by(Country) %&gt;%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # columna con el número observado de sucesos\n          n = Population,             # columna con poblaciones no estándar para cada estrato\n          stdpop = pop,               # poblaciones estándar para cada estrato\n          stdpoptype = \"field\")       # cualquier \"vector\" para un vector independiente o \"filed\" significando poblaciones estándar en los datos   \n \n# Imprimir tabla\nknitr::kable(mortality_ds_rate_phe)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\ntotal_count\ntotal_pop\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\nA\n11344\n86790567\n23.56686\n23.08107\n24.05944\n95%\ndsr per 100000\nDobson\n\n\nB\n9955\n52898281\n19.32549\n18.45516\n20.20882\n95%\ndsr per 100000\nDobson\n\n\n\n\n\n\n\n\nTasas estandarizadas indirectamente\nPara la estandarización indirecta, se necesita una población de referencia con el número de defunciones y el número de población por estrato. En este ejemplo, calcularemos las tasas del país A utilizando el país B como población de referencia, ya que la población de referencia de standard_pop_clean no incluye el número de defunciones por estrato.\nA continuación, creamos primero la población de referencia del país B. Luego, pasamos los datos de mortalidad y población del país A, los combinamos con la población de referencia y los pasamos a la función calculate_ISRate(), para obtener tasas estandarizadas indirectamente. Por supuesto, también se puede hacer a la inversa.\nEn nuestro ejemplo, la población de referencia se proporciona como un dataframe separado. En este caso, nos aseguraremos que los vectores x =, n =, x_ref = y n_ref = estén ordenados por los mismos valores de categoría de normalización (estrato) que los de nuestro dataframe específico del país, ya que los registros se emparejarán por posición.\nConsulta la ayuda de ?phr_isr o los enlaces de la sección Referencias para obtener más información.\n\n# Crear población de referencia\nrefpopCountryB &lt;- country_data %&gt;% \n  filter(Country == \"B\") \n\n# Calcular las tasas del país A estandarizadas indirectamente por edad y sexo\nmortality_is_rate_phe_A &lt;- country_data %&gt;%\n     filter(Country == \"A\") %&gt;%\n     PHEindicatormethods::calculate_ISRate(\n          x = Deaths,                 # columna con el número observado de sucesos\n          n = Population,             # columna con población no estándar para cada estrato\n          x_ref = refpopCountryB$Deaths,  # número de defunciones de referencia para cada estrato\n          n_ref = refpopCountryB$Population)  # población de referencia para cada estrato\n\n# Imprimir tabla\nknitr::kable(mortality_is_rate_phe_A)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nobserved\nexpected\nref_rate\nvalue\nlowercl\nuppercl\nconfidence\nstatistic\nmethod\n\n\n\n\n11344\n15847.42\n18.81914\n13.47123\n13.22446\n13.72145\n95%\nindirectly standardised rate per 100000\nByars",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tasas estandarizadas</span>"
    ]
  },
  {
    "objectID": "new_pages/standardization.es.html#resources-14",
    "href": "new_pages/standardization.es.html#resources-14",
    "title": "21  Tasas estandarizadas",
    "section": "21.5 Recursos",
    "text": "21.5 Recursos\nSi deseas ver otro ejemplo reproducible utilizando dsr, consulta esta viñeta\nSi deseas ver otro ejemplo en el que se utilizan los métodos de PHEindicator, visita este sitio web\nVer el archivo pdf de referencia de PHEindicatormethods",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Tasas estandarizadas</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.es.html",
    "href": "new_pages/moving_average.es.html",
    "title": "22  Medias Móviles",
    "section": "",
    "text": "22.1 Preparación",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Medias Móviles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.es.html#preparation-13",
    "href": "new_pages/moving_average.es.html#preparation-13",
    "title": "22  Medias Móviles",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  tidyverse,      # para la gestión de datos y viz\n  slider,         # para calcular medias móviles\n  tidyquant       # para calcular medias móviles dentro de ggplot\n)\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).\n\n# importar linelist\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Medias Móviles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.es.html#calculate-with-slider",
    "href": "new_pages/moving_average.es.html#calculate-with-slider",
    "title": "22  Medias Móviles",
    "section": "22.2 Calcular con slider",
    "text": "22.2 Calcular con slider\nUtiliza este enfoque para calcular una media móvil en un dataframe antes de representarla\nEl paquete slider proporciona varias funciones de “ventana deslizante” para calcular medias móviles, sumas acumulativas, regresiones móviles, etc. Trata un dataframe como un vector de filas, permitiendo la iteración por filas sobre un dataframe.\nEstas son algunas de las funciones más comunes:\n\nslide_dbl() - itera a través de una columna numérica (de ahí “_dbl”) realizando una operación mediante una ventana deslizante\n\nslide_sum() - función abreviada de suma móvil para slide_dbl()\nslide_mean() - función abreviada de media móvil para slide_dbl()\n\nslide_index_dbl() - aplica la ventana móvil en una columna numérica utilizando una columna separada para indexar la progresión de la ventana (útil si se rueda por fecha con algunas fechas ausentes)\n\nslide_index_sum() - Función abreviada de suma móvil con indexación\nslide_index_mean() - Función de acceso directo a la media móvil con indexación\n\n\nEl paquete slider tiene muchas otras funciones que se tratan en la sección de Recursos de esta página. Tocamos brevemente las más comunes.\nArgumentos básicos\n\n.x, el primer argumento por defecto, es el vector sobre el que iterar y al que aplicar la función\n.i = para las versiones de “índice” de las funciones de deslizamiento - proporciona una columna para “indexar” el rollo (véase la sección siguiente)\n.f = , el segundo argumento por defecto, bien:\n\nUna función, escrita sin paréntesis, como mean, o\nUna fórmula, que se convertirá en una función. Por ejemplo ~ .x - mean(.x) devolverá el resultado del valor actual menos la media del valor de la ventana\n\nPara más detalles, consulta este material de referencia\n\nTamaño de la ventana\nEspecifica el tamaño de la ventana utilizando los argumentos .before, .after, o ambos:\n\n.before = - Proporcionar un número entero\n.after =- Proporcionar un número entero\n.complete =- Pon este valor a TRUE si sólo quieres que se realicen cálculos en ventanas completas\n\nPor ejemplo, para conseguir una ventana de 7 días que incluya el valor actual y los seis anteriores, utiliza .before = 6. Para conseguir una ventana “centrada” proporciona el mismo número tanto a .before = como a .after =.\nPor defecto, .complete = será FALSE por lo que si la ventana completa de filas no existe, las funciones utilizarán las filas disponibles para realizar el cálculo. Si se ajusta a TRUE, los cálculos sólo se realizan en ventanas completas.\nVentana expansiva\nPara lograr operaciones acumulativas, establece el argumento .before = en Inf. Esto realizará la operación sobre el valor actual y todos los que vengan antes.\n\nBalancear por fecha\nEl caso más probable de uso de un cálculo rotativo en epidemiología aplicada es examinar una medida a lo largo del tiempo. Por ejemplo, una medición continua de la incidencia de casos, basada en el recuento diario de casos.\nSi tienes datos de series temporales limpios con valores para cada fecha, puede estar bien utilizar slide_dbl(), como se demuestra aquí en la página de series temporales y detección de brotes.\nSin embargo, en muchas circunstancias de epidemiología aplicada puede haber fechas ausentes en los datos, donde no hay eventos registrados. En estos casos, es mejor utilizar las versiones “index” de las funciones slider.\n\n\nDatos indexados\nA continuación, mostramos un ejemplo utilizando slide_index_dbl() en la lista de casos. Digamos que nuestro objetivo es calcular una incidencia acumulada de 7 días - la suma de casos utilizando una ventana móvil de 7 días. Si estás buscando un ejemplo de media móvil, mira la sección de abajo sobre balanceo agrupado.\nPara empezar, se crean los datos daily_counts para reflejar los recuentos diarios de casos de linelist, calculados con count() de dplyr.\n\n# crea un conjunto de datos de recuentos diarios\ndaily_counts &lt;- linelist %&gt;% \n  count(date_hospitalisation, name = \"new_cases\")\n\nAquí está el dataframe daily_counts - hay nrow(daily_counts) filas, cada día está representado por una fila, pero especialmente al principio de la epidemia algunos días no están presentes (no hubo casos admitidos en esos días).\n\n\n\n\n\n\nEs crucial reconocer que una función estándar de balanceo (como slide_dbl() utilizaría una ventana de 7 filas, no de 7 días. Por lo tanto, si hay fechas ausentes, ¡algunas ventanas se extenderán realmente más de 7 días naturales!\nSe puede conseguir una ventana móvil “inteligente” con slide_index_dbl(). El “índex” significa que la función utiliza una columna independiente como “index” para la ventana móvil. La ventana no se basa simplemente en las filas del dataframe.\nSi la columna índex es una fecha, tienes la posibilidad añadida de especificar la extensión de la ventana a .before = y/o .after = en unidades de days() o months() de lubridate. Si haces estas cosas, la función incluirá los días ausentes en las ventanas como si estuvieran allí (como valores NA).\nMostremos una comparación. A continuación, calculamos la incidencia móvil de casos de 7 días con ventanas regulares e indexadas.\n\nrolling &lt;- daily_counts %&gt;% \n  mutate(                                # crea columnas nuevas\n    # usando slide_dbl()\n    ####################\n    reg_7day = slide_dbl(\n      new_cases,                         # calcula sobre new_cases\n      .f = ~sum(.x, na.rm = T),          # la función es sum() con los valores faltantes eliminados\n      .before = 6),                      # la ventana es la FILA y 6 FILAS anteriores\n    \n    # Usando slide_index_dbl()\n    ##########################\n    indexed_7day = slide_index_dbl(\n        new_cases,                       # calcula sobre new_cases\n        .i = date_hospitalisation,       # indexado con date_onset \n        .f = ~sum(.x, na.rm = TRUE),     # la función es sum() con los valores faltantes eliminados\n        .before = days(6))               # la ventana es el DÍA y los 6 DÍAS anteriores\n    )\n\nFíjate cómo en la columna normal de las 7 primeras filas el recuento aumenta constantemente a pesar de que las filas no tienen 7 días de diferencia. La columna adyacente “indexada” tiene en cuenta estos días naturales ausentes, por lo que la suma de 7 días son mucho menores, al menos en este periodo de la epidemia en el que los casos están más alejados.\n\n\n\n\n\n\nAhora puede trazar estos datos utilizando ggplot():\n\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBalanceando por grupo\nSi agrupas los datos antes de utilizar una función slider, las ventanas deslizantes se aplicarán por grupo. Ten cuidado de organizar las filas en el orden deseado por grupo.\nCada vez que se inicia un nuevo grupo, la ventana deslizante se reinicia. Por lo tanto, un matiz a tener en cuenta es que si tus datos están agrupados y has establecido .complete = TRUE, tendrás valores vacíos en cada transición entre grupos. A medida que la función se desplaza hacia abajo a través de las filas, cada transición en la columna de agrupación reiniciará la acumulación del tamaño mínimo de la ventana para permitir un cálculo.\nConsulta la página del manual sobre Agrupar datos para obtener detalles sobre la agrupación de datos.\nA continuación, contamos los casos del listado por fecha y por hospital. Luego ordenamos las filas en orden ascendente, primero ordenando por hospital y luego dentro de éste por fecha. A continuación establecemos group_by(). Entonces podemos crear nuestra nueva media móvil.\n\ngrouped_roll &lt;- linelist %&gt;%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %&gt;% \n\n  arrange(hospital, date_hospitalisation) %&gt;%   # ordena las filas por hospital y luego por fecha\n  \n  group_by(hospital) %&gt;%              # agrupa por hospital \n    \n  mutate(                             # media móvil   \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases,                 # recuento de casos por hospitalización-día\n      .i = date_hospitalisation,      # índice de la fecha de ingreso\n      .f = mean,                      # utiliza mean()                   \n      .before = days(6)               # utiliza el día y los 6 días anteriores\n      )\n  )\n\nAquí está el nuevo conjunto de datos:\n\n\n\n\n\n\nAhora podemos trazar las medias móviles, mostrando los datos por grupo especificando ~ hospital a facet_wrap() en ggplot(). Para divertirnos, trazamos dos geometrías: una geom_col() que muestra los recuentos de casos diarios y una geom_line() que muestra la media móvil de 7 días.\n\nggplot(data = grouped_roll)+\n  geom_col(                       # traza los recuentos diarios de casos como barras grises\n    mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(                      # trazar la media móvil como línea coloreada por hospital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # crea mini-gráficos por hospital\n  theme_classic()+                 # se simplifica el fondo   \n  theme(legend.position = \"none\")+ # se elimina la leyenda\n  labs(                            # añade etiquetas a los gráficos\n    title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")\n\n\n\n\n\n\n\n\nPELIGRO: Si obtienes un error que dice “slide() was deprecated in tsibble 0.9.0 and is now defunct. Please use slider::slide() instead.”, significa que la función slide() del paquete tsibble está enmascarando la función slide() del paquete slider. Soluciona esto especificando el paquete en el comando, como slider::slide_dbl().",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Medias Móviles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.es.html#calcular-con-tidyquant-dentro-de-ggplot",
    "href": "new_pages/moving_average.es.html#calcular-con-tidyquant-dentro-de-ggplot",
    "title": "22  Medias Móviles",
    "section": "22.3 Calcular con tidyquant dentro de ggplot()",
    "text": "22.3 Calcular con tidyquant dentro de ggplot()\nEl paquete tidyquant ofrece otro enfoque para calcular las medias móviles, esta vez dentro del comando ggplot().\nBajo linelist, los datos se cuentan por fecha de inicio, y esto se traza como una línea descolorida (alpha &lt; 1). Encima hay una línea creada con geom_ma() del paquete tidyquant, con una ventana de 7 días (n = 7) con el color y el grosor especificados.\nPor defecto geom_ma() utiliza una media móvil simple (ma_fun = \"SMA\"), pero se pueden especificar otros tipos, como:\n\n“EMA” - media móvil exponencial (más peso a las observaciones recientes)\n“WMA” - media móvil ponderada (los wts se utilizan para ponderar las observaciones en la media móvil)\nOtros se pueden encontrar en la documentación de la función\n\n\nlinelist %&gt;% \n  count(date_onset) %&gt;%                 # recuento de casos por día\n  drop_na(date_onset) %&gt;%               # eliminar casos sin fecha de inicio\n  ggplot(aes(x = date_onset, y = n))+   # inicia ggplot\n    geom_line(                          # traza los valores crudos\n      size = 1,\n      alpha = 0.2                       # línea semitransparente\n      )+             \n    tidyquant::geom_ma(                 # representa la media móvil\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # fondo sencillo\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n\nConsulta esta viñeta para obtener más detalles sobre las opciones disponibles en tidyquant.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Medias Móviles</span>"
    ]
  },
  {
    "objectID": "new_pages/moving_average.es.html#resources-15",
    "href": "new_pages/moving_average.es.html#resources-15",
    "title": "22  Medias Móviles",
    "section": "22.4 Recursos",
    "text": "22.4 Recursos\nConsulta la útil viñeta en línea del paquete slider\nLa página github del slider\nUna viñeta slider\nviñeta tidyquant\nSi tu caso de uso requiere que te “saltes” los fines de semana e incluso los días festivos, puede que te guste el paquete almanac.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Medias Móviles</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html",
    "href": "new_pages/time_series.es.html",
    "title": "23  Series temporales y detección de brotes",
    "section": "",
    "text": "23.1 Resumen\nEsta página muestra el uso de varios paquetes para el análisis de series temporales. Principalmente se basa en paquetes de la familia tidyverts, pero también utilizará el paquete de RECON trending para ajustar modelos más apropiados para la epidemiología de enfermedades infecciosas.\nTen en cuenta que en el siguiente ejemplo utilizamos unos datos del paquete surveillance sobre Campylobacter en Alemania (véase el capítulo Descargando el manual y los datoss del manual para más detalles). Sin embargo, si deseas ejecutar el mismo código en unos datos con múltiples países u otros estratos, hay una plantilla de código de ejemplo para esto en el repo de github de r4epis.\nLos temas que se tratan son:",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#overview-2",
    "href": "new_pages/time_series.es.html#overview-2",
    "title": "23  Series temporales y detección de brotes",
    "section": "",
    "text": "Datos de series temporales\nAnálisis descriptivo\nAjuste de regresiones\nRelación de dos series temporales\nDetección de brotes\nSeries temporales interrumpidas",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#preparation-14",
    "href": "new_pages/time_series.es.html#preparation-14",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.2 Preparación",
    "text": "23.2 Preparación\n\nPaquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También se pueden cargar paquetes con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(rio,          # Importación de fichero\n               here,         # Localizador de archivos\n               tidyverse,    # gestión de datos + gráficos ggplot2\n               tsibble,      # manejar conjuntos de datos de series temporales \n               slider,       # para calcular medias móviles\n               imputeTS,     # para rellenar valores perdidos\n               feasts,       # para descomposición de series temporales y autocorrelación\n               forecast,     # ajustar los términos sin y cosin a los datos (nota: debe cargarse después de feasts)\n               trending,     # ajustar y evaluar modelos \n               tmaptools,    # para obtener geocoordenadas (lon/lat) basadas en nombres de lugares\n               ecmwfr,       # para interactuar con copernicus sateliate CDS API\n               stars,        # para leer archivos .nc (datos climáticos)\n               units,        # para definir unidades de medida (datos climáticos)\n               yardstick,    # para ver la precisión del modelo\n               surveillance  # para detectar aberraciones\n               )\n\n\n\nCargar datos\nPuedes descargar todos los datos utilizados en este manual mediante las instrucciones de la página de descargando el manual y los datos.\nLos datos de ejemplo utilizado en esta sección son los recuentos semanales de casos de campylobacter notificados en Alemania entre 2001 y 2011. Puedes clicar aquí para descargar este archivo de datos (.xlsx).\nEste conjunto de datos es una versión reducida de los datos disponibles en el paquete surveillance. (para más detalles, carga el paquete surveillance y consulta ?campyDE)\nImporta estos datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).\n\n# importar los recuentos a R\ncounts &lt;- rio::import(\"campylobacter_germany.xlsx\")\n\nA continuación se muestran las 10 primeras filas de los recuentos.\n\n\n\n\n\n\n\n\nLimpiar datos\nEl código siguiente se asegura de que la columna de la fecha tenga el formato adecuado. Para esta sección utilizaremos el paquete tsibble y la función yearweek se utilizará para crear una variable de semana de calendario. Hay otras maneras de hacer esto (ver la página de Trabajar con fechas para más detalles), sin embargo para las series temporales es mejor mantenerse dentro de un marco (tsibble).\n\n## asegura que la columna de fecha tiene el formato apropiado\ncounts$date &lt;- as.Date(counts$date)\n\n## crea una variable de semana calendario \n## ajusta las definiciones ISO de las semanas que empiezan en lunes\ncounts &lt;- counts %&gt;% \n     mutate(epiweek = yearweek(date, week_start = 1))\n\n\n\nDescargar datos climáticos\nEn la sección de relación de dos series temporales, compararemos los recuentos de casos de campylobacter con los datos climáticos.\nLos datos climáticos de cualquier parte del mundo pueden descargarse del satélite Copérnico de la UE. No se trata de mediciones exactas, sino que se basan en un modelo (similar a la interpolación), pero la ventaja es la cobertura horaria global, así como las previsiones.\nPuedes descargar cada uno de estos archivos de datos climáticos en la página descargando el manual y los datos.\nPara propósitos de demostración aquí, mostraremos el código R para usar el paquete ecmwfr para extraer estos datos del almacén de datos climáticos de Copernicus. Es necesario crear una cuenta gratuita para que esto funcione. El sitio web del paquete tiene una guía útil de cómo hacerlo. A continuación se muestra un código de ejemplo de cómo hacer esto, una vez que tienes las claves de la API adecuada. Tienes que sustituir las X de abajo por los ID de tu cuenta. Tendrás que descargar un año de datos a la vez, de lo contrario el servidor se queda sin tiempo.\nSi no estás seguro de las coordenadas de un lugar del que quieres descargar datos, puedes utilizar el paquete tmaptools para obtener las coordenadas de OpenStreetMaps. Una opción alternativa es el paquete photon, aunque todavía no se ha publicado en CRAN; lo bueno de photon es que proporciona más datos contextuales para cuando hay varias coincidencias en la búsqueda.\n\nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## ejecútalo para cada año de interés (de lo contrario, el servidor dejará de funcionar)\nfor (i in 2002:2011) {\n  \n  ## descargarlos preparando una consulta \n  ## ver aquí cómo hacerlo: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## cambia la consulta a una lista usando el botón addin de arriba (python to list)\n  ## ¡¡¡El objetivo es el nombre del fichero de salida!!!\n  request &lt;- request &lt;- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## descargar el archivo y almacenarlo en el directorio de trabajo actual\n  file &lt;- wf_request(user     = \"XXXXX\",  # ID de usuario (para autenticación)\n                     request  = request,  # la petición\n                     transfer = TRUE,     # descargar el archivo\n                     path     = here::here(\"data\", \"Weather\")) ## ruta para guardar los datos\n  }\n\n\n\nCargar datos climáticos\nTanto si has descargado los datos climáticos a través de nuestro manual, como si has utilizado el código anterior, ahora deberías tener 10 años de archivos de datos climáticos “.nc” almacenados en la misma carpeta de tu ordenador.\nUtiliza el siguiente código para importar estos archivos en R con el paquete stars.\n\n## definir ruta a carpeta del tiempo \nfile_paths &lt;- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # sustituir por la ruta de archivo propia\n  full.names = TRUE)\n\n## mantener sólo los que tienen el nombre actual de interés\nfile_paths &lt;- file_paths[str_detect(file_paths, \"germany\")]\n\n## leer todos los ficheros como un objeto stars \ndata &lt;- stars::read_stars(file_paths)\n\nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \nt2m, tp, \n\n\nUna vez importados estos archivos como datos del objeto, los convertiremos en un dataframe.\n\n## cambiar a un dataframe \ntemp_data &lt;- as_tibble(data) %&gt;% \n  ## añadir variables y corregir unidades\n  mutate(\n    ## crear una variable de calendario de semana actual \n    epiweek = tsibble::yearweek(time), \n    ## crear una variable de fecha (inicio de la semana de calendario)\n    date = as.Date(epiweek),\n    ## cambiar la temperatura de kelvin a celsius\n    t2m = set_units(t2m, celsius), \n    ## cambiar la precipitación de metros a milímetros \n    tp  = set_units(tp, mm)) %&gt;% \n  ## agrupar por semanas (aunque también se mantiene la fecha)\n  group_by(epiweek, date) %&gt;% \n  ## obtener la media por semana\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))\n\n`summarise()` has grouped output by 'epiweek'. You can override using the\n`.groups` argument.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#time-series-data",
    "href": "new_pages/time_series.es.html#time-series-data",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.3 Datos de series temporales",
    "text": "23.3 Datos de series temporales\nExisten varios paquetes para estructurar y manejar los datos de las series temporales. Como ya hemos dicho, nos centraremos en la familia de paquetes tidyverts y, por tanto, utilizaremos el paquete tsibble para definir nuestro objeto de serie temporal. Tener unos datos definidos como objeto de serie temporal significa que es mucho más fácil estructurar nuestro análisis.\nPara ello utilizamos la función tsibble() y especificamos el “índex”, es decir, la variable que especifica la unidad de tiempo de interés. En nuestro caso se trata de la variable epiweek.\nSi tuviéramos unos datos con recuentos semanales por provincia, por ejemplo, también podríamos especificar la variable de agrupación utilizando el argumento key =. Esto nos permitiría hacer un análisis para cada grupo.\n\n## definir el objeto de serie temporal\ncounts &lt;- tsibble(counts, index = epiweek)\n\nSi observamos el tipo class(counts), veremos que, además de ser un dataframe ordenado (“tbl_df”, “tbl”, “data.frame”), tiene las propiedades adicionales de un dataframe de series temporales (“tbl_ts”).\nSe puede echar un vistazo rápido a los datos utilizando ggplot2. En el gráfico vemos que hay un claro patrón estacional y que no hay pérdidas. Sin embargo, parece haber un problema con la notificación al principio de cada año; los casos descienden en la última semana del año y luego aumentan en la primera semana del año siguiente.\n\n## trazar un gráfico lineal de casos por semana\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()\n\n\n\n\n\n\n\n\nPELIGRO: La mayoría de los conjuntos de datos no están tan limpios como este ejemplo. Tendrás que comprobar si hay duplicados y faltas como se indica a continuación.\n\n\nDuplicados\ntsibble no permite observaciones duplicadas. Así que cada fila deberá ser única, o única dentro del grupo (variable key). El paquete tiene algunas funciones que ayudan a identificar los duplicados. Entre ellas se encuentran are_duplicated(), que proporciona un vector TRUE/FALSE para saber si la fila es un duplicado, y duplicates(), que proporciona un dataframe de las filas duplicadas.\nConsulta la página sobre De-duplicación para obtener más detalles sobre cómo seleccionar las filas que desees.\n\n## obtener un vector de TRUE/FALSE si las filas están duplicadas\nare_duplicated(counts, index = epiweek) \n\n## obtener un data frame de filas duplicadas \nduplicates(counts, index = epiweek) \n\n\n\n\nValores faltantes\nEn nuestra breve inspección anterior hemos visto que no hay faltas, pero también hemos visto que parece haber un problema de retraso en la notificación en torno al año nuevo. Una forma de abordar este problema podría ser establecer estos valores como faltantes y luego imputar los valores. La forma más sencilla de imputación de series temporales consiste en trazar una línea recta entre el último valor no faltante y el siguiente valor no faltante. Para ello, utilizaremos la función na_interpolation() del paquete imputeTS.\nConsulta la página de datos faltantes para conocer otras opciones de imputación.\nOtra alternativa sería calcular una media móvil para intentar suavizar estos aparentes problemas de información (véase la siguiente sección y la página sobre medias móviles.\n\n## crear una variable con los faltantes en lugar de las semanas con problemas de información\ncounts &lt;- counts %&gt;% \n     mutate(case_miss = if_else(\n          ## si epiweek contiene 52, 53, 1 ó 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## entonces se establece como missing \n          NA_real_, \n          ## de lo contrario, mantiene el valor por si acaso\n          case\n     ))\n\n## alternativamente interpola los faltantes por tendencia lineal \n## entre dos puntos adyacentes más cercanos\ncounts &lt;- counts %&gt;% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## para comprobar qué valores se han imputado en comparación con el original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## hacer un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic()",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#descriptive-analysis",
    "href": "new_pages/time_series.es.html#descriptive-analysis",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.4 Análisis descriptivo",
    "text": "23.4 Análisis descriptivo\n\n\nMedias móviles\nSi los datos tienen mucho ruido (los recuentos suben y bajan), puede ser útil calcular una media móvil. En el ejemplo siguiente, para cada semana se calcula la media de casos de las cuatro semanas anteriores. Esto suaviza los datos para hacerlos más interpretables. En nuestro caso esto no aporta mucho, así que nos quedaremos con los datos interpolados para el análisis posterior. Véase la página de medias móviles para más detalles.\n\n## crear una variable de media móvil (se ocupa de las pérdidas)\ncounts &lt;- counts %&gt;% \n     ## crear la variable ma_4w \n     ## desplazar sobre cada fila de la variable de caso\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## para cada fila calcula el nombre\n                               ~ mean(.x, na.rm = TRUE),\n                               ## utiliza las cuatro semanas anteriores\n                               .before = 4))\n                               \n## hacer una visualización rápida de la diferencia \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nPeriodicidad\nA continuación definimos una función personalizada para crear un periodograma. Consulta la página Escribir funciones para obtener información sobre cómo escribir funciones en R.\nEn primer lugar, se define la función. Sus argumentos incluyen unos datos con las columnas counts, start_week = que es la primera semana de los datos, un número para indicar cuántos períodos por año (por ejemplo, 52, 12) y, por último, el estilo de salida (véanse los detalles en el código siguiente).\n\n## Argumentos de la función\n###########################\n## x es un conjunto de datos\n## counts es una variable con datos de recuento o tasas dentro de x  \n## start_week es la primera semana del conjunto de datos\n## period es el número de unidades en un año \n## output es si quiere devolver el periodograma espectral o las semanas de pico\n  ## \"periodogram\" o \"weeks\"\n\n# Define la función\nperiodogram &lt;- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## asegurarse de que no es un tsibble, filtrar al proyecto y mantener sólo las columnas de interés\n    prepare_data &lt;- dplyr::as_tibble(x)\n    \n    # prepare_data &lt;- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data &lt;- dplyr::select(prepare_data, {{counts}})\n    \n    ## crear una serie temporal intermedia \"zoo\" para poder utilizarla con spec.pgram\n    zoo_cases &lt;- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## obtener un periodograma espectral sin utilizar la transformada rápida de fourier \n    periodo &lt;- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## devuelve las semanas de pico\n    periodo_weeks &lt;- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## obtener el periodograma espectral para extraer las semanas con las frecuencias más altas \n## (comprobación de la estacionalidad) \nperiodo &lt;- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## extraer el espectro y la frecuencia en un dataframe para graficarlo\nperiodo &lt;- data.frame(periodo$freq, periodo$spec)\n\n## trazar un periodograma que muestre la periodicidad más frecuente \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n\n\n\n\n\n\n\n## obtener un vector semanas en orden ascendente \npeak_weeks &lt;- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")\n\nNOTA: Es posible utilizar las semanas anteriores para añadirlas a los términos del seno y del coseno, sin embargo, utilizaremos una función para generar estos términos (véase la sección de regresión más adelante) \n\n\n\nDescomposición\nLa descomposición clásica se utiliza para desglosar una serie temporal en varias partes, que en conjunto conforman el patrón que se observa. Estas diferentes partes son:\n\nLa tendencia-ciclo (la dirección a largo plazo de los datos)\nLa estacionalidad (patrones repetitivos)\nEl azar (lo que queda después de quitar la tendencia y la estacionalidad)\n\n\n## descomponer el conjunto de datos de recuentos \ncounts %&gt;% \n  # utilizando un modelo de descomposición clásica aditiva\n  model(classical_decomposition(case_int, type = \"additive\")) %&gt;% \n  ## extraemos la información importante del modelo\n  components() %&gt;% \n## genera un gráfico \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelación\nLa autocorrelación informa de la relación entre los recuentos de cada semana y las semanas anteriores (denominadas retrasos o retardos).\nUtilizando la función ACF(), podemos producir un gráfico que nos muestre un número de líneas para la relación en diferentes retrasos. Cuando el retardo es 0 (x = 0), esta línea sería siempre 1, ya que muestra la relación entre una observación y ella misma (no se muestra aquí). La primera línea mostrada aquí (x = 1) muestra la relación entre cada observación y la observación anterior (retardo de 1), la segunda muestra la relación entre cada observación y la observación anterior (retardo de 2) y así sucesivamente hasta el retardo de 52 que muestra la relación entre cada observación y la observación de 1 año (52 semanas antes).\nEl uso de la función PACF() (para la autocorrelación parcial) muestra el mismo tipo de relación pero ajustada para todas las demás semanas intermedias. Esto es menos informativo para determinar la periodicidad.\n\n## utilizando el conjunto de datos de recuentos\ncounts %&gt;% \n  ## calcula la autocorrelación utilizando retardos de un año completo\n  ACF(case_int, lag_max = 52) %&gt;% \n  ## muestra un gráfico\n  autoplot()\n\n\n\n\n\n\n\n## utilizando el conjunto de datos de recuentos\ncounts %&gt;% \n  ## calcular la autocorrelación parcial utilizando los retardos de un año completo\n  PACF(case_int, lag_max = 52) %&gt;% \n  ## muestra un gráfico\n  autoplot()\n\n\n\n\n\n\n\n\nPuedes probar formalmente la hipótesis nula de independencia en una serie temporal (es decir, que no está autocorrelacionada) utilizando la prueba de Ljung-Box (en el paquete stats). Un valor-p significativo sugiere que hay autocorrelación en los datos.\n\n## prueba de independencia \nBox.test(counts$case_int, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  counts$case_int\nX-squared = 462.65, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#fitting-regressions",
    "href": "new_pages/time_series.es.html#fitting-regressions",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.5 Ajuste de regresiones",
    "text": "23.5 Ajuste de regresiones\nEs posible ajustar un gran número de regresiones diferentes a una serie temporal, sin embargo, aquí mostraremos cómo ajustar una regresión binomial negativa, ya que suele ser la más apropiada para los datos de recuento en las enfermedades infecciosas.\n\n\nTérminos de Fourier\nLos términos de Fourier son el equivalente a las curvas seno y coseno. La diferencia es que éstos se ajustan basándose en la búsqueda de la combinación de curvas más adecuada para explicar los datos.\nSi sólo se ajusta un término de fourier, esto equivaldría a ajustar un seno y un coseno para el desfase más frecuente que se ve en el periodograma (en nuestro caso, 52 semanas). Utilizamos la función fourier() del paquete forecast.\nEn el código de abajo asignamos usando el $, ya que fourier() devuelve dos columnas (una para seno y otra para el coseno) y así se añaden al conjunto de datos como una lista, llamada “fourier” - pero esta lista se puede usar como una variable normal en la regresión.\n\n## añade los términos de fourier usando las variabless epiweek y case_int\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  fourier(K = 1)\n\n\n\n\nBinomial negativa\nEs posible ajustar las regresiones utilizando las funciones básicas de stats o MASS (por ejemplo, lm(), glm() y glm.nb()). Sin embargo, utilizaremos las del paquete trending, ya que esto permite calcular intervalos de confianza y predicción adecuados (que de otro modo no están disponibles). La sintaxis es la misma, y se especifica una variable de resultado, luego una tilde (~) y luego se añaden las diversas variables de exposición de interés separadas por un signo más (+).\nLa otra diferencia es que primero definimos el modelo y luego lo ajustamos a los datos (fit()). Esto es útil porque permite comparar varios modelos diferentes con la misma sintaxis.\nSUGERENCIA: Si deseas utilizar tasas, en lugar de recuentos, puedes incluir la variable de población como un término de compensación logarítmica, añadiendo offset(log(population). Entonces tendría que establecerse que la población es 1, antes de usar predict() para producir una tasa. \nSUGERENCIA: Para ajustar modelos más complejos, como ARIMA o prophet, consulta el paquete fable\n\n## define el modelo que quieres ajustar (binomial negativo) \nmodel &lt;- glm_nb_model(\n  ## establece el número de casos como resultado de interés\n  case_int ~\n    ## utiliza epiweek para tener en cuenta la tendencia\n    epiweek +\n    ## usa los términos de fourier para tener en cuenta la estacionalidad\n    fourier)\n\n## ajusta tu modelo utilizando el conjunto de datos de recuentos\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## calcula los intervalos de confianza y de predicción  \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nestimate_res &lt;- data.frame(observed$result)\n\n## representar la regresión \nggplot(data = estimate_res, aes(x = epiweek)) + \n   ## añadir una línea para la estimación del modelo\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## añadir una banda para los intervalos de predicción \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## añade una línea para los recuentos de casos observados\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## crea un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nResiduos\nPara ver si nuestro modelo se ajusta a los datos observados, tenemos que observar los residuos. Los residuos son la diferencia entre los recuentos observados y los recuentos estimados a partir del modelo. Podríamos calcularlo simplemente utilizando case_int - estimate, pero la función residuals() lo extrae directamente de la regresión por nosotros.\nLo que vemos a continuación es que no estamos explicando toda la variación que podríamos con el modelo. Es posible que debamos ajustar más términos de Fourier y abordar la amplitud. Sin embargo, para este ejemplo lo dejaremos como está. Los gráficos muestran que nuestro modelo es peor en los picos y en los valles (cuando los recuentos son los más altos y los más bajos) y que es más probable que subestime los recuentos observados.\n\n## calcular los residuos \nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = fitted_model$result[[1]]$residuals)\n\n## ¿son los residuos bastante constantes a lo largo del tiempo (si no es así: brotes? ¿cambio en la práctica?)\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## ¿hay autocorrelación en los residuos (hay un patrón en el error?)  \nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## ¿se distribuyen normalmente los residuos (se subestiman o sobreestiman?)  \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## comparar los recuentos observados con sus residuos \n  ## tampoco debería haber un patrón \nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## probar formalmente la autocorrelación de los residuos\n## H0 es que los residuos proceden de una serie de ruido blanco (es decir, aleatoria)\n## prueba de independencia \n## si el valor p es significativo entonces no es aleatorio\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 336.25, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#relation-of-two-time-series",
    "href": "new_pages/time_series.es.html#relation-of-two-time-series",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.6 Relación de dos series temporales",
    "text": "23.6 Relación de dos series temporales\nEn este caso, analizamos el uso de los datos meteorológicos (concretamente la temperatura) para explicar los recuentos de casos de campylobacter.\n\n\nFusión de conjuntos de datos\nPodemos unir nuestros conjuntos de datos utilizando la variable semana (epiweek). Para obtener más información sobre la fusión, consulta la página del manual sobre unir datos\n\n## left join para que sólo tengamos las filas ya existentes en counts\n## elimina la variable fecha de temp_data (de lo contrario estará duplicada)\ncounts &lt;- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")\n\n\n\n\nAnálisis descriptivo\nEn primer lugar, traza los datos para ver si hay alguna relación evidente. El siguiente gráfico muestra que hay una clara relación en la estacionalidad de las dos variables, y que la temperatura puede alcanzar su punto máximo unas semanas antes que el número de casos. Para más información sobre pivotar datos, consulta la sección del manual sobre pivotar datos.\n\ncounts %&gt;% \n  ## conservar las variables que nos interesan \n  select(epiweek, case_int, t2m) %&gt;% \n  ## cambiar los datos a formato largo\n  pivot_longer(\n    ## utiliza epiweek como la clave\n    !epiweek,\n    ## mover los nombres de las columnas a la nueva columna \"measure\"\n    names_to = \"measure\", \n    ## mover los valores de cell a la nueva columna \" values\"\n    values_to = \"value\") %&gt;% \n  ## crear un gráfico con el conjunto de datos anterior\n  ## dibujar epiweek en el eje-x y valores (recuentos/celsius) en el eje-y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## crea un gráfico separado para los recuentos de temperaturas y casos  \n    ## dejar que establezcan sus propios ejes-y\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## dibuja ambos como una línea\n    geom_line()\n\n\n\n\n\n\n\n\n\n\n\nRetrasos y correlación cruzada\nPara comprobar formalmente qué semanas están más relacionadas entre los casos y la temperatura. Podemos utilizar la función de correlación cruzada (CCF()) del paquete de feats. También se podría visualizar (en lugar de utilizar arrange) utilizando la función autoplot().\n\ncounts %&gt;% \n  ## calcular la correlación cruzada entre los recuentos interpolados y la temperatura\n  CCF(case_int, t2m,\n      ## fija el desfase máximo en 52 semanas\n      lag_max = 52, \n      ## devuelve el coeficiente de correlación \n      type = \"correlation\") %&gt;% \n  ## ordena el coeficiente de correlación en orden descendente\n  ## muestra los retardos más asociados\n  arrange(-ccf) %&gt;% \n  ## muestra sólo los diez primeros \n  slice_head(n = 10)\n\n# A tsibble: 10 x 2 [1W]\n        lag   ccf\n   &lt;cf_lag&gt; &lt;dbl&gt;\n 1      -4W 0.749\n 2      -5W 0.745\n 3      -3W 0.735\n 4      -6W 0.729\n 5      -2W 0.727\n 6      -7W 0.704\n 7      -1W 0.695\n 8      -8W 0.671\n 9       0W 0.649\n10      47W 0.638\n\n\nVemos que un desfase de 4 semanas es el más correlacionado, por lo que creamos una variable de temperatura retardada para incluirla en nuestra regresión.\nPELIGRO: Ten en cuenta que las primeras cuatro semanas de nuestros datos en la variable de temperatura retardada faltan (NA) - ya que no hay cuatro semanas anteriores para obtener datos. Para utilizar este conjunto de datos con la función predict() de trending, necesitamos utilizar el argumento simulate_pi = FALSE dentro de predict() más abajo. Si quisiéramos utilizar la opción de simulación, entonces tenemos que eliminar estas pérdidas y almacenarlas como un nuevo conjunto de datos añadiendo drop_na(t2m_lag4) al fragmento de código que aparece a continuación.\n\ncounts &lt;- counts %&gt;% \n  ## crea una nueva variable para la temperatura retardada cada cuatro semanas\n  mutate(t2m_lag4 = lag(t2m, n = 4))\n\n\n\n\nBinomial negativa con dos variables\nAjustamos una regresión binomial negativa como se hizo anteriormente. Esta vez añadimos la variable de temperatura con un retraso de cuatro semanas.\nPRECAUCIóN: Observa el uso de simulate_pi = FALSE dentro del argumento predict(). Esto se debe a que el comportamiento por defecto de trending es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto no funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles. \n\n## define el modelo que se quiere ajustar (binomial negativo) \nmodel &lt;- glm_nb_model(\n  ## establecer el número de casos como resultado de interés\n  case_int ~\n    ## utiliza epiweek para tener en cuenta la tendencia\n    epiweek +\n    ## usar los términos de fourier para tener en cuenta la estacionalidad\n    fourier + \n    ### usa el retraso de cuatro semanas de la temperatura\n    t2m_lag4\n    )\n\n## ajusta el modelo usando el conjunto de datos de recuentos\nfitted_model &lt;- trending::fit(model, data.frame(counts))\n\n## calcula los intervalos de confianza y de predicción \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\nPara investigar los términos individuales, podemos sacar la regresión binomial negativa original del formato de trending utilizando get_model() y pasarla a la función tidy() del paquete broom para recuperar las estimaciones exponenciadas y los intervalos de confianza asociados.\nLo que esto nos muestra es que la temperatura retardada, tras controlar la tendencia y la estacionalidad, es similar a los recuentos de casos (estimación ~ 1) y está significativamente asociada. Esto sugiere que podría ser una buena variable para predecir el número de casos futuros (ya que las previsiones climáticas están disponibles).\n\nfitted_model %&gt;% \n  ## extrae la regresión binomial negativa original\n  get_fitted_model() #%&gt;% \n\n[[1]]\n\nCall:  glm.nb(formula = case_int ~ epiweek + fourier + t2m_lag4, data = data.frame(counts), \n    init.theta = 32.80689607, link = log)\n\nCoefficients:\n (Intercept)       epiweek  fourierS1-52  fourierC1-52      t2m_lag4  \n   5.825e+00     8.464e-05    -2.850e-01    -1.954e-01     6.672e-03  \n\nDegrees of Freedom: 504 Total (i.e. Null);  500 Residual\n  (4 observations deleted due to missingness)\nNull Deviance:      2015 \nResidual Deviance: 508.2    AIC: 6784\n\n  ## obtiene un dataframe ordenado de los resultados\n  # tidy(exponentiate = TRUE, \n  #      conf.int = TRUE)\n\nUna rápida inspección visual del modelo muestra que se podría hacer un mejor trabajo de estimación de los recuentos de casos observados.\n\n## traza la regresión \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## añade una línea para la estimación del modelo\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## añade una banda para los intervalos de predicción \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## añade una línea para los recuentos de casos observados\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## crea un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic()\n\n\n\n\n\n\n\n\n\nResiduos\nVolvemos a investigar los residuos para ver si nuestro modelo se ajusta a los datos observados. Los resultados y la interpretación aquí son similares a los de la regresión anterior, por lo que puede ser más factible quedarse con el modelo más simple sin temperatura.\n\n## calcular los residuos \nestimate_res &lt;- estimate_res %&gt;% \n  mutate(resid = case_int - estimate)\n\n## ¿son los residuos bastante constantes a lo largo del tiempo (si no es así: brotes? ¿cambio en la práctica?)\nestimate_res %&gt;%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n\n\n\n\n\n\n\n## ¿hay autocorrelación en los residuos (hay un patrón en el error?)  \nestimate_res %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  ACF(resid, lag_max = 52) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n## ¿se distribuyen normalmente los residuos (se subestiman o sobreestiman?)  \nestimate_res %&gt;%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n\n\n\n\n\n\n\n## compara los recuentos observados con sus residuales\n  ## tampoco debería haber un patrón\nestimate_res %&gt;%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n\n\n\n\n\n\n\n## probar formalmente la autocorrelación de los residuos\n## H0 es que los residuos proceden de una serie de ruido blanco (es decir, aleatoria)\n## prueba de independencia \n## si el valor p es significativo entonces no es aleatorio\nBox.test(estimate_res$resid, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  estimate_res$resid\nX-squared = 346.64, df = 1, p-value &lt; 2.2e-16",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#outbreak-detection",
    "href": "new_pages/time_series.es.html#outbreak-detection",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.7 Detección de brotes",
    "text": "23.7 Detección de brotes\nAquí mostraremos dos métodos (similares) de detección de brotes. El primero se basa en las secciones anteriores. Utilizamos el paquete trending para ajustar las regresiones a los años anteriores, y luego predecir lo que esperamos ver en el año siguiente. Si los recuentos observados están por encima de lo que esperamos, esto podría sugerir que hay un brote. El segundo método se basa en principios similares, pero utiliza el paquete surveillance, que tiene varios algoritmos diferentes para la detección de aberraciones.\nATENCIÓN: Normalmente, estás interesado en el año actual (donde sólo se conocen los recuentos hasta la semana actual). Así que en este ejemplo pretendemos estar en la semana 39 de 2011.\n\n\nPaquete trending\nPara este método definimos una línea base (que normalmente debería ser de unos 5 años de datos). Ajustamos una regresión a los datos de referencia y la utilizamos para predecir las estimaciones del año siguiente.\n\n\nFecha de corte\nEs más fácil definir las fechas en un lugar y luego utilizarlas en el resto del código.\nAquí definimos una fecha de inicio (cuando comenzaron nuestras observaciones) y una fecha de corte (el final de nuestro período de referencia - y cuando comienza el período que queremos predecir). ~También definimos cuántas semanas hay en nuestro año de interés (el que vamos a predecir)~. También definimos cuántas semanas hay entre nuestra fecha límite de referencia y la fecha final para la que nos interesa predecir.\nNOTA: En este ejemplo pretendemos estar actualmente a finales de septiembre de 2011 (“2011 W39”).\n\n## define la fecha de inicio (cuando empezaron las observaciones)\nstart_date &lt;- min(counts$epiweek)\n\n\n## define una semana de corte (fin de la línea base, inicio del periodo de predicción)\ncut_off &lt;- yearweek(\"2010-12-31\")\n\n## define la última fecha de interés (es decir, el final de la predicción)\nend_date &lt;- yearweek(\"2011-12-31\")\n\n## encontrar cuántas semanas en el período (año) de interés\nnum_weeks &lt;- as.numeric(end_date - cut_off)\n\n\n\n\nAñadir filas\nPara poder pronosticar en un formato tidyverse, necesitamos tener el número correcto de filas en nuestro conjunto de datos, es decir, una fila por cada semana hasta la end_date (fecha de corte) definida anteriormente. El código siguiente permite añadir estas filas por una variable de agrupación - por ejemplo, si tuviéramos varios países en unos datos, podríamos agrupar por país y luego añadir filas apropiadas para cada uno. La función group_by_key() de tsibble nos permite hacer esta agrupación y luego pasar los datos agrupados a las funciones de dplyr, group_modify() y add_row(). Luego especificamos la secuencia de semanas entre una después de la semana máxima disponible actualmente en los datos y la semana final.\n\n## añade las semanas que faltan hasta final de año  \ncounts &lt;- counts %&gt;%\n  ## agrupa por región\n  group_by_key() %&gt;%\n  ## para cada grupo, añade filas desde la mayor epiweek hasta el final del año\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))\n\n\n\n\nTérminos de Fourier\nTenemos que redefinir nuestros términos de fourier, ya que queremos ajustarlos sólo a la fecha de referencia y luego predecir (extrapolar) esos términos para el año siguiente. Para ello tenemos que combinar dos listas de salida de la función fourier() juntas; la primera es para los datos de referencia, y la segunda predice para el año de interés (definiendo el argumento h).\nN.b. para enlazar filas tenemos que usar rbind() (en lugar de bind_rows de tidyverse) ya que las columnas de fourier son una lista (por lo que no se nombran individualmente).\n\n## define los términos de fourier (sencos) \ncounts &lt;- counts %&gt;% \n  mutate(\n    ## combina los términos de fourier para las semanas anteriores y posteriores a la fecha límite de 2010\n    ## (nb. los términos de fourier de 2011 están proyectados)\n    fourier = rbind(\n      ## obtiene los términos de fourier de años anteriores\n      fourier(\n        ## conserva sólo las filas anteriores a 2011\n        filter(counts, \n               epiweek &lt;= cut_off), \n        ## incluye un conjunto de términos sen cos \n        K = 1\n        ), \n      ## predice los términos de fourier para 2011 (usando datos de referencia)\n      fourier(\n        ## conserva sólo las filas anteriores a 2011\n        filter(counts, \n               epiweek &lt;= cut_off),\n        ## incluye un conjunto de términos sen cos \n        K = 1, \n        ## predice con 52 semanas de antelación\n        h = num_weeks\n        )\n      )\n    )\n\n\n\n\nDividir los datos y ajustar la regresión\nAhora tenemos que dividir nuestro conjunto de datos en el período de referencia y el período de predicción. Esto se hace utilizando la función group_split() de dplyr después de group_by(), y creará una lista con dos dataframes, uno para antes de tu corte y otro para después.\nA continuación, utilizamos la función pluck() del paquete purrr para extraer los datos del listado (lo que equivale a utilizar corchetes, por ejemplo, dat[1]]), y podemos ajustar nuestro modelo a los datos de referencia, y luego utilizar la función predict() para nuestros datos de interés después del corte.\nConsulta la página sobre Iteración, bucles y listas para saber más sobre purrr.\nATENCIÓN: Observa el uso de simulate_pi = FALSE dentro del argumento predict(). Esto se debe a que el comportamiento por defecto de trending es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto no funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles. \n\n# divide los datos para el ajuste y la predicción\ndat &lt;- counts %&gt;% \n  group_by(epiweek &lt;= cut_off) %&gt;%\n  group_split()\n\n## define el modelo que se desea ajustar (binomial negativa)  \nmodel &lt;- glm_nb_model(\n  ## establece el número de casos como resultado de interés\n  case_int ~\n    ## usa epiweek para tener en cuenta la tendencia\n    epiweek +\n    ## utiliza los términos furier para tener en cuenta la estacionalidad\n    fourier\n)\n\n# define qué datos utilizar para el ajuste y cuáles para la predicción\nfitting_data &lt;- pluck(dat, 2)\npred_data &lt;- pluck(dat, 1) %&gt;% \n  select(case_int, epiweek, fourier)\n\n# ajusta el modelo \nfitted_model &lt;- trending::fit(model, data.frame(fitting_data))\n\n# obtiene intervalos de confianza y estimaciones para los datos ajustados\nobserved &lt;- fitted_model %&gt;% \n  predict(simulate_pi = FALSE)\n\n# pronostica con los datos con los que se quiere predecir \nforecasts &lt;- fitted_model %&gt;% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## combina los conjuntos de datos de referencia y de predicción\nobserved &lt;- bind_rows(observed$result, forecasts$result)\n\nComo anteriormente, podemos visualizar nuestro modelo con ggplot. Resaltamos las alertas con puntos rojos para los recuentos observados por encima del intervalo de predicción del 95%. Esta vez también añadimos una línea vertical para etiquetar cuándo empieza la predicción. ##hastaqui\n\n## representar la regresión \nggplot(data = observed, aes(x = epiweek)) + \n  ## añade una línea para la estimación del modelo\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## añade una banda para los intervalos de predicción \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## añade una línea para los recuentos de casos observados\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## representar en puntos los recuentos observados por encima de lo esperado\n  geom_point(\n    data = filter(observed, case_int &gt; upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## añade una línea vertical y una etiqueta para mostrar dónde empieza la previsión\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## realiza un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic()\n\nWarning: Removed 13 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\nValidación de la predicción\nMás allá de la inspección de los residuos, es importante investigar lo bueno que es tu modelo para predecir casos en el futuro. Esto te da una idea de la fiabilidad de tus umbrales de alerta.\nLa forma tradicional de validar es ver lo bien que se puede predecir el último año anterior al actual (porque aún no se conocen los recuentos del “año actual”). Por ejemplo, en nuestro conjunto de datos, utilizaríamos los datos de 2002 a 2009 para predecir 2010, y luego veríamos la precisión de esas predicciones. A continuación, volveríamos a ajustar el modelo para incluir los datos de 2010 y los utilizaríamos para predecir los recuentos de 2011.\nComo puede verse en la siguiente figura de Hyndman et al en “Forecasting principles and practice”.\n figura reproducida con permiso de los autores\nLa desventaja de esto es que no estás usando todos los datos disponibles, y no es el modelo final que estás usando para la predicción.\nUna alternativa es utilizar un método llamado validación cruzada. En este caso, se pasan todos los datos disponibles para ajustar múltiples modelos de predicción a un año vista. Se utilizan cada vez más datos en cada modelo, como se ve en la siguiente figura del mismo [texto de Hyndman et al]((https://otexts.com/fpp3/). Por ejemplo, el primer modelo utiliza 2002 para predecir 2003, el segundo utiliza 2002 y 2003 para predecir 2004, y así sucesivamente.  figura reproducida con permiso de los autores\nA continuación, utilizamos la función map() del paquete purrr para recorrer cada conjunto de datos. Luego, ponemos las estimaciones conjunto de datos y las fusionamos con los recuentos de casos originales, para utilizar el paquete yardstick para calcular las medidas de precisión. Calculamos cuatro medidas que incluyen: Error medio cuadrático (RMSE), Error medio absoluto (MAE), Error medio absoluto a escala (MASE), Error medio porcentual absoluto (MAPE).\nATENCIÓN: Observa el uso de simulate_pi = FALSE dentro del argumento predict(). Esto se debe a que el comportamiento por defecto de la tendencia es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto no funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles.\n\n## Validación cruzada: predicción de la(s) semana(s) anterior(es) basada en una ventana deslizante.\n\n## amplía los datos en ventanas de 52 semanas (antes + después) \n## para predecir 52 semanas por delante\n## (crea cadenas de observaciones cada vez más largas - mantiene los datos más antiguos)\n\n## define la ventana que se quiere utilizar\nroll_window &lt;- 52\n\n## define las semanas que se quieren predecir \nweeks_ahead &lt;- 52\n\n## crea un conjunto de datos repetidos, cada vez más largos\n## etiqueta cada conjunto de datos con un id único\n## utiliza sólo casos anteriores al año de interés (es decir, 2011)\ncase_roll &lt;- counts %&gt;% \n  filter(epiweek &lt; cut_off) %&gt;% \n  ## mantiene sólo las variables de semana y recuento de casos\n  select(epiweek, case_int) %&gt;% \n    ## elimina las últimas x observaciones \n    ## dependiendo de cuántas semanas se prevean \n    ## (de lo contrario será una previsión real a \"desconocido\")\n    slice(1:(n() - weeks_ahead)) %&gt;%\n    as_tsibble(index = epiweek) %&gt;% \n    ## desplaza cada semana en x después de las ventanas para crear ID de agrupación \n    ## dependiendo de lo que especifique roll_window\n    stretch_tsibble(.init = roll_window, .step = 1) %&gt;% \n  ## elimina el primer par - ya que no tiene casos \"anteriores\"\n  filter(.id &gt; roll_window)\n\n\n## para cada uno de los grupos de datos únicos se ejecuta el código siguiente\nforecasts &lt;- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## sólo se mantiene el conjunto actual que se está ajustando \n  mini_data &lt;- filter(case_roll, .id == i) %&gt;% \n    as_tibble()\n  \n  ## crea un conjunto de datos vacío para la previsión \n  forecast_data &lt;- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  # añade los datos de previsión a los originales \n  mini_data &lt;- bind_rows(mini_data, forecast_data)\n  \n  ## define los puntos de corte en función de los últimos datos de recuento no faltantes \n  cv_cut_off &lt;- mini_data %&gt;% \n    ## conserva sólo las filas no faltantes\n    drop_na(case_int) %&gt;% \n    ## obtiene la última semana\n    summarise(max(epiweek)) %&gt;% \n    ## extrae lo que no está en un dataframe\n    pull()\n  \n## convierte mini_data en un tsibble\n  mini_data &lt;- tsibble(mini_data, index = epiweek)\n  \n  ## define los términos de fourier (sencos) \n  mini_data &lt;- mini_data %&gt;% \n    mutate(\n    ## combina los términos de fourier para las semanas anteriores y posteriores a la fecha de corte\n    fourier = rbind(\n      ## obtiene los términos de fourier de años anteriores\n      forecast::fourier(\n        ## conserva sólo las filas anteriores a la fecha de corte\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off), \n        ## incluye un conjunto de términos sen cos \n        K = 1\n        ), \n      ## predice los términos de fourier para el año siguiente (utilizando los datos de referencia)\n      fourier(\n        ## conserva sólo las filas anteriores al corte\n        filter(mini_data, \n               epiweek &lt;= cv_cut_off),\n        ## incluye un conjunto de términos seno-cos \n        K = 1, \n        ## predice con 52 semanas de antelación\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # divide los datos para el ajuste y la predicción\n  dat &lt;- mini_data %&gt;% \n    group_by(epiweek &lt;= cv_cut_off) %&gt;%\n    group_split()\n\n  ## define el modelo que se quiere ajustar (binomial negativa) \n  model &lt;- glm_nb_model(\n    ## establece el número de casos como resultado de interés\n    case_int ~\n      ## utiliza epiweek para tener en cuenta la tendencia\n      epiweek +\n      ## usa los términos de furier para tener en cuenta la estacionalidad\n      fourier\n  )\n\n  # define qué datos utilizar para el ajuste y cuáles para la predicción\n  fitting_data &lt;- pluck(dat, 2)\n  pred_data &lt;- pluck(dat, 1)\n  \n  # ajusta el modelo \n  fitted_model &lt;- trending::fit(model, fitting_data)\n  \n  # proyecta con los datos que se quieren predecir \n  forecasts &lt;- fitted_model %&gt;% \n    predict(data.frame(pred_data), simulate_pi = FALSE) \n  forecasts &lt;- data.frame(forecasts$result[[1]]) %&gt;% \n    ## conserva sólo la semana y la estimación de la previsión\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## convierte la lista en un dataframe con todas las proyecciones\nforecasts &lt;- bind_rows(forecasts)\n\n## une las proyecciones con los datos observados\nforecasts &lt;- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## usando {yardstick} calcula las métricas\n  ## RMSE: Root mean squared error (error cuadrático medio)\n  ## MAE: Error medio absoluto  \n  ## MASE: Mean absolute scaled error (Error medio absoluto a escala)\n  ## MAPE: Error porcentual medio absoluto\nmodel_metrics &lt;- bind_rows(\n  ## compara lo observado con lo proyectado en el conjunto de datos de previsiones\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %&gt;% \n  ## conserva sólo el tipo de métrica y su salida\n  select(Metric  = .metric, \n         Measure = .estimate) %&gt;% \n  ## convierte en formato ancho para poder enlazar filas después\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## devuelve las métricas del modelo \nmodel_metrics\n\n# A tibble: 1 × 4\n   rmse   mae  mase  mape\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  252.  199.  1.96  17.3\n\n\n\n\n\n\npaquete surveillance\nEn esta sección utilizamos el paquete surveillance para crear umbrales de alerta basados en algoritmos de detección de brotes. Hay varios métodos diferentes disponibles en el paquete, aunque aquí nos centraremos en dos opciones. Para más detalles, consulta estos documentos sobre la aplicación y la teoría de los algoritmos utilizados.\nLa primera opción utiliza el método Farrington mejorado. Este método ajusta un glm binomial negativo (incluyendo la tendencia) y pondera a la baja los brotes pasados (valores atípicos) para crear un nivel de umbral.\nLa segunda opción utiliza el método glrnb. Esto también se ajusta a un glm binomial negativo, pero incluye la tendencia y los términos de fourier (por lo que se favorece aquí). La regresión se utiliza para calcular la “media de control” (~valores ajustados), y a continuación se utiliza un estadístico de relación de verosimilitud generalizada para evaluar si hay un cambio en la media de cada semana. Ten en cuenta que el umbral de cada semana tiene en cuenta las semanas anteriores, por lo que si hay un cambio sostenido se activará una alarma. (También hay que tener en cuenta que después de cada alarma el algoritmo se reinicia)\nPara trabajar con el paquete surveillance, primero tenemos que definir un objeto “surveillance time series” (utilizando la función sts()) para que encaje en el marco de trabajo.\n\n## define el objeto series temporales de vigilancia\n## nota. se puede incluir un denominador con el objeto población (ver ?sts)\ncounts_sts &lt;- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## subconjunto para mantener sólo el año desde start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subconjunto para mantener sólo la semana a partir de start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define el tipo de datos (en este caso semanales)\n                  freq = 52)\n\n## define el rango de semanas que se quiere incluir (es decir, el periodo de predicción)\n## nota: el objeto sts sólo cuenta las observaciones sin asignarles un identificador de semana o año. \n## identificador de año - utilizaremos nuestros datos para definir las observaciones adecuadas\nweekrange &lt;- cut_off - start_date\n\n\n\nMétodo Farrington\nA continuación, definimos cada uno de nuestros parámetros para el método Farrington en una list. A continuación, ejecutamos el algoritmo utilizando farringtonFlexible() y luego podemos extraer el umbral de una alerta utilizando farringtonmethod@upperbound para incluirlo en nuestro conjunto de datos. También es posible extraer un TRUE/FALSE para cada semana si se activó una alerta (estaba por encima del umbral) utilizando farringtonmethod@alarm.\n\n## define control\nctrl &lt;- list(\n  ## define para qué periodo de tiempo se quiere el umbral (por ejemplo, 2011)\n  range = which(counts_sts@epoch &gt; weekrange),\n  b = 9, ## cuántos años hacia atrás para la línea base\n  w = 2, ## tamaño de la ventana móvil en semanas\n  weightsThreshold = 2.58, ## reponderar brotes pasados (método noufaily mejorado - original sugiere 1)\n  ## pastWeeksNotIncluded = 3, ## utiliza todas las semanas disponibles (noufaily sugiere dejar 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normalmente, sin embargo se aconseja 1 en el método mejorado (es decir, mantener siempre)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## aplicar el método farrington flexible\nfarringtonmethod &lt;- farringtonFlexible(counts_sts, ctrl)\n\n## crea una nueva variable en el conjunto de datos original llamada umbral\n## que contiene el límite superior de farrington \n## nota: esto es solo para las semanas de 2011 (por lo que hay que hacer un subconjunto de filas)\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] &lt;- farringtonmethod@upperbound\n\nA continuación, podemos visualizar los resultados en ggplot como se hizo anteriormente.\n\nggplot(counts, aes(x = epiweek)) + \n  ## añade los recuentos de casos observados como una línea\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## añade el límite superior del algoritmo de aberración\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define los colores\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## realiza un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic() + \n  ## elimina el título de la leyenda \n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nMétodo GLRNB\nDel mismo modo, para el método GLRNB definimos cada uno de nuestros parámetros en una list, luego ajustamos el algoritmo y extraemos los límites superiores.\nATENCIÓN: Este método utiliza la “fuerza bruta” (similar al bootstrapping) para calcular los umbrales, por lo que puede llevar mucho tiempo.\nConsulta la viñeta GLRNB para más detalles.\n\n## define las opciones de control\nctrl &lt;- list(\n  ## define para qué periodo de tiempo se quiere el umbral (por ejemplo, 2011)\n  range = which(counts_sts@epoch &gt; weekrange),\n  mu0 = list(S = 1,    ## número de términos de fourier (armónicos) a incluir\n  trend = TRUE,   ## si incluye la tendencia o no\n  refit = FALSE), ## si se reajusta el modelo después de cada alarma\n  ## cARL = umbral para el estadístico GLR (arbitrario)\n     ## 3 ~ término medio para minimizar los falsos positivos\n     ## 1 se ajusta al 99%PI de glm.nb - con cambios después de los picos (umbral reducido para la alerta)\n   c.ARL = 2,\n   # theta = log(1.5), ## equivale a un aumento del 50% de casos en un brote\n   ret = \"cases\"     ## devuelve el límite superior del umbral como recuento de casos\n  )\n\n## aplica el método glrnb\nglrnbmethod &lt;- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## crea una nueva variable en el conjunto de datos original llamada umbral\n## que contiene el límite superior de glrnb \n## nota: esto es solo para las semanas de 2011 (por lo que hay que hacer un subconjunto de filas)\ncounts[which(counts$epiweek &gt;= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] &lt;- glrnbmethod@upperbound\n\nVisualiza los resultados como antes.\n\nggplot(counts, aes(x = epiweek)) + \n  ## añade los recuentos de casos observados como una línea\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## añade el límite superior del algoritmo de aberración\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define los colores\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## realiza un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic() + \n  ## elimina el título de la leyenda  \n  theme(legend.title = element_blank())",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#interrupted-timeseries",
    "href": "new_pages/time_series.es.html#interrupted-timeseries",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.8 Series temporales interrumpidas",
    "text": "23.8 Series temporales interrumpidas\nLas series temporales interrumpidas (también llamadas análisis de regresión segmentada o de intervención), se utilizan a menudo para evaluar el impacto de las vacunas en la incidencia de la enfermedad. Pero puede utilizarse para evaluar el impacto de una amplia gama de intervenciones o introducciones. Por ejemplo, cambios en los procedimientos hospitalarios o la introducción de una nueva cepa de enfermedad en una población.\nEn este ejemplo, supondremos que se introdujo una nueva cepa de Campylobacter en Alemania a finales de 2008, y veremos si eso afecta al número de casos. Volveremos a utilizar la regresión binomial negativa. Esta vez, la regresión se dividirá en dos partes, una antes de la intervención (o introducción de la nueva cepa en este caso) y otra después (los períodos anterior y posterior). Esto nos permite calcular una tasa de incidencia comparando los dos periodos de tiempo. Explicar la ecuación podría aclararlo (si no es así, ignórala).\nLa regresión binomial negativa puede definirse como sigue:\n\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]\nDonde: \\((Y_t\\)) es el número de casos observados en el momento \\((t\\)) \\((pop_t\\)) es el tamaño de la población en 100.000s en el momento \\((t\\)) (no se utiliza aquí) \\((t_0\\)) es el último año del preperíodo (incluyendo el tiempo de transición si lo hay) \\((δ(x\\)) es la función indicadora (es 0 si x≤0 y 1 si x\\(&gt;0)\\)((x)\\(^+\\)) es el operador de corte (es x si x\\(&gt;0 y 0 en caso contrario)\\)(e_t$) denota el residuo\nSe pueden añadir los términos adicionales tendencia y estación según sea necesario.\n\\(β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+\\) es la parte lineal generalizada del periodo posterior y es cero en el periodo anterior. Esto significa que las estimaciones \\(β_2\\) y \\(β_3\\) son los efectos de la intervención.\nAquí tenemos que volver a calcular los términos de Fourier sin previsión, ya que utilizaremos todos los datos de que disponemos (es decir, a posteriori). Además, tenemos que calcular los términos adicionales necesarios para la regresión.\n\n## añade los términos de fourier utilizando las variables epiweek y case_int\ncounts$fourier &lt;- select(counts, epiweek, case_int) %&gt;% \n  as_tsibble(index = epiweek) %&gt;% \n  fourier(K = 1)\n\n## define la semana de intervención \nintervention_week &lt;- yearweek(\"2008-12-31\")\n\n## define variables para la regresión \ncounts &lt;- counts %&gt;% \n  mutate(\n    ## corresponde a t en la fórmula\n      ## recuento de semanas (probablemente también se podría usar directamente la variable epiweek)\n    # linear = row_number(epiweek), \n    ## corresponde a delta(t-t0) en la fórmula\n      ## periodo anterior o posterior a la intervención\n    intervention = as.numeric(epiweek &gt;= intervention_week), \n    ## corresponde a (t-t0)^+ en la fórmula\n      ## recuento de semanas posteriores a la intervención\n      ## ( elige el número mayor entre 0 y lo que resulte del cálculo)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n\nA continuación, utilizamos estos términos para ajustar una regresión binomial negativa y elaboramos una tabla con el porcentaje de cambio. Lo que muestra este ejemplo es que no hubo ningún cambio significativo.\nATENCIÓN: Observa el uso de simulate_pi = FALSE dentro del argumento de predict(). Esto se debe a que el comportamiento por defecto de la tendencia es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto no funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles.\n\n## define el modelo que se quiere ajustar (binomial negativo) \nmodel &lt;- glm_nb_model(\n  ## establece el número de casos como resultado de interés\n  case_int ~\n    ## utiliza epiweek para tener en cuenta la tendencia\n    epiweek +\n    ## utiliza los términos furier para tener en cuenta la estacionalidad\n    fourier + \n    ## añade si está en el periodo anterior o posterior \n    intervention + \n    ## añade el tiempo posterior a la intervención \n    time_post\n    )\n\n## ajusta el modelo utilizando el conjunto de datos de recuentos\nfitted_model &lt;- trending::fit(model, counts)\n\n## calcula los intervalos de confianza y de predicción \nobserved &lt;- predict(fitted_model, simulate_pi = FALSE)\n\n\n## muestra las estimaciones y el porcentaje de cambio en una tabla\nfitted_model %&gt;% \n  ## extrae la regresión binomial negativa original\n  get_model() %&gt;% \n  ## obtiene un dataframe ordenado de los resultados\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %&gt;% \n  ## conserva sólo el valor de intervención \n  filter(term == \"intervention\") %&gt;% \n  ## cambia la TIR (IRR) por el porcentaje de cambio para la estimación y los IC \n  mutate(\n    ## para cada una de las columnas de interés - crea una nueva columna\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## aplica la fórmula para calcular el cambio porcentual\n            .f = function(i) 100 * (i - 1), \n      ## añade un sufijo a los nuevos nombres de columna con \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %&gt;% \n  ## sólo mantiene (y renombra) ciertas columnas \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)\n\nComo en el caso anterior, podemos visualizar los resultados de la regresión.\n\nestimate_res &lt;- data.frame(observed$result)\n\n\nggplot(estimate_res, aes(x = epiweek)) + \n  ## añade los recuentos de casos observados como una línea\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## añade una línea para la estimación del modelo\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## añade una banda para los intervalos de predicción \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## añade una línea vertical y una etiqueta para mostrar dónde empezó la predicción\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define los colores\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## realiza un gráfico tradicional (con ejes negros y fondo blanco)\n  theme_classic()\n\nWarning: Unknown or uninitialised column: `upper_pi`.\n\n\nWarning in max(observed$upper_pi): no non-missing arguments to max; returning\n-Inf",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/time_series.es.html#resources-16",
    "href": "new_pages/time_series.es.html#resources-16",
    "title": "23  Series temporales y detección de brotes",
    "section": "23.9 Recursos",
    "text": "23.9 Recursos\nForecasting: principles and practice. Libro de texto\nEstudios de casos de análisis de series temporales de EPIET\nCurso de Penn State\nManuscrito del paquete Surveillance",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Series temporales y detección de brotes</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.es.html",
    "href": "new_pages/epidemic_models.es.html",
    "title": "24  Modelización de epidemias",
    "section": "",
    "text": "24.1 Resumen\nExiste un conjunto creciente de herramientas para la modelización de epidemias que nos permite realizar análisis bastante complejos con un esfuerzo mínimo. En esta sección se ofrece una visión general de cómo utilizar estas herramientas para:\nNo pretende ser una visión general de las metodologías y los métodos estadísticos en los que se basan estas herramientas, así que consulta la sección de Recursos para ver los enlaces a algunos documentos que cubren esto. Asegúrese de que conoce los métodos antes de utilizar estas herramientas, ya que así podrá interpretar con precisión sus resultados.\nA continuación se muestra un ejemplo de uno de los resultados que produciremos en esta sección.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modelización de epidemias</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.es.html#overview-3",
    "href": "new_pages/epidemic_models.es.html#overview-3",
    "title": "24  Modelización de epidemias",
    "section": "",
    "text": "estimar el número de reproducción efectivo Rt y las estadísticas relacionadas, como el tiempo de duplicación\nelaborar proyecciones a corto plazo de la incidencia futura",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modelización de epidemias</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.es.html#preparation-15",
    "href": "new_pages/epidemic_models.es.html#preparation-15",
    "title": "24  Modelización de epidemias",
    "section": "24.2 Preparación",
    "text": "24.2 Preparación\nUtilizaremos dos métodos y paquetes diferentes para la estimación de Rt, a saber, EpiNow y EpiEstim, así como el paquete projections para la previsión de la incidencia de casos.\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n   rio,          # Importación de ficheros\n   here,         # Localizador de ficheros\n   tidyverse,    # Gestión de datos + gráficos ggplot2\n   epicontacts,  # Análisis de redes de transmisión\n   EpiNow2,      # Estimación Rt\n   EpiEstim,     # Estimación Rt\n   projections,  # Proyecciones de incidencia\n   incidence2,   # Manejo de datos de incidencia\n   epitrix,      # Funciones epi útiles\n   distcrete     # Distribuciones discretas de retraso\n)\n\nUtilizaremos la lista de casos limpia para todos los análisis de esta sección. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Consulta la página de descargando el manual y los datos para descargar todos los datos de ejemplo utilizados en este manual.\n\n# importar linelist depurado\nlinelist &lt;- import(\"linelist_cleaned.rds\")",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modelización de epidemias</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.es.html#estimating-rt",
    "href": "new_pages/epidemic_models.es.html#estimating-rt",
    "title": "24  Modelización de epidemias",
    "section": "24.3 Estimación de Rt",
    "text": "24.3 Estimación de Rt\n\nEpiNow2 vs. EpiEstim\nEl número de reproducción R es una medida de la transmisibilidad de una enfermedad y se define como el número esperado de casos secundarios por cada caso infectado. En una población totalmente susceptible, este valor representa el número básico de reproducción R0. Sin embargo, como el número de individuos susceptibles en una población cambia en el transcurso de un brote o pandemia, y como se aplican diversas medidas de respuesta, la medida de transmisibilidad más utilizada es el número de reproducción efectivo Rt; éste se define como el número esperado de casos secundarios por caso infectado en un tiempo t determinado.\nEl paquete EpiNow2 proporciona el marco más sofisticado para estimar Rt. Tiene dos ventajas clave sobre el otro paquete comúnmente utilizado, EpiEstim:\n\nTiene en cuenta los retrasos en la notificación y, por lo tanto, puede estimar la Rt incluso cuando los datos recientes son incompletos.\nEstima la Rt en función de las fechas de infección y no de las fechas de inicio de la notificación, lo que significa que el efecto de una intervención se reflejará inmediatamente en un cambio en la Rt, en lugar de con un retraso.\n\nSin embargo, también tiene dos desventajas fundamentales:\n\nRequiere conocer la distribución del tiempo de generación (es decir, la distribución de los retrasos entre la infección de un caso primario y uno secundario), la distribución del periodo de incubación (es decir, la distribución de los retrasos entre la infección y el inicio de los síntomas) y cualquier otra distribución de los retrasos que sea relevante para sus datos (por ejemplo, si tiene fechas de notificación, necesita la distribución de los retrasos desde el inicio de los síntomas hasta la notificación). Aunque esto permitirá una estimación más precisa de Rt, EpiEstim sólo requiere la distribución de intervalos en serie (es decir, la distribución de retrasos entre el inicio de los síntomas de un caso primario y uno secundario), que puede ser la única distribución disponible para usted.\nEpiNow2 es significativamente más lento que EpiEstim, anecdóticamente por un factor de 100-1000. Por ejemplo, la estimación de Rt para el brote de la muestra considerada en esta sección tarda unas cuatro horas (esto se ejecutó para un gran número de iteraciones para asegurar una alta precisión y probablemente podría reducirse si fuera necesario, sin embargo los puntos son que el algoritmo es lento en general). Esto puede ser inviable si se actualizan regularmente las estimaciones de Rt.\n\nPor tanto, el paquete que elijas utilizar dependerá de los datos, el tiempo y los recursos informáticos de que disponga.\n\n\nEpiNow2\n\nEstimación de las distribuciones de los retrasos\nLas distribuciones de retraso necesarias para ejecutar EpiNow2 dependen de los datos que tengas. Esencialmente, necesita poder describir el retraso desde la fecha de la infección hasta la fecha del evento que quieres usar para estimar Rt. Si estás usando fechas de inicio, esto sería simplemente la distribución del periodo de incubación. Si se utilizan las fechas de notificación, se requiere el retraso desde la infección hasta la notificación. Como es poco probable que esta distribución se conozca directamente, EpiNow2 permite encadenar varias distribuciones de retraso; en este caso, el retraso desde la infección hasta el inicio de los síntomas (por ejemplo, el periodo de incubación, que probablemente se conoce) y desde el inicio de los síntomas hasta la notificación (que a menudo se puede estimar a partir de los datos).\nComo tenemos las fechas de inicio de todos nuestros casos en nuestro linelist de ejemplo, sólo necesitaremos la distribución del periodo de incubación para relacionar nuestros datos (por ejemplo, las fechas de inicio de los síntomas) con la fecha de la infección. Podemos estimar esta distribución a partir de los datos o utilizar valores de la literatura.\nUna estimación bibliográfica del periodo de incubación del ébola (tomada de este documento) con una media de 9,1, una desviación estándar de 7,3 y un valor máximo de 30 se especificaría como sigue:\n\nincubation_period_lit &lt;- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n\nTen en cuenta que EpiNow2 requiere que estas distribuciones de retardo se proporcionen en una escala logarítmica, de ahí la llamada log alrededor de cada valor (excepto el parámetro max que, confusamente, tiene que proporcionarse en una escala natural). Los parámetros mean_sd y sd_sd definen la desviación estándar de las estimaciones de la media y la desviación estándar. Como no se conocen en este caso, elegimos el valor bastante arbitrario de 0,1.\nEn este análisis, en cambio, estimamos la distribución del periodo de incubación a partir del propio listado utilizando la función bootstrapped_dist_fit, que ajustará una distribución lognormal a los retrasos observados entre la infección y el inicio en linelist.\n\n## estimación del periodo de incubación\nincubation_period &lt;- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n\nLa otra distribución que necesitamos es el tiempo de generación. Como tenemos datos sobre los tiempos de infección y los enlaces de transmisión, podemos estimar esta distribución a partir de linelist calculando el retraso entre los tiempos de infección de los pares infector-infectado. Para ello, utilizamos la práctica función get_pairwise del paquete epicontacts, que nos permite calcular las diferencias por pares de las propiedades de linelist entre los pares de transmisión. Primero creamos un objeto epicontacts (ver la página de cadenas de transmisión para más detalles):\n\n## generar contactos\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## generar el objeto epicontacts\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nA continuación, ajustamos la diferencia de tiempos de infección entre pares de transmisión, calculada mediante get_pairwise, a una distribución gamma:\n\n## estimar el tiempo de generación gamma\ngeneration_time &lt;- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)\n\n\n\nEjecución de EpiNow2\nAhora sólo tenemos que calcular la incidencia diaria de linelist, lo que podemos hacer fácilmente con las funciones group_by() y n() de dplyr. Ten en cuenta que EpiNow2 requiere que los nombres de las columnas sean date y confirm.\n\n## obtener la incidencia a partir de las fechas de inicio\ncases &lt;- linelist %&gt;%\n  group_by(date = date_onset) %&gt;%\n  summarise(confirm = n())\n\nPodemos entonces estimar Rt utilizando la función epinow. Algunas notas sobre las entradas:\n\nPodemos proporcionar cualquier número de distribuciones de retraso “encadenadas” al argumento delays: simplemente las insertaríamos junto al objeto incubation_period dentro de la función delay_opts.\n\nEl objeto return_output asegura que la salida se devuelve dentro de R y no solo se guarda en un archivo.\n\nverbose especifica que queremos una lectura del progreso.\nhorizon indica para cuántos días queremos proyectar la incidencia futura.\nPasamos opciones adicionales al argumento stan para especificar durante cuánto tiempo queremos ejecutar la inferencia. Aumentando samples y chains obtendremos una estimación más precisa que caracteriza mejor la incertidumbre, sin embargo tardará más en ejecutarse.\n\n\n## ejecutar epinow\nepinow_res &lt;- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)\n\n\n\nAnálisis de los resultados\nUna vez que el código ha terminado de ejecutarse, podemos trazar un resumen muy fácilmente, como se indica a continuación. Desplaza la imagen para ver la extensión completa.\n\n## gráfico resumen \nplot(epinow_res)\n\n\n\n\n\n\n\n\nTambién podemos consultar varias estadísticas resumidas:\n\n## tabla resumen\nepinow_res$summary\n\n                                 measure                  estimate\n                                  &lt;char&gt;                    &lt;char&gt;\n1: New confirmed cases by infection date                4 (2 -- 6)\n2:        Expected change in daily cases                    Unsure\n3:            Effective reproduction no.        0.88 (0.73 -- 1.1)\n4:                        Rate of growth -0.012 (-0.028 -- 0.0052)\n5:          Doubling/halving time (days)          -60 (130 -- -25)\n    numeric_estimate\n              &lt;list&gt;\n1: &lt;data.table[1x9]&gt;\n2:              0.56\n3: &lt;data.table[1x9]&gt;\n4: &lt;data.table[1x9]&gt;\n5: &lt;data.table[1x9]&gt;\n\n\nPara otros análisis y trazados personalizados, puedes acceder a las estimaciones diarias resumidas a través de $estimates$summarised. Convertiremos esto desde data.table por defecto a un tibble para facilitar su uso con dplyr.\n\n## extraer resumen y convertir a tibble\nestimates &lt;- as_tibble(epinow_res$estimates$summarised)\nestimates\n\n\n\n\n\n\n\nA modo de ejemplo, hagamos un gráfico del tiempo de duplicación y Rt. Sólo nos fijaremos en los primeros meses del brote, cuando Rt es muy superior a uno, para evitar trazar tiempos de duplicación extremadamente altos.\nUtilizamos la fórmula log(2)/growth_rate para calcular el tiempo de duplicación a partir de la tasa de crecimiento estimada.\n\n## hacer un df ancho para el trazado de la mediana\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date &lt; as.Date(\"2014-09-01\")\n  ) %&gt;%\n  ## convertir las tasas de crecimiento en tiempos de duplicación\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## cambiar el nombre de la variable para reflejar la transformación\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## hacer un df largo para el trazado de cuantiles\ndf_long &lt;- df_wide %&gt;%\n  ## aquí hacemos coincidir los cuantiles (por ejemplo, lower_90 con upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## crear el gráfico\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## usar label_parsed para permitir la etiqueta del subscript\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n ## definir manualmente la transparencia de los cuantiles\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nEpiEstim\nPara ejecutar EpiEstim, necesitamos proporcionar datos sobre la incidencia diaria y especificar el intervalo de serie (es decir, la distribución de los retrasos entre el inicio de los síntomas de los casos primarios y secundarios).\nLos datos de incidencia pueden proporcionarse a EpiEstim como un vector, un dataframe o un objeto incidence del paquete incidence original. Incluso se puede distinguir entre infecciones importadas y adquiridas localmente; consulta la documentación en ?estimate_R para más detalles.\nCrearemos la entrada utilizando incidence2. Consulta la página sobre curvas epidémicas para ver más ejemplos con el paquete incidence2. Dado que ha habido actualizaciones en el paquete incidence2 que no se alinean completamente con la entrada esperada de estimate_R(), hay algunos pasos adicionales menores necesarios. El objeto incidence consiste en un tibble con fechas y sus respectivos recuentos de casos. Usamos complete() de tidyr para asegurarnos que se incluyen todas las fechas (incluso las que no tienen casos), y luego rename() las columnas para alinearlas con lo que espera estimate_R() en un paso posterior.\n\n## obtener la incidencia a partir de la fecha de inicio\ncases &lt;- incidence2::incidence(linelist, date_index = \"date_onset\") %&gt;% # obtiene el número de casos por día\n  tidyr::complete(date_index = seq.Date(                              # asegura que todas las fechas están representadas\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %&gt;%                                       # convierte los recuentos NA en 0\n  rename(I = count,                                                   # renombra a los nombres esperados por estimateR\n         dates = date_index)\n\nEl paquete proporciona varias opciones para especificar el intervalo en serie, cuyos detalles se proporcionan en la documentación en ?estimate_R. Aquí cubriremos dos de ellas.\n\nUtilizando estimaciones de intervalos de serie de la literatura\nUtilizando la opción method = \"parametric_si\", podemos especificar manualmente la media y la desviación estándar del intervalo en serie en un objeto config creado con la función make_config. Utilizamos una media y una desviación estándar de 12,0 y 5,2, respectivamente, definidas en este documento:\n\n## definir config\nconfig_lit &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\n\nEntonces podemos estimar Rt con la función estimate_R:\n\ncases &lt;- cases %&gt;% \n     filter(!is.na(date))\n#create a dataframe for the function estimate_R()\ncases_incidence &lt;- data.frame(dates = seq.Date(from = min(cases$dates),\n                               to = max(cases$dates), \n                               by = 1))\ncases_incidence &lt;- left_join(cases_incidence, cases) %&gt;% \n     select(dates, I) %&gt;% \n     mutate(I = ifelse(is.na(I), 0, I))\n\nJoining with `by = join_by(dates)`\n\nepiestim_res_lit &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_lit\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n\ny trazar un resumen de los resultados:\n\nplot(epiestim_res_lit)\n\n\n\n\n\n\n\n\n\n\nUtilización de estimaciones de intervalos de serie a partir de los datos\nComo tenemos datos sobre las fechas de inicio de los síntomas y los vínculos de transmisión, también podemos estimar el intervalo de serie a partir de linelist calculando el retraso entre las fechas de inicio de los pares infector-infectado. Como hicimos en la sección EpiNow2, utilizaremos la función get_pairwise del paquete epicontacts, que nos permite calcular las diferencias por pares de las propiedades de linelist entre los pares de transmisión. Primero creamos un objeto epicontacts (ver la página de cadenas de transmisión para más detalles):\n\n## generar contactos\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## generar objeto epicontactos\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nA continuación, ajustamos la diferencia de fechas de inicio entre los pares de transmisión, calculada mediante get_pairwise, a una distribución gamma. Utilizamos el práctico fit_disc_gamma del paquete epitrix para este procedimiento de ajuste, ya que necesitamos una distribución discreta.\n\n## estimar el intervalo en serie gamma\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\nA continuación, pasamos esta información al objeto config, ejecutamos de nuevo EpiEstim y trazamos los resultados:\n\n## definir config\nconfig_emp &lt;- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## ejecutar epiestim\nepiestim_res_emp &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_emp\n)\n\nDefault config will estimate R on weekly sliding windows.\n    To change this change the t_start and t_end arguments. \n\n## gráfico de resultados\nplot(epiestim_res_emp)\n\n\n\n\n\n\n\n\n\n\nEspecificación de las ventanas de tiempo de estimación\nEstas opciones por defecto proporcionarán una estimación deslizante semanal y podrían actuar como una advertencia de que está estimando Rt demasiado pronto en el brote para una estimación precisa. Puedes cambiar esto estableciendo una fecha de inicio posterior para la estimación, como se muestra a continuación. Lamentablemente, EpiEstim sólo proporciona una forma muy tosca de especificar estos tiempos de estimación, ya que tiene que proporcionar un vector de enteros que se refieran a las fechas de inicio y fin de cada ventana temporal.\n\n## definir un vector de fechas a partir del 1 de junio\nstart_dates &lt;- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %&gt;%\n  ## restar la fecha de inicio para convertirla en numérica\n  `-`(min(cases$dates)) %&gt;%\n  ## convertir a entero\n  as.integer()\n\n## añadir seis días para una ventana deslizante de una semana\nend_dates &lt;- start_dates + 6\n  \n## definir config\nconfig_partial &lt;- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n\nAhora volvemos a ejecutar EpiEstim y podemos ver que las estimaciones sólo comienzan a partir de junio:\n\n## ejecutar epiestim\nepiestim_res_partial &lt;- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## gráfico de resultados\nplot(epiestim_res_partial)\n\n\n\n\n\n\n\n\n\n\nAnálisis de los resultados\nSe puede acceder a los principales resultados a través de $R. Como ejemplo, crearemos un gráfico de Rt y una medida de “potencial de transmisión” dada por el producto de Rt y el número de casos notificados en ese día; esto representa el número esperado de casos en la siguiente generación de infección.\n\n## crear un dataframe ancho para la mediana\ndf_wide &lt;- epiestim_res_lit$R %&gt;%\n  rename_all(clean_labels) %&gt;%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %&gt;%\n  mutate(\n    ## extraer la fecha mediana de t_start y t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %&gt;%\n  ## fusionar los datos de incidencia diaria\n  left_join(cases, \"dates\") %&gt;%\n  ## calcular el riesgo en todas las estimaciones de r\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %&gt;%\n  ## separar las estimaciones de r y las estimaciones de riesgo\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %&gt;%\n  ## asignar niveles de factor\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## crear un dataframe largo a partir de los cuantiles\ndf_long &lt;- df_wide %&gt;%\n  select(-variable, -median) %&gt;%\n  ## seperate r/risk estimates and quantile levels\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %&gt;%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## realizar gráfico\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## usar label_parsed para permitir el subíndice label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## definir manualmente la transparencia de los cuantiles\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modelización de epidemias</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.es.html#projecting-incidence",
    "href": "new_pages/epidemic_models.es.html#projecting-incidence",
    "title": "24  Modelización de epidemias",
    "section": "24.4 Proyección de la incidencia",
    "text": "24.4 Proyección de la incidencia\n\nEpiNow2\nAdemás de la estimación de Rt, EpiNow2 también admite la previsión de Rt y las proyecciones del número de casos mediante la integración con el paquete EpiSoon por debajo. Todo lo que hay que hacer es especificar el argumento de horizon en la llamada a la función epinow, indicando cuántos días se quiere proyectar en el futuro; véase EpiNow2 en la sección “Estimación de Rt” para obtener detalles sobre cómo poner en marcha EpiNow2. En esta sección, sólo vamos a trazar los resultados de ese análisis, almacenados en el objeto epinow_res.\n\n## definir la fecha mínima para el gráfico\nmin_date &lt;- as.Date(\"2015-03-01\")\n\n## extraer las estimaciones resumen\nestimates &lt;-  as_tibble(epinow_res$estimates$summarised)\n\n## extraer datos crudos sobre la incidencia de casos\nobservations &lt;- as_tibble(epinow_res$estimates$observations) %&gt;%\n  filter(date &gt; min_date)\n\n## extraer estimaciones previstas del número de casos\ndf_wide &lt;- estimates %&gt;%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date &gt; min_date\n  )\n\n## convertir a un formato largo para el trazado de cuantiles\ndf_long &lt;- df_wide %&gt;%\n  ## aquí emparejamos cuantiles coincidentes (por ejemplo, lower_90 con upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## hacer el gráfico\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## definir manualmente la transparencia de los cuantiles\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\nProyecciones\nEl paquete projections desarrollado por RECON hace que sea muy fácil hacer previsiones de incidencia a corto plazo, requiriendo sólo el conocimiento del número de reproducción efectivo Rt y el intervalo serial. Aquí cubriremos cómo utilizar las estimaciones del intervalo de serie de la literatura y cómo utilizar nuestras propias estimaciones de linelist.\n\nUtilizando estimaciones de intervalos de serie de la literatura\nLas proyecciones requieren una distribución de intervalos seriales discretizados del tipo distcrete del paquete distcrete. Utilizaremos una distribución gamma con una media de 12,0 y una desviación estándar de 5,2 definida en este documento. Para convertir estos valores en los parámetros de forma y escala necesarios para una distribución gamma, utilizaremos la función gamma_mucv2shapescale del paquete epitrix.\n\n## obtener parámetros de forma y escala a partir de la media mu y el coeficiente de\n## variación (por ejemplo, la relación entre la desviación estándar y la media)\nshapescale &lt;- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## crear un objeto discreto\nserial_interval_lit &lt;- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n\nAquí tenemos una comprobación rápida para asegurarnos que el intervalo de la serie parece correcto. Accedemos a la densidad de la distribución gamma que acabamos de definir mediante $d, lo que equivale a llamar a dgamma:\n\n## comprobar que el intervalo de serie parece correcto\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\n\n\nUtilización de estimaciones de intervalos de serie a partir de los datos\nComo tenemos datos sobre las fechas de inicio de los síntomas y los vínculos de transmisión, también podemos estimar el intervalo de serie a partir de linelist calculando el retraso entre las fechas de inicio de los pares infector-infectado. Como hicimos en la sección EpiNow2, utilizaremos la función get_pairwise del paquete epicontacts, que nos permite calcular las diferencias por pares de las propiedades de linelist entre los pares de transmisión. Primero creamos un objeto epicontacts (ver la página de cadenas de transmisión para más detalles):\n\n## generar contactos\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %&gt;%\n  drop_na()\n\n## generar el objeto epicontacts\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n\nA continuación, ajustamos la diferencia de fechas de inicio entre los pares de transmisión, calculada mediante get_pairwise, a una distribución gamma. Utilizamos el práctico fit_disc_gamma del paquete epitrix para este procedimiento de ajuste, ya que necesitamos una distribución discreta.\n\n## estimar intervalo de serie gamma\nserial_interval &lt;- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspeccionar la estimación\nserial_interval[c(\"mu\", \"sd\")]\n\n$mu\n[1] 11.51047\n\n$sd\n[1] 7.696056\n\n\n\n\nProyección de la incidencia\nPara proyectar la incidencia futura, todavía tenemos que proporcionar la incidencia histórica en forma de un objeto de incidence, así como una muestra de valores de Rt plausibles. Generaremos estos valores utilizando las estimaciones de Rt generadas por EpiEstim en la sección anterior (en “Estimación de Rt”) y almacenadas en el objeto epiestim_res_emp. En el código siguiente, extraemos las estimaciones de la media y la desviación estándar de Rt para la última ventana temporal del brote (utilizando la función tail para acceder al último elemento de un vector), y simulamos 1000 valores a partir de una distribución gamma utilizando rgamma. También puedes proporcionar un vector propio de valores de Rt que desees utilizar para las proyecciones a futuro.\n\n## crear un objeto de incidencia a partir de las fechas de inicio\ninc &lt;- incidence::incidence(linelist$date_onset)\n\n256 missing observations were removed.\n\n## extraer valores plausibles de r a partir de la estimación más reciente\nmean_r &lt;- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r &lt;- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale &lt;- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r &lt;- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## comprobar la distribución\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nA continuación, utilizamos la función project() para realizar la previsión real. Especificamos para cuántos días queremos proyectar mediante los argumentos n_days, y especificamos el número de simulaciones utilizando el argumento n_sim.\n\n## hacer la proyección\nproj &lt;- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n\nA continuación, podemos trazar fácilmente la incidencia y las proyecciones utilizando las funciones plot() y add_projections(). Podemos fácilmente subconjuntar el objeto de incidencia para mostrar sólo los casos más recientes utilizando el operador de corchetes.\n\n## gráfica de incidencia y proyecciones\nplot(inc[inc$dates &gt; as.Date(\"2015-03-01\")]) %&gt;%\n  add_projections(proj)\n\n\n\n\n\n\n\n\nTambién puedes extraer fácilmente las estimaciones brutas del número de casos diarios convirtiendo la salida en un dataframe.\n\n## convertir a dataframe para datos crudos\nproj_df &lt;- as.data.frame(proj)\nproj_df",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modelización de epidemias</span>"
    ]
  },
  {
    "objectID": "new_pages/epidemic_models.es.html#resources-17",
    "href": "new_pages/epidemic_models.es.html#resources-17",
    "title": "24  Modelización de epidemias",
    "section": "24.5 Recursos",
    "text": "24.5 Recursos\n\nAquí está el documento que describe la metodología implementada en EpiEstim.\nAquí está el documento que describe la metodología implementada en EpiNow2.\nAquí hay un documento que describe varias consideraciones metodológicas y prácticas para estimar el Rt.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Modelización de epidemias</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html",
    "href": "new_pages/contact_tracing.es.html",
    "title": "25  Rastreo de contactos",
    "section": "",
    "text": "25.1 Preparation",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html#preparation-16",
    "href": "new_pages/contact_tracing.es.html#preparation-16",
    "title": "25  Rastreo de contactos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,          # importación de datos  \n  here,         # rutas relativas de archivos  \n  janitor,      # limpieza de datos y tablas\n  lubridate,    # trabajar con fechas\n  epikit,       # función age_categories()\n  apyramid,     # pirámides de edad\n  tidyverse,    # manipulación y visualización de datos\n  RColorBrewer, # paletas de colores\n  formattable,  # tablas de fantasía\n  kableExtra    # formateo de tablas\n)\n\n\n\nImportar datos\nImportaremos conjuntos de datos de muestra de contactos y de su “seguimiento”. Estos datos se han recuperado y desanidado de la API Go.Data y se han almacenado como archivos “.rds”.\nPuedes descargar todos los datos de ejemplo de este manual en la página de descarga de manuales y datos.\nSi deseas descargar los datos de seguimiento de contactos de ejemplo específicos de esta página, utiliza los tres enlaces de descarga que aparecen a continuación:\nClica para descargar los datos de casos de la investigación (archivo .rds)\nClica para descargar los datos del registro de contactos (archivo .rds)\nClica para descargar los datos de seguimiento de los contactos (archivo .rds)\n\n\n\nEn su formato original los archivos descargables, reflejan los datos proporcionados por la API de Go.Data (puedes aprender sobre las API aquí). A modo de ejemplo, aquí limpiaremos los datos para que sean más fáciles de leer en esta página. Si estás utilizando una instancia de Go.Data, puedes ver las instrucciones completas sobre cómo recuperar sus datos aquí.\nA continuación, los conjuntos de datos se importan utilizando la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos. Utilizamos here() para especificar la ruta del archivo - debes escribir la ruta del archivo específica de tu ordenador. A continuación, utilizamos select() para seleccionar sólo ciertas columnas de los datos, para simplificar la demostración.\n\nDatos de casos\nEstos datos son una tabla de los casos, y la información sobre ellos.\n\ncases &lt;- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %&gt;% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)\n\nAquí están los casos nrow(cases):\n\n\n\n\n\n\n\n\nDatos de contactos\nEstos datos son una tabla de todos los contactos e información sobre ellos. De nuevo, proporciona tu propia ruta de acceso al archivo. Después de la importación, realizamos algunos pasos preliminares de limpieza de datos que incluyen:\n\nEstablecer age_class como factor e invertir el orden de los niveles para que las edades más jóvenes sean las primeras\nSeleccionar sólo una columna determinada, renombrando una de ellas\nAsignar artificialmente a “Djembe” las filas a las que les falta el nivel 2 de administración, para mejorar la claridad de algunas visualizaciones de ejemplo\n\n\ncontacts &lt;- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %&gt;% \n  mutate(age_class = forcats::fct_rev(age_class)) %&gt;% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %&gt;% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))\n\nAquí están las filas de los datos de contactos (nrow(contacts)):\n\n\n\n\n\n\n\n\nDatos de seguimiento\nEstos datos son registros de las interacciones de “seguimiento” con los contactos. Se supone que cada contacto tiene un encuentro diario durante los 14 días siguientes a su exposición.\nImportamos y realizamos algunos pasos de limpieza. Seleccionamos ciertas columnas y también convertimos una columna de caracteres a todos los valores en minúsculas.\n\nfollowups &lt;- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %&gt;% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %&gt;% \n  mutate(followup_status = str_to_lower(followup_status))\n\nAquí están las primeras 50 filas de followups (cada fila es una interacción de seguimiento, con el estado del resultado en la columna followup_status):\n\n\n\n\n\n\n\n\nDatos de las relaciones\nAquí importamos datos que muestran la relación entre casos y contactos. Seleccionamos cierta columna para mostrarlos.\n\nrelationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)\n\nA continuación se muestran las primeras 50 filas de los datos de relaciones (relationships), cuyos registros son todas las relaciones entre casos y contactos.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html#descriptive-analyses",
    "href": "new_pages/contact_tracing.es.html#descriptive-analyses",
    "title": "25  Rastreo de contactos",
    "section": "25.2 Análisis descriptivo",
    "text": "25.2 Análisis descriptivo\nPuedes utilizar las técnicas tratadas en otras páginas de este manual para realizar análisis descriptivos de los casos, contactos y sus relaciones. A continuación se ofrecen algunos ejemplos.\n\nDatos demográficos\nComo se muestra en la página dedicada a las pirámides demográficas, se puede visualizar la distribución por edades y por sexos (aquí utilizamos el paquete apyramid).\n\nEdad y sexo de los contactos\nLa pirámide que se muestra a continuación compara la distribución de la edad de los contactos, por género. Observa que los contactos a los que les falta la edad se incluyen en su propia barra en la parte superior. Puedes cambiar este comportamiento por defecto, pero entonces considera listar el número que falta en una leyenda.\n\napyramid::age_pyramid(\n  data = contacts,                                   # utilizar los datos de contactos\n  age_group = \"age_class\",                           # columna de edad categórica\n  split_by = \"gender\") +                             # género para las mitades de la pirámide\n  labs(\n    fill = \"Gender\",                                 # título de la leyenda\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # título del gráfico\n  theme_minimal()                                    # fondo simple\n\n\n\n\n\n\n\n\nCon la estructura de datos Go.Data, los datos relationships contienen las edades tanto de los casos como de los contactos, por lo que podrías utilizar ese conjunto de datos y crear una pirámide de edades que muestre las diferencias entre estos dos grupos de personas. El dataframe relationships será mutado para transformar las columnas numéricas de edad en categorías (véase la página de limpieza de datos y funciones básicas). También pivotamos el dataframe a largo para facilitar el trazado con ggplot2 (ver Pivotar datos).\n\nrelation_age &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  transmute(                              # transmute es como mutate() pero elimina todas las demás columnas no mencionadas\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %&gt;% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivotar largo\n\n\nrelation_age\n\n# A tibble: 200 × 2\n   category         age_class\n   &lt;chr&gt;            &lt;fct&gt;    \n 1 source_age_class 80+      \n 2 target_age_class 15-19    \n 3 source_age_class &lt;NA&gt;     \n 4 target_age_class 50-54    \n 5 source_age_class &lt;NA&gt;     \n 6 target_age_class 20-24    \n 7 source_age_class 30-34    \n 8 target_age_class 45-49    \n 9 source_age_class 40-44    \n10 target_age_class 30-34    \n# ℹ 190 more rows\n\n\nAhora podemos representar este conjunto de datos transformado con age_pyramid() como antes, pero sustituyendo gender con la category (contacto, o caso).\n\napyramid::age_pyramid(\n  data = relation_age,                               # utilizar los datos de relación modificados\n  age_group = \"age_class\",                           # columna de edad categórica\n  split_by = \"category\") +                           # por casos y contactos\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # para especificar colores Y etiquetas\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # título de la leyenda\n    title = \"Age/Sex Pyramid of COVID-19 contacts and cases\")+ # título del gráfico\n  theme_minimal()                                              # fondo simple\n\n\n\n\n\n\n\n\nTambién podemos ver otras características como el desglose profesional (por ejemplo, en forma de gráfico circular).\n\n# Limpiar los datos y obtener los recuentos por ocupación\nocc_plot_data &lt;- cases %&gt;% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # convertir en categoría los valores faltantes NA\n         occupation = forcats::fct_infreq(occupation)) %&gt;%   # ordenar los niveles de los factores por orden de frecuencia\n  count(occupation)                                          # obtener los recuentos por ocupación\n  \n# Hacer un gráfico de tarta\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Known occupations of COVID-19 cases\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nContactos por caso\nEl número de contactos por caso puede ser una métrica importante para evaluar la calidad de la enumeración de los contactos y la conformidad de la población con la respuesta de salud pública.\nDependiendo de la estructura de datos, esto puede evaluarse con un juego de datos que contenga todos los casos y contactos. En el conjunto de datos de Go.Data, los vínculos entre los casos (“fuentes”) y los contactos (“objetivos”) se almacenan en relationships.\nEn este conjunto de datos, cada fila es un contacto, y el caso de origen aparece en la fila. No hay contactos que tengan relaciones con múltiples casos, pero si esto existiese, puede ser necesario tenerlos en cuenta antes de representarlo (¡y explorarlos también!).\nComenzamos contando el número de filas (contactos) por caso de origen. Esto se guarda como un dataframe.\n\ncontacts_per_case &lt;- relationships %&gt;% \n  count(source_visualid)\n\ncontacts_per_case\n\n   source_visualid  n\n1   CASE-2020-0001 13\n2   CASE-2020-0002  5\n3   CASE-2020-0003  2\n4   CASE-2020-0004  4\n5   CASE-2020-0005  5\n6   CASE-2020-0006  3\n7   CASE-2020-0008  3\n8   CASE-2020-0009  3\n9   CASE-2020-0010  3\n10  CASE-2020-0012  3\n11  CASE-2020-0013  5\n12  CASE-2020-0014  3\n13  CASE-2020-0016  3\n14  CASE-2020-0018  4\n15  CASE-2020-0022  3\n16  CASE-2020-0023  4\n17  CASE-2020-0030  3\n18  CASE-2020-0031  3\n19  CASE-2020-0034  4\n20  CASE-2020-0036  1\n21  CASE-2020-0037  3\n22  CASE-2020-0045  3\n23            &lt;NA&gt; 17\n\n\nUtilizamos geom_histogram() para trazar estos datos como un histograma.\n\nggplot(data = contacts_per_case)+        # comenzar con el dataframe de recuento creado anteriormente\n  geom_histogram(mapping = aes(x = n))+  # imprimir histograma del número de contactos por caso\n  scale_y_continuous(expand = c(0,0))+   # eliminar el exceso de espacio por debajo de 0 en el eje y\n  theme_light()+                         # simplificar el fondo\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html#contact-follow-up",
    "href": "new_pages/contact_tracing.es.html#contact-follow-up",
    "title": "25  Rastreo de contactos",
    "section": "25.3 Seguimiento de contactos",
    "text": "25.3 Seguimiento de contactos\nLos datos de rastreo de contactos suelen contener datos de “seguimiento”, que registran los resultados de los controles diarios de los síntomas de las personas en cuarentena. El análisis de estos datos puede servir de base para la estrategia de respuesta e identificar a los contactos con riesgo de pérdida de seguimiento o con riesgo de desarrollar la enfermedad.\n\nLimpieza de datos\nEstos datos pueden existir en una variedad de formatos. Pueden existir como una hoja de Excel de formato “ancho” con una fila por contacto y una columna por “día” de seguimiento. Consulta Pivotar datos para ver las descripciones de los datos “largos” y “anchos” y cómo pivotar los datos anchos o largos.\nEn nuestro ejemplo de Go.Data, estos datos se almacenan en el dataframe followups, que tiene un formato “largo” con una fila por interacción de seguimiento. Las primeras 50 filas tienen este aspecto:\n\n\n\n\n\n\nPRECAUCIÓN: Ten cuidado con los duplicados al tratar los datos de seguimiento, ya que podría haber varios seguimientos erróneos en el mismo día para un contacto determinado. Tal vez parezca un error, pero refleja la realidad: por ejemplo, un rastreador de contactos podría enviar un formulario de seguimiento a primera hora del día cuando no pudo contactar con el contacto, y enviar un segundo formulario cuando se le pudo contactar más tarde. Dependerá del contexto operativo la forma en que desees gestionar los duplicados, pero asegúrate de documentar claramente tu enfoque. \nVeamos cuántos casos de filas “duplicadas” tenemos:\n\nfollowups %&gt;% \n  count(contact_id, date_of_followup) %&gt;%   # obtiene contact_days únicos\n  filter(n &gt; 1)                             # ver los registros en los que el recuento es superior a 1  \n\n  contact_id date_of_followup n\n1       &lt;NA&gt;       2020-09-03 2\n2       &lt;NA&gt;       2020-09-04 2\n3       &lt;NA&gt;       2020-09-05 2\n\n\nEn nuestros datos de ejemplo, los únicos registros a los que se aplica esto son los que carecen de ID. Podemos eliminarlos. Pero, a efectos de demostración, mostraremos los pasos para la eliminación de la duplicación de modo que sólo haya un registro de seguimiento por persona y por día. Para más detalles, consulta la página de De-duplicación. Asumiremos que el registro de encuentro más reciente es el correcto. También aprovechamos la oportunidad para limpiar la columna followup_number (el “día” de seguimiento que debe ir de 1 a 14).\n\nfollowups_clean &lt;- followups %&gt;%\n  \n  # De-duplicar\n  group_by(contact_id, date_of_followup) %&gt;%        # agrupa filas por día de contacto\n  arrange(contact_id, desc(date_of_followup)) %&gt;%   # ordena filas, por contacto-día, por fecha de seguimiento (la más reciente arriba)\n  slice_head() %&gt;%                                  # mantiene sólo la primera fila por identificador único de contacto  \n  ungroup() %&gt;% \n  \n  # Otras limpiezas\n  mutate(followup_number = replace(followup_number, followup_number &gt; 14, NA)) %&gt;% # limpia datos erróneos\n  drop_na(contact_id)                               # elimina las filas en las que falta contact_id\n\nPara cada encuentro de seguimiento, tenemos un estado de seguimiento (como si el encuentro se produjo y, si es así, el contacto tuvo síntomas o no). Para ver todos los valores podemos ejecutar un tabyl() rápido (de janitor) o table() (de R base) (ver Tablas descriptivas) por followup_status para ver la frecuencia de cada uno de los resultados.\nEn este conjunto de datos, “seen_not_ok” significa “visto con síntomas”, y “seen_ok” significa “visto sin síntomas”.\n\nfollowups_clean %&gt;% \n  tabyl(followup_status)\n\n followup_status   n    percent\n          missed  10 0.02325581\n   not_attempted   5 0.01162791\n   not_performed 319 0.74186047\n     seen_not_ok   6 0.01395349\n         seen_ok  90 0.20930233\n\n\n\n\nGráfica en el tiempo\nComo los datos de las fechas son continuos, utilizaremos un histograma para representarlos con date_of_followup asignado al eje-x. Podemos conseguir un histograma “apilado” especificando un argumento fill = dentro de aes(), que asignamos a la columna followup_status. En consecuencia, se puede establecer el título de la leyenda utilizando el argumento fill = de labs().\nPodemos ver que los contactos se identificaron en oleadas (presumiblemente correspondientes a las oleadas epidémicas de casos), y que la finalización del seguimiento no parece haber mejorado a lo largo de la epidemia.\n\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # muestra todos los niveles del factor (followup_status) en la leyenda, incluso los no utilizados\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # Subtítulo dinámico\n\n\n\n\n\n\n\n\nPRECAUCIÓN: Si estás preparando muchos gráficos (por ejemplo, para múltiples jurisdicciones) querrás que las leyendas aparezcan de forma idéntica incluso con diferentes niveles de finalización o composición de los datos. Puede haber gráficos para los cuales no todos los estados de seguimiento están presentes, pero todavía quieres que esas categorías aparezcan en las leyendas. En ggplot (como arriba), puedes especificar el argumento drop = FALSE de scale_fill_discrete(). En las tablas, utiliza tabyl() que muestra los recuentos de todos los niveles de los factores, o si utilizas count() de dplyr añade el argumento .drop = FALSE para incluir los recuentos de todos los niveles de los factores.\n\n\nSeguimiento individual diario\nSi tu brote es lo suficientemente pequeño, es posible que quieras mirar cada contacto individualmente y ver su estado a lo largo del seguimiento. Afortunadamente, este conjunto de datos de seguimiento ya contiene una columna con el “número” de día de seguimiento (1-14). Si no existe en tus datos, puedes crearla calculando la diferencia entre la fecha de encuentro y la fecha en la que el seguimiento debía comenzar para el contacto.\nUn mecanismo de visualización conveniente (si el número de casos no es demasiado grande) puede ser un gráfico de calor, hecho con geom_tile(). Mira más detalles en la página Gráficos de calor.\n\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # Cuadrículas grises\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))\n\n\n\n\n\n\n\n\n\n\nAnalizar por grupos\nTal vez estos datos de seguimiento se consulten diaria o semanalmente para la toma de decisiones operativas. Es posible que desees desgloses más significativos por zona geográfica o por equipo de seguimiento de contactos. Podemos hacerlo ajustando las columnas proporcionadas a group_by().\n\nplot_by_region &lt;- followups_clean %&gt;%                                        # comienza con los datos de seguimiento\n  count(admin_1_name, admin_2_name, followup_status) %&gt;%   # obtiene los recuentos por región-status único (crea la columna 'n' con los recuentos)\n  \n  # comenzar ggplot()\n  ggplot(                                         # comienza ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # reordena los niveles del factor admin por los valores numéricos de la columna 'n'\n                  y = n,                            # altura de las barras de la columna 'n'\n                  fill = followup_status,           # colorear las barras apiladas según su estado\n                  label = n))+                      # para pasar a geom_label()                \n  geom_col()+                                     # barras apiladas, asignación heredada de arriba  \n  geom_text(                                      # añade texto, asignación heredada de arriba\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # simplifica el fondo\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduce facetas \n\nplot_by_region",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html#kpi-tables",
    "href": "new_pages/contact_tracing.es.html#kpi-tables",
    "title": "25  Rastreo de contactos",
    "section": "25.4 Tablas KPI",
    "text": "25.4 Tablas KPI\nHay una serie de Indicadores Clave de Rendimiento (KPI) que pueden calcularse y seguirse a distintos niveles de desagregación y a lo largo de diferentes períodos de tiempo para supervisar el rendimiento del rastreo de contactos. Una vez que se tienen los cálculos y el formato básico de la tabla, es bastante fácil cambiar los diferentes KPI.\nExisten numerosas fuentes de KPI de rastreo de contactos, como ésta de ResolveToSaveLives.org. La mayor parte del trabajo consistirá en recorrer la estructura de datos y pensar en todos los criterios de inclusión/exclusión. A continuación mostramos algunos ejemplos, utilizando la estructura de metadatos de Go.Data:\n\n\n\n\n\n\n\n\n\nCategoría\nIndicador\nNumerador Go.Data\nDenominador Go.Data\n\n\n\n\nIndicador de proceso - Velocidad de rastreo de contactos\n% de casos entrevistados y aislados en las 24 horas siguientes a la notificación del caso\nCOUNT OF case_id WHERE (date_of_reporting - date_of_data_entry) &lt; 1 day AND (isolation_startdate - date_of_data_entry) &lt; 1 day\nCOUNT OF case_id\n\n\nIndicador de proceso - Velocidad de rastreo de contactos\n% de contactos notificados y puestos en cuarentena en las 24 horas siguientes a la solicitud\nCOUNT OF contact_id WHERE followup_status == “SEEN_NOT_OK” OR “SEEN_OK” AND date_of_followup - date_of_reporting &lt; 1 day\nCOUNT OF contact_id\n\n\nIndicador de proceso - Completitud de las pruebas\n% de nuevos casos sintomáticos examinados y entrevistados en los 3 días siguientes al inicio de los síntomas\nCOUNT OF case_id WHERE (date_of_reporting - date_of_onset) &lt; =3 days\nCOUNT OF case_id\n\n\nIndicador de resultado - Global\n% de nuevos casos entre la lista de contactos existente\nCOUNT OF case_id WHERE was_contact == “TRUE”\nCOUNT OF case_id\n\n\n\nA continuación veremos un ejercicio de ejemplo para crear una bonita tabla visual para mostrar el seguimiento de los contactos en las áreas de administración. Al final, lo haremos apto para la presentación con el paquete formattable (pero podrías usar otros paquetes como flextable - ver Tablas para presentaciones).\nLa forma de crear una tabla como ésta dependerá de la estructura de los datos de seguimiento de contactos. Utiliza la página de tablas descriptivas para aprender a resumir los datos utilizando las funciones de dplyr.\nCrearemos una tabla que será dinámica y cambiará a medida que cambien los datos. Para que los resultados sean interesantes, estableceremos una report_date que nos permita simular la ejecución de la tabla en un día determinado (elegimos el 10 de junio de 2020). Los datos se filtran por esa fecha.\n\n# Set \"Report date\" to simulate running the report with data \"as of\" this date\nreport_date &lt;- as.Date(\"2020-06-10\")\n\n# Create follow-up data to reflect the report date.\ntable_data &lt;- followups_clean %&gt;% \n  filter(date_of_followup &lt;= report_date)\n\nAhora, basándonos en nuestra estructura de datos, haremos lo siguiente:\n\nComienza con los datos de followups y resúmelos para contener, para cada contacto único:\n\n\nLa fecha del último registro (sin importar el estado del encuentro)\nLa fecha del último encuentro en el que el contacto fue “visto”\nEl estado del encuentro en ese último encuentro “visto” (por ejemplo, con síntomas, sin síntomas)\n\n\nUniremos estos datos a los de los contactos, que contienen otra información como el estado general del contacto, la fecha de la última exposición a un caso, etc. También calcularemos las métricas de interés para cada contacto, como los días desde la última exposición\nAgrupamos los datos de contacto mejorados por región geográfica (`admin_2_name) y calculamos las estadísticas resumidas por región\nPor último, damos un buen formato a la tabla para su presentación\n\nPrimero resumimos los datos de seguimiento para obtener la información de interés:\n\nfollowup_info &lt;- table_data %&gt;% \n  group_by(contact_id) %&gt;% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %&gt;% \n  ungroup()\n\nAsí es como se ven estos datos:\n\n\n\n\n\n\nAhora añadiremos esta información a los datos de contacts y calcularemos algunas columnas adicionales.\n\ncontacts_info &lt;- followup_info %&gt;% \n  right_join(contacts, by = \"contact_id\") %&gt;% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\n\nAsí es como se ven estos datos. Observa la columna contacts a la derecha, y la nueva columna calculada en el extremo derecho.\n\n\n\n\n\n\nA continuación, resumimos los datos de los contactos por región, para conseguir un dataframe conciso de columnas de estadísticas resumidas.\n\ncontacts_table &lt;- contacts_info %&gt;% \n  \n  group_by(`Admin 2` = admin_2_name) %&gt;%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure &lt; 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure &gt;= 8 & days_since_exposure &lt; 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen &gt;= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %&gt;% \n    \n  arrange(desc(`Registered contacts`))\n\n\n\n\n\n\n\nY ahora aplicamos el estilo de los paquetes formattable y knitr, incluyendo una nota a pie de página que muestra la fecha “a partir de”.\n\ncontacts_table %&gt;%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %&gt;%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %&gt;%\n  kable_styling(\"hover\", full_width = FALSE) %&gt;%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %&gt;% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf contacts currently under follow up\n\n\nStatus of last visit\n\n\n\nAdmin 2\nRegistered contacts\nActive contacts\nIn first week\nIn second week\nBecame case\nLost to follow up\nNever seen\nFollowed up - signs\nFollowed up - no signs\nNot Followed up\n\n\n\n\nDjembe \n59\n30\n44\n0\n2\n15\n22\n0\n0\n0\n\n\nTrumpet\n3\n1\n3\n0\n0\n0\n0\n0\n0\n0\n\n\nVenu \n2\n0\n0\n0\n2\n0\n2\n0\n0\n0\n\n\nCongas \n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\nCornet \n1\n0\n1\n0\n1\n0\n1\n0\n0\n0\n\n\n\nNote: \n\n\n\n\n\n\n\n\n\n\n\n\n Data are current to Jun 10 2020",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html#transmission-matrices",
    "href": "new_pages/contact_tracing.es.html#transmission-matrices",
    "title": "25  Rastreo de contactos",
    "section": "25.5 Matrices de transmisión",
    "text": "25.5 Matrices de transmisión\nComo se discutió en la página de Gráficos de calor, puedes crear una matriz de “quién infectó a quién” utilizando geom_tile().\nCuando se crean nuevos contactos, Go.Data almacena esta información de relación en el punto final de la API relationships; y podemos ver las primeras 50 filas de este conjunto de datos a continuación. Esto significa que podemos crear un gráfico de calor con relativamente pocos pasos, dado que cada contacto ya está unido a su caso de origen.\n\n\n\n\n\n\nAl igual que en el caso de la pirámide de edad que compara casos y contactos, podemos seleccionar las pocas variables que necesitamos y crear columnas con agrupaciones categóricas de edad tanto para las fuentes (casos) como para los objetivos (contactos).\n\nheatmap_ages &lt;- relationships %&gt;% \n  select(source_age, target_age) %&gt;% \n  mutate(                              # transmute es como mutate() pero elimina todas las demás columnas\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \n\nComo se ha descrito anteriormente, creamos una tabulación cruzada;\n\ncross_tab &lt;- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab\n\n            target_cases\nsource_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54\n       0-4     0   0     0     0     0     0     0     0     0     1     0\n       5-9     0   0     1     0     0     0     0     1     0     0     0\n       10-14   0   0     0     0     0     0     0     0     0     0     0\n       15-19   0   0     0     0     0     0     0     0     0     0     0\n       20-24   1   1     0     1     2     0     2     1     0     0     0\n       25-29   1   2     0     0     0     0     0     0     0     0     0\n       30-34   0   0     0     0     0     0     0     0     1     1     0\n       35-39   0   2     0     0     0     0     0     0     0     1     0\n       40-44   0   0     0     0     1     0     2     1     0     3     1\n       45-49   1   2     2     0     0     0     3     0     1     0     3\n       50-54   1   2     1     2     0     0     1     0     0     3     4\n       55-59   0   1     0     0     1     1     2     0     0     0     0\n       60-64   0   0     0     0     0     0     0     0     0     0     0\n       65-69   0   0     0     0     0     0     0     0     0     0     0\n       70-74   0   0     0     0     0     0     0     0     0     0     0\n       75-79   0   0     0     0     0     0     0     0     0     0     0\n       80+     1   0     0     2     1     0     0     0     1     0     0\n            target_cases\nsource_cases 55-59 60-64 65-69 70-74 75-79 80+\n       0-4       1     0     0     0     0   0\n       5-9       1     0     0     0     0   0\n       10-14     0     0     0     0     0   0\n       15-19     0     0     0     0     0   0\n       20-24     1     0     0     0     0   1\n       25-29     0     0     0     0     0   0\n       30-34     1     0     0     0     0   0\n       35-39     0     0     0     0     0   0\n       40-44     1     0     0     0     1   1\n       45-49     2     1     0     0     0   1\n       50-54     1     0     1     0     0   1\n       55-59     0     0     0     0     0   0\n       60-64     0     0     0     0     0   0\n       65-69     0     0     0     0     0   0\n       70-74     0     0     0     0     0   0\n       75-79     0     0     0     0     0   0\n       80+       0     0     0     0     0   0\n\n\nconvertimos en formato largo con proporciones;\n\nlong_prop &lt;- data.frame(prop.table(cross_tab))\n\ny creamos un mapa de calor para la edad.\n\nggplot(data = long_prop)+       # utiliza datos largos, con proporciones como Freq\n  geom_tile(                    # visualizarlo en mosaicos\n    aes(\n      x = target_cases,         # el eje-x es la edad de los casos\n      y = source_cases,     # el eje-y es la edad del infector\n      fill = Freq))+            # el color del mosaico es la columna Freq de los datos\n  scale_fill_gradient(          # ajusta el color de relleno de los mosaicos\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # etiquetas\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # título de la leyenda\n  )",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/contact_tracing.es.html#resources-18",
    "href": "new_pages/contact_tracing.es.html#resources-18",
    "title": "25  Rastreo de contactos",
    "section": "25.6 Recursos",
    "text": "25.6 Recursos\nhttps://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting\nhttps://worldhealthorganization.github.io/godata/\nhttps://community-godata.who.int/",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Rastreo de contactos</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html",
    "href": "new_pages/survey_analysis.es.html",
    "title": "26  Análisis de encuestas",
    "section": "",
    "text": "26.1 Resumen\nEsta página muestra el uso de varios paquetes para el análisis de encuestas.\nLa mayoría de los paquetes R de encuestas se basan en el paquete survey para realizar análisis ponderados. Utilizaremos survey, así como srvyr (una envoltura para survey que permite la codificación al estilo tidyverse) y gtsummary (una envoltura para survey que permite obtener tablas listas para su publicación). Aunque el paquete original survey no permite la codificación al estilo tidyverse, tiene la ventaja añadida de permitir modelos lineales generalizados ponderados por la encuesta (que se añadirán a esta página más adelante). También demostraremos el uso de una función del paquete sitrep para crear ponderaciones de muestreo (n.b. este paquete no está todavía en CRAN, pero se puede instalar desde github).\nLa mayor parte de esta página se basa en el trabajo realizado para el proyecto “R4Epis”; para ver el código detallado y las plantillas R-markdown del mismo, consulta la página github de “R4Epis”. Parte del código basado en el paquete de encuestas se basa en las primeras versiones de los estudios de caso de EPIET.\nActualmente, esta página no aborda el cálculo del tamaño de la muestra ni el muestreo. Para una calculadora del tamaño muestral fácil de usar, consulta OpenEpi. La página de conceptos básicos de los SIG del manual tendrá eventualmente una sección sobre muestreo aleatorio espacial, y esta página tendrá eventualmente una sección sobre marcos de muestreo así como cálculos del tamaño de la muestra.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#overview-4",
    "href": "new_pages/survey_analysis.es.html#overview-4",
    "title": "26  Análisis de encuestas",
    "section": "",
    "text": "Datos de encuestas\nTiempo de observación\nPonderación\nObjetos de diseño de la encuesta\nAnálisis descriptivo\nProporciones ponderadas\nTasas ponderadas",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#preparation-17",
    "href": "new_pages/survey_analysis.es.html#preparation-17",
    "title": "26  Análisis de encuestas",
    "section": "26.2 Preparación",
    "text": "26.2 Preparación\n\nPaquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También se pueden cargar paquetes con library() de R base . Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R. Aquí también mostramos el uso de la función p_load_gh() de pacman para instalar y cargar un paquete de github que aún no ha sido publicado en CRAN.\n\n## load packages from CRAN\npacman::p_load(rio,          # Importación de fichero\n               here,         # Localizador de archivos\n               tidyverse,    # gestión de datos + gráficos ggplot2\n               tsibble,      # manejar conjuntos de datos de series temporales\n               survey,       # para funciones de encuesta\n               srvyr,        # paquete dplyr para encuestas\n               gtsummary,    # paquete de encuestas para producir tablas\n               apyramid,     # un paquete dedicado a crear pirámides de edad\n               patchwork,    # para combinar ggplots\n               ggforce       # para gráficos aluviales/sankey\n               ) \n\n\n## load packages from github\n\npacman::p_load_gh(\n  \n  \"r4epi/sitrep\" # para el tiempo de observación / funciones de ponderación\n\n)\n\n\n\nCarga de datos\nEl conjunto de datos de ejemplo utilizado en esta sección:\n\ndatos de encuesta de mortalidad ficticia.\nrecuentos de población ficticios para la zona de la encuesta.\ndiccionario de datos para los datos de la encuesta de mortalidad ficticia.\n\nSe basa en la encuesta pre-aprobada por la junta de revisión ética de MSF OCA. Los datos ficticios se produjeron como parte del proyecto “R4Epis”. Todo ello se basa en los datos recopilados mediante KoboToolbox, un software de recopilación de datos basado en Open Data Kit.\nKobo permite exportar tanto los datos recogidos como el diccionario de datos para ese conjunto de datos. Recomendamos encarecidamente hacer esto, ya que simplifica la limpieza de los datos y es útil para buscar variables/preguntas.\nCONSEJO: El diccionario de datos de Kobo tiene nombres de variables en la columna “name” de la hoja de la encuesta. Los valores posibles para cada variable se especifican en la hoja de opciones. En la hoja de opciones, “name” tiene el valor acortado y las columnas “label::english” y “label::french” tienen las versiones largas correspondientes. Si utilizas la función msf_dict_survey() del paquete epidict para importar un archivo excel del diccionario Kobo, éste se reformulará para que pueda utilizarse fácilmente para recodificar. \nPRECAUCIÓN: El conjunto de datos de ejemplo no es lo mismo que una exportación (ya que en Kobo se exportan los diferentes niveles del cuestionario de forma individual) - Mira la sección de datos de la encuesta más abajo para fusionar los diferentes niveles.\nLos datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.\n\n# importar los datos de la encuesta\nsurvey_data &lt;- rio::import(\"survey_data.xlsx\")\n\n# importar el diccionario en R\nsurvey_dict &lt;- rio::import(\"survey_dict.xlsx\") \n\nMás abajo se muestran las primeras 10 filas de la encuesta\n\n\n\n\n\n\nTambién queremos importar los datos de la población de muestreo para poder elaborar las ponderaciones adecuadas. Estos datos pueden estar en diferentes formatos, sin embargo sugerimos tenerlos como se ve a continuación (esto puede ser simplemente escrito en un Excel).\n\n# importar los datos de población\npopulation &lt;- rio::import(\"population.xlsx\")\n\nA continuación se muestran las 10 primeras filas de la encuesta.\n\n\n\n\n\n\nEn el caso de las encuestas por conglomerados, es posible que desees añadir ponderaciones de la encuesta a nivel de conglomerado. Puedes introducir estos datos como se indica más arriba. Alternativamente, si sólo hay unos pocos recuentos, éstos podrían introducirse como se indica a continuación en un tibble. En cualquier caso, tendrá que tener una columna con un identificador de conglomerado que coincida con los datos de tu encuesta, y otra columna con el número de hogares en cada conglomerado.\n\n## definir el número de hogares en cada cluster\ncluster_counts &lt;- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))\n\n\n\nLimpieza de datos\nA continuación se asegura que la columna de fechas tenga el formato adecuado. Hay varias otras maneras de hacer esto (ver la página Trabajar con fechas para más detalles), sin embargo, usar el diccionario para definir las fechas es rápido y fácil.\nTambién creamos una variable de grupo de edad utilizando la función age_categories() de epikit - véase la sección del manual de limpieza de datos para más detalles. Además, creamos una variable de carácter que define en qué distrito se encuentran las distintas agrupaciones.\nPor último, recodificamos todas las variables sí/no en variables VERDADERO/FALSO, ya que de lo contrario no pueden ser utilizadas por las funciones de proporción de survey.\n\n## seleccionar los nombres de las variables de fecha del diccionario \nDATEVARS &lt;- survey_dict %&gt;% \n  filter(type == \"date\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## filtrar para que coincidan los nombres de las columnas de los datos\n  pull(name) # selecciona vars de fecha\n  \n## cambiar a fechas \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## añadir los que sólo tienen edad en meses a la variable año (dividir por doce)\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## definir variable de grupo de edad\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## create a character variable based off groups of a different variable \nsurvey_data &lt;- survey_data %&gt;% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## seleccionar los nombres de las variables yes/no del diccionario\nYNVARS &lt;- survey_dict %&gt;% \n  filter(type == \"yn\") %&gt;% \n  filter(name %in% names(survey_data)) %&gt;% \n  ## filter to match the column names of your data\n  pull(name) # select yn vars\n  \n## cambiar a fechas \nsurvey_data &lt;- survey_data %&gt;%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(all_of(YNVARS), str_detect, pattern = \"yes\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#survey-data",
    "href": "new_pages/survey_analysis.es.html#survey-data",
    "title": "26  Análisis de encuestas",
    "section": "26.3 Datos de encuestas",
    "text": "26.3 Datos de encuestas\nExisten numerosos diseños de muestreo que pueden utilizarse para las encuestas. Aquí mostraremos el código para: - Estratificado - Conglomerado - Estratificado y conglomerado\nComo se ha descrito anteriormente (dependiendo de cómo se diseñe el cuestionario) los datos de cada nivel se exportarían como unos datos separados desde Kobo. En nuestro ejemplo hay un nivel para los hogares y un nivel para los individuos dentro de esos hogares.\nEstos dos niveles están vinculados por un identificador único. Para unos datos de Kobo, esta variable es “_index” en el nivel del hogar, que coincide con “_parent_index” en el nivel individual. Esto creará nuevas filas para el hogar con cada individuo que coincida, véase la sección del manual sobre unir datos para más detalles.\n\n## unir los datos de individuos y hogares para formar un conjunto de datos completo\nsurvey_data &lt;- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## crear un identificador único combinando los índices de los dos niveles \nsurvey_data &lt;- survey_data %&gt;% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#observation-time",
    "href": "new_pages/survey_analysis.es.html#observation-time",
    "title": "26  Análisis de encuestas",
    "section": "26.4 Tiempo de observación",
    "text": "26.4 Tiempo de observación\nEn el caso de las encuestas de mortalidad, queremos saber cuánto tiempo ha estado presente cada individuo en el lugar para poder calcular una tasa de mortalidad adecuada para nuestro periodo de interés. Esto no es relevante para todas las encuestas, pero en particular para las encuestas de mortalidad es importante, ya que se realizan con frecuencia entre poblaciones móviles o desplazadas.\nPara ello, primero definimos nuestro periodo de interés, también conocido como periodo de recuerdo (es decir, el tiempo sobre el que se pide a los participantes que informen al responder a las preguntas). A continuación, podemos utilizar este periodo para establecer las fechas inadecuadas como ausentes, es decir, si las muertes se notifican fuera del periodo de interés.\n\n## establecer el inicio/fin del periodo de recuperación\n## puede cambiarse a variables de fecha de los datos \n## (por ejemplo, fecha de llegada y fecha del cuestionario)\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end   = as.Date(\"2018-05-01\")\n  )\n\n\n#establecer fechas inapropiadas a NA basado en reglas \n## p.ej. llegadas antes del inicio, salidas después del final\nsurvey_data &lt;- survey_data %&gt;%\n      mutate(\n           arrived_date = if_else(arrived_date &lt; recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date &lt; recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date &gt; recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date &gt; recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n\nEntonces podemos utilizar nuestras variables de fecha para definir las fechas de inicio y fin de cada individuo. Podemos utilizar la función find_start_date() de sitrep para afinar la elección de las fechas y luego utilizarla para calcular la diferencia entre días (persona-tiempo).\nFecha de inicio: Evento de llegada más temprano dentro del período de recogida O bien el inicio del período de recogida (definidas de antemano), o una fecha posterior al inicio de la recogida, si procede (por ejemplo, llegadas o nacimientos)\nFecha de finalización: Evento de salida más temprano dentro del periodo de recogida O bien el final del periodo de recogida, o una fecha anterior al final de la recogida si procede (por ejemplo, salidas, fallecimientos)\n\n## crear nuevas variables para las fechas/causas de inicio y fin\nsurvey_data &lt;- survey_data %&gt;% \n     ## elegir la fecha más temprana introducida en la encuesta\n     ## de nacimientos, llegadas a hogares y llegadas a\n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end   = \"recall_end\",\n                  datecol      = \"startdate\",\n                  datereason   = \"startcause\" \n                 ) %&gt;%\n     ## elegir la fecha más temprana introducida en la encuesta\n     ## de salidas del campamento, fallecimiento y fin del estudio\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end   = \"recall_end\",\n                datecol      = \"enddate\",\n                datereason   = \"endcause\" \n               )\n\n\n## etiquetar los que estaban presentes al inicio/final (excepto nacimientos/muertes)\nsurvey_data &lt;- survey_data %&gt;% \n     mutate(\n       ## rellenar la fecha de inicio para que sea el comienzo del periodo de recuerdo (para los vacíos) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## establecer la causa de inicio como presente al inicio si es igual al periodo de retirada \n       ## a menos que sea igual a la fecha de nacimiento \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## rellenar la fecha final para que sea el final del periodo de retirada (para los que estén vacíos) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## establecer la causa final para que esté presente al final si es igual a recall end \n       ## a menos que sea igual a la fecha de defunción\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Definir el tiempo de observación en días\nsurvey_data &lt;- survey_data %&gt;% \n  mutate(obstime = as.numeric(enddate - startdate))",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#weighting",
    "href": "new_pages/survey_analysis.es.html#weighting",
    "title": "26  Análisis de encuestas",
    "section": "26.5 Ponderación",
    "text": "26.5 Ponderación\nEs importante que elimines las observaciones erróneas antes de añadir los pesos de la encuesta. Por ejemplo, si hay observaciones con tiempo de observación negativo, tendrás que comprobarlas (puedes hacerlo con la función assert_positive_timespan() de sitrep. Otra cosa es si quieres eliminar las filas vacías (por ejemplo, con drop_na(uid)) o eliminar los duplicados (véase la sección del manual sobre De-duplicación para más detalles). También hay que eliminar las que no tienen consentimiento.\nEn este ejemplo, filtramos los casos que queremos eliminar y los almacenamos en un dataframe separado, de forma que podamos describir los que fueron excluidos de la encuesta. A continuación, utilizamos la función anti_join() de dplyr para eliminar estos casos descartados de los datos de nuestra encuesta.\nPELIGRO: No puede haber valores faltantes en la variable de peso, ni en ninguna de las variables relevantes para el diseño de la encuesta (por ejemplo, edad, sexo, estratos o variables de agrupación).\n\n## almacena los casos que abandona para poder describirlos (por ejemplo, no consentir \n## o pueblo/cluster equivocado)\ndropped &lt;- survey_data %&gt;% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## utilizar los casos descartados para eliminar las filas no utilizadas de los datos de la encuesta  \nsurvey_data &lt;- anti_join(survey_data, dropped, by = names(dropped))\n\nComo se ha mencionado anteriormente, demostramos cómo añadir ponderaciones para tres diseños de estudio diferentes (estratificado, conglomerado y conglomerado estratificado). Estos requieren información sobre la población de origen y/o los conglomerados encuestados. Utilizaremos el código de conglomerado estratificado para este ejemplo, pero utiliza el que sea más apropiado para tu diseño de estudio.\n\n# estratificado ------------------------------------------------------------------\n# crear una variable llamada \"surv_weight_strata\"\n# contiene ponderaciones para cada individuo - por grupo de edad, sexo y distrito sanitario\nsurvey_data &lt;- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# obtiene el número de personas de individuos entrevistados por hogar\n# añade una variable con los recuentos de la variable índice del hogar (padre)\nsurvey_data &lt;- survey_data %&gt;%\n  add_count(index, name = \"interviewed\")\n\n\n## crear ponderaciones de clusters\nsurvey_data &lt;- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# estratificado y cluster ------------------------------------------------------\n# crear un peso de encuesta para cluster y estratos\nsurvey_data &lt;- survey_data %&gt;%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#survey-design-objects",
    "href": "new_pages/survey_analysis.es.html#survey-design-objects",
    "title": "26  Análisis de encuestas",
    "section": "26.6 Objetos de diseño de la encuesta",
    "text": "26.6 Objetos de diseño de la encuesta\nCrea un objeto de encuesta de acuerdo con el diseño de tu estudio. Se utiliza de la misma manera que los dataframes para calcular las proporciones ponderadas, etc. Asegúrate que todas las variables necesarias están creadas antes de esto.\nHay cuatro opciones, comenta las que no utilizas: - Aleatorio simple - Estratificado - Conglomerado - Conglomerado estratificado\nPara esta plantilla, supondremos que agrupamos las encuestas en dos estratos distintos (distritos sanitarios A y B). Por lo tanto, para obtener las estimaciones globales necesitamos haber combinado las ponderaciones de los grupos y de los estratos.\nComo se ha mencionado anteriormente, hay dos paquetes disponibles para hacer esto. El clásico es survey y luego hay un paquete envolvente llamado srvyr que hace objetos y funciones amigables con tidyverse. Mostraremos ambos, pero ten en cuenta que la mayor parte del código de este capítulo utilizará objetos basados en srvyr. La única excepción es que el paquete gtsummary sólo acepta objetos de survey.\n\nPaquete survey\nEl paquete survey utiliza efectivamente la codificación de R base, por lo que no es posible utilizar pipes (%&gt;%) u otra sintaxis de dplyr. Con el paquete de survey utilizamos la función svydesign() para definir un objeto de encuesta con clusters, pesos y estratos adecuados.\nNOTA: necesitamos utilizar la tilde (~) delante de las variables, esto es porque el paquete utiliza la sintaxis de R base de asignación de variables basadas en fórmulas.\n\n# aleatorio simple  ---------------------------------------------------------------\nbase_survey_design_simple &lt;- svydesign(ids = ~1, # 1 para cluster sin ids\n                   weights = NULL,               # no se añade peso\n                   strata = NULL,                # el muestreo fue simple (sin estratos)\n                   data = survey_data            # hay que especificar los datos\n                  )\n\n## estratificado  ------------------------------------------------------------------\nbase_survey_design_strata &lt;- svydesign(ids = ~1,  # 1 para cluster sin ids\n                   weights = ~surv_weight_strata, # variable de peso creada anteriormente\n                   strata = ~health_district,     # el muestreo se estratificó por distrito\n                   data = survey_data             # hay que especificar los datos\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster &lt;- svydesign(ids = ~village_name, # ids de cluster\n                   weights = ~surv_weight_cluster,           # variable de peso creada anteriormente\n                   strata = NULL,                            # el muestreo fue simple (sin estratos)\n                   data = survey_data                        # hay que especificar los datos\n                  )\n\n# cluster estratificado  ----------------------------------------------------------\nbase_survey_design &lt;- svydesign(ids = ~village_name,      # ids de cluster\n                   weights = ~surv_weight_cluster_strata, # variable de peso creada anteriormente\n                   strata = ~health_district,             # el muestreo se estratificó por distrito\n                   data = survey_data                     # hay que especificar los datos\n                  )\n\n\n\nPaquete Srvyr\nCon el paquete srvyr podemos utilizar la función as_survey_design(), que tiene los mismos argumentos que la anterior pero permite los pipes (%&gt;%), por lo que no es necesario utilizar la tilde (~).\n\n# aleatorio simple ---------------------------------------------------------------\nsurvey_design_simple &lt;- survey_data %&gt;% \n  as_survey_design(ids = 1, # 1 para cluster sin ids \n                   weights = NULL, # no se añade peso\n                   strata = NULL # el muestreo fue simple (sin estratos)\n                  )\n## estratificado ------------------------------------------------------------------\nsurvey_design_strata &lt;- survey_data %&gt;%\n  as_survey_design(ids = 1, # 1 para cluster sin ids\n                   weights = surv_weight_strata, # variable de peso creada anteriormente\n                   strata = health_district # el muestreo se estratificó por distrito\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # ids de cluster\n                   weights = surv_weight_cluster, # variable de peso creada anteriormente\n                   strata = NULL # el muestreo fue simple (sin estratos)\n                  )\n\n# cluster estratificado ----------------------------------------------------------\nsurvey_design &lt;- survey_data %&gt;%\n  as_survey_design(ids = village_name, # ids de cluster\n                   weights = surv_weight_cluster_strata, # variable de peso creada anteriormente\n                   strata = health_district # el muestreo se estratificó por distrito\n                  )",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#descriptive-analysis-2",
    "href": "new_pages/survey_analysis.es.html#descriptive-analysis-2",
    "title": "26  Análisis de encuestas",
    "section": "26.7 Análisis descriptivo",
    "text": "26.7 Análisis descriptivo\nEl análisis descriptivo básico y la visualización se tratan extensamente en otros capítulos del manual, por lo que no nos detendremos en ellos aquí. Para más detalles, consulta los capítulos sobre tablas descriptivas, pruebas estadísticas, tablas para presentaciones, conceptos básicos de ggplot e informes con R markdown.\nEn este apartado nos centraremos en cómo investigar el sesgo de la muestra y visualizarlo. También veremos cómo visualizar el flujo de la población en un entorno de encuesta utilizando diagramas aluviales/sankey.\nEn general, debes considerar incluir los siguientes análisis descriptivos:\n\nNúmero final de agrupaciones, hogares e individuos incluidos\nNúmero de personas excluidas y motivos de la exclusión\nMediana (rango) del número de hogares por grupo y de individuos por hogar\n\n\nSesgo de muestreo\nCompara las proporciones de cada grupo de edad entre tu muestra y la población de origen. Esto es importante para poder resaltar el posible sesgo de muestreo. También puedes repetir esta operación para ver las distribuciones por sexo.\nTen en cuenta que estos valores-p son sólo indicativos, y que una discusión descriptiva (o la visualización con las pirámides de edad que aparecen a continuación) de las distribuciones en tu muestra de estudio en comparación con la población de origen es más importante que la prueba binomial en sí. Esto se debe a que el aumento del tamaño de la muestra suele dar lugar a diferencias que pueden ser irrelevantes después de ponderar los datos.\n\n## recuentos y datos de la población de estudio\nag &lt;- survey_data %&gt;% \n  group_by(age_group) %&gt;% \n  drop_na(age_group) %&gt;% \n  tally() %&gt;% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## recuentos y datos de la población de origen\npropcount &lt;- population %&gt;% \n  group_by(age_group) %&gt;%\n    tally(population) %&gt;%\n    mutate(proportion = n / sum(n))\n\n## unir las columnas de dos tablas, agrupar por edad, y realizar una \n## prueba binomial para ver si n/total es significativamente diferente de la \n## proporción de población.\n  ## el sufijo aquí añade texto al final de las columnas en cada uno de los dos conjuntos de datos\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %&gt;%\n  group_by(age_group) %&gt;%\n  ## broom::tidy(binom.test()) crea un dataframe a partir de la prueba binomial y\n  ## añadirá las variables p.value, parameter, conf.low, conf.high, method, y\n  ## alternativa. Aquí sólo utilizaremos p.value. Puede incluir otras\n  ## columnas si desea informar de los intervalos de confianza\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %&gt;%\n  unnest(cols = c(binom)) %&gt;% # important for expanding the binom.test data frame\n  mutate(proportion_pop = proportion_pop * 100) %&gt;%\n  ## Ajuste de los valores p para corregir los falsos positivos \n  ## (porque la prueba de múltiples grupos de edad). Esto sólo hará \n  ## una diferencia si tiene muchas categorías de edad\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %&gt;%\n                      \n  ## Mostrar sólo valores p superiores a 0,001 (los inferiores se reportan como &lt;0,001)\n  mutate(p.value = ifelse(p.value &lt; 0.001, \n                          \"&lt;0.001\", \n                          as.character(round(p.value, 3)))) %&gt;% \n  \n  ## renombra las columnas adecuadamente\n  select(\n    \"Age group\" = age_group,\n    \"Study population (n)\" = n,\n    \"Study population (%)\" = proportion,\n    \"Source population (n)\" = n_pop,\n    \"Source population (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )\n\n# A tibble: 5 × 6\n# Groups:   Age group [5]\n  `Age group` `Study population (n)` `Study population (%)`\n  &lt;chr&gt;                        &lt;int&gt;                  &lt;dbl&gt;\n1 0-2                             12                 0.0256\n2 3-14                            42                 0.0896\n3 15-29                           64                 0.136 \n4 30-44                           52                 0.111 \n5 45+                            299                 0.638 \n# ℹ 3 more variables: `Source population (n)` &lt;dbl&gt;,\n#   `Source population (%)` &lt;dbl&gt;, `P-value` &lt;chr&gt;\n\n\n\n\nPirámides demográficas\nLas pirámides demográficas (o de edad y sexo) son una forma sencilla de visualizar la distribución de la población de la encuesta. También vale la pena considerar la creación de tablas descriptivas de edad y sexo por estratos de la encuesta. Demostraremos el uso del paquete apyramid, ya que permite las proporciones ponderadas utilizando nuestro objeto de diseño de la encuesta creado anteriormente. Otras opciones para crear pirámides demográficas se tratan ampliamente en ese capítulo del manual. También utilizaremos una función envolvente de apyramid llamada age_pyramid() que ahorra algunas líneas de codificación para producir un gráfico con proporciones.\nAl igual que con el test binomial formal de la diferencia, vista anteriormente en la sección de sesgo de muestreo, aquí estamos interesados en visualizar si nuestra población muestreada es sustancialmente diferente de la población de origen y si la ponderación corrige esta diferencia. Para ello, utilizaremos el paquete patchwork para mostrar nuestras visualizaciones ggplot una al lado de la otra; para más detalles, consulta la sección sobre la combinación de gráficos en el capítulo de consejos de ggplot del manual. Visualizaremos nuestra población de origen, nuestra población de encuesta no ponderada y nuestra población de encuesta ponderada. También puedes considerar la posibilidad de visualizar por cada estrato de tu encuesta - en nuestro ejemplo aquí sería utilizando el argumento stack_by = \"health_district\" (ver ?plot_age_pyramid para más detalles).\nNOTA: Los ejes-x e y están invertidos en las pirámides\n\n## define los límites y etiquetas del eje-x ---------------------------------------------\n## (actualiza estos números para que sean los valores del gráfico)\nmax_prop &lt;- 35      ## elige la proporción más alta que se quiere mostrar \nstep &lt;- 5           # elige el espacio que se desea entre etiquetas\n\n## esta parte define el vector usando los números anteriores con saltos de eje\nbreaks &lt;- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## esta parte define el vector usando los números anteriores con los límites del eje\nlimits &lt;- c(max_prop/100 * -1, max_prop/100)\n\n## esta parte define el vector usando los números anteriores con las etiquetas de los ejes\nlabels &lt;-  c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## crear gráficos individualmente   --------------------------------------------------\n\n## representar la población de origen \n## nota: esto necesita estar colapsado para la población total (es decir, eliminando los distritos sanitarios)\nsource_population &lt;- population %&gt;%\n  ## asegurar que la edad y el sexo son factores\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %&gt;% \n  group_by(age_group, sex) %&gt;% \n  ## sumar los recuentos de cada distrito sanitario \n  summarise(population = sum(population)) %&gt;% \n  ## eliminar la agrupación para poder calcular la proporción global\n  ungroup() %&gt;% \n  mutate(proportion = population / sum(population)) %&gt;% \n  ## representar la pirámide \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## mostrar sólo la etiqueta del eje-y (por lo demás se repite en los tres gráficos)\n  labs(title = \"Source population\", \n       y = \"\", \n       x = \"Age group (years)\") + \n  ## hacer que el eje-x sea el mismo para todos los gráficos \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## dibujar la población de la muestra no ponderada \nsample_population &lt;- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## mostrar sólo la etiqueta del eje-x (por lo demás se repite en los tres gráficos)\n  labs(title = \"Unweighted sample population\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## hacer que el eje-x sea el mismo para todos los gráficos \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## dibujar la población de la muestra ponderada \nweighted_population &lt;- survey_design %&gt;% \n  ## asegurar que las variables son factores\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %&gt;%\n  age_pyramid( \n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## mostrar sólo la etiqueta del eje-x (por lo demás se repite en los tres gráficos)\n  labs(title = \"Weighted sample population\", \n       y = \"\", \n       x = \"\")  + \n  ## hacer que el eje-x sea el mismo para todos los gráficos  \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combinar los tres gráficos  ----------------------------------------------------\n## combinar tres gráficos uno al lado del otro usando + \nsource_population + sample_population + weighted_population + \n  ## sólo mostrar una leyenda y definir tema \n  ## observar el uso de & para combinar el tema con plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\",                    # mover la leyenda a la parte inferior\n        legend.title = element_blank(),                # eliminar el título\n        text = element_text(size = 18),                # cambiar el tamaño del texto\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # cambiar el texto del eje-x\n       )\n\n\n\n\n\n\n\n\n\n\nDiagrama aluvial/sankey\nVisualizar los puntos de partida y los resultados de los individuos puede ser muy útil para obtener una visión general. Su aplicación es bastante obvia en el caso de las poblaciones móviles, pero hay muchas otras aplicaciones, como las cohortes o cualquier otra situación en la que haya transiciones de estados para los individuos. Estos diagramas tienen varios nombres diferentes, como diagramas aluviales, de sankey y paralelos; los detalles se encuentran en el capítulo del manual sobre diagramas y gráficos.\n\n## resumir datos\nflow_table &lt;- survey_data %&gt;%\n  count(startcause, endcause, sex) %&gt;%  # get counts \n  gather_set_data(x = c(\"startcause\", \"endcause\"))     # cambiar el formato del gráfico\n\n\n## representa los datos \n  ## en el eje-x están las causas de inicio y fin\n  ## gather_set_data genera un ID para cada combinación posible\n  ## dividiendo por y da las posibles combinaciones inicio/fin\n  ## el valor como n lo da como recuentos (también podría cambiarse a proporción)\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colorear las líneas por sexo \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +\n  ## rellenar de gris los cuadros de etiquetas\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") +\n  ## cambiar el color y el ángulo del texto (hay que ajustarlo)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) +\n  ## eliminar las etiquetas de los ejes\n  theme_void()+\n  ## mover la leyenda a la parte inferior\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#weighted-proportions",
    "href": "new_pages/survey_analysis.es.html#weighted-proportions",
    "title": "26  Análisis de encuestas",
    "section": "26.8 Proporciones ponderadas",
    "text": "26.8 Proporciones ponderadas\nEsta sección detallará cómo producir tablas para recuentos y proporciones ponderadas, con los intervalos de confianza asociados y el efecto del diseño. Hay cuatro opciones diferentes que utilizan funciones de los siguientes paquetes: survey, srvyr, sitrep y gtsummary. Para una codificación mínima que produzca una tabla de estilo epidemiológico estándar, recomendaríamos la función sitrep - que es una envoltura para el código srvyr; Ten en cuenta, sin embargo, que esto no está todavía en CRAN y puede cambiar en el futuro. Por lo demás, es probable que el código de survey sea el más estable a largo plazo, mientras que srvyr se adaptará mejor a los flujos de trabajo de tidyverse. Aunque las funciones de gtsummary tienen mucho potencial, parecen ser experimentales e incompletas en el momento de escribir este artículo.\n\nPaquete survey\nPodemos utilizar la función svyciprop() de survey para obtener las proporciones ponderadas y los correspondientes intervalos de confianza del 95%. Se puede extraer un efecto de diseño apropiado utilizando la función svymean() en lugar de svyprop(). Cabe señalar que svyprop() sólo parece aceptar variables entre 0 y 1 (o TRUE/FALSE), por lo que las variables categóricas no funcionarán.\nNOTA: Las funciones de survey también aceptan objetos de diseño srvyr, pero aquí hemos utilizado el objeto de diseño de survey sólo por coherencia\n\n## producir recuentos ponderados  \nsvytable(~died, base_survey_design)\n\ndied\n     FALSE       TRUE \n1406244.43   76213.01 \n\n## producir proporciones ponderadas\nsvyciprop(~died, base_survey_design, na.rm = T)\n\n              2.5% 97.5%\ndied 0.0514 0.0208  0.12\n\n## producir proporciones ponderadas\nsvymean(~died, base_survey_design, na.rm = T, deff = T) %&gt;% \n  deff()\n\ndiedFALSE  diedTRUE \n 3.755508  3.755508 \n\n\nPodemos combinar las funciones de survey mostradas arriba en una función que definimos nosotros mismos a continuación, llamada svy_prop; y podemos entonces usar esa función junto con map() del paquete purrr para iterar sobre varias variables y crear una tabla. Consulta el capítulo de iteración del manual para obtener más detalles sobre purrr.\n\n# Define la función para calcular recuentos ponderados, proporciones, IC y efecto de diseño.\n# x es la variable entre comillas \n# design es el objeto de diseño de la encuesta\n\nsvy_prop &lt;- function(design, x) {\n  \n  ## poner la variable de interés en una fórmula \n  form &lt;- as.formula(paste0( \"~\" , x))\n  ## conservar sólo la columna TRUE de los recuentos de svytable\n  weighted_counts &lt;- svytable(form, design)[[2]]\n  ## calcular proporciones (multiplicar por 100 para obtener porcentajes)\n  weighted_props &lt;- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extraer los intervalos de confianza y multiplicar para obtener los porcentajes\n  weighted_confint &lt;- confint(weighted_props) * 100\n  ## usar svymean para calcular el efecto del diseño y mantener sólo la columna TRUE\n  design_eff &lt;- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combinar en un dataframe\n  full_table &lt;- cbind(\n    \"Variable\"        = x,\n    \"Count\"           = weighted_counts,\n    \"Proportion\"      = weighted_props,\n    weighted_confint, \n    \"Design effect\"   = design_eff\n    )\n  \n  ## devuelve la tabla como un dataframe\n  full_table &lt;- data.frame(full_table, \n             ## remove the variable names from rows (is a separate column now)\n             row.names = NULL)\n  \n  ## cambiar los valores numéricos a numéricos\n  full_table[ , 2:6] &lt;- as.numeric(full_table[, 2:6])\n  \n  ## devolver dataframe\n  full_table\n}\n\n## iterar sobre varias variables para crear una tabla \npurrr::map(\n  ## definir variables de interés\n  c(\"left\", \"died\", \"arrived\"), \n  ## indicar la función utilizada y los argumentos de dicha función (diseño)\n  svy_prop, design = base_survey_design) %&gt;% \n  ## colapsar la lista en un único dataframe\n  bind_rows() %&gt;% \n  ## redondear \n  mutate(across(where(is.numeric), round, digits = 1))\n\n  Variable    Count Proportion X2.5. X97.5. Design.effect\n1     left 701199.1       47.3  39.2   55.5           2.4\n2     died  76213.0        5.1   2.1   12.1           3.8\n3  arrived 761799.0       51.4  40.9   61.7           3.9\n\n\n\n\nPaquete Srvyr\nCon srvyr podemos utilizar la sintaxis de dplyr para crear una tabla. Observa que se utiliza la función survey_mean() y se especifica el argumento de la proporción, y también que se utiliza la misma función para calcular el efecto del diseño. Esto se debe a que srvyr envuelve las dos funciones del paquete survey, svyciprop() y svymean(), que se utilizan en la sección anterior.\nNOTA: Tampoco parece posible obtener proporciones a partir de variables categóricas utilizando srvyr, si lo necesitas, consulta la sección siguiente utilizando sitrep \n\n## utilizar el objeto de diseño srvyr\nsurvey_design %&gt;% \n  summarise(\n    ## producir los recuentos ponderados \n    counts = survey_total(died), \n    ## producir proporciones ponderadas e intervalos de confianza \n    ## multiplicar por 100 para obtener un porcentaje \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## obtener el efecto del diseño \n    deff = survey_mean(died, deff = TRUE)) %&gt;% \n  ## conservar sólo las filas de interés\n  ## (eliminar los errores estándar y repetir el cálculo de la proporción)\n  select(counts, props, props_low, props_upp, deff_deff)\n\n# A tibble: 1 × 5\n  counts props props_low props_upp deff_deff\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 76213.  5.14      2.08      12.1      3.76\n\n\nAquí también podríamos escribir una función para iterar sobre múltiples variables utilizando el paquete purrr. Consulta el capítulo de iteración del manual para obtener más detalles sobre purrr.\n\n# Definir función para calcular recuentos ponderados, proporciones, IC y efecto de diseño\n# diseño es el objeto de diseño de su encuesta\n# x es la variable entre comillas \n\n\nsrvyr_prop &lt;- function(design, x) {\n  \n  summarise(\n    ## utilizando el objeto de diseño de la encuesta\n    design, \n    ## producir los recuentos ponderados \n    counts = survey_total(.data[[x]]), \n    ## producir proporciones ponderadas e intervalos de confianza \n    ## multiplicar por 100 para obtener un porcentaje\n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(.data[[x]], deff = TRUE)) %&gt;% \n  ## añadir el nombre de la variable\n  mutate(variable = x) %&gt;% \n  ## conservar sólo las filas de interés\n  ## ( elimina los errores estándar y repite el cálculo de la proporción)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## iterar sobre varias variables para crear una tabla \npurrr::map(\n  ## definir variables de interés\n  c(\"left\", \"died\", \"arrived\"), \n  ## función de estado usando y argumentos para esa función (diseño)\n  ~srvyr_prop(.x, design = survey_design)) %&gt;% \n  ## colapsar la lista en un único dataframe\n  bind_rows()\n\n# A tibble: 3 × 6\n  variable  counts props props_low props_upp deff_deff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 left     701199. 47.3      39.2       55.5      2.38\n2 died      76213.  5.14      2.08      12.1      3.76\n3 arrived  761799. 51.4      40.9       61.7      3.93\n\n\n\n\nPaquete Sitrep\nLa función tab_survey() de sitrep es una envoltura para srvyr, que permite crear tablas ponderadas con una codificación mínima. También permite calcular proporciones ponderadas para variables categóricas.\n\n## utilizando el objeto de diseño de la encuesta\nsurvey_design %&gt;% \n  ## pasar los nombres de las variables de interés sin comillas\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE,   # calcular el efecto del diseño\n             pretty = TRUE  # unir la proporción y el IC 95%\n             )\n\nWarning: removing 257 missing value(s) from `education_level`\n\n\n# A tibble: 9 × 5\n  variable        value            n  deff ci               \n  &lt;chr&gt;           &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            \n1 arrived         TRUE       761799.  3.93 51.4% (40.9-61.7)\n2 arrived         FALSE      720658.  3.93 48.6% (38.3-59.1)\n3 left            TRUE       701199.  2.38 47.3% (39.2-55.5)\n4 left            FALSE      781258.  2.38 52.7% (44.5-60.8)\n5 died            TRUE        76213.  3.76 5.1% (2.1-12.1)  \n6 died            FALSE     1406244.  3.76 94.9% (87.9-97.9)\n7 education_level higher     171644.  4.70 42.4% (26.9-59.7)\n8 education_level primary    102609.  2.37 25.4% (16.2-37.3)\n9 education_level secondary  130201.  6.68 32.2% (16.5-53.3)\n\n\n\n\nPaquete Gtsummary\nCon gtsummary no parece haber todavía funciones incorporadas para añadir intervalos de confianza o efecto de diseño. Aquí mostramos cómo definir una función para añadir intervalos de confianza y luego añadir intervalos de confianza a una tabla gtsummary creada con la función tbl_svysummary().\n\nconfidence_intervals &lt;- function(data, variable, by, ...) {\n  \n  ## extraer los intervalos de confianza y multiplicar para obtener porcentajes\n  props &lt;- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## extraer los intervalos de confianza \n  as.numeric(confint(props) * 100) %&gt;% ## convierte en numérico y multiplica por porcentaje\n    round(., digits = 1) %&gt;%           ## redondea a un dígito\n    c(.) %&gt;%                           ## extrae los números de la matriz\n    paste0(., collapse = \"-\")          ## combina a un solo caracter\n}\n\n## utilizando el objeto de diseño del paquete survey\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died),   ## define las variables que se quieren incluir\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %&gt;% ## define las estadísticas de interés\n  add_n() %&gt;%  ## añade el total ponderado  \n  add_stat(fns = everything() ~ confidence_intervals) %&gt;% ## añade los ICs\n  ## modify the column headers\n  modify_header(\n    list(\n      n ~ \"**Weighted total (N)**\",\n      stat_0 ~ \"**Weighted Count**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )\n\n\n\n\n\n\n\n\nCharacteristic\nWeighted total (N)\nWeighted Count1\n95%CI\n\n\n\n\narrived\n1,482,457\n761,799 (51%)\n40.9-61.7\n\n\nleft\n1,482,457\n701,199 (47%)\n39.2-55.5\n\n\ndied\n1,482,457\n76,213 (5.1%)\n2.1-12.1\n\n\n\n1 n (%)",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#weighted-ratios",
    "href": "new_pages/survey_analysis.es.html#weighted-ratios",
    "title": "26  Análisis de encuestas",
    "section": "26.9 Razones ponderadas",
    "text": "26.9 Razones ponderadas\nDel mismo modo, para los ratios ponderados (como los ratios de mortalidad) puedes utilizar el paquete survey o srvyr. También se pueden escribir funciones (similares a las anteriores) para iterar sobre varias variables. También se podría crear una función para gtsummary como la anterior, pero actualmente no tiene una funcionalidad incorporada.\n\nPaquete survey\n\nratio &lt;- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci &lt;- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)\n\n      obstime    2.5 %   97.5 %\ndied 5.981922 1.194294 10.76955\n\n\n\n\nPaquete Srvyr\n\nsurvey_design %&gt;% \n  ## proporción de encuesta utilizada para tener en cuenta el tiempo de observación \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )\n\n# A tibble: 1 × 3\n  mortality mortality_low mortality_upp\n      &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1      5.98         0.349          11.6",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survey_analysis.es.html#resources-19",
    "href": "new_pages/survey_analysis.es.html#resources-19",
    "title": "26  Análisis de encuestas",
    "section": "26.10 Recursos",
    "text": "26.10 Recursos\nPágina de estadísticas de la UCLA\nAnalizar datos de encuestas gratis\nsrvyr packge\npaquete gtsummary\nEstudios de caso de la encuesta EPIET",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Análisis de encuestas</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html",
    "href": "new_pages/survival_analysis.es.html",
    "title": "27  Análisis de supervivencia",
    "section": "",
    "text": "27.1 Resumen\nEl análisis de supervivencia se centra en la descripción, para un individuo o grupo de individuos determinado, de un acontecimiento puntual denominado evento (aparición de una enfermedad, curación de una enfermedad, muerte, recaída tras la respuesta al tratamiento…) que se produce tras un periodo de tiempo denominado tiempo del evento (o tiempo de seguimiento (tiempo de seguimiento en los estudios basados en cohortes/poblaciones) durante el cual se observa a los individuos. Para determinar el tiempo de fracaso, es necesario definir un tiempo de origen (que puede ser la fecha de inclusión, la fecha de diagnóstico…).\nEl objetivo de la inferencia para el análisis de supervivencia es entonces el tiempo entre un origen y un evento. En la investigación médica actual, se utiliza ampliamente en los estudios clínicos para evaluar el efecto de un tratamiento, por ejemplo, o en la epidemiología del cáncer para evaluar una gran variedad de medidas de supervivencia del cáncer.\nSuele expresarse mediante la probabilidad de supervivencia (survival probability), que es la probabilidad de que el suceso de interés no haya ocurrido en una duración t.\nCensura: La censura se produce cuando al final del seguimiento, algunos de los individuos no han tenido el evento de interés, y por lo tanto su verdadero tiempo hasta el evento es desconocido. Aquí nos centraremos principalmente en la censura derecha, pero para más detalles sobre la censura y el análisis de supervivencia en general, puedes consultar las referencias.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html#preparation-18",
    "href": "new_pages/survival_analysis.es.html#preparation-18",
    "title": "27  Análisis de supervivencia",
    "section": "27.2 Preparación",
    "text": "27.2 Preparación\n\nCargar paquetes\nPara realizar análisis de supervivencia en R, uno de los paquetes más utilizados es el de survival. Primero lo instalamos y luego lo cargamos, así como los demás paquetes que se utilizarán en esta sección:\nEn este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\nEsta página explora los análisis de supervivencia sobre el archivo linelist utilizado en la mayoría de las páginas anteriores y sobre el que aplicamos algunos cambios para tener unos datos de supervivencia adecuados.\n\n\nImportar los datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).\n\n# importar linelist\nlinelist_case_data &lt;- rio::import(\"linelist_cleaned.rds\")\n\n\n\nGestión y transformación de datos\nEn resumen, los datos de supervivencia pueden describirse con las tres características siguientes:\n\nla variable dependiente o respuesta es el tiempo de espera hasta la ocurrencia de un evento bien definido,\nobservaciones censuradas, en el sentido de que para algunas unidades el evento de interés no ha ocurrido en el momento en que se analizan los datos, y\n\n\nexisten predictores o variables explicativas cuyo efecto sobre el tiempo de espera queremos evaluar o controlar.\n\nAsí, crearemos las diferentes variables necesarias para respetar esa estructura y ejecutaremos el análisis de supervivencia.\nDefiniremos:\n\nun nuevo dataframe linelist_surv para este análisis\nnuestro evento de interés como “death” (por lo tanto, nuestra probabilidad de supervivencia será la probabilidad de estar vivo después de un cierto tiempo después del momento de origen),\nel tiempo de seguimiento (futime) como el tiempo transcurrido entre el momento del inicio y el momento del desenlace en días,\npacientes censurados son aquellos que se recuperaron o para los que no se conoce el resultado final, es decir, no se observó el evento “muerte” (evento=0).\n\nPRECAUCIÓN: Dado que en un estudio de cohortes real, la información sobre el momento de origen y el final del seguimiento se conoce dado que los individuos son observados, eliminaremos las observaciones en las que se desconozca la fecha de inicio o la fecha de desenlace. También se eliminarán los casos en los que la fecha de inicio sea posterior a la fecha de desenlace, ya que se consideran erróneos.\nCONSEJO: Dado que el filtrado a mayor (&gt;) o menor (&lt;) de una fecha puede eliminar las filas con valores faltantes, la aplicación del filtro en las fechas incorrectas también eliminará las filas con fechas faltantes.\nA continuación, utilizamos case_when() para crear una columna age_cat_small en la que sólo hay 3 categorías de edad.\n\n#crea linelist_surv a partir de linelist_case_data\n\nlinelist_surv &lt;-  linelist_case_data %&gt;% \n     \n  dplyr::filter(\n       # eliminar observaciones con fechas de inicio o de resultado erróneas o ausentes\n       date_outcome &gt; date_onset) %&gt;% \n  \n  dplyr::mutate(\n       # crear la var evento que es 1 si el paciente falleció y 0 si fue correctamente censurado\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # crear la var de tiempo de seguimiento en días\n       futime = as.double(date_outcome - date_onset), \n    \n       # crear una nueva variable de categoría de edad con sólo 3 estratos\n       age_cat_small = dplyr::case_when( \n            age_years &lt; 5  ~ \"0-4\",\n            age_years &gt;= 5 & age_years &lt; 20 ~ \"5-19\",\n            age_years &gt;= 20   ~ \"20+\"),\n       \n       # el paso anterior creó la variable age_cat_small como carácter.\n       # ahora se convierte en factor y se especifican los niveles.\n       # Nótese que los valores NA siguen siendo NA y no se ponen en un nivel \"desconocido\" por ejemplo,\n       # ya que en los siguientes análisis tienen que ser eliminados.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\n\nCONSEJO: Podemos verificar las nuevas columnas que hemos creado haciendo un resumen sobre futime y una tabulación cruzada entre event y outcome a partir del cual se ha creado. Además de esta verificación, es un buen hábito comunicar la mediana del tiempo de seguimiento al interpretar los resultados del análisis de supervivencia.\n\nsummary(linelist_surv$futime)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    6.00   10.00   11.98   16.00   64.00 \n\n# cruzar la nueva variable de evento y la de resultado a partir de la que se creó\n# para asegurarse de que el código ha hecho lo que debía\nlinelist_surv %&gt;% \n  tabyl(outcome, event)\n\n outcome    0    1\n   Death    0 1952\n Recover 1547    0\n    &lt;NA&gt; 1040    0\n\n\nAhora cruzamos la nueva var de age_cat_small y la antigua columna age_cat para asegurarnos de que las asignaciones son correctas\n\nlinelist_surv %&gt;% \n  tabyl(age_cat_small, age_cat)\n\n age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n           0-4 834   0     0     0     0     0     0   0   0\n          5-19   0 852   717   575     0     0     0   0   0\n           20+   0   0     0     0   862   554    69   5   0\n          &lt;NA&gt;   0   0     0     0     0     0     0   0  71\n\n\nAhora revisamos las 10 primeras observaciones de los datos de linelist_surv mirando las variables específicas (incluyendo las de nueva creación).\n\nlinelist_surv %&gt;% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %&gt;% \n  head(10)\n\n   case_id age_cat_small date_onset date_outcome outcome event futime\n1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\n\n\nTambién podemos cruzar las columnas age_cat_small y gender para tener más detalles sobre la distribución de esta nueva columna por género. Utilizamos tabyl() y las funciones de adorno de janitor como se describe en la página de tablas descriptivas.\n\n\nlinelist_surv %&gt;% \n  tabyl(gender, age_cat_small, show_na = F) %&gt;% \n  adorn_totals(where = \"both\") %&gt;% \n  adorn_percentages() %&gt;% \n  adorn_pct_formatting() %&gt;% \n  adorn_ns(position = \"front\")\n\n gender         0-4          5-19           20+          Total\n      f 482 (22.4%) 1,184 (54.9%)   490 (22.7%) 2,156 (100.0%)\n      m 325 (15.0%)   880 (40.6%)   960 (44.3%) 2,165 (100.0%)\n  Total 807 (18.7%) 2,064 (47.8%) 1,450 (33.6%) 4,321 (100.0%)",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html#basics-of-survival-analysis",
    "href": "new_pages/survival_analysis.es.html#basics-of-survival-analysis",
    "title": "27  Análisis de supervivencia",
    "section": "27.3 Fundamentos del análisis de supervivencia",
    "text": "27.3 Fundamentos del análisis de supervivencia\n\nConstruir un objeto de tipo surv-type\nPrimero utilizaremos Surv() de survival para construir un objeto de supervivencia a partir de las columnas de tiempo de seguimiento y evento.\nEl resultado de este paso es producir un objeto de tipo Surv que condensa la información de tiempo y si fue observado el evento de interés (muerte). Este objeto se utilizará en última instancia en el lado derecho de las fórmulas posteriores del modelo (véase la documentación).\n\n# Utilizar la sintaxis Suv() para datos correctamente censurados\nsurvobj &lt;- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\n\n\n\n\n\n\nPuedes revisar las primeras 10 filas de los datos de linelist_surv, viendo sólo algunas columnas importantes.\n\nlinelist_surv %&gt;% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %&gt;% \n  head(10)\n\n   case_id date_onset date_outcome futime outcome event\n1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n3   893f25 2014-05-21   2014-05-29      8 Recover     0\n4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n6   369449 2014-06-02   2014-06-07      5   Death     1\n7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n8   1389ca 2014-06-05   2014-06-09      4   Death     1\n9   2978ac 2014-06-06   2014-06-15      9   Death     1\n10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n\n\nY aquí están los primeros 10 elementos de survobj. Se imprime esencialmente como un vector de tiempo de seguimiento, con “+” a la derecha para representar si una observación fue censurada. Mira cómo los números se alinean arriba y abajo.\n\n#imprimir los 50 primeros elementos del vector para ver cómo se presenta\nhead(survobj, 10)\n\n [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+\n\n\n\n\nRealización de los primeros análisis\nA continuación, iniciamos nuestro análisis utilizando la función survfit() para producir un objeto survfit, que se ajusta a los cálculos por defecto para las estimaciones de Kaplan Meier (KM) de la curva de supervivencia global (marginal), que son de hecho una función escalonada con saltos en los tiempos de los eventos observados. El objeto survfit final contiene una o más curvas de supervivencia y se crea utilizando el objeto Surv como variable de respuesta en la fórmula del modelo.\nNOTA: La estimación de Kaplan-Meier es una estimación no paramétrica de máxima verosimilitud (MLE) de la función de supervivencia. (ver recursos para más información).\nEl resumen de este objeto survfit dará lo que se llama una tabla de vida. Para cada paso de tiempo de seguimiento (time) en el que ocurrió un evento (en orden ascendente):\n\nel número de personas que estaban en riesgo de desarrollar el evento (personas que aún no tenían el evento ni estaban censuradas: (n.risk)\nlos que sí desarrollaron el evento (n.event)\ny de lo anterior: la probabilidad de no desarrollar el evento (probabilidad de no morir, o de sobrevivir más allá de ese tiempo específico)\npor último, se obtienen y muestran el error estándar y el intervalo de confianza de esa probabilidad\n\nAjustamos las estimaciones de KM mediante la fórmula en la que el objeto Surv “survobj” anterior es la variable de respuesta. “~ 1” precisa que ejecutamos el modelo para la supervivencia global.\n\n# ajustar las estimaciones de KM utilizando una fórmula donde el objeto Surv \"survobj\" es la variable de respuesta.\n# \"~ 1\" significa que ejecutamos el modelo para la supervivencia global  \nlinelistsurv_fit &lt;-  survival::survfit(survobj ~ 1)\n\n#imprimir su resumen para más detalles\nsummary(linelistsurv_fit)\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1   4539      30    0.993 0.00120        0.991        0.996\n    2   4500      69    0.978 0.00217        0.974        0.982\n    3   4394     149    0.945 0.00340        0.938        0.952\n    4   4176     194    0.901 0.00447        0.892        0.910\n    5   3899     214    0.852 0.00535        0.841        0.862\n    6   3592     210    0.802 0.00604        0.790        0.814\n    7   3223     179    0.757 0.00656        0.745        0.770\n    8   2899     167    0.714 0.00700        0.700        0.728\n    9   2593     145    0.674 0.00735        0.660        0.688\n   10   2311     109    0.642 0.00761        0.627        0.657\n   11   2081     119    0.605 0.00788        0.590        0.621\n   12   1843      89    0.576 0.00809        0.560        0.592\n   13   1608      55    0.556 0.00823        0.540        0.573\n   14   1448      43    0.540 0.00837        0.524        0.556\n   15   1296      31    0.527 0.00848        0.511        0.544\n   16   1152      48    0.505 0.00870        0.488        0.522\n   17   1002      29    0.490 0.00886        0.473        0.508\n   18    898      21    0.479 0.00900        0.462        0.497\n   19    798       7    0.475 0.00906        0.457        0.493\n   20    705       4    0.472 0.00911        0.454        0.490\n   21    626      13    0.462 0.00932        0.444        0.481\n   22    546       8    0.455 0.00948        0.437        0.474\n   23    481       5    0.451 0.00962        0.432        0.470\n   24    436       4    0.447 0.00975        0.428        0.466\n   25    378       4    0.442 0.00993        0.423        0.462\n   26    336       3    0.438 0.01010        0.419        0.458\n   27    297       1    0.436 0.01017        0.417        0.457\n   29    235       1    0.435 0.01030        0.415        0.455\n   38     73       1    0.429 0.01175        0.406        0.452\n\n\nAl utilizar summary() podemos añadir la opción times y especificar ciertos tiempos en los que queremos ver la información de supervivencia\n\n#imprimir su resumen en momentos concretos\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))\n\nCall: survfit(formula = survobj ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    5   3899     656    0.852 0.00535        0.841        0.862\n   10   2311     810    0.642 0.00761        0.627        0.657\n   20    705     446    0.472 0.00911        0.454        0.490\n   30    210      39    0.435 0.01030        0.415        0.455\n   60      2       1    0.429 0.01175        0.406        0.452\n\n\nTambién podemos utilizar la función print(). El argumento print.rmean = TRUE se utiliza para obtener el tiempo medio de supervivencia y su error estándar (se).\nNOTA: El tiempo medio de supervivencia restringido (RMST) es una medida de supervivencia específica cada vez más utilizada en el análisis de supervivencia del cáncer y que suele definirse como el área bajo la curva de supervivencia, dado que observamos a los pacientes hasta el tiempo restringido T (más detalles en la sección Recursos).\n\n# imprimir el objeto linelistsurv_fit con el tiempo medio de supervivencia y su se. \nprint(linelistsurv_fit, print.rmean = TRUE)\n\nCall: survfit(formula = survobj ~ 1)\n\n        n events rmean* se(rmean) median 0.95LCL 0.95UCL\n[1,] 4539   1952   33.1     0.539     17      16      18\n    * restricted mean with upper limit =  64 \n\n\nCONSEJO: Podemos crear el objeto surv directamente en la función survfit() y ahorrarnos una línea de código. Esto se verá como: linelistsurv_quick &lt;- survfit(Surv(futime, event) ~ 1, data=linelist_surv).\n\n\nRiesgo acumulado\nAdemás de la función summary(), también podemos utilizar la función str() que da más detalles sobre la estructura del objeto survfit(). Se trata de una lista de 16 elementos.\nEntre estos elementos hay uno importante: el cumhaz, que es un vector numérico. Se puede trazar para mostrar el riesgo acumulado, siendo el riesgo la tasa instantánea de ocurrencia del evento (ver referencias).\n\nstr(linelistsurv_fit)\n\nList of 16\n $ n        : int 4539\n $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n $ type     : chr \"right\"\n $ logse    : logi TRUE\n $ conf.int : num 0.95\n $ conf.type: chr \"log\"\n $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n $ call     : language survfit(formula = survobj ~ 1)\n - attr(*, \"class\")= chr \"survfit\"\n\n\n\n\n\nRepresentar curvas de Kaplan-Meir\nUna vez ajustadas las estimaciones de KM, podemos visualizar la probabilidad de estar vivo a lo largo de un tiempo determinado utilizando la función básica plot() que dibuja la “curva de Kaplan-Meier”. En otras palabras, la curva de abajo es una ilustración convencional de la experiencia de supervivencia en todo el grupo de pacientes.\nPodemos verificar rápidamente el tiempo de seguimiento mínimo y máximo en la curva.\nUna forma fácil de interpretarlo es decir que en el momento cero, todos los participantes están vivos y la probabilidad de supervivencia es entonces del 100%. Esta probabilidad disminuye con el tiempo a medida que los pacientes mueren. La proporción de participantes que sobreviven más allá de los 60 días de seguimiento se sitúa en torno al 40%.\n\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",    # etiqueta del eje-x\n     ylab=\"Survival Probability\",   # etiqueta del eje-y\n     main= \"Overall survival curve\" # título de la figura\n     )\n\n\n\n\n\n\n\n\nEl intervalo de confianza de las estimaciones de supervivencia de KM también se representa por defecto y puede descartarse añadiendo la opción conf.int = FALSE al comando plot().\nDado que el evento de interés es “death”, dibujar una curva que describa los complementos de las proporciones de supervivencia llevará a dibujar las proporciones de mortalidad acumulada. Esto puede hacerse con lines(), que añade información a un gráfico existente.\n\n# gráfico original\nplot(\n  linelistsurv_fit,\n  xlab = \"Days of follow-up\",       \n  ylab = \"Survival Probability\",       \n  mark.time = TRUE,              # marca los eventos en la curva: se imprime un \"+\" en cada evento\n  conf.int = FALSE,              # no representa el intervalo de confianza\n  main = \"Overall survival curve and cumulative mortality\"\n  )\n\n# dibujar una curva adicional a la anterior\nlines(\n  linelistsurv_fit,\n  lty = 3,             # use different line type for clarity\n  fun = \"event\",       # dibuja los eventos acumulativos en lugar de la supervivencia \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# añade una leyenda al gráfico\nlegend(\n  \"topright\",                               # posición de la leyenda\n  legend = c(\"Survival\", \"Cum. Mortality\"), # texto de la leyenda  \n  lty = c(1, 3),                            # tipos de línea a utilizar en la leyenda\n  cex = .85,                                # parámetro que define el tamaño del texto de la leyenda\n  bty = \"n\"                                 # no se dibujará ningún tipo de recuadro para la leyenda\n  )",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html#comparison-of-survival-curves",
    "href": "new_pages/survival_analysis.es.html#comparison-of-survival-curves",
    "title": "27  Análisis de supervivencia",
    "section": "27.4 Comparación de las curvas de supervivencia",
    "text": "27.4 Comparación de las curvas de supervivencia\nPara comparar la supervivencia dentro de los diferentes grupos de nuestros participantes o pacientes observados, es posible que tengamos que observar primero sus respectivas curvas de supervivencia y luego realizar pruebas para evaluar la diferencia entre grupos independientes. Esta comparación puede referirse a grupos basados en el género, la edad, el tratamiento, la comorbilidad…\n\nTest Log rank\nEl test Log rank (de rango logarítmico) es una prueba popular que compara toda la experiencia de supervivencia entre dos o más grupos independientes y puede considerarse como una prueba de si las curvas de supervivencia son idénticas (se superponen) o no (hipótesis nula de no diferencia de supervivencia entre los grupos). La función survdiff() del paquete survival permite ejecutar el test Log rank cuando especificamos rho = 0 (que es el valor predeterminado). Los resultados de la prueba dan un estadístico chi-cuadrado junto con un valor-p, ya que el estadístico log rank se distribuye aproximadamente como un test estadístico de chi-cuadrado.\nEn primer lugar, tratamos de comparar las curvas de supervivencia por grupos de género. Para ello, primero intentamos visualizarlo (comprobar si las dos curvas de supervivencia se superponen). Se creará un nuevo objeto survfit con una fórmula ligeramente diferente. Luego se creará el objeto survdiff.\nAl suministrar ~ gender como lado derecho de la fórmula, ya no trazamos la supervivencia global sino por género.\n\n# crear el nuevo objeto survfit basado en el género\nlinelistsurv_fit_sex &lt;-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n\nAhora podemos trazar las curvas de supervivencia por género. Observa el orden de los niveles de los estratos en la columna de género antes de definir los colores y la leyenda.\n\n# establecer colores\ncol_sex &lt;- c(\"lightgreen\", \"darkgreen\")\n\n# crear gráfico\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Days of follow-up\",\n  ylab = \"Survival Probability\")\n\n# añadir leyenda\nlegend(\n  \"topright\",\n  legend = c(\"Female\",\"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\n\nY ahora podemos calcular la prueba de la diferencia entre las curvas de supervivencia utilizando survdiff()\n\n#calcular el test de la diferencia entre las curvas de supervivencia\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )\n\nCall:\nsurvival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n\nn=4321, 218 observations deleted due to missingness.\n\n            N Observed Expected (O-E)^2/E (O-E)^2/V\ngender=f 2156      924      909     0.255     0.524\ngender=m 2165      929      944     0.245     0.524\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nVemos que la curva de supervivencia de las mujeres y la de los hombres se superponen y la prueba de rango logarítmico no da pruebas de una diferencia de supervivencia entre mujeres y hombres.\nAlgunos otros paquetes de R permiten ilustrar curvas de supervivencia para diferentes grupos y probar la diferencia de una sola vez. Utilizando la función ggsurvplot() del paquete survminer, también podemos incluir en nuestra curva las tablas de riesgo impresas para cada grupo, así como el valor p del test log-rank.\nPRECAUCIÓN: las funciones de survminer requieren que especifiques el objeto de supervivencia y que vuelvas a especificar los datos utilizados para ajustar el objeto de supervivencia. Recuerda hacer esto para evitar mensajes de error no específicos. \n\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv,          # especifica de nuevo los datos usados para ajustar linelistsurv_fit_sex \n    conf.int = FALSE,              # no muestra el intervalo de confianza de las estimaciones de KM\n    surv.scale = \"percent\",        # presenta las probabilidades en el eje y en %\n    break.time.by = 10,            # presenta el eje temporal con un incremento de 10 días\n    xlab = \"Follow-up days\",\n    ylab = \"Survival Probability\",\n    pval = T,                      # imprime el valor p de la prueba Log-rank \n    pval.coord = c(40,.91),        # imprime el valor p en estas coordenadas del gráfico\n    risk.table = T,                # imprime la tabla de riesgos en la parte inferior \n    legend.title = \"Gender\",       # características de la leyenda\n    legend.labs = c(\"Female\",\"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\",             # especifica la paleta de colores \n    surv.median.line = \"hv\",       # dibuja líneas horizontales y verticales a las medianas de supervivencia\n    ggtheme = theme_light()        # simplifica el fondo del gráfico\n)\n\n\n\n\n\n\n\n\nTambién podemos comprobar si hay diferencias en la supervivencia según la fuente de infección (fuente de contaminación).\nEn este caso, la prueba de rango logarítmico da pruebas suficientes de una diferencia en las probabilidades de supervivencia a alfa= 0,005. Las probabilidades de supervivencia de los pacientes que se infectaron en los funerales son mayores que las de los pacientes que se infectaron en otros lugares, lo que sugiere un beneficio para la supervivencia.\n\nlinelistsurv_fit_source &lt;-  survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# gráfico\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\",   # line types\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Follow-up days\",\n  ylab= \"Survival Probability\",\n  pval = T,\n  pval.coord = c(40,.91),\n  risk.table = T,\n  legend.title = \"Source of \\ninfection\",\n  legend.labs = c(\"Funeral\", \"Other\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\",\"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)\n\nWarning in geom_segment(aes(x = 0, y = max(y2), xend = max(x1), yend = max(y2)), : All aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?\nAll aesthetics have length 1, but the data has 2 rows.\nℹ Did you mean to use `annotate()`?",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html#cox-regression-analysis",
    "href": "new_pages/survival_analysis.es.html#cox-regression-analysis",
    "title": "27  Análisis de supervivencia",
    "section": "27.5 Análisis de regresión de Cox",
    "text": "27.5 Análisis de regresión de Cox\nLa regresión de riesgos proporcionales de Cox es una de las técnicas de regresión más populares para el análisis de supervivencia. También se pueden utilizar otros modelos, ya que el modelo de Cox requiere supuestos importantes que deben verificarse para un uso adecuado, como el supuesto de riesgos proporcionales: véanse las referencias.\nEn un modelo de regresión de riesgos proporcionales de Cox, la medida del efecto es la tasa de riesgo (HR), que es el riesgo de fracaso (o el riesgo de muerte en nuestro ejemplo), dado que el participante ha sobrevivido hasta un momento específico. Normalmente, nos interesa comparar grupos independientes con respecto a sus riesgos, y utilizamos una razón de riesgo, que es análoga a una razón de probabilidades en el entorno del análisis de regresión logística múltiple. La función cox.ph() del paquete de supervivencia se utiliza para ajustar el modelo. La función cox.zph() del paquete survival puede utilizarse para probar la suposición de riesgos proporcionales para un ajuste del modelo de regresión de Cox.\nNOTA: Una probabilidad debe estar en el rango de 0 a 1. Sin embargo, el peligro representa el número esperado de eventos por una unidad de tiempo.\n\nSi la razón de riesgo (RR)de un predictor es cercana a 1, entonces ese predictor no afecta a la supervivencia,\nSi la RR es inferior a 1, entonces el predictor es protector (es decir, está asociado a una mejor supervivencia),\ny si la RR es mayor que 1, entonces el predictor se asocia a un mayor riesgo (o a una menor supervivencia).\n\n\nAjuste de un modelo de Cox\nPrimero podemos ajustar un modelo para evaluar el efecto de la edad y el sexo en la supervivencia. Con sólo imprimir el modelo, tenemos la información sobre:\n\nlos coeficientes de regresión estimados coef que cuantifican la asociación entre los predictores y el resultado,\nsu exponencial (para su interpretación, exp(coef)) que produce la razón de riesgo,\nsu error estándar se(coef),\nla puntuación z: cuántos errores estándar se aleja el coeficiente estimado de 0,\ny el valor- p: la probabilidad de que el coeficiente estimado sea 0.\n\nLa función summary() aplicada al objeto del modelo de Cox ofrece más información, como el intervalo de confianza de la RR estimada y las diferentes puntuaciones de la prueba.\nEl efecto de la primera covariable, gender, se presenta en la primera fila. Se imprime genderm (masculino), lo que implica que el primer nivel de estrato (“f”), es decir, el grupo femenino, es el grupo de referencia para el género. Por lo tanto, la interpretación del parámetro de la prueba es la de los hombres en comparación con las mujeres. El valor p indica que no hay pruebas suficientes de un efecto del género sobre el peligro esperado o de una asociación entre el género y la mortalidad por todas las causas.\nLa misma falta de pruebas se observa en relación con el grupo de edad.\n\n#ajustar el modelo cox\nlinelistsurv_cox_sexage &lt;-  survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#impresión del modelo ajustado\nlinelistsurv_cox_sexage\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n                      coef exp(coef) se(coef)      z     p\ngenderm           -0.03149   0.96900  0.04767 -0.661 0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n\nLikelihood ratio test=2.8  on 3 df, p=0.4243\nn= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n#resumen del modelo\nsummary(linelistsurv_cox_sexage)\n\nCall:\nsurvival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n    data = linelist_surv)\n\n  n= 4321, number of events= 1853 \n   (218 observations deleted due to missingness)\n\n                      coef exp(coef) se(coef)      z Pr(&gt;|z|)\ngenderm           -0.03149   0.96900  0.04767 -0.661    0.509\nage_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\nage_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n\n                  exp(coef) exp(-coef) lower .95 upper .95\ngenderm               0.969     1.0320    0.8826     1.064\nage_cat_small5-19     1.099     0.9103    0.9680     1.247\nage_cat_small20+      1.052     0.9509    0.9176     1.205\n\nConcordance= 0.514  (se = 0.007 )\nLikelihood ratio test= 2.8  on 3 df,   p=0.4\nWald test            = 2.78  on 3 df,   p=0.4\nScore (logrank) test = 2.78  on 3 df,   p=0.4\n\n\nFue interesante ejecutar el modelo y observar los resultados, pero un primer vistazo para verificar si se respetan los supuestos de riesgos proporcionales podría ayudar a ahorrar tiempo.\n\ntest_ph_sexage &lt;- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage\n\n              chisq df    p\ngender        0.454  1 0.50\nage_cat_small 0.838  2 0.66\nGLOBAL        1.399  3 0.71\n\n\nNOTA: Se puede especificar un segundo argumento llamado método cuando se calcula el modelo de Cox, que determina cómo se manejan los empates. El valor por defecto es “efron”, y las otras opciones son “breslow” y “exact”.\nEn otro modelo añadimos más factores de riesgo, como el origen de la infección y el número de días entre la fecha de inicio y el ingreso. Esta vez, primero verificamos la hipótesis de riesgos proporcionales antes de seguir adelante.\nEn este modelo, hemos incluido un predictor continuo (days_onset_hosp). En este caso, interpretamos las estimaciones de los parámetros como el aumento del logaritmo esperado del riesgo relativo por cada aumento de una unidad en el predictor, manteniendo los demás predictores constantes. Primero verificamos el supuesto de riesgos proporcionales.\n\n#ajustar el modelo\nlinelistsurv_cox &lt;-  coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#comprobar el modelo de riesgo proporcional\nlinelistsurv_ph_test &lt;- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test\n\n                   chisq df       p\ngender           0.45062  1    0.50\nage_years        0.00199  1    0.96\nsource           1.79622  1    0.18\ndays_onset_hosp 31.66167  1 1.8e-08\nGLOBAL          34.08502  4 7.2e-07\n\n\nLa verificación gráfica de esta suposición puede realizarse con la función ggcoxzph() del paquete survminer.\n\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n\n\n\n\n\n\n\n\nLos resultados del modelo indican que existe una asociación negativa entre la duración del inicio del ingreso y la mortalidad por todas las causas. El riesgo esperado es 0,9 veces menor en una persona que ingresa un día más tarde que otra, manteniendo el género constante. O, en una explicación más directa, un aumento de una unidad en la duración del inicio al ingreso se asocia con una disminución del 10,7% (coef *100) en el riesgo de muerte.\nLos resultados muestran también una asociación positiva entre la fuente de infección y la mortalidad por todas las causas. Es decir, hay un mayor riesgo de muerte (1,21 veces) para los pacientes que tuvieron una fuente de infección distinta de los funerales.\n\n#imprimir el resumen del modelo\nsummary(linelistsurv_cox)\n\nCall:\ncoxph(formula = Surv(futime, event) ~ gender + age_years + source + \n    days_onset_hosp, data = linelist_surv)\n\n  n= 2772, number of events= 1180 \n   (1767 observations deleted due to missingness)\n\n                     coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \ngenderm          0.004710  1.004721  0.060827  0.077   0.9383    \nage_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \nsourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \ndays_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\ngenderm            1.0047     0.9953    0.8918    1.1319\nage_years          0.9978     1.0023    0.9930    1.0025\nsourceother        1.1953     0.8366    1.0133    1.4100\ndays_onset_hosp    0.9012     1.1097    0.8764    0.9267\n\nConcordance= 0.566  (se = 0.009 )\nLikelihood ratio test= 71.31  on 4 df,   p=1e-14\nWald test            = 59.22  on 4 df,   p=4e-12\nScore (logrank) test = 59.54  on 4 df,   p=4e-12\n\n\nPodemos comprobar esta relación con una tabla:\n\nlinelist_case_data %&gt;% \n  tabyl(days_onset_hosp, outcome) %&gt;% \n  adorn_percentages() %&gt;%  \n  adorn_pct_formatting()\n\n days_onset_hosp Death Recover   NA_\n               0 44.3%   31.4% 24.3%\n               1 46.6%   32.2% 21.2%\n               2 43.0%   32.8% 24.2%\n               3 45.0%   32.3% 22.7%\n               4 41.5%   38.3% 20.2%\n               5 40.0%   36.2% 23.8%\n               6 32.2%   48.7% 19.1%\n               7 31.8%   38.6% 29.5%\n               8 29.8%   38.6% 31.6%\n               9 30.3%   51.5% 18.2%\n              10 16.7%   58.3% 25.0%\n              11 36.4%   45.5% 18.2%\n              12 18.8%   62.5% 18.8%\n              13 10.0%   60.0% 30.0%\n              14 10.0%   50.0% 40.0%\n              15 28.6%   42.9% 28.6%\n              16 20.0%   80.0%  0.0%\n              17  0.0%  100.0%  0.0%\n              18  0.0%  100.0%  0.0%\n              22  0.0%  100.0%  0.0%\n              NA 52.7%   31.2% 16.0%\n\n\nHabría que considerar e investigar por qué existe esta asociación en los datos. Una posible explicación podría ser que los pacientes que viven lo suficiente como para ser ingresados más tarde tenían una enfermedad menos grave para empezar. Otra explicación, quizá más probable, es que, dado que utilizamos unos datos falsos simulados, este patrón no refleja la realidad.\n\n\n\nForest plots\nA continuación, podemos visualizar los resultados del modelo cox utilizando los prácticos gráficos de bosque con la función ggforest() del paquete survminer.\n\nggforest(linelistsurv_cox, data = linelist_surv)",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html#time-dependent-covariates-in-survival-models",
    "href": "new_pages/survival_analysis.es.html#time-dependent-covariates-in-survival-models",
    "title": "27  Análisis de supervivencia",
    "section": "27.6 Covariables tiempo-dependientes en modelos de supervivencia",
    "text": "27.6 Covariables tiempo-dependientes en modelos de supervivencia\nAlgunas de las siguientes secciones han sido adaptadas con permiso de la excelente introducción al análisis de supervivencia en R por la Dra. Emily Zabor\nEn la última sección hemos tratado el uso de la regresión de Cox para examinar las asociaciones entre las covariables de interés y los resultados de supervivencia, pero estos análisis dependen de que la covariable se mida en la línea de base, es decir, antes de que comience el tiempo de seguimiento del evento.\n¿Qué ocurre si tienes interés en una covariable que se mide después del tiempo de seguimiento? O, ¿qué pasa si tienes una covariable que puede cambiar con el tiempo?\nPor ejemplo, tal vez estés trabajando con datos clínicos en los que se repiten medidas de valores de laboratorio del hospital que pueden cambiar con el tiempo. Este es un ejemplo de una covariable dependiente del tiempo. Para abordar esto se necesita una configuración especial, pero afortunadamente el modelo de Cox es muy flexible y este tipo de datos también puede ser modelado con herramientas del paquete survival.\n\nConfiguración de covariables dependientes del tiempo\nEl análisis de covariables dependientes del tiempo en R requiere la configuración de unos datos especial. Si tienes interés, mira el documento del autor del paquete survival Using Time Dependent Covariates and Time Dependent Coefficients in the Cox Model.\nPara ello, utilizaremos un nuevo conjunto de datos del paquete SemiCompRisks denominado BMT, que incluye datos de 137 pacientes de trasplante de médula ósea. Las variables en las que nos centraremos son:\n\nT1 - tiempo (en días) hasta la muerte o el último seguimiento\ndelta1 - indicador de muerte; 1-Muerto, 0-Vivo\nTA - tiempo (en días) hasta la enfermedad aguda de injerto contra huésped\ndeltaA - indicador de la enfermedad aguda de injerto contra huésped;\n\n1 - Desarrolló la enfermedad aguda de injerto contra huésped\n0 - Nunca desarrolló la enfermedad aguda de injerto contra huésped\n\n\nCargaremos este conjunto de datos del paquete survival utilizando el comando DE R base data(), que puede utilizarse para cargar datos que ya están incluidos en un paquete de R que se ha cargado. El dataframe BMT aparecerá en tu entorno de R.\n\ndata(BMT, package = \"SemiCompRisks\")\n\n\nAñadir un identificador único de paciente\nNo hay una columna de identificación única en los datos de BMT, que es necesaria para crear el tipo de conjunto de datos que queremos. Así que utilizamos la función rowid_to_column() del paquete tibble de tidyverse para crear una nueva columna de identificación llamada my_id (añade una columna al principio del dataframe con identificadores de fila secuenciales, empezando por el 1). Llamamos al dataframe bmt.\n\nbmt &lt;- rowid_to_column(BMT, \"my_id\")\n\nEl conjunto de datos tiene ahora este aspecto:\n\n\n\n\n\n\n\n\nAmpliar las filas de pacientes\nA continuación, utilizaremos la función tmerge() con las funciones de ayuda event() y tdc() para crear el conjunto de datos reestructurado. Nuestro objetivo es reestructurar el conjunto de datos para crear una fila separada para cada paciente por cada intervalo de tiempo en el que tengan un valor diferente de deltaA. En este caso, cada paciente puede tener como máximo dos filas dependiendo de si desarrollaron la enfermedad aguda de injerto contra huésped durante el periodo de recogida de datos. Llamaremos a nuestro nuevo indicador para el desarrollo de la enfermedad aguda de injerto contra huésped agvhd.\n\ntmerge() crea unos datos largos con múltiples intervalos de tiempo para los diferentes valores de las covariables de cada paciente\nevent() crea el nuevo indicador de eventos para que vaya con los intervalos de tiempo recién creados\ntdc() crea la columna de covarianza dependiente del tiempo, agvhd, para que vaya con los intervalos de tiempo recién creados\n\n\ntd_dat &lt;- \n  tmerge(\n    data1 = bmt %&gt;% select(my_id, T1, delta1), \n    data2 = bmt %&gt;% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\n\nPara ver qué hace esto, veamos los datos de los 5 primeros pacientes individuales.\nLas variables de interés en los datos originales tenían este aspecto:\n\nbmt %&gt;% \n  select(my_id, T1, delta1, TA, deltaA) %&gt;% \n  filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1   TA deltaA\n1     1 2081      0   67      1\n2     2 1602      0 1602      0\n3     3 1496      0 1496      0\n4     4 1462      0   70      1\n5     5 1433      0 1433      0\n\n\nEl nuevo conjunto de datos para estos mismos pacientes tiene el siguiente aspecto:\n\ntd_dat %&gt;% \n  filter(my_id %in% seq(1, 5))\n\n  my_id   T1 delta1 tstart tstop death agvhd\n1     1 2081      0      0    67     0     0\n2     1 2081      0     67  2081     0     1\n3     2 1602      0      0  1602     0     0\n4     3 1496      0      0  1496     0     0\n5     4 1462      0      0    70     0     0\n6     4 1462      0     70  1462     0     1\n7     5 1433      0      0  1433     0     0\n\n\nAhora algunos de nuestros pacientes tienen dos filas en el conjunto de datos correspondientes a intervalos en los que tienen un valor diferente de nuestra nueva variable, agvhd. Por ejemplo, el paciente 1 tiene ahora dos filas con un valor de agvhd de cero desde el tiempo 0 hasta el tiempo 67, y un valor de 1 desde el tiempo 67 hasta el tiempo 2081.\n\n\n\nRegresión de Cox con covariables dependientes del tiempo\nAhora que hemos remodelado nuestros datos y añadido la nueva variable aghvd dependiente del tiempo, vamos a ajustar un modelo de regresión cox simple de una sola variable. Podemos utilizar la misma función coxph() que antes, sólo tenemos que cambiar nuestra función Surv() para especificar tanto el tiempo de inicio como el de finalización de cada intervalo utilizando los argumentos time1 = y time2 =.\n\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n    agvhd, data = td_dat)\n\n  n= 163, number of events= 80 \n\n        coef exp(coef) se(coef)    z Pr(&gt;|z|)\nagvhd 0.3351    1.3980   0.2815 1.19    0.234\n\n      exp(coef) exp(-coef) lower .95 upper .95\nagvhd     1.398     0.7153    0.8052     2.427\n\nConcordance= 0.535  (se = 0.024 )\nLikelihood ratio test= 1.33  on 1 df,   p=0.2\nWald test            = 1.42  on 1 df,   p=0.2\nScore (logrank) test = 1.43  on 1 df,   p=0.2\n\n\nDe nuevo, visualizaremos los resultados de nuestro modelo de Cox utilizando la función ggforest() del paquete urvminer.:\n\nggforest(bmt_td_model, data = td_dat)\n\n\n\n\n\n\n\n\nComo se puede ver en el gráfico de forest, el intervalo de confianza y el valor-p, no parece haber una fuerte asociación entre la muerte y la enfermedad aguda de injerto contra huésped en el contexto de nuestro modelo simple.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/survival_analysis.es.html#resources-20",
    "href": "new_pages/survival_analysis.es.html#resources-20",
    "title": "27  Análisis de supervivencia",
    "section": "27.7 Recursos",
    "text": "27.7 Recursos\nAnálisis de supervivencia Parte I: Conceptos básicos y primeros análisis\nAnálisis de supervivencia en R\nAnálisis de supervivencia en la investigación de enfermedades infecciosas: Descripción de eventos en el tiempo\nCapítulo sobre modelos de supervivencia avanzados Princeton\nUso de covariables y coeficientes dependientes del tiempo en el modelo de Cox\nHoja de trucos de análisis de supervivencia con R\nHoja de trucos de Survminer\nDocumento sobre diferentes medidas de supervivencia para datos de registros de cáncer con Rcode proporcionado como material suplementario",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Análisis de supervivencia</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html",
    "href": "new_pages/gis.es.html",
    "title": "28  Conceptos básicos de los SIG",
    "section": "",
    "text": "28.1 Resumen\nLos aspectos espaciales de tus datos pueden proporcionar mucha información sobre la situación del brote, y responder a preguntas como:\nEl enfoque actual de esta página de los SIG (Sistemas de información geográfico; GIS, por sus siglas en inglés) es abordar las necesidades de la epidemiología aplicada en su respuesta a los brotes. Exploraremos los métodos básicos de visualización de datos espaciales utilizando los paquetes tmap y ggplot2. También recorreremos algunos de los métodos básicos de gestión y consulta de datos espaciales con el paquete sf. Por último, abordaremos brevemente conceptos de estadística espacial como las relaciones espaciales, la autocorrelación espacial y la regresión espacial utilizando el paquete spdep.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#overview-6",
    "href": "new_pages/gis.es.html#overview-6",
    "title": "28  Conceptos básicos de los SIG",
    "section": "",
    "text": "¿Dónde están los focos actuales de la enfermedad?\n¿Cómo han cambiado los puntos conflictivos con el tiempo?\n¿Cómo es el acceso a las instalaciones sanitarias? ¿Se necesitan mejoras?",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#key-terms-1",
    "href": "new_pages/gis.es.html#key-terms-1",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.2 Términos clave",
    "text": "28.2 Términos clave\nA continuación presentamos algunos términos clave. Para una introducción completa a los SIG y al análisis espacial, te sugerimos que revises uno de los tutoriales o cursos más largos que aparecen en la sección de Recursos.\nSistemas de Información Geográfica (SIG) - Un SIG es un marco o entorno de trabajo para recopilar, gestionar, analizar y visualizar datos espaciales.\n\nSoftware SIG\nAlgunos de los programas de SIG más conocidos permiten la interacción “señalar y clicar” para el desarrollo de mapas y el análisis espacial. Estas herramientas tienen ventajas como no tener que aprender código y la facilidad de seleccionar y colocar manualmente los iconos y características en un mapa. He aquí dos de los más populares:\nArcGIS - Un software comercial de SIG desarrollado por la empresa ESRI, que es muy popular pero bastante caro.\nQGIS - Un software de SIG gratuito de código abierto que puede hacer casi todo lo que ArcGIS puede hacer. Puedes descargar QGIS aquí\nEl uso de R como SIG puede parecer más intimidante al principio porque, en lugar de “señalar y clicar”, tiene una “interfaz de línea de comandos” (hay que codificar para adquirir el resultado deseado). Sin embargo, esto es una gran ventaja si se necesita producir mapas repetidamente o crear un análisis que sea reproducible.\n\n\nDatos espaciales\nLas dos formas principales de datos espaciales utilizadas en los SIG son los datos vectoriales y los ráster:\nDatos vectoriales - Es el formato más común de datos espaciales utilizado en los SIG. Los datos vectoriales se componen de características geométricas de vértices y trayectorias. Los datos espaciales vectoriales pueden dividirse a su vez en tres tipos ampliamente utilizados:\n\nPuntos - Un punto consiste en un par de coordenadas (x,y) que representan una ubicación específica en un sistema de coordenadas. Los puntos son la forma más básica de datos espaciales, y pueden utilizarse para denotar un caso (por ejemplo, el domicilio de un paciente) o una ubicación (por ejemplo, un hospital) en un mapa.\nLíneas - Una línea está compuesta por dos puntos conectados. Las líneas tienen una longitud y pueden utilizarse para indicar cosas como carreteras o ríos.\nPolígonos - Un polígono está compuesto por al menos tres líneas conectadas por puntos. Los polígonos tiene una longitud (es decir, el perímetro del área) así como una medida de área. Los polígonos pueden utilizarse para señalar una zona (por ejemplo, un pueblo) o una estructura (por ejemplo, la superficie real de un hospital).\n\nDatos ráster - Es un formato alternativo para los datos espaciales. Los datos ráster son una matriz de celdas (por ejemplo, píxeles) en la que cada celda contiene información como la altura, la temperatura, la pendiente, la cubierta forestal, etc. Suelen ser fotografías aéreas, imágenes de satélite, etc. Las imágenes ráster también pueden utilizarse como “mapas base” debajo de los datos vectoriales.\n\n\nVisualización de datos espaciales\nPara representar visualmente los datos espaciales en un mapa, el software SIG requiere que se proporcione suficiente información sobre dónde deben estar las diferentes características y la relación de unas con otras. Si se utilizan datos vectoriales, como ocurre en la mayoría de los casos, esta información suele almacenarse en un archivo shapefile:\nShapefiles - Un shapefile es un formato de datos común para almacenar datos espaciales “vectoriales” consistentes en líneas, puntos o polígonos. Un shapefile es en realidad un grupo de al menos tres archivos - .shp, .shx y .dbf. Estos archivos deben estar en un determinado directorio (una misma carpeta) para que el shapefile se pueda leer. Estos archivos asociados pueden comprimirse en un archivo ZIP para enviarlos por correo electrónico o descargarlos de un sitio web.\nEl shapefile contendrá información sobre las características con las que estemos tratando, así como su ubicación en la superficie de la Tierra. Esto es importante porque, aunque la Tierra es un globo terráqueo, los mapas suelen ser bidimensionales; las decisiones sobre cómo “aplanar” los datos espaciales pueden tener un gran impacto en el aspecto y la interpretación del mapa resultante.\nSistemas de referencia de coordenadas (CRS-SRC) - Un SRC es un sistema basado en coordenadas que se utiliza para localizar accidentes geográficos en la superficie de la Tierra. Tiene unos cuantos componentes clave:\n\nSistema de coordenadas - Hay muchos sistemas de coordenadas diferentes, así que asegúrate de saber en qué sistema están tus coordenadas. Los grados de latitud/longitud son muy comunes, pero también puede que tu información esté guardada como coordenadas UTM.\nUnits - Asegúrate de saber cuáles son las unidades del sistema de coordenadas (por ejemplo, grados decimales, metros).\nDatum - Es una versión particular modelada de la Tierra. Los datum ya estan establecidos y han sido revisados a lo largo de los años, así que asegúrate de que las capas de tu mapa utilizan el mismo datum.\nProyección - Es la referencia a la ecuación matemática que se utilizó para proyectar la tierra (realmente redonda) sobre una superficie plana (mapa).\n\nRecuerda que puedes resumir los datos espaciales sin utilizar las herramientas cartográficas que se muestran a continuación. A veces basta con una simple tabla por zonas geográficas (por ejemplo, distrito, país, etc.).",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#getting-started-with-gis",
    "href": "new_pages/gis.es.html#getting-started-with-gis",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.3 Introducción a los SIG",
    "text": "28.3 Introducción a los SIG\nHay un par de elementos clave que deberás tener y en los que deberás pensar para hacer un mapa. Entre ellos están:\n\nDatos: pueden estar con un formato de datos espaciales (como los shapefiles, como se ha indicado anteriormente) o pueden no estar en un formato espacial (por ejemplo, sólo como un csv).\nSi tus datos no están en formato espacial, también necesitarás unos datos de referencia. Los datos de referencia consisten en la representación espacial de los datos y sus atributos relacionados, que incluirían el material que contiene la información de ubicación y dirección de características específicas.\nSi estás trabajando con límites geográficos predefinidos (por ejemplo, regiones administrativas), probablemente puedas encontrar shapefiles de referencia que te puedes descargar de forma gratuita desde una agencia gubernamental u organización de intercambio de datos. En caso de duda, un buen punto de partida es buscar en Google “[regions] shapefile”\nSi tus datos están guardados como direcciones, en vez de como latitud/longitud, puede que tengas que utilizar un motor de geocodificación que te permita hacer la “traducción” de una dirección específica a a datos en formato espacial.\nPiensa cómo quieres presentar la información de los datos a tu audiencia. Hay muchos tipos diferentes de mapas, y es importante pensar qué tipo de mapa se ajusta mejor a tus necesidades.\n\n\nTipos de mapas para visualizar tus datos\nMapa de coropletas: Es un tipo de mapa temático en el que se utiliza colores, sombreados o patrones para representar regiones geográficas en relación con el valor de un atributo. Por ejemplo, un valor mayor podría indicarse con un color más oscuro que un valor menor. Este tipo de mapa es particularmente útil cuando se visualiza una variable y cómo cambia a través de regiones o áreas geopolíticas definidas.\n\n\n\n\n\n\n\n\n\nMapa de densidad de calor de casos: Es un tipo de mapa temático en el que se utiliza colores para representar la intensidad de un valor, pero que no utiliza regiones definidas ni límites geopolíticos para agrupar los datos. Este tipo de mapa se suele utilizar para mostrar “puntos conflictivos” o zonas con una alta densidad o concentración de puntos.\n\n\n\n\n\n\n\n\n\nMapa de densidad de puntos: Es un tipo de mapa temático que utiliza puntos para representar los valores de los datos. Este tipo de mapa es el más adecuado para visualizar cómo están dispersos los datos en el mapa y buscar clústers visualmente.\nMapa de símbolos proporcionales (mapa de símbolos graduados): es un mapa temático similar a un mapa de coropletas, pero en lugar de utilizar el color para indicar el valor de un atributo, utiliza un símbolo (normalmente un círculo) cuyo tamaño esta en relación con el valor. Por ejemplo, un valor mayor podría indicarse con un símbolo de tamaño mayor que un valor menor. Este tipo de mapa se utiliza mejor cuando se quiere visualizar el tamaño o la cantidad de los datos en distintas regiones geográficas.\nTambién puedes combinar varios tipos de visualizaciones diferentes para mostrar patrones geográficos complejos. Por ejemplo, los casos (puntos) del siguiente mapa están coloreados según su centro sanitario más cercano (véase la leyenda). Los círculos grandes de color negro muestran las zonas de captación de los centros sanitarios de un determinado radio, y los puntos/círculos rojos brillantes son los que no tienen ninguna zona de captación de centros sanitarios dentro de ese radio determinado:\n\n\n\n\n\n\n\n\n\nNota: El enfoque principal de esta página del SIG se centra en el contexto de respuesta a brotes en el terreno. Por lo tanto, el contenido de esta página cubrirá la manipulación, visualización y análisis básicos de datos espaciales.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#preparation-19",
    "href": "new_pages/gis.es.html#preparation-19",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.4 Preparación",
    "text": "28.4 Preparación\n\nCargar paquetes\nEste trozo de código muestra cómo puedes cargar de los paquetes necesarios para el análisis espacial que vamos a realizar. En este manual destacamos la función p_load() del paquete pacman: esta instala el paquete (si aún no está instalado) y lo carga para su uso. También puedes cargar los paquetes uno por uno con la funcion library() de R base., si ya los tienes instalados. Consulta la página sobre los Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,           # para importar datos\n  here,          # para localizar archivos\n  tidyverse,     # para limpiar, manejar y graficar los datos (incluye el paquete ggplot2)\n  sf,            # para manejar datos espaciales usando el formato Simple Feature\n  tmap,          # para producir mapas simples, funciona tanto para mapas interactivos como estáticos\n  janitor,       # para limpiar los nombres de las columnas\n  OpenStreetMap, # para añadir el mapa base OSM en el mapa ggplot\n  spdep          # estadísticas espaciales\n  ) \n\nEn este enlace de CRAN “Spatial Task View” puedes ver un resumen de todos los paquetes de R que pueden trabajar con datos espaciales.\n\n\nEjemplos con una base de datos\nA muestra de ejemplo, trabajaremos con una muestra aleatoria de 1000 casos del brote de ébola simulado en el dataframe linelist (computacionalmente, una base de datos pequeña hace que sea más fácil trabajar con este ejemplo). Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds).\nLos resultados que tengas al correr el código de este ejercicio puede que sean un poco diferentes de los que se aquí mostramos. Esto es porque vamos a estar trabajando con una muestra aleatoria de los casos.\nImporta los datos con la función import() del paquete rio (este paquete puede manejar muchos tipos de archivos, como .xlsx, .csv, .rds - véase la página de importación y exportación para más detalles).\n\n#  importar linelist limpio\nlinelist &lt;- import(\"linelist_cleaned.rds\")  \n\nPara seleccionar la muestra aleatoria de 1000 filas utiliza sample() de R base.\n\n# genera 1000 números de fila aleatorios, a partir del número de filas de linelist\nsample_rows &lt;- sample(nrow(linelist), 1000)\n\n# subconjunto de linelist para mantener sólo las filas de muestra, y todas las columnas\nlinelist &lt;- linelist[sample_rows,]\n\nAhora queremos convertir este linelist, que es de tipo “dataframe”, en un objeto de tipo “sf” (spatial features, por sus siglas en inglés). Dado que linelist tiene dos columnas “lon” y “lat” que representan la longitud y latitud de la residencia de cada caso, esto será fácil.\nUtilizamos la función st_as_sf() del paquete sf (spatial features) para crear el nuevo objeto que llamamos linelist_sf. Este nuevo objeto tiene el mismo aspecto que la linelist, pero las columnas lon y lat han sido designadas como columnas de coordenadas, y se ha asignado un sistema de referencia de coordenadas (CRS) para poder visualizar los puntos. Este CRS es el númermo 4326 que corresponde a coordenadas especificas basadas en el Sistema Geodésico Mundial 1984 (WGS84) - que es el estándar para las coordenadas GPS.\n\n# Crea el objeto sf\nlinelist_sf &lt;- linelist %&gt;%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nEste es el aspecto del dataframe original linelist. En esta demostración, sólo utilizaremos la columna date_onset y geometry (que se construyó a partir de los campos de longitud y latitud anteriores y es la última columna del dataframe).\n\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n\n\n\n\n\n\n\nArchivos shapefiles de límites administrativos\nSierra Leona: Archivos shapefiles de los límites administrativos\nPrimero, descárgate todos los límites administrativos de Sierra Leona del sitio web de Humanitarian Data Exchange (HDX). Como alternativa, también te puedes descargar estos archivos y todos los demás datos de ejemplo que usamos para este manual a través de nuestro paquete R, como se explica en la página descargando el manual y los datos.\nAhora vamos a hacer lo siguiente para guardar el shapefile del nivel administrativo 3 en R:\n\nImportar el shapefile\nLimpiar los nombres de las columnas\nFiltrar las filas para mantener sólo las áreas de interés\n\nPara importar un shapefile utilizamos la función read_sf() del paquete sf, y usamos la función here() para que R encuentre el archivo. En nuestro caso, el archivo se encuentra dentro de nuestro proyecto R en las subcarpetas “data”, “gis” y “shp”, con nombre de archivo “sle_adm3.shp” (para más información ver las páginas sobre Importación y exportación y Proyectos en R). En tu caso, tendrás que indicar la localización específica donde tienes tus archivos en tu ordenador.\nA continuación utilizamos clean_names() del paquete janitor para estandarizar los nombres de las columnas del shapefile. También utilizamos filter() para mantener sólo las filas con admin2name de “Western Area Urban” o “Western Area Rural”.\n\n# Limpieza de nivel ADM3\nsle_adm3 &lt;- sle_adm3_raw %&gt;%\n  janitor::clean_names() %&gt;% # estandariza los nombres de las columnas  \n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filter to keep certain areas\n\nA continuación puedes ver el aspecto del shapefile después de la importación y limpieza. Desplázate a la derecha para ver cómo hay columnas con el nivel de administración 0 (país), el nivel de administración 1, el nivel de administración 2 y, finalmente, el nivel de administración 3. Cada nivel tiene un nombre y un identificador único “pcode”. El pcode se expande con cada nivel de administración creciente, por ejemplo, SL (Sierra Leona) -&gt; SL04 (Occidental) -&gt; SL0410 (Zona Occidental Rural) -&gt; SL040101 (Koya Rural).\n\n\n\n\n\n\n\n\nDatos de población\nSierra Leona: Población por ADM3\nAl igual que hemos hecho antes, te puedes descargar estos datos de HDX) o a través de nuestro paquete R epirhandbook como se explica en esta página. Utilizamos import() para cargar el archivo .csv. Al igual que antes, pasamos el archivo importado a clean_names() para estandarizar la sintaxis de los nombres de las columnas.\n\n# Población del nivel ADM3\nsle_adm3_pop &lt;- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %&gt;%\n  clean_names() \n\nEste es el aspecto del archivo de población. Desplázate a la derecha para ver cómo cada jurisdicción tiene columnas con la población male, female, y la población total y el desglose de la población en columnas por grupos de edad.\n\n\n\n\n\n\n\n\nInstalaciones sanitarias\nSierra Leone: Health facility data from OpenStreetMap\nUna vez más, hemos descargado la localización de los centros sanitarios desde el HDX aquí o mediante las instrucciones de la página descarga de manuales y datos.\nImportamos el shapefile de puntos de las instalaciones con read_sf(), limpiamos de nuevo los nombres de las columnas y filtramos para mantener sólo los puntos etiquetados como “hospital”, “clinic” o “doctors”.\n\n# Archivo shapefile OSM de centros sanitarios\nsle_hf &lt;- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %&gt;% \n  clean_names() %&gt;% \n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))\n\nAquí está el dataframe resultante – desplázate a la derecha para ver el nombre de la instalación y las coordenadas geométricas (geometry).",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#plotting-coordinates",
    "href": "new_pages/gis.es.html#plotting-coordinates",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.5 Trazado de coordenadas",
    "text": "28.5 Trazado de coordenadas\nLa forma más sencilla de representar las coordenadas X-Y (longitud/latitud, puntos) de los casos es dibujarlas como puntos directamente desde el objeto linelist_sf que ya creamos en la sección de preparación.\nEl paquete tmap nos permite visualizar este tipo de informacion tanto de modo estático (modo “plot”) como de modo interactivo (modo “view”) con sólo unas pocas líneas de código. La sintaxis de tmap es similar a la de ggplot2, de forma que los comandos se añaden unos a otros con +. Lee más detalles en esta viñeta.\n\nLo primero es establecer qué modo tmap queremos. En este caso utilizaremos el modo “plot”, que produce salidas estáticas.\n\n\ntmap_mode(\"plot\") # choose either \"view\" or \"plot\"\n\nAbajo puedes ver que, por ahora, sólo estamos trazando los puntos. Utilizamos el tm_shape() con el objeto linelist_sf. A continuación, añadimos la informacion de los puntos mediante tm_dots(), especificando el tamaño y el color deseados. Recuerda que el linelist_sf es un objeto sf, con lo que ya tenemos designadas las dos columnas que contienen las coordenadas lat/long y el sistema de referencia de coordenadas (CRS):\n\n# Sólo los casos (puntos)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n\n\n\n\n\n\n\n\nPor sí solos, los puntos no nos dicen mucho. Así que también tenemos que dibujar los límites administrativos:\nPara esto, vamos a usar tm_shape() (documentación), pero en vez de proporcionar el shapefile de los puntos de los casos, proporcionamos el shapefile de los límites administrativos (polígonos).\nCon el argumento bbox =(bbox significa “bounding box”) podemos especificar los límites de las coordenadas, lo cual nos ayuda a hacer zoom a una zona específica de interés. Primero mostramos la visualización del mapa sin bbox, y luego con él.\n\n# Sólo los límites administrativos (polígonos)\ntm_shape(sle_adm3) +               # shapefile de límites administrativos\n  tm_polygons(col = \"#F7F7F7\")+    # muestra los polígonos en gris claro\n  tm_borders(col = \"#000000\",      # muestra las fronteras con color y línea gruesa\n             lwd = 2) +\n  tm_text(\"admin3name\")            # texto de columna a mostrar para cada polígono\n\n\n# Same as above, but with zoom from bounding box\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # esquina\n                  -13.2, 8.5)) +  # esquina opuesta\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCon esto ya podemos trazar los puntos y los polígonos juntos:\n\n# Todo junto\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # da título al mapa\n\n\n\n\n\n\n\n\nPara leer una buena comparación de las opciones de mapeo en R, consulta esta entrada del blog.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#spatial-joins",
    "href": "new_pages/gis.es.html#spatial-joins",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.6 Uniones espaciales",
    "text": "28.6 Uniones espaciales\nEs posible que estés familiarizado/a con la unión de datos entre bases de datos. En la página unión de datos de este manual se trata varios métodos para unir bases de datos. Una unión espacial tiene un propósito similar, pero aprovecha las relaciones espaciales entre bases de datos. En lugar de confiar en los valores comunes de las columnas para hacer coincidir correctamente las observaciones, puede utilizar distintos tipos de relaciones espaciales, como por ejemplo que una característica esté contenida dentro de otra, que sea el “vecino más cercano” de otra característica, o que esté dentro de un buffer de determinado radio de otra.\nEl paquete sf ofrece varios métodos para las uniones espaciales. Puedes explorar la documentación del método st_join() y otros tipos de uniones espaciales en esta referencia.\n\nPuntos en el polígono\nAsignación espacial de unidades administrativas a los casos\nAquí se plantea un dilema interesante: la lista de casos no contiene ninguna información sobre las unidades administrativas de los mismos. Aunque lo ideal es recoger dicha información durante la fase inicial de recogida de datos, también podemos asignar unidades administrativas a los casos individuales basándonos en sus relaciones espaciales (es decir, el punto se cruza con un polígono).\nA continuación, haremos una intersección espacial de las ubicaciones de nuestros casos (puntos) con los límites de la ADM3 (polígonos):\n\nComenzamos con la linelist (casos/puntos)\nContinuamos con la unión espacial a los límites administrativos, estableciendo el tipo de unión en “st_intersects”\nUtilizamos select() para mantener sólo algunas de las nuevas columnas de los límites administrativos (este paso lo realizamos un poco más abajo)\n\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # une el fichero de límites administrativos a la lista de casos, basándose en la intersección espacial\n  sf::st_join(sle_adm3, join = st_intersects)\n\n¡Todas las columnas de sle_adms se han añadido a linelist! Cada caso tiene ahora columnas que detallan los niveles administrativos a los que pertenece. En este ejemplo, sólo queremos mantener dos de las nuevas columnas (las de nivel administrativo 3), así que haremos select() de los nombres de las columnas antiguas de la linelist, y sólo las dos adicionales de interés:\n\nlinelist_adm &lt;- linelist_sf %&gt;%\n  \n  # une el fichero de límites administrativos a la lista de casos, basándose en la intersección espacial\n  sf::st_join(sle_adm3, join = st_intersects) %&gt;% \n  \n  # Mantiene los antiguos nombres de columna y dos nuevos admin de interés\n  select(names(linelist_sf), admin3name, admin3pcod)\n\nAquí os mostramos los diez primeros casos para que veais que se ha añadido la información correspondiente de sus jurisdicciones a nivel de administración 3 (ADM3), basándose en la región del polígono donde se cruza el punto.\n\n# Ahora se verán los nombres ADM3 adjuntos a cada caso\nlinelist_adm %&gt;% select(case_id, admin3name, admin3pcod)\n\nSimple feature collection with 1000 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -13.27101 ymin: 8.446206 xmax: -13.20684 ymax: 8.489713\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     case_id     admin3name admin3pcod                   geometry\n3126  74a28f         West I   SL040206  POINT (-13.2472 8.483339)\n353   ed67c0 Mountain Rural   SL040102 POINT (-13.21534 8.470513)\n611   b788f1 Mountain Rural   SL040102 POINT (-13.21094 8.453044)\n4741  c2595d       West III   SL040208 POINT (-13.26345 8.464106)\n1849  e4511f Mountain Rural   SL040102 POINT (-13.21843 8.477415)\n1711  f42008         West I   SL040206 POINT (-13.24938 8.488129)\n1437  62a2ef        West II   SL040207 POINT (-13.23794 8.469774)\n3195  41f6db       West III   SL040208 POINT (-13.25348 8.459296)\n2030  604a5e       West III   SL040208  POINT (-13.26761 8.46162)\n495   ce86cc      Central I   SL040201 POINT (-13.23299 8.487209)\n\n\nAhora podemos describir nuestros casos por unidad administrativa, algo que no podíamos hacer antes de la unión espacial.\n\n# Crear un nuevo dataframe que contiene los recuentos de casos por unidad administrativa\ncase_adm3 &lt;- linelist_adm %&gt;%          # comienza con linelist con nuevas cols administrativas\n  as_tibble() %&gt;%                      # convierte a tibble para una mejor visualización\n  group_by(admin3pcod, admin3name) %&gt;% # agrupa por unidad administrativa, tanto por nombre como por pcode\n  summarise(cases = n()) %&gt;%           # resumen y recuento de filas\n  arrange(desc(cases))                     # ordena en orden descendente\n\ncase_adm3\n\n# A tibble: 10 × 3\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;\n 1 SL040102   Mountain Rural   276\n 2 SL040208   West III         234\n 3 SL040207   West II          176\n 4 SL040204   East II          103\n 5 SL040201   Central I         63\n 6 SL040203   East I            61\n 7 SL040206   West I            47\n 8 SL040202   Central II        22\n 9 SL040205   East III          16\n10 &lt;NA&gt;       &lt;NA&gt;               2\n\n\nTambién podemos crear un gráfico de barras con el número de casos por unidad administrativa.\nEn este ejemplo, utilizamos ggplot() con linelist_adm para poder aplicar funciones que manejan factores, como fct_infreq() que ordena las barras por frecuencia (véase la página sobre Factores para ver algunos consejos).\n\nggplot(\n    data = linelist_adm,                       # comienza con linelist que contiene información de la unidad administrativa\n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # el eje-x son unidades admin, ordenadas por frecuencia (invertida)\n  geom_bar()+                                # crea barras, la altura es el número de filas\n  coord_flip()+                              # invierte los ejes X e Y para facilitar la lectura de las unidades adm\n  theme_classic()+                           # simplifica el fondo\n  labs(                                      # títulos y etiquetas\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nVecino más cercano\nEncontrar el centro sanitario más cercano\nPodría ser útil saber dónde se encuentran los centros sanitarios (clínicas/hospitales) en relación con los focos de la enfermedad.\nPodemos utilizar el método de unión st_nearest_feature de la función st_join() (paquete sf) para visualizar el centro sanitario más cercano a cada uno de los casos.\n\nComenzamos con el shapefile linelist linelist_sf\nUnimos espacialmente con sle_hf, que es la ubicación de los centros sanitarios y las clínicas (puntos), estableciendo el tipo de unión en “st_nearest_feature”\n\n\n# Centro sanitario más cercano a cada caso\nlinelist_sf_hf &lt;- linelist_sf %&gt;%                  # comienza con el shapefile delinelist  \n  st_join(sle_hf, join = st_nearest_feature) %&gt;%   # datos de la clínica más cercana unidos a los datos del caso \n  select(case_id, osm_id, name, amenity) %&gt;%       # mantiene las columnas de interés, incluyendo id, nombre, tipo y geometría del centro sanitario\n  rename(\"nearest_clinic\" = \"name\")                # renombra para mayor claridad\n\nPodemos ver a continuación (primeras 50 filas) que cada caso tiene ahora datos sobre la clínica/hospital más cercano\n\n\n\n\n\n\nPodemos ver que “Den Clinic” es el centro sanitario más cercano para aproximadamente el 30% de los casos.\n\n# Contar casos por centro sanitario\nhf_catchment &lt;- linelist_sf_hf %&gt;%   # comienza con linelist incluyendo datos de la clínica más cercana\n  as.data.frame() %&gt;%                # convierte de shapefile a dataframe\n  count(nearest_clinic,              # cuenta filas por \"nombre\" (de la clínica)\n        name = \"case_n\") %&gt;%         # asigna nueva columna de recuento como \"case_n\"\n  arrange(desc(case_n))              # ordena en orden descendente\n\nhf_catchment                         # imprime en la consola\n\n                         nearest_clinic case_n\n1                            Den Clinic    381\n2       Shriners Hospitals for Children    317\n3         GINER HALL COMMUNITY HOSPITAL    173\n4                             panasonic     45\n5 Princess Christian Maternity Hospital     38\n6                  MABELL HEALTH CENTER     18\n7                                  &lt;NA&gt;     16\n8                     ARAB EGYPT CLINIC     12\n\n\nPara visualizar los resultados, podemos utilizar tmap - esta vez en modo interactivo para facilitar la visualización\n\ntmap_mode(\"view\")   # establece el modo tmap en interactivo\n\n# representar los casos y los puntos de las clínicas \ntm_shape(linelist_sf_hf) +            # representa los casos\n  tm_dots(size=0.08,                  # casos coloreados por la clínica más cercana\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # puntos negros grandes para las clínicas\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # se superpone el nombre de la clínica\ntm_view(set.view = c(-13.2284, 8.4699, 13), # ajusta el zoom (coordenadas centrales, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cases, colored by nearest clinic\")\n\n\n\n\n\n\n\nBuffers\nTambién podemos explorar cuántos casos se encuentran a menos de 2,5 km (~30 minutos) de distancia a pie del centro sanitario más cercano. Esto se conoce como buffer o zona o ámbito de influencia.\nNota: Para un cálculo más preciso de la distancia, es mejor reproyectar el objeto sf al respectivo sistema de proyección cartográfica local, como UTM (Tierra proyectada sobre una superficie plana). En este ejemplo, para simplificar, nos ceñiremos al sistema de coordenadas geográficas del Sistema Geodésico Mundial (WGS84) (la Tierra representada en una superficie esférica/redonda, por lo que las unidades están en grados decimales). Utilizaremos una conversión general de: 1 grado decimal = ~111km.\nPuedes ver más información sobre proyecciones cartográficas y sistemas de coordenadas en este artículo de esri. Este blog habla de los diferentes tipos de proyecciones cartográficas y de cómo se puede elegir una proyección adecuada en función del área de interés y del contexto de su mapa/análisis.\nEn primer lugar, se crea un buffer circular con un radio de ~2,5km alrededor de cada centro sanitario. Esto se hace con la función st_buffer() de tmap. Como la unidad del mapa está en grados decimales lat/long, tenemos que proporcionar el valor de dist en grados decimales, es decir, tenemos que proporcionar un valor de “0,02” (2,5/111 = 0.02 grados decimales, correspondiente a ~2,5km). Si el sistema de coordenadas del mapa está en metros, el número debe proporcionarse en metros.\n\nsle_hf_2k &lt;- sle_hf %&gt;%\n  st_buffer(dist=0.02)       # grados decimales que se corresponden con aproximadamente 2.5km \n\nA continuación, trazamos las zonas de influencia propiamente dichas, con ese buffer:\n\ntmap_mode(\"plot\")\n# Crear buffers circulares\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # trazar las instalaciones clínicas en grandes puntos rojos\n  tm_dots(size=0.3, col='black')      \n\n\n\n\n\n\n\n\nEn segundo lugar, intersectamos estos buffers con los casos (puntos) utilizando st_join() y el tipo de unión st_intersects. Es decir, ponemos juntos los datos de los buffers y los de los puntos con los que se cruzan.\n\n# Intersecta los casos con los buffers\nlinelist_sf_hf_2k &lt;- linelist_sf_hf %&gt;%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %&gt;%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %&gt;%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n\nAhora podemos contabilizar cuántos de nuestros casos no estan dentro de ningun buffer (sus puntos no se cruzan con ningún buffer): nrow(linelist_sf_hf_2k[is.na(linelist_sf_hf_2k$osm_id.y),]). Con este código vemos que falta información para este valor (estamos buscando NA), y por tanto, inferimos que estos casos viven a más de 30 minutos a pie del centro sanitario más cercano.\n\n# Casos que no se cruzaron con ninguno de los buffers de los centros sanitarios\nlinelist_sf_hf_2k %&gt;% \n  filter(is.na(osm_id.y)) %&gt;%\n  nrow()\n\n[1] 1000\n\n\nPodemos visualizar los resultados de forma que los casos que no se cruzan con ningún buffer aparezcan en rojo.\n\ntmap_mode(\"view\")\n\n# Primero muestra los casos en puntos\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# representa las instalaciones sanitarias en puntos negros grandes\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# A continuación, se superpone el buffer de los centros sanitarios en polilíneas\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Se resaltan los casos que no forman parte de ningún centro sanitario\n# en puntos rojos  \ntm_shape(linelist_sf_hf_2k %&gt;%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# añade el título   \ntm_layout(title = \"Cases by clinic catchment area\")\n\n\n\n\n\n\n\nOtras uniones espaciales\nLos siguientes son valores alternativos para el argunmento join (puedes encontrar más información en documentation)\n\nst_contains_properly\n\nst_contains\n\nst_covered_by\n\nst_covers\n\nst_crosses\n\nst_disjoint\n\nst_equals_exact\n\nst_equals\n\nst_is_within_distance\n\nst_nearest_feature\n\nst_overlaps\n\nst_touches\n\nst_within",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#choropleth-maps",
    "href": "new_pages/gis.es.html#choropleth-maps",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.7 Mapas de coropletas",
    "text": "28.7 Mapas de coropletas\nLos mapas de coropletas pueden ser útiles para visualizar los datos por áreas predefinidas, como por ejemplo unidades administrativas o áreas de salud. Cuando se responde a un brote esto puede ser muy útil para dirigir los recursos a zonas específicas con altas tasas de incidencia, por ejemplo.\nAhora que tenemos los nombres de las unidades administrativas asignados a todos los casos (véase la sección sobre uniones espaciales, más arriba), podemos empezar a mapear el número de casos por zonas (mapa de coropletas).\nComo también tenemos datos de población por ADM3, podemos añadir esta información a la tabla case_adm3 creada anteriormente.\nComenzamos con el dataframe creado en el paso anterior case_adm3, que es una tabla resumen de cada unidad administrativa y su número de casos.\n\nLos datos de la población sle_adm3_pop se unen utilizando un left_join() de dplyr utilizando la columna admin3pcod del dataframe case_adm3, y la columna adm_pcode en el dataframe sle_adm3_pop, que tienen la misma información. Véase la página sobre la unión de datos.\nselect() se aplica al nuevo dataframe, para mantener sólo las columnas que nos interesan - total es la población total.\nLos casos por cada 10.000 habitantes se calculan como una nueva columna con mutate().\n\n\n# Añadir datos de población y calcular los casos por cada 10K habitantes\ncase_adm3 &lt;- case_adm3 %&gt;% \n     left_join(sle_adm3_pop,                             # añade columnas del conjunto de datos de población\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %&gt;%  # join basado en valores comunes entre estas dos columnas\n     select(names(case_adm3), total) %&gt;%                 # conserva sólo las columnas importantes, incluida la población total\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # crea una nueva columna con la tasa de casos por 10000, redondeada a 3 decimales\n\ncase_adm3                                                # imprime en la consola para su visualización\n\n# A tibble: 10 × 5\n# Groups:   admin3pcod [10]\n   admin3pcod admin3name     cases  total case_10kpop\n   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;  &lt;int&gt;       &lt;dbl&gt;\n 1 SL040102   Mountain Rural   276  33993       81.2 \n 2 SL040208   West III         234 210252       11.1 \n 3 SL040207   West II          176 145109       12.1 \n 4 SL040204   East II          103  99821       10.3 \n 5 SL040201   Central I         63  69683        9.04\n 6 SL040203   East I            61  68284        8.93\n 7 SL040206   West I            47  60186        7.81\n 8 SL040202   Central II        22  23874        9.22\n 9 SL040205   East III          16 500134        0.32\n10 &lt;NA&gt;       &lt;NA&gt;               2     NA       NA   \n\n\nPara poder mapear estos datos, tenemos que unir esta tabla con el shapefile de polígonos ADM3:\n\ncase_adm3_sf &lt;- case_adm3 %&gt;%                 # begin with cases & rate by admin unit\n  left_join(sle_adm3, by=\"admin3pcod\") %&gt;%    # join a datos del shapefile por columna común\n  select(objectid, admin3pcod,                # mantiene sólo ciertas columnas de interés\n         admin3name = admin3name.x,           # limpia el nombre de una columna\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %&gt;%                        # mantiene la geometría para poder trazar los polígonos\n  drop_na(objectid)%&gt;%                        # elimina las filas vacías\n  st_as_sf()                                  # convierte a shapefile\n\nPara mapear los resultados en un mapa estático:\n\n# tmap mode\ntmap_mode(\"plot\")               # ver mapa estático\n\n# plot polygons\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # colorea según la columna de número de casos\n        tm_text(\"admin3name\")   # visualización del nombre\n\n\n\n\n\n\n\n\nTambién podemos mapear las tasas de incidencia:\n\n# Casos por 10.000 habitantes\ntmap_mode(\"plot\")             # modo de visualización estático\n\n# representación del mapa\ntm_shape(case_adm3_sf) +                # polígonos del gráfico\n  tm_polygons(\"case_10kpop\",            # colorea según la columna que contiene la tasa de casos\n              breaks=c(0, 10, 50, 100), # define los puntos de ruptura para los colores\n              palette = \"Purples\"       # usa una paleta de colores púrpura\n              ) +\n  tm_text(\"admin3name\")                 # muestra el texto",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#mapping-with-ggplot2",
    "href": "new_pages/gis.es.html#mapping-with-ggplot2",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.8 Mapeo con ggplot2",
    "text": "28.8 Mapeo con ggplot2\nSi ya conoces el uso de ggplot2, puedes utilizar ese paquete para crear mapas estáticos de tus datos. La función geom_sf() dibujará diferentes objetos en función de las características de los datos. Por ejemplo, puedes utilizar geom_sf() en un ggplot() utilizando datos sf con geometría de polígonos para crear un mapa de coropletas.\nPara ilustrar cómo funciona esto, podemos empezar con el archivo shape de polígonos ADM3 que hemos utilizado antes. Recordemos que se trata de regiones de nivel administrativo 3 en Sierra Leona:\n\nsle_adm3\n\nSimple feature collection with 12 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 20\n   objectid admin3name   admin3pcod admin3ref_n admin2name admin2pcod admin1name\n *    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n 1      155 Koya Rural   SL040101   Koya Rural  Western A… SL0401     Western   \n 2      156 Mountain Ru… SL040102   Mountain R… Western A… SL0401     Western   \n 3      157 Waterloo Ru… SL040103   Waterloo R… Western A… SL0401     Western   \n 4      158 York Rural   SL040104   York Rural  Western A… SL0401     Western   \n 5      159 Central I    SL040201   Central I   Western A… SL0402     Western   \n 6      160 East I       SL040203   East I      Western A… SL0402     Western   \n 7      161 East II      SL040204   East II     Western A… SL0402     Western   \n 8      162 Central II   SL040202   Central II  Western A… SL0402     Western   \n 9      163 West III     SL040208   West III    Western A… SL0402     Western   \n10      164 West I       SL040206   West I      Western A… SL0402     Western   \n11      165 West II      SL040207   West II     Western A… SL0402     Western   \n12      167 East III     SL040205   East III    Western A… SL0402     Western   \n# ℹ 13 more variables: admin1pcod &lt;chr&gt;, admin0name &lt;chr&gt;, admin0pcod &lt;chr&gt;,\n#   date &lt;date&gt;, valid_on &lt;date&gt;, valid_to &lt;date&gt;, shape_leng &lt;dbl&gt;,\n#   shape_area &lt;dbl&gt;, rowcacode0 &lt;chr&gt;, rowcacode1 &lt;chr&gt;, rowcacode2 &lt;chr&gt;,\n#   rowcacode3 &lt;chr&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nPodemos utilizar la función left_join() de dplyr para añadir al objeto shapefile los datos que queremos mapear. En este caso, vamos a utilizar el dataframe case_adm3 que creamos anteriormente para resumir los recuentos de casos por región administrativa. También podemos utilizar este mismo enfoque para mapear cualquier dato almacenado en un dataframe.\n\nsle_adm3_dat &lt;- sle_adm3 %&gt;% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join = sólo se conservan los datos de ambos objetos\n\nselect(sle_adm3_dat, admin3name.x, cases) # imprime las variables seleccionadas en la consola\n\nSimple feature collection with 9 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\nGeodetic CRS:  WGS 84\n# A tibble: 9 × 3\n  admin3name.x   cases                                                  geometry\n  &lt;chr&gt;          &lt;int&gt;                                        &lt;MULTIPOLYGON [°]&gt;\n1 Mountain Rural   276 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.4…\n2 Central I         63 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.48…\n3 East I            61 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.49…\n4 East II          103 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.4…\n5 Central II        22 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.4…\n6 West III         234 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.4…\n7 West I            47 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.49…\n8 West II          176 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.4…\n9 East III          16 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.4…\n\n\nPara hacer un gráfico de columnas de los recuentos de casos por región utilizando ggplot2, podemos llamar a geom_col() de la siguiente manera:\n\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # reordena el eje-x por 'casos' descendentes\n               y=cases)) +                                  # el eje-y es el número de casos por región\n  theme_bw() +\n  labs(                                                     # establecer el texto de la figura\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # ajusta las etiquetas del eje-x a 45 grados para que encajen mejor\n\n\n\n\n\n\n\n\nSi queremos utilizar ggplot2 para hacer un mapa de coropletas de los recuentos de casos, podemos utilizar una sintaxis similar para llamar a la función geom_sf():\n\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # configura el relleno para que varíe según la variable de recuento de casos\n\n\n\n\n\n\n\n\nA continuación, podemos personalizar la apariencia de nuestro mapa utilizando una sintaxis que sea consistente en ggplot2, por ejemplo:\n\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # cambia el gradiente de color\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # establece el texto de la figura\n       subtitle = \"Admin level 3\"\n  )\n\n\n\n\n\n\n\n\nPara las personas que se sientan cómodas trabajando con ggplot2, geom_sf() ofrece una implementación simple y directa que es adecuada para las visualizaciones básicas de mapas. Para saber más, mira la viñeta de geom_sf() o el libro de ggplot2.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#basemaps",
    "href": "new_pages/gis.es.html#basemaps",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.9 Mapas base",
    "text": "28.9 Mapas base\n\nOpenStreetMap\nA continuación describimos cómo conseguir un mapa base para realizar un mapa con ggplot2 utilizando las características de OpenStreetMap. Existen métodos alternativos que incluyen el uso de ggmap que requiere el registro gratuito con Google (detalles).\nOpenStreetMap es un proyecto de colaboración para crear un mapa editable y gratuito del mundo. Los datos de geolocalización subyacentes (por ejemplo, ubicaciones de ciudades, carreteras, características naturales, aeropuertos, escuelas, hospitales, caminos, etc.) se consideran el resultado principal del proyecto.\nPrimero cargamos el paquete OpenStreetMap, del que obtendremos nuestro mapa base.\nA continuación, creamos el objeto map, que definimos mediante la función openmap() del paquete OpenStreetMap (documentación). Proporcionamos lo siguiente:\n\nupperLeft y lowerRight: Estas son dos pares de coordenadas que especifican los límites del marco del mapa base.\n\nEn este caso hemos puesto los máximos y mínimos de las filas del listado, para que el mapa responda dinámicamente a los datos\n\nzoom = (si es nulo se determina automáticamente)\ntype = qué tipo de mapa base - aquí hemos enumerado varias posibilidades y el código utiliza actualmente la primera ([1]) “osm”\nmergeTiles = elegimos TRUE para que las capas se fusionen en uno solo\n\n\n# cargar el paquete\npacman::p_load(OpenStreetMap)\n\n# Ajustar mapa base por rango de coordenadas lat/long. Se elige el tipo de mosaico\nmap &lt;- openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # límites del mosaico del mapa base\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\n\nSi trazamos este mapa ahora mismo, usando autoplot.OpenStreetMap() del paquete OpenStreetMap, verás que las unidades en los ejes no son coordenadas de latitud/longitud. Se está utilizando un sistema de coordenadas diferente. Para mostrar correctamente las residencias de los casos (que se almacenan en lat/long), se debe cambiar esto.\n\nautoplot.OpenStreetMap(map)\n\n\n\n\n\n\n\n\nVamos a convertir el mapa a latitud/longitud con la función openproj() del paquete OpenStreetMap. Proporcionamos el mapa base map y también el Sistema de Referencia de Coordenadas (CRS) que queremos. Lo hacemos proporcionando la cadena de caracteres “proj.4” para la proyección WGS 1984, pero también se puede proporcionar el CRS de otras maneras. (ver esta página para entender mejor qué es una cadena proj.4)\n\n# Projección WGS84\nmap_latlon &lt;- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n\nAhora cuando creamos el gráfico vemos que a lo largo de los ejes están las coordenadas de latitud y longitud. El sistema de coordenadas ha sido convertido. Ahora nuestros casos se trazarán correctamente si se superponen:\n\n# Dibujar el mapa. Se debe usar \"autoplot\" para trabajar con ggplot\nautoplot.OpenStreetMap(map_latlon)\n\n\n\n\n\n\n\n\nConsulta estos dos tutoriales aquí y aquí para obtener más información sobre este tema.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#contoured-density-heatmaps",
    "href": "new_pages/gis.es.html#contoured-density-heatmaps",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.10 Mapas de calor de densidad contorneada",
    "text": "28.10 Mapas de calor de densidad contorneada\nA continuación describimos cómo conseguir un mapa de calor de densidad contorneada de casos, sobre un mapa base, comenzando con un listado (una fila por caso).\n\nCrear un mapa base a partir de OpenStreetMap, como se ha descrito anteriormente.\nTrazar los casos de linelist utilizando las columnas de latitud y longitud.\nConvertir los puntos en un mapa de calor de densidad con stat_density_2d() de ggplot2,\n\nCuando tenemos un mapa base con coordenadas de latitud y longitud, podemos trazar nuestros casos encima utilizando las coordenadas de latitud y longitud de su residencia.\nPartiendo de la función autoplot.OpenStreetMap() para crear el mapa base, se pueden añadir las funciones de ggplot2, como se muestra con geom_point() a continuación:\n\n# Dibujar el mapa. Se debe usar \"autoplot\" para trabajar con ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # comienza con el mapa base\n  geom_point(                                       # añade puntos xy de las columnas lon y lat de linelist \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # elimina la leyenda por completo\n  labs(x = \"Longitude\",                             # títulos y etiquetas\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n\n\n\n\n\n\n\n\nEl mapa anterior puede ser difícil de interpretar, especialmente con los puntos superpuestos. Para mejorar esto, vamos a trazar un mapa de densidad en 2d utilizando la función ggplot2 stat_density_2d(). Sguemos utilizando las coordenadas lat/lon del listado, pero ahora estamos realizando una estimación de la densidad del núcleo en 2D y los resultados se muestran con líneas de contorno - como un mapa topográfico. Puedes leer esta documentación completa para saber más.\n\n# comienza con el mapa base\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # añadir el mapa de densidad\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # especificar escala de color\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # etiquetas\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")\n\n\n\n\n\n\n\n\n\n\nMapa de calor de series temporales\nEl mapa de calor de densidad anterior muestra los casos acumulados. Podemos examinar el brote a lo largo del tiempo y del espacio haciendo un facetado del mapa de calor basado en el mes de inicio de los síntomas, si tenemos esta información en el linelist.\nComenzamos con linelist, creando una nueva columna con el Año y el Mes de inicio. La función format() de R base cambia la forma en que se muestra una fecha. En este caso queremos “AAAA-MM”.\n\n# Extraer mes de inicio\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examinar los valores\ntable(linelist$date_onset_ym, useNA = \"always\")\n\n\n2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 2015-02 \n      9      16      41      79     196     204     126      84      81      51 \n2015-03 2015-04    &lt;NA&gt; \n     53      25      35 \n\n\nAhora, simplemente introducimos el facetado a través de ggplot2 en el mapa de calor de densidad. Se aplica facet_wrap(), utilizando la nueva columna como filas. Fijamos el número de columnas de facetas en 4 paraque se vea mejor.\n\n# paquetes\npacman::p_load(OpenStreetMap, tidyverse)\n\n# comienza con el mapa base\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # añadir el mapa de densidad\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # especificar escala de color\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # etiquetas \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facetar el gráfico por mes-año de inicio\n  facet_wrap(~ date_onset_ym, ncol = 4)",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#spatial-statistics",
    "href": "new_pages/gis.es.html#spatial-statistics",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.11 Estadísticas espaciales",
    "text": "28.11 Estadísticas espaciales\nLa mayor parte de nuestra discusión hasta ahora se ha centrado en la visualización de datos espaciales. En algunos casos, también puede interesarte utilizar estadísticas espaciales para cuantificar las relaciones espaciales de los atributos de tus datos. En esta sección se ofrece una breve visión general de algunos conceptos claves de la estadística espacial y se sugiere algunos recursos que te resultarán útiles si deseas realizar análisis espaciales más exhaustivos.\n\nRelaciones espaciales\nAntes de poder calcular cualquier estadística espacial, tenemos que especificar las relaciones entre las características de nuestros datos. Hay muchas formas de conceptualizar las relaciones espaciales, pero un modelo sencillo y comúnmente aplicable es el de la adyacencia, es decir, que esperamos una relación geográfica entre las zonas que comparten una frontera o son “vecinas” unas de otras.\nPodemos cuantificar las relaciones de adyacencia entre los polígonos de las regiones administrativas en los datos sle_adm3 que hemos estado utilizando con el paquete spdep. Especificaremos la contigüidad queen, que significa que las regiones serán vecinas si comparten al menos un punto a lo largo de sus fronteras. La alternativa sería la contigüidad rook, que requiere que las regiones compartan un borde - en nuestro caso, con polígonos irregulares, la distinción es trivial, pero en algunos casos la elección entre queen y rook puede ser influyente.\n\nsle_nb &lt;- spdep::poly2nb(sle_adm3_dat, queen=T) # crear vecinos  \nsle_adjmat &lt;- spdep::nb2mat(sle_nb)    # crear matriz que resuma las relaciones de vecindad\nsle_listw &lt;- spdep::nb2listw(sle_nb)   # crear el objeto listw (lista de pesos) -- lo necesitaremos más adelante\n\nsle_nb\n\nNeighbour list object:\nNumber of regions: 9 \nNumber of nonzero links: 30 \nPercentage nonzero weights: 37.03704 \nAverage number of links: 3.333333 \n\nround(sle_adjmat, digits = 2)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\nattr(,\"call\")\nspdep::nb2mat(neighbours = sle_nb)\n\n\nLa matriz de arriba muestra las relaciones entre las 9 regiones de nuestros datos sle_adm3. Una puntuación de 0 indica que dos regiones no son vecinas, mientras que cualquier valor distinto de 0 indica una relación de vecindad. Los valores de la matriz se han escalado para que cada región tenga un peso total de 1 en la fila.\nLa mejor manera de visualizar estas relaciones de vecindad es dibujarlas:\n\nplot(sle_adm3_dat$geometry) +                                           # representar las fronteras de las regiones\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # añadir relaciones de vecindad\n\n\n\n\n\n\n\n\nHemos utilizado un enfoque de adyacencia para identificar los polígonos vecinos; los vecinos que identificamos también se denominan a veces vecinos por contigüidad. Pero ésta es sólo una forma de elegir qué regiones se espera que tengan una relación geográfica. Los enfoques alternativos más comunes para identificar las relaciones geográficas generan vecinos basados en la distancia; brevemente, estos son:\n\nK-vecinos más cercanos - Basándose en la distancia entre los centroides (el centro ponderado geográficamente de cada región poligonal), selecciona las n regiones más cercanas como vecinas. También se puede especificar un umbral de proximidad de distancia máxima. En spdep, puedes utilizar knearneigh() (documentación).\nVecinos de umbral de distancia - Selecciona todos los vecinos dentro de un umbral de distancia. En spdep, estas relaciones de vecindad pueden ser identificadas usando dnearneigh() (documentación).\n\n\n\nAutocorrelación espacial\nLa tan citada primera ley de la geografía de Tobler afirma que “todo está relacionado con todo lo demás, pero las cosas cercanas están más relacionadas que las lejanas”. En epidemiología, esto suele significar que el riesgo de un determinado resultado sanitario en una región determinada es más similar al de sus regiones vecinas que al de las lejanas. Este concepto se ha formalizado como autocorrelación espacial: la propiedad estadística de que las características geográficas con valores similares se agrupan en el espacio. Las medidas estadísticas de autocorrelación espacial pueden utilizarse para cuantificar el alcance de la agrupación espacial de tus datos, localizar dónde se produce la agrupación e identificar patrones compartidos de autocorrelación espacial entre distintas variables de los datos. Esta sección ofrece una visión general de algunas medidas comunes de autocorrelación espacial y cómo calcularlas en R.\nI de Moran - Se trata de una estadística de resumen global de la correlación entre el valor de una variable en una región y los valores de la misma variable en las regiones vecinas. La estadística I de Moran suele oscilar entre -1 y 1. Un valor de 0 indica que no hay ningún patrón de correlación espacial, mientras que los valores más cercanos a 1 o -1 indican una mayor autocorrelación espacial (valores similares cercanos) o dispersión espacial (valores disímiles cercanos), respectivamente.\nComo ejemplo, calcularemos la estadística I de Moran para cuantificar la autocorrelación espacial en los casos de Ébola que hemos mapeado antes (recordemos que se trata de un subconjunto de casos de la epidemia simulada del dataframe linelist). El paquete spdep tiene una función, moran.test, que puede hacer este cálculo por nosotros:\n\nmoran_i &lt;-spdep::moran.test(sle_adm3_dat$cases,    # vector numérico con variable de interés.\n                            listw=sle_listw)       # objeto listw que resume las relaciones entre vecinos\n\nmoran_i                                            # imprimir resultados del test I de Moran\n\n\n    Moran I test under randomisation\n\ndata:  sle_adm3_dat$cases  \nweights: sle_listw    \n\nMoran I statistic standard deviate = 1.6726, p-value = 0.0472\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n       0.22513266       -0.12500000        0.04381958 \n\n\nEl resultado de la función moran.test() nos muestra una estadística I de Moran de round(moran_i$estimate[1],2). Esto indica la presencia de autocorrelación espacial en nuestros datos; en concreto, sugiere que es probable que las regiones con un número similar de casos de Ébola estén próximas entre sí. El valor p proporcionado por moran.test() se genera mediante la comparación con la expectativa bajo la hipótesis nula de ausencia de autocorrelación espacial, y puede utilizarse si se necesita informar de los resultados de una prueba de hipótesis formal.\nI de Moran local - Podemos descomponer la estadística I de Moran (global) calculada anteriormente para identificar la autocorrelación espacial localizada; es decir, para identificar grupos específicos en nuestros datos. Esta estadística, que a veces se denomina indicador local de asociación espacial (LISA), resume el grado de autocorrelación espacial alrededor de cada región individual. Puede ser útil para encontrar puntos “calientes” y “fríos” en el mapa.\nPara mostrar un ejemplo, podemos calcular y mapear la I de Moran local para los recuentos de casos de Ébola utilizados anteriormente, con la función local_moran() de spdep:\n\n# calcular I de Moran local\nlocal_moran &lt;- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable de interés\n  listw=sle_listw                                  # objeto listw con pesos de vecindad\n)\n\n# unir los resultados a los datos de sf\nsle_adm3_dat&lt;- cbind(sle_adm3_dat, local_moran)    \n\n# representar el mapa\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nGetis-Ord Gi * - Esta es otra estadística que se utiliza comúnmente para el análisis de puntos calientes; en gran parte, la popularidad de esta estadística se relaciona con su uso en la herramienta de análisis de puntos calientes en ArcGIS. Se basa en la suposición de que, normalmente, la diferencia del valor de una variable entre regiones vecinas debería seguir una distribución normal. Utiliza un enfoque de puntuación z para identificar las regiones que tienen valores significativamente más altos (punto caliente) o significativamente más bajos (punto frío) de una variable específica, en comparación con sus vecinos.\nPodemos calcular y asignar la estadística Gi* utilizando la función localG() de spdep:\n\n# Realizar análisis G local\ngetis_ord &lt;- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# join results to sf data\nsle_adm3_dat$getis_ord &lt;- as.numeric(getis_ord)\n\n# representar el mapa\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n\n\n\n\n\n\n\n\nComo puedes ver, el mapa de Getis-Ord Gi* tiene un aspecto ligeramente diferente del mapa de Moran local elaborado anteriormente. Esto refleja que el método utilizado para calcular estas dos estadísticas es ligeramente diferente. Cuál de ellas debes utilizar depende de tu caso de uso específico y de la pregunta de investigación de interés.\nPrueba L de Lee - Es una prueba estadística de correlación espacial bivariada. Permite comprobar si el patrón espacial de una determinada variable x es similar al patrón espacial de otra variable, y, que se supone que está relacionada espacialmente con x.\nPara dar un ejemplo, vamos a probar si el patrón espacial de los casos de Ébola de la epidemia simulada está correlacionado con el patrón espacial de la población. Para empezar, necesitamos tener una variable population en nuestros datos sle_adm3. Podemos utilizar la variable total del dataframe sle_adm3_pop que hemos cargado anteriormente.\n\nsle_adm3_dat &lt;- sle_adm3_dat %&gt;% \n  rename(population = total)                          # renombra 'total' a 'population'\n\nPodemos visualizar rápidamente los patrones espaciales de las dos variables una al lado de la otra, para ver si se parecen:\n\ntmap_mode(\"plot\")\n\ncases_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map &lt;- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # organizar en 2 x 1 facetas\n\n\n\n\n\n\n\n\nVisualmente, los patrones parecen no parecen muy similares. Podemos utilizar la función lee.test() de spdep para comprobar estadísticamente si el patrón de autocorrelación espacial de las dos variables está relacionado. La estadística L será cercana a 0 si no hay correlación entre los patrones, cercana a 1 si hay una fuerte correlación positiva (es decir, los patrones son similares), y cercana a -1 si hay una fuerte correlación negativa (es decir, los patrones son inversos).\n\nlee_test &lt;- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 a comparar\n  y=sle_adm3_dat$population,     # variable 2 a comparar\n  listw=sle_listw                # objeto listw con pesos de vecindad\n)\n\nlee_test\n\n\n    Lee's L statistic randomisation\n\ndata:  sle_adm3_dat$cases ,  sle_adm3_dat$population \nweights: sle_listw  \n\nLee's L statistic standard deviate = -0.97539, p-value = 0.8353\nalternative hypothesis: greater\nsample estimates:\nLee's L statistic       Expectation          Variance \n      -0.15401321       -0.04561233        0.01235108 \n\n\nEl resultado anterior muestra que la estadística L de Lee para nuestras dos variables fue round(lee_test$estimate[1],2), lo que indica una débil correlación negativa. Esto confirma nuestra evaluación visual de que el patrón de los casos y la población no están relacionados entre sí, y proporciona pruebas de que el patrón espacial de los casos no es estrictamente un resultado de la densidad de población en las zonas de alto riesgo.\nLa estadística L de Lee puede ser útil para hacer este tipo de inferencias sobre la relación entre variables distribuidas espacialmente; sin embargo, para describir la naturaleza de la relación entre dos variables con más detalle, o ajustar por confusión, tenemos que aplicar técnicas de regresión espacial. Describeremos brevemente algunas de estas en la siguiente sección.\n\n\nRegresión espacial\nEs posible que quieras hacer inferencias estadísticas sobre las relaciones entre las variables de tus datos espaciales. En estos casos, es útil considerar las técnicas de regresión espacial, es decir, los enfoques de regresión que consideran explícitamente la organización espacial de las unidades en los datos. Algunas de las razones por las que puedes necesitar considerar modelos de regresión espacial, en lugar de modelos de regresión estándar como los GLM, incluyen:\n\nLos modelos de regresión estándar asumen que los residuos son independientes entre sí. En presencia de una autocorrelación espacial fuerte, es probable que los residuos de un modelo de regresión estándar también estén autocorrelacionados espacialmente, violando así este supuesto. Esto puede dar lugar a problemas de interpretación de los resultados del modelo, en cuyo caso sería preferible un modelo espacial.\nLos modelos de regresión también suelen suponer que el efecto de una variable x es constante en todas las observaciones. En el caso de la heterogeneidad espacial, los efectos que deseamos estimar pueden variar a lo largo del espacio, y podemos estar interesados en cuantificar esas diferencias. En este caso, los modelos de regresión espacial ofrecen más flexibilidad para estimar e interpretar los efectos.\n\nLos detalles de los enfoques de regresión espacial están fuera del alcance de este manual. En su lugar, esta sección ofrece una visión general de los modelos de regresión espacial más comunes y sus usos, y te remite a referencias que pueden ser útiles por si se deseas profundizar en este ámbito.\nModelos de error espacial - Estos modelos suponen que los términos de error entre unidades espaciales están correlacionados, en cuyo caso los datos violarían los supuestos de un modelo OLS estándar. Los modelos de error espacial también se denominan a veces modelos autorregresivos simultáneos (SAR). Pueden ajustarse utilizando la función errorsarlm() del paquete spatialreg (funciones de regresión espacial que solían formar parte de spdep).\nModelos de desfase espacial - Estos modelos suponen que la variable dependiente de una región i está influida no sólo por el valor de las variables independientes en i, sino también por los valores de esas variables en las regiones vecinas a i. Al igual que los modelos de error espacial, los modelos de desfase espacial también se describen a veces como modelos autorregresivos simultáneos (SAR). Pueden ajustarse utilizando la función lagsarlm() del paquete spatialreg.\nEl paquete spdep contiene varias pruebas de diagnóstico útiles para decidir entre los modelos OLS estándar, de desfase espacial y de error espacial. Estas pruebas, denominadas diagnósticos del multiplicador de Lagrange, pueden utilizarse para identificar el tipo de dependencia espacial en sus datos y elegir el modelo más apropiado. La función lm.LMtests() puede utilizarse para calcular todos los diagnósticos del multiplicador de Lagrange. Anselin (1988) también proporciona una útil herramienta de diagrama de flujo para decidir qué modelo de regresión espacial utilizar basándose en los resultados de las pruebas del multiplicador de Lagrange:\n\n\n\n\n\n\n\n\n\nModelos jerárquicos bayesianos: Los enfoques bayesianos se utilizan habitualmente para algunas aplicaciones del análisis espacial, sobre todo para el mapeo de enfermedades. Se prefieren en los casos en los que los datos de los casos están escasamente distribuidos (por ejemplo, en el caso de un resultado raro) o son estadísticamente “ruidosos”, ya que pueden utilizarse para generar estimaciones “suavizadas” del riesgo de enfermedad al tener en cuenta el proceso espacial latente subyacente. Esto puede mejorar la calidad de las estimaciones. También permiten que el investigador especifique previamente (mediante la elección de “priors” (valores pre-establecidos)) los patrones complejos de correlación espacial que pueden existir en los datos, los cuales pueden tomar en cuenta la variación espacialmente dependiente e independiente en las variables independientes y dependientes. En R, los modelos jerárquicos bayesianos pueden ajustarse utilizando el paquete CARbayes (véase la viñeta) o R-INLA (véase este sitio web y el libro de texto). A través de R también puedes usar software externo que realice estimaciones bayesianas, como JAGS o WinBUGS.",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/gis.es.html#resources-21",
    "href": "new_pages/gis.es.html#resources-21",
    "title": "28  Conceptos básicos de los SIG",
    "section": "28.12 Recursos",
    "text": "28.12 Recursos\n\nFunciones simples de R y viñeta del paquete sf\nViñeta del paquete tmap\nggmap: Visualización espacial con ggplot2\nIntroducción a la elaboración de mapas con R, visión general de los diferentes paquetes\nDatos espaciales en R (curso EarthLab)\nLibro de texto Applied Spatial Data Analysis in R\nSpatialEpiApp - una aplicación Shiny que se puede descargar como un paquete de R, lo que le permite proporcionar sus propios datos y llevar a cabo la cartografía, el análisis de conglomerados y las estadísticas espaciales.\nTaller de introducción a la econometría espacial en R",
    "crumbs": [
      "Análisis",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Conceptos básicos de los SIG</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html",
    "href": "new_pages/tables_presentation.es.html",
    "title": "29  Tablas para presentaciones",
    "section": "",
    "text": "29.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html#preparation-20",
    "href": "new_pages/tables_presentation.es.html#preparation-20",
    "title": "29  Tablas para presentaciones",
    "section": "",
    "text": "Cargar paquetes\nInstala y carga flextable. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar paquetes con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,            # importar/exportar\n  here,           # rutas de archivos\n  flextable,      # hacer imágenes bonitas de tablas \n  officer,        # funciones de ayuda para tablas\n  tidyverse)      # gestión, resumen y visualización de datos\n\n\n\nImportar datos\nPara empezar, importamos los datos limpios de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio”(como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).\n\n# importar el listado de casos\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas de linelist.\n\n\n\n\n\n\n\n\nPreparar la tabla\nAntes de empezar a utilizar flextable tendrás que crear tu tabla como un dataframe. Consulta la página sobre Tablas descriptivas y Pivotar datos para aprender a crear un dataframe utilizando paquetes como janitor y dplyr. Debes organizar el contenido en filas y columnas tal y como quieres que se muestre. Luego, el dataframe se pasará a flextable para mostrarlo con colores, encabezados, fuentes, etc.\nA continuación se muestra un ejemplo de la página de tablas descriptivas para convertir la lista de casos en un dataframe que resume los resultados de los pacientes y los valores de TC por hospital, con una fila de totales en la parte inferior. El resultado se guarda como table.\n\ntable &lt;- linelist %&gt;% \n  \n  # Obtener valores resumidos por grupo de hospital-resultado\n  ###############################################\n  group_by(hospital, outcome) %&gt;%                      # Agrupar datos\n  summarise(                                           # Creaar columnas nuevas con indicadores de interés\n    N = n(),                                            # Número de filas por grupos de hospital-resultado     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # Valor de la mediana CT por grupo\n  \n  # añadir totales\n  ################\n  bind_rows(                                           # Une la tabla anterior con esta mini-tabla de totales\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Agrupados sólo por resultado, no por hospital    \n      summarise(\n        N = n(),                                       # Número de filas del conjunto de datos     \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # Mediana CT del conjunto de datos \n  \n  # Pivotar ancho y formato\n  #########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivotar de largo a ancho\n    values_from = c(ct_value, N),                       # Los nuevos valores están desde la columna ct a la count\n    names_from = outcome) %&gt;%                           # los nombres nuevos de columna son para el resultado \n  mutate(                                              # Añadir columnas nuevas\n    N_Known = N_Death + N_Recover,                               # número con resultado conocidos\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentaje de casos que fallecieron (con 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # porcentaje que se recuperaron (con 1 decimal)\n  select(                                              # Re-ordenar columnas\n    hospital, N_Known,                                   # Intro columnas\n    N_Recover, Pct_Recover, ct_value_Recover,            # Columnas para recuerados\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Columnas para fallecidos\n  arrange(N_Known)                                    # Ordenar las filas de menor a mayor (fila total al final)\n\ntable  # Imprime\n\n# A tibble: 7 × 8\n# Groups:   hospital [7]\n  hospital      N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n  &lt;chr&gt;           &lt;int&gt;     &lt;int&gt; &lt;chr&gt;                  &lt;dbl&gt;   &lt;int&gt; &lt;chr&gt;    \n1 St. Mark's M…     325       126 38.8%                     22     199 61.2%    \n2 Central Hosp…     358       165 46.1%                     22     193 53.9%    \n3 Other             685       290 42.3%                     21     395 57.7%    \n4 Military Hos…     708       309 43.6%                     22     399 56.4%    \n5 Missing          1125       514 45.7%                     21     611 54.3%    \n6 Port Hospital    1364       579 42.4%                     21     785 57.6%    \n7 Total            3440      1469 42.7%                     22    1971 57.3%    \n# ℹ 1 more variable: ct_value_Death &lt;dbl&gt;",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html#basic-flextable",
    "href": "new_pages/tables_presentation.es.html#basic-flextable",
    "title": "29  Tablas para presentaciones",
    "section": "29.2 Flextable básica",
    "text": "29.2 Flextable básica\n\nCrear una flextble\nPara crear y gestionar los objetos de flextable, primero pasamos el dataframe por la función flextable(). Guardamos el resultado como my_table.\n\nmy_table &lt;- flextable(table) \nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nDespués de hacer esto, podemos enlazar con pipe progresivamente el objeto my_table a través de más funciones de formato de flextable.\nEn esta página, para mayor claridad, guardaremos la tabla en pasos intermedios como my_table, añadiendo las funciones de flextable bit a bit. Si quieres ver todo el código de principio a fin escrito en un solo trozo, visita la sección Todo el código junto más abajo.\nLa sintaxis general de cada línea de código de flextable es la siguiente:\n\nfunction(table, i = X, j = X, part = \"X\"), donde:\n\nLa “función” puede ser una de muchas funciones diferentes, como width() para determinar el ancho de las columnas, bg() para establecer los colores de fondo, align() para establecer si el texto está alineado al centro/derecha/izquierda, etc.\ntable = es el nombre del dataframe, aunque no es necesario indicarlo si el dataframe se introduce en la función.\npart = se refiere a la parte de la tabla a la que se aplica la función. Por ejemplo, “header”, “body” o “all”.\ni= especifica la fila a la que se aplicará la función, donde ‘X’ es el número de fila. Si se trata de varias filas, por ejemplo de la primera a la tercera, se puede especificar:i = c(1:3). Ten en cuenta que si se selecciona “body”, la primera fila empieza por debajo de la sección de cabecera.\nj = especifica la columna a la que se aplicará la función, donde ‘x’ es el número o nombre de la columna. Si hay varias columnas, por ejemplo la quinta y la sexta, se puede especificar: j = c(5,6).\n\n\nPuedes encontrar la lista completa de funciones de formato de flextable aquí o revisar la documentación escribiendo ?flextable.\n\n\nAncho de columna\nPodemos utilizar la función autofit(), que estira la tabla de forma que cada celda sólo tiene una fila de texto. La función qflextable() es una abreviatura conveniente para flextable() y autofit().\n\nmy_table %&gt;% autofit()\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nSin embargo, esto podría no ser siempre apropiado, especialmente si hay valores muy largos dentro de las celdas, lo que significa que la tabla podría no caber en la página.\nEn cambio, podemos especificar el ancho con la función width(). Puede ser necesario jugar un poco para saber qué valor de anchura poner. En el ejemplo siguiente, especificamos diferentes anchos para la columna 1, la columna 2 y las columnas 4 a 8.\n\nmy_table &lt;- my_table %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table\n\nhospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nEncabezados de columna\nQueremos encabezados más claros para facilitar la interpretación del contenido de la tabla.\nPara esta tabla, querremos añadir una segunda capa de cabecera para que las columnas que cubren los mismos subgrupos puedan agruparse. Lo hacemos con la función add_header_row() con top = TRUE. Proporcionamos el nuevo nombre de cada columna a values = , dejando los valores vacíos \"\" para las columnas que sabemos que vamos a fusionar más tarde.\nTambién renombramos los nombres de las cabeceras en la ahora segunda cabecera en un comando separado set_header_labels().\nPor último, para “combinar” ciertas cabeceras de columna en la cabecera superior utilizamos merge_at() para fusionar las cabeceras de columna en la fila de la cabecera superior.\n\nmy_table &lt;- my_table %&gt;% \n  \n  add_header_row(\n    top = TRUE,                # La nueva cabecera va encima de la fila de cabecera existente\n    values = c(\"Hospital\",     # Valores de cabecera para cada columna a continuación\n               \"Total cases with known outcome\", \n               \"Recovered\",    # Este será el encabezado de nivel superior para esta columna y las dos siguientes\n               \"\",\n               \"\",\n               \"Died\",         # Este será el encabezado de nivel superior para esta columna y las dos siguientes\n               \"\",             # Dejar en blanco, ya que se fusionará con \"Died\"\n               \"\")) %&gt;% \n    \n  set_header_labels(         # Renombra las columnas de la fila de cabecera original\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # Combina horizontalmente las columnas 3 a 5 en la nueva fila de encabezado\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Combina horizontalmente las columnas 6 a 8 en la nueva fila de encabezado\n\nmy_table  # print\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nBordes y fondos\nPuedes ajustar los bordes, las líneas internas, etc. con varias funciones de flextable. A menudo es más fácil empezar eliminando todos los bordes existentes con border_remove().\nA continuación, puedes aplicar los temas de borde por defecto pasando la tabla a theme_box(), theme_booktabs() o theme_alafoli().\nPuedes añadir líneas verticales y horizontales con una variedad de funciones. hline() y vline() añaden líneas a una fila o columna especificada, respectivamente. Dentro de cada una, debes especificar la part = como “all”, “body”, o “header”. Para las líneas verticales, especifica la columna j =, y para las líneas horizontales la fila a i =. Otras funciones como vline_right(), vline_left(), hline_top(), y hline_bottom() añaden líneas sólo a los lados.\nEn todas estas funciones, el propio estilo de línea debe especificarse a border = y debe ser la salida de un comando separado utilizando la función fp_border() del paquete officer. Esta función te ayuda a definir el ancho y el color de la línea. Puedes definirlo sobre los comandos de la tabla, como se muestra a continuación.\n\n# define el estilo del borde\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# añade líneas de borde a la tabla\nmy_table &lt;- my_table %&gt;% \n\n  # Elimina todos los bordes existentes\n  border_remove() %&gt;%  \n  \n  # añade líneas horizontales mediante una configuración predeterminada del tema\n  theme_booktabs() %&gt;% \n  \n  # añadir líneas verticales para separar las secciones Recuperado y Fallecido\n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # en la columna 2 \n  vline(part = \"all\", j = 5, border = border_style)       # en la columna 5\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nFuente y alineación\nAlineamos en el centro todas las columnas, excepto la más a la izquierda, con los nombres de los hospitales, utilizando la función align() de flextable.\n\nmy_table &lt;- my_table %&gt;% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nAdemás, podemos aumentar el tamaño de la fuente de la cabecera y cambiarla a negrita. También podemos cambiar la fila total a negrita.\n\nmy_table &lt;-  my_table %&gt;%  \n  fontsize(i = 1, size = 12, part = \"header\") %&gt;%   # ajusta el tamaño de la fuente del encabezado\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;%     # ajusta la negrita de la cabecera\n  bold(i = 7, bold = TRUE, part = \"body\")           # ajusta la negrita de la fila total (fila 7 del cuerpo)\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nPodemos asegurar que las columnas de proporción muestren sólo un decimal utilizando la función colformat_num(). Ten en cuenta que esto también podría haberse hecho en la fase de gestión de datos con la función round().\n\nmy_table &lt;- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nFusionar celdas\nAl igual que fusionamos celdas horizontalmente en la fila de la cabecera, también podemos fusionar celdas verticalmente utilizando merge_at() y especificando las filas (i) y la columna (j). Aquí fusionamos los valores “Hospital” y “Total cases with known outcome” verticalmente para darles más espacio.\n\nmy_table &lt;- my_table %&gt;% \n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\n\n\nColor de fondo\nPara distinguir el contenido de la tabla de las cabeceras, es posible que queramos añadir un formato adicional, por ejemplo, cambiando el color de fondo. En este ejemplo cambiamos el cuerpo de la tabla a gris.\n\nmy_table &lt;- my_table %&gt;% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html#conditional-formatting",
    "href": "new_pages/tables_presentation.es.html#conditional-formatting",
    "title": "29  Tablas para presentaciones",
    "section": "29.3 Formato condicional",
    "text": "29.3 Formato condicional\nPodemos resaltar todos los valores de una columna que cumplan una determinada regla, por ejemplo, que más del 55% de los casos hayan muerto. Basta con poner el criterio en el argumento i = o j =, precedido de una tilde ~. Escribe la referencia a la columna en el dataframe, no a los valores del encabezamiento de la pantalla.\n\nmy_table %&gt;% \n  bg(j = 7, i = ~ Pct_Death &gt;= 55, part = \"body\", bg = \"red\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22\n\n\nO bien, podemos resaltar toda la fila que cumpla un determinado criterio, como un hospital de interés. Para ello, basta con eliminar la especificación de la columna (j) para que los criterios se apliquen a todas las columnas.\n\nmy_table %&gt;% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") \n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html#tbl_pres_all",
    "href": "new_pages/tables_presentation.es.html#tbl_pres_all",
    "title": "29  Tablas para presentaciones",
    "section": "29.4 Todo el código junto",
    "text": "29.4 Todo el código junto\nA continuación mostramos todo el código de las secciones anteriores juntas.\n\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # importar/exportar\n  here,           # rutas de archivos\n  flextable,      # hacer tablas HTML \n  officer,        # funciones de ayuda para tablas\n  tidyverse)      # gestión, resumen y visualización de datos\n\ntable &lt;- linelist %&gt;% \n\n  # Obtener valores resumidos por grupo de hospital-resultado\n  ###########################################################\n  group_by(hospital, outcome) %&gt;%                      # Agrupa los datos\n  summarise(                                           # Crea nuevas columnas de resumen de indicadores de interés\n    N = n(),                                            # Número de filas por grupo hospital-resultado     \n    ct_value = median(ct_blood, na.rm=T)) %&gt;%           # valor mediano de CT por grupo\n  \n  # añadir totales\n  ################\n  bind_rows(                                           # Une la tabla anterior con esta mini-tabla de totales\n    linelist %&gt;% \n      filter(!is.na(outcome) & hospital != \"Missing\") %&gt;%\n      group_by(outcome) %&gt;%                            # Agrupado sólo por resultado, no por hospital    \n      summarise(\n        N = n(),                                       # Número de filas de todo el conjunto de datos    \n        ct_value = median(ct_blood, na.rm=T))) %&gt;%     # Mediana de CT para todo el conjunto de datos\n  \n  # Pivotar ancho y formato\n  #########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %&gt;% \n  pivot_wider(                                         # Pivota de largo a ancho\n    values_from = c(ct_value, N),                       # los nuevos valores proceden de las columnas ct y count\n    names_from = outcome) %&gt;%                           # los nuevos nombres de columna proceden de outcomes\n  mutate(                                              # Añade nuevas columnas\n    N_Known = N_Death + N_Recover,                               # número con resultado conocido\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentaje de casos que murieron (a 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %&gt;% # porcentaje que se recuperaron (a 1 decimal)\n  select(                                              # Reordena las columnas\n    hospital, N_Known,                                   # Columnas iniciales\n    N_Recover, Pct_Recover, ct_value_Recover,            # Columnas de recuperados\n    N_Death, Pct_Death, ct_value_Death)  %&gt;%             # Columnas de fallecidos\n  arrange(N_Known) %&gt;%                                 # Ordenar las filas de menor a mayor (Total en la parte inferior)\n\n  # Formato\n  ############\n  flextable() %&gt;%              # la tabla se define desde arriba\n  add_header_row(\n    top = TRUE,                # El nuevo encabezado va encima de la fila de encabezado existente\n    values = c(\"Hospital\",     # Valores de cabecera para cada columna a continuación\n               \"Total cases with known outcome\", \n               \"Recovered\",    # Este será el encabezado de nivel superior para esta columna y las dos siguientes\n               \"\",\n               \"\",\n               \"Died\",         # Este será el encabezado de nivel superior para esta columna y las dos siguientes\n               \"\",             # Dejar en blanco, ya que se fusionará con \"Died\"\n               \"\")) %&gt;% \n    set_header_labels(         # Renombra las columnas en la fila de cabecera original\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %&gt;% \n  merge_at(i = 1, j = 3:5, part = \"header\") %&gt;% # Combina horizontalmente las columnas 3 a 5 en la nueva fila de cabecera\n  merge_at(i = 1, j = 6:8, part = \"header\") %&gt;%  \n  border_remove() %&gt;%  \n  theme_booktabs() %&gt;% \n  vline(part = \"all\", j = 2, border = border_style) %&gt;%   # en la columna 2 \n  vline(part = \"all\", j = 5, border = border_style) %&gt;%   # en la columna 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %&gt;% \n  merge_at(i = 1:2, j = 2, part = \"header\") %&gt;% \n  width(j=1, width = 2.7) %&gt;% \n  width(j=2, width = 1.5) %&gt;% \n  width(j=c(4,5,7,8), width = 1) %&gt;% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %&gt;% \n  bg(., part = \"body\", bg = \"gray95\")  %&gt;% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %&gt;% \n  colformat_num(., j = c(4,7), digits = 1) %&gt;%\n  bold(i = 1, bold = TRUE, part = \"header\") %&gt;% \n  bold(i = 7, bold = TRUE, part = \"body\")\n\n`summarise()` has grouped output by 'hospital'. You can override using the\n`.groups` argument.\n\ntable\n\nHospitalTotal cases with known outcomeRecoveredDiedTotal% of casesMedian CT valuesTotal% of casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html#saving-your-table",
    "href": "new_pages/tables_presentation.es.html#saving-your-table",
    "title": "29  Tablas para presentaciones",
    "section": "29.5 Guardar tu tabla",
    "text": "29.5 Guardar tu tabla\nHay diferentes maneras de integrar la tabla en tu salida.\n\nGuardar una tabla\nPuedes exportar las tablas a Word, PowerPoint o HTML o como archivos de imagen (PNG). Para ello, utiliza una de las siguientes funciones:\n\nsave_as_docx()\n\nsave_as_pptx()\n\nsave_as_image()\n\nsave_as_html()\n\nPor ejemplo, a continuación guardamos nuestra tabla como un documento de Word. Ten en cuenta la sintaxis del primer argumento - puedes proporcionar simplemente el nombre de tu objeto flextable, por ejemplo, my_table, o puedes darle un “nombre” como se muestra a continuación (el nombre es “my_table”). Si se especifica un nombre, éste aparecerá como el título de la tabla en Word. También mostramos el código para guardar como imagen PNG.\n\n# Edita 'my table' si es necesario para el título de la tabla.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\n\nTen en cuenta que los paquetes webshot o webshot2 son necesarios para guardar una flextable como imagen. Las imágenes pueden salir con fondos transparentes.\nSi deseas ver una versión “en vivo” de la salida de flextable en el formato de documento previsto, utiliza print() y especifica uno de los siguientes para preview =. El documento se “abrirá” en tu ordenador en el programa de software especificado, pero no se guardará. Esto puede ser útil para comprobar si la tabla cabe en una página/diapositiva o para poder copiarla rápidamente en otro documento, puedes utilizar el método de impresión con el argumento vista previa establecido en “pptx” o “docx”.\n\nprint(my_table, preview = \"docx\") # Ejemplo de documento Word \nprint(my_table, preview = \"pptx\") # Ejemplo de documento Powerpoint \n\n\n\nImprimir tabla en R markdown\nEsta tabla puede integrarse en un documento automatizado, una salida de R markdown, si el objeto tabla se llama dentro del chunk de R markdown. Esto significa que la tabla puede actualizarse como parte de un informe en el que los datos podrían cambiar, por lo que los números pueden actualizarse.\nMira los detalles en la página de Informes con R Markdown de este manual.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/tables_presentation.es.html#resources-22",
    "href": "new_pages/tables_presentation.es.html#resources-22",
    "title": "29  Tablas para presentaciones",
    "section": "29.6 Recursos",
    "text": "29.6 Recursos\nEl libro completo de flextable está en: https://ardata-fr.github.io/flextable-book/ El sitio Github está aquí Un manual de todas las funciones de flextable puede encontrarse aquí\nPuedes acceder a una galería de bonitos ejemplos de flextables con código aquí",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Tablas para presentaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html",
    "href": "new_pages/ggplot_basics.es.html",
    "title": "30  Conceptos básicos de ggplot",
    "section": "",
    "text": "30.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#preparation-21",
    "href": "new_pages/ggplot_basics.es.html#preparation-21",
    "title": "30  Conceptos básicos de ggplot",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También podes cargar los paquetes instalados con library() de R base. Consulta la página sobre los fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  tidyverse,      # incluye ggplot2 y otras herramientas de gestión de datos\n  janitor,        # limpieza de datos\n  rio,            # importación/exportación\n  here,           # rutas de los archivos\n  stringr,         # trabajar con caracteres    \n  ggforce \n)\n\n\n\nImportar datos\nImportamos el conjunto de datos de casos de una epidemia de Ebola simulada. Si quieres seguir el proceso, cliquea para descargar linelist “limpia” (como archivo .rds). Para importar sus datos utilizando la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - consulta la página de importación y exportación para más detalles).\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado. Nos centraremos en las variables continuas age, wt_kg (peso en kilos), ct_blood (valores de CT, cycle threshold, umbral de ciclo del test de PCR) y days_onset_hosp (diferencia entre la fecha de inicio de síntomas y la hospitalización).\n\n\n\n\n\n\n\n\nLimpieza general\nCuando se preparan los datos para trazarlos (graficarlos), lo mejor es hacer que los datos se adhieran a los estándares de datos “ordenados” tanto como sea posible. En las páginas de este manual, sobre Limpieza de datos y funciones básicas, se explica cómo conseguirlo.\nAlgunas formas sencillas de preparar nuestros datos para que sea mas fáciles trazarlos pueden incluir la mejora del contenido de los datos para su visualización, lo que no equivale necesariamente a una manipulación de los datos mas sencilla. Por ejemplo:\n\nSustituye los valores NA de una columna de caracteres por la cadena de caracteres “Unknown” (Desconocido)\nConsidera la posibilidad de convertir la columna en de tipo factor para que sus valores tengan niveles ordinales prescritos\nLimpia los valores de algunas columnas para cambiar texto “amigable con los datos” con barra baja, etc. a texto normal o a mayúsculas y minúsculas (ver Caracteres y cadenas)\n\nHe aquí algunos ejemplos de esto en acción:\n\n# hace la versión de visualización de las columnas con nombres más amigables\nlinelist &lt;- linelist %&gt;%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m a Masculino \n                            gender == \"f\" ~ \"Female\",      # f a Femenino,\n                            is.na(gender) ~ \"Unknown\"),    # NA a Desconocido\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # sustituye el resultado NA por \"unknown\"\n  )\n\n\n\nPivotar a lo largo\nComo una cuestión de estructura de datos, para ggplot2 a menudo queremos pivotar nuestros datos en formatos largos. Lee más sobre esto en la página de Pivoteo de datos.\n\n\n\n\n\n\n\n\n\nPor ejemplo, digamos que queremos trazar datos que están en un formato “a lo ancho”, como por ejemplo para cada caso en linelist y sus síntomas. A continuación creamos una minilista llamada symptoms_data que contiene sólo las columnas case_id y symptoms.\n\nsymptoms_data &lt;- linelist %&gt;% \n  select(c(case_id, fever, chills, cough, aches, vomit))\n\nAsí es como se ven las primeras 50 filas de esta minilista - ¿ves cómo están formateadas “a lo ancho” con cada síntoma como una columna?\n\n\n\n\n\n\nSi quisiéramos trazar el número de casos con síntomas específicos, estamos limitados por el hecho de que cada síntoma es una columna específica. Sin embargo, podemos hacer pivotar las columnas de síntomas a un formato más largo como este:\n\nsymptoms_data_long &lt;- symptoms_data %&gt;%    # comienza con una \"mini\" lista de líneas llamada symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivotea todas las columnas excepto case_id (todas las de síntomas)\n    names_to = \"symptom_name\",             # se asigna un nombre a la nueva columna que contiene los síntomas\n    values_to = \"symptom_is_present\") %&gt;%  # se asigna un nombre a la nueva columna que contiene los valores (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convierte NA en \"unknown\"\n\nAquí están las primeras 50 filas. Observa que cada caso tiene 5 filas - una para cada síntoma posible. Las nuevas columnas symptom_name y symptom_is_present son el resultado del pivote. Ten en cuenta que este formato puede no ser muy útil para otras operaciones, pero es útil para trazar.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#basics-of-ggplot",
    "href": "new_pages/ggplot_basics.es.html#basics-of-ggplot",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.2 Fundamentos de ggplot",
    "text": "30.2 Fundamentos de ggplot\n“Gramática de los gráficos” - ggplot2\nEl trazado con ggplot2 se basa en “añadir” capas de trazado y elementos de diseño unos sobre otros, añadiendo cada comando a los anteriores con un símbolo de suma (+). El resultado es un objeto de trazado multicapa que se puede guardar, modificar, imprimir, exportar, etc.\nLos objetos ggplot pueden ser muy complejos, pero el orden básico de las capas suele ser el siguiente:\n\nComienza con el comando ggplot() como punto de partida - esto “abre” el ggplot y permite agregar las funciones subsecuentes con +. Normalmente, el conjunto de datos también se especifica en este comando\nAñadí capas “geom” - estas funciones visualizan los datos como geometrías (formas), por ejemplo, como un gráfico de barras, un gráfico de líneas, un gráfico de dispersión, un histograma (¡o una combinación!). Todas estas funciones comienzan con geom_ como prefijo.\nAñadí elementos de diseño al gráfico, como etiquetas de ejes, título, fuentes, tamaños, esquemas de color, leyendas o rotación de ejes.\n\nUn ejemplo sencillo del esqueleto del código es el siguiente. Explicaremos cada componente en las secciones siguientes.\n\n# Traza los datos de las columnas de my_data como puntos rojos\nggplot(data = my_data)+                   # Usa el conjunto de datos my_data\"\n  geom_point(                             # añade una capa de puntos\n    mapping = aes(x = col1, y = col2),    # \"asigna\" la columna de datos a los ejes\n    color = \"red\")+                       # otras especificaciones para el geom\n  labs()+                                 # aquí se añaden los títulos, las etiquetas de los ejes, etc.\n  theme()                                 # aquí se ajusta el color, la fuente, el tamaño, etc. de los elementos de trazado no relacionados con los datos (ejes, título, etc.)",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#ggplot",
    "href": "new_pages/ggplot_basics.es.html#ggplot",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.3 ggplot()",
    "text": "30.3 ggplot()\nEl comando de apertura de cualquier gráfico ggplot2 es ggplot(). Este comando simplemente crea un lienzo en blanco sobre el que añadir capas. Se “abre” el camino para añadir más capas con un símbolo +.\nNormalmente, el comando ggplot() incluye el argumento data = para el gráfico. Esto establece el conjunto de datos que se utilizará de manera predeterminada para las capas posteriores del gráfico.\nEste comando terminará con un + después de su paréntesis de cierre. Esto deja el comando “abierto”. El ggplot sólo se ejecutará/aparecerá cuando el comando completo incluya una capa final sin un + al final.\n\n# Esto creará un lienzo en blanco\nggplot(data = linelist)",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#geoms",
    "href": "new_pages/ggplot_basics.es.html#geoms",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.4 Geoms",
    "text": "30.4 Geoms\nUn lienzo en blanco no es suficiente: necesitamos crear geometrías (formas o tipos de gráfico) a partir de nuestros datos (por ejemplo, gráficos de barras, histogramas, gráficos de dispersión, gráficos de caja).\nEsto se hace añadiendo capas “geoms” al comando inicial ggplot(). Hay muchas funciones de ggplot2 que crean “geoms”. Cada una de estas funciones comienza con “geom_”, por lo que nos referiremos a ellas genéricamente como geom_XXXX(). Hay más de 40 geoms disponibles en ggplot2 y muchos otros creados por fans. Míralos en la galería de ggplot2. Algunos geoms de uso común se enumeran a continuación:\n\nHistogramas - geom_histogram()\nGráficos de barras - geom_bar() o geom_col() (véase la sección “Gráfico de barras”)\nGráficos de caja - geom_boxplot()\nPuntos (por ejemplo, gráficos de dispersión) - geom_point()\nGráficos de líneas - geom_line() o geom_path()\nLíneas de tendencia - geom_smooth()\n\nEn un gráfico se pueden exponer uno o varios geoms. Cada uno se añade a los comandos anteriores de ggplot2 con un +, y se agregan secuencialmente de manera que los geoms posteriores se trazan encima de los anteriores.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#ggplot_basics_mapping",
    "href": "new_pages/ggplot_basics.es.html#ggplot_basics_mapping",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.5 Asignación de datos al gráfico",
    "text": "30.5 Asignación de datos al gráfico\nA la mayoría de las funciones geom hay que darle instrucciones sobre qué elementos utilizar para crear sus formas, por lo que hay que indicarles cómo se deben asignar las columnas de los datos a los distintos componentes del gráfico, como los ejes, los colores de las formas, los tamaños de las formas, etc. Para la mayoría de las funciones geom, los componentes esenciales que deben asignarse a las columnas de los datos son el eje-x y (si es necesario) el eje-y.\nEste “mapeo” (o asignación) se produce con el argumento mapping =. Los mapeos que proporciones a mapping deben estar envueltos en la función aes(), por lo que hay que escribir algo como mapping = aes(x = col1, y = col2), como se muestra a continuación.\nA continuación, en el comando ggplot() los datos se identifican utilizando el termino linelist . En el argumento mapping = aes() la columna age se asigna al eje-x, y la columna wt_kg se asigna al eje-y.\nDespués de agregar un +, los comandos de trazado pueden continuar. Se crea una forma o tipo de gráfico con la función de “geom” denominada geom_point(). Este geom hereda los mapeos del comando ggplot() anterior - conoce las asignaciones eje-columna y procede a visualizar esas relaciones como puntos en el lienzo.\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\n\n\n\n\n\n\n\n\nOtro ejemplo que presentamos a continuación demuestra el uso de los mismos datos pero con un mapeo ligeramente diferente y utilizando un geom diferente. Ahora utilizamos la función geom_histogram() que sólo requiere una columna mapeada en el eje-x, ya que el eje-y de conteo de casos (‘count’) se genera automáticamente.\n\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nEstética del gráfico\nEn la terminología de ggplot, la “estética” de un gráfico tiene un significado específico. Se refiere a una propiedad visual de los datos trazados. Ten en cuenta que “estética” aquí se refiere a los datos que se trazan en geoms / formas - no a lo que aparece en la periferia, tales como títulos, etiquetas de los ejes, el color de fondo, como podría comúnmente asociarse con la palabra “estética”. En ggplot esos detalles se llaman “temas” y se ajustan dentro de un comando denominado theme() (ver esta sección).\nPor lo tanto, la estética de los objetos de ploteo puede ser colores, tamaños, transparencias, colocación, etc. de los datos ploteados. No todos los geoms tendrán las mismas opciones estéticas, pero muchas pueden ser utilizadas por la mayoría de los geoms. He aquí algunos ejemplos:\n\nshape = Representar un punto con geom_point() con forma de punto, estrella, triángulo o cuadrado…\nfill = El color interior (por ejemplo, de una barra o boxplot)\ncolor = El color de la línea exterior o borde de una barra, boxplot, etc., o el color del perimetro del punto si se utiliza geom_point()\nsize = El tamaño (por ejemplo, grosor de línea, tamaño de punto)\nalpha = Transparencia (1 = opaco, 0 = invisible)\nbinwidth = Ancho de los bins (o cubos) del histograma\nwidth = Ancho de las columnas del “diagrama de barras”\nlinetype = Tipo de línea (por ejemplo, sólida, discontinua, punteada)\n\nA esta estética de los objetos del gráfico se le pueden asignar valores de dos maneras:\n\nSe asigna un valor estático (por ejemplo, color = \"blue\") que se aplica a todas las observaciones trazadas\nSe asigna a una columna de los datos (por ejemplo, color = hospital) de manera que la visualización de cada observación depende de su valor en esa columna\n\n\n\n\nAsignar un valor estático\nSi se desea que la estética del objeto de trazado sea estática, es decir, que sea la misma para cada observación de los datos, se escribe su asignación dentro del geom pero fuera del comando mapping = aes(). Estas asignaciones podrían escribirse como size = 1 o color = \"blue\". Aquí hay dos ejemplos:\n\nEn el primer ejemplo, el mapping = aes() está en el comando ggplot() y los ejes se asignan a las columnas de edad (age) y peso (wt_kg) en los datos. La estética del gráfico color =, size =, y alpha = (transparencia) se asignan a valores estáticos. Aclaramos que la asignación de valores estéticos de naturaleza estática se hace en la función geom_point(), ya que se pueden añadir otros geoms después que tomarían valores estéticos diferentes\nEn el segundo ejemplo, el histograma requiere sólo el eje-x mapeado a una columna. El binwidth = (el ancho de los cubos), el color = (el color del borde de los cubos), el fill = (color interno o color de relleno de los cubos), y el alpha = (la transparencia del color de los cubos) se establecen dentro del geom como valores estáticos.\n\n\n# scatterplot\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # establecer datos y ejes de mapeo\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # establecer la estética de los puntos estáticos\n\n# histogram\nggplot(data = linelist, mapping = aes(x = age))+       # establecer datos y ejes\n  geom_histogram(              # mostrar histograma\n    binwidth = 7,                # anchura de los bins (cuadrados)\n    color = \"red\",               # color de la línea del bin\n    fill = \"blue\",               # color del interior del bin\n    alpha = 0.1)                 # transparencia del bin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscalado a los valores de la columna\nComo alternativa al uso de estéticas de naturaleza estática, se pueden graficar objetos con tamaños proporcionales a sus valores como aparecen en su respectiva columna. Con este enfoque, la visualización de esta estética dependerá del valor de esa observación en la columna de datos correspondiente. Si los valores de la columna son continuos, la escala de visualización (en la leyenda) para esa estética será continua. Si los valores de la columna son discretos, la leyenda mostrará cada valor y los datos trazados aparecerán claramente “agrupados” (lea más en la sección de agrupación de esta página).\nPara conseguir esto, se asigna esa estética de gráfico a un nombre de columna o variable (sin utilizar comillas). Esto debe hacerse dentro del comando mapping = aes()(nota: hay varios lugares en el código donde puedes hacer estas asignaciones de mapeo, como se discute a continuación).\nPresentamos dos ejemplos a continuación.\n\nEn el primer ejemplo, la estética d color = (de cada punto) está mapeada a la columna age - ¡y ha aparecido una escala en una leyenda! Por ahora sólo hay que tener en cuenta que la escala existe - mostraremos cómo modificarla en secciones posteriores.\nEn el segundo ejemplo, dos nuevas estéticas de trazado se asignan a columnas (color = y size =), mientras que las estéticas de trazado shape = y alpha = se asignan a valores estáticos fuera de cualquier función de mapping = aes().\n\n\n# scatterplot\nggplot(data = linelist,   # establecer los datos\n       mapping = aes(     # asignar la estética a los valores de la columna\n         x = age,           # asigna el eje-x a la edad             \n         y = wt_kg,         # asignar el eje-y al peso\n         color = age)     # asignar el color a la edad\n       )+     \n  geom_point()         # mostrar los datos como puntos \n\n# scatterplot\nggplot(data = linelist,   # establecer los datos\n       mapping = aes(     # asignar la estética a los valores de la columna\n         x = age,           # asigna el eje-x a la edad            \n         y = wt_kg,         # asignar el eje-y al peso\n         color = age,       # asignar el color a la edad\n         size = age))+      # asignar el tamaño a la edad\n  geom_point(             # mostrar los datos como puntos\n    shape = \"diamond\",      # los puntos se muestran como diamantes\n    alpha = 0.3)            # transparencia de los puntos al 30%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota: Los ejes siempre se asignan a las columnas de los datos o variables (no a los valores estáticos), y esto se hace siempre dentro de mapping = aes().\nEs importante mantener un seguimiento de las capas y las estéticas se hacen gráficos más complejos, por ejemplo, gráficos con múltiples geom. En el ejemplo siguiente, la estetica size = se asigna dos veces - una para geom_point() y otra para geom_smooth() - ambas veces como un valor estático.\n\nggplot(data = linelist,\n       mapping = aes(           # asignar la estética a las columnas\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # añadir puntos para cada fila de datos\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # añadir una línea de tendencia  \n    method = \"lm\",             # con método lineal\n    size = 2)                   # tamaño (ancho de la línea) de 2\n\n\n\n\n\n\n\n\n\n\nDónde hacer las asignaciones\nLa asignación de estéticas dentro de mapping = aes() puede hacerse en varios lugares en sus comandos e incluso puede escribirse más de una vez. Esto puede ser escrito en el comando ggplot() inicial, y/o en cada geom individual debajo. Los matices incluyen:\n\nLas asignaciones de estéticas realizadas en el comando ggplot() inicial se heredarán por defecto en cualquier geom a continuación, al igual que se heredan x = e y =\nLas asignaciones realizadas dentro de un geom se aplican sólo a ese geom\n\nDel mismo modo, el comando data = especificado en el ggplot() inicial se aplicará por defecto a cualquier geom que se agregue a continuación, pero también se podrían especificar datos para cada geom (pero esto es más difícil).\nAsí, cada uno de los siguientes comandos creará el mismo gráfico:\n\n# Estos comandos producirán exactamente el mismo gráfico\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))\n\n\n\nGrupos\nPuedes agrupar fácilmente los datos y “graficar por grupo”. De hecho, ¡ya lo has hecho!\nAsigna la columna que quieres agrupar a la estética adecuada, dentro del comando mapping = aes(). Más arriba hemos mostrado esto usando valores continuos cuando asignamos el tamaño del punto usando size = a la columna age. Sin embargo, esto funciona de la misma manera con columnas o variables discretas/categóricas.\nPor ejemplo, si quieres agrupar los puntos por género asignándole un color distinto a cada genero, deberás establecer mapping = aes(color = gender). Automáticamente aparecerá una leyenda. Esta asignación puede hacerse dentro de mapping = aes() en el comando ggplot() inicial (y ser heredado por el geom), o podría asignarse dentro de mapping = aes() escrito dentro del comando de geom. Ambos enfoques se muestran a continuación:\n\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n# Este código alternativo produce el mísmo gráfico\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)\n\nTené en cuenta que dependiendo del tipo de geom, tendrás que utilizar diferentes argumentos para agrupar los datos. Para geom_point() lo más probable es que tengas que utilizar color =, shape = o size =. Mientras que para geom_bar() es más probable que utilices fill =. Esto dependerá del tipo de geom y de la estética del gráfico que deses usar para reflejar las agrupaciones.\nPara tu información - la forma más básica de agrupar los datos es utilizando sólo el argumento group = dentro de mapping = aes(). Sin embargo, esto por sí mismo no cambiará los colores, el relleno o las formas. Tampoco creará una leyenda. Sin embargo, los datos están agrupados, por lo que las visualizaciones estadísticas pueden verse afectadas.\nPara ajustar el orden de los grupos en un gráfico, consulta la página de Consejos de ggplot o la página sobre Factores. Hay muchos ejemplos de gráficos agrupados en las secciones siguientes sobre el trazado de datos continuos y categóricos.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#ggplot_basics_facet",
    "href": "new_pages/ggplot_basics.es.html#ggplot_basics_facet",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.6 Facetas / Múltiplos pequeños",
    "text": "30.6 Facetas / Múltiplos pequeños\nLas facetas, o “pequeños gráficos múltiples”, se utilizan para dividir un gráfico en una figura de varios paneles, con un panel (“faceta”) representando un grupo de datos. El mismo tipo de gráfico se crea varias veces, cada vez utilizando un subgrupo del mismo conjunto de datos.\nEl facetado es una funcionalidad que viene con ggplot2, por lo que las leyendas y los ejes de los paneles facetados se alinean automáticamente. Hay otros paquetes que abordamos en la página de Consejos de ggplot que se utilizan para combinar gráficos representando conjuntos de datos completamente diferentes (cowplot y patchwork) en una figura.\nEl facetado se realiza con una de las siguientes funciones de ggplot2:\n\nfacet_wrap() Para mostrar un panel diferente para cada nivel de una unica variable. Un ejemplo de esto podría ser mostrar una curva de epidemia diferente para cada hospital de una región. Las facetas se ordenan alfabéticamente, a menos que la variable sea un factor con otro orden definido.\n\n\nPuedes invocar ciertas opciones para determinar la disposición de las facetas, por ejemplo, nrow = 1 o ncol = 1 para controlar el número de filas o columnas en las que se organizan los gráficos con facetas.\n\n\nfacet_grid() Se utiliza cuando se quiere introducir una segunda variable en la disposición de las facetas. Aquí cada panel de una cuadrícula muestra la intersección entre los valores de dos columnas. Por ejemplo, las curvas epidémicas para cada combinación hospital-grupo de edad con los hospitales en la parte superior (columnas) y los grupos de edad en los lados (filas).\n\n\nnrow y ncol no son relevantes, ya que los subgrupos se presentan en una cuadrícula\n\nCada una de estas funciones acepta una sintaxis de fórmula para especificar la(s) columna(s) para el facetado. Ambas aceptan hasta dos columnas, una a cada lado de la tilde ~.\n\nPara facet_wrap() lo más frecuente es escribir una sola columna precedida de una tilde ~ como facet_wrap(~hospital). Sin embargo, puedes escribir dos columnas facet_wrap(outcome~hospital) - cada combinación única se mostrará en un panel separado, pero no se organizarán en una cuadrícula. Los encabezados mostrarán los términos combinados y éstos no tendrán una lógica específica para las columnas frente a las filas. Si quieres proporcionar una sóla variable de facetado, debes utilizar un punto . como marcador de posición en el otro lado de la fórmula - mira los ejemplos de código.\nPara facet_grid() también puedes especificar una o dos columnas en la fórmula (rows ~ columns). Si sólo quieres especificar una, puedes colocar un punto . al otro lado de la tilde como facet_grid(. ~ hospital) o facet_grid(hospital ~ .).\n\nLas facetas pueden contener rápidamente una cantidad abrumadora de información, por lo que conviene asegurarse de no tener demasiados niveles de cada variable por la que se elija hacer la faceta. He aquí algunos ejemplos rápidos con el conjunto de datos sobre la malaria (véase Descargar el manual y los datos), que consiste en el recuento diario de casos de malaria en los centros, por grupos de edad.\nA continuación importamos y hacemos algunas modificaciones rápidas para simplificar la tarea:\n\n# Estos datos son recuentos diarios de casos de paludismo, por centro-día\nmalaria_data &lt;- import(here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;%  # importa\n  select(-submitted_date, -Province, -newid)                                 # elimina columnas innecesarias\n\nA continuación se muestran las primeras 50 filas de los datos sobre la malaria. Observa que hay una columna malaria_tot, pero también columnas para los recuentos por grupo de edad (que se utilizarán en el segundo ejemplo de facet_grid()).\n\n\n\n\n\n\n\nfacet_wrap()\nPor el momento, vamos a centrarnos en las columnas malaria_tot y District. Ignoremos por ahora las columnas de recuento por edad. Trazaremos las curvas epidémicas con geom_col(), que produce una columna para cada día a la altura del eje-y especificada en la columna malaria_tot (los datos ya son recuentos diarios, por lo que utilizamos geom_col() - véase más adelante la sección “Diagrama de barras”).\nCuando añadimos el comando facet_wrap(), especificamos una tilde y a continuación la columna sobre la que hacer la faceta (District en este caso). Podés colocar otra columna a la izquierda de la tilde, - esto creará una faceta para cada combinación - pero te recomendamos que lo hagas con facet_grid() en su lugar. En este caso, se crea una faceta para cada valor único de District.\n\n# Un gráfico con facetas por distrito\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # graficar los datos de recuento en forma de columnas\n  theme_minimal()+                              # simplificar los paneles de fondo\n  labs(                                         # añadir al gráfico etiquetas, título, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # se crean las facetas\n\n\n\n\n\n\n\n\n\n\nfacet_grid()\nPodemos utilizar un enfoque de facet_grid() para cruzar dos variables. Digamos que queremos cruzar District y edad. Bien, necesitamos hacer algunas transformaciones de datos en las columnas de edad para poner estos datos en el formato “largo” preferido por ggplot. Los grupos de edad tienen sus propias columnas - los queremos en una sola columna llamada age_group y otra llamada num_cases. Consulta la página sobre Pivoteo de datos para obtener más información sobre este proceso.\n\nmalaria_age &lt;- malaria_data %&gt;%\n  select(-malaria_tot) %&gt;% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # elegir columnas para pivotear largo\n    names_to = \"age_group\",      # los nombres de las columnas se convierten en grupos de edad\n    values_to = \"num_cases\"      # valores a una sola columna (num_cases)\n  ) %&gt;%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\n\nAhora las primeras 50 filas de datos tienen este aspecto:\n\n\n\n\n\n\nCuando se asignan las dos variables a facet_grid(), lo más fácil es utilizar la notación de fórmula (por ejemplo, x ~  y) donde x son filas e y son columnas. Aquí está el gráfico, utilizando facet_grid() que muestra los gráficos para cada combinación de las columnas age_group y District.\n\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Casos de malaria por distrito y grupo de edad\"\n  ) +\n  facet_grid(District ~ age_group)\n\n\n\n\n\n\n\n\n\n\nEjes libres o fijos\nLas escalas de los ejes que se muestran en gráficos facetados son, por defecto, las mismas (fijas) en todas las facetas. Esto es útil para las comparaciones cruzadas, pero no siempre es apropiado.\nAl utilizar facet_wrap() o facet_grid(), podemos añadir scales = \"free_y\" para “liberar” los ejes-y de los paneles para que se ajuste la escala adecuadamente en relación a su subconjunto de datos. Esto es particularmente útil si los recuentos reales son pequeños para una de las subcategorías y las tendencias son difíciles de ver. En lugar de “free_y” también podemos escribir “free_x” para hacer lo mismo con el eje-x (por ejemplo, para las fechas) o “free” para liberar ambos ejes. Ten en cuenta que en facet_grid, las escalas de y serán las mismas para las facetas en la misma fila, y las escalas de x serán las mismas para las facetas en la misma columna.\nCuando se utiliza facet_grid solamente, podemos añadir space = \"free_y\" o space = \"free_x\" para que la altura o el ancho de la faceta sea ponderada en relación a los valores de la figura en su interior. Esto sólo funciona si ya se ha asignado scale = \"free\" (y o x).\n\n# Free y-axis\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # graficar los datos de recuento en forma de columnas\n  theme_minimal()+                              # simplificar los paneles de fondo\n  labs(                                         # añadir al gráfico etiquetas, título, etc..\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # se crean las facetas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrden del nivel de los factores en las facetas\nConsulta esta entrada sobre cómo reordenar los niveles de los factores dentro de las facetas.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#storing-plots",
    "href": "new_pages/ggplot_basics.es.html#storing-plots",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.7 Almacenamiento de gráficos",
    "text": "30.7 Almacenamiento de gráficos\n\nGuardar los gráficos\nCuando se ejecuta un comando ggplot(), el gráfico se mostrará en el panel de Plots RStudio de manera predeterminada. Sin embargo, también podés guardar el gráfico como un objeto utilizando el operador de asignación &lt;- y asignandole un nombre. Entonces el gráfico no se mostrará a menos que se ejecute el nombre del objeto mismo. También podés mostrarlo envolviendo el nombre del gráfico con print(), pero esto sólo es necesario en ciertas circunstancias, como cuando el gráfico se crea dentro de un loop for o bucle utilizado para imprimir múltiples gráficos a la vez (véase la página Iteración, bucles y listas ).\n\n# definir gráfico\nage_by_wt &lt;- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# Imprimir\nage_by_wt    \n\n\n\n\n\n\n\n\n\n\nModificación de gráficos guardados\nUna gran ventaja de ggplot2 es que podés definir un gráfico (como se ve arriba), y luego añadirle capas empezando por su nombre sin necesidad de repetir todos los comandos que crearon el gráfico original.\nPor ejemplo, si se desea modificar el gráfico age_by_wt que se definió anteriormente, para incluir una línea vertical a la edad de 50 años, sólo tendríamos que añadir un + y empezar a añadir capas adicionales al gráfico.\n\nage_by_wt+\n  geom_vline(xintercept = 50)\n\n\n\n\n\n\n\n\n\n\nExportación de gráficos\nLa exportación de ggplots es fácil con la función ggsave() de ggplot2. Puede funcionar de dos maneras, ya sea:\n\nEspecifica el nombre del objeto del gráfico, a continuación, la ruta del archivo y el nombre del archivo incluyendo la extensión\n\nPor ejemplo: ggsave(my_plot, here(\"plots\", \"my_plot.png\"))\n\nEjecuta el comando con sólo una ruta de archivo, para guardar el último gráfico que se imprimió en pantalla\n\nPor ejemplo: ggsave(here(\"plots\", \"my_plot.png\"))\n\n\nPuedes exportar como png, pdf, jpeg, tiff, bmp, svg, o varios otros tipos de archivos, especificando la extensión del archivo en la ruta del mismo.\nTambién puedes especificar los argumentos width =, height = y units = (ya sea “in”, “cm” o “mm”). Asimismo podés especificar dpi = asignando un número para la resolución del trazado (por ejemplo, 300). Consulta los detalles de la función ejecutando ?ggsave o leyendo la documentación en línea.\nRecuerda que podés utilizar la sintaxis here() para proporcionar la ruta de archivo deseada. Consulta la página de importación y exportación para obtener más información.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#labels",
    "href": "new_pages/ggplot_basics.es.html#labels",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.8 Etiquetas",
    "text": "30.8 Etiquetas\nSeguramente querrás añadir o ajustar las etiquetas del gráfico. Esto se hace más fácilmente dentro de la función labs() que se añade al gráfico con + al igual que los geoms.\nDentro de labs() podes proporcionar cadenas de caracteres a estos argumentos:\n\nx = e y = El título del eje-x y del eje-y (etiquetas)\ntitle = El título del gráfico principal\nsubtitle = El subtítulo del gráfico, en texto más pequeño debajo del título\ncaption = El pie del gráfico, que aparecerá en la parte inferior derecha de manera predeterminada\n\nAquí está el mismo gráfico que hicimos antes, pero con etiquetas más bonitas:\n\nage_by_wt &lt;- ggplot(\n  data = linelist,   # establecer los datos\n  mapping = aes(     # asignar la estética a los valores de la columna\n         x = age,           # asigna el eje-x a la edad             \n         y = wt_kg,         # asignar el eje-y al peso\n         color = age))+     # asignar el color a la edad\n  geom_point()+           # mostrar los datos como puntos \n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt\n\n\n\n\n\n\n\n\nObserva cómo en la asignación del pie del gráfico hemos utilizado str_glue() del paquete stringr para integrar código R dinámico dentro del texto de la cadena. El pie del gráfico mostrará la fecha “Datos a partir de:” que refleja la fecha máxima de hospitalización en el listado de datos. Puedes leer más sobre esto en la página sobre Caracteres y cadenas.\nUna nota sobre la especificación del título de la leyenda: No hay un argumento “título de la leyenda”, ya que podrías tener múltiples escalas en tu leyenda. Dentro de labs(), podes escribir el argumento de la estética del gráfico utilizado para crear la leyenda, y proporcionar el título de esta manera. Por ejemplo, arriba asignamos color = age para crear la leyenda. Por lo tanto, proporcionamos color = a labs() y asignamos el título de la leyenda deseado (“Age” con A mayúscula). Si se crea la leyenda con aes(fill = COLUMN), entonces en labs() se escribiría fill = para ajustar el título de esa leyenda. La sección sobre escalas de color en la página Consejos de ggplot proporciona más detalles sobre la edición de leyendas, y un enfoque alternativo utilizando las funciones scales_().",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#ggplot_basics_themes",
    "href": "new_pages/ggplot_basics.es.html#ggplot_basics_themes",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.9 Temas",
    "text": "30.9 Temas\nUna de las mejores partes de ggplot2 es el nivel de control que tienes sobre el gráfico - ¡puedes definir lo que quieras! Como se mencionó anteriormente, los aspectos de diseño del gráfico que no están relacionados con las formas/geometrías de los datos se ajustan dentro de la función theme(). Por ejemplo, el color de fondo del gráfico, la presencia/ausencia de líneas de cuadrícula, y la fuente/tamaño/color/alineación del texto (títulos, subtítulos, pie de gráfico, texto de los ejes…). Estos ajustes pueden realizarse de dos maneras:\n\nAñadiendo una función theme_() completa para realizar ajustes de barrido – estas funciones de tema completo incluyen theme_classic(), theme_minimal(), theme_dark(), theme_light() theme_grey(), theme_bw() entre otras\nAjustando cada pequeño aspecto del gráfico individualmente dentro de theme()\n\n\nTemas completos\nComo son bastante sencillas, demostraremos las funciones del tema completo a continuación y no las describiremos más aquí. Ten en cuenta que cualquier microajuste con theme() debe hacerse después de utilizar un tema completo.\nEscribílos con paréntesis vacíos.\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModificar el tema\nLa función theme() puede tomar un gran número de argumentos, cada uno de los cuales edita un aspecto específico del gráfico. No hay manera de que podamos cubrir todos los argumentos, pero describiremos el patrón general para ellos y te mostraremos cómo encontrar el nombre del argumento que necesitas. La sintaxis básica es esta:\n\nDentro de theme() escribe el nombre del argumento del elemento del gráfico que queres editar, como plot.title =\nProporciona una función element_() al argumento\n\nLo más habitual es utilizar element_text(), pero también element_rect() para los colores de fondo del lienzo, o element_blank() para eliminar los elementos del gráfico\n\nDentro de la función element_(), escribí las asignaciones de argumentos para realizar los ajustes finos que desees\n\nEsa descripción es bastante abstracta, así que aquí hay algunos ejemplos.\nEl siguiente gráfico parece tonto, pero sirve para mostrarte una variedad de formas en las que podés ajustar su gráfico.\n\nComenzamos con el gráfico age_by_wt definido anteriormente y añadimos theme_classic()\nPara realizar ajustes más finos, añadimos theme() e incluimos un argumento por cada elemento del gráfico que queremos ajustar\n\nPuede ser util organizar los argumentos en secciones lógicas. A continuación se describen algunos argumentos utilizados:\n\nlegend.position = es el único argumento que acepta valores simples como “bottom”, “top”, “left”, y “right” (abajo, arriba, izquierda y derecha). Por lo general, los argumentos relacionados con el texto requieren que se coloquen los detalles dentro de element_text().\nTamaño del título se ajusta con element_text(size = 30)\nLa alineación horizontal del pie del gráfico se logra con el argumento element_text(hjust = 0) (de derecha a izquierda)\nEl subtítulo aparece en cursiva gracias al argumento element_text(face = \"italic\")\n\n\nage_by_wt + \n  theme_classic()+                                 # ajustes temáticos predefinidos\n  theme(\n    legend.position = \"bottom\",                    # mover la leyenda a la parte inferior\n    \n    plot.title = element_text(size = 30),          # tamaño del título a 30\n    plot.caption = element_text(hjust = 0),        # alinear el título a la izquierda\n    plot.subtitle = element_text(face = \"italic\"), # poner en cursiva el subtítulo\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # ajustar sólo el texto del eje-x\n    axis.text.y = element_text(size = 15),         # ajustar sólo el texto del eje-y\n    \n    axis.title = element_text(size = 20)           # ajusta los títulos de ambos ejes\n    )     \n\n\n\n\n\n\n\n\nAquí hay algunos argumentos de theme() especialmente comunes. Reconocerás algunos patrones, como añadir .x o .y para aplicar el cambio sólo a un eje.\n\n\n\n\n\n\n\nargumento de theme() argument\nLo que ajusta\n\n\n\n\nplot.title = element_text()\nEl título\n\n\nplot.subtitle = element_text()\nEl subtítulo\n\n\nplot.caption = element_text()\nLa leyenda (familia, cara, color, tamaño, ángulo, vjust (justificación vertical), hjust (justificación horizontal)…)\n\n\naxis.title = element_text()\nTítulos de los ejes (tanto x como y) (tamaño, cara, ángulo, color…)\n\n\naxis.title.x = element_text()\nTítulo del eje-x solamente (usar .y para el eje-y solamente)\n\n\naxis.text = element_text()\nTexto de los ejes (x e y)\n\n\naxis.text.x = element_text()\nTexto del eje-x solamente (usar .y para el eje-y solamente)\n\n\naxis.ticks = element_blank()\nEliminar las marcas del eje\n\n\naxis.line = element_line()\nLíneas del eje (color, tamaño, tipo de línea: sólida, punteada, etc.)\n\n\nstrip.text = element_text()\nTexto de la tira de facetas (color, cara, tamaño, ángulo…)\n\n\nstrip.background = element_rect()\nTira de facetas (relleno, color, tamaño…)\n\n\n\nPero ¡hay tantos argumentos de tema! ¿Cómo podría recordarlos todos? No te preocupes, es imposible recordarlos todos. Por suerte, hay algunas herramientas que te ayudarán:\nLa documentación de tidyverse sobre la modificación del tema, tiene una lista completa.\nCONSEJO: Ejecuta theme_get() de ggplot2 para imprimir en pantalla una lista de los más de 90 argumentos de theme() en la consola.\nCONSEJO: Si alguna vez quieres eliminar un elemento de un gráfico, también puedes hacerlo a través de theme(). Basta con pasar element_blank() a un argumento para que desaparezca por completo. Para eliminar leyendas, puedes asignar legend.position = \"none\".",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#colors",
    "href": "new_pages/ggplot_basics.es.html#colors",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.10 Colores",
    "text": "30.10 Colores\nConsulta esta sección sobre las escalas de color de la página de consejos de ggplot.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#piping-into-ggplot2",
    "href": "new_pages/ggplot_basics.es.html#piping-into-ggplot2",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.11 Pipes en ggplot2",
    "text": "30.11 Pipes en ggplot2\nCuando se utilizan pipes para limpiar y transformar los datos, es fácil pasar los datos transformados a ggplot().\nLas pipes que pasan el conjunto de datos de función a función se convertiran a + una vez que se invoque a la función ggplot(). Ten en cuenta que, en este caso, no es necesario especificar el argumento data =, ya que éste se define automáticamente como el conjunto de datos canalizado.\nAsí es como podría verse:\n\nlinelist %&gt;%                                                     # comenzar con linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # seleccionar columnas\n  pivot_longer(                                                  # pivotear largo\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # reemplazar los valores faltantes\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  \n  ggplot(                                                        # comenzar ¡ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#plot-continuous-data",
    "href": "new_pages/ggplot_basics.es.html#plot-continuous-data",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.12 Trazado de datos continuos",
    "text": "30.12 Trazado de datos continuos\nA lo largo de esta página, ya has visto muchos ejemplos de trazado de datos continuos. Aquí los consolidamos brevemente y presentamos algunas variaciones. Las visualizaciones que aquí se cubren incluyen:\n\nGráficos para una variable continua:\n\nHistogram, un gráfico clásico para presentar la distribución de una variable continua.\nGráfico de caja (también llamado de caja y bigotes), para mostrar los percentiles 25, 50 y 75, los extremos de la cola de la distribución y los valores atípicos (limitaciones importantes).\nGráfico de fluctuación, para mostrar todos los valores como puntos que se “fluctúan” para que se puedan ver (casi) todos, incluso cuando dos tienen el mismo valor.\nGráfico del violín, muestra la distribución de una variable continua en función del ancho simétrico del “violín”.\nLos gráficos de Sina, son una combinación de los gráficos de jitter y de violín, donde se muestran los puntos individuales pero con la forma simétrica de la distribución (a través del paquete ggforce).\nGráfico de dispersión para dos variables continuas.\nGráficos de calor para tres variables continuas (enlazado a la página de gráficos de calor)\n\n\n\nHistogramas\nLos histogramas pueden parecerse a los gráficos de barras, pero son distintos porque miden la distribución de una variable continua. No hay espacios entre las “barras”, y sólo se proporciona una columna a geom_histogram().\nA continuación se muestra el código para generar histogramas, que agrupan datos continuos en rangos y se muestran en barras adyacentes de altura variable. Esto se hace utilizando geom_histogram(). Consulta la sección “Gráfico de barras” de la página de fundamentos de ggplot para entender la diferencia entre geom_histogram(), geom_bar() y geom_col().\nVamos a mostrar la distribución de las edades de los casos. Dentro de mapping = aes() especifica la columna de la que quieres ver la distribución. Puedes asignar esta columna al eje-x o al eje-y.\nLas filas serán asignadas a “bins” basados en su edad numérica, y estos bins serán representados gráficamente por barras. Si se especifica un número de bins con la estética de gráfico bins =, los puntos de ruptura se espacian uniformemente entre los valores mínimos y máximos del histograma. Si no se especifica bins =, se adivinará un número apropiado de bins y aparecera este mensaje después del gráfico:\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nSi no quieres especificar un número de bins a bins =, puedes especificar alternativamente binwidth = en las unidades del eje. Damos algunos ejemplos que muestran diferentes bins y anchos de bins:\n\n# A) Histograma regular\nggplot(data = linelist, aes(x = age))+  # proporcionar variable x\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) Más barras\nggplot(data = linelist, aes(x = age))+  # # proporcionar variable x\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Menos barras\nggplot(data = linelist, aes(x = age))+  # proporcionar variable x\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# B) Más barras\nggplot(data = linelist, aes(x = age))+  # proporcionar variable x\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara obtener proporciones suavizadas, puede utilizar geom_density():\n\n# Frecuencia con eje de proporciones, suavizado\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Frecuencia apilada con eje de proporción, suavizada\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara obtener un histograma “apilado” (de una columna continua de datos), puedes hacer una de las siguientes cosas:\n\nUtilizar geom_histogram() con el argumento fill = dentro de aes() y asignado a la columna de agrupación, o bien\n\nUtilizar geom_freqpoly(), que es probablemente más fácil de leer (aún puedes establecer binwidth =)\n\nPara ver las proporciones de todos los valores, se puede utilizar y = after_stat(density) (utiliza esta sintaxis exactamente - no ha cambiado para los datos). Nota: estas proporciones se mostrarán por grupo.\n\nCada uno se muestra a continuación (*nótese el uso de color = versus fill = en cada uno):\n\n# Histograma \"apilado\"\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frecuencia \nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frecuencia con eje de proporciones\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frecuencia con eje de proporción, suavizada\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi quieres divertirte un poco, prueba con geom_density_ridges del paquete ggridges vignette aquí.\nLee más en detalle sobre los histogramas en la página de tidyverse sobre geom_histogram()\n\n\nGráficos de caja\nLos gráficos de caja (Boxplot) son habituales, pero tienen limitaciones importantes. Pueden ocultar la distribución real - por ejemplo, una distribución bimodal. Consulta esta galería de gráficos de R y este artículo sobre la visualización de datos para obtener más detalles. Sin embargo, muestran muy bien el rango intercuartil y los valores atípicos, por lo que pueden superponerse a otros tipos de gráficos que muestran la distribución con más detalle.\nA continuación te recordamos los distintos componentes de un boxplot:\n\n\n\n\n\n\n\n\n\nCuando se utiliza geom_boxplot() para crear un gráfico de caja, generalmente se asigna sólo un eje (x o y) dentro de aes(). El eje especificado determina si los gráficos son horizontales o verticales.\nEn la mayoría de los geoms, se crea un gráfico por grupo asignando una estética como color = o fill = a una columna dentro de aes(). Sin embargo, en el caso de los gráficos de caja, esto se consigue asignando la columna de agrupación al eje no asignado (x o y). A continuación se muestra el código para un diagrama de caja de todos los valores de edad en el conjunto de datos, y un segundo trozo de código para mostrar un diagrama de caja para cada género (no ausente) en el conjunto de datos. Ten en cuenta que los valores NA (valores faltantes) aparecerán como un gráfico de caja separado a menos que se eliminen. En este ejemplo, también hemos asignado el fill de la columna outcome para que cada gráfico tenga un color diferente, pero esto no es necesario.\n\n# A) Boxplot general\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # only y axis mapped (not x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Boxplot por grupo\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # remove legend (redundant)\n  labs(title = \"B) Boxplot by gender\")      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara ver el código para añadir un gráfico de caja a los bordes de un gráfico de dispersión (gráficos “marginales”), consulta la página Consejos de ggplot.\n\n\nGráficos de violín, fluctuación y sina\nA continuación se muestra el código para crear gráficos de violín (geom_violin) y gráficos de fluctuación (geom_jitter) para mostrar distribuciones. Se puede especificar que el relleno o el color también estén determinados por los datos, insertando estas opciones dentro de aes().\n\n# A) Gráfico de fluctuación por grupo\nggplot(data = linelist %&gt;% drop_na(outcome),      # eliminar valores faltantes\n       mapping = aes(y = age,                     # Variable continua\n           x = outcome,                           # Variable de agrupación\n           color = outcome))+                     # Variable de color\n  geom_jitter()+                                  # Crear el gráfico de fluctuación\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# A) Gráfico de violín por grupo\nggplot(data = linelist %&gt;% drop_na(outcome),       # eliminar valores faltantes\n       mapping = aes(y = age,                      # Variable continua\n           x = outcome,                            # Variable de agrupación\n           fill = outcome))+                       # Variable de relleno (color)\n  geom_violin()+                                   # Crear el gráfico de violín\n  labs(title = \"B) violin plot by gender\")    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPuedes combinar los dos tipos de gráfico usando la función geom_sina() del paquete ggforce. sina (Gráfico de violín punteado) traza los puntos de fluctuación en la forma del gráfico de violín. Cuando se superpone al gráfico de violín (ajustando las transparencias) puede ser más fácil de interpretar visualmente.\n\n# A) Gráfico Sina por grupos\nggplot(\n  data = linelist %&gt;% drop_na(outcome), \n  aes(y = age,           # variable numérica\n      x = outcome)) +    # variable de grupo\n  geom_violin(\n    aes(fill = outcome), # relleno (color de fondo del violín)\n    color = \"white\",     # contorno blanco\n    alpha = 0.2)+        # transparencia\n  geom_sina(\n    size=1,                # Cambia el tamaño del jitter (gráfico de fluctuaciones)\n    aes(color = outcome))+ # color (color de los puntos)    \n  scale_fill_manual(       # Definir el relleno del fondo del violín por fallecimiento / recuperación\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Definir colores para puntos por fallecimiento / recuperación\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Eliminar el fondo gris\n  theme(legend.position = \"none\") +                # Eliminar la leyenda innecesaria\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      \n\n\n\n\n\n\n\n\n\n\nDos variables continuas\nSiguiendo una sintaxis similar, geom_point() te permitirá trazar dos variables continuas en un gráfico de dispersión. Esto es útil para mostrar los valores reales en lugar de sus distribuciones. En (A) se muestra un gráfico de dispersión simple de la edad frente al peso. En (B) volvemos a utilizar facet_grid() para mostrar la relación entre dos variables continuas.\n\n# Diagrama de dispersión básico de peso y edad\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Gráfico de dispersión de peso y edad por sexo y resultado del ébola\nggplot(data = linelist %&gt;% drop_na(gender, outcome), # filtro manteniendo los que género/resultado no faltante\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTres variables continuas\nPuedes mostrar tres variables continuas utilizando el argumento fill = para crear un gráfico de calor. El color de cada “celda” reflejará el valor de la tercera columna continua de datos. Consulta la página Consejos de ggplot y la página de gráficos de calor para obtener más detalles y varios ejemplos.\nHay formas de hacer gráficos en 3D en R, pero para la epidemiología aplicada suelen ser difíciles de interpretar y, por tanto, menos útiles para la toma de decisiones.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#trazar-datos-categóricos",
    "href": "new_pages/ggplot_basics.es.html#trazar-datos-categóricos",
    "title": "30  Conceptos básicos de ggplot",
    "section": "Trazar datos categóricos",
    "text": "Trazar datos categóricos\nLos datos categóricos pueden ser valores de carácter, pueden ser lógicos (TRUE/FALSE), o factores (ver la página de Factores).\n\nPreparación\n\nEstructura de datos\nLo primero que hay que entender sobre tus datos categóricos es si existen como observaciones en bruto, como una lista de casos, o como un dataframe de resumen o agregado que contiene recuentos o proporciones. El estado de sus datos afectará a la función de trazado que utilice:\n\nSi tus datos son observaciones en bruto con una fila por observación, es probable que utilices geom_bar()\nSi sus datos ya están agregados en recuentos o proporciones, es probable que utilices geom_col()\n\n\n\nTipo de columna y ordenación de valores\nA continuación, examina el tipo o clase de las columnas (variables) que desea trazar. Veamos hospital, primero usando class() de R base, y luego con tabyl() de janitor.\n\n# Ver clase de columna hospital - podemos ver que es de caracteres\nclass(linelist$hospital)\n\n[1] \"character\"\n\n# Mira los valores y proporciones dentro de la columna hospital\nlinelist %&gt;% \n  tabyl(hospital)\n\n                             hospital    n    percent\n                     Central Hospital  454 0.07710598\n                    Military Hospital  896 0.15217391\n                              Missing 1469 0.24949049\n                                Other  885 0.15030571\n                        Port Hospital 1762 0.29925272\n St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n\n\nPodemos ver que los valores de la variable hospital son caracteres, ya que son nombres de hospitales, y por defecto están ordenados alfabéticamente. Hay valores otros y `faltantes”, que preferiríamos que fueran las últimas subcategorías al presentar los desgloses. Así que convertimos esta columna a clase factor y la reordenamos. Esto se trata con más detalle en la página de Factores.\n\n# Convertir a factor y definir el orden de los niveles para que \"Other\" y \"Missing\" sean los últimos\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\n\n\nlevels(linelist$hospital)\n\n[1] \"St. Mark's Maternity Hospital (SMMH)\"\n[2] \"Port Hospital\"                       \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Other\"                               \n[6] \"Missing\"                             \n\n\n\n\n\nGráfico de barras\nUtiliza geom_bar() si deseas que la altura de las barras (o la altura de los componentes de las barras apiladas) refleje el número de filas relevantes de los datos. Estas barras tendrán huecos entre ellas, a menos que se ajuste la estética de width =.\n\nProporciona sólo una asignación de columna de eje (normalmente el eje-x). Si proporcionas x e y, obtendrás un Error: stat_count() can only have an x or y aesthetic.\nPuedes crear barras apiladas añadiendo una asignación de Columba usando fill = dentro de mapping = aes()\nEl eje opuesto se llamará por defecto “count” (recuento), ya que representa el número de filas\n\nA continuación, hemos asignado el resultado (outcome) al eje-y, pero podría estar fácilmente asignarse al eje-x. Si tienes valores de caracteres más largos, a veces el gráfico se ve mejor si las barras se grafican de manera horizontal en vez de vertical ,poniendo la leyenda en la parte inferior del gráfico. Esto puede afectar el orden en el que aparecen los factores - en este caso los invertimos con fct_rev() para poner la categoría de “faltantes” y “otros” en la parte inferior.\n\n# A) Resultados en todos los casos\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Resultados en todos los casos por hospital\nggplot(linelist %&gt;% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_col()\nUtiliza geom_col() si deseas que la altura de las barras (o la altura de los componentes de las barras apiladas) refleje valores precalculados que existen en los datos. A menudo, se trata de recuentos sumarios o “agregados”, o de proporciones.\nProporciona las asignaciones de columna para ambos ejes a geom_col(). Normalmente la columna del eje-x es discreta y la del eje-y es numérica.\nDigamos que tenemos los un conjunto de datos denominado outcomes:\n\n\n# A tibble: 2 × 3\n  outcome     n proportion\n  &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 Death    1022       56.2\n2 Recover   796       43.8\n\n\nA continuación se muestra un código que utiliza geom_col() para crear gráficos de barras sencillos que muestren la distribución de los resultados de los pacientes con Ebola. Con geom_col, es necesario especificar tanto x como y. Aquí x es la variable categórica a lo largo del eje-x, e y es la columna de proporciones precalculada denominada proportion.\n\n# A) Resultados en todos los casos\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\n\n\n\n\n\n\n\n\nPara mostrar los desgloses por hospital, necesitaríamos que nuestra tabla contuviera más información, y que estuviera en formato “largo”. Creamos esta tabla con las frecuencias de las categorías combinadas outcome y hospital (véase la página de Agrupar datos para obtener consejos de agrupación).\n\noutcomes2 &lt;- linelist %&gt;% \n  drop_na(outcome) %&gt;% \n  count(hospital, outcome) %&gt;%  # obtiene recuentos por hospital y resultado\n  group_by(hospital) %&gt;%        # Agrupa para que las proporciones estén fuera del total del hospital\n  mutate(proportion = n/sum(n)*100)  # calcula las proporciones del total del hospital\n\nhead(outcomes2) # Vista previa de los datos\n\n# A tibble: 6 × 4\n# Groups:   hospital [3]\n  hospital                             outcome     n proportion\n  &lt;fct&gt;                                &lt;chr&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n3 Port Hospital                        Death     785       57.6\n4 Port Hospital                        Recover   579       42.4\n5 Central Hospital                     Death     193       53.9\n6 Central Hospital                     Recover   165       46.1\n\n\nA continuación, creamos el ggplot añadiendo algunas asignaciones de formato:\n\nCambio de posición del eje: Intercambiamos los ejes con coord_flip() para poder leer los nombres de los hospitales.\nColumnas de lado a lado: Se ha añadido un argumento de position = \"dodge\" para que las barras de muerte (Death) y recuperación (Recover) se presenten una al lado de la otra en lugar de apiladas. Ten en cuenta que las barras apiladas aparecen de manera predeterminada.\nAncho de columna: Se especifica el “ancho”, para graficar las columnas a la mitad del ancho posible.\nOrden de las columnas: Se ha invertido el orden de las categorías en el eje-y para que “Otros” y “Faltantes” aparezcan últimos, con scale_x_discrete(limits=rev). Ten en cuenta que usamos eso en lugar de scale_y_discrete porque la variable hospital se asigno al eje-x en el en el argumento de aes(), aunque visualmente se vea en el eje-y. Hacemos esto porque ggplot parece presentar las categorías al revés a menos que le digamos que no lo haga.\nOtros detalles: Añadimos etiquetas/títulos y colores dentro de las funciones de labs y scale_fill_color respectivamente.\n\n\n# B) Resultados en todos los casos por hospital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # muestra los valores de proporción precalculados\n      y = fct_rev(hospital),          # invierte el orden de los niveles para que missing/other estén a final\n      fill = outcome),                # apilado por resultado\n    width = 0.5)+                    # barras más finas (de 1)\n  theme_minimal() +                  # tema mínimo \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # título de la leyenda\n       y = \"Count\",                  # título del eje-y\n       x = \"Hospital of admission\")+ # título del eje-x\n  scale_fill_manual(                 # añade los colores manualmente\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) \n\n\n\n\n\n\n\n\nTen en cuenta que las proporciones son binarias, por lo que podemos preferir omitir recuperar y mostrar sólo la proporción que murió. Esto es sólo a título ilustrativo.\nSi se utiliza geom_col() con datos de fechas (por ejemplo, una epicurva a partir de datos agregados) - querrá ajustar el argumento width = para eliminar los “huecos” entre las barras. Si se utilizan datos diarios (en días), ajuste width= 1. Si se trata de datos semanales, la anchura seria width = 7. Los meses no son posibles de representar porque cada mes tiene un número diferente de días.\n\n\ngeom_histogram()\nLos histogramas pueden parecerse a los gráficos de barras, pero son distintos porque miden la distribución de una variable continua. No hay huecos o espacios entre las “barras” y sólo se asigna una columna a geom_histogram(). Hay argumentos específicos para los histogramas como bin_width = y breaks = para especificar cómo se deben dividir los datos. La sección anterior sobre datos continuos y la página sobre curvas epidémicas proporcionan detalles adicionales.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_basics.es.html#resources-23",
    "href": "new_pages/ggplot_basics.es.html#resources-23",
    "title": "30  Conceptos básicos de ggplot",
    "section": "30.13 Recursos",
    "text": "30.13 Recursos\nHay una gran cantidad de ayuda en línea, especialmente sobre ggplot. Consulta las siguietnes páginas con maerial en inglés:\n\nhoja de trucos de ggplot2\notra hoja de trucos\npágina de fundamentos de tidyverse ggplot\ntrazado de variables continuas\npáginas de R for Data Science en español sobre visualización de datos\ngráficos para la comunicación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Conceptos básicos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html",
    "href": "new_pages/ggplot_tips.es.html",
    "title": "31  Consejos de ggplot",
    "section": "",
    "text": "31.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#preparation-22",
    "href": "new_pages/ggplot_tips.es.html#preparation-22",
    "title": "31  Consejos de ggplot",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  tidyverse,      # incluye ggplot2 y otros\n  rio,            # importar/exportar\n  here,           # localizador de ficheros\n  stringr,        # trabajar con caracteres   \n  scales,         # transformar números\n  ggrepel,        # etiquetas colocadas inteligentemente\n  gghighlight,    # resaltar una parte del gráfico\n  RColorBrewer    # escalas de color\n)\n\n\n\nImportar datos\nPara esta página, importamos el conjunto de datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - ver la página de importación y exportación para más detalles).\n\nlinelist &lt;- rio::import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas de linelist.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#ggplot_tips_colors",
    "href": "new_pages/ggplot_tips.es.html#ggplot_tips_colors",
    "title": "31  Consejos de ggplot",
    "section": "31.2 Escalas para el color, relleno, ejes, etc.",
    "text": "31.2 Escalas para el color, relleno, ejes, etc.\nEn ggplot2, cuando la estética de los datos trazados (por ejemplo, el tamaño, el color, la forma, el relleno, el eje de trazado) se asigna a las columnas de los datos, la visualización exacta se puede ajustar con el correspondiente comando “scale”. En esta sección explicamos algunos ajustes de escala comunes.\n\nEsquemas de color\nUna cosa que puede ser inicialmente difícil de entender con ggplot2 es el control de los esquemas de color. Ten en cuenta que esta sección discute el color de los objetos a representar (geoms/shapes) como puntos, barras, líneas, mosaicos, etc. Para ajustar el color del texto accesorio, los títulos o el color de fondo, consulta la sección Temas de la página Conceptos básicos de ggplot.\nPara controlar el “color” de los objetos de la gráfica se ajustará la estética del color = (el color exterior) o la estética del relleno, fill = (el color interior). Una excepción a este patrón es geom_point(), donde realmente sólo se llega a controlar color =, que controla el color del punto (interior y exterior).\nAl establecer el color o el relleno puedes utilizar nombres de colores reconocidos por R como \"red\" (ver lista completa o introducir ?colors), o un color hexadecimal específico como \"#ff0505\".\n\n# histograma - \nggplot(data = linelist, mapping = aes(x = age))+       # establece datos y ejes\n  geom_histogram(              # muestra el histograma\n    binwidth = 7,                # anchura de los cuadrados\n    color = \"red\",               # color de la línea de los cuadrados\n    fill = \"lightblue\")          # color del interior del cuadrado (fill)\n\n\n\n\n\n\n\n\nComo se explica en la sección asignación de datos al gráfico de Conceptos básicos de ggplot sobre la estética como fill = y color = puede definirse fuera de una sentencia mapping = aes() o dentro de ella. Si está fuera de aes(), el valor asignado debe ser estático (por ejemplo, color = \"blue\") y se aplicará a todos los datos trazados por geom. Si está dentro, la estética debe asignarse a una columna, como color = hospital, y la expresión variará según el valor de esa fila en los datos. Algunos ejemplos:\n\n# Color estático para los puntos y para la línea\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Color asignado a la columna continua\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Color asignado a una columna discreta\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# gráfico de barras, relleno a columna discreta, color a valor estático\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscalas\nUna vez que se asigna una columna a una estética de la gráfica (por ejemplo, x =, y =, fill =, color =…), tu gráfica ganará una escala / leyenda. Mira arriba cómo la escala puede ser continua, discreta, de fecha, etc. dependiendo del tipo de la columna asignada. Si tienes múltiples estéticas asignadas a las columnas, tu gráfico tendrá múltiples escalas.\nPuedes controlar las escalas con la función scales_() apropiada. Las funciones de escala de ggplot() tienen 3 partes que se escriben así: scale_AESTHETIC_METHOD().\n\nLa primera parte, scale_(), es fija.\nLa segunda parte, la ESTÉTICA, debe ser la estética para la que deseas ajustar la escala (_fill_, _shape_, _color_, _size_, _alpha_…) - las opciones aquí también incluyen _x_ e _y_.\nLa tercera parte, el MÉTODO, será _discrete(), continuous(), _date(), _gradient(), o _manual() dependiendo del tipo de la columna y de cómo se quiera controlar. Hay otros, pero estos son los más utilizados.\n\nAsegúrate de utilizar la función correcta para la escala. De lo contrario, tu comando de escala no parecerá cambiar nada. Si tienes varias escalas, puedes utilizar varias funciones de escala para ajustarlas. Por ejemplo:\n\n\nArgumentos de la escala\nCada tipo de escala tiene sus propios argumentos, aunque hay cierto solapamiento. Consulta la función escribiendo ?scale_color_discrete en la consola de R para ver la documentación de los argumentos de la función.\nPara escalas continuas, utiliza breaks = para proporcionar una secuencia de valores con seq() (to =, from =, y by = como se muestra en el ejemplo siguiente. Fija expand = c(0,0) para eliminar el espacio de relleno alrededor de los ejes (esto se puede utilizar en cualquier escala _x_ o _y_.\nEn el caso de las escalas discretas, puedes ajustar el orden de aparición de los niveles con los breaks =, y cómo se muestran los valores con el argumento labels =. Proporciona un vector de caracteres a cada uno de ellos (véase el ejemplo siguiente). También puedes dejar de lado NA fácilmente estableciendo na.translate = FALSE.\nLos matices de las escalas de fechas se tratan más ampliamente en la página de curvas epidémicas.\n\n\nAjustes manuales\nUno de los trucos más útiles es utilizar las funciones de escalado “manual” para asignar explícitamente los colores que se deseen. Son funciones con la sintaxis scale_xxx_manual() (por ejemplo, scale_colour_manual() o scale_fill_manual()). Cada uno de los argumentos siguientes se demuestra en el ejemplo de código que sigue.\n\nAsignar colores a los valores de los datos con el argumento values =\nEspecificar un color para NA con na.value =\nCambiar cómo se escriben los valores en la leyenda con el argumento labels =\nCambiar el título de la leyenda con name =\n\nA continuación, creamos un gráfico de barras y mostramos cómo aparece por defecto, y luego con tres escalas ajustadas - la escala continua del eje-y, la escala discreta del eje-x, y el ajuste manual del relleno (color interior de la barra).\n\n# LÍNEA BASE - sin ajuste de escala\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n\n\n\n\n\n\n# ESCALAS AJUSTADAS\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # fondo simplificado\n  \n  scale_y_continuous(                # escala continua para el eje-y (recuentos)\n    expand = c(0,0),                 # sin relleno\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # escala discreta para el eje x (género)\n    expand = c(0,0),                  # sin relleno\n    drop = FALSE,                     # muestra todos los niveles del factor (incluso si no están en los datos)\n    na.translate = FALSE,             # elimina los resultados NA del gráfico\n    labels = c(\"Died\", \"Recovered\"))+ # Cambia la visualización de los valores\n    \n  \n  scale_fill_manual(                  # Especifica manualmente el relleno (color interior de la barra)\n    values = c(\"m\" = \"violetred\",     # valores de referencia en los datos para asignar colores\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          # reetiqueta la leyenda (utiliza la asignación \"=\" para evitar errores)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # título de la leyenda\n    na.value = \"grey\"                 # asigna un color para los valores que faltan\n  )+\n  labs(title = \"Adjustment of scales\") # ajusta el título de la leyenda de relleno\n\n\n\n\n\n\n\n\n\n\nEscalas de ejes continuos\nCuando los datos se mapean a los ejes del gráfico, éstos también pueden ajustarse con comandos de escalas. Un ejemplo común es el ajuste de la visualización de un eje (por ejemplo, el eje-y) que se asigna a una columna con datos continuos.\nEs posible que queramos ajustar los descansos o la visualización de los valores en ggplot utilizando scale_y_continuous(). Como se indicó anteriormente, utiliza el argumento breaks = para proporcionar una secuencia de valores que servirán como “saltos” a lo largo de la escala. Estos son los valores en los que se mostrarán los números. A este argumento, puedes proporcionar un vector c() que contenga los valores de ruptura deseados, o puedes proporcionar una secuencia regular de números utilizando la función seq() de R base. Esta función seq() acepta to =, from =, y by =.\n\n# LÍNEA BASE - sin ajuste de escala\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar porcentajes\nSi los valores de datos originales son proporciones, puedes mostrarlos fácilmente como porcentajes con “%” proporcionando labels = scales::percent en el comando de escalas, como se muestra a continuación.\nAunque una alternativa sería convertir los valores en caracteres y añadir un carácter “%” al final, este enfoque causará complicaciones porque tus datos ya no serán valores numéricos continuos.\n\n# Proporciones originales del eje-y\n###################################\nlinelist %&gt;%                                   # empieza con linelist\n  group_by(hospital) %&gt;%                       # agrupa los datos por hospital\n  summarise(                                   # crea columnas de resumen\n    n = n(),                                     # número total de filas en el grupo\n    deaths = sum(outcome == \"Death\", na.rm=T),   # número de defunciones en el grupo\n    prop_death = deaths/n) %&gt;%                   # proporción de defunciones en el grupo\n  ggplot(                                      # comienza a trazar\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Mostrar las proporciones del eje-y como porcentajes\n#####################################################\nlinelist %&gt;%         \n  group_by(hospital) %&gt;% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %&gt;% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # muestra las proporciones como porcentajes\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscala logarítmica\nPara transformar un eje continuo a escala logarítmica, añade trans = \"log2\" al comando de escala. A modo de ejemplo, creamos un dataframe de regiones con sus respectivos valores de preparedness_index y casos acumulados.\n\nplot_data &lt;- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data\n\n  region preparedness_index cases_cumulative\n1      A                8.8               15\n2      B                7.5               45\n3      C                3.4               80\n4      D                3.6               20\n5      E                2.1               21\n6      F                7.9                7\n7      G                7.0               51\n8      H                5.6               30\n9      I                1.0             1442\n\n\nLos casos acumulados de la región “I” son mucho mayores que los de las demás regiones. En circunstancias como ésta, puedes optar por mostrar el eje-y utilizando una escala logarítmica para que el lector pueda ver las diferencias entre las regiones con menos casos acumulados.\n\n# Eje-y original\npreparedness_plot &lt;- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # puntos para cada región \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # añade etiquetas de texto\n  theme_minimal()\n\npreparedness_plot                  # imprime el gráfico original\n\n\n# imprime con el eje-y transformado\npreparedness_plot+                   # comienza con el gráfico anterior\n  scale_y_continuous(trans = \"log2\") # añade transformación al eje-y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscalas de gradiente\nLas escalas de degradado de relleno pueden implicar matices adicionales. Los valores predeterminados suelen ser bastante agradables, pero es posible que desees ajustar los valores, los cortes, etc.\nPara demostrar cómo ajustar una escala de colores continua, utilizaremos unos datos de la página de Rastreo de contactos que contiene las edades de los casos y de sus casos de origen.\n\ncase_source_relationships &lt;- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %&gt;% \n  select(source_age, target_age) \n\nA continuación, producimos un gráfico de densidad de mapa de calor “rasterizado”. No vamos a desarrollar cómo (ver el enlace en el párrafo anterior), pero nos centraremos en cómo podemos ajustar la escala de colores. Lee más sobre la función stat_density2d() de ggplot2 aquí. Observa cómo la escala de relleno es continua.\n\ntrans_matrix &lt;- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\n\nAhora mostramos algunas variaciones en la escala de relleno:\n\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora mostramos algunos ejemplos de cómo ajustar realmente los puntos de ruptura de la escala:\n\nscale_fill_gradient() acepta dos colores (high/low)\nscale_fill_gradientn() acepta un vector de cualquier longitud de colores a values = (los valores intermedios serán interpolados)\nUsa scales::rescale() para ajustar la posición de los colores a lo largo del gradiente; reescala tu vector de posiciones para que esté entre 0 y 1.\n\n\ntrans_matrix + \n  scale_fill_gradient(     # escala de gradiente de 2 lados\n    low = \"aquamarine\",    # valor bajo\n    high = \"purple\",       # valor alto\n    na.value = \"grey\",     # valor para NA\n    name = \"Density\")+     # Título de la leyenda\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ colores en la escala\ntrans_matrix + \n  scale_fill_gradientn(    # escala de 3 colores (bajo/medio/alto)\n    colors = c(\"blue\", \"yellow\",\"red\") # proporciona los colores en el vector\n  )+\n  labs(title = \"3-color scale\")\n\n# Uso de rescale() para ajustar la colocación de los colores a lo largo de la escala\ntrans_matrix + \n  scale_fill_gradientn(    # proporciona cualquier número de colores\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # las posiciones de los colores se reescalan entre 0 y 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# uso de valores de corte que obtienen color de relleno\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaletas\n\nColorbrewer y Viridis\nEn general, si deseas paletas predefinidas, puedes utilizar las funciones scale_xxx_brewer o scale_xxx_viridis_y.\nLas funciones ‘brewer’ pueden dibujar desde las paletas de colorbrewer.org.\nLas funciones ‘viridis’ se basan en las paletas viridis (¡difíciles para los daltónicos!), que “proporcionan mapas de color que son perceptivamente uniformes tanto en color como en blanco y negro. También están diseñadas para ser percibidas por espectadores con formas comunes de daltonismo”. (lee más aquí y aquí). Define si la paleta es discreta, continua o con intervalos especificando esto al final de la función (por ejemplo, discreta es scale_xxx_viridis_d).\nSe aconseja que pruebes tu esquema en este simulador de daltonismo. Si tienes un esquema de color rojo/verde, prueba en su lugar un esquema “caliente-frío” (rojo-azul) como se describe aquí\nAquí hay un ejemplo de la página de Conceptos básicos de ggplot, utilizando varios esquemas de color.\n\nsymp_plot &lt;- linelist %&gt;%                                         # comienza con linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %&gt;%     # selecciona columnas\n  pivot_longer(                                                  # pivotea largo\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %&gt;%\n  mutate(                                                        # reemplaza los valores faltantes\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %&gt;% \n  ggplot(                                                        # ¡comienza ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  # imprime con colores por defecto\n\n#################################\n# imprimir con colores especificados manualmente\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # define explícitamente los colores\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # ordena los factores correctamente\n    name = \"\"                           # establece la leyenda sin título\n\n  ) \n\n#################################\n# imprimir con colores discretos viridis\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#change-order-of-discrete-variables",
    "href": "new_pages/ggplot_tips.es.html#change-order-of-discrete-variables",
    "title": "31  Consejos de ggplot",
    "section": "31.3 Cambiar el orden de las variables discretas",
    "text": "31.3 Cambiar el orden de las variables discretas\nCambiar el orden en que aparecen las variables discretas es a menudo difícil de entender para las personas que son nuevas en los gráficos de ggplot2. Sin embargo, es fácil de entender cómo hacer esto una vez que se entiende cómo ggplot2 maneja las variables discretas por debajo. En general, si se utiliza una variable discreta, se convierte automáticamente en un tipo de factor - que ordena los factores por orden alfabético por defecto. Para manejar esto, simplemente tienes que reordenar los niveles de los factores para reflejar el orden en que te gustaría que aparecieran en el gráfico. Para obtener información más detallada sobre cómo reordenar los objetos de factor, consulta la página Factores.\nPodemos ver un ejemplo común utilizando los grupos de edad - por defecto el grupo de 5 a 9 años se colocará en medio de los grupos de edad (dado el orden alfanumérico), pero podemos moverlo detrás del grupo de 0 a 4 años del gráfico renivelando los factores.\n\nggplot(\n  data = linelist %&gt;% drop_na(age_cat5),                         # elimina las filas en las que falta age_cat5\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # factor de renivelación\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n31.3.0.1 ggthemr\nTambién considera utilizar el paquete ggthemr. Puedes descargar este paquete desde Github usando estas instrucciones. Ofrece paletas que son muy agradables estéticamente, pero ten en cuenta que estas suelen tener un número máximo de valores que puede ser limitante si quieres más de 7 u 8 colores.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#contour-lines",
    "href": "new_pages/ggplot_tips.es.html#contour-lines",
    "title": "31  Consejos de ggplot",
    "section": "31.4 Líneas de contorno",
    "text": "31.4 Líneas de contorno\nLos gráficos de contorno son útiles cuando se tienen muchos puntos que pueden cubrirse unos a otros (“sobretrazado”). Los datos de la fuente de casos utilizados anteriormente se trazan de nuevo, pero de forma más sencilla utilizando stat_density2d() y stat_density2d_filled() para producir niveles de contorno discretos - como un mapa topográfico. Lee más sobre las estadísticas aquí.\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %&gt;% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#marginal-distributions",
    "href": "new_pages/ggplot_tips.es.html#marginal-distributions",
    "title": "31  Consejos de ggplot",
    "section": "31.5 Distribuciones marginales",
    "text": "31.5 Distribuciones marginales\nPara mostrar las distribuciones en los bordes de un gráfico de dispersión geom_point(), puedes utilizar el paquete ggExtra y su función ggMarginal(). Guarda tu ggplot original como un objeto, y pásalo a ggMarginal() como se muestra a continuación. Estos son los argumentos clave:\n\nDebe especificar el type = como “histogram”, “density” “boxplot”, “violin”, o “densigram”\nPor defecto, los gráficos marginales aparecerán para ambos ejes. Puedes establecer margins = a “x” o “y” si sólo quieres uno.\nOtros argumentos opcionales son fill = (color de la barra), color = (color de la línea), size = (tamaño del gráfico en relación con el tamaño del margen, por lo que un número mayor hace que el gráfico marginal sea más pequeño).\nPuedes proporcionar otros argumentos específicos del eje a xparams = e yparams =. Por ejemplo, para tener diferentes tamaños de cubos de histograma, como se muestra a continuación.\n\nPuedes hacer que los gráficos marginales reflejen grupos (columnas a las que se les ha asignado un color = en su estética mapeada de ggplot()). Si este es el caso, establece el argumento ggMarginal() groupColour = o groupFill = a TRUE, como se muestra a continuación.\nLee más en esta viñeta, en la galería de gráficos de R o en la documentación de la función R ?ggMarginal.\n\n# Instalar/cargar ggExtra\npacman::p_load(ggExtra)\n\n# Gráfico básico de dispersión de peso y edad\nscatter_plot &lt;- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n\nPara añadir histogramas marginales utiliza type = \"histogram\". Opcionalmente puedes establecer groupFill = TRUE para obtener histogramas apilados.\n\n# con histogramas\nggMarginal(\n  scatter_plot,                     # añade histogramas marginales\n  type = \"histogram\",               # especifica histogramas\n  fill = \"lightblue\",               # relleno de barras\n  xparams = list(binwidth = 10),    # otros parámetros para el eje-x marginal\n  yparams = list(binwidth = 5))     # otros parámetros para el eje-y marginal\n\n\n\n\n\n\n\n\nGráfico de densidad marginal con valores agrupados/coloreados:\n\n# Diagrama de dispersión, coloreado por resultado\n# La columna Outcome se asigna como color en ggplot. groupFill en ggMarginal se establece en TRUE\nscatter_plot_color &lt;- ggplot(data = linelist %&gt;% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n\n\n\n\n\n\n\n\nEstablece el argumento size = para ajustar el tamaño relativo del gráfico marginal. Un número más pequeño hace un gráfico marginal más grande. También se establece el color =. A continuación se muestra un boxplot marginal, con la demostración del argumento margins = por lo que aparece en un solo eje:\n\n# con boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # sólo muestra el gráfico marginal del eje-x\n  type = \"boxplot\")",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#smart-labeling",
    "href": "new_pages/ggplot_tips.es.html#smart-labeling",
    "title": "31  Consejos de ggplot",
    "section": "31.6 Etiquetado inteligente",
    "text": "31.6 Etiquetado inteligente\nEn ggplot2, también es posible añadir texto a los gráficos. Sin embargo, esto viene con la notable limitación de que las etiquetas de texto a menudo chocan con los puntos de datos en un gráfico, haciendo que se vean desordenados o difíciles de leer. No hay una manera ideal de lidiar con esto en el paquete base, pero hay un complemento de ggplot2, conocido como ggrepel que hace que esto sea muy simple.\nEl paquete ggrepel proporciona dos nuevas funciones, geom_label_repel() y geom_text_repel(), que sustituyen a geom_label() y geom_text(). Basta con utilizar estas funciones en lugar de las funciones base para producir etiquetas ordenadas. Dentro de la función, mapea la estética aes() como siempre, pero incluye el argumento label = al que le proporciona un nombre de columna que contenga los valores que deseas mostrar (por ejemplo, id de paciente, o nombre, etc.). Puedes hacer etiquetas más complejas combinando columnas y nuevas líneas (\\n) dentro de str_glue() como se muestra a continuación.\nAlgunos consejos:\n\nUtiliza min.segment.length = 0 para dibujar siempre segmentos de línea, o min.segment.length = Inf para no dibujarlos nunca\nUtiliza size = fuera de aes() para establecer el tamaño del texto\nUtiliza force = para cambiar el grado de repulsión entre las etiquetas y sus respectivos puntos (por defecto es 1)\nIncluye fill = dentro de aes() para tener la etiqueta coloreada por el valor\n\nPuede aparecer una letra “a” en la leyenda - añade guides(fill = guide_legend(override.aes = aes(color = NA)))+ para eliminarla\n\n\nPara verlo con mayor profundidad, consulta este tutorial\n\npacman::p_load(ggrepel)\n\nlinelist %&gt;%                                               # empieza con linelist\n  group_by(hospital) %&gt;%                                   # agrupa por hospital\n  summarise(                                               # crea un nuevo conjunto de datos con valores de resumen por hospital\n    n_cases = n(),                                           # número de casos por hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # retraso medio por hospital\n  ) %&gt;% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # envía los datos a ggplot\n  geom_point(size = 2)+                                    # añade puntos\n  geom_label_repel(                                        # añade etiquetas de puntos\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # cómo se muestra la etiqueta\n      ), \n    size = 3,                                              # tamaño del texto en las etiquetas\n    min.segment.length = 0)+                               # muestra todos los segmentos de línea                 \n  labs(                                                    # añade etiquetas a los ejes\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\n\n\n\n\n\n\n\n\nPuedes etiquetar sólo un subconjunto de los puntos de datos - utilizando la sintaxis estándar de ggplot() para proporcionar diferentes data = para cada geom del gráfico. A continuación, se trazan todos los casos, pero sólo se etiquetan algunos.\n\nggplot()+\n  # Todos los puntos en gris\n  geom_point(\n    data = linelist,                                   # todos los datos proporcionados a esta capa\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # gris y semitransparente\n  \n  # Pocos puntos en negro\n  geom_point(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # datos filtrados proporcionados a esta capa\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # por defecto negro y no transparente\n  \n  # etiquetas para algunos puntos\n  geom_label_repel(\n    data = linelist %&gt;% filter(days_onset_hosp &gt; 15),  # filtra los datos para las etiquetas\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # color de la etiqueta por resultado\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # etiqueta creada con str_glue()\n    min.segment.length = 0) +                                  # muestra segmentos de línea para todos\n  \n  # elimina la letra \"a\" del interior de los cuadros de leyenda\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # etiquetas de los ejes\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#time-axes",
    "href": "new_pages/ggplot_tips.es.html#time-axes",
    "title": "31  Consejos de ggplot",
    "section": "31.7 Ejes temporales",
    "text": "31.7 Ejes temporales\nTrabajar con ejes de tiempo en ggplot puede parecer desalentador, pero se hace muy fácil con unas pocas funciones clave. Recuerda que cuando trabajes con el tiempo o la fecha debes asegurarte que las variables correctas están formateadas como tipo date o datetime - mira la página Trabajar con fechas para más información sobre esto, o la página Curvas epidémicas (sección ggplot) para ver ejemplos.\nEl conjunto de funciones más útil para trabajar con fechas en ggplot2 son las funciones de escala (scale_x_date(), scale_x_datetime(), y sus funciones afines del eje-y). Estas funciones permiten definir la frecuencia de las etiquetas de los ejes, y cómo formatear las etiquetas de los ejes. Para saber cómo dar formato a las fechas, vuelve a ver la sección de trabajar con fechas. Puedes utilizar los argumentos date_breaks y date_labels para especificar el aspecto de las fechas:\n\ndate_breaks permite especificar la frecuencia con la que se producen las rupturas de los ejes - se puede pasar aquí una cadena (por ejemplo, \"3 months\", or “2 days\")\ndate_labels permite definir el formato en el que se muestran las fechas. Puedes pasar una cadena de formato de fecha a estos argumentos (por ejemplo, \"%b-%d-%Y\"):\n\n\n# crea la curva epidemiológica por fecha de inicio cuando esté disponible\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # 1 salto cada 1 mes\n    date_breaks = \"1 months\",\n    # las etiquetas deben mostrar el mes y luego la fecha\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#highlighting",
    "href": "new_pages/ggplot_tips.es.html#highlighting",
    "title": "31  Consejos de ggplot",
    "section": "31.8 Resaltando",
    "text": "31.8 Resaltando\nResaltar elementos específicos en un gráfico es una forma útil de llamar la atención sobre una instancia específica de una variable, a la vez que se proporciona información sobre la dispersión de los datos. Aunque esto no es fácil de hacer en ggplot2 base, hay un paquete externo que puede ayudar a hacer esto conocido como gghighlight. Es fácil de usar dentro de la sintaxis de ggplot.\nEl paquete gghighlight utiliza la función gghighlight() para lograr este efecto. Para usar esta función, suministra una declaración lógica a la función - esto puede tener resultados bastante flexibles, pero aquí mostraremos un ejemplo de la distribución de edad de los casos en nuestro listado, resaltándolos por resultado.\n\n# carga gghighlight\nlibrary(gghighlight)\n\n# sustituye los valores NA por unknown en la variable outcome\nlinelist &lt;- linelist %&gt;%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produce a histogram of all cases by age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # highlight instances where the patient has died.\n\n\n\n\n\n\n\n\nEsto también funciona bien con las funciones de facetas - ¡permite al usuario producir gráficos de facetas con los datos de fondo resaltados que no se aplican a la faceta! A continuación, contamos los casos por semana y trazamos las curvas de epidemia por hospital (color = y facet_wrap() ajustado a la columna hospital).\n\n# produce un histograma de todos los casos por edad\nlinelist %&gt;% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %&gt;% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # resalta los casos en los que el paciente ha fallecido.\n  facet_wrap(~hospital)                              # crea facetas por resultado",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#plotting-multiple-datasets",
    "href": "new_pages/ggplot_tips.es.html#plotting-multiple-datasets",
    "title": "31  Consejos de ggplot",
    "section": "31.9 Representar múltiples conjuntos de datos",
    "text": "31.9 Representar múltiples conjuntos de datos\nTen en cuenta que alinear correctamente los ejes para trazar múltiples conjuntos de datos en el mismo gráfico puede ser difícil. Considera una de las siguientes estrategias:\n\nFusionar los datos antes de trazarlos y convertirlos al formato “long” con una columna que refleje el conjunto de datos\nUtilizar Cowplot o un paquete similar para combinar dos gráficos (véase más abajo)",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#combine-plots",
    "href": "new_pages/ggplot_tips.es.html#combine-plots",
    "title": "31  Consejos de ggplot",
    "section": "31.10 Combinar gráficos",
    "text": "31.10 Combinar gráficos\nDos paquetes que son muy útiles para combinar gráficos son cowplot y patchwork. En esta página nos centraremos principalmente en cowplot, con el uso ocasional de patchwork.\nAquí está la introducción en línea a cowplot. Puedes leer la documentación más extensa de cada función en línea aquí. A continuación cubriremos algunos de los casos de uso y funciones más comunes.\nEl paquete cowplot funciona en tándem con ggplot2 - esencialmente, se utiliza para organizar y combinar ggplots y sus leyendas en figuras compuestas. También puede aceptar gráficos de R base.\n\npacman::p_load(\n  tidyverse,      # manipulación y visualización de datos\n  cowplot,        # combinar gráficos\n  patchwork       # combinar gráficos\n)\n\nMientras que las facetas (descritas en la página de Conceptos básicos de ggplot) son un enfoque conveniente para el trazado, a veces no es posible obtener los resultados que deseas de su enfoque relativamente restrictivo. En este caso, se puede optar por combinar los gráficos pegándolos en un gráfico más grande. Hay tres paquetes bien conocidos que son excelentes para esto - cowplot, gridExtra, y patchwork. Sin embargo, estos paquetes hacen en gran medida las mismas cosas, por lo que nos centraremos en cowplot para esta sección.\n\nplot_grid()\nEl paquete cowplot tiene una gama bastante amplia de funciones, pero el uso más fácil de él se puede lograr mediante el uso de plot_grid(). Se trata de una forma de organizar los gráficos predefinidos en una cuadrícula. Podemos trabajar a través de otro ejemplo con el conjunto de datos de la malaria - aquí podemos trazar el total de casos por distrito, y también mostrar la curva epidémica en el tiempo.\n\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# gráfico de barras del total de casos por distrito\np1 &lt;- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# curva epidémica a lo largo del tiempo\np2 &lt;- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 columna y dos filas - apiladas una sobre otra\n                   ncol = 1,\n                   nrow = 2,\n                   # el gráfico superior es 2/3 más alto que el segundo\n                   rel_heights = c(2, 3))\n\n\n\n\n\n\n\n\n\n\nCombinar leyendas\nSi tus gráficos tienen la misma leyenda, combinarlos es relativamente sencillo. Simplemente utiliza el método de cowplot anterior para combinar los gráficos, pero elimina la leyenda de uno de ellos (de-duplica).\nSi tus gráficos tienen leyendas diferentes, debes utilizar un enfoque alternativo:\n\nCrea y guarda tus gráficos sin leyendas utilizando theme(legend.position = \"none\")\nExtrae las leyendas de cada gráfica utilizando get_legend() como se muestra a continuación - pero extrae las leyendas de los gráficos modificados para mostrar realmente la leyenda\nCombina las leyendas en un panel de leyendas\nCombina el panel de gráficos y leyendas\n\nPara comprobarlo, mostramos las dos gráficos por separado, y luego dispuestas en una cuadrícula con sus propias leyendas mostrando (uso feo e ineficiente del espacio):\n\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\n\nAsí es como se ven los dos gráficos cuando se combinan usando plot_grid() sin combinar sus leyendas:\n\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n\n\n\n\n\n\n\n\nY ahora mostramos cómo combinar las leyendas. Esencialmente lo que hacemos es definir cada gráfica sin su leyenda (theme(legend.position = \"none\"), y luego definimos la leyenda de cada gráfica por separado, utilizando la función get_legend() de cowplot. Cuando extraemos la leyenda del gráfico guardado, tenemos que añadir + la leyenda de nuevo, incluyendo la especificación de la colocación (“derecha”) y pequeños ajustes para la alineación de las leyendas y sus títulos. A continuación, combinamos las leyendas verticalmente, y luego combinamos los dos gráficos con las leyendas recién combinadas. Voila!\n\n# Define plot 1 without legend\np1 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Define plot 2 without legend\np2 &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, age_cat) %&gt;% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extract legend from p1 (from p1 + legend)\nleg_p1 &lt;- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extract vertical legend\n                                      legend.justification = c(0,0.5))+ # so legends  align\n                                labs(fill = \"Outcome\"))                 # title of legend\n# extract legend from p2 (from p2 + legend)\nleg_p2 &lt;- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extract vertical legend   \n                                      legend.justification = c(0,0.5))+  # so legends align\n                                labs(fill = \"Age Category\"))             # title of legend\n\n# create a blank plot for legend alignment\n#blank_p &lt;- patchwork::plot_spacer() + theme_void()\n\n# create legends panel, can be one on top of the other (or use spacer commented above)\nlegends &lt;- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combine two plots and the combined legends panel\ncombined &lt;- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # print\n\n\n\n\n\n\n\n\nEsta solución fue aprendida de este post con un arreglo menor para alinear las leyendas de este post.\nCONSEJO: Nota divertida: la “vaca” en cowplot viene del nombre del creador: Claus O. Wilke.\n\n\nGráficos insertados\nPuedes insertar una gráfica en otra utilizando cowplot. Aquí hay cosas que hay que tener en cuenta:\n\nDefine el gráfico principal con theme_half_open() de cowplot; puede ser mejor tener la leyenda arriba o abajo\nDefine el gráfico de inserción. Lo mejor es tener un gráfico en el que no se necesite una leyenda. Puedes eliminar los elementos del tema del gráfico con element_blank() como se muestra a continuación.\nCombínalos aplicando ggdraw() al gráfico principal, y luego añadiendo draw_plot() en el gráfico de inserción y especificando las coordenadas (x e y de la esquina inferior izquierda), la altura y la anchura como proporción de todo el gráfico principal.\n\n\n# Define main plot\nmain_plot &lt;- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Define inset plot\ninset_plot &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %&gt;% \n  count(hospital, outcome) %&gt;% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combine main with inset\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)\n\n\n\n\n\n\n\n\nEsta técnica se explica mejor en estas dos viñetas:\nLaboratorio Wilke\ndocumentación de draw_plot()",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#dual-axes",
    "href": "new_pages/ggplot_tips.es.html#dual-axes",
    "title": "31  Consejos de ggplot",
    "section": "31.11 Ejes dobles",
    "text": "31.11 Ejes dobles\nUn eje-y secundario es a menudo una adición solicitada a un gráfico ggplot2. Aunque existe un fuerte debate sobre la validez de estos gráficos en la comunidad de visualización de datos, y a menudo no se recomiendan, es posible que tu jefe los quiera. A continuación, presentamos un método para conseguirlos: usa el paquete cowplot para combinar dos gráficos separados.\nEste enfoque implica la creación de dos gráficos separados - uno con un eje-y a la izquierda, y el otro con un eje-y a la derecha. Ambos utilizarán un tema específico de theme_cowplot() y deben tener el mismo eje-x. Luego, en un tercer comando, los dos gráficos se alinean y se superponen. Las funcionalidades de cowplot, de las que ésta es sólo una, se describen en profundidad en este sitio.\nPara demostrar esta técnica, superpondremos la curva epidémica con una línea del porcentaje semanal de pacientes fallecidos. Utilizamos este ejemplo porque la alineación de las fechas en el eje-x es más compleja que, por ejemplo, alinear un gráfico de barras con otro gráfico. Hay que tener en cuenta algunas cosas:\n\nPara la curva epidémica y la línea se agrupan en semanas antes de trazarlas y los date_breaks y date_labels son idénticos - lo hacemos para que los ejes-x de los dos gráficos sean los mismos cuando se superponen.\nEl eje-y se mueve a la derecha para el gráfico 2 con el argumento position = de scale_y_continuous().\nAmbos gráficos hacen uso de theme_cowplot()\n\nObserva que hay otro ejemplo de esta técnica en la página de curvas epidémicas: la superposición de la incidencia acumulada sobre la curva epidemica.\nHacer el gráfico 1 Esto es esencialmente la curva epidémica. Usamos geom_area() sólo para mostrar su uso (área bajo una línea, por defecto)\n\npacman::p_load(cowplot)            # load/install cowplot\n\np1 &lt;- linelist %&gt;%                 # save plot as object\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # view plot \n\n\n\n\n\n\n\n\nHacer el gráfico 2 Crea el segundo gráfico mostrando una línea del porcentaje semanal de casos que murieron.\n\np2 &lt;- linelist %&gt;%         # save plot as object\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %&gt;% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %&gt;% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # view plot\n\n\n\n\n\n\n\n\nAhora alineamos el gráfico utilizando la función align_plots(), especificando la alineación horizontal y vertical (“hv”, también podría ser “h”, “v”, “none”). También especificamos la alineación de todos los ejes (top, bottom, left, y right) con “tblr”. La salida es de tipo list (2 elementos).\nLuego dibujamos los dos gráficos juntos usando ggdraw() (de cowplot) y referenciando las dos partes del objeto aligned_plots.\n\naligned_plots &lt;- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # align the two plots and save them as list\naligned_plotted &lt;- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # overlay them and save the visual plot\naligned_plotted                                                                # print the overlayed plots",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#packages-to-help-you",
    "href": "new_pages/ggplot_tips.es.html#packages-to-help-you",
    "title": "31  Consejos de ggplot",
    "section": "31.12 Paquetes para ayudarte",
    "text": "31.12 Paquetes para ayudarte\nHay algunos paquetes de R muy buenos diseñados específicamente para ayudarte a navegar por ggplot2:\n\nApuntar y clicar en ggplot2 con equisse\n“Este complemento te permite explorar interactivamente tus datos visualizándolos con el paquete ggplot2. Te permite dibujar gráficos de barras, curvas, gráficos de dispersión, histogramas, boxplot y objetos sf, y luego exportar el gráfico o recuperar el código para reproducir el gráfico.”\nInstala y luego lanza el complemento con el menú de RStudio o con esquisse::esquisser().\nVer la página de Github de esquisse\nDocumentación adicional",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#miscellaneous",
    "href": "new_pages/ggplot_tips.es.html#miscellaneous",
    "title": "31  Consejos de ggplot",
    "section": "31.13 Miscelánea",
    "text": "31.13 Miscelánea\n\nPantalla numérica\nPuedes desactivar la notación científica ejecutando este comando antes de representar gráficamente.\n\noptions(scipen=999)\n\nO aplicar number_format() del paquete scales a un valor o columna específicos, como se muestra a continuación.\nUtiliza las funciones del paquete scales para ajustar fácilmente la forma en que se muestran los números. Pueden aplicarse a las columnas del dataframe, pero se muestran en los números individuales a modo de ejemplo.\n\nscales::number(6.2e5)\n\n[1] \"620 000\"\n\nscales::number(1506800.62,  accuracy = 0.1,)\n\n[1] \"1 506 800.6\"\n\nscales::comma(1506800.62, accuracy = 0.01)\n\n[1] \"1,506,800.62\"\n\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")\n\n[1] \"1.506.800,62\"\n\nscales::percent(0.1)\n\n[1] \"10%\"\n\nscales::dollar(56)\n\n[1] \"$56\"\n\nscales::scientific(100000)\n\n[1] \"1e+05\"",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/ggplot_tips.es.html#resources-24",
    "href": "new_pages/ggplot_tips.es.html#resources-24",
    "title": "31  Consejos de ggplot",
    "section": "31.14 Recursos",
    "text": "31.14 Recursos\nInspiración galería de gráficos de ggplot\nDirectrices para la presentación de los datos de vigilancia del Centro Europeo para la Prevención y el Control de las Enfermedades (ecdc)\nUtilización de etiquetadoras para tiras de facetas y Etiquetadoras]\nAjuste del orden con factores\nfct_reorder\nfct_inorder\nCómo reordenar un boxplot\nReordenar una variable en ggplot2\nR for Data Science en español - Factores\nLeyendas\nAjustar el orden de las leyendas\nPies de foto\nAlineación de las leyendas\nEtiquetas\nggrepel\nCheetsheets\nTrazado bonito con ggplot2",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Consejos de ggplot</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html",
    "href": "new_pages/epicurves.es.html",
    "title": "32  Curvas epidémicas",
    "section": "",
    "text": "32.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#preparation-23",
    "href": "new_pages/epicurves.es.html#preparation-23",
    "title": "32  Curvas epidémicas",
    "section": "",
    "text": "Paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,          # importación/exportación de archivos\n  here,         # rutas relativas \n  lubridate,    # trabajar con fechas/semanas epid.\n  aweek,        # paquete alternativo para trabajar con fechas/semanas epid.\n  incidence2,   # epicurvas de datos linelist\n  i2extras,     # suplemento a incidence2\n  stringr,      # buscar y manipular cadenas de caracteres\n  forcats,      # trabajar con factores\n  RColorBrewer, # paletas de colores de colorbrewer2.org\n  tidyverse     # gestión de datos + gráficos ggplot2\n) \n\n\n\nImportar datos\nEn esta sección se utilizan dos conjuntos de datos de ejemplo:\n\nLinelist con casos individuales de una epidemia simulada\nRecuentos agregados por hospital de la misma epidemia simulada\n\nLos datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.\nLinelist con casos\nImportamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso a paso, consulta las instrucciones en la página Descargando el manual y los datos. Asumimos que el archivo está en el directorio de trabajo, por lo que no se especifican subcarpetas en esta ruta de archivo.\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas.\n\n\n\n\n\n\nRecuentos de casos agregados por hospital\nA efectos del manual, los datos de recuentos semanales agregados por hospital se crean a partir de linelist con el siguiente código.\n\n# importar los datos de los recuentos a R\ncount_data &lt;- linelist %&gt;% \n  group_by(hospital, date_hospitalisation) %&gt;% \n  summarize(n_cases = dplyr::n()) %&gt;% \n  filter(date_hospitalisation &gt; as.Date(\"2013-06-01\")) %&gt;% \n  ungroup()\n\nA continuación se muestran las primeras 50 filas:\n\n\n\n\n\n\n\n\nEstablecer parámetros\nPara la producción de un informe, es posible que desees establecer parámetros editables como la fecha para la que los datos sean actuales (la “data_date”). A continuación, puedes hacer referencia al objeto data_date en tu código cuando apliques filtros o en subtítulos dinámicos.\n\n## establece la fecha del informe\n## nota: se puede establecer en Sys.Date() para la fecha actual\ndata_date &lt;- as.Date(\"2015-05-15\")\n\n\n\nVerificar las fechas\nVerifica que cada columna de fecha relevante es de tipo Date y tiene un rango de valores apropiado. Puedes hacerlo simplemente utilizando hist() para histogramas, o range() con na.rm=TRUE, o con ggplot() como se indica a continuación.\n\n# comprobar el intervalo de fechas de inicio\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#epicurves-with-ggplot2",
    "href": "new_pages/epicurves.es.html#epicurves-with-ggplot2",
    "title": "32  Curvas epidémicas",
    "section": "32.2 Curvas epidémicas con ggplot2",
    "text": "32.2 Curvas epidémicas con ggplot2\nEl uso de ggplot() para construir tu curva epidémica permite más flexibilidad y personalización, pero requiere más esfuerzo y comprensión de cómo funciona ggplot().\nA diferencia de lo que ocurre con el paquete incidence2, hay que controlar manualmente la agregación de los casos por tiempo (en semanas, meses, etc.) y los intervalos de las etiquetas en el eje de fechas. Esto debe gestionarse cuidadosamente.\nEstos ejemplos utilizan un subconjunto de los datos de linelist: sólo los casos del Hospital Central.\n\ncentral_data &lt;- linelist %&gt;% \n  filter(hospital == \"Central Hospital\")\n\nPara producir una curva epidémica con ggplot() hay tres elementos principales:\n\nUn histograma, con los casos de la lista de líneas agregados en “bins” distinguidos por puntos específicos de “ruptura”.\n\nEscalas para los ejes y sus etiquetas\n\nTemas para la apariencia del gráfico, incluyendo títulos, etiquetas, subtítulos, etc.\n\n\nEspecificaciones de las barras\nAquí mostramos cómo especificar cómo se agregarán los casos en los intervalos del histograma (“barras”). Es importante reconocer que la agregación de los casos en los intervalos del histograma no son necesariamente los mismos intervalos que las fechas que aparecerán en el eje-x.\nA continuación se muestra el código más sencillo para producir curvas epidémicas diarias y semanales.\nEn el comando general ggplot() se proporciona el conjunto de datos en data =. Sobre esta base, se añade la geometría de un histograma con un +. Dentro de geom_histogram(), mapeamos la estética de tal manera que la columna date_onset se mapea al eje-x. También dentro de geom_histogram() pero no dentro de aes() establecemos la anchura de las barras del histograma con binwidth =, en días. Si esta sintaxis de ggplot2 es confusa, revisa la página sobre Conceptos básicos de ggplot.\nPRECAUCIÓN: El trazado de casos semanales mediante el uso de binwidth = 7 inicia la primera barra de 7 días en el primer caso, ¡que podría ser cualquier día de la semana! Para crear semanas específicas, véase la sección siguiente.\n\n# diariamente\nggplot(data = central_data) +          # establecer datos\n  geom_histogram(                      # añadir histograma\n    mapping = aes(x = date_onset),     # asignar la columna de fecha al eje-x\n    binwidth = 1)+                     # casos agrupados por 1 día\n  labs(title = \"Central Hospital - Daily\")                # título\n\n# semanalmente\nggplot(data = central_data) +          # establecer datos \n  geom_histogram(                      # añadir histograma\n      mapping = aes(x = date_onset),   # asignar la columna de fecha al eje-x\n      binwidth = 7)+                   # casos agrupados cada 7 días, empezando por el primer caso (!)\n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # título\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservamos que el primer caso de este conjunto de datos del Hospital Central tuvo un inicio de síntomas el:\n\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")\n\n[1] \"Thursday 01 May, 2014\"\n\n\nPara especificar manualmente las pausas del histograma, no utilices el argumento binwidth =, y en su lugar suministra un vector de fechas a breaks =.\nCrea el vector de fechas con la función seq.Date() de R base. Esta función espera argumentos to =, from =, y by =. Por ejemplo, el comando siguiente devuelve fechas mensuales que comienzan en el 15 de enero y terminan en el 28 de junio.\n\nmonthly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # imprime\n\n [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\"\n [6] \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\"\n[11] \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\"\n[16] \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n\n\nEste vector puede proporcionarse a geom_histogram() como breaks =:\n\n# mensualmente \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # proporciona el vector predefinido de rupturas                   \n  labs(title = \"Monthly case bins\")   # título\n\n\n\n\n\n\n\n\nUna secuencia simple de fechas semanales puede ser devuelta estableciendo by = \"week\". Por ejemplo:\n\nweekly_breaks &lt;- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n\nUna alternativa a la provisión de fechas específicas de inicio y fin es escribir un código dinámico para que los intervalos semanales comiencen el lunes anterior al primer caso. Utilizaremos estos vectores de fechas a lo largo de los ejemplos siguientes.\n\n# Secuencia de fechas semanales del lunes para el HOSPITAL CENTRAL\nweekly_breaks_central &lt;- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # lunes anterior al primer caso\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lunes posterior al último caso\n  by   = \"week\")\n\nDescompongamos el código anterior, que es bastante desalentador:\n\nEl valor “from” (fecha más temprana) se crea de la siguiente manera: el valor mínimo de fecha (min() con na.rm=TRUE) en la columna date_onset se introduce en floor_date() del paquete lubridate. floor_date() ajustado a “week” devuelve la fecha de inicio de la “semana” de esos casos, dado que el día de inicio de cada semana es un lunes (week_start = 1).\nAsimismo, el valor “to” (fecha final) se crea utilizando la función inversa ceiling_date() para devolver el lunes posterior al último caso.\nEl argumento “by” de seq.Date() puede establecerse en cualquier número de días, semanas o meses.\nUtiliza week_start = 7 para las semanas de domingo\n\nComo vamos a utilizar estos vectores de fechas a lo largo de esta página, también definimos uno para todo el brote (el anterior es sólo para el Hospital Central).\n\n# Secuencia para todo el brote\nweekly_breaks_all &lt;- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # lunes anterior al primer caso\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # lunes posterior al último caso\n  by   = \"week\")\n\nEstas salidas de seq.Date() pueden utilizarse para crear los saltos de las casillas del histograma, pero también los saltos de las etiquetas de fecha, que pueden ser independientes de las casillas. Lea más sobre las etiquetas de fecha en secciones posteriores.\nCONSEJO: Para un comando ggplot() más sencillo, guarda los saltos de cubo y los saltos de etiqueta de fecha como vectores con nombre por adelantado, y simplemente proporciona sus nombres a breaks =..\n\n\nEjemplo de curva epidémica semanal\nA continuación se muestra un código de ejemplo detallado para producir curvas epidémicas semanales para las semanas del lunes, con barras alineadas, etiquetas de fecha y líneas de cuadrícula verticales. Esta sección es para el usuario que necesita el código rápidamente. Para entender cada aspecto (temas, etiquetas de fecha, etc.) en profundidad, continúa con las secciones siguientes. Es importante tener en cuenta:\n\nLas pausas del histograma se definen con seq.Date(), como se ha explicado anteriormente, para comenzar el lunes anterior al caso más antiguo y terminar el lunes posterior al último caso\nEl intervalo de las etiquetas de fecha se especifica mediante date_breaks = dentro de scale_x_date()\nEl intervalo de líneas verticales menores entre etiquetas de fecha se especifica en date_minor_breaks =\nexpand = c(0,0) en los ejes x e y elimina el exceso de espacio a cada lado de los ejes, lo que también asegura que las etiquetas de fecha comiencen desde la primera barra.\n\n\n# ALINEACIÓN TOTAL DE LA SEMANA DEL LUNES\n#########################################\n# Definir secuencia de rupturas semanales\nweekly_breaks_central &lt;- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # lunes anterior al primer caso\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lunes posterior al último caso\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # crear histograma: especificar puntos de ruptura: comienza el lunes anterior al primer caso, finaliza el lunes posterior al último caso\n  geom_histogram(\n    \n    # estética del mapeo\n    mapping = aes(x = date_onset),  # columna de fecha asignada al eje-x\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # rupturas del histograma definidas previamente\n    \n    # Barras\n    color = \"darkblue\",     # color de las líneas alrededor de las barras\n    fill = \"lightblue\"      # color del relleno de las barras\n  )+ \n    \n  # Etiquetas del eje-x\n  scale_x_date(\n    expand            = c(0,0),           # elimina el exceso de espacio del eje-x antes y después de las barras de casos\n    date_breaks       = \"4 weeks\",        # las etiquetas de fecha y las cuadrículas verticales mayores aparecen cada 3 semanas de lunes\n    date_minor_breaks = \"week\",           # las líneas verticales menores aparecen cada semana de lunes\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # formato de las etiquetas de fecha\n  \n  # eje-y\n  scale_y_continuous(\n    expand = c(0,0))+             # elimina el exceso de espacio del eje-y por debajo de 0 (alinea el histograma con el eje-x)\n  \n  # temas estéticos\n  theme_minimal()+                # simplifica el fondo del gráfico\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # texto a la izquierda\n                                face = \"italic\"), # y en cursiva\n    axis.title = element_text(face = \"bold\"))+    # títulos de los ejes en negrita\n  \n  # etiquetas con texto dinámico\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\n\nSemanas dominicales\nPara conseguir el gráfico anterior para las semanas desde los domingos son necesarias algunas modificaciones, ya que los date_breaks = \"weeks\" sólo funcionan para las semanas de los lunes.\n\nLos puntos de ruptura de las franjas del histograma deben fijarse en los domingos (week_start = 7)\nDentro de scale_x_date(), los saltos de fecha similares deben proporcionarse a breaks = y minor_breaks = para asegurar que las etiquetas de fecha y las líneas verticales de la cuadrícula se alineen los domingos.\n\nPor ejemplo, el comando scale_x_date() para las semanas del domingo podría tener este aspecto:\n\nscale_x_date(\n    expand = c(0,0),\n    \n     # especificar el intervalo de las etiquetas de fecha y las principales Cuadrícula\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # domingo anterior al primer caso\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # domingo posterior al último caso\n      by   = \"4 weeks\"),\n    \n    # especificar el intervalo de la Cuadrícula vertical menor \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # domingo anterior al primer caso\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # domingo posterior al último caso\n      by   = \"week\"),\n   \n    # formato de etiqueta de fecha\n    label = scales::label_date_short()) # automatic label formatting\n\n\n\n\nAgrupar/colorear por valor\nLas barras del histograma pueden colorearse por grupos y “apilarse”. Para designar la columna de agrupación, haz los siguientes cambios. Consulta la página de Conceptos básicos de ggplot para más detalles.\n\nDentro del mapeo estético del histograma aes(), asigna el nombre de la columna a los argumentos group = y fill =\nElimina cualquier argumento fill = fuera de aes(), ya que anulará el de dentro\nLos argumentos dentro de aes() se aplicarán por grupo, mientras que los de fuera se aplicarán a todas las barras (por ejemplo, es posible que quieras color = fuera, para que cada barra tenga el mismo borde)\n\nEste es el aspecto que tendría el comando aes() para agrupar y colorear las barras por gender:\n\naes(x = date_onset, group = gender, fill = gender)\n\nAquí se aplica:\n\nggplot(data = linelist) +     # empieza con linelist (muchos hospitales)\n  \n  # realizar el histograma: especifica los puntos de corte: empieza el lunes anterior al primer caso, termina el lunes posterior al último caso\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # agrupa los datos por hospital\n      fill = hospital),       # relleno de las barras (color interior) por hospital\n    \n    # las saltos son las semanas de los lunes\n    breaks = weekly_breaks_all,   # secuencia de saltos de semanas de lunes para todo el brote, definidos en el código anterior       \n    \n    # Color alrededor de las barras\n    color = \"black\")\n\n\n\n\n\n\n\n\n\n\nAjustar los colores\n\nPara establecer manualmente el relleno de cada grupo, utiliza scale_fill_manual() (nota: scale_color_manual() es diferente).\n\nUtiliza el argumento values = para aplicar un vector de colores.\nUtiliza na.value = para especificar un color para los valores NA.\nUtiliza el argumento labels = para cambiar el texto de los elementos de la leyenda. Para estar seguro, proporciónalo como un vector, como c(\"old\" = \"new\", \"old\" = \"new\") o ajusta los valores en los propios datos.\nUtiliza name = para dar un título adecuado a la leyenda\n\nConsulta la página sobre Conceptos básicos de ggplot para obtener más información sobre escalas y paletas de colores.\n\n\nggplot(data = linelist)+           # empieza con linelist (muchos hospitales)\n  \n  # realizar el histograma\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # casos agrupados por hospital\n        fill = hospital),          # relleno de las barras por hospital\n    \n    # saltos\n    breaks = weekly_breaks_all,        # secuencia de saltos de semanas de lunes, definidos en el código anterior\n    \n    # Color alrededor de las barras\n    color = \"black\")+              # color del borde de cada barra\n  \n  # especificación manual de colores\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # especifica los colores de relleno (valores) - ¡atención al orden!\n\n\n\n\n\n\n\n\n\n\nAjustar el orden de los niveles\nEl orden en que se apilan las barras agrupadas se ajusta mejor clasificando la columna de agrupación como tipo Factor. A continuación, puedes designar el orden de los niveles de los factores (y sus etiquetas de visualización). Consulta la página sobre Factores o consejos de ggplot para obtener más detalles.\nAntes de realizar el gráfico, utiliza la función fct_relevel() del paquete forcats para convertir la columna de agrupación en de tipo factor y ajustar manualmente el orden de los niveles, como se detalla en la página sobre Factores.\n\n# carga el paquete forcats para trabajar con factores\npacman::p_load(forcats)\n\n\n# Definir nuevo conjunto de datos con hospital como factor\nplot_data &lt;- linelist %&gt;% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convierte a factor y establece \"Missing\" y \"Other\" como niveles superiores para aparecer en la curvaepi\n\nlevels(plot_data$hospital) # imprime los niveles en orden\n\n[1] \"Missing\"                             \n[2] \"Other\"                               \n[3] \"Central Hospital\"                    \n[4] \"Military Hospital\"                   \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\nEn el siguiente gráfico, las únicas diferencias con respecto al anterior es que la columna hospital se ha consolidado como en el caso anterior, y utilizamos guides() para invertir el orden de la leyenda, de modo que “Missing” se encuentra en la parte inferior de la leyenda.\n\nggplot(plot_data) +                     # Utiliza el NUEVO conjunto de datos con el hospital como factor reordenado\n  \n  # realizar el histograma\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # casos agrupados por hospital\n        fill = hospital),               # relleno de las barras por hospital\n    \n    breaks = weekly_breaks_all,         # secuencia de pausas de semanas de lunes para todo el brote, definidas en la parte superior de la sección ggplot\n    \n    color = \"black\")+                   # color del borde de cada barra\n    \n  # Etiquetas del eje-x\n  scale_x_date(\n    expand            = c(0,0),         # elimina el exceso de espacio del eje-x antes y después de las barras de casos\n    date_breaks       = \"3 weeks\",      # las etiquetas aparecen cada 3 semanas de lunes\n    date_minor_breaks = \"week\",         # las líneas verticales aparecen cada semana de lunes\n    label = scales::label_date_short())+ # efficient date labels\n  \n  # eje-y\n  scale_y_continuous(\n    expand = c(0,0))+                   # elimina el exceso de espacio del eje-y por debajo de 0\n  \n  # especificación manual de colores, ¡atención al orden!\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # temas de estética\n  theme_minimal()+                      # simplificar el fondo del gráfico\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # texto en cursiva a la izquierda\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # títulos de los ejes en negrita\n  \n  # etiquetas\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")\n\n\n\n\n\n\n\n\nCONSEJO: Para invertir solamente el orden de la leyenda, añade este comando ggplot2: guides(fill = guide_legend(reverse = TRUE)).\n\n\nAjustar la leyenda\nLee más sobre las leyendas y las escalas en la página Consejos de ggplot. Aquí hay algunos puntos destacados:\n\nEdita el título de la leyenda, ya sea en la función de escala o con labs(fill = \"Título de la leyenda\") (si estás usando color = estético, entonces usa labs(color = \"\"))\ntheme(legend.title = element_blank()) para no tener título de leyenda\ntheme(legend.position = \"top\") (“bottom”, “left”, “right”, o “none” para eliminar la leyenda)\ntheme(legend.direction = \"horizontal\") leyenda horizontal\nguides(fill = guide_legend(reverse = TRUE)) para invertir el orden de la leyenda\n\n\n\nBarras de lado a lado\nLa visualización lado a lado de las barras de grupo (en lugar de apiladas) se especifica dentro de geom_histogram() con position = \"dodge\" colocado fuera de aes().\nSi hay más de dos grupos de valores, éstos pueden resultar difíciles de leer. Considera la posibilidad de utilizar un gráfico facetado (múltiples pequeños). Para mejorar la legibilidad en este ejemplo, se han eliminado los valores de género que faltan.\n\nggplot(central_data %&gt;% drop_na(gender))+   # comienza con los casos del Hospital Central eliminando el género faltante\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # casos agrupados por género\n          fill = gender),         # barras rellenas por género\n        \n        # cortes del histograma\n        breaks = weekly_breaks_central,   # secuencia de fechas semanales para el brote del Central - definida en la parte superior de la sección ggplot\n        \n        color = \"black\",          # color del borde de la barra\n        \n        position = \"dodge\")+      # barras LADO A LADO\n                      \n  \n  # Las etiquetas en el eje-x\n  scale_x_date(expand            = c(0,0),         # elimina el exceso de espacio del eje-x antes y después de las barras de casos\n               date_breaks       = \"3 weeks\",      # las etiquetas aparecen cada 3 semanas de lunes\n               date_minor_breaks = \"week\",         # las líneas verticales aparecen cada semana de lunes\n               label = scales::label_date_short()) + # efficient label formatting\n  \n  # eje-y\n  scale_y_continuous(expand = c(0,0))+             # elimina el exceso de espacio del eje-y por debajo de 0\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # especificación manual de colores, ¡atención al orden!\n                    na.value = \"grey\" )+     \n\n  # temas de estética\n  theme_minimal()+                                               # un conjunto de temas para simplificar el gráfico\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # texto a la izquierda en cursiva\n        axis.title = element_text(face = \"bold\"))+               # títulos de los ejes en negrita\n  \n  # etiquetas\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # proporciona un nuevo título para la leyenda\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")\n\n\n\n\n\n\n\n\n\n\nLímites del eje\nHay dos maneras de limitar la extensión de los valores del eje.\nPor lo general, la forma preferida es utilizar el comando coord_cartesian(), que acepta xlim = c(min, max) y ylim = c(min, max) (donde proporcionas los valores mínimos y máximos). Esto actúa como un “zoom” sin eliminar realmente ningún dato, lo que es importante para las estadísticas y las medidas de resumen.\nAlternativamente, puedes establecer valores de fecha máximos y mínimos utilizando limits = c() dentro de scale_x_date(). Por ejemplo:\n\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # fija una fecha mínima pero deja abierta la máxima.  \n\nAsimismo, si deseas que el eje-x se extienda hasta una fecha concreta (por ejemplo, la fecha actual), aunque no se hayan notificado nuevos casos, puedes utilizar\n\nscale_x_date(limits = c(NA, Sys.Date()) # Asegura que el eje de fecha se extenderá hasta la fecha actual  \n\nPELIGRO: Ten cuidado al establecer los cortes o límites de la escala del eje-y (por ejemplo, de 0 a 30 por 5: seq(0, 30, 5)). Tales números estáticos pueden cortar tu gráfica demasiado si los datos cambian para superar el límite!\n\n\nEjes de fecha etiquetas/cuadrículas\nCONSEJO: Recuerda que las etiquetas de los ejes de fecha son independientes de la agregación de los datos en barras, pero visualmente puede ser importante alinear las franjas, las etiquetas de fecha y las líneas verticales de la cuadrícula.\nPara modificar las etiquetas de fecha y las líneas de la cuadrícula, utiliza scale_x_date() de una de estas maneras:\n\nSi los intervalos de tu histograma son días, semanas de lunes, meses o años:\n\nUtiliza date_breaks = para especificar el intervalo de las etiquetas y las líneas principales de la cuadrícula (por ejemplo, “day”, “week”, “3 weeks”, “month”, o “year”)\nUtiliza date_minor_breaks = para especificar el intervalo de las líneas verticales menores (entre las etiquetas de fecha)\nAñade expand = c(0,0) para comenzar las etiquetas en la primera barra\nUsa date_labels = para especificar el formato de las etiquetas de fecha - mira la página de trabajar con fechas para consejos (usa \\n para una nueva línea)\n\nSi las franjas de tu histograma son semanas de domingo:\n\nUsa breaks = y minor_breaks = proporcionando una secuencia de saltos de fecha para cada una\nPuedes seguir utilizando date_labels = y expand = para formatear, como se ha descrito anteriormente\n\n\nAlgunas notas:\n\nConsulta la sección de apertura de ggplot para obtener instrucciones sobre cómo crear una secuencia de fechas utilizando seq.Date().\nConsulta esta página o la página Trabajar con fechas para obtener consejos sobre la creación de etiquetas con fechas.\n\n\nDemostraciones\nA continuación se hace una demostración de gráficos en los que los intervalos y las etiquetas de los gráficos/líneas de la cuadrícula están alineados y no alineados:\n\n# Intervalos de 7 días + etiquetas de lunes\n###########################################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # intervalos de 7 días con inicio en el primer caso\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),               # elimina el exceso de espacio bajo el eje-x y después de las barras de casos\n    date_breaks = \"3 weeks\",       # lunes cada 3 semanas\n    date_minor_breaks = \"week\",    # semanas de lunes\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # elimina el espacio sobrante bajo el eje-x y alinea\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# intervalos de 7 días + Meses\n##############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                  # elimina el exceso de espacio bajo el eje-x y después de las barras de casos\n    date_breaks = \"months\",           # 1º de mes\n    date_minor_breaks = \"week\",       # semanas de lunes\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # elimina el espacio sobrante bajo el eje-x y alinea\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# ALINEACIÓN TOTAL DEL LUNES: especificar que los saltos manuales de las cajas sean los lunes\n#############################################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # los cortes del histograma se establecen en 7 días a partir del lunes anterior al primer caso\n    breaks = weekly_breaks_central,    # definido anteriormente en esta página\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # elimina el espacio sobrante antes y después de las barras de casos\n    date_breaks = \"4 weeks\",           # Lunes cada 4 semanas\n    date_minor_breaks = \"week\",        # semanas de lunes \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # elimina el espacio sobrante bajo el eje-x y alinea\n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# ALINEACIÓN TOTAL DE LUNES CON ETIQUETAS DE MESES:\n###################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # los cortes del histograma se establecen en 7 días a partir del lunes anterior al primer caso\n    breaks = weekly_breaks_central,            # definido anteriormente en esta página\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # elimina el exceso de espacio en el eje-x antes y después de las barras de casos\n    date_breaks = \"months\",            # Lunes cada 4 semanas\n    date_minor_breaks = \"week\",        # semanas de lunes \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # elimina el espacio sobrante bajo el eje-x y alinea\n  \n  theme(panel.grid.major = element_blank())+  # Elimina las cuadrículas principales ( coinciden con el día 1 de cada mes)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# ALINEACIÓN TOTAL DEL DOMINGO: especificar los puntos de corte manualmente Y las etiquetas que serán domingos\n##############################################################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # cortes del histograma fijados en 7 días a partir del domingo anterior al primer caso\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # rupturas de etiquetas de fecha y cuadrículas principales establecidas cada 3 semanas a partir del domingo anterior al primer caso\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # Cuadrículas menores fijadas en semanal a partir del domingo anterior al primer caso\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # elimina el espacio sobrante bajo el eje-x y ajusta\n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatos agregados\nA menudo, en lugar de un listado, se comienza con recuentos agregados de instalaciones, distritos, etc. Se puede hacer una curva epidémica con ggplot() pero el código será ligeramente diferente. Esta sección utilizará los datos de count_data que fue importado anteriormente, en la sección de preparación de datos. Este conjunto de datos es linelist agregado a los recuentos de día-hospital. A continuación se muestran las primeras 50 filas.\n\n\n\n\n\n\n\nRepresentar recuentos diarios\nPodemos trazar una curva epidémica diaria a partir de estos recuentos diarios. Aquí están las diferencias con el código:\n\nDentro del mapeo estético aes(), especifica y = como columna de recuento (en este caso, el nombre de la columna es n_cases)\nAñadir el argumento stat = \"identity\" dentro de geom_histogram(), que especifica que la altura de la barra debe ser el valor y = y no el número de filas, como es el valor por defecto\nAñade el argumento width = para evitar las líneas blancas verticales entre las barras. Para los datos diarios, establece el valor 1. Para los datos semanales, escribe 7. Para los datos de recuento mensual, las líneas blancas son un problema (cada mes tiene un número diferente de días) - considera la posibilidad de transformar el eje x en un factor categórico ordenado (meses) y utilizar geom_col().\n\n\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # para recuentos diarios, establece anchura = 1 para evitar espacios en blanco entre barras\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")\n\n\n\n\n\n\n\n\n\n\nrepresentar recuentos semanales\nSi tus datos ya son recuentos de casos por semana, podrían parecerse a este conjunto de datos (llamado count_data_weekly):\nA continuación se muestran las primeras 50 filas de count_data_weekly. Puedes ver que los recuentos se han agregado en semanas. Cada semana se muestra por el primer día de la semana (lunes por defecto).\n\n\n\n\n\n\nAhora trace de manera que x =la columna epiweek. Recuerda añadir y = la columna de recuentos al mapeo estético, y añadir stat = \"identity\" como se ha explicado anteriormente.\n\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # el eje-x es epiweek (como tipo Fecha)\n      y = n_cases_weekly,    # altura del eje-y en los recuentos semanales de casos\n      group = hospital,      # agrupa las barras y colorea por hospital\n      fill = hospital),\n    stat = \"identity\")+      # esto también es necesario al dibujar datos de recuento\n     \n  # etiquetas para el eje-x\n  scale_x_date(\n    date_breaks = \"2 months\",      # etiquetas cada 2 meses \n    date_minor_breaks = \"1 month\", # cuadrículas cada mes\n    label = scales::label_date_short())+ # label formatting\n     \n  # Elige la paleta de colores (utiliza el paquete RColorBrewer)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")\n\n\n\n\n\n\n\n\n\n\n\nMedias móviles\nConsulta la página sobre medias móviles para obtener una descripción detallada y varias opciones. A continuación se muestra una opción para calcular medias móviles con el paquete slider. En este enfoque, la media móvil se calcula antes de representarla:\n\nAgrega los datos en recuentos según sea necesario (diario, semanal, etc.) (véase la página de Agrupar datos)\nCrea una nueva columna para contener la media móvil, creada con slide_index() del paquete slider\nDibuja la media móvil como una geom_line() encima (después) del histograma de la curva epidémica\n\nEs muy útil la viñeta en línea del paquete slider\n\n# cargar paquete\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# crea un conjunto de datos con los recuentos diarios y la media móvil de 7 días\n################################################################################\nll_counts_7day &lt;- linelist %&gt;%    # comienza con linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %&gt;%   # nombra la nueva columna con los recuentos como \"new_cases\"\n  drop_na(date_onset) %&gt;%                     # elimina los casos en los que falta date_onset\n  \n  ## calcular el número medio de casos en una ventana de 7 días\n  mutate(\n    avg_7day = slider::slide_index(    # crea una nueva columna\n      new_cases,                       # calcula basándose en el valor de la columna new_cases\n      .i = date_onset,                 # el índice es date_onset col, por lo que las fechas no presentes se incluyen en la ventana \n      .f = ~mean(.x, na.rm = TRUE),    # la función es mean() con los valores faltantes eliminados\n      .before = 6,                     # la ventana es el día y los 6 días anteriores\n      .complete = FALSE),              # debe ser FALSE para que unlist() funcione en el siguiente paso\n    avg_7day = unlist(avg_7day))       # convierte el tipo lista en tipo numérico\n\n\n# realizar el gráfico\n#####################\nggplot(data = ll_counts_7day) +  # comienza con el nuevo conjunto de datos definido anteriormente \n    geom_histogram(              # crea el histograma de la curva epidemiológica\n      mapping = aes(\n        x = date_onset,          # columna de fecha como eje-x\n        y = new_cases),          # la altura es el número de casos nuevos diarios\n        stat = \"identity\",       # la altura es el valor-y\n        fill=\"#92a8d1\",          # color frío para las barras\n        colour = \"#92a8d1\",      # mismo color para el borde de las barras\n        )+ \n    geom_line(                   # crea la linea de la media móvil\n      mapping = aes(\n        x = date_onset,          # columna de fecha para el eje-x\n        y = avg_7day,            # valor-y establecido con la columna de media móvil\n        lty = \"7-day \\nrolling avg\"), # nombre de la línea en la leyenda\n      color=\"red\",               # color de la línea\n      size = 1) +                # anchura de la línea\n    scale_x_date(                # escala de fechas\n      date_breaks = \"1 month\",\n      label = scales::label_date_short(), # label formatting\n      expand = c(0,0)) +\n    scale_y_continuous(          # escala del eje-y\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # elimina el título de la leyenda\n\n\n\n\n\n\n\n\n\n\nFacetas/pequeñas múltiples\nAl igual que con otros ggplots, puedes crear gráficos facetados (“pequeños múltiples”). Como se explica en la página Consejos de ggplot de este manual, puedes utilizar facet_wrap() o facet_grid(). Aquí lo mostramos con facet_wrap(). Para las curvas epidémicas, facet_wrap() es típicamente más fácil, ya que es probable que sólo necesites facetar una columna.\nLa sintaxis general es facet_wrap(rows ~ cols), donde a la izquierda de la tilde (~) está el nombre de una columna que se extiende a través de las “filas” del gráfico facetado, y a la derecha de la tilde está el nombre de una columna que se extiende a través de las “columnas” del gráfico facetado. Lo más sencillo es utilizar un nombre de columna, a la derecha de la tilde: facet_wrap(~age_cat).\nEjes libres Tendrás que decidir si las escalas de los ejes para cada faceta son “fijas” (por defecto), o “libres” (lo que significa que cambiarán en función de los datos dentro de la faceta). Haz esto con el argumento scales = dentro de facet_wrap() especificando “free_x” o “free_y”, o “free”.\nNúmero de columnas y filas de las facetas Se puede especificar con ncol = y nrow = dentro de facet_wrap().\nOrden de los paneles Para cambiar el orden de aparición, cambia el orden de los niveles de la columna de factores utilizada para crear las facetas.\nEstética El tamaño y tipo de la fuente, el color de la franja, etc, se pueden modificar mediante theme() con argumentos como:\n\nstrip.text = element_text() (size, colour, face, angle..(tamaño, color, cara, ángulo)\nstrip.background = element_rect() (e.g. element_rect(fill=“grey”))\n\nstrip.position = (posición “bottom”, “top”, “left”, o “right” (Abajo, arriba, izquierda o derecha))\n\nEtiquetas de banda Las etiquetas de los gráficos de facetas pueden modificarse a través de las “etiquetas” de la columna como factor, o mediante el uso de un “etiquetador”.\nHaz un etiquetador como este, usando la función as_labeller() de ggplot2. A continuación, proporciona el argumento labeller = en facet_wrap() como se muestra a continuación.\n\nmy_labels &lt;- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n\nUn ejemplo de gráfico facetado - facetado por la columna age_cat.\n\n# crear el gráfico\n##################\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # los argumentos dentro de aes() se aplican por grupo\n      \n    color = \"black\",      # los argumentos fuera de aes() se aplican a todos los datos\n        \n    # cortes del histograma\n    breaks = weekly_breaks_central)+  # vector de fechas predefinido (véase más arriba en esta página)\n                      \n  # Las etiquetas del eje-x\n  scale_x_date(\n    expand            = c(0,0),         # elimina el exceso de espacio del eje-x debajo y después de las barras de casos\n    date_breaks       = \"2 months\",     # elimina el exceso de espacio del eje-x debajo y después de las barras de casos\n    date_minor_breaks = \"1 month\",      # las líneas verticales aparecen cada 1 mes \n    label = scales::label_date_short())+ # label formatting\n  \n  # eje-y\n  scale_y_continuous(expand = c(0,0))+                       # elimina el exceso de espacio en el eje y entre la parte inferior de las barras y las etiquetas\n  \n  # temas estéticos\n  theme_minimal()+                                           # un conjunto de temas para simplificar el gráfico\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # leyenda a la izquierda en cursiva\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # títulos de los ejes en negrita\n  \n  # crear facetas\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # Etiquetas\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # proporciona un nuevo título para la leyenda\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\nConsulta este enlace para obtener más información sobre las etiquetadoras.\n\nConjunto de la Epidemia como fondo de la faceta\nPara mostrar el conjunto de la epidemia como fondo de cada faceta, añade la función gghighlight() con paréntesis vacíos al ggplot. Esto es del paquete gghighlight. Observa que el máximo del eje Y en todas las facetas se basa ahora en el pico de toda la epidemia. Hay más ejemplos de este paquete en la página Consejos de ggplot.\n\nggplot(central_data) + \n  \n  # curvaepi por grupo\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # los argumentos dentro de aes() se aplican por grupo\n    \n    color = \"black\",    # los argumentos fuera de aes() se aplican a todos los datos\n    \n    # cortes del histograma\n    breaks = weekly_breaks_central)+     # vector de fechas predefinido (véase la parte superior de la sección ggplot)                \n  \n  # añade gris epidémico de fondo a cada faceta\n  gghighlight::gghighlight()+\n  \n  # etiquetas en el eje-x\n  scale_x_date(\n    expand            = c(0,0),         # elimina el exceso de espacio en el eje-x debajo y después de las barras de casos\n    date_breaks       = \"2 months\",     # las etiquetas aparecen cada 2 meses\n    date_minor_breaks = \"1 month\",      # las líneas verticales aparecen cada 1 mes \n    label = scales::label_date_short())+ # label formatting\n  \n  # eje-y\n  scale_y_continuous(expand = c(0,0))+  # elimina el exceso de espacio del eje-y por debajo de 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # una serie de temas para simplificar el gráfico\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # ajustado a la izquierda en cursiva\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # títulos de los ejes en negrita\n  \n  # crear facetas\n  facet_wrap(\n    ~age_cat,                          # cada gráfico es un valor de age_cat\n    ncol = 4,                          # número de columnas\n    strip.position = \"top\",            # posición del título/tira de la faceta\n    labeller = my_labels)+             # etiquetado definido arriba\n  \n  # Etiquetas\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # proporciona un nuevo título para la leyenda\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))\n\n\n\n\n\n\n\n\n\n\nUna faceta con datos\nSi quieres tener una caja de facetas que contenga todos los datos, duplica todo el conjunto de datos y trata los duplicados como un solo valor de facetas. Una función de “ayuda” CreateAllFacet() a continuación puede ayudar con esto (gracias a esta entrada del blog). Cuando se ejecuta, el número de filas se duplica y habrá una nueva columna llamada facet en la que las filas duplicadas tendrán el valor “all”, y las filas originales tienen el valor original de la columna facet. Ahora sólo tienes que hacer la faceta con la columna facet.\nAquí está la función de ayuda. Ejecútala para que esté disponible para ti.\n\n# Definir la función de ayuda\nCreateAllFacet &lt;- function(df, col){\n     df$facet &lt;- df[[col]]\n     temp &lt;- df\n     temp$facet &lt;- \"all\"\n     merged &lt;-rbind(temp, df)\n     \n     # asegura que el valor de la faceta es un factor\n     merged[[col]] &lt;- as.factor(merged[[col]])\n     \n     return(merged)\n}\n\nAhora aplica la función de ayuda a los datos, en la columna age_cat:\n\n# Crea un conjunto de datos duplicado y con una nueva columna \"facet\" para mostrar \"todas\" las categorías de edad como otro nivel de faceta\ncentral_data2 &lt;- CreateAllFacet(central_data, col = \"age_cat\") %&gt;%\n  \n  # establecer niveles del factor\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `facet = fct_relevel(...)`.\nCaused by warning:\n! 1 unknown level in `f`: 70+\n\n# comprobar niveles\ntable(central_data2$facet, useNA = \"always\")\n\n\n  all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  &lt;NA&gt; \n  454    84    84    82    58    73    57     7     9 \n\n\nLos cambios más importantes en el comando ggplot() son:\n\nLos datos utilizados son ahora central_data2 (el doble de filas, con la nueva columna “facet”)\nLa etiquetadora tendrá que ser actualizada, si se utiliza\nOpcional: para conseguir facetas apiladas verticalmente: la columna de la faceta se mueve al lado de las filas de la ecuación y a la derecha se sustituye por “.” (facet_wrap(facet\\~.)), y ncol = 1. También puede ser necesario ajustar la anchura y la altura de la imagen png guardada (ver ggsave() en Conceptos básicos de ggplot).\n\n\nggplot(central_data2) + \n  \n  # curvas epidemiológicas actuales por grupo\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # los argumentos dentro de aes() se aplican por grupo\n        color = \"black\",    # los argumentos fuera de aes() se aplican a todos los datos\n        \n        # histogram breaks\n        breaks = weekly_breaks_central)+    # vector de fechas predefinido (véase la parte superior de la sección ggplot)\n                     \n  # Etiquetas del eje-x\n  scale_x_date(\n    expand            = c(0,0),         # elimina el exceso de espacio en el eje-x debajo y después de las barras de casos\n    date_breaks       = \"2 months\",     # las etiquetas aparecen cada 2 meses\n    date_minor_breaks = \"1 month\",      # las líneas verticales aparecen cada 1 mes \n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # eje-y\n  scale_y_continuous(expand = c(0,0))+  # elimina el exceso de espacio en el eje-y entre la parte inferior de las barras y las etiquetas\n  \n  # temas estéticos\n  theme_minimal()+                                           # un conjunto de temas para simplificar el gráfico\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # ajusta a la izquierda en cursiva\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # crear facetas\n  facet_wrap(facet~. ,                           # cada gráfico es un valor de faceta\n             ncol = 1)+            \n\n  # Etiquetas\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # proporcionar un nuevo título para la leyenda\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %&gt;% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#tentative-data",
    "href": "new_pages/epicurves.es.html#tentative-data",
    "title": "32  Curvas epidémicas",
    "section": "32.3 Datos provisionales",
    "text": "32.3 Datos provisionales\nLos datos más recientes que se muestran en las curvas epidémicas deben marcarse a menudo como provisionales, o sujetos a retrasos en los informes. Esto puede hacerse añadiendo una línea vertical y/o un rectángulo sobre un número determinado de días. Aquí hay dos opciones:\n\nUtiliza annotate():\n\nPara una línea utiliza annotate(geom = \"segment\"). Proporciona x, xend, y, e yend. Ajusta el tamaño, el tipo de línea (lty) y el color.\nPara un rectángulo utiliza annotate(geom = \"rect\"). Proporciona xmin/xmax/ymin/ymax. Ajusta el color y el alpha.\n\nAgrupar los datos por estado tentativo y colorear esas barras de forma diferente\n\nPRECAUCIÓN: Puedes intentar geom_rect() para dibujar un rectángulo, pero el ajuste de la transparencia no funciona en un contexto de listado. Esta función superpone un rectángulo para cada observación/fila!. Utiliza un alfa muy bajo (por ejemplo, 0,01), u otro enfoque. \n\nUso de annotate()\n\nDentro de annotate(geom = \"rect\"), los argumentos xmin y xmax deben tener entradas del tipo Date.\nTen en cuenta que, como estos datos se agregan en barras semanales, y la última barra se extiende hasta el lunes siguiente al último punto de datos, la región sombreada puede parecer que abarca 4 semanas\nEste es un ejemplo de annotate() en línea\n\n\nggplot(central_data) + \n  \n  # histograma\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # vector de fechas predefinido - véase la parte superior de la sección ggplot\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # escalas\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                   # elimina el exceso de espacio del eje-x debajo y después de las barras de casos\n    date_breaks = \"1 month\",           # 1º de mes\n    date_minor_breaks = \"1 month\",     # 1º de mes\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # etiquetas y tema\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # añadir un rectángulo rojo semitransparente a los datos provisionales\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # la nota debe estar incluida en as.Date()\n    xmax  = as.Date(Inf),                                          # la nota debe estar incluida en in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha fácil e intuitivo de ajustar usando annotate()\n    fill  = \"red\")+\n  \n  # añadir línea vertical negra sobre otras capas\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 días antes del último dato\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # la línea comienza en y = 0\n    yend  = Inf,       # línea hasta la parte superior del gráfico\n    size  = 2,         # tamaño de la línea\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\" (sólida, rayada)\n\n  # añadir texto en el rectángulo\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\n\n\n\n\n\n\n\n\nLa misma línea vertical negra se puede conseguir con el código de abajo, pero usando geom_vline() se pierde la capacidad de controlar la altura:\n\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")\n\n\n\nColor de las barras\nUn enfoque alternativo podría ser ajustar el color o la visualización de las propias barras de datos tentativos. Podrías crear una nueva columna en la etapa de preparación de los datos y utilizarla para agrupar los datos, de manera que el aes(fill = ) de los datos tentativos pueda tener un color o un alfa diferente al de las otras barras.\n\n# añadir columna\n############\nplot_data &lt;- central_data %&gt;% \n  mutate(tentative = case_when(\n    date_onset &gt;= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # provisional si es en los últimos 7 días\n    TRUE                                       ~ \"Reliable\")) # todos los demás se considerarán definitivos\n\n# Gráfico\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histograma\n  geom_histogram(\n    breaks = weekly_breaks_central,    # vector de datos predefinido, véase la parte superior de la página ggplot\n    color = \"black\") +\n\n   # escalas\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                   # elimina el exceso de espacio en el eje-x debajo y después de las barras de casose bars\n    date_breaks = \"3 weeks\",           # lunes cada 3 semanas\n    date_minor_breaks = \"week\",        # semanas de lunes \n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # etiquetas y tema\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # elimina el título de la leyenda",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#multi-level-date-labels",
    "href": "new_pages/epicurves.es.html#multi-level-date-labels",
    "title": "32  Curvas epidémicas",
    "section": "32.4 Etiquetas de fecha de varios niveles",
    "text": "32.4 Etiquetas de fecha de varios niveles\nSi deseas etiquetas de fecha de varios niveles (por ejemplo, mes y año) sin duplicar los niveles de etiquetas inferiores, considera uno de los enfoques siguientes:\nRecuerda - puedes utilizar herramientas como \\n dentro de los argumentos date_labels o labels para poner partes de cada etiqueta en una nueva línea inferior. Sin embargo, el código de abajo le ayuda a usar años o meses (por ejemplo) en una línea inferior y sólo una vez. Algunas notas sobre el código de abajo:\n\nLos recuentos de casos se agregan en semanas por motivos estéticos. Véase la página de Epicurves (sección de datos agregados) para más detalles.\nSe utiliza una línea geom_area() en lugar de un histograma, ya que el enfoque de facetas que se presenta a continuación no funciona bien con los histogramas.\n\nAgregar a los recuentos semanales\n\n# Crear conjunto de datos de recuentos de casos por semana\n##########################################################\ncentral_weekly &lt;- linelist %&gt;%\n  filter(hospital == \"Central Hospital\") %&gt;%   # filtra linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %&gt;%  \n  count(week) %&gt;%                              # resume el recuento semanal de casos\n  drop_na(week) %&gt;%                            # elimina los casos en los que falta onset_date\n  complete(                                    # completa todas las semanas sin casos notificados\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # convertir los nuevos valores NA en 0 casos\n\nHacer gráficos\n\n# gráfico con borde en la caja del año\n######################################\nggplot(central_weekly) +\n  geom_area(aes(x = week, y = n),    # crea una línea, especifica x e y\n            stat = \"identity\") +             # porque la altura de la línea es el número de casos\n  scale_x_date(date_labels=\"%b\",             # formato de etiqueta de fecha muestra el mes \n               date_breaks=\"month\",          # etiquetas de fecha el día 1 de cada mes\n               expand=c(0,0)) +              # elimina el espacio sobrante en cada extremoach end\n  scale_y_continuous(\n    expand  = c(0,0))+                       # elimina el espacio sobrante debajo del eje-x\n  facet_grid(~lubridate::year(week), # faceta sobre el año (de la columna de clase Date)\n             space=\"free_x\",                \n             scales=\"free_x\",                # los ejes-x se adaptan al rango de datos (no son \"fijos\")\n             switch=\"x\") +                   # etiquetas de facetas (año) en la parte inferior\n  theme_bw() +\n  theme(strip.placement = \"outside\",         # colocación de las etiquetas de las facetas\n        strip.background = element_rect(fill = NA, # las etiquetas de facetas sin relleno con borde gris\n                                        colour = \"grey50\"),\n        panel.spacing = unit(0, \"cm\"))+      # sin espacio entre paneles de facetas\n  labs(title = \"Nested year labels, grey label border\")\n\n\n\n\n\n\n\n# gráfico sin borde en la caja del año\n#######################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establecer x e y para todo el gráfico\n  geom_line(stat = \"identity\",              # crear línea, la altura de la línea es el número de casos\n            color = \"#69b3a2\") +            # color de la línea\n  geom_point(size=1, color=\"#69b3a2\") +     # crear puntos en los datos semanales\n  geom_area(fill = \"#69b3a2\",               # relleno del área bajo la línea\n            alpha = 0.4)+                   # relleno transparente\n  scale_x_date(date_labels=\"%b\",            # formato de etiqueta de fecha mostrar mes \n               date_breaks=\"month\",         # etiquetas de fecha el día 1 de cada mes\n               expand=c(0,0)) +             # elimina el espacio sobrante\n  scale_y_continuous(\n    expand  = c(0,0))+                      # elimina el espacio sobrante bajo el eje-x\n  facet_grid(~lubridate::year(week),        # faceta sobre el año (de la columna de clase Date)\n             space=\"free_x\",                \n             scales=\"free_x\",               # los ejes-x se adaptan al rango de datos (no son \"fijos\")\n             switch=\"x\") +                 # etiquetas de facetas (año) en la parte inferior\n  theme_bw() +\n  theme(strip.placement = \"outside\",                     # colocación de etiqueta de faceta\n          strip.background = element_blank(),            # sin fondo de etiqueta de faceta\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(colour=\"grey40\"),  # borde gris de la faceta PANEL\n          panel.spacing=unit(0,\"cm\"))+                   # sin espacio entre paneles de facetas\n  labs(title = \"Nested year labels - points, shaded, no label border\")\n\n\n\n\n\n\n\n\nLas técnicas anteriores fueron adaptadas de este y este post en stackoverflow.com.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#dual-axis",
    "href": "new_pages/epicurves.es.html#dual-axis",
    "title": "32  Curvas epidémicas",
    "section": "32.5 Doble eje",
    "text": "32.5 Doble eje\nAunque hay fuertes discusiones sobre la validez de los ejes duales dentro de la comunidad de visualización de datos, muchos supervisores de epi todavía quieren ver una curva epidémica o un gráfico similar con un porcentaje superpuesto con un segundo eje. Esto se discute más ampliamente en la página Consejos de ggplot, pero a continuación se muestra un ejemplo utilizando el método cowplot:\n\nSe hacen dos gráficos distintos y luego se combinan con el paquete cowplot.\nLos gráficos deben tener exactamente el mismo eje x (límites establecidos) o de lo contrario los datos y las etiquetas no se alinearán\nCada uno de ellos utiliza theme_cowplot() y uno de ellos tiene el eje-y desplazado a la derecha del gráfico\n\n\n# cargar paquete\npacman::p_load(cowplot)\n\n# Crea el primer gráfico, el histograma de la curvaepi\n######################################################\nplot_cases &lt;- linelist %&gt;% \n  \n  # representa casos por semana\n  ggplot()+\n  \n  # crea el histograma  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # intervalos semanales desde el lunes anterior al primer caso hasta el lunes posterior al último caso\n    breaks = weekly_breaks_all)+  # vector predefinido de fechas semanales (véase la parte superior de la sección ggplot)\n        \n  # especifica el principio y el final del eje de fechas para alinearlo con otros gráficos\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max de las rupturas predefinidas semanales del histograma\n  \n  # etiquetas\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# crea un segundo gráfico con el porcentaje de fallecidos por semana\n####################################################################\nplot_deaths &lt;- linelist %&gt;%                        # comienza con linelist\n  group_by(week = floor_date(date_onset, \"week\")) %&gt;%  # crea la columna semana\n  \n  # resume para obtener el porcentaje semanal de casos que fallecieron\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %&gt;% \n  \n  # comienza el gráfico\n  ggplot()+\n  \n  # línea de porcentaje semanal de fallecidos\n  geom_line(                                # crea la línea del porcentaje de fallecidos\n    mapping = aes(x = week, y = pct_died),  # especifica la altura-y como columna pct_died\n    stat = \"identity\",                      # establece la altura de la línea al valor de la columna pct_dead, no al número de filas (que es por defecto)\n    size = 2,\n    color = \"black\")+\n  \n  # Mismos límites del eje-fecha que el otro gráfico - alineación perfecta\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max de los cortes semanales predefinidos del histograma\n  \n  \n  # ajustes del eje-y\n  scale_y_continuous(                # ajusta el eje-y\n    breaks = seq(0,100, 10),         # establece los intervalos de ruptura del eje porcentual\n    limits = c(0, 100),              # establece la extensión del eje porcentual\n    position = \"right\")+             # mueve el eje porcentual a la derecha\n  \n  # etiqueta del eje-Y, sin etiqueta del eje-x\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # etiqueta del eje de porcentajes\n  \n  theme_cowplot()                   # añade esto para que los dos gráficos se fusionen bien\n\nAhora utiliza cowplot para superponer los dos gráficos. Se ha prestado atención a la alineación del eje-x, al lado del eje-y y al uso de theme_cowplot().\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#cumulative-incidence-1",
    "href": "new_pages/epicurves.es.html#cumulative-incidence-1",
    "title": "32  Curvas epidémicas",
    "section": "32.6 Incidencia acumulada",
    "text": "32.6 Incidencia acumulada\nNota: Si utilizas incidence2, consulta la sección sobre cómo puede producirse la incidencia acumulada con una función simple. Esta página abordará cómo calcular la incidencia acumulada y dibujarla con ggplot().\nSi se empieza con una lista de casos, crea una nueva columna que contenga el número acumulado de casos por día en un brote utilizando cumsum() de R base:\n\ncumulative_case_counts &lt;- linelist %&gt;% \n  count(date_onset) %&gt;%                # recuento de filas por día (devuelto en la columna \"n\")     \n  mutate(                         \n    cumulative_cases = cumsum(n)       # nueva columna del número acumulado de filas en cada fecha\n    )\n\nA continuación se muestran las 10 primeras filas:\n\n\n\n\n\n\nEsta columna acumulativa puede entonces ser dibujada contra date_onset, usando geom_line():\n\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n\n\n\n\n\n\n\n\nTambién se puede superponer a la curva epidémica, con doble eje utilizando el método cowplot descrito anteriormente y en la página Consejos de ggplot:\n\n# cargar paquete\npacman::p_load(cowplot)\n\n# Crea el primer gráfico, el histograma de la curvaepi\nplot_cases &lt;- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# crea un segundo gráfico de la línea de casos acumulados\nplot_cumulative &lt;- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\n\nAhora utiliza cowplot para superponer los dos gráficos. Se ha prestado atención a la alineación del eje-x, al lado del eje-y y al uso de theme_cowplot().\n\naligned_plots &lt;- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/epicurves.es.html#resources-25",
    "href": "new_pages/epicurves.es.html#resources-25",
    "title": "32  Curvas epidémicas",
    "section": "32.7 Recursos",
    "text": "32.7 Recursos",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Curvas epidémicas</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.es.html",
    "href": "new_pages/age_pyramid.es.html",
    "title": "33  Pirámides de población y escalas de Likert",
    "section": "",
    "text": "33.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pirámides de población y escalas de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.es.html#preparation-24",
    "href": "new_pages/age_pyramid.es.html#preparation-24",
    "title": "33  Pirámides de población y escalas de Likert",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de . Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(rio,       # para importar datos\n               here,      # para localizar archivos\ntidyverse,                # para limpiar, manejar y graficar los datos (incluye el paquete ggplot2)\n               apyramid,  # un paquete dedicado a crear pirámides de edad\n               janitor,   # tablas y limpieza de datos\n               stringr)   # trabajar con cadenas para títulos, subtítulos, etc.\n\n\n\nImportar datos\nPara empezar, importamos la lista de casos limpia de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - vea la página de importación y exportación para más detalles).\n\n# importar linelist de casos \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.\n\n\n\n\n\n\n\n\nLimpieza\nPara hacer una pirámide demográfica tradicional de edad/género, primero hay que limpiar los datos de la siguiente manera:\n\nDebe limpiarse la columna gender.\nDependiendo del método, la edad debe ser almacenada como un número o en una columna de categoría de edad.\n\nSi se utilizan categorías de edad, los valores de las columnas deben corregirse ordenados, ya sea por defecto alfanumérico o intencionadamente al convertirlo en de tipo factor.\nA continuación utilizamos tabyl() de janitor para inspeccionar las columnas gender y age_cat5.\n\nlinelist %&gt;% \n  tabyl(age_cat5, gender)\n\n age_cat5   f   m NA_\n      0-4 640 416  39\n      5-9 641 412  42\n    10-14 518 383  40\n    15-19 359 364  20\n    20-24 305 316  17\n    25-29 163 259  13\n    30-34 104 213   9\n    35-39  42 157   3\n    40-44  25 107   1\n    45-49   8  80   5\n    50-54   2  37   1\n    55-59   0  30   0\n    60-64   0  12   0\n    65-69   0  12   1\n    70-74   0   4   0\n    75-79   0   0   1\n    80-84   0   1   0\n      85+   0   0   0\n     &lt;NA&gt;   0   0  86\n\n\nTambién realizamos un histograma rápido de la columna age para asegurarnos de que está limpia y correctamente clasificada:\n\nhist(linelist$age)",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pirámides de población y escalas de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.es.html#apyramid-package",
    "href": "new_pages/age_pyramid.es.html#apyramid-package",
    "title": "33  Pirámides de población y escalas de Likert",
    "section": "33.2 paquete apyramid",
    "text": "33.2 paquete apyramid\nEl paquete apyramid es un producto del proyecto R4Epis. Puedes leer más sobre este paquete aquí. Te permite hacer rápidamente una pirámide de edad. Para situaciones más matizadas consulta, más abajo, la sección sobre el uso de ggplot(). Puedes leer más sobre el paquete apyramid en su página de ayuda introduciendo ?age_pyramid en la consola de R.\n\nDatos individualizados\nUtilizando el conjunto de datos de linelist limpio, podemos crear una pirámide de edad con un simple comando age_pyramid(). En este comando:\n\nEn el argumento data = se establece el dataframe linelist\nEn el argumento age_group = (para el eje Y) se establece la columna age categórica (entre comillas)\nEn el argumento split_by = (para el eje x) se establece la columna gender\n\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\n\n\n\n\n\n\n\n\nLa pirámide puede mostrarse con el porcentaje de todos los casos en el eje x, en lugar de los recuentos, incluyendo proportional = TRUE.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\n\n\n\n\n\n\n\n\nCuando se utiliza el paquete agepyramid, si la columna split_by es binaria (por ejemplo, male/female, o yes/no), el resultado aparecerá como una pirámide. Sin embargo, si hay más de dos valores en la columna split_by (sin incluir NA), la pirámide aparecerá como un gráfico de barras facetadas con barras grises en el “fondo” que indican el rango de los datos no facetados para ese grupo de edad. En este caso, los valores de split_by = aparecerán como etiquetas en la parte superior de cada panel de facetas. Por ejemplo, a continuación se muestra lo que ocurre si a split_by = se le asigna la columna hospital.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  \n\n\n\n\n\n\n\n\n\nValores faltantes\nLas filas que tienen valores faltantes NA en las columnas split_by = o age_group =, si se codifican como NA, no producirán el aspecto mostrado arriba. Por defecto, estas filas no se mostrarán. Sin embargo, puede especificar que aparezcan, en un gráfico de barras adyacente y como un grupo de edad separado en la parte superior, especificando na.rm = FALSE.\n\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # mostrar pacientes sin edad o sexo\n\n\n\n\n\n\n\n\n\n\nProporciones, colores y estética\nPor defecto, las barras muestran los recuentos (no el %), se muestra una línea media discontinua para cada grupo y los colores son verde/morado. Cada uno de estos parámetros puede ajustarse, como se muestra a continuación:\nTambién puede añadir comandos adicionales de ggplot() al gráfico utilizando la sintaxis estándar de ggplot() “+”, como temas estéticos y ajustes de etiquetas:\n\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # muestra porcentajes, no conteos\n  show_midpoint = FALSE,            # elimina la línea del punto medio de la barra\n  #pal = c(\"orange\", \"purple\")     # puede especificar colores alternativos aquí (pero no etiquetas)\n  )+                 \n  \n  # comandos adicionales de ggplot\n  theme_minimal()+                               # simplifica el fondo\n  scale_fill_manual(                             # especificar colores Y etiquetas\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # observa que los labs x e y se intercambian\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # leyenda en la parte inferior\n    axis.text = element_text(size = 10, face = \"bold\"),  # fuentes/tamaños\n    axis.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nDatos agregados\nLos ejemplos anteriores suponen que sus datos están en formato de listado, con una fila por observación. Si los datos ya están agregados en recuentos por categoría de edad, puedes seguir utilizando el paquete apyramid, como se muestra a continuación.\nPara la demostración, agregamos los datos del listado en recuentos por categoría de edad y género, en un formato “ancho”. Esto simulará como si sus datos estuvieran agregados desde el principios. Aprende más sobre Agrupar datos y Pivotar datos en sus respectivas páginas.\n\ndemo_agg &lt;- linelist %&gt;% \n  count(age_cat5, gender, name = \"cases\") %&gt;% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %&gt;% \n  rename(`missing_gender` = `NA`)\n\n…lo que hace que el conjunto de datos tenga el siguiente aspecto: con columnas para la categoría age, y recuentos de male, de female y de missing.\n\n\n\n\n\n\nPara configurar estos datos para la pirámide de edad, pivotaremos los datos para que sean “largos” con la función pivot_longer() de dplyr. Esto se debe a que ggplot() generalmente prefiere datos “largos”, y apyramid está utilizando ggplot().\n\n# pivotar los datos agregados en formato largo\ndemo_agg_long &lt;- demo_agg %&gt;% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # columnas a alargar\n    names_to = \"gender\",                # nombre para la nueva columna de categorías\n    values_to = \"counts\") %&gt;%           # nombre para la nueva columna de recuentos\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # convierte \"missing_gender\" en NA\n\n\n\n\n\n\n\nA continuación, utiliza los argumentos split_by = y count = de age_pyramid() para especificar las respectivas columnas de los datos:\n\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# nombre de columna para la categoría de edad\n                      split_by = \"gender\",   # nombre de columna para género\n                      count = \"counts\")      # nombre de columna para el recuento de casos\n\n\n\n\n\n\n\n\nObserva en lo anterior, que el orden de los factores “m” y “f” es diferente (pirámide invertida). Para ajustar el orden debes redefinir el género en los datos agregados como un Factor y ordenar los niveles como se desee. Consulta la página Factores.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pirámides de población y escalas de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.es.html#demo_pyr_gg",
    "href": "new_pages/age_pyramid.es.html#demo_pyr_gg",
    "title": "33  Pirámides de población y escalas de Likert",
    "section": "33.3 ggplot()",
    "text": "33.3 ggplot()\nEl uso de ggplot() para construir tu pirámide de edad permite más flexibilidad, pero requiere más esfuerzo y comprensión de cómo funciona ggplot(). También es más fácil cometer errores accidentalmente.\nPara usar ggplot() para hacer pirámides demográficas, se crean dos gráficos de barras (uno para cada género), se convierten los valores de un gráfico en negativo y, finalmente, se invierten los ejes x e y para mostrar los gráficos de barras verticalmente, con sus bases encontrándose en el centro del gráfico.\n\nPreparación\nEste enfoque utiliza la columna numérica age, no la columna categórica de age_cat5. Así que comprobaremos que el tipo de esta columna es efectivamente numérica.\n\nclass(linelist$age)\n\n[1] \"numeric\"\n\n\nPodrías utilizar la misma lógica que se indica a continuación para construir una pirámide a partir de datos categóricos utilizando geom_col() en lugar de geom_histogram().\n\n\n\nConstrucción del gráfico\nEn primer lugar, hay que entender que para hacer una pirámide de este tipo utilizando ggplot() el planteamiento es el siguiente:\n\nDentro de ggplot(), crea dos histogramas utilizando la columna numérica de la edad. Crea uno para cada uno de los dos valores de agrupación (en este caso los géneros masculino y femenino). Para ello, los datos para cada histograma se especifican dentro de sus respectivos comandos geom_histogram(), con los respectivos filtros aplicados a linelist.\nUn gráfico tendrá valores de recuento positivos, mientras que el otro tendrá sus recuentos convertidos a valores negativos - esto crea la “pirámide” con el valor 0 en el centro del gráfico. Los valores negativos se crean utilizando un término especial de ggplot2 ..count.. y multiplicando por -1.\nEl comando coord_flip() cambia los ejes X e Y, lo que hace que los gráficos se vuelvan verticales y se cree la pirámide.\nPor último, hay que modificar las etiquetas de los valores del eje de recuento para que aparezcan como recuentos “positivos” en ambos lados de la pirámide (a pesar de que los valores subyacentes en un lado sean negativos).\n\nA continuación se muestra una versión sencilla de esto, utilizando geom_histogram():\n\n  # comenzar ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # histograma de mujeres\n  geom_histogram(data = linelist %&gt;% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # histograma de hombres (valores convertidos a negativo)\n  geom_histogram(data = linelist %&gt;% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # invertir los ejes X e Y\n  coord_flip() +\n  \n  # ajustar la escala del eje de recuentos\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n\n\n\n\n\n\n\n\nPELIGRO: Si los límites de tu eje de recuentos son demasiado bajos, y una barra de recuentos los sobrepasa, la barra desaparecerá por completo o se acortará artificialmente. Ten cuidado con esto si analizas datos que se actualizan de forma rutinaria. Evítalo haciendo que los límites del eje de recuentos se ajusten automáticamente a los datos, como se indica a continuación.\nHay muchas cosas que puedes cambiar/añadir a esta sencilla versión, entre ellas:\n\nAjustar automáticamente la escala del eje de recuentos a sus datos (evita los errores que se comentan en la advertencia que aparece a continuación)\nEspecificar manualmente los colores y las etiquetas de las leyendas\n\nConvertir recuentos en porcentajes\nPara convertir los recuentos en porcentajes (del total), hazlo en los datos antes de representarlos. A continuación, obtenemos los recuentos de age-gender, entonces desagrupamos con ungroup(), y luego mutamos con mutate() para crear nuevas columnas de porcentajes. Si quieres porcentajes por género, omite el paso de desagrupación.\n\n# crear conjunto de datos con proporciones del total\npyramid_data &lt;- linelist %&gt;%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %&gt;% \n  ungroup() %&gt;%                 # desagrupar para que los porcentajes no sean por grupo\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,     # convierte hombres en valores negativos\n            TRUE          ~ NA_real_))    # el valor NA también debe ser numérico\n\nEs importante que guardemos los valores máximo y mínimo para saber cuáles deben ser los límites de la escala. Estos se utilizarán en el comando ggplot() a continuación.\n\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nmax_per\n\n[1] 10.9\n\nmin_per\n\n[1] -7.1\n\n\nFinalmente hacemos el ggplot() sobre los datos porcentuales. Especificamos scale_y_continuous() para extender las longitudes predefinidas en cada dirección (positiva y “negativa”). Usamos floor() y ceiling() para redondear los decimales en la dirección apropiada (abajo o arriba) para el lado del eje.\n\n# comenzar ggplot\n  ggplot()+  # por defecto el eje-x es la edad en años;\n\n  # gráfico de datos de casos\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # blanco alrededor de cada barra\n  \n  # invierte los ejes X e Y para hacer la pirámide vertical\n  coord_flip()+\n  \n\n  # ajusta las escalas de los ejes\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # secuencia de valores, por 2s\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # secuencia de valores absolutos, por 2s, con \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # designar colores y etiquetas de leyenda manualmente\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # etiquetas de valores ( recordar que ahora X e Y están invertidas)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # mostrar temas\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )\n\n\n\n\n\n\n\n\n\n\n\nComparación con una línea basal\nCon la flexibilidad de ggplot(), se puede tener una segunda capa de barras en el fondo que represente la pirámide de población “verdadera” o “de referencia”. Esto puede proporcionar una buena visualización para comparar lo observado con una referencia.\nImporta y visualiza los datos de población (véase la página Descargando el manual y los datos):\n\n# importa los datos demográficos de la población\npop &lt;- rio::import(\"country_demographics.csv\")\n\n\n\n\n\n\n\nEn primer lugar, algunos pasos de gestión de datos:\nAquí registramos el orden de las categorías de edad que queremos que aparezcan. Debido a algunas peculiaridades de la forma en que se implementa ggplot(), en este escenario específico es más fácil almacenar estos como un vector de caracteres y utilizarlos más tarde en la función de representación gráfica.\n\n# registrar correctamente los niveles de las categorías de edad\nage_levels &lt;- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n\nCombina los datos de la población y de los casos mediante la función bind_rows() de dplyr:\n\nEn primer lugar, asegúrate que los nombres de las columnas, los valores de las categorías de edad y los valores del género son exactamente los mismos\nHaz que tengan la misma estructura de datos: columnas de categoría de edad, sexo, recuentos y porcentaje del total\nAgruparlas, una encima de la otra (bind_rows())\n\n\n# crear/transformar datos de población, con porcentaje del total\n################################################################\npop_data &lt;- pop %&gt;% \n  pivot_longer(      # pivota largo las columnas de género\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %&gt;% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % of total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent,               # si es hombre, convierte el % en negativo\n     TRUE          ~ NA_real_))\n\nRevisar el conjunto de datos de la población modificada\n\n\n\n\n\n\nAhora implementa lo mismo para los casos de linelist Ligeramente diferente porque comienza con las filas de casos, no con los recuentos.\n\n# crear datos de casos por edad/género, con porcentaje del total\n################################################################\ncase_data &lt;- linelist %&gt;%\n  count(age_cat5, gender, name = \"counts\") %&gt;%   # recuentos por grupos de edad/género\n  ungroup() %&gt;% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calcula el % del total por grupos de edad-género\n    percent = case_when(                                     # convierte % en negativo si es hombre\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent,\n      TRUE          ~ NA_real_))\n\nRevisa los datos de casos modificados\n\n\n\n\n\n\nAhora los dos dataframes están combinados, uno encima del otro (tienen los mismos nombres de columna). Podemos “nombrar” cada uno de los dataframes, y utilizar el argumento .id = para crear una nueva columna “data_source” que indicará de qué dataframe se originó cada fila. Podemos utilizar esta columna para filtrar en ggplot().\n\n# combina datos de casos y de población (mismos nombres de columna, valores de age_cat y valores de género)\npyramid_data &lt;- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n\nAlmacena los valores porcentuales máximo y mínimo, utilizados en la función de trazado para definir la extensión del gráfico (¡y no acortar ninguna barra!)\n\n# Define la extensión del eje porcentual, utilizado para los límites del gráfico\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\nAhora el gráfico se hace con ggplot():\n\nUn gráfico de barras de los datos de población (barras más anchas y transparentes)\nUn gráfico de barras de los datos del caso (barras pequeñas y más sólidas)\n\n\n# comienza ggplot\n##############\nggplot()+  # el eje-x por defecto es la edad en años;\n\n  # gráfico de datos de población\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # color negro alrededor de las barras\n    alpha = 0.2,                                    # más transparente\n    width = 1)+                                     # anchura completa\n  \n  # gráfico de datos de casos\n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # categorías de edad como eje-X original\n      y = percent,                                # % como eje-Y original\n      fill = gender),                             # relleno de barras por género\n    colour = \"black\",                               # color negro alrededor de las barras\n    alpha = 1,                                      # no transparente \n    width = 0.3)+                                   # mitad anchura\n  \n  # invierte los ejes X e Y para hacer la pirámide vertical\n  coord_flip()+\n  \n  # asegura manualmente que el eje de edad está ordenado correctamente\n  scale_x_discrete(limits = age_levels)+     # definido en el trozo (chunk) anterior\n  \n  # establecer el eje de porcentajes\n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # min y max definidos arriba\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # de min% a max% por 2  \n    labels = paste0(                                                       # para las etiquetas, pegar juntas...  \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # designar colores y etiquetas de leyenda manualmente\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # asigna colores a los valores de los datos\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # cambia las etiquetas que aparecen en la leyenda, observa el orden\n  ) +\n\n  # etiquetas, títulos y pies de foto \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # temas estéticos opcionales\n  theme(\n    legend.position = \"bottom\",                             # mueve la leyenda hacia abajo\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pirámides de población y escalas de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.es.html#likert-scale",
    "href": "new_pages/age_pyramid.es.html#likert-scale",
    "title": "33  Pirámides de población y escalas de Likert",
    "section": "33.4 Escalas de Likert",
    "text": "33.4 Escalas de Likert\nLas técnicas utilizadas para hacer una pirámide de población con ggplot() también se pueden utilizar para hacer gráficos de datos de encuestas en escala Likert.\nImporta los datos (consulta la página Descargando el manual y los datos si lo deseas).\n\n# importa los datos de respuesta de la escala de likert\nlikert_data &lt;- rio::import(\"likert_data.csv\")\n\nEmpieza con datos que tengan este aspecto, con una clasificación categórica de cada encuestado (status y sus respuestas a 8 preguntas en una escala tipo Likert de 4 puntos (“Muy pobre”, “Pobre”, “Bueno”, “Muy bueno”).\n\n\n\n\n\n\nEn primer lugar, algunos pasos de gestión de datos:\n\nPivotar los datos a lo largo\nCrear una nueva columna direction en función de si la respuesta fue generalmente “positiva” o “negativa”\nEstablece el orden del nivel de factor para la columnas status y Response\nAlmacena el valor de recuento máximo para que los límites del gráfico sean los adecuados\n\n\nmelted &lt;- likert_data %&gt;% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %&gt;% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # must reverse 'Very Poor' and 'Poor' for ordering to work\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# obtener el valor maximo para los limites de escala\nmelted_max &lt;- melted %&gt;% \n  count(status, Question) %&gt;% # obtener recuentos\n  pull(n) %&gt;%                 # columna 'n'\n  max(na.rm=T)                # obtener max\n\nAhora haz el gráfico. Como en las pirámides de edad anteriores, estamos creando dos gráficos de barras e invirtiendo los valores de uno de ellos a negativo.\nUtilizamos geom_bar() porque nuestros datos son una fila por observación, no recuentos agregados. Utilizamos el término especial de ggplot2 ..count.. en uno de los gráficos de barras para invertir los valores en negativo (*-1), y establecemos position = \"stack\" para que los valores se apilen unos encima de otros.\n\n# make plot\nggplot()+\n     \n  # gráfico de barras de las respuestas \"negativas\"\n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # recuentos invertidos a negativo\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # gráfico de barras de las respuestas \"positivas\"\n     geom_bar(\n       data = melted %&gt;% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # invierte los ejes X e Y\n     coord_flip()+\n  \n     # Línea vertical negra en 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # convertir etiquetas a todos los números positivos\n    scale_y_continuous(\n      \n      # límites de la escala del eje-x\n      limits = c(-ceiling(melted_max/10)*11,    # secuencia de neg a pos por 10, bordes redondeados hacia afuera al más cercano a 5\n                 ceiling(melted_max/10)*10),   \n      \n      # valores de la escala del eje-x\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # etiquetas de la escala del eje-x\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # escalas de color asignadas manualmente \n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # asigna colores\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # ordena la leyenda\n     \n    \n     \n    # Facetar todo el gráfico para que cada pregunta sea un subgráfico\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # etiquetas, títulos, leyenda\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # ajustes de visualización \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # Subtítulos de las facetas\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # recuadro negro alrededor de cada faceta",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pirámides de población y escalas de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/age_pyramid.es.html#resources-26",
    "href": "new_pages/age_pyramid.es.html#resources-26",
    "title": "33  Pirámides de población y escalas de Likert",
    "section": "33.5 Recursos",
    "text": "33.5 Recursos\ndocumentación de apyramide",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pirámides de población y escalas de Likert</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.es.html",
    "href": "new_pages/heatmaps.es.html",
    "title": "34  Gráficos de calor",
    "section": "",
    "text": "34.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Gráficos de calor</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.es.html#preparation-25",
    "href": "new_pages/heatmaps.es.html#preparation-25",
    "title": "34  Gráficos de calor",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  tidyverse,       # manipulación y visualización de datos\n  rio,             # importación de datos \n  lubridate        # trabajar con fechas\n  )\n\nConjuntos de datos\nEsta página utiliza los casos de linelist un brote simulado para la sección de la matriz de transmisión, y unos datos separados de recuentos diarios de casos de malaria por instalación para la sección de seguimiento de métricas. Se cargan y limpian en sus secciones individuales.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Gráficos de calor</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.es.html#transmission-matrix",
    "href": "new_pages/heatmaps.es.html#transmission-matrix",
    "title": "34  Gráficos de calor",
    "section": "34.2 Matriz de transmisión",
    "text": "34.2 Matriz de transmisión\nLos mapas de calor pueden ser útiles para visualizar matrices. Un ejemplo es la visualización de “quién-infectó-quién” en un brote. Esto supone que se tiene información sobre los eventos de transmisión.\nTen en cuenta que la página Rastreo de contactos contiene otro ejemplo de elaboración de una matriz de contactos del mapa de calor, utilizando unos datos diferentes (quizás más sencillo) en el que las edades de los casos y sus fuentes están perfectamente alineadas en la misma fila del dataframe. Estos mismos datos se utilizan para hacer un mapa de densidad en la página Consejos de ggplot. Este ejemplo comienza a partir de linelist y, por lo tanto, implica una considerable manipulación de los datos antes de lograr un dataframe ploteable. Así que hay muchos escenarios para elegir…\nPartimos de la lista de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - vea la página de importación y exportación para más detalles).\nA continuación se muestran las primeras 50 filas del listado para su demostración:\n\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nEn este linelist:\n\nHay una fila por caso, identificada por case_id\nHay una columna posterior infector que contiene el case_id del infector, que también es un caso en linelist\n\n\n\n\n\n\n\n\nPreparación de los datos\nObjetivo: Necesitamos conseguir un dataframe de estilo “largo” que contenga una fila por cada posible ruta de transmisión edad-a-edad, con una columna numérica que contenga la proporción de esa fila de todos los eventos de transmisión observados en linelist.\nEsto requerirá varios pasos de manipulación de datos para lograrlo:\n\nHacer el dataframe de casos\nPara empezar, creamos un dataframe de los casos, sus edades y sus infectadores - llamamos al dataframe case_ages. Las primeras 50 filas se muestran a continuación.\n\ncase_ages &lt;- linelist %&gt;% \n  select(case_id, infector, age_cat) %&gt;% \n  rename(\"case_age_cat\" = \"age_cat\")\n\n\n\n\n\n\n\n\n\nHacer un dataframe de infectores\nA continuación, creamos un dataframe de los infectores, que por el momento consta de una sola columna. Se trata de las identificaciones de los infectores del listado. No todos los casos tienen un infector conocido, por lo que eliminamos los valores que faltan. A continuación se muestran las primeras 50 filas.\n\ninfectors &lt;- linelist %&gt;% \n  select(infector) %&gt;% \n  drop_na(infector)\n\n\n\n\n\n\n\nA continuación, utilizamos las uniones para obtener las edades de los infectores. Esto no es sencillo, ya que en linelist, las edades de los infectores no aparecen como tales. Conseguimos este resultado uniendo los casos de linelist con los infectores. Comenzamos con los infectores, y left_join() (añadimos) linelist de tal manera que la columna de ID del infector del lado izquierdo del dataframe “base” se une a la columna case_id en el dataframe linelist en el lado derecho.\nAsí, los datos del registro de casos del infector en linelist(incluida la edad) se añaden a la fila del infector. A continuación se muestran las 50 primeras filas.\n\ninfector_ages &lt;- infectors %&gt;%             # empieza con los infectores\n  left_join(                               # añade los datos de linelist a cada infector   \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %&gt;%    # relaciona infector con su información como caso\n  select(infector, age_cat) %&gt;%            # mantiene sólo las columnas de interés\n  rename(\"infector_age_cat\" = \"age_cat\")   # renombra para mayor claridad\n\n\n\n\n\n\n\nA continuación, combinamos los casos y sus edades con los infectores y sus edades. Cada uno de estos dataframes tiene la columna infector, por lo que se utiliza para la unión. Las primeras filas se muestran a continuación:\n\nages_complete &lt;- case_ages %&gt;%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %&gt;%        # cada uno tiene la columna infector\n  drop_na()                     # elimina las filas en las que faltan datos\n\nWarning in left_join(., infector_ages, by = \"infector\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 6 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\n\n\n\n\nA continuación, una simple tabulación cruzada de los recuentos entre los grupos de edad de los casos y de los infectantes. Se añaden etiquetas para mayor claridad.\n\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)\n\n       infectors\ncases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n  0-4   105 156   105   114   143   117    13   0\n  5-9   102 132   110   102   117    96    12   5\n  10-14 104 109    91    79   120    80    12   4\n  15-19  85 105    82    39    75    69     7   5\n  20-29 101 127   109    80   143   107    22   4\n  30-49  72  97    56    54    98    61     4   5\n  50-69   5   6    15     9     7     5     2   0\n  70+     1   0     2     0     0     0     0   0\n\n\nPodemos convertir esta tabla en un dataframe con data.frame() de R base, que también la convierte automáticamente al formato “long”, que es el deseado por ggplot(). Las primeras filas se muestran a continuación.\n\nlong_counts &lt;- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\n\n\n\n\n\n\n\nAhora hacemos lo mismo, pero aplicamos prop.table() de R base a la tabla para que en lugar de recuentos obtengamos proporciones del total. Las primeras 50 filas se muestran a continuación.\n\nlong_prop &lt;- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))\n\n\n\n\n\n\n\n\n\n\nCrear un gráfico de calor\nAhora, finalmente, podemos crear el gráfico de calor con el paquete ggplot2, utilizando la función geom_tile(). Consulta la página Consejos de ggplot para conocer más ampliamente las escalas de color/relleno, especialmente la función scale_fill_gradient().\n\nEn la estética aes() de geom_tile() establece la x y la y como la edad del caso y la edad del infector\nTambién en aes() establece el argumento fill = en la columna Freq - este es el valor que se convertirá en un color de mosaico\nEstablece un color de escala con scale_fill_gradient() - puedes especificar los colores high/low\n\nTen en cuenta que scale_color_gradient() es diferente. En este caso quieres que rellene\n\nDado que el color se hace a través de “fill”, puedes utilizar el argumento fill = en labs() para cambiar el título de la leyenda\n\n\nggplot(data = long_prop)+       # usar datos largos, con proporciones como Freq\n  geom_tile(                    # visualizarlo en mosaicos\n    aes(\n      x = cases,         # el eje-x es la edad de los casos\n      y = infectors,     # el eje-y es la edad del infector\n      fill = Freq))+            # el color del mosaico es la columna Freq de los datos\n  scale_fill_gradient(          # ajusta el color de relleno de los mosaicos\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # etiquetas\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # título de la leyenda\n  )",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Gráficos de calor</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.es.html#reporting-metrics-over-time",
    "href": "new_pages/heatmaps.es.html#reporting-metrics-over-time",
    "title": "34  Gráficos de calor",
    "section": "34.3 Informar sobre las métricas a lo largo del tiempo",
    "text": "34.3 Informar sobre las métricas a lo largo del tiempo\nA menudo, en el ámbito de la salud pública, uno de los objetivos es evaluar las tendencias a lo largo del tiempo de muchas entidades (instalaciones, jurisdicciones, etc.). Una forma de visualizar esas tendencias a lo largo del tiempo es un gráfico de calor en el que el eje de abscisas es el tiempo y en el eje de ordenadas están las numerosas entidades.\n\nPreparación de los datos\nComenzamos importando unos datos de informes diarios sobre la malaria procedentes de muchos centros. Los informes contienen una fecha, una provincia, un distrito y el recuento de paludismo. Consulta la página Descargando el manual y los datos para saber cómo descargar estos datos. A continuación se muestran las primeras 30 filas:\n\nfacility_count_data &lt;- import(\"malaria_facility_count_data.rds\")\n\n\n\n\n\n\n\n\nAgregar y resumir\nEl objetivo de este ejemplo es transformar los recuentos diarios del total de casos de malaria del centro (vistos en la sección anterior) en estadísticas resumidas semanales de la declaración de cada centro, en este caso la proporción de días por semana en que el centro notificó algún dato. Para este ejemplo mostraremos los datos sólo para el distrito de Spring.\nPara ello, realizaremos los siguientes pasos de gestión de datos:\n\nFiltrar los datos según convenga (por lugar, fecha)\nCrear una columna de semana utilizando floor_date() del paquete lubridate \n\nEsta función devuelve la fecha de inicio de la semana de una fecha dada, utilizando una fecha de inicio especificada de cada semana (por ejemplo, “onday”)\n\nLos datos se agrupan por las columnas “location” y “week” para crear unidades de análisis de “instalación-semana”\nLa función summarise() crea nuevas columnas para reflejar las estadísticas resumidas por grupo de facility-week:\n\nNúmero de días por semana (7 - un valor estático)\nNúmero de informes recibidos de la semana de la instalación (¡podrían ser más de 7!)\nSuma de los casos de paludismo notificados por el centro-semana (sólo por interés)\nNúmero de días únicos en la semana de la instalación para los que hay datos reportados\nPorcentaje de los 7 días por instalación-semana para los que se comunicaron datos\n\n\n\nEl dataframe se une con right_join() a una lista exhaustiva de todas las posibles combinaciones de semanas de instalaciones, para que el conjunto de datos esté completo. La matriz de todas las combinaciones posibles se crea aplicando expand() a esas dos columnas del dataframe tal y como se encuentra en ese momento en la cadena de pipes (representada por .). Como se utiliza un right_join(), se mantienen todas las filas del dataframe de expand() y se añaden a agg_weeks si es necesario. Estas nuevas filas aparecen con valores resumidos NA (missing).\n\nA continuación lo mostramos paso a paso:\n\n# Crear conjunto de datos de resumen semanal\nagg_weeks &lt;- facility_count_data %&gt;% \n  \n  # Filtrar los datos según convenga\n  filter(\n    District == \"Spring\",\n    data_date &lt; as.Date(\"2020-08-01\")) \n\nAhora el conjunto de datos tiene nrow(agg_weeks) filas, cuando antes tenía nrow(facility_count_data).\nA continuación creamos una columna week que refleje la fecha de inicio de la semana para cada registro. Esto se consigue con la función floor_date() del paquete lubridate, que se establece como “week” y para que las semanas comiencen los lunes (día 1 de la semana - los domingos serían 7). A continuación se muestran las filas superiores.\n\nagg_weeks &lt;- agg_weeks %&gt;% \n  # Crear la columna semana a partir de data_date\n  mutate(\n    week = lubridate::floor_date(                     # crea nueva columna de semanas\n      data_date,                                      # columna de fechas\n      unit = \"week\",                                  # indicar el inicio de la semana\n      week_start = 1))                                # las semanas empiezan los lunes \n\nLa nueva columna week puede verse en el extremo derecho del dataframe\n\n\n\n\n\n\nAhora agrupamos los datos en semanas de instalaciones y los resumimos para producir estadísticas por facility-week. Consulta la página sobre tablas descriptivas para obtener consejos. La agrupación en sí misma no cambia el dataframe, pero afecta a la forma en que se calculan las estadísticas de resumen posteriores.\nA continuación se muestran las filas superiores. Observa cómo las columnas han cambiado completamente para reflejar las estadísticas de resumen deseadas. Cada fila refleja una facility-week.\n\nagg_weeks &lt;- agg_weeks %&gt;%   \n\n  # Agrupar en centros-semanas\n  group_by(location_name, week) %&gt;%\n  \n  # Crear columnas estadísticas de resumen sobre los datos agrupados\n  summarize(\n    n_days          = 7,                                          # 7 días por semana           \n    n_reports       = dplyr::n(),                                 # número de comunicaciones recibidas por semana \n    malaria_tot     = sum(malaria_tot, na.rm = T),                # total de casos de malaria notificados\n    n_days_reported = length(unique(data_date)),                  # número de días únicos de notificación por semana\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;%  # porcentaje de días notificados\n  ungroup(location_name, week)\n\n\n\n\n\n\n\nPor último, ejecutamos el siguiente comando para asegurarnos que TODAS las semanas posibles de las instalaciones están presentes en los datos, incluso si antes no estaban.\nEstamos utilizando un right_join() sobre sí mismo (el conjunto de datos está representado por “.”) pero habiéndose expandido para incluir todas las combinaciones posibles de las columnas week y location_name. Véase la documentación sobre la función expand() en la página sobre Pivotar datos. Antes de ejecutar este código, el conjunto de datos contiene nrow(agg_weeks) filas.\n\n# Crear dataframe de cada posible centro-semana\nexpanded_weeks &lt;- agg_weeks %&gt;% \n  tidyr::expand(location_name, week)  # expand data frame to include all possible facility-week combinations\n\nAquí está expanded_weeks:\n\n\n\n\n\n\nAntes de ejecutar este código, agg_weeks contiene nrow(agg_weeks) filas.\n\n# Realizar una unión a la derecha con la lista ampliada de centros-semanas para rellenar los huecos que faltan en los datos.\nagg_weeks &lt;- agg_weeks %&gt;%      \n  right_join(expanded_weeks) %&gt;%                            # Asegurarse de que todas las combinaciones posibles de semana-centro aparecen en los datos\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # convertir los valores faltantes en 0                          \n\nJoining with `by = join_by(location_name, week)`\n\n\nDespués de ejecutar este código, agg_weeks contiene nrow(agg_weeks) filas.\n\n\n\n\nCrear un gráfico de calor\nggplot() se realiza utilizando geom_tile() del paquete ggplot2:\n\nLas semanas en el eje-x se transforman en fechas, lo que permite utilizar scale_x_date()\nlocation_name en el eje y mostrará todos los nombres de las instalaciones\nfill (relleno) es p_days_reported, el rendimiento para ese establecimiento-semana (numérico)\nscale_fill_gradient() se utiliza en el relleno numérico, especificando los colores para el alto, el bajo y NA\nscale_x_date() se utiliza en el eje x especificando las etiquetas cada 2 semanas y su formato\nLos temas de visualización y las etiquetas pueden ajustarse según sea necesario\n\n\n\n\nBásico\nA continuación se produce un gráfico de calor básico, utilizando los colores, escalas, etc., por defecto. Como se ha explicado anteriormente, dentro de aes() para geom_tile() debes proporcionar una columna del eje-x, una columna del eje-y y una columna para fill =. El relleno es el valor numérico que se presenta como color del mosaico.\n\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))\n\n\n\n\n\n\n\n\n\n\nGráfico limpio\nPodemos hacer que este gráfico se vea mejor añadiendo funciones adicionales de ggplot2, como se muestra a continuación. Consulta la página Consejos de ggplot para más detalles.\n\nggplot(data = agg_weeks)+ \n  \n  # mostrar datos como mosaicos\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # líneas de cuadrícula en blanco\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # eje de fecha\n  scale_x_date(\n    expand = c(0,0),             # elimina el espacio extra en los lados\n    date_breaks = \"2 weeks\",     # etiquetas cada 2 semanas\n    date_labels = \"%d\\n%b\")+     # el formato es día sobre mes (\\n en una línea nueva)\n  \n  # temas estéticos\n  theme_minimal()+                                  # simplificar fondo\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # altura de la leyenda\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # anchura de la leyenda\n    \n    axis.text.x = element_text(size=12),              # tamaño del texto del eje\n    axis.text.y = element_text(vjust=0.2),            # alineación del texto del eje\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # tamaño del título del eje y negrita\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # título alineado a la derecha, grande, negrita\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # leyenda alineada a la derecha y en cursiva\n    )+\n  \n  # etiquetas del gráfico\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # título de la leyenda, porque la leyenda aparece rellena\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\n\n\n\n\n\n\n\n\n\n\nEje-y ordenado\nActualmente, las instalaciones están ordenadas “alfanuméricamente” de abajo a arriba. Si deseas ajustar el orden de las instalaciones del eje-y, conviértelas en de tipo factor y proporciona el orden. Consulta la página sobre Factores para obtener consejos.\nComo hay muchas instalaciones y no queremos escribirlas todas, intentaremos otro enfoque: ordenar las instalaciones en un dataframe y utilizar la columna de nombres resultante como orden de los niveles del factor. A continuación, la columna location_name se convierte en un factor, y el orden de sus niveles se establece en función del número total de días de notificación presentados por el centro en todo el período de tiempo.\nPara ello, creamos un dataframe que representa el número total de informes por instalación, ordenados de forma ascendente. Podemos utilizar este vector para ordenar los niveles del factor en el gráfico.\n\nfacility_order &lt;- agg_weeks %&gt;% \n  group_by(location_name) %&gt;% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %&gt;% \n  arrange(tot_reports) # ascending order\n\nVéase el dataframe más abajo:\n\n\n\n\n\n\nAhora utiliza una columna del dataframe anterior (facility_order$location_name) para que sea el orden de los niveles del factor location_name en el dataframe agg_weeks:\n\n# cargar paquete \npacman::p_load(forcats)\n\n# crear factor y definir niveles manualmente\nagg_weeks &lt;- agg_weeks %&gt;% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\n\nY ahora los datos se vuelven a representar, con location_name como factor ordenado:\n\nggplot(data = agg_weeks)+ \n  \n  # mostrar datos como mosaicos\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # líneas de cuadrícula en blanco\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # eje de fecha\n  scale_x_date(\n    expand = c(0,0),             # elimina el espacio extra en los lados\n    date_breaks = \"2 weeks\",     # etiquetas cada 2 semanas\n    date_labels = \"%d\\n%b\")+     # el formato es día sobre mes (\\n en una línea nueva)\n  \n  # temas estéticos\n  theme_minimal()+                                  # simplificar fondo\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # altura de la leyenda\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # anchura de la leyenda\n    \n    axis.text.x = element_text(size=12),              # tamaño del texto del eje\n    axis.text.y = element_text(vjust=0.2),            # alineación del texto del eje\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # tamaño del título del eje y negrita\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # título alineado a la derecha, grande, negrita\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # leyenda alineada a la derecha y en cursiva\n    )+\n  \n  # etiquetas del gráfico\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # título de la leyenda, porque la leyenda aparece rellena\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\n\n\n\n\n\n\n\n\n\n\nMostrar valores\nPuedes añadir una capa geom_text() encima de los mosaicos, para mostrar los números reales de cada mosaico. Ten en cuenta que esto puede no parecer bonito si tiene muchos mosaicos pequeños.\nSe ha añadido el siguiente código: geom_text(aes(label = p_days_reported)). Esto añade texto en cada mosaico. El texto que se muestra es el valor asignado al argumento label =, que en este caso se ha establecido en la misma columna numérica p_days_reported que también se utiliza para crear el gradiente de color.\n\nggplot(data = agg_weeks)+ \n  \n  # mostrar datos como mosaicos\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # líneas de cuadrícula en blanco\n  \n  # texto\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+      # add text on top of tile\n  \n  # rellenar escala\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # eje de fecha\n  scale_x_date(\n    expand = c(0,0),             # elimina el espacio extra en los lados\n    date_breaks = \"2 weeks\",     # etiquetas cada 2 semanas\n    date_labels = \"%d\\n%b\")+     # el formato es día sobre mes (\\n en una línea nueva)\n  \n  # temas estéticos\n  theme_minimal()+                                    # simplificar fondo\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # altura de la leyenda\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # anchura de la leyenda\n    \n    axis.text.x = element_text(size=12),              # tamaño del texto del eje\n    axis.text.y = element_text(vjust=0.2),            # alineación del texto del eje\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # tamaño del título del eje y negrita\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # título alineado a la derecha, grande, negrita\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # leyenda alineada a la derecha y en cursiva\n    )+\n  \n  # etiquetas del gráfico\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # título de la leyenda, porque la leyenda aparece rellena\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Gráficos de calor</span>"
    ]
  },
  {
    "objectID": "new_pages/heatmaps.es.html#resources-27",
    "href": "new_pages/heatmaps.es.html#resources-27",
    "title": "34  Gráficos de calor",
    "section": "34.4 Recursos",
    "text": "34.4 Recursos\nscale_fill_gradient()\nGalería de gráficos R - mapa de calor",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Gráficos de calor</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html",
    "href": "new_pages/diagrams.es.html",
    "title": "35  Diagramas y gráficos",
    "section": "",
    "text": "35.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html#preparation-28",
    "href": "new_pages/diagrams.es.html#preparation-28",
    "title": "35  Diagramas y gráficos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También es posible cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  DiagrammeR,     # para diagramas de flujo\n  networkD3,      # para diagramas aluviales/Sankey\n  tidyverse)      # gestión y visualización de datos\n\n\n\nImportar datos\nLa mayor parte del contenido de esta página no requiere unos datos. Sin embargo, en la sección del diagrama de Sankey, utilizaremos la lista de casos de una epidemia de ébola simulada. Si quieres seguir esta parte, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - consulta la página importación y exportación para más detalles).\n\n# importa linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html#flow-diagrams",
    "href": "new_pages/diagrams.es.html#flow-diagrams",
    "title": "35  Diagramas y gráficos",
    "section": "35.2 Diagramas de flujo",
    "text": "35.2 Diagramas de flujo\nSe puede utilizar el paquete R DiagrammeR para crear gráficos/gráficos de flujo. Pueden ser estáticos o ajustarse de forma dinámica en función de los cambios en unos datos.\nHerramientas\nLa función grViz() se utiliza para crear un diagrama “Graphviz”. Esta función acepta una cadena de caracteres de entrada que contiene las instrucciones para hacer el diagrama. Dentro de esa cadena, las instrucciones están escritas en un lenguaje diferente, llamado DOT - es bastante fácil aprender lo básico.\nEstructura básica\n\nAbre las instrucciones grViz(\"\nEspecifica la dirección y el nombre del gráfico, y abre los paréntesis, por ejemplo, digraph my_flow_chart {\nDefine los elementos del gráfico (layout, rank direction)\nEstablece los nodos (create nodes)\nEstablece las conexiones entre nodos\nCierra las instrucciones }\")\n\n\nEjemplos sencillos\nA continuación, dos sencillos ejemplos\nUn ejemplo mínimo:\n\n# Un gráfico mínimo\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -&gt; b -&gt; c\n}\")\n\n\n\n\n\nUn ejemplo con un contexto de salud pública quizás más aplicado:\n\ngrViz(\"                           # Todas las instrucciones están dentro de una cadena de caracteres grandes\ndigraph surveillance_diagram {    # 'digraph' significa 'gráfico direccional', luego el nombre del gráfico \n  \n  # enunciado del gráfico\n  #######################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodos\n  #######\n  node [shape = circle,           # forma = círculo\n       fixedsize = true\n       width = 1.3]               # anchura de los círculos\n  \n  Primary                         # nombres de los nodos\n  Secondary\n  Tertiary\n\n  # Bordes\n  #######\n  Primary   -&gt; Secondary [label = ' case transfer']\n  Secondary -&gt; Tertiary [label = ' case transfer']\n}\n\")\n\n\n\n\n\n\n\nSintaxis\nSintaxis básica\nLos nombres de los nodos, o las etiquetas de las conexiones (edges), pueden separarse con espacios, punto y coma o nuevas líneas.\nDirección del rango\nSe puede reorientar un gráfico para que se mueva de izquierda a derecha ajustando el argumento rankdir dentro de la sentencia del gráfico. El valor predeterminado es TB (top-bottom, de arriba a abajo), pero puede ser LR (Left-Right, de izquierda a derecha), RL o BT.\nNombres de los nodos\nLos nombres de los nodos pueden ser palabras sueltas, como en el sencillo ejemplo anterior. Para utilizar nombres con varias palabras o caracteres especiales (por ejemplo, paréntesis, guiones), pon el nombre del nodo entre comillas simples (’ ’). Puede ser más fácil tener un nombre de nodo corto, y asignar una etiqueta como se muestra a continuación entre corchetes [ ]. Si quieres tener una nueva línea dentro del nombre del nodo, debes hacerlo a través de una etiqueta - utiliza \\n en la etiqueta del nodo entre comillas simples, como se muestra a continuación.\nSubgrupos\nAl definir las conexiones (aristas), se pueden crear subgrupos a ambos lados de la arista con corchetes ({ }). La arista se aplica entonces a todos los nodos en el corchete - es una forma abreviada.\nDiseños\n\ndot (establecer rankdir entre TB, LR, RL, BT, )\nneato\n\ntwopi\n\ncirco\n\nNodos - atributos editables\n\nlabel (texto, entre comillas simples si es de varias palabras)\n\nfillcolor (muchos colores posibles)\n\nfontcolor (color de la fuente)\nalpha (transparencia 0-1)\n\nshape (ellipse, oval, diamond, egg, plaintext, point, square, triangle)\n\nstyle (estilo)\nsides (lados)\nperipheries (periferia)\nfixedsize (h x w) (tamaño fijo (alto x ancho))\nheight (alto)\nwidth (ancho)\ndistortion (dstorsión)\npenwidth (ancho del borde de la forma)\n\nx (left/right) (desplazamiento a la izquierda/derecha)\ny (up/down) (desplazamiento arriba/abajo)\nfontname (nombre de la fuente)\nfontsize (tamaño de letra)\nicon\n\nConexioness - atributos editables\n\narrowsize (tamaño de la flecha)\narrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)\n\narrowtail (cola de flecha)\ndir (dirección, )\n\nstyle (guiones, …)\n\ncolor\n\nalpha\n\nheadport (texto delante de la punta de la flecha)\n\ntailport (texto detrás de la cola de flecha)\nfontname (nombre de la fuente)\nfontsize (tamaño de letra)\nfontcolor (color de la fuente)\npenwidth (anchura de la flecha)\n\nminlen (longitud mínima)\n\nNombres de los colores: valores hexadecimales o nombres de colores “X11”, véase aquí para los detalles de X11\n\n\nEjemplos complejos\nEl siguiente ejemplo amplía el surveillance_diagram, añadiendo nombres de nodos complejos, conexiones agrupadas, colores y estilos\nDiagrammeR::grViz(\"               # Todas las instrucciones están dentro de una cadena de caracteres grandes\ndigraph surveillance_diagram {    # 'digraph' significa 'gráfico direccional', luego el nombre del gráfico  \n  \n  # enunciado del gráfico\n  #######################\n  graph [layout = dot,\n         rankdir = TB,            # disposición de arriba abajo\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,           # forma = círculo\n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary   [label = 'Primary\\nFacility'] \n  Secondary [label = 'Secondary\\nFacility'] \n  Tertiary  [label = 'Tertiary\\nFacility'] \n  SC        [label = 'Surveillance\\nCoordination',\n             fontcolor = darkgreen] \n  \n  # Bordes\n  #######\n  Primary   -&gt; Secondary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  Secondary -&gt; Tertiary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  \n  # Bordes agrupados\n  {Primary Secondary Tertiary} -&gt; SC [label = 'case reporting',\n                                      fontcolor = darkgreen,\n                                      color = darkgreen,\n                                      style = dashed]\n}\n\")\n\n\n\n\n\n\nAgrupaciones de subgráficos\nPara agrupar los nodos en clústeres de cajas, ponlos dentro del mismo subgrafo (subgraph name {}). Para que cada subgrafo se identifique dentro de una caja delimitadora, comienza el nombre del subgrafo con “cluster”, como se muestra con las 4 cajas de abajo.\nDiagrammeR::grViz(\"             # Todas las instrucciones están dentro de una cadena de caracteres grandes\ndigraph surveillance_diagram {  # 'digraph' significa 'gráfico direccional', luego el nombre del gráfico \n  \n  # enunciado del gráfico\n  #######################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n\n  # nodos (círculos)\n  ###################\n  node [shape = circle,                  # forma = círculo\n       fixedsize = true\n       width = 1.3]                      # anchura de los círculos\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Primary\\nFacility'] \n    Secondary [label = 'Secondary\\nFacility'] \n    Tertiary  [label = 'Tertiary\\nFacility'] \n    SC        [label = 'Surveillance\\nCoordination',\n               fontcolor = darkgreen] \n  }\n  \n  # nodos (cajas)\n  ###############\n  node [shape = box,                     # forma del nodo\n        fontname = Helvetica]            # fuente de texto del nodo\n  \n  subgraph cluster_active {\n    Active [label = 'Active\\nSurveillance'] \n    HCF_active [label = 'HCF\\nActive Search']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Event-Based\\nSurveillance (EBS)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Community-Based\\nSurveillance (CBS)']\n    RECOs\n  }\n\n  \n  # Bordes\n  #######\n  {Primary Secondary Tertiary} -&gt; SC [label = 'case reporting']\n\n  Primary   -&gt; Secondary [label = 'case transfer',\n                          fontcolor = red]\n  Secondary -&gt; Tertiary [label = 'case transfer',\n                          fontcolor = red]\n  \n  HCF_active -&gt; Active\n  \n  {'Social Media' Radio} -&gt; EBS\n  \n  RECOs -&gt; CBS\n}\n\")\n\n\n\n\n\n\n\nFormas de los nodos\nEl siguiente ejemplo, tomado de este tutorial, muestra las formas de los nodos aplicados y una abreviatura de las conexiones de los bordes en serie\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# define los estilos globales de los nodos. Podemos anular estos en la caja si lo deseamos\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]\nprocess [label =  'Process \\n Data']\nstatistical [label = 'Statistical \\n Analysis']\nresults [label= 'Results']\n\n# definiciones de las bordes con los ID de los nodos\n{data1 data2}  -&gt; process -&gt; statistical -&gt; results\n}\")\n\n\n\n\n\n\n\nSalidas\nCómo manejar y guardar las salidas\n\nLas salidas aparecerán en el panel del Visor de RStudio, por defecto en la parte inferior derecha junto a Files, Plots, Packages, y Help.\nPara exportarlos puedes “Save as image” o “Copy to clipboard” desde el Visor. El gráfico se ajustará al tamaño especificado.\n\n\n\nFiguras parametrizadas\nEsta es una cita a este tutorial: https://mikeyharper.uk/flowcharts-in-r-using-diagrammer/\n“Figuras parametrizadas”: Una gran ventaja de diseñar figuras dentro de R es que podemos conectar las figuras directamente con nuestro análisis leyendo los valores de R directamente en nuestros diagramas de flujo. Por ejemplo, imagina que has creado un proceso de filtrado que elimina valores después de cada etapa de un proceso, puedes hacer que una figura muestre el número de valores que quedan en el conjunto de datos después de cada etapa de su proceso. Para hacer esto, puedes utilizar el símbolo @@X directamente dentro de la figura, y luego hacer referencia a esto en el pie de página del gráfico utilizando [X]:, donde X es el índice numérico único”.\nTe animamos a revisar este tutorial si te interesa la parametrización.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html#alluvialsankey-diagrams",
    "href": "new_pages/diagrams.es.html#alluvialsankey-diagrams",
    "title": "35  Diagramas y gráficos",
    "section": "35.3 Diagramas Aluviales/Sankey",
    "text": "35.3 Diagramas Aluviales/Sankey\n\nCargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\nCargamos el paquete networkD3 para producir el diagrama, y también tidyverse para los pasos de preparación de datos.\n\npacman::p_load(\n  networkD3,\n  tidyverse)\n\n\n\nTrazado desde los datos\nTrazado de las conexiones en unos datos. A continuación mostramos el uso de este paquete con linelist Aquí hay un tutorial en línea.\nComenzamos obteniendo los recuentos de casos para cada combinación única de categoría de edad y hospital. Hemos eliminado los valores con categoría de edad ausente para mayor claridad. También reetiquetamos las columnas hospital y age_cat como source y target respectivamente. Estos serán los dos lados del diagrama aluvial.\n\n# recuentos por hospital y categoría de edad\nlinks &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = hospital,\n         target = age_cat)\n\nEl conjunto de datos tiene ahora este aspecto:\n\n\n\n\n\n\nAhora creamos un dataframe de todos los nodos del diagrama, bajo la columna name. Esto consiste en todos los valores de hospital y age_cat. Observa que nos aseguramos de que todos son de tipo carácter antes de combinarlos. Ajustamos las columnas ID para que sean números en lugar de etiquetas:\n\n# Nombres únicos de los nodos\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\nnodes  # imprime\n\n                                   name\n1                      Central Hospital\n2                     Military Hospital\n3                               Missing\n4                                 Other\n5                         Port Hospital\n6  St. Mark's Maternity Hospital (SMMH)\n7                                   0-4\n8                                   5-9\n9                                 10-14\n10                                15-19\n11                                20-29\n12                                30-49\n13                                50-69\n14                                  70+\n\n\nA continuación editamos el dataframe links, que hemos creado anteriormente con count(). Añadimos dos columnas numéricas IDsource e IDtarget que reflejarán/crearán los enlaces entre los nodos. Estas columnas contendrán los números de ruta (posición) de los nodos de origen y destino. Se resta 1 para que estos números de posición comiencen en 0 (no en 1).\n\n# coincide con números, no con nombres\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\nEl conjunto de datos links tiene ahora este aspecto:\n\n\n\n\n\n\nAhora traza el diagrama Sankey con sankeyNetwork(). Puedes leer más sobre cada argumento ejecutando ?sankeyNetwork en la consola. Ten en cuenta que a menos que establezcas iterations = 0 el orden de los nodos puede no ser el esperado.\n\n# gráfico\n#########\np &lt;- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # asegura que el orden de los nodos es como en los datos\np\n\n\n\n\n\nEste es un ejemplo en el que también se incluye el resultado del paciente. Obsérva que en el paso de preparación de los datos tenemos que calcular los recuentos de casos entre la edad y el hospital, y por separado entre el hospital y el resultado - y luego unir todos estos recuentos con bind_rows().\n\n# recuentos por hospital y categoría de edad\nage_hosp_links &lt;- linelist %&gt;% \n  drop_na(age_cat) %&gt;% \n  select(hospital, age_cat) %&gt;%\n  count(hospital, age_cat) %&gt;% \n  rename(source = age_cat,          # renombra\n         target = hospital)\n\nhosp_out_links &lt;- linelist %&gt;% \n    drop_na(age_cat) %&gt;% \n    select(hospital, outcome) %&gt;% \n    count(hospital, outcome) %&gt;% \n    rename(source = hospital,       # renombra\n           target = outcome)\n\n# combina las conexiones\nlinks &lt;- bind_rows(age_hosp_links, hosp_out_links)\n\n# Nombres únicos de los nodos\nnodes &lt;- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %&gt;% \n    unique()\n  )\n\n# Crear números de identificación\nlinks$IDsource &lt;- match(links$source, nodes$name)-1 \nlinks$IDtarget &lt;- match(links$target, nodes$name)-1\n\n# gráfico\n#########\np &lt;- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np\n\n\n\n\n\nhttps://www.displayr.com/sankey-diagrams-r/",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html#event-timelines",
    "href": "new_pages/diagrams.es.html#event-timelines",
    "title": "35  Diagramas y gráficos",
    "section": "35.4 Calendario de eventos",
    "text": "35.4 Calendario de eventos\nPara hacer una línea de tiempo que muestre eventos específicos, puedes utilizar el paquete vistime.\nMira esta viñeta\n\n# cargar paquetes\npacman::p_load(vistime, # hacer la línea de tiempo\n               plotly # para visualización interactiva\n               )\n\nEste es el conjunto de datos de eventos con el que comenzamos:\n\n\n\n\n\n\n\np &lt;- vistime(data)    # aplica vistime\n\nlibrary(plotly)\n\n# paso 1: transformar en una lista\npp &lt;- plotly_build(p)\n\n# paso 2: tamaño del marcador\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size &lt;- 10\n}\n\n# paso 3: tamaño del texto\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size &lt;- 10\n}\n\n\n# paso 4: posición del texto\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition &lt;- \"right\"\n}\n\n#imprimir\npp",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html#dags",
    "href": "new_pages/diagrams.es.html#dags",
    "title": "35  Diagramas y gráficos",
    "section": "35.5 DAGs",
    "text": "35.5 DAGs\nPuedes construir un DAG manualmente utilizando el paquete DiagammeR y el lenguaje DOT como se ha descrito anteriormente.\nComo alternativa, existen paquetes como ggdag y daggity\nViñeta de Introducción a los DAGs ggdag\nInferencia causal con dags en R",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/diagrams.es.html#resources-28",
    "href": "new_pages/diagrams.es.html#resources-28",
    "title": "35  Diagramas y gráficos",
    "section": "35.6 Recursos",
    "text": "35.6 Recursos\nGran parte de lo anterior sobre el lenguaje DOT está adaptado del tutorial de este sitio\nOtro tutorial más detallado sobre DiagammeR\nEsta página sobre los diagramas de Sankey",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Diagramas y gráficos</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.es.html",
    "href": "new_pages/combination_analysis.es.html",
    "title": "36  Análisis de combinaciones",
    "section": "",
    "text": "36.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Análisis de combinaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.es.html#preparation-29",
    "href": "new_pages/combination_analysis.es.html#preparation-29",
    "title": "36  Análisis de combinaciones",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  tidyverse,     # gestión y visualización de datos\n  UpSetR,        # paquete especial para gráficos combinados\n  ggupset)       # paquete especial para gráficos combinados\n\n\n\n\nImportar datos\nPara empezar, importamos la lista de casos limpia de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio”, (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - ver la página de importación y exportación para más detalles).\n\n# importar linelist de casos \nlinelist_sym &lt;- import(\"linelist_cleaned.rds\")\n\nLinelist incluye cinco variables “yes/no” sobre los síntomas declarados. Tendremos que transformar un poco estas variables para utilizar el paquete ggupset para hacer nuestro gráfico. Para ver los datos desplázate a la derecha para ver las variables de los síntomas).\n\n\n\n\n\n\n\n\n\nReformular los valores\nPara alinearse con el formato esperado por ggupset, convertimos el “yes” y el “no” en el nombre real del síntoma, utilizando case_when() de dplyr. Si “no”, establecemos el valor en blanco, por lo que los valores son NA o el síntoma.\n\n# crear columna con los síntomas nombrados, separados por punto y coma\nlinelist_sym_1 &lt;- linelist_sym %&gt;% \n    # convertir los valores \"yes\" y \"no \" en el propio nombre del síntoma\n    # si el valor anterior es \"yes\", el nuevo valor es \"fever\", de lo contrario se establece como faltante (NA)\n     mutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n            chills = ifelse(chills == \"yes\", \"chills\", NA),\n            cough = ifelse(cough == \"yes\", \"cough\", NA),\n            aches = ifelse(aches == \"yes\", \"aches\", NA),\n            vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\n\nAhora hacemos dos columnas finales:\n\nConcatenando (pegar) todos los síntomas del paciente (una columna de caracteres)\nConviertiendo la columna anterior en una de tipo list, para que pueda ser aceptada por ggupset para hacer la trama\n\nConsulta la página sobre Caracteres y cadenas para saber más sobre la función unite() de stringr\n\nlinelist_sym_1 &lt;- linelist_sym_1 %&gt;% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %&gt;% \n  mutate(\n# crea una copia de la columna all_symptoms, pero de clase \"list\" (necesaria para usar ggupset() en el siguiente paso)\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )\n\nEn los datos nuevos observa las dos columnas del extremo derecho: los valores combinados pegados y la lista",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Análisis de combinaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.es.html#ggupset",
    "href": "new_pages/combination_analysis.es.html#ggupset",
    "title": "36  Análisis de combinaciones",
    "section": "36.2 ggupset",
    "text": "36.2 ggupset\nCarga el paquete\n\npacman::p_load(ggupset)\n\nCrear el gráfico. Comenzamos con ggplot() y geom_bar(), pero luego añadimos la función especial scale_x_upset() de ggupset.\n\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")\n\n\n\n\n\n\n\n\nPuedes encontrar más información sobre ggupset en línea o fuera de línea en la documentación del paquete en su pestaña de Ayuda de RStudio ?ggupset.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Análisis de combinaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.es.html#upsetr",
    "href": "new_pages/combination_analysis.es.html#upsetr",
    "title": "36  Análisis de combinaciones",
    "section": "36.3 UpSetR",
    "text": "36.3 UpSetR\nEl paquete UpSetR permite una mayor personalización del gráfico, pero puede ser más difícil de ejecutar:\nCargar paquete\n\npacman::p_load(UpSetR)\n\nLimpieza de datos\nDebemos convertir los valores de los síntomas de linelist en 1 / 0.\n\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n     # convierte los valores \"yes\" y \"no\" en 1s y 0s\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n\nSi está interesado en un comando más eficiente, puede aprovechar la función +(), que convierte en 1s y 0s basándose en una sentencia lógica. Este comando utiliza la función across() para cambiar varias columnas a la vez (lea más en Limpieza de datos y funciones básicas).\n\n# Convierte eficazmente \"yes\" en 1 y 0\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n  \n  # convierte los valores \"yes\" y \"no\" en 1s y 0s\n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n\nAhora haz el gráfico usando la función personalizada upset() - utilizando sólo las columnas de síntomas. Debes designar qué “conjuntos” comparar (los nombres de las columnas de síntomas). Alternativamente, utiliza nsets = y order.by = \"freq\" para mostrar sólo las X combinaciones principales.\n\n# Crea el gráfico\nlinelist_sym_2 %&gt;% \n  UpSetR::upset(\n       sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n       order.by = \"freq\",\n       sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n       empty.intersections = \"on\",\n       # nsets = 3,\n       number.angles = 0,\n       point.size = 3.5,\n       line.size = 2, \n       mainbar.y.label = \"Symptoms Combinations\",\n       sets.x.label = \"Patients with Symptom\")",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Análisis de combinaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.es.html#recursos-resources-29",
    "href": "new_pages/combination_analysis.es.html#recursos-resources-29",
    "title": "36  Análisis de combinaciones",
    "section": "36.4 Recursos {resources-29}",
    "text": "36.4 Recursos {resources-29}\nLa página de github de UpSetR\nUna versión de app Shiny: puedes cargar tus propios datos\n*documentación - difícil de interpretar",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Análisis de combinaciones</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.es.html",
    "href": "new_pages/transmission_chains.es.html",
    "title": "37  Cadenas de transmisión",
    "section": "",
    "text": "37.1 Resumen\nLa principal herramienta para manejar, analizar y visualizar las cadenas de transmisión y los datos de rastreo de contactos es el paquete epicontacts, desarrollado por la gente de RECON. Prueba con el gráfico interactivo que se muestra a continuación pasando el cursor por encima de los nodos para obtener más información, arrastrándolos para moverlos y clicando sobre ellos para resaltar los casos posteriores.\nWarning in epicontacts::make_epicontacts(linelist = linelist, contacts =\ncontacts, : Cycle(s) detected in the contact network: this may be unwanted",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Cadenas de transmisión</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.es.html#preparation-30",
    "href": "new_pages/transmission_chains.es.html#preparation-30",
    "title": "37  Cadenas de transmisión",
    "section": "37.2 Preparación",
    "text": "37.2 Preparación\n\nCargar paquetes\nPrimero carga los paquetes estándar necesarios para la importación y manipulación de datos. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También se pueden cargar paquetes con library() desde R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n   rio,          # Importación de ficheros\n   here,         # Localizador de ficheros\n   tidyverse,    # Gestión de datos + gráficos ggplot2\n   remotes       # Instalación de paquetes desde github\n)\n\nNecesitarás la versión de desarrollo de epicontacts, que puede instalarse desde github utilizando la función p_install_github() de pacman. Sólo necesitas ejecutar este comando una vez, no cada vez que utilizas el paquete (a partir de entonces, puedes utilizar sólo p_load()).\n\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n\n\nImportar datos\nImportamos el conjunto de datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso a paso, consulta las instrucciones en la página de descargando el manual y los datos. El conjunto de datos se importa utilizando la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.\n\n# importar linelist\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nA continuación se muestran las primeras 50 filas del listado. Son especialmente interesantes las columnas case_id, generation, infector, y source.\n\n\n\n\n\n\n\n\nCreación de un objeto epicontacts\nA continuación, tenemos que crear un objeto epicontacts, que requiere dos tipos de datos:\n\nun listado de casos en los que las columnas son variables y las filas corresponden a casos únicos\nuna lista de bordes que definen los vínculos entre los casos sobre la base de sus identificadores únicos (pueden ser contactos, eventos de transmisión, etc.)\n\nComo ya tenemos un listado, sólo tenemos que crear una lista de aristas entre los casos, más concretamente entre sus ID. Podemos extraer los enlaces de transmisión del listado vinculando la columna infector con la columna case_id. En este punto también podemos añadir “propiedades de borde”, con lo que nos referimos a cualquier variable que describa el vínculo entre los dos casos, no los casos en sí. Por ejemplo, añadiremos una variable location que describa la ubicación del evento de transmisión, y una variable de duración que describa la duración del contacto en días.\nEn el código siguiente, la función transmute() de dplyr es similar a mutate, excepto que sólo mantiene las columnas que hemos especificado dentro de la función. La función drop_na filtrará cualquier fila en la que las columnas especificadas tengan un valor NA; en este caso, sólo queremos mantener las filas en las que se conoce el infector.\n\n## generar contactos\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %&gt;%\n  drop_na(infector)\n\nAhora podemos crear el objeto epicontacts utilizando la función make_epicontacts. Necesitamos especificar qué columna del listado apunta al identificador único del caso, así como qué columnas de los contactos apuntan a los identificadores únicos de los casos involucrados en cada enlace. Estos enlaces son direccionales en el sentido de que la infección va del infector al caso, por lo que necesitamos especificar los argumentos from y to. Por lo tanto, también establecemos el argumento directed a TRUE, que afectará a las operaciones futuras.\n\n## generar el objeto epicontactos\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n\nWarning in make_epicontacts(linelist = linelist, contacts = contacts, id =\n\"case_id\", : Cycle(s) detected in the contact network: this may be unwanted\n\n\nAl examinar los objetos epicontacts, podemos ver que la columna case_id del listado ha sido renombrada a id y las columnas case_id e infector de los contactos han sido renombradas a from y to. Esto garantiza la coherencia en las operaciones posteriores de manipulación, visualización y análisis.\n\n## ver el objeto epicontactos\nepic\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 5,888 cases in linelist; 3,800 contacts; directed \n\n  // linelist\n\n# A tibble: 5,888 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 8689b7          4 NA             2014-05-13 2014-05-14           2014-05-18  \n 3 11f8ea          2 NA             2014-05-16 2014-05-18           2014-05-30  \n 4 b8812a          3 2014-05-04     2014-05-18 2014-05-20           NA          \n 5 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 be99c8          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 369449          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 f393b4          4 NA             2014-06-05 2014-06-06           2014-06-18  \n10 1389ca          4 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 3,800 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Community         9\n 2 f90f5f b8812a Community         9\n 3 11f8ea 893f25 Nosocomial        4\n 4 aec8ec be99c8 Nosocomial        3\n 5 893f25 07e3e8 Nosocomial        3\n 6 133ee7 369449 Nosocomial        1\n 7 996f3a 2978ac Nosocomial        5\n 8 133ee7 57a565 Community         3\n 9 37a6f6 fc15ef Community         2\n10 9f6884 2eaa9a Nosocomial        5\n# ℹ 3,790 more rows",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Cadenas de transmisión</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.es.html#handling",
    "href": "new_pages/transmission_chains.es.html#handling",
    "title": "37  Cadenas de transmisión",
    "section": "37.3 Manipulación",
    "text": "37.3 Manipulación\n\nSubconjunto\nEl método subset() para los objetos epicontacts permite, entre otras cosas, filtrar las redes en función de las propiedades del listado (“atributos de nodos”) y de la base de datos de contactos (“atributos de aristas”). Estos valores deben pasarse como listas con nombre al argumento respectivo. Por ejemplo, en el código que sigue mantenemos en linelist sólo los casos masculinos que tienen una fecha de infección entre abril y julio de 2014 (las fechas se especifican como rangos), y los enlaces de transmisión que se produjeron en el hospital.\n\nsub_attributes &lt;- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 69 cases in linelist; 1,928 contacts; directed \n\n  // linelist\n\n# A tibble: 69 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 3 2978ac          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15  \n 4 57a565          4 2014-05-28     2014-06-13 2014-06-15           NA          \n 5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09  \n 6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09  \n 7 f327be          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14  \n 8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16  \n 9 a47529          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26  \n10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01  \n# ℹ 59 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 1,928 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 11f8ea 893f25 Nosocomial        4\n 2 aec8ec be99c8 Nosocomial        3\n 3 893f25 07e3e8 Nosocomial        3\n 4 133ee7 369449 Nosocomial        1\n 5 996f3a 2978ac Nosocomial        5\n 6 9f6884 2eaa9a Nosocomial        5\n 7 4802b1 bbfa93 Nosocomial       10\n 8 8e104d ddddee Nosocomial        7\n 9 5d9e4d 8bd1e8 Nosocomial        5\n10 a15e13 f327be Nosocomial       10\n# ℹ 1,918 more rows\n\n\nPodemos utilizar la función thin para filtrar linelist para incluir los casos que se encuentran en los contactos estableciendo el argumento what = \"linelist\", o filtrar los contactos para incluir los casos que se encuentran en linelist estableciendo el argumento what = \"contacts\". En el código siguiente, filtramos aún más el objeto epicontactos para mantener sólo los enlaces de transmisión que implican los casos masculinos infectados entre abril y julio que habíamos filtrado anteriormente. Podemos ver que sólo dos enlaces de transmisión conocidos se ajustan a esa especificación.\n\nsub_attributes &lt;- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)\n\n[1] 4\n\n\nAdemás de la subdivisión por atributos de nodos y aristas, las redes pueden podarse para incluir sólo los componentes que están conectados a ciertos nodos. El argumento cluster_id toma un vector de IDs de casos y devuelve linelist de individuos que están vinculados, directa o indirectamente, a esos IDs. En el código siguiente, podemos ver que un total de 13 casos del listado están involucrados en los clusters que contienen 2ae019 y 71577a.\n\nsub_id &lt;- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)\n\n[1] 13\n\n\nEl método subset() para los objetos epicontacts también permite filtrar por tamaño de cluster usando los argumentos cs, cs_min y cs_max. En el código siguiente, estamos manteniendo sólo los casos vinculados a clusters de 10 casos o más, y podemos ver que 271 casos del listado están involucrados en tales clusters.\n\nsub_cs &lt;- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)\n\n[1] 271\n\n\n\n\nAcceso a los IDs\nLa función get_id() recupera información sobre los ID de los casos en el conjunto de datos, y puede parametrizarse como sigue:\n\nlinelist: IDs en los datos del listado\ncontacts: IDs en el conjunto de datos de los contactos (“desde” y “hasta” combinados)\nfrom: IDs en la columna “from” de los datos del contacto\nto los identificadores de la columna “a” de los datos de los contactos\nall: Las identificaciones que aparecen en cualquier parte de cualquiera de los conjuntos de datos\ncommon: identificaciones que aparecen tanto en el conjunto de datos de contactos como en linelist\n\nPor ejemplo, ¿cuáles son las diez primeras identificaciones de los datos de contactos?\n\ncontacts_ids &lt;- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)\n\n [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\"\n [9] \"9f6884\" \"4802b1\"\n\n\n¿Cuántas identificaciones se encuentran tanto en linelist como en los contactos?\n\nlength(get_id(epic, \"common\"))\n\n[1] 4352",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Cadenas de transmisión</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.es.html#visualization",
    "href": "new_pages/transmission_chains.es.html#visualization",
    "title": "37  Cadenas de transmisión",
    "section": "37.4 Visualización",
    "text": "37.4 Visualización\n\nRepresentación básica\nTodas las visualizaciones de los objetos epicontacts son manejadas por la función plot. En primer lugar, filtraremos el objeto epicontacts para incluir solo los casos con fechas de inicio en junio de 2014 utilizando la función de subconjunto, y solo incluiremos los contactos vinculados a esos casos utilizando la función thin.\n\n## subconjunto objeto epicontactos\nsub &lt;- epic %&gt;%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %&gt;%\n thin(\"contacts\")\n\nA continuación, podemos crear el gráfico básico e interactivo de la siguiente manera:\n\n## dibuja el objeto epicontactos\nplot(\n  sub,\n  width = 700,\n  height = 700\n)\n\n\n\n\n\nPuedes mover los nodos arrastrándolos, pasar por encima de ellos para obtener más información y clicar sobre ellos para resaltar los casos conectados.\nHay un gran número de argumentos para modificar este gráfico. Aquí cubriremos los principales, pero consulta la documentación a través de ?vis_epicontacts (la función a la que se llama cuando se utiliza plot en un objeto epicontacts) para obtener una descripción completa de los argumentos de la función.\n\nVisualizar los atributos de los nodos\nEl color, la forma y el tamaño del nodo se pueden asignar a una columna determinada en linelist utilizando los argumentos node_color, node_shape y node_size. Esto es similar a la sintaxis aes que puede reconocer ggplot2.\nLos colores, formas y tamaños específicos de los nodos pueden especificarse de la siguiente manera:\n\nColores a través del argumento col_pal, ya sea proporcionando una lista de nombres para la especificación manual de cada color como se hace a continuación, o proporcionando una función de paleta de colores como colorRampPalette(c(\"black\", \"red\", \"orange\")), que proporcionaría un gradiente de colores entre los especificados.\nFormas pasando una lista con nombre al argumento shapes, especificando una forma para cada elemento único en la columna del listado especificada por el argumento node_shape. Ver en codeawesome las formas disponibles.\nTamaño pasando un rango de tamaño de los nodos al argumento size_range.\n\nAquí un ejemplo, donde el color representa el resultado, la forma el género y el tamaño la edad:\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nVisualizar los atributos de los bordes\nEl color, tamaño y el tipo de línea de los bordes pueden asignarse a una columna determinada del dataframe de los contactos utilizando los argumentos edge_color, edge_width y edge_linetype. Los colores y tamaño específicos de los bordes se pueden especificar como sigue:\n\nColores a través del argumento edge_col_pal, de la misma manera que se utiliza para col_pal.\nTamaño pasando un rango de tamaño de los nodos al argumento width_range.\n\nAquí un ejemplo:\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\n\nEje temporal\nTambién podemos visualizar la red a lo largo de un eje temporal asignando el argumento x_axis a una columna del listado. En el ejemplo siguiente, el eje-x representa la fecha de inicio de los síntomas. También hemos especificado el argumento arrow_size para asegurarnos que las flechas no son demasiado grandes, y hemos establecido label = FALSE para que la figura esté menos recargada.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nHay un gran número de argumentos adicionales para especificar aún más cómo se visualiza esta red a lo largo de un eje temporal, que puede comprobar a través de ?vis_temporal_interactive (la función que se llama cuando se utiliza plot en un objeto epicontacts con el x_axis especificado). A continuación veremos algunos.\n\nEspecificar la forma del árbol de transmisión\nHay dos formas principales que puede adoptar el árbol de transmisión, especificadas mediante el argumento network_shape. La primera es una forma ramificada, como se muestra arriba, en la que un borde recto conecta dos nodos cualesquiera. Esta es la representación más intuitiva, pero puede dar lugar a la superposición de aristas en una red densamente conectada. La segunda forma es rectangle, que produce un árbol parecido a una filogenia. Por ejemplo:\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nA cada nodo del caso se le puede asignar una posición vertical única mediante el argumento position_dodge. La posición de los casos no conectados (es decir, sin contactos reportados) se especifica utilizando el argumento unlinked_pos.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nLa posición del nodo padre respecto a los nodos hijos puede especificarse mediante el argumento parent_pos. La opción por defecto es colocar el nodo padre en el centro, sin embargo puede colocarse en la parte inferior (parent_pos = 'bottom') o en la parte superior (parent_pos = 'top').\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nCómo guardar gráficos y valores\nPuedes guardar un gráfico como un archivo html interactivo y autónomo con la función visSave del paquete VisNetwork:\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %&gt;%\n  visNetwork::visSave(\"network.html\")\n\nGuardar estas salidas de red como una imagen es desafortunadamente menos fácil y requiere que guardes el archivo como un html y luego tomes una captura de pantalla de este archivo usando el paquete webshot. En el código siguiente, estamos convirtiendo el archivo html guardado anteriormente en un PNG:\n\nwebshot(url = \"network.html\", file = \"network.png\")\n\n\n\n\nLíneas de tiempo\nTambién se pueden incluir líneas de tiempo en la red, que se representan en el eje de abscisas de cada caso. Esto puede servir para visualizar la ubicación de los casos, por ejemplo, o el tiempo hasta el resultado. Para generar una línea de tiempo, tenemos que crear un data.frame de al menos tres columnas que indiquen el ID del caso, la fecha de inicio del “evento” y la fecha de finalización del “evento”. También se puede añadir cualquier número de otras columnas que luego se pueden asignar a las propiedades de los nodos y aristas de la línea de tiempo. En el código siguiente, generamos una línea de tiempo que va desde la fecha de inicio de los síntomas hasta la fecha del desenlace, y mantenemos las variables de desenlace y hospital que utilizamos para definir la forma y el color de los nodos. Ten en cuenta que puede tener más de una fila/evento de la línea de tiempo por caso, por ejemplo si un caso es transferido entre varios hospitales.\n\n## generar la línea temporal\ntimeline &lt;- linelist %&gt;%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n\nA continuación, pasamos el elemento de la línea de tiempo al argumento timeline. Podemos mapear los atributos de la línea de tiempo a los colores, formas y tamaños de los nodos de la línea de tiempo de la misma manera definida en las secciones anteriores, excepto que tenemos dos nodos: el nodo de inicio y el nodo final de cada línea de tiempo, que tienen argumentos separados. Por ejemplo, tl_start_node_color define qué columna de la línea de tiempo se asigna al color del nodo inicial, mientras que tl_end_node_shape define qué columna de la línea de tiempo se asigna a la forma del nodo final. También podemos asignar el color, la anchura, el tipo de línea y las etiquetas al borde de la línea de tiempo mediante los argumentos tl_edge_.\nConsulta ?vis_temporal_interactive (la función a la que se llama cuando se traza un objeto epicontacto) para obtener documentación detallada sobre los argumentos. Cada argumento está anotado también en el código de abajo:\n\n## define las formas\nshapes &lt;- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define los colores\ncolours &lt;- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## realizar el gráfico\nplot(\n  sub,\n  ## coordenada x máxima a la fecha de inicio\n  x_axis = \"date_onset\",\n  ## utiliza una forma de red rectangular\n  network_shape = \"rectangle\",\n  ## asigna las formas de los nodos a la columna de género\n  node_shape = \"gender\",\n  ## no queremos asignar el color del nodo a ninguna columna - esto es importante ya que el\n  ## valor por defecto es asignar al id del nodo, lo que desordenará el esquema de color\n  node_color = NULL,\n  ## establecer el tamaño del nodo caso a 30 (como no es un caracter, node_size no es\n  ## asignado a una columna sino que se interpreta como el tamaño real del nodo)\n  node_size = 30,\n  ## establece la anchura del enlace de transmisión en 4 (como no es un carácter, edge_width \n  ## no se asigna a una columna, sino que se interpreta como la anchura real del borde).\n  edge_width = 4,\n  ## proporciona el objeto timeline\n  timeline = timeline,\n  ## asigna la forma del nodo final a la columna del resultado en el objeto timeline\n  tl_end_node_shape = \"outcome\",\n  ## establece el tamaño del nodo final en 15 (como no es un carácter, este\n  ## argumento no se asigna a una columna sino que se interpreta como el\n  ## tamaño real del nodo)\n  tl_end_node_size = 15,\n  ## asigna el color del borde de timeline a la columna hospital\n  tl_edge_color = \"hospital\",\n  ## establece el ancho del borde de la línea de tiempo en 2 (como no es un carácter, este argumento \n  ## argumento no se asigna a una columna, sino que se interpreta como la anchura real\n  ## del borde).\n  tl_edge_width = 2,\n  ## asigna las etiquetas de los bordes a la variable hospital\n  tl_edge_label = \"hospital\",\n  ## especifica la forma para cada atributo de nodo (definido anteriormente)\n  shapes = shapes,\n  ## especifica la paleta de colores (definida anteriormente)\n  col_pal = colours,\n  ## establece el tamaño de la flecha en 0.5\n  arrow_size = 0.5,\n  ## usa dos columnas en la leyenda\n  legend_ncol = 2,\n  ## establece el tamaño de la fuente\n  font_size = 15,\n  ## define el formato de las fechas\n  date_labels = c(\"%d %b %Y\"),\n  ## no muestra las etiquetas ID debajo de los nodos\n  label = FALSE,\n  ## especifica la altura\n  height = 1000,\n  ## especifica la anchura\n  width = 1200,\n  ## asegura que cada nodo case tiene una única coordenada y - esto es muy importante\n  ## cuando se utilizan líneas de tiempo, de lo contrario tendrá líneas de tiempo superpuestas de\n  ## diferentes casos\n  position_dodge = TRUE\n)\n\nWarning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed\nas ID not found in linelist or start/end date is NA",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Cadenas de transmisión</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.es.html#analysis",
    "href": "new_pages/transmission_chains.es.html#analysis",
    "title": "37  Cadenas de transmisión",
    "section": "37.5 Análisis",
    "text": "37.5 Análisis\n\nResumiendo\nPodemos obtener una visión general de algunas de las propiedades de la red utilizando la función summary.\n\n## resume el objeto epicontactos\nsummary(epic)\n\n\n/// Overview //\n  // number of unique IDs in linelist: 5888\n  // number of unique IDs in contacts: 5511\n  // number of unique IDs in both: 4352\n  // number of contacts: 3800\n  // contacts with both cases in linelist: 56.868 %\n\n/// Degrees of the network //\n  // in-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n\n  // out-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n\n  // in and out degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   1.000   1.078   1.000   7.000 \n\n/// Attributes //\n  // attributes in linelist:\n generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n\n  // attributes in contacts:\n location duration\n\n\nPor ejemplo, podemos ver que sólo el 57% de los contactos tienen ambos casos en linelist; esto significa que no tenemos datos del listado sobre un número significativo de casos involucrados en estas cadenas de transmisión.\n\n\nCaracterísticas de los pares\nLa función get_pairwise() permite procesar la(s) variable(s) del listado según cada par de los datos de contactos. En el siguiente ejemplo, la fecha de inicio de la enfermedad se extrae del listado para calcular la diferencia entre la fecha de inicio de la enfermedad para cada par. El valor que se obtiene de esta comparación representa el intervalo de serie (si).\n\nsi &lt;- get_pairwise(epic, \"date_onset\")   \nsummary(si)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    5.00    9.00   11.01   15.00   99.00    1820 \n\ntibble(si = si) %&gt;%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1820 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nLa función get_pairwise() interpretará el tipo de la columna que se utiliza para la comparación, y ajustará su método de comparación de los valores en consecuencia. Para los números y las fechas (como en el ejemplo de si), la función restará los valores. Cuando se aplica a columnas que son caracteres o categóricas, get_pairwise() pegará los valores. Dado que la función también permite un procesamiento arbitrario (véase el argumento “f”), estas combinaciones discretas pueden ser fácilmente tabuladas y analizadas.\n\nhead(get_pairwise(epic, \"gender\"), n = 10)\n\n [1] \"f -&gt; m\" NA       \"m -&gt; m\" NA       \"m -&gt; f\" \"f -&gt; f\" NA       \"f -&gt; m\"\n [9] NA       \"m -&gt; f\"\n\nget_pairwise(epic, \"gender\", f = table)\n\n           values.to\nvalues.from   f   m\n          f 464 516\n          m 510 468\n\nfisher.test(get_pairwise(epic, \"gender\", f = table))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  get_pairwise(epic, \"gender\", f = table)\np-value = 0.03758\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6882761 0.9892811\nsample estimates:\nodds ratio \n 0.8252575 \n\n\nEn este caso, se observa una asociación significativa entre los vínculos de transmisión y el género.\n\n\nIdentificación de clusters\nLa función get_clusters() puede utilizarse para identificar componentes conectados en un objeto epicontacts. En primer lugar, la utilizamos para recuperar un data.frame que contenga la información de los clusters:\n\nclust &lt;- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42 \n\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\nVeamos los clusters más grandes. Para ello, añadimos la información de los clústers al objeto epicontacts y luego lo subconjuntamos para mantener sólo los clústers más grandes:\n\nepic &lt;- get_clusters(epic)\nmax_size &lt;- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))\n\n\n\n\n\n\n\nCálculo de grados\nEl grado de un nodo corresponde a su número de aristas o conexiones con otros nodos. get_degree() proporciona un método sencillo para calcular este valor para las redes de epicontacts. Un grado alto en este contexto indica un individuo que estuvo en contacto con muchos otros. El argumento type indica que queremos contar tanto el grado de entrada como el de salida, el argumento only_linelist indica que sólo queremos calcular el grado para los casos del listado.\n\ndeg_both &lt;- get_degree(epic, type = \"both\", only_linelist = TRUE)\n\n¿Qué personas son las que tienen más de 10 contactos?\n\nhead(sort(deg_both, decreasing = TRUE), 10)\n\n916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n     7      6      6      6      5      5      5      5      5      5 \n\n\n¿Cuál es el número medio de contactos?\n\nmean(deg_both)\n\n[1] 1.078473",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Cadenas de transmisión</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.es.html#resources-30",
    "href": "new_pages/transmission_chains.es.html#resources-30",
    "title": "37  Cadenas de transmisión",
    "section": "37.6 Recursos",
    "text": "37.6 Recursos\nLa página de epicontacts ofrece una visión general de las funciones del paquete e incluye algunas viñetas más detalladas.\nLa página de github de epicontacts puede utilizarse para plantear problemas y solicitar funciones.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Cadenas de transmisión</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.es.html",
    "href": "new_pages/phylogenetic_trees.es.html",
    "title": "38  Árboles filogenéticos",
    "section": "",
    "text": "38.1 Resumen\nLos árboles filogenéticos se utilizan para visualizar y describir el parentesco y la evolución de los organismos a partir de la secuencia de su código genético.\nPueden construirse a partir de secuencias genéticas utilizando métodos basados en la distancia (como el método de unión de vecinos) o métodos basados en los caracteres (como el método de máxima verosimilitud y el método Bayesiano Markov Chain Monte Carlo). La secuenciación de nueva generación (NGS, por sus siglas en inglés) se ha vuelto más económica y se está utilizando cada vez más en el área de salud pública para describir los patógenos causantes de enfermedades infecciosas. Los dispositivos de secuenciación portátil reducen el tiempo de respuesta y prometen facilitar los datos en tiempo real y así apoyar la investigación de brotes. Los datos de NGS se pueden utilizar para identificar el origen o la fuente de una cepa de un brote y su propagación, así como para determinar la presencia de genes de resistencia antimicrobiana. Para visualizar el parentesco genético entre muestras biológicas se construye un árbol filogenético.\nAquí aprenderemos a utilizar el paquete ggtree, que permite la visualización combinada de árboles filogenéticos con datos de muestra adicionales en forma de dataframe. Esto nos permitirá observar patrones y comprender mejor la dinámica de los brotes.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Árboles filogenéticos</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.es.html#preparation-31",
    "href": "new_pages/phylogenetic_trees.es.html#preparation-31",
    "title": "38  Árboles filogenéticos",
    "section": "38.2 Preparación",
    "text": "38.2 Preparación\n\nCargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios. En este manual destacamos ‘p_load()’ de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,             # importa/exportar\n  here,            # rutas de fichero relativas\n  tidyverse,       # manejo general de datos y visualización\n  ape,             # para importar y exportar archivos filogenéticos\n  ggtree,          # para visualizar archivos filogenéticos\n  treeio,          # para visualizar archivos filogenéticos\n  ggnewscale)      # para añadir capas adicionales de esquemas de color\n\n\n\nImportar datos\nLos datos de esta página pueden descargarse con las instrucciones de la página Descargando el manual y los datos.\nHay varios formatos diferentes en los que se puede almacenar un árbol filogenético (por ejemplo, Newick, NEXUS, Phylip). Uno de los más comunes es el formato de archivo Newick (.nwk), que es el estándar para representar árboles en forma legible por el ordenador. Esto significa que un árbol completo puede expresarse en un formato de cadena como “((t2:0,04,t1:0,34):0,89,(t5:0,37,(t4:0,03,t3:0,67):0,9):0,59);”, enumerando todos los nodos y puntas, y su relación (longitud de rama) entre sí.\nNota: Es importante entender que el archivo del árbol filogenético en sí mismo no contiene datos de secuenciación, sino que es simplemente el resultado de las distancias genéticas entre las secuencias. Por lo tanto, no podemos extraer datos de secuenciación de un archivo de árbol.\nEn primer lugar, utilizamos la función read.tree() del paquete ape para importar un archivo de árbol filogenético de Newick en formato .txt, y lo almacenamos en un objeto tipo lista llamado “phylo”. Si es necesario, utiliza la función here() del paquete here para especificar la ruta relativa del archivo.\nNota: En este caso el árbol newick se guarda como un archivo .txt para facilitar su manejo y descarga desde Github.\n\ntree &lt;- ape::read.tree(\"Shigella_tree.txt\")\n\nInspeccionamos nuestro objeto árbol (‘tree’) y vemos que contiene 299 puntas (o muestras) y 236 nodos.\n\ntree\n\n\nPhylogenetic tree with 299 tips and 236 internal nodes.\n\nTip labels:\n  SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\nNode labels:\n  17, 29, 100, 67, 100, 100, ...\n\nRooted; includes branch lengths.\n\n\nEn segundo lugar, importamos una tabla almacenada en un archivo .csv con información adicional para cada muestra secuenciada, como el sexo, el país de origen y los atributos de resistencia antimicrobiana, utilizando la función import() del paquete rio:\n\nsample_data &lt;- import(\"sample_data_Shigella_tree.csv\")\n\nA continuación se muestran las primeras 50 filas de los datos:\n\n\n\n\n\n\n\n\nLimpiar e inspeccionar\nLimpiamos e inspeccionamos nuestros datos: Para asignar los datos de muestra correctos al árbol filogenético, los valores de la columna Sample_ID en el dataframe sample_data deben coincidir con los valores de tip.labels en el archivo tree:\nComprobamos el formato de los tip.labels en el archivo de árbol mirando las 6 primeras entradas usando head() de R base.\n\nhead(tree$tip.label) \n\n[1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\"\n[6] \"S17BD05939\"\n\n\nTambién nos aseguramos de que la primera columna de nuestro dataframe sample_data sea Sample_ID. Miramos los nombres de las columnas de nuestro dataframe utilizando colnames() de R base.\n\ncolnames(sample_data)   \n\n [1] \"Sample_ID\"                  \"serotype\"                  \n [3] \"Country\"                    \"Continent\"                 \n [5] \"Travel_history\"             \"Year\"                      \n [7] \"Belgium\"                    \"Source\"                    \n [9] \"Gender\"                     \"gyrA_mutations\"            \n[11] \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n[13] \"MIC_CIP\"                   \n\n\nMiramos los Sample_IDs en el dataframe para asegurarnos de que el formato es el mismo que en el tip.label (por ejemplo, las letras son todas mayúsculas, no hay barras bajas adicionales _ entre las letras y los números, etc.)\n\nhead(sample_data$Sample_ID) # volvemos a inspeccionar sólo los 6 primeros usando head()\n\n[1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\"\n[6] \"S18BD02657\"\n\n\nTambién podemos comparar si todas las muestras están presentes en el archivo tree y viceversa, generando un vector lógico de TRUE o FALSE donde coinciden o no. Estos no se imprimen aquí, para simplificar.\n\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\n\nPodemos utilizar estos vectores para mostrar cualquier ID que no esté en el árbol (no hay ninguno).\n\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]\n\ncharacter(0)\n\n\nAl inspeccionar podemos ver que el formato de Sample_ID en el dataframe corresponde al formato de los nombres de las muestras en el tip.labels. No es necesario que estén clasificados en el mismo orden para que coincidan.\nEstamos listos para empezar!",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Árboles filogenéticos</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.es.html#simple-tree-visualization",
    "href": "new_pages/phylogenetic_trees.es.html#simple-tree-visualization",
    "title": "38  Árboles filogenéticos",
    "section": "38.3 Visualización simple de un árbol",
    "text": "38.3 Visualización simple de un árbol\n\nDiferentes configuraciones de los árboles\nggtree ofrece varios formatos de presentación y algunos pueden ser más adecuados que otros dependiendo del propósito específico. A continuación se muestran algunos ejemplos. Para otras opciones, consulta este libro en línea.\nA continuación, vemos algunos ejemplos de configuración de árboles:\n\nggtree(tree)                                            # árbol lineal simple\nggtree(tree,  branch.length = \"none\")                   # árbol lineal simple con todas las puntas alineadas\nggtree(tree, layout=\"circular\")                         # árbol circular simple\nggtree(tree, layout=\"circular\", branch.length = \"none\") # árbol circular simple con todas las puntas alineadas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÁrbol simple con datos de muestra\nEl operador %&lt;+% se utiliza para conectar el dataframe sample_data con el archivo tree. La anotación más sencilla de un árbol es el agregado de los nombres de las muestras en las puntas, así como la coloración de las puntas y, si se desea, de las ramas:\nEste es un ejemplo de árbol circular:\n\nggtree(tree, layout = \"circular\", branch.length = 'none') %&lt;+% sample_data + # %&lt;+% agrega un dataframe con datos de muestra al árbol\n  aes(color = Belgium)+                       # colorea las ramas de acuerdo con una variable en tu dataframe\n  scale_color_manual(\n    name = \"Sample Origin\",                      # nombre de tu esquema de color (aparecerá en la leyenda así) \n    breaks = c(\"Yes\", \"No\"),                     # las diferentes opciones en tu variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # cómo quieres que se nombren las diferentes opciones en tu leyenda, permite formatearlas\n    values = c(\"blue\", \"black\"),                 # el color que deseas asignar a la variable  \n    na.value = \"black\") +                        # colorea los valores no disponibles (NA) en negro \n  new_scale_color()+                             # permite añadir un esquema de color adicional para otra variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # color de la punta por continente Puedes cambiar la forma añadiendo \"shape = \"\n      size = 1.5)+                               # define el tamaño de la punta\n  scale_color_brewer(\n    name = \"Continent\",                    # nombre de tu esquema de color (se mostrará en la leyenda así)\n    palette = \"Set1\",                      # elegimos un conjunto de colores que vienen con el paquete de Brewer\n    na.value = \"grey\") +                    # para los valores NA elegimos el color gris\n  geom_tiplab(                             # añade el nombre de la muestra en la punta de su rama \n    color = 'black',                       # añade tantas líneas de texto como desees con + , pero es posible que tengas que ajustar el valor de desplazamiento para colocarlas una al lado de la otra\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    #align = TRUE\n    )+    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # Nombre del árbol\n  theme(\n    axis.title.x = element_blank(), # elimina el título del eje x\n    axis.title.y = element_blank(), # elimina el título del eje y\n    legend.title = element_text(    # define el tamaño y el formato de la fuente del título de la leyenda\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # define el tamaño de letra y tipografía de la leyenda\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # define el tamaño de letra y tipografía del título del gráfico\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # define la posición de la leyenda\n    legend.box = \"vertical\",        # define la posición de la leyenda\n    legend.margin = margin())   \n\n\n\n\n\n\n\n\nPodes exportar el gráfico de árbol con ggsave() como lo harías con cualquier otro objeto ggplot. Escrito de esta manera, ggsave() guarda la última imagen producida en la ruta de archivo que especifiques. Recordá que podes utilizar here() y rutas de archivo relativas para guardar fácilmente en subcarpetas, etc.\n\nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Árboles filogenéticos</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.es.html#tree-manipulation",
    "href": "new_pages/phylogenetic_trees.es.html#tree-manipulation",
    "title": "38  Árboles filogenéticos",
    "section": "38.4 Manipulación de árboles",
    "text": "38.4 Manipulación de árboles\nA veces puede tener un árbol filogenético muy grande y sólo le interesa una parte del árbol. Por ejemplo, si ha creado un árbol que incluye muestras históricas o internacionales para obtener una gran visión general sobre como pueden encajar tus datos en esos contextos. Pero luego, para ver más de cerca alguna parte tus datos, tendrás que inspeccionar sólo esa parte del árbol.\nDado que el archivo del árbol filogenético es el resultado del análisis de los datos de secuenciación, no podemos manipular el orden de los nodos y las ramas en el propio archivo. Estos ya han sido determinados en análisis anteriores a partir de los datos NGS en bruto. Sin embargo, podemos ampliar partes, ocultar partes e incluso subdividir partes del árbol.\n\nAmpliar el zoom\nSi en vez de “cortar” tu árbol, prefieres inspeccionar sólo una parte más de cerca, puedes hacer zoom para ver una parte específica.\nEn primer lugar, trazamos todo el árbol en formato lineal y añadimos etiquetas numéricas a cada nodo del árbol.\n\np &lt;- ggtree(tree,) %&lt;+% sample_data +\n  geom_tiplab(size = 1.5) +                # etiqueta las puntas de todas las ramas del árbol con el nombre de la muestra\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # etiqueta todos los nodos del árbol\n\np  # imprime en pantalla\n\n\n\n\n\n\n\n\nPara hacer zoom en una rama en particular (la que sobresale a la derecha), utilizá viewClade() en el objeto ggtree p y proporcioná el número de nodo para verlo más de cerca:\n\nviewClade(p, node = 452)\n\n\n\n\n\n\n\n\n\n\nRamas colapsadas\nSin embargo, tal vez queramos ignorar esta rama, entonces podemos colapsarla en ese mismo nodo (nodo 452) utilizando collapse(). Definimos este árbol como p_collapsed.\n\np_collapsed &lt;- collapse(p, node = 452)\np_collapsed\n\n\n\n\n\n\n\n\nComo aclaración, cuando imprimimos p_collapsed, añadimos un geom_point2() (un diamante azul) en el nodo de la rama colapsada.\n\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # asignamos un símbolo al nodo colapsado\n            size = 5,                     # definimos el tamaño del símbolo\n            shape = 23,                   # definimos la forma del símbolo\n            fill = \"steelblue\")           # definimos el color del símbolo\n\n\n\n\n\n\n\n\n\n\nSubconjunto de un árbol\nSi queremos hacer un cambio más permanente y crear un nuevo árbol reducido con el que trabajar, podemos subconjuntar parte de él con tree_subset(). Luego podemos guardarlo como un nuevo archivo de árbol newick o archivo .txt.\nEn primer lugar, inspeccionamos los nodos del árbol y las etiquetas de las puntas para decidir qué subconjunto se va a seleccionar.\n\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %&lt;+% sample_data +               # añade los datos de la muestra usando el operador %&lt;+%\n  geom_tiplab(size = 1)+                                # etiqueta las puntas de todas las ramas del árbol con el nombre de la muestra\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # etiqueta todos los nodos del árbol\n theme(\n   legend.position = \"none\",                            # elimina la leyenda\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\n\n\n\n\n\n\n\n\nAhora, digamos que hemos decidido crear un un subconjunto del árbol (o sub-árbol) con solo el nodo 528 (manteniendo las puntas dentro de esta rama después del nodo 528) y lo guardamos como un nuevo objeto sub_tree1:\n\nsub_tree1 &lt;- tree_subset(\n  tree,\n  node = 528)                                            #Subconjuntamos el árbol en el nodo 528\n\nVeamos el subconjunto del árbol 1:\n\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\n\n\n\n\n\n\n\n\nTambién podes hacer un subconjunto basado en una muestra en particular, especificando cuántos nodos “hacia atrás” queres incluir. Vamos a subconjuntar la misma parte del árbol basándonos en una muestra, en este caso S17BD07692, retrocediendo 9 nodos y lo guardamos como un nuevo objeto sub_tree2:\n\nsub_tree2 &lt;- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back define cuántos nodos hacia atrás quieres ir desde la punta de la muestra\n\nVeamos el subconjunto del árbol 2:\n\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n\n\n\n\n\n\n\n\nTambién podes guardar tu nuevo sub-árbol como un archivo Newick o incluso un archivo de texto utilizando la función write.tree() del paquete ape:\n\n# para guardar en formato .nwk \nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# para guardar en formato  .txt\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')\n\n\n\nRotación de nodos en un árbol\nComo ya hemos dicho, no podemos cambiar el orden de las puntas o de los nodos en el árbol, ya que éste se basa en su parentesco genético y no está sujeto a manipulación visual. Pero podemos rotar las ramas alrededor de los nodos si eso facilita la visualización.\nEn primer lugar, trazamos nuestro nuevo sub-árbol 2 con las etiquetas de los nodos para elegir el nodo que queremos manipular y lo almacenamos en un objeto de ggtree plot p.\n\np &lt;- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # etiqueta todos los nodos del árbol\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\n\n\n\n\n\n\n\n\nLuego podemos manipular los nodos aplicando ggtree::rotate() o ggtree::flip(): Nota: para ilustrar qué nodos estamos manipulando aplicamos primero la función geom_hilight() de ggtree para resaltar las muestras en los nodos que nos interesan y almacenamos ese objeto gráfico de ggtree en un nuevo objeto p1.\n\np1 &lt;- p + geom_hilight(  # resalta el nodo 39 en azul, \"extend =\" permite definir la longitud del bloque de color\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # resalta el nodo 37 en amarillo\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # imprime en pantalla\n\n\n\n\n\n\n\n\nAhora podemos rotar el nodo 37 en el objeto p1 para que las muestras del nodo 38 se muevan hacia abajo. Almacenamos el árbol rotado en un nuevo objeto p2\n\np2 &lt;- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # imprime en pantalla\n\n\n\n\n\n\n\n\nO podemos usar el comando flip para rotar el nodo 36 en el objeto p1 y mover el nodo 37 a la parte superior y el nodo 39 a la parte inferior. Almacenamos el árbol con nodos rotados como un nuevo objeto p3.\n\np3 &lt;- ggtree::flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # imprime en pantalla\n\n\n\n\n\n\n\n\n\n\nEjemplo de sub-árbol con anotación de datos\nDigamos que estamos investigando el grupo de casos con expansión clonal que se produjo en 2017 y 2018 representados en el nodo 39 de nuestro sub-árbol. Añadimos el año de aislamiento de la cepa, así como el historial de viajes y coloreamos por país para ver el origen de otras cepas estrechamente relacionadas genéticamente:\n\nggtree(sub_tree2) %&lt;+% sample_data +     # usamos el operador %&lt;+% para enlazar con sample_data\n  geom_tiplab(                          # etiqueta las puntas de todas las ramas del árbol con el nombre de la muestra\n    size = 2.5,\n    offset = 0.001,\n    #align = TRUE\n    ) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # establece los límites del eje x de nuestro árbol\n  geom_tippoint(aes(color=Country),     # colorea la punta por continente\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                         # añade el año de aislamiento como etiqueta de texto en las puntas\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    #align = TRUE\n    )+ \n  geom_tiplab(                          # añade el historial de viajes como una etiqueta de texto en las puntas, en color rojo\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    #align = TRUE\n    )+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # añade el título del árbol\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                   # añade una etiqueta en el eje x\n \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\nNuestra observación apunta a un evento de importación de cepas procedentes de Asia, que luego circularon en Bélgica a lo largo de los años y parecen haber causado el último brote.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Árboles filogenéticos</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.es.html#more-complex-trees-adding-heatmaps-of-sample-data",
    "href": "new_pages/phylogenetic_trees.es.html#more-complex-trees-adding-heatmaps-of-sample-data",
    "title": "38  Árboles filogenéticos",
    "section": "38.5 Árboles más complejos: añadir mapas térmicos de datos de muestra",
    "text": "38.5 Árboles más complejos: añadir mapas térmicos de datos de muestra\nPodemos añadir información más compleja, como la presencia categórica de genes de resistencia antimicrobiana y valores numéricos de resistencia realmente medida contra agentes antimicrobianos en forma de mapa de calor utilizando la función ggtree::gheatmap().\nPrimero necesitamos graficar nuestro árbol (puede ser lineal o circular) y almacenarlo en un nuevo objeto ggtree p: Utilizaremos el sub-árbol de la parte 3).\n\np &lt;- ggtree(sub_tree2, branch.length='none', layout='circular') %&lt;+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\n\n\n\n\n\n\n\n\nEn segundo lugar, preparamos nuestros datos. Para visualizar las diferentes variables con nuevos esquemas de color, realizamos un subconjunto de nuestro dataframe a la variable deseada. Es importante añadir el Sample_ID como nombre de fila (rownames) de lo contrario los datos no coinciden con los tip.labels del árbol.\nEn nuestro ejemplo, queremos ver el género y las mutaciones que podrían conferir resistencia a la ciprofloxacina, un importante antibiótico de primera línea utilizado para tratar las infecciones por Shigella.\nCreamos un dataframe para el género:\n\ngender &lt;- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) &lt;- sample_data$Sample_ID\n\nCreamos un dataframe para las mutaciones en el gen gyrA, que confieren resistencia a la ciprofloxacina:\n\ncipR &lt;- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) &lt;- sample_data$Sample_ID\n\nCreamos un dataframe para la concentración inhibitoria mínima (CIM) medida en laboratorio para la ciprofloxacina:\n\nMIC_Cip &lt;- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) &lt;- sample_data$Sample_ID\n\nCreamos un primer gráfico añadiendo un mapa de calor binario para el género al árbol filogenético y almacenándolo en un nuevo objeto de gráfico ggtree h1:\n\nh1 &lt;-  gheatmap(p, gender,                            # añadimos al árbol una capa de mapa de calor para el género del dataframe\n                offset = 10,                          # offset desplaza el mapa de calor a la derecha\n                width = 0.10,                         # width define el ancho de la columna del mapa de calor\n                color = NULL,                         # color define el borde de las columnas del mapa de calor\n         colnames = FALSE) +                          # oculta los nombres de las columnas del mapa de calor\n  scale_fill_manual(name = \"Gender\",                  # define el esquema de colores y la leyenda para el género\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nA continuación, añadimos información sobre las mutaciones en el gen gyrA, que confieren resistencia a la ciprofloxacina:\nNota: La presencia de mutaciones cromosómicas puntuales en los datos de secuenciación del genoma completo (WGS) se determinó previamente utilizando la herramienta PointFinder desarrollada por Zankari et al. (ver la sección de referencias adicionales)\nEn primer lugar, asignamos un nuevo esquema de colores a nuestro objeto gráfico h1 y lo almacenamos en un objeto llamado h2. Esto nos permite definir y cambiar los colores para nuestra segunda variable en el mapa de calor.\n\nh2 &lt;- h1 + new_scale_fill() \n\nA continuación, añadimos la segunda capa del mapa de calor a h2 y almacenamos los gráficos combinados en un nuevo objeto h3:\n\nh3 &lt;- gheatmap(h2, cipR,         # añade la segunda capa del mapa de calor que describe las mutaciones de resistencia a la ciprofloxacina\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh3\n\n\n\n\n\n\n\n\nRepetimos el proceso anterior, añadiendo primero una nueva capa de escala de colores a nuestro objeto existente h3, y luego añadiendo los datos continuos sobre la concentración inhibitoria mínima (CIM) de ciprofloxacina para cada cepa al objeto resultante h4 para producir el objeto final h5:\n\n# Primero añadimos el nuevo esquema de colores:\nh4 &lt;- h3 + new_scale_fill()\n\n# luego combinamos los dos en una nueva gráfica:\nh5 &lt;- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # aquí definimos un esquema de color de gradiente para la variable continua MIC\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5\n\n\n\n\n\n\n\n\nPodemos hacer el mismo ejercicio para un árbol lineal:\n\np &lt;- ggtree(sub_tree2) %&lt;+% sample_data +\n  geom_tiplab(size = 3) + # etiqueta las puntas\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\n\n\n\n\n\n\n\n\nPrimero añadimos el género:\n\nh1 &lt;-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh1\n\n\n\n\n\n\n\n\nA continuación, añadimos las mutaciones de resistencia a la ciprofloxacina después de añadir otra capa de colores representando los genes que confieren resistencia antimicrobiana:\n\nh2 &lt;- h1 + new_scale_fill()\nh3 &lt;- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n h3\n\n\n\n\n\n\n\n\nA continuación, añadimos en forma de mapa de calor la concentración mínima inhibitoria determinada por el laboratorio (MIC):\n\nh4 &lt;- h3 + new_scale_fill()\nh5 &lt;- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\nh5",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Árboles filogenéticos</span>"
    ]
  },
  {
    "objectID": "new_pages/phylogenetic_trees.es.html#resources-31",
    "href": "new_pages/phylogenetic_trees.es.html#resources-31",
    "title": "38  Árboles filogenéticos",
    "section": "38.6 Recursos",
    "text": "38.6 Recursos\nhttp://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors\nhttps://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html\nhttps://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: una novedosa herramienta web para la detección basada en WGS de la resistencia a los antimicrobianos asociada a mutaciones puntuales cromosómicas en patógenos bacterianos, Journal of Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764-2768, https://doi.org/10.1093/jac/dkx217",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Árboles filogenéticos</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.es.html",
    "href": "new_pages/interactive_plots.es.html",
    "title": "39  Gráficos interactivos",
    "section": "",
    "text": "39.1 Preparación",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Gráficos interactivos</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.es.html#preparation-32",
    "href": "new_pages/interactive_plots.es.html#preparation-32",
    "title": "39  Gráficos interactivos",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library(). Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,       # importación/exportación\n  here,      # rutas de archivos\n  lubridate, # lubridate\n  plotly,    # gráficos interactivos\n  scales,    # porcentajes rápidos\n  tidyverse  # gestión y visualización de datos\n  ) \n\n\n\nComienza con un ggplot()\nEn esta página asumimos que comienzas con un gráfico ggplot() que deseas convertir en interactivo. Construiremos varios de estos gráficos en esta página, utilizando la base de datos linelist, la cual es ampliamente utilizada en este manual.\n\n\nImportar datos\nPara empezar, importamos la lista de casos limpia de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio” (como archivo .rds). Importae los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - consulta la página de importación y exportación para más detalles).\n\n# Importar base de datos linelist \nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas de la base de datos.",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Gráficos interactivos</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.es.html#plot-with-ggplotly",
    "href": "new_pages/interactive_plots.es.html#plot-with-ggplotly",
    "title": "39  Gráficos interactivos",
    "section": "39.2 Trazar con ggplotly()",
    "text": "39.2 Trazar con ggplotly()\nLa función ggplotly() del paquete plotly facilita la conversión de un ggplot() para que sea interactivo. Simplemente guarda tu ggplot() y luego pásaselo a la función ggplotly().\nA continuación, trazamos una línea simple que representa la proporción de casos que murieron en una semana determinada.\nComenzamos creando unos datos resumidos de cada semana epidemiológica y el porcentaje de casos con resultado conocido que murieron.\n\nweekly_deaths &lt;- linelist %&gt;%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %&gt;%  # crear y agrupar los datos por la columna epiweek\n  summarise(                                              # crear nuevo dataframe descriptivo \n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # número de casos por grupo con resultado conocido\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # número de casos por grupo que murieron\n    pct_death = 100*(n_death / n_known_outcome)           # porcentaje de casos con resultado conocido que murieron\n  )\n\nAquí están las primeras 50 filas de los datos weekly_deaths.\n\n\n\n\n\n\nLuego creamos el gráfico con ggplot2, utilizando geom_line().\n\ndeaths_plot &lt;- ggplot(data = weekly_deaths)+            # comenzar introduciendo los datos de  weekly deaths \n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # hacer un gráfico de línea\n\ndeaths_plot   # imprimir\n\n\n\n\n\n\n\n\nPodemos convertirlo en interactivo simplemente pasando este gráfico mediante un “pipe” a ggplotly(), como se muestra abajo. Pasa el cursor por encima de la línea para mostrar los valores x e y. Puedes ampliar el gráfico y arrastrarlo. También puedes ver los iconos en la parte superior derecha del gráfico. En orden, estos botones permiten:\n\nDescargar la vista actual como imagen PNG\nAcercarse con un cuadro de selección\n“Pan”, o moverse a través de la gráfica clicando y arrastrando la gráfica\nAcercar, alejar o volver al zoom por defecto\nRestablecer los ejes por defecto\nActivar/desactivar las “líneas en pico” que son líneas punteadas desde el punto interactivo que se extienden a los ejes x e y\nAjustes para que los datos se muestren cuando no se está sobre la línea\n\n\ndeaths_plot %&gt;% plotly::ggplotly()\n\n\n\n\n\nLos datos agrupados también funcionan con ggplotly(). A continuación, realizaremos una curva epidemica semanal agrupada por resultado. Las barras apiladas son interactivas. Prueba a clicar en los diferentes elementos de la leyenda (aparecerán/desaparecerán).\n\n# Hacer curva epidémica con el paquete incidence2\np &lt;- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %&gt;% plot(fill = outcome)\n\n\n# Hacer interactivo\np %&gt;% plotly::ggplotly()",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Gráficos interactivos</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.es.html#modifications",
    "href": "new_pages/interactive_plots.es.html#modifications",
    "title": "39  Gráficos interactivos",
    "section": "39.3 Modificaciones",
    "text": "39.3 Modificaciones\n\nTamaño del archivo\nCuando se exportan imagenes en un HTML generado por R Markdown (¡como este libro!) es deseable que el gráfico tenga el menor tamaño de datos posible (y siempre que se pueda, evitar que esto tenga repercusiones negativas). Para ello, sólo hay que realizar “pipe” desde el gráfico interactivo a partial_bundle(), de plotly.\n\np &lt;- p %&gt;% \n  plotly::ggplotly() %&gt;%\n  plotly::partial_bundle()\n\n\n\nBotones\nAlgunos de los botones de un plotly estándar son superfluos y pueden distraer, por lo que, si quieres, puedes eliminarlos. Puedes hacer esto simplemente canalizando la haz pipe hacia config() de plotly y especifican qué botones eliminar. En el siguiente ejemplo especificamos por adelantado los nombres de los botones a eliminar, y los especificamos en el argumento modeBarButtonsToRemove =. También establecemos displaylogo = FALSE para eliminar el logo de plotly.\n\n## estos botones distraen y queremos eliminarlos\nplotly_buttons_remove &lt;- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np &lt;- p %&gt;%            # redefinir el gráfico  interactivo sin estos botones\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Gráficos interactivos</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.es.html#heat-tiles",
    "href": "new_pages/interactive_plots.es.html#heat-tiles",
    "title": "39  Gráficos interactivos",
    "section": "39.4 Gráficos de calor",
    "text": "39.4 Gráficos de calor\nPuedes hacer que casi cualquier gráfico de ggplot() sea interactivo, incluidos los gráficos de calor. En la página sobre gráficos de calor puede leer cómo hacer el siguiente gráfico, que muestra la proporción de días a la semana en que determinados centros comunicaron datos a su provincia.\nAquí está el código, aunque en este capítulo no describiremos en profundidad como realizarlo.\n\n# importar datos\nfacility_count_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# datos agregados en semanas para el distrito de Spring\nagg_weeks &lt;- facility_count_data %&gt;% \n  filter(District == \"Spring\",\n         data_date &lt; as.Date(\"2020-08-01\")) %&gt;% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %&gt;% \n  group_by(location_name, week, .drop = F) %&gt;%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %&gt;% \n  ungroup(location_name, week) %&gt;% \n  right_join(tidyr::expand(., week, location_name)) %&gt;% \n  mutate(week = aweek::week2date(week))\n\n# crear plot\nmetrics_plot &lt;- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # imprimir\n\n\n\n\n\n\n\n\nA continuación, lo convertimos en interactivo y lo modificamos para que los botones sean sencillos y disminuya el tamaño del archivo.\n\nmetrics_plot %&gt;% \n  plotly::ggplotly() %&gt;% \n  plotly::partial_bundle() %&gt;% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Gráficos interactivos</span>"
    ]
  },
  {
    "objectID": "new_pages/interactive_plots.es.html#resources-32",
    "href": "new_pages/interactive_plots.es.html#resources-32",
    "title": "39  Gráficos interactivos",
    "section": "39.5 Recursos",
    "text": "39.5 Recursos\nPlotly no es sólo para R, también funciona bien con Python (y realmente con cualquier lenguaje de ciencia de datos, ya que está construido en JavaScript). Puedes leer más sobre él en el sitio web de plotly",
    "crumbs": [
      "Visualización de datos",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Gráficos interactivos</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html",
    "href": "new_pages/rmarkdown.es.html",
    "title": "40  Informes con R Markdown",
    "section": "",
    "text": "40.1 Preparación\nAntecedentes de R Markdown\nExplicamos algunos de los conceptos y paquetes involucrados:\nEn resumen, el proceso que ocurre en segundo plano (¡no es necesario que conozcas todos estos pasos!) consiste en alimentar el archivo .Rmd a knitr, que ejecuta los trozos de código R y crea un nuevo archivo .md (markdown) que incluye el código R y su salida renderizada. El archivo .md es entonces procesado por pandoc para crear el producto final: un documento de Microsoft Word, un archivo HTML, un documento powerpoint, un pdf, etc.\n(fuente: https://rmarkdown.rstudio.com/authoring_quick_tour.html):\nInstalación\nPara crear una salida de R Markdown, necesitas tener instalado lo siguiente:\npacman::p_load(tinytex)     # instala el paquete tinytex\ntinytex::install_tinytex()  # Comando de R para instalar el software TinyTeX",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#preparation-33",
    "href": "new_pages/rmarkdown.es.html#preparation-33",
    "title": "40  Informes con R Markdown",
    "section": "",
    "text": "Markdown es un “lenguaje” que permite escribir un documento en texto plano, que se puede convertir a html y otros formatos. No es específico de R. Los archivos escritos en Markdown tienen una extensión ‘.md’.\nR Markdown: es una variación de markdown que es específica de R - te permite escribir un documento usando markdown para producir texto y para integrar código R y mostrar sus resultados. Los archivos R Markdown tienen la extensión ‘.Rmd’.\nrmarkdown - el paquete: Usado por R para convertir el archivo .Rmd en el tipo de documento de salida deseado. Su objetivo es convertir la sintaxis markdown (texto), por lo que también necesitamos…\nknitr: Este paquete de R leerá los trozos de código, los ejecutará y los “tejerá” dentro del documento. Así es como se incluyen las tablas y los gráficos junto al texto.\nPandoc: Por último, pandoc convierte el documento de salida en word/pdf/powerpoint, etc. Es un software independiente de R, y viene instalado automáticamente con RStudio.\n\n\n\n\n\n\n\nEl paquete rmarkdown (knitr también se instalará automáticamente)\nPandoc, que debería venir instalado con RStudio. Si no utilizas RStudio, podés descargar Pandoc aquí: http://pandoc.org .\nSi querés generar una salida en PDF (un poco más complicado), necesitarás instalar LaTeX. Para los usuarios de R Markdown que no hayan instalado LaTeX antes, recomendamos que instalen TinyTeX (https://yihui.name/tinytex/)https://yihui.name/tinytex/). Puedes utilizar los siguientes comandos:",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#getting-started",
    "href": "new_pages/rmarkdown.es.html#getting-started",
    "title": "40  Informes con R Markdown",
    "section": "40.2 Cómo empezar",
    "text": "40.2 Cómo empezar\n\nInstalar el paquete R rmarkdown\nInstalá el paquete R rmarkdown. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y ademas lo carga para su uso. También podés cargar los paquetes instalados con library() de R base. Consultá la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(rmarkdown)\n\n\n\nIniciar un nuevo archivo Rmd\nEn RStudio, abrí un nuevo archivo R markdown, comenzando con ‘File’, luego ‘New file’ luego ‘R markdown…’.\n\n\n\n\n\n\n\n\n\nR Studio te dará algunas opciones de salida para elegir. En el ejemplo siguiente seleccionamos “HTML” porque queremos crear un documento html. El título y los nombres de los autores no son importantes. Si el tipo de documento de salida que desea no es uno de estos, no te preocupes - podés elegir cualquiera y cambiarlo en el script más tarde.\n\n\n\n\n\n\n\n\n\nEsto abrirá un nuevo script .Rmd.\n\n\nEs importante saber\nEl directorio de trabajo\nEl directorio de trabajo de un archivo markdown es el lugar donde se guarda el propio archivo Rmd. Por ejemplo, si el proyecto R está dentro de ~/Documents/projectX y el archivo Rmd en sí está en una subcarpeta ~/Documents/projectX/markdownfiles/markdown.Rmd, el código read.csv(\"data.csv\") dentro del markdown buscará un archivo csv en la carpeta markdownfiles, y no en la carpeta raíz del proyecto donde los scripts dentro de los proyectos normalmente buscarían archivos de manera automática.\nPara referirse a archivos en otro lugar, tendrá que utilizar la ruta completa del archivo o utilizar el paquete here. El paquete here establece el directorio de trabajo en la carpeta raíz del proyecto R y se explica en detalle en las páginas de proyectos R e importación y exportación de este manual. Por ejemplo, para importar un archivo llamado “data.csv” desde la carpeta projectX, el código sería import(here(\"data.csv\")).\nTen en cuenta que no se recomienda el uso de setwd() en los scripts de R Markdown - sólo se aplica al trozo de código en el que está escrito.\nTrabajar en una unidad versus tu ordenador\nDebido a que R Markdown puede tener problemas con pandoc cuando se ejecuta en una unidad de red compartida, se recomienda que la carpeta esté ubicada en tu máquina local, por ejemplo, en un proyecto dentro de ‘Mis Documentos’. Si utilizas Git (¡super recomendable!), esto te resultará familiar. Para más detalles, consulta las páginas del manual sobre R en unidades de red y Errores y ayuda.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#r-markdown-components",
    "href": "new_pages/rmarkdown.es.html#r-markdown-components",
    "title": "40  Informes con R Markdown",
    "section": "40.3 Componentes de R Markdown",
    "text": "40.3 Componentes de R Markdown\nUn documento R Markdown puede ser editado en RStudio igual que un script estándar de R. Cuando se inicia un nuevo script de R Markdown, RStudio intenta ayudarnos mostrando una plantilla que explica las diferentes secciones de un script de R Markdown.\nLo que aparece a continuación es lo que veremos al iniciar un nuevo script Rmd destinado a producir un documento de salida en html (según la sección anterior).\n\n\n\n\n\n\n\n\n\nComo puedes ver, hay tres componentes básicos en un archivo Rmd: YAML, texto Markdown y trozos de código R.\nEstos crearán y se convertirán en la salida de su documento. Consulta el siguiente diagrama:\n\n\n\n\n\n\n\n\n\n\nMetadatos YAML\nDenominado ‘metadatos YAML’ o simplemente ‘YAML’, se encuentra en la parte superior del documento R Markdown. Esta sección del script le dirá a su archivo Rmd qué tipo de salida producir, preferencias de formato y otros metadatos como el título del documento, el autor y la fecha. Hay otros usos que no se mencionan aquí (pero a los que se hace referencia en ‘Producción del documento de salida’). Ten en cuenta que la sangría es importante; los tabuladores no se aceptan, pero los espacios sí.\nEsta sección debe comenzar con una línea que contenga sólo tres guiones --- y debe cerrar con una línea que contenga sólo tres guiones ---. Los parámetros YAML vienen en pares key:value. La colocación de los dos puntos en YAML es importante - los pares key:value están separados por dos puntos (¡no por signos de igualdad!).\nEl YAML debe comenzar con los metadatos del documento. El orden de estos parámetros YAML primarios (sin sangría) no importa. Por ejemplo:\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"2024-05-10\"\nPuedes utilizar código R en valores YAML escribiéndolo como código en línea (precedido por r entre comillas) pero también entre comillas (véase el ejemplo anterior para date:).\nEn la imagen de arriba, porque hemos seleccionado el tipo de documento de salida como html, podemos ver que el YAML dice output: html_document. Sin embargo, también podemos cambiar esto escribir powerpoint_presentation o word_document o incluso pdf_document.\n\n\nTexto\nEsta es la narrativa de t u documento, incluyendo los títulos y encabezados. Está escrito en el lenguaje “markdown”, que se utiliza en muchos otros programas.\nA continuación se presentan las formas principales de escribir este texto. Podés consultar material de referencia más detallado disponible en R Markdown “cheatsheet” en el sitio web de RStudio.\n\nNuevas líneas\nEn R Markdown, para iniciar una nueva línea, introducí *dos espacios** al final de la línea anterior y luego Enter/Return. Esto es una particularidad de R Markdown.\n\n\nFormato de texto\nRodea el texto normal con estos caracteres para cambiar su apariencia en la salida.\n\nGuiones bajos (_texto_) o un asterisco simple (*texto*) para poner en cursiva (itálica)\nDoble asterisco (**texto**) para el texto en negrita\nComillas invertidas (texto) para mostrar el texto como código\n\nEl aspecto real de la fuente puede establecerse utilizando plantillas específicas (especificadas en los metadatos YAML; ver sub-secciones de este capitulo).\n\n\nColor\nNo existe un mecanismo sencillo para cambiar el color del texto en R Markdown. Como solución, si tu salida es un archivo HTML, es añadir una línea de codigo HTML en el texto de Markdown. El siguiente código HTML imprimirá una línea de texto en negrita roja.\n&lt;span style=\"color: red;\"&gt;**_PELIGRO:_** Esto es una advertencia.&lt;/span&gt;  \nPELIGRO: Esto es una advertencia.\n\n\nTítulos y encabezamientos\nUn símbolo de almohadilla (hash #) delante de un texto en un script de R Markdown crea un encabezado. Esto es diferente que en un trozo de código R en el script, en el que un símbolo de almohadilla permite comentar/anotar/desactivar, como en un script normal de R.\nLos distintos niveles de encabezamiento se establecen con diferentes números de símbolos de almohadilla al comienzo de una nueva línea. Un solo símbolo de almohadilla genera un título o encabezamiento primario. Dos símbolos hash generan un encabezamiento de segundo nivel. Los encabezamientos de tercer y cuarto nivel pueden hacerse con más símbolos hash sucesivamente.\n# Encabezamiento / título de primer nivel\n\n## Encabezamiento de segundo nivel\n\n### Encabezamiento de tercer nivel\n\n\nViñetas y numeración\nUtilizá asteriscos (*) para crear una lista de viñetas. Completá la frase anterior, introducí dos espacios, presioná Enter/Return dos veces, y luego comenzá tus viñetas. Incluí un espacio entre el asterisco y el texto de tu viñeta. Después de cada viñeta, introducí dos espacios y luego presioná Enter/Return. Las sub-viñetas funcionan de la misma manera pero con sangría. Los números funcionan de la misma manera, pero en lugar de un asterisco, escribí 1), 2), etc. El texto de tu script de R Markdown se vería como mostramos a continuación.\nAquí están mis viñetas (hay dos espacios después de los dos puntos):\n\n* Viñeta 1 (seguida de dos espacios y Enter/Return)\n* Viñeta 2 (seguida de dos espacios y Enter/Return)\n  * Sub-viñeta 1 (seguida de dos espacios y Enter/Return)\n  * Sub-viñeta 2 (seguida de dos espacios y Enter/Return)\n* Subbalanceo 2 (seguido de dos espacios y Enter/Return)\n\n\nComentar el texto\nPuedes desactivar o “esconder” el texto de R Markdown del mismo modo que puede utilizar el “#” para desactivar una línea de código en un chunk de R. Simplemente resalta el texto y clica Ctrl+Mayús+c (Cmd+Mayús+c para Mac). El texto aparecerá rodeado de flechas y se volverá verde. No aparecerá en tu salida.\n\n\n\n\n\n\n\n\n\n\n\n\nTrozos de código (chunks)\nLas secciones del script que se dedican a ejecutar el código R se denominan “chunks” o trozos. Aquí es donde se pueden cargar paquetes, importar datos y realizar la gestión y visualización de datos propiamente dicha. Puede haber muchos trozos de código, por lo que puede ser de ayuda organizar tu código R en partes, quizás intercaladas con texto. Para tener en cuenta: estos trozos tendrán un color de fondo ligeramente diferente al de la parte narrativa del documento.\nCada trozo se abre con una línea que comienza con tres comillas invertidas y corchetes que contienen parámetros para el trozo ({ }). El trozo termina con otras tres comillas invertidas.\nPuedes crear un nuevo fragmento escribiendo tú mismo las marcas, utilizando el atajo de teclado “Ctrl + Alt + i” (o Cmd + Shift + r en Mac), o clicando en el icono verde ‘insert a new code chunk’ en la parte superior de tu editor de scripts.\nAlgunas notas sobre el contenido de las corchetes { }:\n\nEmpiezan con una “r” para indicar que el nombre del idioma dentro del chunk es R\nDespués de la r puedes asignarle un “nombre” al chunk - no es necesario pero puede ayudarte a organizar tu trabajo. Ten en cuenta que si nombras tus chunks, debes usar SIEMPRE nombres únicos o de lo contrario R se quejará cuando intentes procesarlos.\nLos corchetes pueden incluir también otras opciones, escritas como tag=value, como por ejemplo\neval = FALSE para no ejecutar el código R\n\necho = FALSE para no imprimir o esconder el código fuente de R del chunk en el documento de salida\nwarning = FALSE para no imprimir las advertencias producidas por el código R\nmessage = FALSE para no imprimir ningún mensaje producido por el código R\ninclude = TRUE/FALSE para incluir (o no) los resultados generados por los trozos (por ejemplo, los gráficos) en el documento de salida\nout.width = y out.height = - asigna proporciones de ancho y largo, por ejemplo out.width = \"75%\"\nfig.align = \"center\" ajusta cómo se alinea una figura en la página\nfig.show = 'hold' si tu chunk imprime múltiples figuras y querés imprimirlas una al lado de la otra usá también la funciónout.width = c(\"33%\", \"67%\"). También podés establecer como fig.show='asis' para mostrarlas debajo del código que las genera, 'hide' para ocultarlas, o 'animate' para concatenar varias figuras en una animación.\n\nLa cabecera de un trozo debe escribirse en una sola línea\nIntentá evitar puntos, barras bajas y espacios. Utiliza guiones ( - ) en su lugar si necesitas un separador.\n\nLeé más extensamente sobre las opciones de knitr aquí.\nAlgunas de estas opciones pueden configurarse usando los botones de configuración situados en la parte superior derecha del chunk. Aquí puedes especificar qué partes del chunk quieres incluir en el documento renderizado, es decir, el código, las salidas generadas y las advertencias. Estas preferencias aparecerán escritas como código dentro de los corchetes, por ejemplo, si especificás que querés mostrar sólo la salida (‘Show output only’) aparecerá echo=FALSE entre los corchetes.\n\n\n\n\n\n\n\n\n\nTambién hay dos flechas en la parte superior derecha de cada trozo, que son útiles para ejecutar el código dentro de un trozo, o todo el código en trozos anteriores. Pasa el cursor por encima de estos iconos para ver lo que hacen.\nPara que las opciones globales se apliquen a todos los chunks del script, podés configurar esto dentro del primer chunk de código R en el script. Por ejemplo, para sólo muestrar las salidas generadas por cada trozo de código y no el propio código, podés incluir este comando en el trozo de código R:\n\nknitr::opts_chunk$set(echo = FALSE) \n\n\nCódigo R en el texto\nTambién se puede insertar un mínimo de código R entre comillas invertidas (back ticks) intercalado entre el texto narrativo. Dentro de las comillas invertidas, comenzá el código con la letra “r” y un espacio, para que RStudio sepa que debe evaluar el código como código R. Ver el siguiente ejemplo.\nEl ejemplo siguiente muestra múltiples niveles de encabezamiento, viñetas, y utiliza el código (Sys.Date()) para obtener y mostrar la fecha actual.\n\n\n\n\n\n\n\n\n\nEl ejemplo anterior es sencillo (muestra la fecha actual), pero utilizando la misma sintaxis puede mostrar valores producidos por un código R más complejo (por ejemplo, para calcular el mínimo, la mediana o el máximo de una columna). También podés integrar objetos R o valores que han sido creados en trozos de código R anteriores.\nComo ejemplo, el siguiente script calcula la proporción de casos que tienen menos de 18 años, utilizando funciones tidyverse, y crea los objetos less18, total y less18prop. Este valor dinámico se inserta en el texto narrativo. Vemos cómo queda cuando se teje en un documento de Word.\n\n\n\n\n\n\n\n\n\n\n\n\nImágenes\nHay dos maneras de incluir imágenes en R Markdown:\n\n![](\"path/to/image.png\")  \n\nSi el código anterior no funciona, probá utilizar knitr::include_graphics()\n\nknitr::include_graphics(\"path/to/image.png\")\n\n(recordá que podes declarar la ruta de tu archivo usando el paquete here)\n\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))\n\n\n\nTablas\nCreá una tabla utilizando guiones ( - ) y barras ( | ). El número de guiones entre las barras determina el número de espacios en la celda a patrir del cual el texto comienza a envolverse.\nColumn  1 |Column   2 |Column 3\n----------|-----------|--------\nCell A    |Cell B     |Cell C\nCell D    |Cell E     |Cell F\nEl código anterior produce la siguiente tabla:\n\n\n\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\nCell A\nCell B\nCell C\n\n\nCell D\nCell E\nCell F\n\n\n\n\n\nSecciones con pestañas\nPara las salidas HTML, podés organizar las secciones con “pestañas”. Basta con añadir .tabset entre las llaves { } que se colocan después de un encabezamiento. Todos los subtítulos debajo de ese encabezado (hasta el próximo encabezado del mismo nivel) aparecerán como pestañas en las que el usuario puedes clicar. Lee más aquí\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPuedes añadir una opción adicional .tabset-pills después de .tabset para dar a las pestañas una apariencia “en forma de píldora”. Ten en cuenta que al ver la salida HTML con etiquetas, la funcionalidad de búsqueda Ctrl+f sólo buscará en las etiquetas “activas”, no en las ocultas.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#file-structure",
    "href": "new_pages/rmarkdown.es.html#file-structure",
    "title": "40  Informes con R Markdown",
    "section": "40.4 Estructura de los archivos",
    "text": "40.4 Estructura de los archivos\nHay varias maneras de estructurar el archivo de R Markdown y sus scripts de R asociados. Cada una tiene sus ventajas y desventajas:\n\nR Markdown autónomo - todo lo necesario para el informe se importa o se crea dentro del R Markdown\n\nUbicar otros archivos - Podés ejecutar scripts R externos con el comando source() y utilizar sus salidas en el Rmd\nScripts hijos - un mecanismo alternativo para source()\n\n\nUtilizar un “archivo de ejecución” - Ejecutar comandos en un script R antes de renderizar el R Markdown\n\n\nRmd autónomo\nPara un informe relativamente sencillo, puedes optar por organizar tu script de R Markdown de manera que sea “autosuficiente” y no implique utilizar ningún script externo.\nTodo lo que se necesite para ejecutar el R Markdown se importa o se crea dentro del archivo Rmd, incluyendo todos los trozos de código y la carga de paquetes. Este enfoque “autosuficiente” es apropiado cuando no necesitás hacer mucho procesamiento de datos (por ejemplo, cuando se importa un archivo de datos limpio o semilimpio) y el procesamiento del R Markdown no tomará demasiado tiempo.\nEn este escenario, una organización lógica del script de R Markdown podría ser:\n\nEstablecer las opciones globales de knitr\nCargar paquetes\nImportar los datos\nProcesar los datos\nGenerar resultados (tablas, gráficos, etc.)\nGuardar los resultados, si es el caso (.csv, .png, etc.)\n\n\nObtener otros archivos\nUna variación del enfoque “autocontenido” es hacer que los trozos de código R Markdown busquen (ejecuten) scripts de R externos. Esto puede hacer que tu script de R Markdown sea menos desordenado, más simple y más fácil de organizar. También puede ayudar si quieres mostrar las cifras finales al principio del informe. En este enfoque, el script de R Markdown final simplemente combina las salidas preprocesadas en un documento.\nUna forma de hacerlo es proporcionando los scripts de R (ruta del archivo y nombre con extensión) al comando source() R base.\n\nsource(\"your-script.R\", local = knitr::knit_global())\n# o sys.source(\"your-script.R\", envir = knitr::knit_global())\n\nTené en cuenta que cuando utilizás source() dentro de R Markdown, los archivos externos se ejecutarán durante el curso del procesamiento de tu archivo Rmd. Por lo tanto, cada script se ejecuta cada vez que se procesa el informe. Por lo tanto, utilizar comandos source() dentro del R Markdown no acelera el tiempo de ejecución, ni ayuda mucho a la depuración, ya que el error producido todavía se imprimirá al producir el R Markdown.\nUna alternativa es utilizar la opción child = knitr. #EXPLICAR MÁS PARA HACER\nDebes ser consciente de los distintos entornos de R. Los objetos creados dentro de un entorno no estarán necesariamente disponibles para el entorno utilizado por R Markdown.\n\n\n\nEjecutar archivo\nEste enfoque implica utilizar el script de R que contiene el comando(s) render() para preprocesar los objetos que se introducen en el R markdown.\nPor ejemplo, podés cargar los paquetes, cargar y limpiar los datos, e incluso crear los gráficos de interés antes de ejecutarrender(). Estos pasos pueden ocurrir en el script de R, o en otros scripts que se convocan. Siempre y cuando estos comandos ocurran en la misma sesión de RStudio y los objetos se guarden en el entorno, los objetos pueden ser convocados dentro del contenido de Rmd. Entonces R markdown sólo se utilizará para el paso final, es decir, para producir la salida con todos los objetos pre-procesados. Esto es mucho más fácil de depurar si se genera algún error.\nEste enfoque es útil por las siguientes razones:\n\nMensajes de error más informativos - estos mensajes serán generados por el script de R, no por el R Markdown. Los errores de R Markdown tienden a informar qué trozo tuvo un problema, pero no te dirán qué línea.\nSi ejecutás muchos pasos de procesamiento antes de usar el comando render() - se ejecutarán sólo una vez.\n\nEn el ejemplo siguiente, tenemos un script de R en el que preprocesamos el objeto data en el entorno de R y luego procesamos “create_output.Rmd” usando render().\n\ndata &lt;- import(\"datafile.csv\") %&gt;%       # Cargar datos y guardarlos en el entorno\n  select(age, hospital, weight)          # Seleccionar columnas\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Crear archivo Rmd \n\n\n\nEstructura de carpetas\nEl flujo de trabajo también se refiere a la estructura general de las carpetas, como tener una carpeta de ‘salida’ para los documentos y figuras creados, y carpetas de ‘datos’ o ‘entradas’ para los datos depurados. No entramos en más detalles aquí, pero echa un vistazo a la página de organización de informes rutinarios.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#producing-the-document",
    "href": "new_pages/rmarkdown.es.html#producing-the-document",
    "title": "40  Informes con R Markdown",
    "section": "40.5 Producir el documento",
    "text": "40.5 Producir el documento\nPuedes generar el documento de las siguientes maneras:\n\nManualmente haciendo click sobre el botón “Knit” en la parte superior del editor de scripts de RStudio (rápido y fácil)\nEjecutando el comando render() (ejecutado fuera del script de R Markdown)\n\n\nOpción 1: botón “Knit”\nCuando tengas el archivo Rmd abierto, cliqueá el botón ‘Knit’ en la parte superior del archivo.\nR Studio te mostrará el progreso dentro de una pestaña ‘R Markdown’ cerca de la consola R. El documento se abrirá automáticamente cuando esté completo.\nEl documento se guardará en la misma carpeta que tu script de R markdown, y con el mismo nombre de archivo (excepto la extensión). Obviamente, esto no es ideal para el control de versiones (se sobreescribirá cada vez que se haga un knit, a menos que se mueva manualmente), ya que entonces puede que tengas que renombrar el archivo (por ejemplo, añadir una fecha).\nEste es el botón de acceso directo de RStudio para la función render() de rmarkdown. Este enfoque sólo es compatible con un R markdown autocontenido, donde todos los componentes necesarios existen o se convocan dentro del archivo.\n\n\n\n\n\n\n\n\n\n\n\nOpción 2: comando render()\nOtra forma de producir el documento de salida de R Markdown es ejecutar la función render() (del paquete rmarkdown). Debés ejecutar este comando fuera del script de R Markdown, ya sea en un script de R separado (a menudo llamado “archivo de ejecución”), o como un comando independiente en la consola de R.\n\nrmarkdown::render(input = \"my_report.Rmd\")\n\nAl igual que con “knit”, la configuración predeterminada guardará la salida Rmd en la misma carpeta que el script Rmd, con el mismo nombre de archivo (excepto la extensión del archivo). Por ejemplo, “mi_informe.Rmd” cuando se procese creará “mi_informe.docx” si se procesa a un documento de Word. Sin embargo, al usar render() existe la opción de usar diferentes configuraciones. render() puede aceptar argumentos que incluyen:\n\noutput_format = Este es el formato del documento salida al que se va a convertir (por ejemplo, \"html_document\", \"pdf_document\", \"word_document\", o \"all\"). Esto también se puede especificar en el YAML dentro del script de R Markdown.\noutput_file = Este es el nombre del archivo de salida (y la ruta del archivo). Se puede crear a través de funciones de R como here() o str_glue() como se demuestra a continuación.\noutput_dir =Este es un directorio de salida (carpeta) para guardar el archivo. Esto te permite elegir un directorio distinto en el que se guarda el archivo Rmd.\noutput_options = Podés proporcionar una lista de opciones que anulen las del YAML del script\noutput_yaml = Podés proporcionar la ruta a un archivo .yml que contenga las especificaciones YAML\nparams = Ver la sección de parámetros más abajo\nVer la lista completa aquí\n\nComo ejemplo, para mejorar el control de versiones, el siguiente comando guardará el archivo de salida dentro de una subcarpeta ‘outputs’, con la fecha actual en el nombre del archivo. Para crear el nombre del archivo, se utiliza la función str_glue() del paquete stringr para “pegar” las cadenas estáticas (escritas sin formato) con el código dinámico de R (escrito entre corchetes). Por ejemplo, si es 10 de abril de 2021, el nombre del archivo será “Informe_2021-04-10.docx”. Consultá la página sobre Caracteres y cadenas para obtener más detalles sobre str_glue().\n\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) \n\nA medida que el archivo se procesa, la consola de RStudio mostrará el progreso hasta el 100%, y un mensaje final para indicar que la renderización se ha completado.\n\n\nOpción 3: paquete reportfactory\nEl paquete de R reportfactory ofrece un método alternativo de organización y compilación de informes R Markdown para situaciones en las que se ejecutan informes de forma rutinaria (por ejemplo, diariamente, semanalmente…). Facilita la compilación de múltiples archivos R Markdown y la organización de sus resultados. En esencia, proporciona una “fábrica” desde la que se pueden ejecutar los informes R Markdown, obtener automáticamente carpetas con fecha y hora para los resultados, y tener un control de versiones “ligero”.\nLeé más sobre este flujo de trabajo en la página sobre la organización de informes rutinarios.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#parameterised-reports",
    "href": "new_pages/rmarkdown.es.html#parameterised-reports",
    "title": "40  Informes con R Markdown",
    "section": "40.6 Informes parametrizados",
    "text": "40.6 Informes parametrizados\nPodés utilizar la parametrización para generar informes dinámicos, de forma que pueda ejecutarse con una configuración específica (por ejemplo, una fecha o lugar concretos o con determinadas opciones de procesamiento). A continuación, nos centramos en los aspectos básicos, pero hay más detalles en línea sobre los informes parametrizados.\nUtilizando el listado de casos de Ébola como ejemplo, digamos que queremos ejecutar un informe de diario vigilancia estándar para cada hospital. Mostramos cómo se puede hacer esto usando parámetros.\nImportante: los informes dinámicos también son posibles sin la estructura formal de parámetros (sin params:), utilizando simples objetos R en un script adyacente. Esto se explica al final de esta sección.\n\nEstablecer parámetros\nExisten varias opciones para especificar los valores de los parámetros para tu documento de salida de R Markdown.\n\nOpción 1: Establecer parámetros dentro de YAML\nEditá el YAML para incluir una opción params:, con declaraciones indentadas para cada parámetro a definir. En este ejemplo creamos los parámetros date y hospital, y especificamos sus valores. Estos valores están sujetos a cambios cada vez que se ejecuta el informe. Si utilizás el botón “Knit” para producir la salida, los parámetros estarán predeterminados por estos valores. Del mismo modo, si utilizás render() los parámetros tendrán estos valores por defecto a menos que se especifiquen de otra manera en el comando render().\n---\ntitle: Informe de vigilancia\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Hospital Central\n---\nEn un segundo plano, los valores de los parámetros están contenidos en una lista de sólo lectura llamada params. Así, puedes insertar los valores de los parámetros en el código de R como lo harías con otro objeto/valor de R en tu entorno. Simplemente escriba params$ seguido del nombre del parámetro. Por ejemplo params$hospital para representar el nombre del hospital (“Hospital Central” por defecto).\nTené en cuenta que los parámetros también pueden tener valores true o false, y por lo tanto estos pueden ser incluidos en sus opciones de knitr dentro de un chunk de R. Por ejemplo, puedes establecer {r, eval=params$run} en lugar de {r, eval=FALSE}, y ahora si el chunk se ejecuta o no depende del valor de un parámetro run:.\nLos parámetros que son fechas, serán introducidos como una cadena. Por lo tanto, para que params$date se interprete en el código de R, es probable que tenga que ser envuelto con as.Date() o una función similar para convertir al tipo Date.\n\n\nOpción 2: Establecer los parámetros dentro de render()\nComo se ha mencionado anteriormente, como alternativa a cliquear el botón “Knit” para producir la salida es ejecutar la función render() desde un script independiente. En este último caso, se pueden especificar los parámetros a utilizar con el argumento params = de render().\nHay que tener en cuenta que los valores de los parámetros asignados aquí sobrescribirán sus valores predeterminados si aparacen el YAML. Escribimos los valores entre comillas ya que en este caso deben ser definidos como valores de carácter/cadena.\nEl siguiente comando genera “surveillance_report.Rmd”, especifica un nombre dinámico para el archivo de salida y una carpeta, y proporciona un list() de dos parámetros y sus valores al argumento params =.\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))\n\n\n\nOpción 3: Establecer los parámetros mediante una interfaz gráfica de usuario\nPara obtener una experiencia más interactiva, se puede utilizar la interfaz gráfica de usuario (GUI, por sus siglas en ingles) para seleccionar manualmente los valores de los parámetros. Para ello, podemos clicar en el menú desplegable situado junto al botón ‘Knit’ y elegir ‘Knit with parameters’.\nAparecerá una ventana que te permitirá introducir los valores de los parámetros establecidos en el YAML del documento.\n\n\n\n\n\n\n\n\n\nSe puede lograr lo mismo a través del comando render() especificando params = \"ask\", como se demuestra a continuación.\n\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)\n\nSin embargo, la asignación de valores en esta ventana emergente está sujeta a errores y faltas de ortografía. Es posible añadir restricciones a los valores que se pueden introducir a través de los menús desplegables. Podés hacerlo añadiendo en el YAML especificaciones para cada entrada params:.\n\nlabel: es el título para ese menú desplegable en particular\nvalue: es el valor predeterminado (inicial)\ninput: establecer select para utilizar un menú desplegable\n\nchoices: Indique los valores opcionales en el menú desplegable\n\nA continuación, estas especificaciones están escritas para el parámetro hospital\n---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---\nAl procesarlo (con el botón ‘knit with parameters’ o con render(), la ventana emergente tendrá opciones desplegables para seleccionarlos.\n\n\n\n\n\n\n\n\n\n\n\n\nEjemplo parametrizado\nEl siguiente código crea parámetros para date y hospital, que se utilizan en el R Markdown como params$date y params$hospital, respectivamente.\nEn la salida del informe resultante, los datos se filtran al hospital específico, y el título del gráfico se refiere al hospital y a la fecha correctos. En este caso utilizamos el archivo “linelist_cleaned.rds”, pero sería especialmente adecuado que la propia lista de casos tuviera también un sello de fecha para alinearse con la fecha parametrizada.\n\n\n\n\n\n\n\n\n\nSi se procesa esto se obtiene la salida final con la fuente y el diseño predeterminados.\n\n\n\n\n\n\n\n\n\n\n\nParametrización sin parámetros\nSi estás procesando un archivo R Markdown con render() desde un script independiente, puede crear el mismo efecto de parametrización sin usar la funcionalidad params:.\nPor ejemplo, en el script de R que contiene el comando render(), podés simplemente definir hospital y date como dos objetos R (valores) antes del comando render(). En el R Markdown, no sería necesario tener una sección params: en el YAML, y nos referiríamos al objeto date en lugar de params$date y a hospital en lugar de params$hospital.\n\n# Este es un script de R separado de R Markdown\n\n# define objetos de R\nhospital &lt;- \"Central Hospital\"\ndate &lt;- \"2021-04-10\"\n\n# Renderiza (procesa) el R markdown\nrmarkdown::render(input = \"create_output.Rmd\") \n\nEste enfoque significa que no se puede procesar con “knit with parameters”, ni utilizar la interfaz gráfica, ni incluir opciones de procesamiento dentro de los parámetros. Sin embargo, permite simplificar el código, lo cual puede resultar ventajoso.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#looping-reports",
    "href": "new_pages/rmarkdown.es.html#looping-reports",
    "title": "40  Informes con R Markdown",
    "section": "40.7 Informes en bucle",
    "text": "40.7 Informes en bucle\nEs posible que queramos ejecutar un informe varias veces, variando los parámetros de entrada, para producir un informe para cada jurisdicción/unidad. Esto puede hacerse utilizando herramientas para la iteración, que se explican en detalle en la página sobre Iteración, bucles y listas. Las opciones incluyen el paquete purrr, o el uso de un for loop como se explica a continuación.\nA continuación, utilizamos un simple for loop para generar un informe de vigilancia para todos los hospitales de interés. Esto se hace con un solo comando (en lugar de cambiar manualmente el parámetro del hospital uno por uno). El comando para generar los informes debe existir en un script separado fuera del informe Rmd. Este script también contendrá objetos definidos para “hacer un bucle” - la fecha de hoy, y un vector de nombres de hospitales para hacer un bucle.\n\nhospitals &lt;- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \n\nA continuación, introducimos estos valores uno a uno en el comando render() mediante un bucle, que ejecuta el comando una vez por cada valor del vector hospitales. La letra “i” representa la posición del índice (del 1 al 4) del hospital que se está utilizando en esa iteración, de modo que “lista_de_hospitales[1]sería \"Hospital Central\". Esta información se suministra en dos lugares en el comandorender()`:\n\nAl nombre del archivo, de forma que el nombre del archivo de la primera iteración, si se produce el 10 de abril de 2021, sería “Informe_Hospital Central_2021-04-10.docx”, guardado en la subcarpeta ‘output’ del directorio de trabajo.\n\nA params = de forma que el Rmd utilice el nombre del hospital internamente siempre que se llame al valor params$hospital (por ejemplo, para filtrar los datos sólo a un hospital determinado). En este ejemplo, se crearían cuatro archivos, uno por cada hospital.\n\n\nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#templates",
    "href": "new_pages/rmarkdown.es.html#templates",
    "title": "40  Informes con R Markdown",
    "section": "40.8 Plantillas",
    "text": "40.8 Plantillas\nUtilizando un documento de plantilla que contenga cualquier formato deseado, podés ajustar la estética del archivo de salida Rmd. Podés crear, por ejemplo, un archivo de MS Word o Powerpoint que contenga páginas/diapositivas con las dimensiones, marcas de agua, fondos y fuentes deseadas.\n\nDocumentos en Word\nPara crear una plantilla, iniciá un nuevo documento de Word (o utiliza uno ya existente con el formato deseado), y editá las fuentes definiendo los Estilos. En el Estilo, los encabezados 1, 2 y 3 se refieren a los distintos niveles de encabezado de markdown (# Header 1, ## Header 2 and ### Header 3, respectivamente). Cliqueá con el botón derecho en el estilo y selectioná ‘modificar’ para cambiar el formato de la fuente, así como el párrafo (por ejemplo, podés introducir saltos de página antes de ciertos estilos que pueden ayudar con el espaciado). Otros aspectos del documento de Word, como los márgenes, el tamaño de la página, los encabezados, etc., pueden modificarse como un documento de Word normal en el que se trabaja directamente.\n\n\n\n\n\n\n\n\n\n\n\nDocumentos en Powerpoint\nComo en el caso anterior, creá un nuevo conjunto de diapositivas o utiliza un archivo PowerPoint existente con el formato deseado. Para seguir editando, cliqueá en “Ver” y “Patrón de diapositivas”. Desde aquí se puede cambiar la apariencia de la diapositiva “maestra” editando el formato del texto en los cuadros de texto, así como el fondo y las dimensiones del página.\n\n\n\n\n\n\n\n\n\nDesgraciadamente, la edición de archivos PowerPoint es un poco menos flexible:\n\nUn encabezado de primer nivel (# Header 1) se convertirá automáticamente en el título de una nueva diapositiva,\nEl texto del # Header 2 no aparecerá como subtítulo, sino como texto dentro del cuadro de texto principal de la diapositiva (a menos que encuentre una manera de manipular la vista del Patrón).\nLos gráficos y las tablas resultantes irán automáticamente a nuevas diapositivas. Tendrás que combinarlos, por ejemplo con la función patchwork para combinar ggplots, para que aparezcan en la misma página. Esta entrada del blog trata el uso del paquete patchwork para colocar múltiples imágenes en una diapositiva.\n\nEn el paquete oficcer  encontrarás una herramienta para trabajar más a fondo con las presentaciones de PowerPoint.\n\n\nIntegración de plantillas en el YAML\nUna vez preparada la plantilla, el detalle de la misma puede añadirse en el YAML del Rmd debajo de la línea ‘output’ y debajo de donde se especifica el tipo de documento (que va a una línea aparte). Para las plantillas de diapositivas de PowerPoint se puede utilizar reference_doc.\nLo más fácil es guardar la plantilla en la misma carpeta en la que está el archivo Rmd (como en el ejemplo siguiente), o en una subcarpeta dentro de ella.\n---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---\n\n\nFormateo de archivos HTML\nLos archivos HTML no utilizan plantillas, pero pueden tener los estilos configurados dentro del YAML. Los HTML son documentos interactivos y particularmente flexibles. Aquí cubrimos algunas opciones básicas.\n\nTabla de contenidos: Podemos añadir una tabla de contenidos con toc: true, y también especificar que permanezca visible (“flotante”) al desplazarse, con toc_float: true.\nTemas: Nos referimos a algunos temas prearmados, que provienen de una biblioteca de temas de Bootswatch. En el siguiente ejemplo utilizamos cerulean. Otras opciones son: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex y yeti.\nResaltar: Configurando esto se cambia el aspecto del texto resaltado (por ejemplo, el código dentro de los trozos que se muestran). Los estilos disponibles son default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark y textmate.\n\nHe aquí un ejemplo de cómo integrar las opciones anteriores en el YAML.\n---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---\nA continuación se muestran dos ejemplos de salidas HTML ambas con tablas de contenido flotantes pero con diferentes estilos de tema y resaltado seleccionados:",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#dynamic-content",
    "href": "new_pages/rmarkdown.es.html#dynamic-content",
    "title": "40  Informes con R Markdown",
    "section": "40.9 Contenido dinámico",
    "text": "40.9 Contenido dinámico\nEn una salida HTML, el contenido de tu informe puede ser dinámico. A continuación, veremos algunos ejemplos:\n\nTablas\nEn un informe HTML, se puede imprimir un dataframe / tibble de manera que el contenido sea dinámico, con filtros y barras de desplazamiento. Hay varios paquetes que ofrecen esta capacidad.\nPara hacer esto con el paquete DT, como se utiliza en este manual, se puede insertar un trozo de código como este:\n\n\n\n\n\n\n\n\n\nLa función datatable() imprimirá el dataframe proporcionado como una tabla dinámica para el lector. Puedes establecer rownames = FALSE para simplificar el extremo izquierdo de la tabla. filter = \"top\" proporciona un filtro sobre cada columna. En el argumento options() proporciona una lista de otras especificaciones. A continuación incluimos dos: pageLength = 5 determina que el número de filas a mostrar sea 5 (las filas restantes se pueden ver paginando a través de flechas), y scrollX=TRUE habilita una barra de desplazamiento en la parte inferior de la tabla (para visualizar las columnas que se extienden a la extrema derecha).\nSi tu conjunto de datos es muy grande, considerá mostrar sólo las filas superiores envolviendo los datos en head().\n\n\nWidgets HTML\nLos widgets HTML para R son un tipo especial de paquetes de R que permiten una mayor interactividad utilizando bibliotecas de JavaScript. Puedes incorporarlos en salidas HTML R Markdown.\nAlgunos ejemplos comunes de estos widgets son:\n\nPlotly (utilizado en la página de este manual y en la página de Gráficos interactivos\nvisNetwork (utilizado en la página de Cadenas de transmisión de este manual)\nLeaflet (Folleto) (utilizado en la página Conceptos básicos de los SIG de este manual)\ndygraphs (útil para mostrar interactivamente los datos de las series temporales)\nDT (datatable()) (se utiliza para mostrar tablas dinámicas con filtro, ordenación, etc.)\n\nLa función ggplotly() de plotly es particularmente fácil de usar. Consúltalo en la sección en la página de Gráficos interactivos.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/rmarkdown.es.html#resources-33",
    "href": "new_pages/rmarkdown.es.html#resources-33",
    "title": "40  Informes con R Markdown",
    "section": "40.10 Recursos",
    "text": "40.10 Recursos\nPodés encontrar más información en:\n\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://rmarkdown.rstudio.com/articles_intro.html\n\nAquí encontras una buena explicación de markdown vs knitr vs Rmarkdown: https://stackoverflow.com/questions/40563479/relationship-between-r-markdown-knitr-pandoc-and-bookdown",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Informes con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html",
    "href": "new_pages/reportfactory.es.html",
    "title": "41  Organización de informes rutinarios",
    "section": "",
    "text": "41.1 Preparación",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#preparation-34",
    "href": "new_pages/reportfactory.es.html#preparation-34",
    "title": "41  Organización de informes rutinarios",
    "section": "",
    "text": "Cargar paquetes\nEn RStudio, instalá la última versión del paquete reportfactory desde Github.\nPodés hacerlo a través del paquete pacman con p_load_current_gh() que forzará la instalación de la última versión desde Github. Proporcioná la cadena de caracteres “reconverse/reportfactory”, que especifica la organización de Github (reconverse) y el repositorio (reportfactory). También puede utilizar install_github() del paquete remotes, como alternativa.\n\n# Instalá y cargá la última versión del paquete desde Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternativa",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#new-factory",
    "href": "new_pages/reportfactory.es.html#new-factory",
    "title": "41  Organización de informes rutinarios",
    "section": "41.2 Nueva fábrica",
    "text": "41.2 Nueva fábrica\nPara crear una nueva fábrica, ejecutá la función new_factory(). Esto creará una nueva carpeta de proyecto R autocontenida con las siguientes características predeterminadas:\n\nLa fábrica se añadirá a tu directorio de trabajo\nEl nombre del proyecto R de la fábrica será “new_factory.Rproj”\nTu sesión de RStudio se “trasladará” a este proyecto R\n\n\n# Este comando creará una fabrica en el directorio de trabajo\nnew_factory()\n\nMirando dentro de la fábrica, se puede ver que las subcarpetas y algunos archivos se han creado de manera automática.\n\n\n\n\n\n\n\n\n\n\nLa carpeta report_sources contendrá tus scripts R Markdown, que generan sus informes\nLa carpeta de outputs contendrá el informe de salida (por ejemplo, HTML, Word, PDF, etc.)\nLa carpeta de scripts puede utilizarse para guardar otros scripts de R (por ejemplo, los que se convican en tus scripts de Rmd)\nLa carpeta de data puede utilizarse para guardar tus datos (se incluyen las subcarpetas “raw” (datos brutos) y “clean” (datos limpios))\nUn archivo .here, para que puedas utilizar el paquete here para convocar a los archivos de las subcarpetas gracias a su relación con esta carpeta raíz (véase la página de proyectos en R para más detalles)\nSe ha creado un archivo gitignore en caso de que se vincule este proyecto R a un repositorio de Github (ver [Control de versiones y colaboración con Github])\nUn archivo README vacío, en caso de que uses un repositorio de Github\n\nPRECAUCIÓN:: dependiendo de la configuración de tu ordenador, los archivos como “.here” pueden existir pero estar ocultos.\nA continuación mencionamos configuraciones predeterminadas que tal vez quieras ajustar con el comando new_factory():\n\nfactory = Proporciona un nombre para la carpeta de fábrica (por defecto es “new_factory”)\npath = Designa una ruta de archivo para la nueva fábrica (por defecto es el directorio de trabajo)\nreport_sources = Proporciona un nombre alternativo para la subcarpeta que contiene los scripts R Markdown (por defecto es “report_sources”)\noutputs = Proporciona un nombre alternativo para la carpeta que contiene los resultados del informe (por defecto es “outputs”)\n\nVer ?new_factory para ver una lista completa de los argumentos.\nCuando creás la nueva fábrica, tu sesión de R se transfiere al nuevo proyecto R, por lo que debés cargar de nuevo el paquete reportfactory.\n\npacman::p_load(reportfactory)\n\nAhora podés ejecutar el comando factory_overview() para ver la estructura interna (todas las carpetas y archivos) de la fábrica.\n\nfactory_overview()            # muestra la estructura de la fábrica en la consola\n\nEl siguiente “árbol” de las carpetas y archivos de la fábrica se imprime en la consola de R. Fijáte que en la carpeta “data” hay subcarpetas para los datos “raw” y “clean”, y datos CSV de ejemplo. También hay “example_report.Rmd” en la carpeta “report_sources”.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#create-a-report",
    "href": "new_pages/reportfactory.es.html#create-a-report",
    "title": "41  Organización de informes rutinarios",
    "section": "41.3 Crear un informe",
    "text": "41.3 Crear un informe\nDesde la fábrica del proyecto R, creá un informe R Markdown como lo harías normalmente, y guardálo en la carpeta “report_sources”. Consultá la página de R Markdown para obtener instrucciones. A modo de ejemplo, hemos añadido lo siguiente a la fábrica:\n\nUn nuevo script de R markdown titulado “daily_sitrep.Rmd”, guardado dentro de la carpeta “report_sources”.\nDatos para el informe (“linelist_cleaned.rds”) guardados en la subcarpeta “clean” dentro de la carpeta “data”\n\nEjecutando factory_overview() podemos ver el archivo R Markdown en la carpeta “report_sources” y el archivo de datos en la carpeta de datos “clean” (resaltado):\n\n\n\n\n\n\n\n\n\nA continuación mostramos una captura de pantalla del comienzo del archivo de Markdown “daily_sitrep.Rmd”. Podés ver que el formato de salida está configurado para ser HTML, a través de la cabecera YAML output: html_document.\n\n\n\n\n\n\n\n\n\nEn este sencillo script, hay comandos para:\n\nCargar los paquetes necesarios\nImportar los datos del listado de casos utilizando una ruta de archivo del paquete here (lea más en la página sobre Importación y exportación)\n\n\nlinelist &lt;- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\n\n\nImprimir una tabla de resumen de casos, y exportarla con export() como un archivo .csv\nImprimir una epicurva, y exportarla con ggsave() como un archivo .png\n\nPodés revisar la lista de informes R Markdown en la carpeta “report_sources” con este comando:\n\nlist_reports()",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#compile",
    "href": "new_pages/reportfactory.es.html#compile",
    "title": "41  Organización de informes rutinarios",
    "section": "41.4 Compilar",
    "text": "41.4 Compilar\nEn una fábrica de informes, “compilar” un informe de R Markdown implica que se ejecutará el script .Rmd y se producirá la salida (como se especifica en el script YAML, por ejemplo, como HTML, Word, PDF, etc.).\nLa fábrica creará automáticamente una carpeta con fecha y hora para las salidas en la carpeta “outputs”.\nEl informe de salida y los archivos generados por el script (por ejemplo, csv, png, xlsx) se guardarán en esta carpeta. Además, el propio script Rmd se guardará en esta carpeta, así tendrás un registro de esa versión del script.\nEsto contrasta con el comportamiento normal de un R Markdown “tejido”, que guarda las salidas en la ubicación del script Rmd. Este comportamiento por defecto puede resultar en carpetas abarrotadas y desordenadas. El objetivo de la fábrica es mejorar la organización de archivos cuando uno necesita ejecutar informes con frecuencia.\n\nCompilar por nombre\nPodés compilar un informe específico ejecutando compile_reports() y proporcionando el nombre del script Rmd (sin la extensión .Rmd) a reports =. Para simplificar, podés omitir reports = y simplemente escribir el nombre R Markdown entre comillas, como se indica a continuación.\n\n\n\n\n\n\n\n\n\nEste comando compilaría sólo el informe “daily_sitrep.Rmd”, guardando el informe de HTML, y las exportaciones de la tabla de .csv y la epicurva de .png en una subcarpeta con fecha y hora específicas, dentro de la carpeta “outputs”.\nTené en cuenta que si proporcionás la extensión .Rmd, debés escribir la extensión tal como aparece en el nombre del archivo (.rmd vs. .Rmd).\nTambién hay que tener en cuenta que, al compilar, es posible que aparezcan temporariamente varios archivos en la carpeta “report_sources”, pero pronto desaparecerán al ser transferidos a la carpeta “outputs”.\n\n\nCompilación por número\nTambién se puede especificar el script Rmd a compilar proporcionando un número o vector de números a reports =. Los números deben alinearse con el orden en que aparecen los informes cuando se ejecuta list_reports().\n\n# Compilar el segundo y el cuarto Rmd en la carpeta \"report_sources\"\ncompile_reports(reports = c(2, 4))\n\n\n\nCompilar todos\nPuedes compilar todos los informes R Markdown en la carpeta “report_sources” usando el argumento reports = a TRUE.\n\n\n\n\n\n\n\n\n\n\n\nCompilar desde la subcarpeta\nPodés añadir subcarpetas a la carpeta “report_sources”. Para ejecutar un informe R Markdown desde una subcarpeta, simplemente proporcioná el nombre de la carpeta a subfolder =. A continuación se muestra un ejemplo de código para compilar un informe Rmd localizado en una subcarpeta de “report_sources”.\n\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\n\nPodés compilar todos los informes Rmd dentro de una subcarpeta proporcionando el nombre de la subcarpeta a reports =, con una barra al final, como se indica a continuación.\n\ncompile_reports(reports = \"for_partners/\")\n\n\n\nParametrización\nComo indicamos en la página sobre Informes con R Markdown, podés ejecutar informes con parámetros especificados. Podés pasar estos parámetros como una lista a compile_reports() a través del argumento params =. Por ejemplo, en este informe ficticio hay tres parámetros proporcionados a los informes de R Markdown.\n\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)\n\n\n\nUtilizar un “run-file”\nSi tenés que ejecutar varios informes, podés crear un script de R que contenga todos los comandos compile_reports(). Un usuario puede simplemente ejecutar todos los comandos en este script de R y todos los informes se compilarán. Puedes guardar este “archivo de ejecución” (run file) en la carpeta “scripts”.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#outputs-1",
    "href": "new_pages/reportfactory.es.html#outputs-1",
    "title": "41  Organización de informes rutinarios",
    "section": "41.5 Salidas",
    "text": "41.5 Salidas\nDespués de haber compilado los informes unas cuantas veces, la carpeta “outputs” tendría este aspecto (los resaltados se han añadido para mayor claridad):\n\n\n\n\n\n\n\n\n\n\nDentro de “outputs”, se han creado subcarpetas para cada informe Rmd\nDentro de ellas, se han creado otras subcarpetas para cada compilación única\n\nEstán marcados con fecha y hora (“2021-04-23_T11-07-36” significa 23 de abril de 2021 a las 11:07:36)\nPodés editar el formato de la fecha/hora. Ver ?compile_reports\n\nDentro de cada carpeta compilada de fecha/hora, se almacena el resultado del informe (por ejemplo, HTML, PDF, Word) junto con el script Rmd (¡control de versiones!) y cualquier otro archivo exportado (por ejemplo, table.csv, epidemic_curve.png)\n\nEsta es una vista dentro de una de las carpetas con fecha/hora, para el informe “daily_sitrep”. La ruta del archivo está resaltada en amarillo para enfatizar.\n\n\n\n\n\n\n\n\n\nPor último, a continuación mostramos una captura de pantalla del informe de salida de HTML .\n\n\n\n\n\n\n\n\n\nPodés utilizar list_outputs() para ver una lista de las salidas.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#miscellaneous-1",
    "href": "new_pages/reportfactory.es.html#miscellaneous-1",
    "title": "41  Organización de informes rutinarios",
    "section": "41.6 Miscelánea",
    "text": "41.6 Miscelánea\n\nKnit\nSi querés “procesar” uno de tus informes R Markdown cliqueando el botón “Knit” podés hacerlo. En este caso, por defecto, las salidas aparecerán en la carpeta donde se guarda el Rmd - la carpeta “report_sources”. En versiones anteriores de reportfactory, la presencia de cualquier archivo que no sea Rmd en la carpeta “report_sources” impediría la compilación, pero esto ya no es así. Es posible ejecutar compile_reports() y no se producirá ningún error.\n\n\nScripts\nTe recomendamos utilizar la carpeta “scripts” para almacenar “archivos de ejecución” o scripts .R que se originan en tus scripts .Rmd. Consultá la página sobre R Markdown para obtener consejos sobre cómo estructurar tu código en varios archivos.\n\n\nExtras\n\nCon reportfactory, podés utilizar la función list_deps() para listar todos los paquetes requeridos en todos los informes de toda la fábrica.\nHay un paquete de acompañamiento en desarrollo llamado rfextras que ofrece más funciones de ayuda para asistirte en la construcción de informes, tales como:\n\nload_scripts() - carga todos los scripts .R en una carpeta determinada (la carpeta “scripts” por defecto)\nfind_latest()- encuentra la última versión de un archivo (por ejemplo, el último conjunto de datos)",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/reportfactory.es.html#resources-34",
    "href": "new_pages/reportfactory.es.html#resources-34",
    "title": "41  Organización de informes rutinarios",
    "section": "41.7 Recursos",
    "text": "41.7 Recursos\nConsultá la página de Github del paquete reportfactory\nConsultá la página de Github del paquete rfextras",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Organización de informes rutinarios</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html",
    "href": "new_pages/flexdashboard.es.html",
    "title": "42  Dashboards con R Markdown",
    "section": "",
    "text": "42.1 Preparación",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#preparation-35",
    "href": "new_pages/flexdashboard.es.html#preparation-35",
    "title": "42  Dashboards con R Markdown",
    "section": "",
    "text": "Cargar paquetes\nEn este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.\n\npacman::p_load(\n  rio,             # importación/exportación de datos     \n  here,            # localizar archivos\n  tidyverse,       # gestión y visualización de datos\n  flexdashboard,   # versiones dashboard de informes R Markdown\n  shiny,           # figuras interactivas\n  plotly           # figuras interactivas\n\n)\n\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).\n\n# importa linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nA continuación se muestran las primeras 50 filas del listado.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#create-new-r-markdown",
    "href": "new_pages/flexdashboard.es.html#create-new-r-markdown",
    "title": "42  Dashboards con R Markdown",
    "section": "42.2 Crear un nuevo R Markdown",
    "text": "42.2 Crear un nuevo R Markdown\nUna vez instalado el paquete, crea un nuevo archivo R Markdown clicando en File &gt; New file &gt; R Markdown.\n\n\n\n\n\n\n\n\n\nEn la ventana que se abre, selecciona “From Template” y selecciona la plantilla “Flex Dashboard”. A continuación, pedirá que nombres el documento. En el ejemplo de esta página, nombraremos nuestro R Markdown como “outbreak_dashboard.Rmd”.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#the-script",
    "href": "new_pages/flexdashboard.es.html#the-script",
    "title": "42  Dashboards con R Markdown",
    "section": "42.3 El script",
    "text": "42.3 El script\nEl script es un script de R Markdown, y por lo tanto tiene los mismos componentes y organización que se describen en la página sobre Informes con R Markdown. Volvemos a revisar brevemente estos y destacamos las diferencias con otros formatos de salida de R Markdown.\n\nYAML\nEn la parte superior del script está la cabecera “YAML”. Esta debe comenzar con tres guiones --- y debe cerrarse con tres guiones ---. Los parámetros YAML vienen en pares key:value. La sangría y la colocación de los dos puntos en YAML es importante - los pares key:value están separados por dos puntos (¡no por signos de igualdad!).\nEl YAML debe comenzar con los metadatos del documento. El orden de estos parámetros YAML primarios (sin sangría) no importa. Por ejemplo:\n\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\n\nPuedes utilizar código R en los valores YAML poniéndolo como código en línea (precedido por r entre comillas) pero también entre comillas (véase más arriba para la fecha).\nUn parámetro YAML necesario es output:, que especifica el tipo de archivo que se producirá (por ejemplo, html_document, pdf_document, word_document, o powerpoint_presentation). En el caso de flexdashboard el valor de este parámetro es un poco confuso - debe establecerse como output:flexdashboard::flex_dashboard. Ten en cuenta los dos puntos simples y dobles, y el guión bajo. Este parámetro de salida YAML suele ir seguido de dos puntos adicionales y de subparámetros con sangría (ver parámetros orientation: y vertical_layout: más abajo).\n\ntitle: \"My dashboard\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll\n\nComo se muestra arriba, se utilizan sangrías (2 espacios) para los subparámetros. En este caso, no olvides poner dos puntos adicionales después del primario, como key:value:.\nSi procede, los valores lógicos deben indicarse en YAML en minúsculas (true, false, null). Si los dos puntos forman parte del valor (por ejemplo, en el título), escribe el valor entre comillas. Revisa los ejemplos en las secciones siguientes.\n\n\nTrozos de código\nUn script de R Markdown puede contener múltiples “trozos” de código (Chunk) - estas son áreas del script donde se puede escribir código R de varias líneas y funcionan como mini scripts R.\nLos trozos de código se crean con tres signos de acento grave (```) y corchetes con una “r” minúscula dentro. El fragmento se cierra con otros tres acentos graves (acento atrás). Puedes crear un nuevo fragmento escribiéndolo tú mismo, utilizando el atajo de teclado “Ctrl + Alt + i” (o Cmd + Shift + r en Mac), o clicando en el icono verde ‘insertar un nuevo fragmento de código’ en la parte superior de tu editor de scripts. A continuación se ofrecen muchos ejemplos.\n\n\nTexto narrativo\nFuera de un “trozo” de código R, puedes escribir texto narrativo. Como se describe en la página sobre Informes con R Markdown, puedes poner el texto en cursiva rodeándolo con un asterisco (*), o en negrita rodeándolo con dos asteriscos (**). Recuerda que las viñetas y los esquemas de numeración son sensibles a las nuevas líneas, a la sangría y a terminar una línea con dos espacios.\nTambién puedes insertar código R en línea en el texto, como se describe en la página Informes con R Markdown, rodeando el código con puntos suspensivos y comenzando el comando con “r”: ` 1+1` (véase el ejemplo con la fecha anterior).\n\n\nEncabezados\nLos diferentes niveles de encabezamiento se establecen con diferentes números de símbolos hash, como se describe en la página Informes con R Markdown.\nEn flexdashboard, un encabezado primario (#) crea una “página” del dashboard. Los encabezados de segundo nivel (##) crean una columna o una fila dependiendo de su parámetro orientation: (ver detalles más abajo). Los encabezados de tercer nivel (###) crean paneles para gráficos, diagramas, tablas, texto, etc.\n# Título de primer nivel (página)\n\n## Título de segundo nivel (fila o columna)\n\n### Título de tercer nivel (panel para gráfico, diagrama, etc.)",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#section-attributes",
    "href": "new_pages/flexdashboard.es.html#section-attributes",
    "title": "42  Dashboards con R Markdown",
    "section": "42.4 Atributos de la sección",
    "text": "42.4 Atributos de la sección\nAl igual que en un R Markdown normal, puedes especificar los atributos que se aplicarán a las partes del cuadro de mando incluyendo las opciones key=value después de un encabezado, entre llaves { }. Por ejemplo, en un típico informe HTML R Markdown podrías organizar los sub-encabezados en pestañas con ## My heading {.tabset}.\nTen en cuenta que estos atributos se escriben después de un título en una parte de texto del script. Son diferentes a las opciones de knitr insertadas dentro en la parte superior de los trozos de código R, como out.height =.\nLos atributos de sección específicos de flexdashboard incluyen:\n\n{data-orientation=} Establece la orientación de las filas rows o de las columnas columns.{orientación de los datos=} . Si tu dashboard tiene varias páginas, añade este atributo a cada una de ellas para indicar la orientación (se explica con más detalle en la sección de diseño).\n{data-width=} y {data-height=} establecen el tamaño relativo de los gráficos, columnas y filas dispuestos en la misma dimensión (horizontal o vertical). Los tamaños absolutos se ajustan para llenar mejor el espacio en cualquier dispositivo de visualización gracias al motor flexbox.\n\nLa altura de las figuras también depende de si se establece el parámetro YAML vertical_layout: fill or vertical_layout: scroll. Si se establece en scroll, la altura de la figura reflejará la opción tradicional fig.height = en el fragmento de código de R.\nConsulta la documentación completa sobre el tamaño en el sitio web de flexdashboard\n\n{.hidden} Utiliza esto para excluir una página específica de la barra de navegación\n{data-navbar=} Utilízalo en un encabezado a nivel de página para anidarlo dentro de un menú desplegable de la barra de navegación. Indica el nombre (entre comillas) del menú desplegable. Véase el ejemplo siguiente.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#layout",
    "href": "new_pages/flexdashboard.es.html#layout",
    "title": "42  Dashboards con R Markdown",
    "section": "42.5 Diseño",
    "text": "42.5 Diseño\nAjusta el diseño de tu panel de control de las siguientes maneras:\n\nAñadir páginas, columnas/filas y gráficos con encabezados R Markdown (por ejemplo, #, ## o ###)\n\nAjustar la orientación de los parámetros YAML: orientation: a rows o columns\n\nEspecificar si el diseño llena el navegador o permite el desplazamiento\n\nAñadir pestañas a un título de sección concreto\n\n\nPáginas\nLos encabezados de primer nivel (#) en el R Markdown representarán las “páginas” del cuadro de mando. Por defecto, las páginas aparecerán en una barra de navegación a lo largo de la parte superior del dashboard.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPuedes agrupar las páginas en un “menú” dentro de la barra de navegación superior añadiendo el atributo {data-navmenu=} al título de la página. Ten cuidado: no incluyas espacios alrededor del signo de igualdad, de lo contrario no funcionará.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:\n\n\n\n\n\n\n\n\n\nTambién puedes convertir una página o una columna en una “barra lateral” en el lado izquierdo del panel de control añadiendo el atributo {.sidebar}. Puede contener texto (visible desde cualquier página) o, si has integrado una interactividad Shiny, puede ser útil para contener controles de entrada del usuario, como deslizadores o menús desplegables.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:\n\n\n\n\n\n\n\n\n\n\n\nOrientación\nAñade el parámetro orientation: yaml para indicar cómo deben interpretarse los encabezados de segundo nivel (##) de R Markdown - como orientation: columns o orientation: rows.\nLos encabezados de segundo nivel (##) se interpretarán como nuevas columnas o filas en función de este ajuste de orientación.\nSi estableces orientation: columns, las cabeceras de segundo nivel crearán nuevas columnas en el dashboard. El siguiente dashboard tiene una página, que contiene dos columnas, con un total de tres paneles. Puedes ajustar el ancho relativo de las columnas con {data-width=} como se muestra a continuación.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:\n\n\n\n\n\n\n\n\n\nSi estableces orientation: rows, los encabezados de segundo nivel crearán nuevas filas en lugar de columnas. A continuación se muestra el mismo script que el anterior, pero con orientation: rows para que los encabezados de segundo nivel produzcan filas en lugar de columnas. Puedes ajustar la altura relativa de las filas con {data-height=} como se muestra a continuación.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:\n\n\n\n\n\n\n\n\n\nSi tu dashboard tiene varias páginas, puedes designar la orientación para cada página específica añadiendo el atributo {data-orientation=} a la cabecera de cada página (especifica rows o columns sin comillas).\n\n\nPestañas\nPuedes dividir el contenido en pestañas con el atributo {.tabset}, como en otras salidas HTML R Markdown.\nSimplemente añade este atributo después del título deseado. Los subtítulos bajo ese encabezado se mostrarán como pestañas. Por ejemplo, en el script de ejemplo que aparece a continuación, la columna 2 de la derecha (##) se modifica para que la curva epidémica y los paneles de la tabla (###) se muestren en pestañas.\nPuedes hacer lo mismo con las filas si su orientación es de filas.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#adding-content",
    "href": "new_pages/flexdashboard.es.html#adding-content",
    "title": "42  Dashboards con R Markdown",
    "section": "42.6 Añadir contenido",
    "text": "42.6 Añadir contenido\nComencemos a construir un panel de control. Nuestro sencillo panel de control tendrá 1 página, 2 columnas y 4 paneles. Construiremos los paneles pieza por pieza para la demostración.\nPuedes incluir fácilmente salidas estándar de R, como texto, ggplots y tablas (véase la página Tablas para presentaciones). Simplemente codifícalos dentro de un fragmento de código R como lo harías con cualquier otro script de R Markdown.\nNota: puedes descargar el script Rmd terminado y el resultado del Dashboard en HTML - ver la página descargando el manual y los datos.\n\nTexto\nPuedes escribir el texto de Markdown e incluir el código en línea como para cualquier otra salida de R Markdown. Consulta la página Informes con R Markdown para obtener más detalles.\nEn este dashboard incluimos un panel de texto resumido que incluye un texto dinámico que muestra la última fecha de hospitalización y el número de casos notificados en el brote.\n\n\nTablas\nPuedes incluir trozos de código R que impriman salidas como tablas. Pero la salida se verá mejor y responderá al tamaño de la ventana si utilizas la función kable() de knitr para mostrar las tablas. Las funciones de flextable pueden producir tablas acortadas / cortadas.\nPor ejemplo, a continuación alimentamos linelist() a través de un comando count() para producir una tabla resumen de casos por hospital. Finalmente, la tabla se enlaza a knitr::kable() y el resultado tiene una barra de desplazamiento a la derecha. Puedes leer más sobre la personalización de la tabla con kable() y kableExtra aquí.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:\n\n\n\n\n\n\n\n\n\nSi deseas mostrar una tabla dinámica que permita al usuario filtrar, ordenar y/o clicar a través de las “páginas” del dataframe, utiliza el paquete DT y su función datatable(), como en el código siguiente.\nEn el código de ejemplo que sigue, se imprime linelist del dataframe. Se puede establecer rownames = FALSE para conservar el espacio horizontal, y filter = \"top\" para tener filtros en la parte superior de cada columna. Se puede proporcionar una lista de otras especificaciones a options =. A continuación, establecemos pageLength = para que aparezcan 5 filas y scrollX = para que el usuario pueda utilizar una barra de desplazamiento en la parte inferior para desplazarse horizontalmente. El argumento class = 'white-space: nowrap' asegura que cada fila sea sólo una línea (no varias líneas). Puedes consultar otros argumentos y valores posibles aquí o introduciendo ?datatable\n\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = list(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )\n\n\n\nGráficos\nPuedes imprimir gráficos en un panel de control como lo harías en un script de R. En nuestro ejemplo, utilizamos el paquete incidence2 para crear una “epicurva” por grupo de edad con dos simples comandos (véase la página de curvas epidémicas). Sin embargo, podrías utilizar ggplot() e imprimir un gráfico de la misma manera.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:\n\n\n\n\n\n\n\n\n\n\n\nGráficos interactivos\nTambién puedes pasar un ggplot estándar u otro objeto de gráfico a ggplotly() del paquete plotly (véase la página de gráficos interactivos). Esto hará que el gráfico sea interactivo, permitirá al lector hacer un “zoom”, y mostrará sobre el dashboard el valor de cada punto de datos (en este escenario el número de casos por semana y el grupo de edad en la curva).\n\nage_outbreak &lt;- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %&gt;% \n  plotly::ggplotly()\n\nEsto es lo que parece en el dashboard (gif). Esta funcionalidad interactiva seguirá funcionando incluso si envías por correo electrónico el Dashboard como un archivo estático (no en línea en un servidor).\n\n\n\n\n\n\n\n\n\n\n\nWidgets HTML\nLos widgets HTML para R son un tipo especial de paquetes R que aumentan la interactividad utilizando bibliotecas JavaScript. Se pueden incrustar en salidas R Markdown (como un flexdashboard) y en dashboards de Shiny.\nAlgunos ejemplos comunes de estos widgets son:\n\nPlotly (utilizado en la página de este manual y en la página de Plots interativos)\nvisNetwork (utilizado en la página de cadenas de transmisión de este manual)\nLeaflet (utilizado en la página conceptos básicos de los SIG de este manual)\ndygraphs (útil para mostrar interactivamente los datos de las series temporales)\nDT (datatable()) (utilizado para mostrar tablas dinámicas con filtro, ordenación, etc.)\n\nA continuación mostramos la adición de una cadena de transmisión de epidemias que utiliza visNetwork al dashboard. El guión muestra sólo el nuevo código añadido a la sección “Columna 2” del script R Markdown. Puedes encontrar el código en la página de cadenas de transmisión de este manual.\n\n\n\n\n\n\n\n\n\nEsto es lo que produce el script:",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#code-organization",
    "href": "new_pages/flexdashboard.es.html#code-organization",
    "title": "42  Dashboards con R Markdown",
    "section": "42.7 Organización del código",
    "text": "42.7 Organización del código\nPuedes elegir tener todo el código dentro del script de R Markdown flexdashboard. Alternativamente, para tener un script de dashboard más limpio y conciso, puedes elegir llamar al código/figuras que están alojadas o creadas en scripts R externos. Esto se describe con mayor detalle en la página Informes con R Markdown.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#shiny-1",
    "href": "new_pages/flexdashboard.es.html#shiny-1",
    "title": "42  Dashboards con R Markdown",
    "section": "42.8 Shiny",
    "text": "42.8 Shiny\nLa integración del paquete R shiny puede hacer que tus Dashboards sean aún más reactivos a la entrada del usuario. Por ejemplo, puedes hacer que el usuario selecciona una jurisdicción, o un rango de fechas, y hacer que los paneles reaccionen a su elección (por ejemplo, filtrar los datos mostrados). Para incrustar la reactividad de shiny en el flexdashboard, sólo tienes que hacer unos pocos cambios en tu script de R Markdown en el flexdashboard.\nTambién se puede utilizar shiny para producir aplicaciones/dashboards sin flexdashboard. La página del manual sobre Dashboards con Shiny ofrece una visión general de este enfoque, incluyendo consejos sobre la sintaxis de Shiny, la estructura de los archivos de la aplicación y las opciones para compartir/publicar (incluyendo opciones de servidor gratuito). Esta sintaxis y los consejos generales se traducen también en el contexto de flexdashboard.\nLa incrustación de shiny en el flexdashboard supone, sin embargo, un cambio fundamental en tu flexdashboard. Ya no producirá una salida HTML que puedas enviar por correo electrónico y que cualquiera puede abrir y ver. En su lugar, será una “aplicación”. El botón “Knit” en la parte superior del script será reemplazado por un icono “Run document”, que abrirá una instancia del dashboard interactivo localmente en tu ordenador.\nPara compartir tu panel de control, ahora será necesario que:\n\nEnviar el script Rmd al espectador, ellos lo abren en R en su ordenador, y ejecutan la aplicación, o\nLa aplicación/dashboard se aloja en un servidor accesible para el espectador\n\nPor lo tanto, la integración de shiny tiene ventajas, pero también complicaciones. Si la facilidad de compartir por correo electrónico es una prioridad y no necesitas las capacidades reactivas de shiny, considera la reducida interactividad que ofrece ggplotly() como se ha demostrado anteriormente.\nA continuación damos un ejemplo muy sencillo utilizando el mismo “outbreak_dashboard.Rmd” que el anterior. Una amplia documentación sobre la integración de Shiny en flexdashboard está disponible en línea aquí.\n\nAjustes\nHabilitar shiny en un flexdashboard añadiendo el parámetro YAML runtime: shiny en el mismo nivel de sangría que output:, como se indica a continuación:\n---\ntitle: \"Dashboard del brote (demo Shiny)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---\nTambién es conveniente habilitar una “barra lateral” para albergar los widgets de entrada de Shiny que recogerán la información del usuario. Como se explicó anteriormente, crea una columna e indica la opción {.sidebar} para crear una barra lateral en el lado izquierdo. Dentro de esta columna se pueden añadir trozos de texto R que contengan los comandos input de shiny.\nSi tu aplicación/panel está alojado en un servidor y puede tener varios usuarios simultáneos, nombra el primer trozo de código R como global. Incluye los comandos para importar/cargar tus datos en este chunk. Este chunk con nombre especial es tratado de manera diferente, y los datos importados dentro de él sólo se importan una vez (no continuamente) y están disponibles para todos los usuarios. Esto mejora la velocidad de arranque de la aplicación.\n\n\nEjemplo trabajado\nAquí adaptamos el script flexdashboard “outbreak_dashboard.Rmd” para incluir shiny. Añadiremos la capacidad de que el usuario seleccione un hospital de un menú desplegable, y que la curva epidémica refleje sólo los casos de ese hospital, con un título de gráfico dinámico. Hacemos lo siguiente:\n\nAñadir runtime: shiny al YAML\nRenombrar el chunk de configuración como global\nCrear una barra lateral que contenga:\n\nCódigo para crear un vector de nombres únicos de hospitales\nUn comando selectInput() (menú desplegable Shiny) con la elección de los nombres de los hospitales. La selección se guarda como hospital_choice, a la que se puede hacer referencia en código posterior como input$hospital_choice\n\nEl código de la curva epidémica (columna 2) está envuelto dentro de renderPlot({ }), incluyendo:\n\nUn filtro en los datos que restringe la columna hospital al valor actual de input$hospital_choice\nUn título de gráfico dinámico que incorpora input$hospital_choice\n\n\nTen en cuenta que cualquier código que haga referencia a un valor de input$ debe estar dentro de una función render({}) (para ser reactiva).\nAquí está la parte superior del script, incluyendo el YAML, el chunk global y la barra lateral:\n\n\n\n\n\n\n\n\n\nAquí está la Columna 2, con el gráfico de la epicurva reactiva:\n\n\n\n\n\n\n\n\n\nY aquí está el Dashboard:\n\n\n\n\n\n\n\n\n\n\n\nOtros ejemplos\nPara leer un ejemplo relacionado con la salud de un Shiny-flexdashboard que utiliza la interactividad de Shiny y el widget de mapeo leaflet, consulta este capítulo del libro en línea Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#sharing",
    "href": "new_pages/flexdashboard.es.html#sharing",
    "title": "42  Dashboards con R Markdown",
    "section": "42.9 Compartir",
    "text": "42.9 Compartir\nLos Dashboards que no contengan elementos Shiny producirán un archivo HTML (.html), que puede enviarse por correo electrónico (si el tamaño lo permite). Esto es útil, ya que puedes enviar el informe del “dashboard” y no tener que configurar un servidor para alojarlo como un sitio web.\nSi has incrustado shiny, no podrás enviar una salida por correo electrónico, pero puedes enviar el propio script a un usuario de R, o alojar el Dashboard en un servidor como se ha explicado anteriormente.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/flexdashboard.es.html#resources-35",
    "href": "new_pages/flexdashboard.es.html#resources-35",
    "title": "42  Dashboards con R Markdown",
    "section": "42.10 Recursos",
    "text": "42.10 Recursos\nA continuación se pueden encontrar excelentes tutoriales que informaron esta página. Si los revisas, lo más probable es que en una hora puedas tener tu propio Dashboard.\nhttps://bookdown.org/yihui/rmarkdown/dashboards.html\nhttps://rmarkdown.rstudio.com/flexdashboard/\nhttps://pkgs.rstudio.com/flexdashboard/articles/using.html\nhttps://pkgs.rstudio.com/flexdashboard/articles/examples.html",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Dashboards con R Markdown</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html",
    "href": "new_pages/shiny_basics.es.html",
    "title": "43  Dashboards con Shiny",
    "section": "",
    "text": "43.1 Preparación",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#preparation-36",
    "href": "new_pages/shiny_basics.es.html#preparation-36",
    "title": "43  Dashboards con Shiny",
    "section": "",
    "text": "Cargar paquetes\nEn este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.\nComenzamos instalando el paquete R Shiny:\n\npacman::p_load(\"shiny\")\n\n\n\nImportar datos\nSi quieres seguir esta página, consulta esta sección del Manual de descarga y datos. Hay enlaces para descargar los scripts de R y los archivos de datos que producen la aplicación final de Shiny.\nSi intentas reconstruir la aplicación utilizando estos archivos, ten en cuenta la estructura de carpetas del proyecto R que se crea en el transcurso de la demostración (por ejemplo, carpetas para “data” y para “funcs”).",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#the-structure-of-a-shiny-app",
    "href": "new_pages/shiny_basics.es.html#the-structure-of-a-shiny-app",
    "title": "43  Dashboards con Shiny",
    "section": "43.2 Estructura de una app Shiny",
    "text": "43.2 Estructura de una app Shiny\n\nEstructuras básicas de archivos\nPara entender Shiny, primero tenemos que entender cómo funciona la estructura de archivos de una aplicación. Deberíamos crear un nuevo directorio antes de empezar. Esto puede hacerse más fácil eligiendo Nuevo proyecto en Rstudio, y eligiendo Aplicación Web Shiny. Esto creará la estructura básica de una aplicación shiny para ti.\nAl abrir este proyecto, notarás que ya hay un archivo .R llamado app.R. Es esencial que tengamos una de las dos estructuras básicas de archivos:\n\nUn archivo llamado app.R, o\nDos archivos, uno llamado ui.R y el otro server.R\n\nEn esta página, utilizaremos el primer enfoque de tener un archivo llamado app.R. Aquí hay un script de ejemplo:\n\n# un ejemplo de app.R\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n    # Título de la aplicación\n    titlePanel(\"My app\"),\n\n    # Barra lateral con un widget de entrada deslizante\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # Mostrar un gráfico \n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n# Definir la lógica del servidor necesaria para dibujar un histograma\nserver &lt;- function(input, output) {\n     \n     plot_1 &lt;- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot &lt;- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Ejecutar la aplicación \nshinyApp(ui = ui, server = server)\n\nSi abres este archivo, te darás cuenta de que hay dos objetos definidos: uno llamado ui (interfaz de usuario) y otro llamado server (servidor). Estos objetos deben ser definidos en todas las aplicaciones shiny y son fundamentales para la estructura de la propia aplicación. De hecho, la única diferencia entre las dos estructuras de archivos descritas anteriormente es que en la estructura 1, tanto ui como server están definidos en un solo archivo, mientras que en la estructura 2 están definidos en archivos separados. Nota: también podemos (y deberíamos si tenemos una aplicación más grande) tener otros archivos .R en nuestra estructura que podemos llamar con source() desde nuestra aplicación.\n\n\nEl servidor y la Interfaz de Usuario (ui)\nA continuación, tenemos que entender lo que hacen realmente los objetos server y ui. En pocas palabras, se trata de dos objetos que interactúan entre sí cada vez que el usuario interactúa con la app shiny.\nEl elemento de interfaz de usuario de una aplicación Shiny es, en un nivel básico, el código R que crea una interfaz HTML. Esto significa todo lo que se muestra en la UI de una app. Esto generalmente incluye:\n\n“Widgets” - menús desplegables, casillas de verificación, deslizadores, etc. con los que puede interactuar el usuario\nGráficos, tablas, etc. - resultados que se generan con el código R\nAspectos de la navegación de una aplicación: pestañas, paneles, etc.\nTexto genérico, hipervínculos, etc.\nElementos HTML y CSS (abordados más adelante)\n\nLo más importante que hay que entender sobre la UI es que recibe entradas del usuario y muestra salidas del servidor. No hay código activo que se ejecute en la UI en ningún momento - todos los cambios que se ven en la UI pasan por el servidor (más o menos). Así que tenemos que hacer nuestros gráficos, descargas, etc en el servidor\nEl servidor de la app shiny es donde se ejecuta todo el código una vez que la aplicación se inicia. La forma en que esto funciona es un poco confusa. La función del servidor reaccionará efectivamente a la interfaz del usuario con la UI, y ejecutará trozos de código en respuesta. Si las cosas cambian en el servidor, estas serán pasadas de vuelta a la UI, donde pueden verse los cambios. Es importante destacar que el código en el servidor se ejecutará de forma no consecutiva (o es mejor pensarlo así). Básicamente, cada vez que una entrada de la ui afecte a un trozo de código en el servidor, éste se ejecutará automáticamente, y se producirá y mostrará esa salida.\nProbablemente todo esto suene muy abstracto por ahora, así que tendremos que sumergirnos en algunos ejemplos para tener una idea clara de cómo funciona realmente.\n\n\nAntes de empezar a crear una app\nAntes de empezar a construir una aplicación, es muy útil saber qué quieres construir. Dado que tu interfaz de usuario estará escrita en código, no puedes visualizar realmente lo que estás construyendo a menos que tengas como objetivo algo específico. Por esta razón, es inmensamente útil mirar muchos ejemplos de aplicaciones Shiny para tener una idea de lo que puedes hacer - ¡incluso mejor si puedes mirar el código fuente detrás de estas aplicaciones! Algunos de los mejores recursos para ello son:\n\nLa galería de aplicaciones de Rstudio\n\nUna vez que tengas una idea de lo que es posible, también es útil hacer un mapa de cómo quieres que sea la tuya; puedes hacerlo en papel o en cualquier software de dibujo (PowerPoint, MS paint, etc.). Es útil empezar con algo sencillo para tu primera aplicación. Tampoco hay que avergonzarse de utilizar el código que encuentres en Internet de una buena aplicación como plantilla para tu trabajo: es mucho más fácil que construir algo desde cero.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#building-a-ui",
    "href": "new_pages/shiny_basics.es.html#building-a-ui",
    "title": "43  Dashboards con Shiny",
    "section": "43.3 Construir una interfaz de usuario",
    "text": "43.3 Construir una interfaz de usuario\nCuando construimos nuestra aplicación, es más fácil trabajar en la interfaz de usuario (UI) primero para que podamos ver lo que estamos haciendo, y no arriesgarnos a que la aplicación falle debido a cualquier error del servidor. Como se mencionó anteriormente, a menudo es bueno utilizar una plantilla cuando se trabaja en la interfaz de usuario. Hay una serie de diseños estándar que se pueden utilizar con shiny que están disponibles en el paquete base de shiny, pero vale la pena señalar que también hay una serie de extensiones del paquete como shinydashboard. Utilizaremos un ejemplo del paquete shiny básico para empezar.\nUna interfaz de usuario Shiny se define generalmente como una serie de funciones anidadas, en el siguiente orden\n\nUna función que define el diseño general (la más básica es fluidPage(), pero hay más disponibles)\nPaneles dentro del diseño como:\n\nuna barra lateral (sidebarPanel())\nun panel “principal” (mainPanel())\nuna pestaña (tabPanel())\nuna “columna” genérica (column())\n\nWidgets y salidas: pueden conferir entradas al servidor (widgets) o salidas del servidor (salidas)\n\nLos widgets suelen tener el estilo de xxxInput(), por ejemplo, selectInput()\nLas salidas suelen tener el estilo de xxxOutput(), por ejemplo, plotOutput()\n\n\nVale la pena repetir que estos datos no se pueden visualizar fácilmente de forma abstracta, por lo que es mejor ver un ejemplo. Consideremos la posibilidad de crear una aplicación básica que visualice nuestros datos de recuento de instalaciones de malaria por distrito. Estos datos tienen muchos parámetros diferentes, por lo que sería estupendo que el usuario final pudiera aplicar algunos filtros para ver los datos por grupo de edad/distrito según su criterio. Podemos utilizar un diseño Shiny muy simple para empezar - el diseño de la barra lateral. Se trata de un diseño en el que los widgets se colocan en una barra lateral a la izquierda, y el gráfico se coloca a la derecha.\nPlanifiquemos nuestra aplicación: podemos empezar con un selector que nos permita elegir el distrito donde queremos visualizar los datos, y otro que nos permita visualizar el grupo de edad que nos interesa. Con estos filtros pretendemos mostrar una epicurva que refleje estos parámetros. Para ello necesitamos:\n\nDos menús desplegables que nos permiten elegir el distrito que queremos y el grupo de edad que nos interesa.\nUn área donde podemos mostrar nuestra epicurva resultante.\n\nEsto podría ser algo así:\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector para el distrito\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector para el grupo de edad\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # La curva epidemiológica va aquí\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nCuando se ejecuta app.R con el código de interfaz de usuario anterior (sin código activo en la parte del server de app.R), el diseño aparece con el siguiente aspecto: ten en cuenta que no habrá ningún gráfico si no hay un servidor que lo represente, ¡pero nuestras entradas están funcionando!\n\n\n\n\n\n\n\n\n\nEsta es una buena oportunidad para discutir cómo funcionan los widgets - nota que cada widget está aceptando un inputId, una label (etiqueta), y una serie de otras opciones que son específicas para el tipo de widget. Este inputId es extremadamente importante - estos son los IDs que se utilizan para pasar la información de la UI al servidor. Por esta razón, deben ser únicos. Deberías hacer un esfuerzo para denominarlos con algo sensato, y específico a lo que están interactuando en casos de aplicaciones más grandes.\nDeberías leer la documentación cuidadosamente para conocer todos los detalles sobre lo que hace cada uno de estos widgets. Los widgets pasarán tipos específicos de datos al servidor dependiendo del tipo de widget, y esto debe entenderse completamente. Por ejemplo, selectInput() pasará un dato de tipo carácter al servidor:\n\nSi seleccionamos Spring para el primer widget aquí, pasará el objeto carácter \"Spring\" al servidor.\nSi seleccionamos dos elementos del menú desplegable, aparecerán como un vector de caracteres (por ejemplo, c(\"Primavera\", \"Bolo\")).\n\nOtros widgets pasarán diferentes tipos de objetos al servidor. Por ejemplo:\n\nnumericInput() pasará un objeto de tipo numérico al servidor\ncheckboxInput() pasará un objeto de tipo lógico al servidor (TRUE o FALSE)\n\nTambién vale la pena tener en cuenta el nombre del vector que usaremos para los datos de edad aquí. Para muchos widgets, el uso de un vector para las opciones mostrará los nombres del vector como las opciones de visualización, pero pasará el valor seleccionado del vector al servidor. Por ejemplo, aquí alguien puede seleccionar “15+” en el menú desplegable, y la interfaz de usuario pasará \"malaria_rdt_15\" al servidor, que resulta ser el nombre de la columna que nos interesa.\nHay un montón de widgets que puedes utilizar para hacer muchas cosas con tu aplicación. Los widgets también permiten cargar archivos en la aplicación y descargar resultados. También hay algunas excelentes extensiones de shiny que te dan acceso a más widgets que el shiny básico - el paquete shinyWidgets es un gran ejemplo de esto. Para ver algunos ejemplos puedes consultar los siguientes enlaces:\n\nGalería de widgets de Shiny\nGalería de shinyWidgets",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#loading-data-into-our-app",
    "href": "new_pages/shiny_basics.es.html#loading-data-into-our-app",
    "title": "43  Dashboards con Shiny",
    "section": "43.4 Cargar datos en nuestra app",
    "text": "43.4 Cargar datos en nuestra app\nEl siguiente paso en el desarrollo de nuestra aplicación es poner en marcha el servidor. Para ello, sin embargo, tenemos que conseguir algunos datos en nuestra aplicación, y averiguar todos los cálculos que vamos a hacer. Una aplicación Shiny no es fácil de depurar, ya que a menudo no está claro de dónde provienen los errores, por lo que es ideal desarrollar el código todo nuestro procesamiento de datos y visualización antes de empezar a hacer el propio servidor.\nAsí que dado que queremos hacer una aplicación que muestre epicurvas que cambien en base a la entrada del usuario, deberíamos pensar en qué código necesitaríamos para ejecutar esto en un script normal de R. Necesitaremos:\n\nCargar nuestros paquetes\nCargar nuestros datos\nTransformar nuestros datos\nDesarrollar una función para visualizar nuestros datos en función de las entradas del usuario\n\nEsta lista es bastante sencilla, y no debería ser demasiado difícil de hacer. Ahora es importante pensar qué partes de este proceso deben hacerse una sola vez y qué partes deben ejecutarse en respuesta a las entradas del usuario. Esto se debe a que las aplicaciones Shiny generalmente ejecutan algún código antes de ejecutarse, que sólo se realiza una vez. Ayudará al rendimiento de nuestra aplicación si la mayor parte de nuestro código puede ser trasladado a esta sección. Para este ejemplo, sólo necesitamos cargar nuestros datos/paquetes y hacer transformaciones básicas una vez, así que podemos poner ese código fuera del servidor. Esto significa que lo único que necesitaremos en el servidor es el código para visualizar nuestros datos. Vamos a desarrollar todos estos componentes en un script primero. Sin embargo, ya que estamos visualizando nuestros datos con una función, también podemos poner el código de la función fuera del servidor para que nuestra función esté en el entorno cuando la aplicación se ejecute.\nPrimero vamos a cargar nuestros datos. Ya que estamos trabajando con un nuevo proyecto, y queremos limpiarlo, podemos crear un nuevo directorio llamado data, y añadir nuestros datos de malaria allí. Podemos ejecutar este código de abajo en un script de prueba que eventualmente borraremos cuando limpiemos la estructura de nuestra aplicación.\n\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# lectura de datos\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\nprint(malaria_data)\n\n# A tibble: 3,038 × 10\n   location_name data_date  submitted_date Province District `malaria_rdt_0-4`\n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt;\n 1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11\n 2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11\n 3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8\n 4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16\n 5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9\n 6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3\n 7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4\n 8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15\n 9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11\n10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19\n# ℹ 3,028 more rows\n# ℹ 4 more variables: `malaria_rdt_5-14` &lt;int&gt;, malaria_rdt_15 &lt;int&gt;,\n#   malaria_tot &lt;int&gt;, newid &lt;int&gt;\n\n\nSerá más fácil trabajar con estos datos si utilizamos estándares de datos ordenados, por lo que también debemos transformarlos en un formato de datos más largo, donde el grupo de edad es una columna, y los casos son otra columna. Podemos hacer esto fácilmente usando lo que hemos aprendido en la página de Pivotar datos.\n\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)\n\n# A tibble: 12,152 × 7\n   location_name data_date  submitted_date Province District age_group       \n   &lt;chr&gt;         &lt;date&gt;     &lt;date&gt;         &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;           \n 1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0-4 \n 2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5-14\n 3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15  \n 4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot     \n 5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0-4 \n 6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5-14\n 7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15  \n 8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot     \n 9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0-4 \n10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5-14\n# ℹ 12,142 more rows\n# ℹ 1 more variable: cases_reported &lt;int&gt;\n\n\nY con esto hemos terminado de preparar nuestros datos! Esto tacha los puntos 1, 2 y 3 de nuestra lista de cosas a desarrollar para nuestro “script de prueba de R”. La última tarea, y la más difícil, será construir una función para producir una epicurva basada en parámetros definidos por el usuario. Como se mencionó anteriormente, se recomienda encarecidamente que cualquier persona que aprenda shimy primero mire la sección sobre la programación funcional (Escribir funciones) para entender cómo funciona esto!\nAl definir nuestra función, puede ser difícil pensar en los parámetros que queremos incluir. Para la programación funcional con shiny, cada parámetro relevante tendrá generalmente un widget asociado a él, así que pensar en esto suele ser bastante fácil. Por ejemplo, en nuestra aplicación actual, queremos ser capaces de filtrar por distrito, y tener un widget para ello, por lo que podemos añadir un parámetro de distrito para reflejar esto. No tenemos ninguna funcionalidad de la aplicación para filtrar por centro (por ahora), así que no necesitamos añadir esto como parámetro. Empecemos haciendo una función con tres parámetros:\n\nLos datos básicos\nEl distrito de elección\nEl grupo de edad elegido\n\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nNo entraremos en grandes detalles sobre esta función, ya que su funcionamiento es relativamente sencillo. Una cosa a tener en cuenta, sin embargo, es que debemos gestionar los errores devolviendo NULL cuando de otro modo daría un error. Esto se debe a que cuando un servidor Shiny produce un objeto NULL en lugar de un objeto gráfico, ¡no se mostrará nada en la interfaz de usuario! Esto es importante, ya que de lo contrario los errores a menudo harán que la aplicación deje de funcionar.\nOtra cosa a tener en cuenta es el uso del operador %in% cuando se evalúa la entrada del district. Como se mencionó anteriormente, esto podría llegar como un vector de caracteres con múltiples valores, por lo que el uso de %in% es más flexible que, por ejemplo, ==.\nVamos a probar nuestra función!\n\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n\n\n\n\n\n\n\n\nCon nuestra función ya trabajando, ahora tenemos que entender cómo va a encajar todo esto en nuestra aplicación Shiny. Hemos mencionado el concepto de código de inicio antes, pero vamos a ver cómo podemos incorporar esto en la estructura de nuestra aplicación. Hay dos maneras de hacerlo.\n\nEscribe este código en tu archivo app.R al principio del script (por encima de la interfaz de usuario), o\nCrea un nuevo archivo en el directorio de tu aplicación llamado global.R, y pon el código de inicio en él.\n\nVale la pena señalar en este punto que generalmente es más fácil, especialmente con aplicaciones más grandes, utilizar la segunda estructura de archivos, ya que permite separar su estructura de una manera sencilla. Vamos a desarrollar completamente este script global.R ahora. Esto es lo que podría parecer:\n\n# script global.R\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n# lectura de datos\nmalaria_data &lt;- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %&gt;% \n  as_tibble()\n\n# limpiar datos y pivotar largo\nmalaria_data &lt;- malaria_data %&gt;%\n  select(-newid) %&gt;%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# define la función de gráficos\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # crear el título del gráfico\n  if (!(\"All\" %in% district)) {            \n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filtra el grupo de edad\n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nFácil! Una gran característica es qe shiny entenderá para qué sirven los archivos llamados app.R, server.R, ui.R y global.R, por lo que no es necesario conectarlos entre sí mediante ningún código. Así que sólo con tener este código en global.R en el directorio adecuado se ejecutará antes de que iniciemos nuestra app!\nTambién debemos tener en cuenta que mejoraría la organización de nuestra aplicación si movemos la función de dibujar a su propio archivo - esto será especialmente útil a medida que las aplicaciones se hacen más grandes. Para hacer esto, podríamos hacer otro directorio llamado funcs, y poner esta función en un archivo llamado plot_epicurve.R. Podríamos entonces leer esta función a través del siguiente comando en global.R\n\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)\n\nTen en cuenta que siempre debes especificar local = TRUE en las aplicaciones shiny, ya que afectará a la obtención de recursos cuando/si la aplicación se publica en un servidor.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#developing-an-app-server",
    "href": "new_pages/shiny_basics.es.html#developing-an-app-server",
    "title": "43  Dashboards con Shiny",
    "section": "43.5 Desarrollar un servidor de app",
    "text": "43.5 Desarrollar un servidor de app\nAhora que tenemos la mayor parte de nuestro código, sólo tenemos que desarrollar nuestro servidor. Esta es la pieza final de nuestra aplicación, y es probablemente la más difícil de entender. El servidor es una gran función de R, pero es útil pensar en él como una serie de funciones más pequeñas, o tareas que la aplicación puede realizar. Es importante entender que estas funciones no se ejecutan en un orden lineal. Hay un orden en ellas, pero no es necesario entenderlo del todo cuando se empieza con Shiny. A un nivel muy básico, estas tareas o funciones se activarán cuando haya un cambio en las entradas del usuario que las afecte, a menos que el desarrollador las haya configurado para que se comporten de forma diferente. De nuevo, todo esto es bastante abstracto, pero vamos a repasar primero los tres tipos básicos de objetos shiny\n\nFuentes reactivas - este es otro término para las entradas del usuario. El servidor shiny tiene acceso a las salidas de la UI a través de los widgets que hemos programado. Cada vez que los valores de estos se cambian, esto se pasa al servidor.\nConductores reactivos - estos son objetos que existen sólo dentro del servidor Shiny. En realidad no los necesitamos para aplicaciones simples, pero producen objetos que sólo pueden ser vistos dentro del servidor, y utilizados en otras operaciones. Generalmente dependen de fuentes reactivas.\nPuntos finales: son las salidas que se pasan del servidor a la interfaz de usuario. En nuestro ejemplo, esto sería la epicurva que estamos produciendo.\n\nCon esto en mente vamos a construir nuestro servidor paso a paso. Vamos a mostrar nuestro código de interfaz de usuario de nuevo aquí sólo para referencia:\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector para el distrito\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector para el grupo de edad\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # La curva epidemiológica va aquí\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\n\nDe este código UI tenemos:\n\nDos entradas:\n\nSelector de distrito (con un inputId de select_district)\nSelector de grupo de edad (con un inputId de select_agegroup)\n\nUna salida:\n\nLa epicurva (con un outputId de malaria_epicurve)\n\n\nComo hemos dicho anteriormente, estos nombres únicos que hemos asignado a nuestras entradas y salidas son cruciales. Deben ser únicos y se utilizan para pasar información entre la ui y el servidor. En nuestro servidor, accedemos a nuestras entradas a través de la sintaxis input$inputID y a las salidas y las pasamos a la ui a través de la sintaxis output$output_name ¡Veamos un ejemplo, porque de nuevo esto es difícil de entender de otra manera!\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}\n\nEl servidor para una aplicación simple como esta es en realidad bastante sencillo. Te darás cuenta de que el servidor es una función con tres parámetros - input, output, and session - esto no es tan importante para entender por ahora, pero es importante seguir esta configuración. En nuestro servidor sólo tenemos una tarea - esta procesa un gráfico basado en la función que hicimos antes, y las entradas del servidor. Fíjate en que los nombres de los objetos de entrada y salida se corresponden exactamente con los de la interfaz de usuario.\nPara entender los fundamentos de cómo el servidor reacciona a las entradas del usuario, debes tener en cuenta que la salida sabrá (a través del paquete subyacente) cuando las entradas cambian, y volver a ejecutar esta función para crear un gráfico cada vez que cambian. Ten en cuenta que aquí también utilizamos la función renderPlot() - esta es de una familia de funciones específicas del tipo que pasan esos objetos a una salida ui. Hay una serie de funciones que se comportan de manera similar, pero hay que asegurarse de que la función utilizada coincide con el tipo de objeto que se está pasando a la ui. Por ejemplo:\n\nrenderText() - enviar texto a la ui\nrenderDataTable - envía una tabla interactiva a la ui.\n\nRecuerda que estos también necesitan coincidir con la función de salida utilizada en la ui - así que renderPlot() se empareja con plotOutput(), y renderText() se empareja con textOutput().\nAsí que finalmente hemos hecho una aplicación que funciona! Podemos ejecutarla clicando el botón Ejecutar aplicación en la parte superior derecha de la ventana de script en Rstudio. Debes tener en cuenta que puedes elegir ejecutar tu aplicación en tu navegador por defecto (en lugar de Rstudio), lo que reflejará con mayor precisión el aspecto que tendrá la aplicación para otros usuarios.\n\n\n\n\n\n\n\n\n\n¡Es divertido observar que en la consola R, la aplicación está “escuchando”. Hablando de reactividad!",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#adding-more-functionality",
    "href": "new_pages/shiny_basics.es.html#adding-more-functionality",
    "title": "43  Dashboards con Shiny",
    "section": "43.6 Añadir más funcionalidad",
    "text": "43.6 Añadir más funcionalidad\nEn este punto tenemos finalmente una aplicación en funcionamiento, pero tenemos muy poca funcionalidad. Tampoco hemos rascado la superficie de lo que shiny puede hacer, ¡así que hay mucho más que aprender! Vamos a seguir construyendo nuestra aplicación actual añadiendo algunas características adicionales. Algunas cosas que podría ser bueno añadir:\n\nAlgunos textos explicativos\nUn botón de descarga para nuestra gráfica - esto proporcionaría al usuario una versión de alta calidad de la imagen que está generando en la aplicación\nUn selector de instalaciones específicas\nOtra página del panel de control: podría mostrar una tabla con nuestros datos.\n\nEsto es mucho para agregar, pero podemos usarlo para aprender en el camino un montón de diferentes características de Shiny. Hay mucho que aprender sobre Shiny (puede ser muy avanzado, pero es de esperar que una vez que los usuarios tienen una mejor idea de cómo usarlo pueden llegar a ser más cómodo usando fuentes de aprendizaje externas también).\n\nAñadir texto estático\nVamos a hablar primero de la adición de texto estático a nuestra aplicación Shiny. Añadir texto a nuestra aplicación es extremadamente fácil, una vez que se tiene un conocimiento básico de la misma. Dado que el texto estático no cambia en la aplicación shiny (si quieres que cambie, puedes utilizar las funciones de procesado de texto en el servidor), todo el texto estático de shiny se añade generalmente en la interfaz de usuario de la aplicación. No vamos a entrar en detalles, pero puedes añadir un número de elementos diferentes a su ui (e incluso personalizados) mediante la interfaz de R con HTML y css.\nHTML y css son lenguajes que intervienen explícitamente en el diseño de la interfaz de usuario. No es necesario entenderlos demasiado bien, pero HTML crea objetos en la interfaz de usuario (como un cuadro de texto, o una tabla), y css se utiliza generalmente para cambiar el estilo y la estética de esos objetos. Shiny tiene acceso a una gran variedad de etiquetas HTML - éstas están presentes para los objetos que se comportan de una manera específica, como los encabezados, los párrafos de texto, los saltos de línea, las tablas, etc. Podemos utilizar algunos de estos ejemplos así:\n\nh1() - esta es una etiqueta de encabezado, que hará que el texto adjunto sea automáticamente más grande, y cambiará los valores predeterminados en cuanto a la fuente, el color, etc. (dependiendo del tema general de tu aplicación). Puedes acceder a subtítulos cada vez más pequeños con h2() hasta h6() también. El uso es así:\n\nh1(\"mi cabecera - sección 1\")\n\np() - esta es una etiqueta de párrafo, que hará que el texto encerrado sea similar al texto de un cuerpo de texto. Este texto se envolverá automáticamente, y será de un tamaño relativamente pequeño (los pies de página podrían ser más pequeños, por ejemplo). Piensa en ello como el cuerpo de texto de un documento de Word. El uso es así:\n\np(\"Este es un cuerpo de texto más grande donde explico la función de mi aplicación\")\n\ntags$b() ytags$i() - se utilizan para poner tags$b() en negrita (bold) y tags$i() en cursiva el texto que se incluya entre los paréntesis.\ntags$ul(), tags$ol() y tags$li() - son etiquetas utilizadas para crear listas. Todas ellas se utilizan dentro de la sintaxis siguiente, y permiten al usuario crear una lista ordenada (tags$ol(); es decir, numerada) o desordenada (tags$ul(), es decir, con viñetas). tags$li() se utiliza para marcar los elementos de la lista, independientemente del tipo de lista que se utilice. p. ej:\n\n\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\n\n\nbr() y hr() - estas etiquetas crean saltos de línea y líneas horizontales (con un salto de línea) respectivamente. Utilízalas para separar las secciones de tu aplicación y el texto. No es necesario pasar ningún elemento a estas etiquetas (los paréntesis pueden permanecer vacíos).\ndiv() - esta es una etiqueta genérica que puede contener cualquier cosa, y puede tener cualquier nombre. Una vez que avances en el diseño de la interfaz de usuario, puedes utilizarlas para compartimentar tu interfaz de usuario, dar estilos específicos a determinadas secciones y crear interacciones entre el servidor y los elementos de la interfaz de usuario. No vamos a entrar en detalles, pero vale la pena conocerlos.\n\nTen en cuenta que se puede acceder a cada uno de estos objetos a través de tags$... o para algunos, sólo la función. Estos son efectivamente sinónimos, pero puede ayudar a utilizar el estilo tags$... si prefieres ser más explícito y no sobrescribir las funciones accidentalmente. Esta no es en absoluto una lista exhaustiva de etiquetas disponibles. Hay una lista completa de todas las etiquetas disponibles en shiny aquí e incluso se pueden utilizar más insertando HTML directamente en su ui!\nSi te sientes seguro, también puedes añadir cualquier elemento de estilo css a tus etiquetas HTML con el argumento style en cualquiera de ellas. No vamos a entrar en detalles sobre cómo funciona esto, pero un consejo para probar los cambios estéticos en una interfaz de usuario es utilizar el modo de inspector de HTML en Chrome (de tu aplicación Shiny que está ejecutando en el navegador), y editar el estilo de los objetos tu mismo!\nVamos a añadir algo de texto a nuestra aplicación\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # selector para el distrito\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector para el grupo de edad\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # La curva epidemiológica va aquí\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)\n\n\n\n\n\n\n\n\n\n\n\n\nAñadir un enlace\nPara añadir un enlace a una página web, utiliza tags$a() con el enlace y el texto a mostrar como se muestra a continuación. Para tener como un párrafo independiente, escríbelo dentro de p(). Para tener sólo algunas palabras de una frase enlazada, divide la frase en partes y utiliza tags$a() para la parte hipervinculada. Para que el enlace se abra en una nueva ventana del navegador, añade target = \"_blank\" como argumento.\n\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")\n\n\n\nAñadir un botón de descarga\nPasemos a la segunda de las tres características. Un botón de descarga es una cosa bastante común para añadir a una aplicación y es bastante fácil de hacer. Tenemos que añadir otro Widget a nuestra ui, y tenemos que añadir otra salida a nuestro servidor para adjuntarlo. También podemos introducir conductores reactivos en este ejemplo!\nVamos a actualizar nuestra interfaz de usuario primero - esto es fácil ya que Shiny viene con un widget llamado downloadButton() - vamos a darle un inputId y una label (etiqueta).\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector para el distrito\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector para el grupo de edad\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # línea horizontal\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # La curva epidemiológica va aquí\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nObserva que también hemos añadido una etiqueta hr() - esto añade una línea horizontal que separa nuestros widgets de control de nuestros widgets de descarga. Esta es otra de las etiquetas HTML que hemos discutido anteriormente.\nAhora que tenemos nuestra ui lista, necesitamos añadir el componente del servidor. Las descargas se realizan en el servidor con la función downloadHandler(). De manera similar a nuestra trama, necesitamos adjuntarla a una salida que tenga el mismo inputId que el botón de descarga. Esta función toma dos argumentos - filename y content - ambos son funciones. Como podrás adivinar, filename se utiliza para especificar el nombre del archivo descargado, y content se utiliza para especificar lo que debe ser descargado. content contiene una función que usarías para guardar los datos localmente - así que si estuvieras descargando un archivo csv podrías usar rio::export(). Como estamos descargando un gráfico, usaremos ggplot2::ggsave(). Veamos cómo programaríamos esto (aún no lo añadiremos al servidor).\n\nserver &lt;- function(input, output, session) {\n  \n  output$malaria_epicurve &lt;- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nObserva que la función content siempre toma un argumento file, que ponemos donde se especifica el nombre del archivo de salida. También puedes notar que estamos repitiendo código aquí - estamos usando nuestra función plot_epicurve() dos veces en este servidor, una para la descarga y otra para la imagen mostrada en la aplicación. Aunque esto no afecta masivamente al rendimiento, significa que el código para generar este gráfico tendrá que ejecutarse cuando el usuario cambie los widgets que especifican el distrito y el grupo de edad, y de nuevo cuando quiera descargar el gráfico. En aplicaciones más grandes, decisiones subóptimas como ésta ralentizarán cada vez más las cosas, así que es bueno aprender a hacer nuestra aplicación más eficiente en este sentido. Lo que tendría más sentido es si tuviéramos una forma de ejecutar el código de la epicurva cuando los distritos/grupos de edad cambien, y dejar que eso sea utilizado por las funciones renderPlot() y downloadHandler(). Aquí es donde entran los conductores reactivos!\nLos conductores reactivos son objetos que se crean en el servidor shiny de forma reactiva, pero no se emiten - sólo pueden ser utilizados por otras partes del servidor. Hay varios tipos de conductores reactivos, pero vamos a repasar los dos básicos.\n\nreactive() - este es el conductor reactivo más básico - reaccionará siempre que cualquier entrada utilizada dentro de él cambie (por nuestros widgets de distrito/grupo de edad)\neventReactive() - este conductor rectivo funciona igual que reactive(), excepto que el usuario puede especificar qué entradas hacen que se vuelva a ejecutar. Esto es útil si tu conductor reactivo tarda mucho en procesar, pero esto se explicará más adelante.\n\nVeamos los dos ejemplos:\n\nmalaria_plot_r &lt;- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# ¡Sólo se ejecuta cuando cambia el selector de distrito!\nmalaria_plot_er &lt;- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\nCuando usamos la configuración de eventReactive(), podemos especificar qué entradas hacen que se ejecute este trozo de código - esto no nos es muy útil por el momento, así que podemos dejarlo por ahora. Ten en cuenta que puedes incluir múltiples entradas con c()\nVeamos cómo podemos integrar esto en el código de nuestro servidor:\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\n\nPuedes ver que sólo estamos llamando a la salida del reactivo que hemos definido en nuestras funciones de descarga y representación gráfica. Una cosa que hay que tener en cuenta y que suele confundir a la gente es que hay que utilizar las salidas de los reactivos como si fueran funciones, por lo que hay que añadir paréntesis vacíos al final de los mismos (es decir, malaria_plot() es correcto, y malaria_plot no lo es). Ahora que hemos añadido esta solución nuestra aplicación es un poco más ordenada, más rápida y más fácil de cambiar ya que todo el código que ejecuta la función epicurve está en un solo lugar.\n\n\n\n\n\n\n\n\n\n\n\nAñadir un selector de instalaciones\nPasemos a nuestra siguiente función: un selector para instalaciones específicas. Implementaremos otro parámetro en nuestra función para poder pasarlo como argumento desde nuestro código. Vamos a ver cómo hacer esto primero - sólo funciona con los mismos principios que los otros parámetros que hemos establecido. Actualicemos y probemos nuestra función.\n\nplot_epicurve &lt;- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data &lt;- data %&gt;%\n      filter(District %in% district)\n    \n    plot_title_district &lt;- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district &lt;- \"all districts\"\n    \n  }\n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data &lt;- data %&gt;%\n    filter(age_group == agegroup)\n  \n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title &lt;- \"All ages\"\n  } else {\n    agegroup_title &lt;- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data &lt;- data %&gt;%\n      filter(location_name == facility)\n    \n    plot_title_facility &lt;- facility\n    \n  } else {\n    \n    plot_title_facility &lt;- \"all facilities\"\n    \n  }\n  \n  # si no quedan datos, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\n\nVamos a probarlo:\n\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\n\n\n\n\n\n\n\n\nCon todas las instalaciones en nuestros datos, no está muy claro qué instalaciones corresponden a qué distritos, y el usuario final tampoco lo sabrá. Esto puede hacer que el uso de la aplicación sea poco intuitivo. Por esta razón, debemos hacer que las opciones de instalaciones en la interfaz de usuario cambien dinámicamente a medida que el usuario cambia de distrito, de modo que una filtra a la otra. Dado que tenemos tantas variables que estamos utilizando en las opciones, también podríamos querer generar algunas de nuestras opciones para la ui en nuestro archivo global.R a partir de los datos. Por ejemplo, podemos añadir este trozo de código a global.R después de haber leído nuestros datos:\n\nall_districts &lt;- c(\"All\", unique(malaria_data$District))\n\n# Dataframe de los nombres de las localidades por distrito\nfacility_list &lt;- malaria_data %&gt;%\n  group_by(location_name, District) %&gt;%\n  summarise() %&gt;% \n  ungroup()\n\nVamos a verlos:\n\nall_districts\n\n[1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\n\n\n\nfacility_list\n\n# A tibble: 65 × 2\n   location_name District\n   &lt;chr&gt;         &lt;chr&gt;   \n 1 Facility 1    Spring  \n 2 Facility 10   Bolo    \n 3 Facility 11   Spring  \n 4 Facility 12   Dingo   \n 5 Facility 13   Bolo    \n 6 Facility 14   Dingo   \n 7 Facility 15   Barnard \n 8 Facility 16   Barnard \n 9 Facility 17   Barnard \n10 Facility 18   Bolo    \n# ℹ 55 more rows\n\n\nPodemos pasar estas nuevas variables a la ui sin ningún problema, ya que son visibles globalmente tanto por el servidor como por la ui. Actualicemos nuestra UI:\n\nui &lt;- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector para el distrito\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector para el grupo de edad\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector para los centros\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # línea horizontal\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # La curva epidemiológica va aquí\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\n\nFíjate en que ahora pasamos variables para nuestras elecciones en lugar de codificarlas en la interfaz de usuario. Esto también puede hacer que nuestro código sea más compacto. Por último, tendremos que actualizar el servidor. Será fácil actualizar nuestra función para incorporar nuestra nueva entrada (sólo tenemos que pasarla como argumento a nuestro nuevo parámetro), pero debemos recordar que también queremos que la ui se actualice dinámicamente cuando el usuario cambie el distrito seleccionado. Es importante entender aquí que podemos cambiar los parámetros y el comportamiento de los widgets mientras la aplicación se está ejecutando, pero esto debe hacerse en el servidor. Tenemos que entender una nueva forma de salida al servidor para aprender a hacer esto.\nLas funciones que necesitamos para entender cómo hacer esto se conocen como funciones de observador, y son similares a las funciones reactivas en cuanto a su comportamiento. Sin embargo, tienen una diferencia clave:\n\nLas funciones reactivas no afectan directamente a las salidas, y producen objetos que pueden verse en otros lugares del servidor\nLas funciones de los observadores pueden afectar a las salidas del servidor, pero lo hacen a través de los efectos secundarios de otras funciones. (También pueden hacer otras cosas, pero esta es su función principal en la práctica)\n\nAl igual que las funciones reactivas, hay dos tipos de funciones de observador, y se dividen por la misma lógica que divide las funciones reactivas:\n\nobserve() - esta función se ejecuta cada vez que cambian las entradas utilizadas dentro de ella\nobserveEvent() - esta función se ejecuta cuando cambia una entrada especificada por el usuario\n\nTambién necesitamos entender las funciones proporcionadas por Shiny que actualizan los widgets. Estas son bastante sencillas de ejecutar - primero toman el objeto session de la función del servidor (esto no necesita ser entendido por ahora), y luego el inputId de la función a ser cambiada. Luego pasamos las nuevas versiones de todos los parámetros que ya son tomados por selectInput() - estos serán actualizados automáticamente en el widget.\nVeamos un ejemplo aislado de cómo podríamos utilizar esto en nuestro servidor. Cuando el usuario cambia de distrito, queremos filtrar nuestra lista de instalaciones por distrito, y actualizar las opciones para que sólo reflejen las que están disponibles en ese distrito (y una opción para todas las instalaciones)\n\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices &lt;- facility_list$location_name\n  } else {\n    new_choices &lt;- facility_list %&gt;%\n      filter(District == input$select_district) %&gt;%\n      pull(location_name)\n  }\n  \n  new_choices &lt;- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\n\nY ya está, podemos añadirlo a nuestro servidor, y ese comportamiento ya funcionará. Este es el aspecto que debería tener nuestro nuevo servidor:\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}\n\n\n\n\n\n\n\n\n\n\n\n\nAñadir otra pestaña con una tabla\nAhora pasaremos al último componente que queremos añadir a nuestra aplicación. Querremos separar nuestra ui en dos pestañas, una de las cuales tendrá una tabla interactiva donde el usuario podrá ver los datos con los que está haciendo la curva epidémica. Para ello, podemos utilizar los elementos de ui empaquetados que vienen con shiny relevantes para las pestañas. En un nivel básico, podemos encerrar la mayor parte de nuestro panel principal en esta estructura general:\n\n# ... el resto de la interfaz de usuario\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\n\nApliquemos esto a nuestra ui. También vamos a querer utilizar el paquete DT aquí - este es un gran paquete para hacer tablas interactivas a partir de datos preexistentes. Podemos ver que se utiliza para DT::datatableOutput() en este ejemplo.\n\nui &lt;- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # selector para el distrito\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector para el grupo de edad\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector para los centros\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # línea horizontal \n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\n\nAhora nuestra aplicación está organizada en pestañas! Hagamos también las modificaciones necesarias en el servidor. Dado que no necesitamos manipular nuestro conjunto de datos antes de procesarlo, esto es muy sencillo: ¡sólo tenemos que procesar los datos malaria_data a través de DT::renderDT() en la interfaz de usuario!\n\nserver &lt;- function(input, output, session) {\n  \n  malaria_plot &lt;- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices &lt;- facility_list$location_name\n    } else {\n      new_choices &lt;- facility_list %&gt;%\n        filter(District == input$select_district) %&gt;%\n        pull(location_name)\n    }\n    \n    new_choices &lt;- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve &lt;- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve &lt;- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # render data table to ui\n  output$raw_data &lt;- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#sharing-shiny-apps",
    "href": "new_pages/shiny_basics.es.html#sharing-shiny-apps",
    "title": "43  Dashboards con Shiny",
    "section": "43.7 Compartir apps Shiny",
    "text": "43.7 Compartir apps Shiny\nAhora que has desarrollado tu aplicación, probablemente quieras compartirla con los demás, ¡al fin y al cabo esta es la principal ventaja de shiny! Podemos hacerlo compartiendo el código directamente, o podemos publicarlo en un servidor. Si compartimos el código, otros podrán ver lo que has hecho y construir sobre él, pero esto anulará una de las principales ventajas de shiny: puede eliminar la necesidad de que los usuarios finales mantengan una instalación de R. Por esta razón, si estás compartiendo tu aplicación con usuarios que no se sienten cómodos con R, es mucho más fácil compartir una aplicación que ha sido publicada en un servidor.\nSi prefieres compartir el código, puedes hacer un archivo .zip de la aplicación, o mejor aún, publicar tu aplicación en github y añadir colaboradores. Puedes consultar la sección de github para más información aquí.\nSin embargo, si vamos a publicar la aplicación en línea, tenemos que hacer un poco más de trabajo. En última instancia, queremos que se pueda acceder a tu aplicación a través de una URL web para que otros puedan acceder a ella de forma rápida y sencilla. Desafortunadamente, para publicar tu aplicación en un servidor, necesitas tener acceso a un servidor donde publicarla. Hay varias opciones de alojamiento en este sentido:\n\nshinyapps.io: es el lugar más sencillo para publicar aplicaciones shiny, ya que es el que menos trabajo de configuración necesita, y tiene algunas licencias gratuitas, pero limitadas.\nRStudio Connect: es una versión mucho más potente de un servidor de R, que puede realizar muchas operaciones, incluida la publicación de aplicaciones Shinys. Sin embargo, es más difícil de usar y menos recomendable para los usuarios noveles.\n\nPara los propósitos de este documento, utilizaremos shinyapps.io, ya que es más fácil para los usuarios noveles. Puedes hacer una cuenta gratuita aquí para empezar - también hay diferentes planes de precios para las licecias de los servidores si es necesario. Cuantos más usuarios esperes tener, más caro tendrá que ser tu plan de precios, así que tenlo en cuenta. Si quieres crear algo para un pequeño grupo de personas, una licencia gratuita puede ser perfectamente adecuada, pero una aplicación de cara al público puede necesitar más licencias.\nPrimero debemos asegurarnos de que nuestra aplicación es adecuada para publicar en un servidor. En tu aplicación, debes reiniciar tu sesión de R, y asegurarte de que se ejecuta sin ejecutar ningún código extra. Esto es importante, ya que una aplicación que requiere la carga de paquetes, o la lectura de datos no definidos en el código de tu aplicación no se ejecutará en un servidor. También ten en cuenta que no puedes tener rutas de archivo explícitas en tu aplicación - éstas serán inválidas en la configuración del servidor - el uso del paquete here resuelve muy bien este problema. Por último, si estás leyendo datos de una fuente que requiere autenticación de usuario, como los servidores de tu organización, esto no funcionará generalmente en un servidor. Tendrás que ponerte en contacto con tu departamento de TI para averiguar cómo poner en la lista blanca el Shiny servidor.\nregistro de la cuenta\nUna vez que tengas tu cuenta, puedes navegar a la página de tokens en Accounts. Aquí querrás añadir un nuevo token, que se utilizará para desplegar tu aplicación.\nA partir de aquí, debes tener en cuenta que la url de tu cuenta reflejará el nombre de tu app - así que si tu app se llama mi_app, la url se añadirá como xxx.io/mi_app/. Elige bien el nombre de tu aplicación. Ahora que está todo listo, clica en desplegar - si tiene éxito esto ejecutará tu aplicación en la url web elegida.\n¿algo sobre la creación de aplicaciones en documentos?",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#further-reading",
    "href": "new_pages/shiny_basics.es.html#further-reading",
    "title": "43  Dashboards con Shiny",
    "section": "43.8 Más información",
    "text": "43.8 Más información\nHasta ahora, hemos cubierto muchos aspectos de shiny, y apenas hemos arañado la superficie de lo que ofrece shiny. Aunque esta guía sirve de introducción, hay mucho más que aprender para entender completamente shiny. Deberías empezar a crear aplicaciones y añadir gradualmente más y más funcionalidad",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#recommended-extension-packages",
    "href": "new_pages/shiny_basics.es.html#recommended-extension-packages",
    "title": "43  Dashboards con Shiny",
    "section": "43.9 Paquetes de extensión recomendados",
    "text": "43.9 Paquetes de extensión recomendados\nA continuación se presenta una selección de extensiones de shiny de alta calidad que pueden ayudarte a sacar mucho más provecho de shiny. Sin ningún orden en particular:\n\nshinyWidgets - este paquete ofrece muchos más widgets que pueden ser utilizados en tu aplicación. Ejecuta shinyWidgets::shinyWidgetsGallery() para ver una selección de los widgets disponibles con este paquete. Mira los ejemplos aquí\nshinyjs - este es un excelente paquete que da al usuario la capacidad de ampliar en gran medida la utilidad de shiny a través de una serie de javascript. Las aplicaciones de este paquete van desde las más sencillas hasta las más avanzadas, pero es posible que quieras utilizarlo primero para manipular la interfaz de usuario de forma sencilla, como ocultar/mostrar elementos, o activar/desactivar botones. Para más información, consulta aqui\nshinydashboard - este paquete expande masivamente la ui disponible que puede ser usada en shiny, específicamente permitiendo al usuario crear un dashboard complejo con una variedad de diseños complejos. Consulta más aquí\nshinydashboardPlus: ¡aún más funciones del marco de trabajo de shinydashboard! Puedes ver más aquí\nshinythemes - ¡cambia el tema css por defecto de tu app shiny con una amplia gama de plantillas preestablecidas! Más aquí\n\nTambién hay una serie de paquetes que pueden utilizarse para crear resultados interactivos compatibles con Shiny.\n\nDT está semi-incorporado en shinybásico, pero proporciona un gran conjunto de funciones para crear tablas interactivas.\nplotly es un paquete para crear gráficos interactivos que el usuario puede manipular en la aplicación. También puede convertir sus gráficos en versiones interactivas mediante plotly::ggplotly(). Como alternativas, dygraphs y highcharter son también excelentes.",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/shiny_basics.es.html#recommended-resources",
    "href": "new_pages/shiny_basics.es.html#recommended-resources",
    "title": "43  Dashboards con Shiny",
    "section": "43.10 Recursos recomendados",
    "text": "43.10 Recursos recomendados",
    "crumbs": [
      "Informes y Dashboards",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Dashboards con Shiny</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html",
    "href": "new_pages/writing_functions.es.html",
    "title": "44  Escribir funciones",
    "section": "",
    "text": "44.1 Preparación",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#preparation-37",
    "href": "new_pages/writing_functions.es.html#preparation-37",
    "title": "44  Escribir funciones",
    "section": "",
    "text": "Cargar paquetes\nEste trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página fundamentos de R para obtener más información sobre los paquetes de R.\n\n\nImportar datos\nImportamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso a paso, consulta las instrucciones en la página [Descargar libro y datos]. Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.\nTambién utilizaremos en la última parte de esta página algunos datos sobre la gripe H7N9 de 2013.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#functions-2",
    "href": "new_pages/writing_functions.es.html#functions-2",
    "title": "44  Escribir funciones",
    "section": "44.2 Funciones",
    "text": "44.2 Funciones\nLas funciones son útiles en la programación, ya que permiten hacer códigos más fáciles de entender, de alguna manera más cortos y menos propensos a errores (dado que no hay errores en la propia función).\nSi has llegado hasta este manual, significa que te has encontrado con un sinfín de funciones ya que en R, cada operación es una llamada a una función +, for, if, [, $, { …. Por ejemplo, x + y es lo mismo que'+'(x, y)\nR es uno de los lenguajes que más posibilidades ofrece para trabajar con funciones y da suficientes herramientas al usuario para escribirlas fácilmente. No debemos pensar en las funciones como algo fijo en la cima o al final de la cadena de programación, R ofrece la posibilidad de utilizarlas como si fueran vectores e incluso utilizarlas dentro de otras funciones, listas…\nExisten muchos recursos muy avanzados sobre programación funcional y aquí sólo daremos una visión para ayudarte a empezar con la programación de funciones con breves ejemplos prácticos. Te animamos a visitar los enlaces de las referencias para leer más sobre el tema.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#why-would-you-use-a-function",
    "href": "new_pages/writing_functions.es.html#why-would-you-use-a-function",
    "title": "44  Escribir funciones",
    "section": "44.3 ¿Por qué utilizar una función?",
    "text": "44.3 ¿Por qué utilizar una función?\nAntes de responder a esta pregunta, es importante tener en cuenta que ya has tenido consejos para llegar a escribir tus primeras funciones R en la página sobre Iteración, bucles y listas de este manual. De hecho, el uso de “if/else” y bucles suele ser una parte fundamental de muchas de nuestras funciones, ya que ayudan fácilmente a ampliar la aplicación de nuestro código permitiendo múltiples condiciones o a iterar códigos para repetir tareas.\n\n¿Estoy repitiendo varias veces el mismo bloque de código para aplicarlo a una variable o dato diferente?\nDeshacerse de él, ¿acortará sustancialmente mi código general y hará que se ejecute más rápido?\n¿Es posible que el código que he escrito se utilice de nuevo pero con un valor diferente en muchos lugares del código?\n\nSi la respuesta a una de las preguntas anteriores es “SÍ”, es probable que tenga que escribir una función.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#how-does-r-build-functions",
    "href": "new_pages/writing_functions.es.html#how-does-r-build-functions",
    "title": "44  Escribir funciones",
    "section": "44.4 ¿Cómo construye R las funciones?",
    "text": "44.4 ¿Cómo construye R las funciones?\nLas funciones en R tienen tres componentes principales:\n\nlas formals() que es la lista de argumentos que controla cómo podemos llamar a la función\nel body() que es el código dentro de la función, es decir, dentro de los paréntesis o después del paréntesis, dependiendo de cómo lo escribamos\n\ny,\n\nel environment() que ayudará a localizar las variables de la función y determina cómo encuentra la función el valor.\n\nUna vez que hayas creado tu función, puedes verificar cada uno de estos componentes llamando a la función asociada.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#basic-syntax-and-structure",
    "href": "new_pages/writing_functions.es.html#basic-syntax-and-structure",
    "title": "44  Escribir funciones",
    "section": "44.5 Sintaxis y estructura básica",
    "text": "44.5 Sintaxis y estructura básica\n\nUna función tendrá que ser nombrada adecuadamente para que su trabajo sea fácilmente comprensible tan pronto como leamos su nombre. En realidad, este es el caso de la mayoría de la arquitectura básica de R. Funciones como mean(), print(), summary() tienen nombres muy sencillos\nUna función necesitará argumentos, como los datos sobre los que trabajar y otros objetos que pueden ser valores estáticos entre otras opciones\nY finalmente una función producirá una salida basada en su tarea principal y en los argumentos que se le han dado. Normalmente utilizaremos las funciones incorporadas como print(), return()… para producir la salida. La salida puede ser un valor lógico, un número, un carácter, un dataframe… en definitiva cualquier tipo de objeto de R.\n\nBásicamente se trata de la composición de una función:\n\nfunction_name &lt;- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\n\nPodemos crear nuestra primera función que se llamará contain_covid19().\n\ncontain_covid19 &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\nA continuación, podemos verificar los componentes de nuestra función recién creada.\n\nformals(contain_covid19)\n\n$barrier_gest\n\n\n$wear_mask\n\n\n$get_vaccine\n\nbody(contain_covid19)\n\n{\n    if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n        \"yes\") \n        return(\"success\")\n    else (\"please make sure all are yes, this pandemic has to end!\")\n}\n\nenvironment(contain_covid19)\n\n&lt;environment: R_GlobalEnv&gt;\n\n\nAhora vamos a probar nuestra función. Para llamar a nuestra función escrita, la usas como usas todas las funciones de R, es decir, escribiendo el nombre de la función y añadiendo los argumentos necesarios.\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")\n\n[1] \"success\"\n\n\nPodemos volver a escribir el nombre de cada argumento por precaución. Pero sin especificarlos, el código debería funcionar ya que R tiene en memoria la posición de cada argumento. Así que mientras pongas los valores de los argumentos en el orden correcto, puedes omitir escribir los nombres de los argumentos al llamar a las funciones.\n\ncontain_covid19(\"yes\", \"yes\", \"yes\")\n\n[1] \"success\"\n\n\nA continuación, veamos qué ocurre si uno de los valores es \"no\" o no \"yes\".\n\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\n[1] \"please make sure all are yes, this pandemic has to end!\"\n\n\nSi proporcionamos un argumento que no es reconocido, se producirá un error:\n\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\n\nError en contain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", : no se pudo encontrar la función \"contain_covid19\"\nNOTA: Algunas funciones (la mayoría de las veces muy cortas y sencillas) pueden no necesitar un nombre y pueden ser utilizadas directamente en una línea de código o dentro de otra función para realizar una tarea rápida. Se llaman funciones anónimas.\nPor ejemplo, a continuación se muestra una primera función anónima que mantiene sólo las variables de carácter de los datos.\n\nlinelist %&gt;% \n  dplyr::slice_head(n=10) %&gt;%  # equivalente a la función de R base \"head\" que retorna las n primeras observaciones de un conjunto de datos.\n  select(function(x) is.character(x)) \n\n\n\n\n\n\n\nA continuación, otra función que selecciona una de cada dos observaciones de nuestro conjunto de datos (puede ser relevante cuando tenemos datos longitudinales con muchos registros por paciente, por ejemplo, después de haber ordenado por fecha o visita). En este caso, la función adecuada que se escribe fuera de dplyr sería function (x) (x%2 == 0) para aplicarla al vector que contiene todos los números de fila.\n\nlinelist %&gt;%   \n   slice_head(n=20) %&gt;% \n   tibble::rownames_to_column() %&gt;% # agrega índices de cada obs como rownames para ver claramente la selección final\n   filter(row_number() %%2 == 0)\n\n\n\n\n\n\n\nUn posible código para la misma tarea sería:\n\nlinelist_firstobs &lt;- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]\n\n\n\n\n\n\n\nPRECAUCIÓN: Aunque es cierto que el uso de funciones puede ayudarnos con nuestro código, puede llevar mucho tiempo escribir algunas funciones o arreglar una si no ha sido pensada a fondo, escrita adecuadamente y está devolviendo errores como resultado. Por esta razón, a menudo se recomienda escribir primero el código en R, asegurarse de que hace lo que pretendemos, y luego transformarlo en una función con sus tres componentes principales, como se ha indicado anteriormente.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#examples-2",
    "href": "new_pages/writing_functions.es.html#examples-2",
    "title": "44  Escribir funciones",
    "section": "44.6 Ejemplos",
    "text": "44.6 Ejemplos\n\nDevuelve tablas de proporciones para varias columnas\nSí, ya disponemos de bonitas funciones en muchos paquetes que permiten resumir la información de una manera muy fácil y agradable. Pero aún así intentaremos hacer las nuestras, en nuestros primeros pasos para acostumbrarnos a escribir funciones.\nEn este ejemplo queremos mostrar cómo la escritura de una función simple te evitaría copiar y pegar el mismo código varias veces.\n\nproptab_multiple &lt;- function(my_data, var_to_tab){\n  \n  # imprime el nombre de cada variable de interés antes de realizar la tabulación\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( # enlaza por filas los resultados de las siguientes dos funciones \n        #tabula la variable de interés: da solo números\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calcula la proporción de cada variable de interés y redondear el valor a 2 decimales\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")\n\n[1] \"gender\"\n\n\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n\nproptab_multiple(linelist, \"age_cat\")\n\n[1] \"age_cat\"\n\n\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n\nproptab_multiple(linelist, \"outcome\")\n\n[1] \"outcome\"\n\n\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nCONSEJO: Como se ha indicado anteriormente, es muy importante comentar las funciones como se haría en la programación general. Ten en cuenta que el objetivo de una función es hacer un código fácil de leer, más corto y más eficiente. Entonces uno debería ser capaz de entender lo que hace la función con sólo leer su nombre y debería tener más detalles leyendo los comentarios.\nUna segunda opción es utilizar esta función en otra a través de un bucle para hacer el proceso a la vez:\n\nfor(var_to_tab in c(\"gender\",\"age_cat\",  \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}\n\n[1] \"gender\"\n           f       m\n[1,] 2807.00 2803.00\n[2,]   50.04   49.96\n[1] \"age_cat\"\n         0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n[1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n[2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n[1] \"outcome\"\n       Death Recover\n[1,] 2582.00 1983.00\n[2,]   56.56   43.44\n\n\nUna forma más sencilla podría ser utilizar la base R “apply” en lugar de un “bucle for” como se expresa a continuación:\nCONSEJO: R se define a menudo como un lenguaje de programación funcional y casi siempre que ejecutas una línea de código estás utilizando algunas funciones incorporadas. Un buen hábito para sentirse más cómodo con la escritura de funciones es echar a menudo un vistazo interno a cómo están construidas las funciones básicas que utiliza a diario. El atajo para hacerlo es seleccionar el nombre de la función y luego clicar en Ctrl+F2 o fn+F2 o Cmd+F2 (dependiendo de tu ordenador).",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#using-purrr-writing-functions-that-can-be-iteratively-applied",
    "href": "new_pages/writing_functions.es.html#using-purrr-writing-functions-that-can-be-iteratively-applied",
    "title": "44  Escribir funciones",
    "section": "44.7 Uso de purrr: escribir funciones que se pueden aplicar de forma iterativa",
    "text": "44.7 Uso de purrr: escribir funciones que se pueden aplicar de forma iterativa\n\nModificar el tipo de múltiples columnas en unos datos\nDigamos que muchas variables de carácter en los datos originales de linelist necesitan ser cambiadas a “factor” para propósitos de análisis y trazado. En lugar de repetir el paso varias veces, podemos utilizar simplemente lapply() para realizar la transformación de todas las variables afectadas en una sola línea de código.\nPRECAUCIÓN: lapply() devuelve una lista, por lo que su uso puede requerir una modificación adicional como último paso.\nEl mismo paso puede realizarse utilizando la función map_if() del paquete purrr\n\nlinelist_factor2 &lt;- linelist %&gt;%\n  purrr::map_if(is.character, as.factor)\n\n\nlinelist_factor2 %&gt;%\n        glimpse()\n\nList of 30\n $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA ...\n $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" ...\n $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" ...\n $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" ...\n $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ...\n\n\n\n\nElaborar de forma iterativa gráficos para diferentes niveles de una variable\nProduciremos aquí un gráfico circular para ver la distribución del resultado de los pacientes en China durante el brote de H7N9 para cada provincia. En lugar de repetir el código para cada una de ellas, nos limitaremos a aplicar una función que crearemos.\n\n# precisar opciones para el uso de highchart\noptions(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n# Crear una función llamada \"chart_outcome_province\" que tome como argumento el conjunto de datos y el nombre de la provincia para la cual plotear la distribución del resultado.\n\nchart_outcome_province &lt;- function(data_used, prov){\n  \n  tab_prov &lt;- data_used %&gt;% \n    filter(province == prov,\n           !is.na(outcome))%&gt;% \n    group_by(outcome) %&gt;% \n    count() %&gt;%\n    adorn_totals(where = \"row\") %&gt;% \n    adorn_percentages(denominator = \"col\", )%&gt;%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %&gt;%\n    filter(outcome != \"Total\") %&gt;% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distibution of the outcome in:\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\n\n\n\n\nchart_outcome_province(flu_china,\"Zhejiang\")\n\n\n\n\nchart_outcome_province(flu_china,\"Jiangsu\")\n\n\n\n\n\n\n\nProducir iterativamente tablas para diferentes niveles de una variable\nAquí crearemos tres indicadores para resumirlos en una tabla y nos gustaría elaborar esta tabla para cada una de las provincias. Nuestros indicadores son el retraso entre el inicio y la hospitalización, el porcentaje de recuperación y la edad media de los casos.\n\nindic_1 &lt;- flu_china %&gt;% \n  group_by(province) %&gt;% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %&gt;%\n  select(province, mean_delay_onset_hosp)  %&gt;% \n  distinct()\n     \n\nindic_2 &lt;-  flu_china %&gt;% \n            filter(!is.na(outcome)) %&gt;% \n            group_by(province, outcome) %&gt;% \n            count() %&gt;%\n            pivot_wider(names_from = outcome, values_from = n) %&gt;% \n    adorn_totals(where = \"col\") %&gt;% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%&gt;% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 &lt;-  flu_china %&gt;% \n            group_by(province) %&gt;% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %&gt;% \n  select(province, median_age_cases)  %&gt;% \n  distinct()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `median_age_cases = median(as.numeric(age), na.rm = TRUE)`.\nℹ In group 11: `province = \"Shanghai\"`.\nCaused by warning in `median()`:\n! NAs introduced by coercion\n\n# unir los indicadores de los tres conjuntos de datos\n\ntable_indic_all &lt;- indic_1 %&gt;% \n  dplyr::left_join(indic_2, by = \"province\") %&gt;% \n        left_join(indic_3, by = \"province\")\n\n\n# imprimir los indicadores en una flextable\n\n\nprint_indic_prov &lt;-  function(table_used, prov){\n  \n  # primero transforma un poco el dataframe para facilitar la impresión\n  indic_prov &lt;- table_used %&gt;%\n    filter(province==prov) %&gt;%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %&gt;% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\",\"perc_recovery\",\"median_age_cases\"),\n   labels=c(\"Mean delay onset-hosp\",\"Percentage of recovery\", \"Median age of the cases\"))\n   ) %&gt;% \n    ungroup(province) %&gt;% \n    select(indic_label, value)\n  \n\n    tab_print &lt;- flextable(indic_prov)  %&gt;%\n    theme_vanilla() %&gt;% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print &lt;- tab_print %&gt;% \n                  autofit()   %&gt;%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %&gt;%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %&gt;%\n    flextable::bold(part = \"header\") %&gt;%\n    flextable::color(color = \"white\", part = \"header\") %&gt;% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de: \", prov)) %&gt;% \nbold(part = \"header\")\n \n tab_print &lt;- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\n\nIndicateurs pour la province de: ShanghaiIndicateursEstimationMean delay onset-hosp4.0Percentage of recovery46.7Median age of the cases67.0\n\nprint_indic_prov(table_indic_all, \"Jiangsu\")\n\nIndicateurs pour la province de: JiangsuIndicateursEstimationMean delay onset-hosp6.0Percentage of recovery71.4Median age of the cases55.0",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#tips-and-best-practices-for-well-functioning-functions",
    "href": "new_pages/writing_functions.es.html#tips-and-best-practices-for-well-functioning-functions",
    "title": "44  Escribir funciones",
    "section": "44.8 Consejos y buens prácticas para el buen funcionamiento de las funciones",
    "text": "44.8 Consejos y buens prácticas para el buen funcionamiento de las funciones\nLa programación funcional está pensada para aliviar el código y facilitar su lectura. Podría producir lo contrario. Los siguientes consejos le ayudarán a tener un código limpio y fácil de leer.\n\nNombres y sintaxis\n\nEvitar el uso de caracteres que podrían haber sido fácilmente tomados por otras funciones ya existentes en su entorno\nSe recomienda que el nombre de la función sea corto y sencillo de entender para otro lector\nEs preferible utilizar verbos como nombre de la función y sustantivos para los nombres de los argumentos.\n\n\n\nNombres de columnas y evaluación ordenada\nSi quiere saber cómo referenciar nombres de columnas que se proporcionan a su código como argumentos, lea esta guía de programación de tidyverse. Entre los temas tratados están la evaluación ordenada y el uso del abrazo con { } “llaves dobles”\nPor ejemplo, aquí hay un esqueleto rápido de código de plantilla del tutorial de la página mencionada anteriormente:\n\nvar_summary &lt;- function(data, var) {\n  data %&gt;%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))\n}\nmtcars %&gt;% \n  group_by(cyl) %&gt;% \n  var_summary(mpg)\n\n\n\nPruebas y tratamiento de errores\nCuanto más complicada sea la tarea de una función, mayor será la posibilidad de errores. Por lo tanto, a veces es necesario añadir alguna verificación dentro de la función para ayudar a entender rápidamente de dónde proviene el error y encontrar una manera de solucionarlo.\n\nPuede ser más que recomendable introducir una comprobación sobre la ausencia de un argumento utilizando missing(argumento). Esta simple comprobación puede devolver el valor “TRUE” o “FALSE”.\n\n\ncontain_covid19_missing &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask ==\"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")\n\n[1] \"please provide arg1\"\n[1] \"please provide arg2\"\n\n\nError in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\n\n\n\nUtiliza stop() para errores más detectables.\n\n\ncontain_covid19_stop &lt;- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\"))\n  \n  if (barrier_gest == \"yes\" & wear_mask ==\"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")\n\nError in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\n\n\n\nComo vemos cuando ejecutamos la mayoría de las funciones incorporadas, hay mensajes y advertencias que pueden aparecer en ciertas condiciones. Podemos integrarlos en nuestras funciones escritas utilizando las funciones message() y warning().\nTambién podemos manejar los errores usando safely() que toma una función como argumento y la ejecuta de forma segura. De hecho, la función se ejecutará sin detenerse si encuentra un error. safely() devuelve como salida una lista con dos objetos que son los resultados y el error que se ha “saltado”.\n\nPodemos verificarlo ejecutando primero la mean() como función, y luego ejecutarla con safely().\n\nmap(linelist, mean)\n\n$case_id\n[1] NA\n\n$generation\n[1] 16.56165\n\n$date_infection\n[1] NA\n\n$date_onset\n[1] NA\n\n$date_hospitalisation\n[1] \"2014-11-03\"\n\n$date_outcome\n[1] NA\n\n$outcome\n[1] NA\n\n$gender\n[1] NA\n\n$age\n[1] NA\n\n$age_unit\n[1] NA\n\n$age_years\n[1] NA\n\n$age_cat\n[1] NA\n\n$age_cat5\n[1] NA\n\n$hospital\n[1] NA\n\n$lon\n[1] -13.23381\n\n$lat\n[1] 8.469638\n\n$infector\n[1] NA\n\n$source\n[1] NA\n\n$wt_kg\n[1] 52.64487\n\n$ht_cm\n[1] 124.9633\n\n$ct_blood\n[1] 21.20686\n\n$fever\n[1] NA\n\n$chills\n[1] NA\n\n$cough\n[1] NA\n\n$aches\n[1] NA\n\n$vomit\n[1] NA\n\n$temp\n[1] NA\n\n$time_admission\n[1] NA\n\n$bmi\n[1] 46.89023\n\n$days_onset_hosp\n[1] NA\n\n\n\nsafe_mean &lt;- safely(mean)\nlinelist %&gt;% \n  map(safe_mean)\n\n$case_id\n$case_id$result\n[1] NA\n\n$case_id$error\nNULL\n\n\n$generation\n$generation$result\n[1] 16.56165\n\n$generation$error\nNULL\n\n\n$date_infection\n$date_infection$result\n[1] NA\n\n$date_infection$error\nNULL\n\n\n$date_onset\n$date_onset$result\n[1] NA\n\n$date_onset$error\nNULL\n\n\n$date_hospitalisation\n$date_hospitalisation$result\n[1] \"2014-11-03\"\n\n$date_hospitalisation$error\nNULL\n\n\n$date_outcome\n$date_outcome$result\n[1] NA\n\n$date_outcome$error\nNULL\n\n\n$outcome\n$outcome$result\n[1] NA\n\n$outcome$error\nNULL\n\n\n$gender\n$gender$result\n[1] NA\n\n$gender$error\nNULL\n\n\n$age\n$age$result\n[1] NA\n\n$age$error\nNULL\n\n\n$age_unit\n$age_unit$result\n[1] NA\n\n$age_unit$error\nNULL\n\n\n$age_years\n$age_years$result\n[1] NA\n\n$age_years$error\nNULL\n\n\n$age_cat\n$age_cat$result\n[1] NA\n\n$age_cat$error\nNULL\n\n\n$age_cat5\n$age_cat5$result\n[1] NA\n\n$age_cat5$error\nNULL\n\n\n$hospital\n$hospital$result\n[1] NA\n\n$hospital$error\nNULL\n\n\n$lon\n$lon$result\n[1] -13.23381\n\n$lon$error\nNULL\n\n\n$lat\n$lat$result\n[1] 8.469638\n\n$lat$error\nNULL\n\n\n$infector\n$infector$result\n[1] NA\n\n$infector$error\nNULL\n\n\n$source\n$source$result\n[1] NA\n\n$source$error\nNULL\n\n\n$wt_kg\n$wt_kg$result\n[1] 52.64487\n\n$wt_kg$error\nNULL\n\n\n$ht_cm\n$ht_cm$result\n[1] 124.9633\n\n$ht_cm$error\nNULL\n\n\n$ct_blood\n$ct_blood$result\n[1] 21.20686\n\n$ct_blood$error\nNULL\n\n\n$fever\n$fever$result\n[1] NA\n\n$fever$error\nNULL\n\n\n$chills\n$chills$result\n[1] NA\n\n$chills$error\nNULL\n\n\n$cough\n$cough$result\n[1] NA\n\n$cough$error\nNULL\n\n\n$aches\n$aches$result\n[1] NA\n\n$aches$error\nNULL\n\n\n$vomit\n$vomit$result\n[1] NA\n\n$vomit$error\nNULL\n\n\n$temp\n$temp$result\n[1] NA\n\n$temp$error\nNULL\n\n\n$time_admission\n$time_admission$result\n[1] NA\n\n$time_admission$error\nNULL\n\n\n$bmi\n$bmi$result\n[1] 46.89023\n\n$bmi$error\nNULL\n\n\n$days_onset_hosp\n$days_onset_hosp$result\n[1] NA\n\n$days_onset_hosp$error\nNULL\n\n\nComo se ha dicho anteriormente, comentar bien nuestros códigos ya es una buena forma de tener documentación en nuestro trabajo.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/writing_functions.es.html#resources-36",
    "href": "new_pages/writing_functions.es.html#resources-36",
    "title": "44  Escribir funciones",
    "section": "44.9 Recursos",
    "text": "44.9 Recursos\nFunciones en R for Data Science en español\nCheatsheet advanzado de programación de R\nCheatsheet del paquete purr\nVídeo-ACM charla de Hadley Wickham: La alegría de la programación funcional (cómo funciona map_dbl)",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Escribir funciones</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html",
    "href": "new_pages/directories.es.html",
    "title": "45  Interacciones con directorios",
    "section": "",
    "text": "45.1 Preparación",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#preparation-38",
    "href": "new_pages/directories.es.html#preparation-38",
    "title": "45  Interacciones con directorios",
    "section": "",
    "text": "Paquete fs\nEl paquete fs es un paquete tidyverse que facilita las interacciones con los directorios, mejorando algunas de las funciones de R base. En las secciones siguientes utilizaremos a menudo funciones de fs.\n\npacman::p_load(\n  fs,             # interacciones archivo/directorio\n  rio,            # importación/exportación\n  here,           # rutas relativas de archivos\n  tidyverse)      # gestión y visualización de datos\n\n\n\nImprimir el directorio como un árbol de dendrogramas\nUtiliza la función dir_tree() de fs.\nProporciona la ruta de la carpeta a path = y decide si quieres mostrar sólo un nivel (recurse = FALSE) o todos los archivos en todos los subniveles (recurse = TRUE). A continuación utilizamos here() como abreviatura del proyecto R y especificamos su subcarpeta “data”, que contiene todos los datos utilizados para este manual de R. Lo configuramos para que muestre todos los archivos dentro de “data” y sus subcarpetas (por ejemplo, “cache”, “epidemic models”, “population”, “shp” y “weather”).\n\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)\n\nC:/Users/ngulu864/AppData/Local/Temp/Rtmp8MqjVI/file26d878683af0/data\n├── africa_countries.geo.json\n├── cache\n│   └── epidemic_models\n│       ├── 2015-04-30\n│       │   ├── estimated_reported_cases_samples.rds\n│       │   ├── estimate_samples.rds\n│       │   ├── latest_date.rds\n│       │   ├── reported_cases.rds\n│       │   ├── summarised_estimated_reported_cases.rds\n│       │   ├── summarised_estimates.rds\n│       │   └── summary.rds\n│       ├── epinow_res.rds\n│       ├── epinow_res_small.rds\n│       ├── generation_time.rds\n│       └── incubation_period.rds\n├── case_linelists\n│   ├── cleaning_dict.csv\n│   ├── fluH7N9_China_2013.csv\n│   ├── linelist_cleaned.rds\n│   ├── linelist_cleaned.xlsx\n│   └── linelist_raw.xlsx\n├── country_demographics.csv\n├── covid_example_data\n│   ├── covid_example_data.xlsx\n│   └── covid_shapefile\n│       ├── FultonCountyZipCodes.cpg\n│       ├── FultonCountyZipCodes.dbf\n│       ├── FultonCountyZipCodes.prj\n│       ├── FultonCountyZipCodes.sbn\n│       ├── FultonCountyZipCodes.sbx\n│       ├── FultonCountyZipCodes.shp\n│       ├── FultonCountyZipCodes.shp.xml\n│       └── FultonCountyZipCodes.shx\n├── covid_incidence.csv\n├── covid_incidence_map.R\n├── district_count_data.xlsx\n├── example\n│   ├── Central Hospital.csv\n│   ├── district_weekly_count_data.xlsx\n│   ├── fluH7N9_China_2013.csv\n│   ├── hospital_linelists.xlsx\n│   ├── linelists\n│   │   ├── 20201007linelist.csv\n│   │   ├── case_linelist20201006.csv\n│   │   ├── case_linelist_2020-10-02.csv\n│   │   ├── case_linelist_2020-10-03.csv\n│   │   ├── case_linelist_2020-10-04.csv\n│   │   ├── case_linelist_2020-10-05.csv\n│   │   └── case_linelist_2020-10-08.xlsx\n│   ├── Military Hospital.csv\n│   ├── Missing.csv\n│   ├── Other.csv\n│   ├── Port Hospital.csv\n│   └── St. Mark's Maternity Hospital (SMMH).csv\n├── facility_count_data.rds\n├── flexdashboard\n│   ├── outbreak_dashboard.html\n│   ├── outbreak_dashboard.Rmd\n│   ├── outbreak_dashboard_shiny.Rmd\n│   ├── outbreak_dashboard_test.html\n│   └── outbreak_dashboard_test.Rmd\n├── fluH7N9_China_2013.csv\n├── gis\n│   ├── africa_countries.geo.json\n│   ├── covid_incidence.csv\n│   ├── covid_incidence_map.R\n│   ├── linelist_cleaned_with_adm3.rds\n│   ├── population\n│   │   ├── sle_admpop_adm3_2020.csv\n│   │   └── sle_population_statistics_sierraleone_2020.xlsx\n│   └── shp\n│       ├── README.txt\n│       ├── sle_adm3.CPG\n│       ├── sle_adm3.dbf\n│       ├── sle_adm3.prj\n│       ├── sle_adm3.sbn\n│       ├── sle_adm3.sbx\n│       ├── sle_adm3.shp\n│       ├── sle_adm3.shp.xml\n│       ├── sle_adm3.shx\n│       ├── sle_hf.CPG\n│       ├── sle_hf.dbf\n│       ├── sle_hf.prj\n│       ├── sle_hf.sbn\n│       ├── sle_hf.sbx\n│       ├── sle_hf.shp\n│       └── sle_hf.shx\n├── godata\n│   ├── cases_clean.rds\n│   ├── contacts_clean.rds\n│   ├── followups_clean.rds\n│   └── relationships_clean.rds\n├── likert_data.csv\n├── linelist_cleaned.rds\n├── linelist_cleaned.xlsx\n├── linelist_raw.xlsx\n├── make_evd_dataset-DESKTOP-JIEUMMI.R\n├── make_evd_dataset.R\n├── malaria_app\n│   ├── app.R\n│   ├── data\n│   │   └── facility_count_data.rds\n│   ├── funcs\n│   │   └── plot_epicurve.R\n│   ├── global.R\n│   ├── malaria_app.Rproj\n│   ├── server.R\n│   └── ui.R\n├── malaria_facility_count_data.rds\n├── phylo\n│   ├── sample_data_Shigella_tree.csv\n│   ├── Shigella_subtree_2.nwk\n│   ├── Shigella_subtree_2.txt\n│   └── Shigella_tree.txt\n├── rmarkdown\n│   ├── outbreak_report.docx\n│   ├── outbreak_report.html\n│   ├── outbreak_report.pdf\n│   ├── outbreak_report.pptx\n│   ├── outbreak_report.Rmd\n│   ├── report_tabbed_example.html\n│   └── report_tabbed_example.Rmd\n├── standardization\n│   ├── country_demographics.csv\n│   ├── country_demographics_2.csv\n│   ├── deaths_countryA.csv\n│   ├── deaths_countryB.csv\n│   └── world_standard_population_by_sex.csv\n├── surveys\n│   ├── population.xlsx\n│   ├── survey_data.xlsx\n│   └── survey_dict.xlsx\n└── time_series\n    ├── campylobacter_germany.xlsx\n    └── weather\n        ├── germany_weather2002.nc\n        ├── germany_weather2003.nc\n        ├── germany_weather2004.nc\n        ├── germany_weather2005.nc\n        ├── germany_weather2006.nc\n        ├── germany_weather2007.nc\n        ├── germany_weather2008.nc\n        ├── germany_weather2009.nc\n        ├── germany_weather2010.nc\n        └── germany_weather2011.nc",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#list-files-in-a-directory",
    "href": "new_pages/directories.es.html#list-files-in-a-directory",
    "title": "45  Interacciones con directorios",
    "section": "45.2 Listar los archivos de un directorio",
    "text": "45.2 Listar los archivos de un directorio\nPara listar sólo los nombres de los archivos de un directorio puedes utilizar dir() de R base. Por ejemplo, este comando lista los nombres de los archivos de la subcarpeta “population” de la carpeta “data” en un proyecto R. La ruta relativa de los archivos se proporciona utilizando here() (sobre la que puede leer más en la página de importación y exportación).\n\n# nombres de archivo\ndir(here(\"data\", \"gis\", \"population\"))\n\n[1] \"sle_admpop_adm3_2020.csv\"                       \n[2] \"sle_population_statistics_sierraleone_2020.xlsx\"\n\n\nPara listar las rutas completas de los archivos del directorio, puedes utilizar dir_ls() de fs. Una alternativa de R base es list.files().\n\n# rutas de archivos\ndir_ls(here(\"data\", \"gis\", \"population\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/Rtmp8MqjVI/file26d878683af0/data/gis/population/sle_admpop_adm3_2020.csv\nC:/Users/ngulu864/AppData/Local/Temp/Rtmp8MqjVI/file26d878683af0/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n\n\nPara obtener toda la información de los metadatos de cada archivo en un directorio, (por ejemplo, la ruta, la fecha de modificación, etc.) puedes utilizar dir_info() de fs.\nEsto puede ser especialmente útil si quieres extraer la última hora de modificación del archivo, por ejemplo si quieres importar la versión más reciente de un archivo. Para ver un ejemplo de esto, consulta la página de importación y exportación.\n\n# información de archivo\ndir_info(here(\"data\", \"gis\", \"population\"))\n\nAquí está el dataframe devuelto. Desplázate a la derecha para ver todas las columnas.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#file-information",
    "href": "new_pages/directories.es.html#file-information",
    "title": "45  Interacciones con directorios",
    "section": "45.3 Información sobre el archivo",
    "text": "45.3 Información sobre el archivo\nPara extraer información de metadatos sobre un archivo específico, puedes utilizar file_info() de fs (o file.info() de R base).\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\n\n\n\n\n\n\nAquí usamos $ para indexar el resultado y devolver sólo el valor de modification_time.\n\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time\n\n[1] \"2024-05-10 04:57:09 CEST\"",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#check-if-exists",
    "href": "new_pages/directories.es.html#check-if-exists",
    "title": "45  Interacciones con directorios",
    "section": "45.4 Comprobar si existe",
    "text": "45.4 Comprobar si existe\n\nObjetos R\nPuedes utilizar exists() de R base para comprobar si un objeto R existe dentro de R (escribe el nombre del objeto entre comillas).\n\nexists(\"linelist\")\n\n[1] FALSE\n\n\nTen en cuenta que algunos paquetes de R base utilizan nombres de objetos genéricos como “data” entre bastidores, que aparecerán como TRUE a menos que se especifique inherit = FALSE. Esta es una razón para no nombrar tu conjunto de datos como “data”.\n\nexists(\"data\")\n\n[1] TRUE\n\nexists(\"data\", inherit = FALSE)\n\n[1] FALSE\n\n\nSi estás escribiendo una función, deberías utilizar missing() de R base para comprobar si un argumento está presente o no, en lugar de exists().\n\n\nDirectorios\nPara comprobar si un directorio existe, escribe la ruta del archivo (y el nombre del archivo) a is_dir() de fs. Desplázate a la derecha para ver que se imprime TRUE.\n\nis_dir(here(\"data\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/Rtmp8MqjVI/file26d878683af0/data \n                                                                 TRUE \n\n\nUna alternativa de R base es file.exists().\n\n\nFiles\nPara comprobar si un archivo específico existe, utiliza is_file() de fs. Desplázate a la derecha para ver que se imprime TRUE.\n\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\n\nC:/Users/ngulu864/AppData/Local/Temp/Rtmp8MqjVI/file26d878683af0/data/case_linelists/linelist_cleaned.rds \n                                                                                                     TRUE \n\n\nUna alternativa de R base es file.exists().",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#create",
    "href": "new_pages/directories.es.html#create",
    "title": "45  Interacciones con directorios",
    "section": "45.5 Crear",
    "text": "45.5 Crear\n\nDirectorios\nPara crear un nuevo directorio (carpeta) puede utilizar dir_create() de fs. Si el directorio ya existe, no se sobrescribirá y no se devolverá ningún error.\n\ndir_create(here(\"data\", \"test\"))\n\nUna alternativa es dir.create() de R base, que mostrará un error si el directorio ya existe. En cambio, dir_create() en este escenario será silencioso.\n\n\nArchivos\nPuedes crear un archivo (vacío) con file_create() de fs. Si el archivo ya existe, no se sobreescribirá ni se modificará.\n\nfile_create(here(\"data\", \"test.rds\"))\n\nUna alternativa de R base es file.create(). Pero si el archivo ya existe, esta opción lo truncará. Si se utiliza file_create() el archivo se dejará sin cambios\n\n\nCrear si no existe\nEN CONSTRUCCIÓN",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#delete",
    "href": "new_pages/directories.es.html#delete",
    "title": "45  Interacciones con directorios",
    "section": "45.6 Borrar",
    "text": "45.6 Borrar\n\nObjetos R\nUtiliza rm() de R base para eliminar un objeto R.\n\n\nDirectorios\nUtiliza dir_delete() de fs.\n\n\nArchivos\nPuedes eliminar archivos con file_delete() de fs.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#running-other-files",
    "href": "new_pages/directories.es.html#running-other-files",
    "title": "45  Interacciones con directorios",
    "section": "45.7 Ejecución de otros archivos",
    "text": "45.7 Ejecución de otros archivos\n\nsource()\nPara ejecutar un script de R desde otro script de R, puedes utilizar el comando source() (de R base).\n\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))\n\nEsto equivale a ver el script de R anterior y clicar en el botón “Source” en la parte superior derecha del script. Esto ejecutará el script pero lo hará de forma silenciosa (sin salida a la consola de R) a menos que se pretenda específicamente. Consulta la página sobre [Consola interactiva] para ver ejemplos de uso de source() para interactuar con un usuario a través de la consola de R en modo de pregunta y respuesta.\n\n\n\n\n\n\n\n\n\n\n\nrender()\nrender() es una variación de source() que se utiliza más a menudo para los scripts de R markdown. Tu pescribes input = que es el archivo R markdown, y también output_format = (“html_document”, “pdf_document”, “word_document”, ““)\nMira la página sobre Informes con R Markdown para más detalles. También consulta la documentación de render() aquí o escribiendo ?render.\n\n\nEjecutar archivos en un directorio\nPuedes crear un bucle for y utilizarlo para source() cada archivo en un directorio, identificado con dir().\n\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # para cada nombre de script en la carpeta \"scripts\" del proyecto R (con extensión .R)\n  source(here(\"scripts\", script))                        # obtiene el archivo con el nombre correspondiente que existe en la carpeta scripts\n}\n\nSi sólo quieres ejecutar determinados scripts, puedes identificarlos por su nombre de la siguiente manera:\n\nscripts_to_run &lt;- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}\n\nAquí puedes ver una comparación de las funciones fs y R base.\n\n\nImportar archivos en un directorio\nConsulta la página sobre importación y exportación para importar y exportar archivos individuales.\nConsulta también la página de importación y exportación para conocer los métodos para importar automáticamente el archivo más reciente, basándose en una fecha del nombre del archivo o mirando los metadatos del mismo.\nConsulta la página sobre Iteración, bucles y listas para ver un ejemplo con el paquete purrr demostrando:\n\nDividir un dataframe y guardarlo como múltiples archivos CSV\nDividir un dataframe y guardar cada parte como una hoja separada dentro de un libro de Excel\nImportar varios archivos CSV y combinarlos en un dataframe\nImportar un libro de Excel con varias hojas y combinarlas en un dataframe",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#base-r-4",
    "href": "new_pages/directories.es.html#base-r-4",
    "title": "45  Interacciones con directorios",
    "section": "45.8 R base",
    "text": "45.8 R base\nMira a continuación las funciones list.files() y dir(), que realizan la misma operación de listar archivos dentro de un directorio especificado. Puedes especificar ignore.case = o un patrón específico para buscar.\n\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)\n\nSi un archivo está actualmente “abierto”, se mostrará en su carpeta con una tilde delante, como “~$hospital_linelists.xlsx”.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/directories.es.html#resources-37",
    "href": "new_pages/directories.es.html#resources-37",
    "title": "45  Interacciones con directorios",
    "section": "45.9 Recursos",
    "text": "45.9 Recursos\nhttps://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Interacciones con directorios</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html",
    "href": "new_pages/collaboration.es.html",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "",
    "text": "46.1 ¿Qué es Git?\nGit es un software de control de versiones que permite seguir los cambios realizados en una carpeta. Se puede utilizar como la opción “control de cambios” de Word, LibreOffice o Google docs, pero para todo tipo de archivos. Es una de las opciones más potentes y más utilizadas para el control de versiones.\n¿Por qué nunca he oído hablar de Git? - Mientras que las personas con formación como desarrollador aprenden habitualmente a utilizar un software de control de versiones (Git, Mercurial, Subversion u otros), a pocas personas de las disciplinas cuantitativas se nos enseñan estas habilidades. En consecuencia, la mayoría de profesionales de la epidemiología nunca hemos oído hablar sobre esto en sus estudios, y tenemos que aprenderlo sobre la marcha.\nEspera, he oído hablar de Github, ¿es lo mismo? - No exactamente, pero a menudo se utilizan juntos, y veremos aquí cómo hacerlo. En resumen:\nSe puede utilizar el cliente/interfaz Github Desktop, que utiliza Git en segundo plano para gestionar los archivos, tanto localmente en el ordenador, como remotamente en un servidor de Github.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#what-is-git",
    "href": "new_pages/collaboration.es.html#what-is-git",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "",
    "text": "Git es el sistema de control de versiones, una pieza de software. Se puede utilizar localmente en el ordenador o para sincronizar una carpeta con un sitio web anfitrión. Por defecto, se utiliza una ventana de terminal para escribir las instrucciones de Git en la línea de comandos.\nSe puede utilizar un cliente/interfaz Git para evitar la línea de comandos y realizar las mismas acciones (al menos para las más sencillas y supercomunes).\nSi se quiere almacenar una carpeta en un sitio web para colaborar con otros, se puede utilizar una cuenta en Github, Gitlab, Bitbucket u otros.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#why-use-the-combo-git-and-github",
    "href": "new_pages/collaboration.es.html#why-use-the-combo-git-and-github",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.2 ¿Por qué utilizar la combinación de Git y Github?",
    "text": "46.2 ¿Por qué utilizar la combinación de Git y Github?\nEl uso de Git facilita:\n\nAlmacenar versiones de archivos con cambios incrementales de forma que permite volver fácilmente a cualquier estado anterior\nMantener ramas paralelas, es decir, versiones de desarrollo/“trabajo” que más adelante pueden integrar los cambios después de su revisión\n\nEsto también se puede hacer localmente en tu ordenador, incluso si no colaboras con otras personas. Alguna vez ….:\n\n¿te has arrepentido de haber eliminado una sección de código, para darte cuenta dos meses después de que realmente la necesitabas?\n¿has vuelto a un proyecto que había estado en pausa e intentado recordar si habías hecho esa complicada modificación en uno de los modelos?\n¿tenías un archivo modelo_1.R y otro archivo modelo_1_prueba.R y un archivo modelo_1_no_funciona.R para probar las cosas?\n¿tenías un archivo report.Rmd, un archivo report_full.Rmd, un archivo report_true_final.Rmd, un archivo report_final_20210304.Rmd, un archivo report_final_20210402.Rmd y maldecías tus habilidades de almacenamiento?\n\nGit puede ayudar con todo eso, y vale la pena aprenderlo sólo por eso.\nSin embargo, se vuelve aún más potente cuando se utiliza con un repositorio en línea como Github para apoyar proyectos de colaboración. Esto facilita:\n\nColaboración: otros pueden revisar, comentar y aceptar o rechazar los cambios\nCompartir el código, los datos y los resultados, e invitar a hacer comentarios al público (o en privado, con tu equipo)\n\ny evitar:\n\n“Uy, me olvidé de enviar la última versión y ahora tienes que rehacer el trabajo de dos días en este nuevo archivo”\nMina, Henry y Oumar trabajaron al mismo tiempo en un script y necesitan fusionar manualmente sus cambios\nDos personas intentan modificar el mismo archivo en Dropbox y Sharepoint y esto crea un error de sincronización.\n\n\nEsto suena complicado, yo no soy un programador\nPuede ser. Los ejemplos de usos avanzados pueden ser bastante aterradores. Sin embargo, al igual que ocurre con R, o incluso con Excel, no es necesario convertirse en un experto para aprovechar las ventajas de la herramienta. El aprendizaje de un pequeño número de funciones y nociones te permite seguir sus cambios, sincronizar los archivos en un repositorio en línea y colaborar con los colegas en muy poco tiempo.\nDebido a la curva de aprendizaje, el contexto de emergencia puede no ser el mejor momento para aprender estas herramientas. Pero el aprendizaje puede hacerse por pasos. Una vez que adquieras un par de nociones, tu flujo de trabajo puede ser bastante eficiente y rápido. Si no estás trabajando en un proyecto en el que la colaboración con personas a través de Git sea una necesidad, … en realidad es un buen momento para adquirir confianza en su uso en solitario antes de sumergirte en ello en un proyecto colaborativo.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#setup",
    "href": "new_pages/collaboration.es.html#setup",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.3 Configuración",
    "text": "46.3 Configuración\n\nInstalar Git\nGit es el motor que está de este control de cambios la computadora; rastrea los cambios, las ramas (versiones), las fusiones y las reversiones. Primero debes instalar Git desde https://git-scm.com/downloads.\n\n\nInstalar una interfaz gráfica (opcional pero recomendable)\nGit tiene su propio lenguaje de comandos, que se pueden escribir en la línea de comandos de un terminal. Sin embargo, hay muchos clientes/interfaces que proporcionan una buena visualización de las modificaciones de archivos o ramas. Esto es recomendable ya que personas que no son desarrolladoras, en su uso diario, rara vez necesitarán interactuar directamente con Git.\nExisten muchas opciones, en todos los sistemas operativos, desde las amigables para los principiantes hasta las más complejas. Unas buenas opciones para principiantes son el panel Git de RStudio y Github Desktop, que mostraremos en este capítulo. Las opciones intermedias (más potentes, pero más complejas) incluyen Source Tree, Gitkracken, Smart Git y otras.\nExplicación rápida sobre los clientes Git.\nNota: dado que todas las interfaces utilizan Git internamente, puedes probar varias de ellas, cambiar de una a otra en un proyecto determinado, utilizar la consola puntualmente para una acción que tu interfaz no soporta, o incluso realizar una serie de acciones online en Github.\nComo se indica más adelante, es posible que ocasionalmente tengas que escribir comandos Git en un terminal como en la pestaña “terminal” de RStudio (una pestaña adyacente a la consola de R) o la aplicación de terminal Git Bash.\n\n\nCuenta de Github\nRegístrate para obtener una cuenta gratuita en github.com.\nEs posible que se te ofrezca configurar la autenticación de dos pasos con una aplicación en tu teléfono. Lee más en estos documentos de ayuda de Github.\nSi usas Github Desktop, puedes introducir tus credenciales de Github después de la instalación siguiendo estos pasos. Si no lo haces, las credenciales se te pedirán más tarde cuando intentes clonar un proyecto desde Github.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#vocabulary-concepts-and-basic-functions",
    "href": "new_pages/collaboration.es.html#vocabulary-concepts-and-basic-functions",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.4 Vocabulario, conceptos y funciones básicas",
    "text": "46.4 Vocabulario, conceptos y funciones básicas\nAl igual que cuando se aprende R, hay que recordar un poco de vocabulario para entender Git. Aquí están los conceptos básicos para empezar / tutorial interactivo. En las próximas secciones, mostraremos cómo usar las interfaces, pero es bueno tener el vocabulario y los conceptos en mente, para construir tu modelo mental, ya que lo necesitarás cuando más tarde, aunque uses las interfaces de los programas.\n\nRepositorio\nUn repositorio Git (“repo”) es una carpeta que contiene todas las subcarpetas y archivos de tu proyecto (datos, código, imágenes, etc.) y sus historiales de revisión. Cuando empieces a seguir los cambios en el repositorio con él, Git creará una carpeta oculta que contiene toda la información de seguimiento. Un repositorio típico de Git es la carpeta de tu proyecto R (ver la página del manual sobre proyectos R).\nMostraremos cómo crear (inicializar) un repositorio Git desde Github, Github Desktop o Rstudio en las siguientes secciones. sections.\n\n\nCommits (Consolidaciones)\nCuando realices un cambio en el proyecto, hay que ejecutar commit para consolidar estos cambios (el delta) realizados en tus archivos. Por ejemplo, quizás hayas editado algunas líneas de código y actualizado unos datos relacionados. Una vez guardados los cambios, puedes agrupar y confirmar estos cambios en un solo “commit”.\nCada consolidación (commit) tiene un ID único (un hash). Para el control de versiones, puedes revertir tu proyecto hacia atrás en base a estas Consolidaciones, así que es mejor mantenerlas relativamente pequeñas y coherentes. También realizarás una breve descripción de los cambios llamada “commit message (mensaje de consolidación)”. En cierto modo, cada commit es una instantánea del proyecto en un momento dado.\n¿Cambios por etapas (staged)? Poner etapas en los cambios es añadirlos a la zona de preparación para la siguiente consolidación. La idea es que puedas decidir con precisión qué cambios incluir en un determinado commit. Por ejemplo, si trabajas en la especificación del modelo en un script, y más tarde en una figura en otro script, tendría sentido tener dos commits diferentes (sería más fácil en caso de que quisieras revertir los cambios en la figura pero no en el modelo).\n\n\nRamas (Branches)\nUna rama representa una línea independiente de cambios en su repo, una versión paralela y alternativa de los archivos del proyecto.\nLas ramas son útiles para probar los cambios antes de incorporarlos a la rama principal (main, master), que suele ser la versión primaria/final/“viva” de tu proyecto. Cuando termines de experimentar en una rama, puedes incorporar los cambios a tu rama principal, fusionándola, o eliminarla, si los cambios no fueron tan exitosos.\nNota: no es necesario colaborar con otras personas para utilizar las ramas, ni es necesario tener un repositorio remoto en línea.\n\n\nRepositorios locales y remotos\n\nel repositorio LOCAL en el ordenador físico. Aquí es donde se hacen los cambios reales a los archivos/código.\nel repositorio REMOTO, en línea: las versiones de los archivos del proyecto en el repositorio Github (o en cualquier otro alojamiento web).\n\nPara sincronizar estos repositorios, utilizaremos más funciones. En efecto, a diferencia de Sharepoint, Dropbox u otro software de sincronización, Git no actualiza automáticamente el repositorio local en base a lo que está en línea, o viceversa. Tú eliges cuándo y cómo sincronizarlo.\n\nFETCH: git fetch descarga los cambios realizados en el repositorio remoto pero no cambia el repositorio local. Piensa en ello para una comprobación del estado del repositorio remoto.\nPULL:git pull descarga archivos cambiados en los repositorios remotos y actualiza el repositorio local.\nPUSH: Actualiza el repositorio remoto. Cuando hayas hecho uno o varios commits localmente, puedes hacer git push de los commits al repositorio remoto. Esto envía tus cambios a Github para actualizar el repositorio y que otras personas puedan verlos y extraerlos si lo desean.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#get-started-create-a-new-repository",
    "href": "new_pages/collaboration.es.html#get-started-create-a-new-repository",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.5 Empezar: crear un nuevo repositorio",
    "text": "46.5 Empezar: crear un nuevo repositorio\nHay muchas formas de crear nuevos repositorios. Puedes hacerlo desde la consola/terminal, desde Github, desde una interfaz gráfica, como Github Desktop o Rstudio-&gt;Git.\nHay dos enfoques generales para la puesta en marcha:\n\nCrear un nuevo proyecto R a partir de un repositorio de Github existente o nuevo (preferible para los principiantes), o\nCrear un repositorio Github para un proyecto R existente\n\n\nArchivos de inicio\nWhen you create a new repository, you can optionally create all of the below files, or you can add them to your repository at a later stage. They would typically live in the “root” folder of the repository.\n\nUn archivo README es un archivo que alguien puede leer para entender por qué existe tu proyecto y qué más deben saber para usarlo. Al principio estará vacío, pero deberías completarlo más adelante.\nUn archivo .gitignore es un archivo de texto donde cada línea contendría carpetas o archivos que Git debería ignorar (no rastrear los cambios). Lee más sobre esto y mira ejemplos aquí.\nPuedes elegir un tipo de licencia para el trabajo, de modo que otras personas sepan en qué condiciones pueden utilizar o reproducir tu obra. Para más información, consulta las licencias Creative Commons.\n\n\n\nCrear un nuevo repositorio en Github\nPara crear un nuevo repositorio, entra en Github y busca el botón verde para crear un nuevo repositorio. Este repositorio, ahora vacío, puede ser clonado localmente en tu ordenador (ver la siguiente sección).\n\n\n\n\n\n\n\n\n\nDebes elegir si quieres que tu repositorio sea público (visible para todo el mundo en Internet) o privado (sólo visible para aquellos con permiso). Esto tiene importantes implicaciones si tus datos son sensibles. Si tu repositorio es privado te encontrarás con algunos límites en circunstancias especiales avanzadas, como por ejemplo si estás usando actions de Github para ejecutar automáticamente tu código en la nube.\n\n\nClonar desde un repositorio de Github\nPuedes clonar un repositorio de Github existente para crear un nuevo proyecto R local en tu ordenador.\nEl repositorio de Github puede ser uno que ya existe y tiene contenido, o puede ser un repositorio vacío que acabas de crear. En este último caso, básicamente estás creando el repositorio de Github y el proyecto local de R al mismo tiempo (ver las instrucciones anteriores).\nNota: si no tienes derechos de contribución en un repositorio de Github, es posible primero bifurcar (fork) el repositorio hacia tu perfil, y luego proceder con las otras acciones. La bifurcación se explica al final de este capítulo, pero recomendamos que leas primero las otras secciones.\nPaso 1: Navega en Github hasta el repositorio, clica en el botón verde “Code” y copia la HTTPS clon URL (ver imagen inferior)\n\n\n\n\n\n\n\n\n\nEl siguiente paso se puede realizar en cualquier interfaz. Lo ilustraremos con Rstudio y Github desktop.\n\nEn Rstudio\nEn RStudio, inicia un nuevo proyecto R clicando en File&gt;New project &gt; Version control &gt; Git) (Archivo &gt; Nuevo proyecto &gt; Control de versiones &gt; Git)\n\nCuando te pida la “URL del repositorio”, pega la URL HTTPS de Github\nAsigna al proyecto R un nombre corto e informativo\nElige dónde se guardará el nuevo proyecto R localmente\nMarca “Abrir en una nueva sesión” y clica en “Crear proyecto”.\n\nAhora estás en un nuevo proyecto local de RStudio que es un clon del repositorio de Github. Este proyecto local y el repositorio de Github están ahora vinculados.\n\n\nEn Github Desktop\n\nClica en File&gt;Clone repository (Archivo &gt; Clonar un repositorio)\nSelecciona la pestaña URL\nPega la URL HTTPS de Github en la primera casilla\nSelecciona la carpeta en la que deseas tener tu repositorio local\nClica en “CLONE”\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuevo repositorio de Github a partir de un proyecto R existente\nUn escenario alternativo de configuración es que ya tengas un proyecto R con contenido, y quieras crear un repositorio Github para él.\n\nCrear un nuevo repositorio de Github vacío para el proyecto (ver instrucciones anteriores)\nClona este repositorio localmente (ver las instrucciones de HTTPS más arriba)\nCopia todo el contenido de tu proyecto R preexistente (códigos, datos, etc.) en este nuevo repositorio local vacío (por ejemplo, utiliza copiar y pegar).\nAbre tu nuevo proyecto en RStudio, y ve al panel Git. Los nuevos archivos deberían registrarse como cambios de archivo, ahora rastreados por Git. Por lo tanto, puedes agrupar estos cambios bajo un commit y push a Github. Una vez hecho push, el repositorio en Github reflejará todos los archivos.\n\nConsulta la sección de flujo de trabajo de Github para obtener más detalles sobre este proceso.\n\n\n¿Qué aspecto tiene ahora?\n\nEn RStudio\nUna vez que hayas clonado un repositorio de Github a un nuevo proyecto R, ahora verás en RStudio una pestaña “Git”. Esta pestaña aparece en el mismo panel de RStudio que Environment:\n\n\n\n\n\n\n\n\n\n\nBotón commit para consolidar los cambios del archivo guardado en local (se abrirá una nueva ventana para añadir la descripción y confirmarlo)\nFlecha azul pull (descarga los cambios realizados en la versión remota/Github de esa rama y actualiza tu versión local de la rama)\nFlecha verde push (enviar cualquier commits/cambio de tu versión local de la rama y actualiza la versión remota/Github de esa rama)\nLa pestaña Git en RStudio\nBotón para crear una rama NUEVA dependiente de la rama que se muestra a la derecha como base. Casi siempre querrá bifurcarse desde la rama principal (después de haber tirado primero para actualizar la rama principal)\nLa Rama en la que trabajas actualmente\nA continuación aparecerán los cambios que haya realizado en el código o en otros archivos\n\n\n\nEn Github Desktop\nGithub Desktop es una aplicación independiente que te permite gestionar todos tus repositorios. Cuando la abres, la interfaz te permite elegir el repositorio en el que quieres trabajar, y luego realizar acciones básicas de Git desde allí.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#git-github-workflow",
    "href": "new_pages/collaboration.es.html#git-github-workflow",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.6 Flujo de trabajo Git + Github",
    "text": "46.6 Flujo de trabajo Git + Github\n\nResumen del proceso\nUna vez que hayas completado la configuración (descrita anteriormente), tendrás un repo de Github que está conectado (clonado) a un proyecto local de R. La rama principal (main por defecto) es la llamada versión “viva” de todos los archivos. Cuando quieras hacer modificaciones, es una buena práctica crear una nueva rama a partir de la rama principal (como “Hacer una copia”). Este es un flujo de trabajo típico en Git porque crear una rama es fácil y rápido.\nUn flujo de trabajo típico es el siguiente:\n\nAsegúrate de que tu repositorio local está actualizado, actualízalo si no es así\nVe a la rama en la que estabas trabajando anteriormente, o crea una nueva rama para probar algunas cosas\nTrabaja en los archivos localmente en tu ordenador, haz uno o varios commits en esta rama\nActualiza la versión remota de la rama con tus cambios (push)\nCuando estés satisfecho con tu rama, puedes fusionar la versión en línea de la rama de trabajo con la rama “principal” en línea para transferir los cambios\n\nOtros miembros del equipo pueden estar haciendo lo mismo con sus propias ramas, o quizás contribuyendo con commits en su rama de trabajo también.\nA continuación, repasamos el proceso anterior paso a paso con más detalle. Es un esquema que hemos desarrollado - está en el formato de una tabla de dos x dos, por lo que debería ayudarnos a entenderlo.\n\n\n\n\n\n\n\n\n\nAquí hay otro diagrama.\nNota: hasta hace poco, se utilizaba el término rama “master” (maestra), pero ahora se denomina rama “main” (principal).\n\n\n\n\n\n\n\n\n\nFuente de la imagen",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#create-a-new-branch",
    "href": "new_pages/collaboration.es.html#create-a-new-branch",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.7 Crear una nueva rama",
    "text": "46.7 Crear una nueva rama\nCuando seleccionas una rama para trabajar, Git restablece tu directorio de trabajo tal y como estaba la última vez que estuviste en esta rama.\n\nEn el panel Git de Rstudio\nAsegúrate que te encuentras en la rama “main” (master, principal) y, a continuación, clica en el icono morado para crear una nueva rama (véase la imagen anterior).\n\nPedirá un nombre descriptivo para esa rama, de una palabra (se pueden usar barras bajas si es necesario).\nVerás que localmente, sigues en el mismo proyecto R, pero ya no estás trabajando en la rama “main”(principal).\nUna vez creada, la nueva rama también aparecerá en el sitio web de Github como una rama.\n\nPuedes visualizar las ramas en el panel Git de Rstudio tras clicar en “History”\n\n\n\n\n\n\n\n\n\n\n\nEn Github Desktop\nEl proceso es muy similar, se pide que des un nombre a tu rama. Después, pedirá que “publique su rama en Github” para que la nueva rama aparezca también en el repositorio remoto.\n\n\n\n\n\n\n\n\n\n\n\nEn la consola\nLo que realmente ocurre entre bastidores es que creas una nueva rama con git branch, y luego vas a la rama con git checkout (es decir, le dices a Git que tus próximos commits se producirán allí). Desde tu repositorio git:\n\ngit branch my-new-branch  # Crea la nueva rama my-new-branch\ngit checkout my-new-branch # Va a la rama\ngit checkout -b my-new-branch # Ambos a la vez (atajo)\n\nPara más información sobre el uso de la consola, consulta la sección sobre comandos Git al final.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#commit-changes",
    "href": "new_pages/collaboration.es.html#commit-changes",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.8 Consolidar los cambios (Commit)",
    "text": "46.8 Consolidar los cambios (Commit)\nAhora puedes editar el código, añadir nuevos archivos, actualizar conjuntos de datos, etc.\nCada uno de tus cambios es rastreado, una vez que el archivo respectivo es guardado. Los archivos modificados aparecerán en la pestaña Git de RStudio, en Github Desktop, o utilizando el comando git status en el terminal (ver más abajo).\nSiempre que hagas cambios sustanciales (por ejemplo, añadir o actualizar una sección de código), haz una pausa y consolida esos cambios (Commit). Piensa en una Consolidación como un “lote” de cambios relacionados con un propósito común. Siempre puedes seguir revisando un archivo después de haber confirmado los cambios en él.\nConsejo sobre los commits: en general, es mejor hacer Consolidaciones pequeñas, que puedan revertirse fácilmente si surge un problema, y Consolidar juntas modificaciones relacionadas con un propósito común. Para lograr esto, verás que debes hacer commits a menudo. Al principio, es probable que te olvides de hacer commits a menudo, pero luego el hábito se impone.\n\nEn Rstudio\nEl ejemplo siguiente muestra que, desde la última consolidación, el script de R Markdown “collaboration.Rmd” ha cambiado, y se han añadido varias imágenes PNG.\n\n\n\n\n\n\n\n\n\nPuede que te preguntes qué representan los cuadrados amarillo, azul, verde y rojo que aparecen junto a los nombres de los archivos. Aquí hay una captura de la hoja de trucos de RStudio que explica su significado. Ten en cuenta que los cambios con el amarillo “?” aún pueden ser puestos en escena, confirmados y enviados.\n\n\n\n\n\n\n\n\n\n\nClica el botón “Commit” en la pestaña Git, que abrirá una nueva ventana (mostrada a continuación)\nClica en un nombre de archivo en el cuadro superior izquierdo\nRevisa los cambios que ha realizado en ese archivo (resaltados en verde o rojo)\n“Stage” (Poner en etapas) el archivo , lo que incluirá esos cambios en la consolidación. Para ello, marca la casilla situada junto al nombre del archivo. También puedes marcar varios nombres de archivo y clicar en “Stage”.\nEscribe un mensaje de consolidación breve pero descriptivo (obligatorio)\nClica el botón “Commit”. Aparecerá un cuadro emergente mostrando el éxito o un mensaje de error.\n\nAhora puedes hacer más cambios y más commits, tantas veces como quieras\n\n\n\n\n\n\n\n\n\n\n\nEn Github Desktop\nPuedes ver la lista de los archivos que se han modificado a la izquierda. Si seleccionas un archivo de texto, verás en el panel derecho un resumen de las modificaciones que se han hecho (la vista no funcionará en archivos más complejos como .docs o .xlsx).\nPara añadir los cambios, basta con marcar la pequeña casilla situada junto a los nombres de los archivos. Cuando hayas seleccionado los archivos que quieres añadir a esta consolidación, dale un nombre a la consolidación, opcionalmente una descripción y luego clica en el botón de commit. button.\n\n\n\n\n\n\n\n\n\n\n\nEn la consola\nLas dos funciones que se utilizan entre bastidores son git add para seleccionar/poner en escena los archivos y git commit para hacer realmente el commit.\n\ngit status # ver los cambios \n\ngit add new_pages/collaboration.Rmd  # selecciona los ficheros a (= stage los cambioss)\n\ngit commit -m \"Describe commit from Github Desktop\" # confirma (commit) los cambios con un mensaje\n\ngit log  # ver información sobre los commits anteriores\n\n\n\nModificar una consolidación anterior\n¿Qué sucede si confirmas algunos cambios, sigues trabajando y te das cuenta de que hiciste cambios que deberían “pertenecer” a la consolidación anterior (en tu opinión)? No temas! Puedes añadir estos cambios a tu consolidación anterior.\nEn Rstudio, debería ser bastante obvio, ya que hay una casilla “Amend previous commit” (modificar una consolidación anterior) en la misma línea que el botón COMMIT.\nPor alguna razón poco clara, la funcionalidad no se ha implementado como tal en Github Desktop, pero hay una forma (conceptualmente incómoda pero fácil) de hacerlo. Si has confirmado pero aún no has enviado tus cambios, aparece un botón “UNDO” justo debajo del botón COMMIT. Clica en él y revertirá tu consolidación (pero mantendrá sus archivos en etapa y tu mensaje de consolidación). Guarda los cambios, añade nuevos archivos a la consolidación si es necesario y vuelva a confirmar.\nEn la consola:\n\ngit add [YOUR FILES] # Añade los nuevos cambios\n\ngit commit --amend  # Modifica la confirmación (commit) anterior\n\ngit commit --amend -m \"An updated commit message\"  # Modifica la confirmación anterior Y actualiza el mensaje de confirmación\n\nNote: think before modifying commits that are already public and shared with your collaborators.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#pull-and-push-changes-up-to-github",
    "href": "new_pages/collaboration.es.html#pull-and-push-changes-up-to-github",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.9 Actualizar los cambios con Github",
    "text": "46.9 Actualizar los cambios con Github\n“Primero PULL (actualizar local), luego PUSH (actualizar reomto)”\nEs una buena práctica fetch y pull antes de empezar a trabajar en tu proyecto, para actualizar la versión de la rama en tu equipo local con los cambios que se han hecho en la versión remota/Github.\nPull a menudo. No dudes. Pull siempre antes de Push.\nCuando los cambios estén hechos y confirmados y estés contento con el estado de tu proyecto, puedes enviar (push) tus consolidaciones a la versión remota/Github de tu rama.\nRepite la operación mientras trabajas en el repositorio.\nNota: es mucho más fácil revertir los cambios que fueron confirmados pero no empujados (es decir, siguen siendo locales) que revertir los cambios que fueron empujados al repositorio remoto (y tal vez ya sacados por otra persona), por lo que es mejor empujar cuando haya terminado de introducir cambios en la tarea en la que estaba trabajando.\n\nEn Rstudio\nPULL - En primer lugar, clica en el icono “Pull” (flecha hacia abajo) que busca y tira al mismo tiempo.\nPUSH – Clicando en el icono verde “Push” (flecha hacia arriba). Es posible que pida que introduzcas tu nombre de usuario y contraseña de Github. La primera vez que la pida, es posible que tenga que introducir dos líneas de comando Git en el Terminal:\n\ngit config –global user.email “you@example.com” (your Github email address), and\n\ngit config –global user.name “Your Github username”\n\nPara saber más sobre cómo introducir estos comandos, consulta la sección siguiente sobre comandos Git.\nSUGERENCIA: ¿Te piden la contraseña muy a menudo? Consulta los capítulos 10 y 11 de este tutorial para conectarse a un repositorio usando una clave SSH (más complicado)\n\n\nEn Github Desktop\nClica en el botón “Fetch origin” para comprobar si hay nuevos commits en el repositorio remoto.\n\n\n\n\n\n\n\n\n\nSi Git encuentra nuevos commits en el repositorio remoto, el botón cambiará a un botón “Pull”. Dado que el mismo botón se utiliza para Pull y Push, no puedes enviar tus cambios si no descargas y actualizas antes.\n\n\n\n\n\n\n\n\n\nPuedes ir a la pestaña “History” (cerca de la pestaña “Changes”) para ver todos los commits (los tuyos y los de los demás). Esta es una buena manera de conocer lo que hicieron tus colaboradores. Puedes leer el mensaje de consolidación, la descripción si la hay, y comparar el código de los dos archivos usando el panel diff.\n\n\n\n\n\n\n\n\n\nUna vez que se han extraído todos los cambios remotos y se ha consignado al menos un cambio local, se puede empujar clicando en el mismo botón.\n\n\n\n\n\n\n\n\n\n\n\nConsola\nSin sorpresas, las órdenes son fetch, pull y push.\n\ngit fetch  # ¿hay nuevos commits en el directorio remoto?\ngit pull   # Trae los commits remotos a tu rama local y la actualiza\ngit push   # Envía los commits locales de esta rama a la rama remota\n\n\n\nQuiero actualizarme pero tengo trabajo local\nEsto puede ocurrir a veces: has hecho algunos cambios en tu repositorio local, pero el repositorio remoto tiene consolidaciones que no has descargado.\nGit rechazará hacer un pull porque podría sobrescribir tus cambios. Hay varias estrategias para guardar tus cambios, bien descritas en Happy Git with R, entre las cuales las dos principales son: - Confirmar tus cambios, obtener los cambios remotos, extraerlos, resolver los conflictos si es necesario (ver la sección más abajo), y consolidar todo en línea - stash tus cambios, lo que en cierto modo los guarda a un lado, pull, unstash (restaurar), y luego confirmar, resolver cualquier conflicto, y push.\nSi los archivos afectados por los cambios remotos y los archivos afectados por tus cambios locales no se solapan, Git puede resolver los conflictos automáticamente.\nEn Github Desktop, esto se puede hacer con botones. Para almacenar, ve a Branch &gt; Stash all changes.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#merge-branch-into-main",
    "href": "new_pages/collaboration.es.html#merge-branch-into-main",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.10 Combinar la rama con la principal",
    "text": "46.10 Combinar la rama con la principal\nSi has terminado de hacer cambios, puedes comenzar el proceso de fusión de esos cambios en la rama principal. Dependiendo de su situación, esto puede ser rápido, o puede tener pasos deliberados de revisión y aprobación que involucren a compañeros de equipo.\n\nLocalmente en Github Desktop\nSe pueden fusionar ramas localmente usando Github Desktop. Primero, ve a (checkout) la rama que será la destinataria de los commits, es decir, la rama que quieres actualizar. A continuación, clica en el menú Branch &gt; Merge into current branch. Un cuadro te permitirá seleccionar la rama desde la que quieres importar.\n\n\n\n\n\n\n\n\n\n\n\nEn la consola\nPrimero, vuelve a la rama que será la destinataria de los cambios. Normalmente es la rama maestra (main), pero puede ser otra rama. Luego fusiona tu rama de trabajo con la maestra.\n\ngit checkout master  # Go back to maste# Vuelve a master (o a la rama a la que se quiere moverla)\ngit merge this_fancy_new_branch\n\nEsta página muestra un ejemplo más avanzado de bifurcación y explica un poco lo que ocurre entre bastidores.\n\n\nEn Github: envío de pull requests\nAunque es totalmente posible fusionar dos ramas localmente, o sin informar a nadie, una fusión puede ser discutida o investigada por varias personas antes de ser integrada en la rama maestra. Para ayudar en el proceso, Github ofrece algunas funciones de discusión en torno a la fusión: el pull request.\nUn pull request (un “PR”) es una solicitud para fusionar una rama con otra (en otras palabras, una solicitud para que tu rama de trabajo se incorpore a la rama “principal”). Una solicitud de extracción suele incluir varias consolidaciones. Un pull request suele iniciar un proceso de conversación y revisión antes de que sea aceptado y la rama sea fusionada. Por ejemplo, puedes leer las discusiones sobre pull requests en el github de dplyr.\nPuedes enviar una solicitud de extracción (PR) directamente desde el sitio web (como se ilustra a continuación) o desde Github Desktop.\n\nIr al repositorio Github (en línea)\nVe a la pestaña “Pull Requests” y clica en el botón “New pull request”.\nSelecciona en el menú desplegable para fusionar su rama en la principal\nEscribe un comentario detallado sobre la solicitud de extracción y clica en “Crear solicitud de extracción”.\n\nEn la imagen siguiente, se ha seleccionado la rama “forests” para fusionarla con la “principal”:\n\n\n\n\n\n\n\n\n\nAhora se debería poder ver el pull request (imagen de ejemplo abajo):\n\nRevisa la pestaña “Files changed” (Archivos cambiados) para ver cómo cambiaría la rama “principal” si se fusionara la rama.\n\nA la derecha, puedes solicitar una revisión a los miembros de tu equipo etiquetando su ID de Github. Si quieres, puedes configurar el repositorio para que se requiera una revisión de aprobación para poder fusionarlo con el principal.\n\nUna vez aprobada la solicitud de extracción, se activará un botón para “Merge pull request” (fusionar la solicitud de extracción). Clica en él.\n\nUna vez completado, elimina tu rama como se explica a continuación.\n\n\n\n\n\n\n\n\n\n\n\n\nResolución de conflictos\nCuando dos personas modifican la(s) misma(s) línea(s) al mismo tiempo, surge un conflicto de fusión. De hecho, Git se niega a tomar una decisión sobre qué versión mantener, pero te ayuda a encontrar dónde está el conflicto. NO TE ASUSTES. La mayoría de las veces, es bastante sencillo de resolver.\nPor ejemplo, en Github:\n\n\n\n\n\n\n\n\n\nDespués de que la fusión haya planteado un conflicto, abre el archivo en tu editor favorito. El conflicto se indicará con una serie de caracteres:\n\n\n\n\n\n\n\n\n\nEl texto entre &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD y ======= proviene de tu repositorio local, y el que está entre ======= y &gt;&gt;&gt;&gt;&gt;&gt;&gt; de la otra rama (que puede ser origin, master o cualquier rama de tu elección).\nTienes que decidir qué versión del código prefieres (o incluso escribir una tercera, incluyendo los cambios de ambas partes si es pertinente), borrar el resto y eliminar todas las marcas que Git ha añadido (&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt; origin/master/tu_nombre_de_rama).\nA continuación, guarda el archivo, estadíalo y haz un commit: este es el commit que hace que la versión fusionada sea “oficial”. No te olvides de hacer push después.\nCuanto más a menudo hagáis pull y push tú y tus colaboradores, menores serán los conflictos.\nNota: Si te sientes cómodo con la consola, existen opciones avanzadas de fusión (por ejemplo, ignorar los espacios en blanco, dar prioridad a un colaborador, etc.).\n\n\nBorrar tu rama\nUna vez que una rama se ha fusionado con la maestra y ya no es necesaria, puedes eliminarla.\n\nGithub + Rstudio\nVe al repositorio en Github y clica en el botón para ver todas las ramas (junto al desplegable para seleccionar ramas). Ahora busca tu rama y clica en el icono de la papelera junto a ella. Lee más detalles sobre cómo eliminar una rama aquí.\nAsegúrate de eliminar también la rama localmente en tu ordenador. Esto no ocurrirá automáticamente.\n\nDesde RStudio, asegúrese de estar en la rama principal\nCambia para escribir los comandos Git en la “Terminal” de RStudio (la pestaña adyacente a la consola de R), y escribe: git branch -d nombre_de_rama, donde “nombre_de_rama” es el nombre de la rama a eliminar\nActualiza tu pestaña Git y la rama debería desaparecer\n\n\n\nEn Github Desktop\nSólo tienes que comprobar la rama que quieres eliminar, e ir al menú Branch &gt; Delete.\n\n\n\nBifurcación\nPuedes bifurcar (fork) un proyecto si quieres contribuir a él pero no tienes los derechos para hacerlo, o si sólo quieres modificarlo para tu uso personal. Puedes encontrar una breve descripción de la bifurcación aquí.\nEn Github, clica en el botón “Fork”:\n\n\n\n\n\n\n\n\n\nEsto clonará el repositorio original, pero en tu propio perfil. Así que ahora hay dos versiones del repositorio en Github: la original, que no puedes modificar, y la versión clonada en tu perfil.\nEntonces, puedes clonar tu versión del repositorio en línea localmente en tu ordenador, utilizando cualquiera de los métodos descritos en las secciones anteriores. Luego, puede crear una nueva rama, hacer cambios, confirmarlos y empujarlos a tu repositorio remoto.\nUna vez que estés contento con el resultado, puedes crear un Pull Request desde Github o Github Desktop para iniciar la conversación con los propietarios/mantenedores del repositorio original.\n¿Y si necesitas algunos commits más recientes del repositorio oficial?\nImagina que alguien hace una modificación crítica en el repositorio oficial, que quieres incluir en tu versión clonada. Es posible sincronizar tu fork con el repositorio oficial. Implica usar el terminal, pero no es demasiado complicado. Principalmente necesitas recordar que - upstream = el repositorio oficial, el que no has podido modificar - origin = tu versión del repositorio en tu perfil de Github\nPuedes leer este tutorial o seguirlo a continuación:\nPrimero, escribe en tu terminal Git (dentro de tu repo):\n\ngit remote -v\n\nSi aún no has configurado el repositorio upstream deberías ver dos líneas, que comienzan por origin. Muestran el repositorio remoto al que apuntan fetch y push. Recuerda que origin es el apodo convencional para tu propia versión del repositorio en Github. Por ejemplo:\n\n\n\n\n\n\n\n\n\nAhora, añade un nuevo repositorio remoto:\n\ngit remote add upstream https://github.com/epirhandbook/Epi_R_handbook.git\n\nAquí la dirección es la que genera Github cuando clonas un repositorio (ver sección de clonación). Ahora tendrás cuatro punteros remotos:\n\n\n\n\n\n\n\n\n\nAhora que la configuración está hecha, siempre que quieras obtener los cambios del repositorio original (upstream), sólo tienes que ir (checkout) a la rama que quieres actualizar y teclear:\n\ngit fetch upstream # Obtiene los nuevos commits del repositorio remoto\ngit checkout the_branch_you_want_to_update\ngit merge upstream/the_branch_you_want_to_update  # Fusiona la rama de upstream en tu rama..\ngit push # Actualiza tu propia versión del repositorio remoto\n\nSi hay conflictos, tendrá que resolverlos, tal y como se explica en la sección Resolución de conflictos.\nResumen: forking es clonación, pero en el lado del servidor de Github. El resto de las acciones son las típicas del flujo de trabajo de colaboración (clonar, empujar, tirar, confirmar, fusionar, enviar solicitudes de extracción…).\nNota: aunque la bifurcación es un concepto, no un comando de Git, también existe en otros hosts web, como Bitbucket.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#what-we-learned",
    "href": "new_pages/collaboration.es.html#what-we-learned",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.11 Lo que hemos aprendido",
    "text": "46.11 Lo que hemos aprendido\nHas aprendido a:\n\nConfigurar Git para rastrear las modificaciones en tus carpetas,\nConectar tu repositorio local a un repositorio remoto en línea,\nConfirmar los cambios,\nSincronizar tus repositorios locales y remotos.\n\nTodo esto debería ayudar a ponerte en marcha y ser suficiente para la mayoría de tus necesidades de análisis epidemiológico. Normalmente no tenemos un uso tan avanzado como los desarrolladores.\nSin embargo, debes saber que si quieres (o necesitas) ir más allá, Git ofrece más potencia para simplificar los historiales de commit, revertir uno o varios commits, hacer cherry-pick de commits, etc. Algunas cosas pueden parecer pura magia, pero ahora que tienes los fundamentos, es más fácil construir sobre ellos.\nTen en cuenta que mientras el panel Git en Rstudio y Github Desktop son buenos para los principiantes / uso diario en nuestra línea de trabajo, no ofrecen una interfaz para algunas de las funciones intermedias / avanzadas de Git. Algunas interfaces más completas permiten hacer más cosas con apuntar y clicar (normalmente a costa de un diseño más complejo).\nRecuerda que, dado que puedes utilizar cualquier herramienta en cualquier momento para realizar el seguimiento de tu repositorio, puedes instalar muy fácilmente una interfaz para probarla a veces, o para realizar alguna tarea compleja menos común ocasionalmente, mientras prefieres una interfaz simplificada para el resto del tiempo (por ejemplo, utilizando Github Desktop la mayor parte del tiempo, y cambiando a SourceTree o Gitbash para algunas tareas específicas).",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#git",
    "href": "new_pages/collaboration.es.html#git",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.12 Comandos Git",
    "text": "46.12 Comandos Git\n\nAprendizaje recomendado\nPara aprender los comandos de Git en un tutorial interactivo, consulta este sitio web.\n\n\n¿Dónde escribir los comandos?\nSe introducen comandos en un entorno Git.\nOpción 1 Puedes abrir una nueva Terminal en RStudio. Esta pestaña está al lado de la Consola R. Si no puedes escribir ningún texto en ella, clica en el menú desplegable debajo de “Terminal” y selecciona “Nueva terminal”. Escribe los comandos en el espacio parpadeante delante del signo de dólar “$”.\n\n\n\n\n\n\n\n\n\nOpción 2 También puede abrir un shell (un terminal para introducir comandos) clicando en el icono azul de “engranajes” en la pestaña Git (cerca del entorno de RStudio). Selecciona “Shell” en el menú desplegable. Se abrirá una nueva ventana en la que puedes escribir los comandos después del signo de dólar “$”.\nOpción 3 Clica con el botón derecho para abrir “Git Bash here” que abrirá el mismo tipo de terminal, o abra Git Bash desde tu lista de aplicaciones. Más información para principiantes sobre Git Bash, cómo encontrarlo y algunos comandos bash que necesitarás.\n\n\nEjemplos de comandos\nA continuación presentamos algunos comandos git comunes. Cuando los uses, ten en cuenta qué rama está activa (check-out), ¡ya que eso cambiará la acción!\nEn los comandos de abajo, representa un nombre de rama. representa el hash ID de un commit específico. representa un número. No escriba los símbolos &lt; o &gt;.\n\n\n\n\n\n\n\nComando Git\nAcción\n\n\n\n\ngit branch &lt;name&gt;\nCrear una nueva rama con el nombre \n\n\ngit checkout &lt;name&gt;\nCambiar la rama actual a \n\n\ngit checkout -b &lt;name&gt;\nAtajo para crear una nueva rama y cambiar a ella\n\n\ngit status\nVer los cambios no rastreados\n\n\ngit add &lt;file&gt;\nPreparar un archivo (estadiarlo)\n\n\ngit commit -m &lt;message&gt;\nConfirmar los cambios preparados a la rama actual con el mensaje\n\n\ngit fetch\nObtener los commits del repositorio remoto.\n\n\ngit pull\nActualizar desde el repositorio remoto en la rama actual\n\n\ngit push\nEnviar los commits locales al directorio remoto\n\n\ngit switch\nUna alternativa a git checkout\n\n\ngit merge &lt;name&gt;\nFusionar la rama  en la rama actual\n\n\ngit rebase &lt;name&gt;\nAñadir los commits de la rama actual a la rama",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/collaboration.es.html#resources-38",
    "href": "new_pages/collaboration.es.html#resources-38",
    "title": "46  Control de versiones y colaboración con Git y Github",
    "section": "46.13 Recursos",
    "text": "46.13 Recursos\nGran parte de esta página está inspirada en this “Happy Git with R” website by Jenny Bryan. Hay una sección muy útil de este sitio web que te ayuda a solucionar errores comunes relacionados con Git y R.\nLa documentación y guía de inicio de Github.com..\nLa hoja de trucos de RStudio “IDE” cheatsheet que incluye consejos sobre Git con RStudio.\nhttps://ohi-science.org/news/github-going-back-in-time\nComandos Git para principiantes\nUn tutorial interactivo para aprender los comandos de Git.\nhttps://www.freecodecamp.org/news/an-introduction-to-git-for-absolute-beginners-86fa1d32ff71/: bueno para aprender los fundamentos absolutos para rastrear los cambios en una carpeta en en tu propio ordenador.\nBuen esquema para entender las ramas: https://speakerdeck.com/alicebartlett/git-for-humans\nTutoriales que cubren temas básicos y más avanzados*\nhttps://tutorialzine.com/2016/06/learn-git-in-30-minutes\nhttps://dzone.com/articles/git-tutorial-commands-and-operations-in-git https://swcarpentry.github.io/git-novice/ (short course) https://rsjakob.gitbooks.io/git/content/chapter1.html\nEl libro Pro Git está considerado como una referencia oficial. Aunque algunos capítulos están bien, suele ser un poco técnico. Probablemente es un buen recurso una vez que hayas usado un poco Git y quieras aprender con un poco más de precisión lo que sucede y cómo ir más allá.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Control de versiones y colaboración con Git y Github</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.es.html",
    "href": "new_pages/errors.es.html",
    "title": "47  Errores comunes",
    "section": "",
    "text": "47.1 Interpretación de los mensajes de error\nLos mensajes de error de R pueden ser crípticos a veces, así que Google es tu amigo. Busca el mensaje de error con “R” y busca publicaciones recientes en StackExchange.com, stackoverflow.com, community.rstudio.com, twitter (#rstats) y otros foros utilizados por los programadores para archivar preguntas y respuestas. Intenta encontrar publicaciones recientes que hayan resuelto problemas similares.\nSi después de mucho buscar no encuentras una respuesta a tu problema, considera la posibilidad de crear un ejemplo reproducible (“reprex”) y publicar tú mismo la pregunta. Consulta la página sobre Cómo obtener ayuda para obtener consejos sobre cómo crear y publicar un ejemplo reproducible en los foros.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Errores comunes</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.es.html#common-errors-1",
    "href": "new_pages/errors.es.html#common-errors-1",
    "title": "47  Errores comunes",
    "section": "47.2 Errores comunes",
    "text": "47.2 Errores comunes\nA continuación, enumeramos algunos errores comunes y posibles explicaciones/soluciones. Algunos de ellos se han tomado prestados de Noam Ross, que analizó los mensajes más comunes del foro en Stack Overflow sobre los mensajes de error de R (véase el análisis aquí)\n\nErrores tipográficos\nError: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\"\nSi aparece “unexpected symbol” (símbolo inesperado), comprueba si faltan comas\n\n\nErrores del paquete\ncould not find function \"x\"...\nEsto probablemente significa que has escrito mal el nombre de la función, o que has olvidado instalar o cargar un paquete.\nError in select(data, var) : unused argument (var)\nCrees que estás usando dplyr::select() pero la función select() ha sido enmascarada por MASS::select() - especifica dplyr:: o reordena la carga de tu paquete para que dplyr esté después de todos los demás.\nOtros errores de enmascaramiento comunes provienen de: plyr::summarise() y stats::filter(). Considere la posibilidad de utilizar el paquete conflicted.\nError in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’\nSi recibes un error diciendo que necesitas eliminar un archivo “00LOCK”, ve a tu biblioteca “R” en el directorio de tu ordenador (por ejemplo, R/win-library/) y busca una carpeta llamada “00LOCK”. Elimínala manualmente e intenta instalar el paquete de nuevo. Es probable que un proceso de instalación anterior se haya interrumpido, provocando este error.\n\n\nErrores en los objetos\nNo such file or directory:\nSi ves un error como este cuando intentas exportar o importar: Comprueba la ortografía del archivo y de la ruta de acceso, y si la ruta contiene barras inclinadas, asegúrese de que son hacia delante / y no hacia atrás \\. Asegúrate también de que has utilizado la extensión de archivo correcta (por ejemplo, .csv, .xlsx).\nobject 'x' not found \nEsto significa que el objeto al que se hace referencia no existe. ¿Quizá el código anterior no se ha ejecutado correctamente?\nError in 'x': subscript out of bounds\nEsto significa que has intentado acceder a algo (un elemento de un vector o una lista) que no estaba allí.\n\n\nErrores de sintaxis de las funciones\n# ejecuta recode sin reiniciar la variable x en mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`.\nEste error de arriba (argument .x is missing, with no default) es común en mutate() si estás suministrando una función como recode() o replace_na() donde se espera que proporciones el nombre de la columna como primer argumento. Esto es fácil de olvidar.\n\n\nErrores lógicos\nError in if\nEsto probablemente significa que se aplicó una sentencia if a algo que no era TRUE o FALSE.\n\n\nErrores de los factores\n#Trató de añadir un valor (\"Missing\") a un factor (con replace_na operando en un factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated\nSi ves este error sobre niveles de factor no válidos, es probable que tengas una columna de tipo Factor (que contiene niveles predefinidos) y hayas intentado añadirle un nuevo valor. Conviértela al tipo Carácter antes de añadir un nuevo valor.\n\n\nErrores de trazado\nError: Insufficient values in manual scale. 3 needed but only 2 provided. ggplot() scale_fill_manual() values = c(“orange”, “purple”) … insuficiente para el número de niveles del factor … considera si NA es ahora un nivel del factor…\nCan't add x object\nProbablemente tienes un + extra al final de un comando ggplot que necesitas eliminar.\n\n\nErrores de R Markdown\nSi el mensaje de error contiene algo como Error en options[sprintf(\"fig.%s\", i)]], comprueba que tus opciones knitr en la parte superior de cada chunk utilizan correctamente out.width = o out.height =y no fig.width= y fig.height=.\n\n\nMiscelánea\nComprueba si has reordenado los verbos dplyr y no has reemplazado un pipe en el medio, o no has eliminado un pipe del final después de reordenar.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Errores comunes</span>"
    ]
  },
  {
    "objectID": "new_pages/errors.es.html#resources-39",
    "href": "new_pages/errors.es.html#resources-39",
    "title": "47  Errores comunes",
    "section": "47.3 Recursos",
    "text": "47.3 Recursos\nEsta es otra entrada del blog que enumera los errores comunes de programación en R a los que se enfrentan los principiantes",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Errores comunes</span>"
    ]
  },
  {
    "objectID": "new_pages/help.es.html",
    "href": "new_pages/help.es.html",
    "title": "48  Cómo obtener ayuda",
    "section": "",
    "text": "48.1 Issues en Github\nMuchos paquetes y proyectos de R tienen su código alojado en el sitio web Github.com. Puedes comunicarte directamente con los autores a través de este sitio web publicando un “Issue”.\nLee más sobre cómo almacenar tu trabajo en Github en la página Colaboración y Github.\nEn Github, cada proyecto está contenido en un repositorio. Cada repositorio contiene código, datos, resultados, documentación de ayuda, etc. También hay un vehículo para comunicarse con los autores llamado “Issues”.\nMira a continuación la página de Github del paquete incidence2 (utilizado para hacer curvas epidémicas). Puedes ver la pestaña “Issues” resaltada en amarillo. Puedes ver que hay 5 temas abiertos.\nUna vez en la pestaña de problemas, podrás ver los problemas abiertos. Revísalas para asegurarte de que tu problema no ha sido ya tratado. Puedes abrir una nueva incidencia clicando en el botón verde de la derecha. Necesitarás una cuenta de Github para hacerlo.\nEn tu Issue, sigue las instrucciones que aparecen a continuación para proporcionar un ejemplo mínimo y reproducible. Y, por favor, ¡se cortés! La mayoría de las personas que desarrollan paquetes y proyectos de R lo hacen en su tiempo libre (¡como este manual!).\nPara leer más materiales avanzados sobre el manejo de problemas en tu propio repositorio de Github, consulta su documentación sobre Problemas.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Cómo obtener ayuda</span>"
    ]
  },
  {
    "objectID": "new_pages/help.es.html#reproducible-example",
    "href": "new_pages/help.es.html#reproducible-example",
    "title": "48  Cómo obtener ayuda",
    "section": "48.2 Ejemplo reproducible",
    "text": "48.2 Ejemplo reproducible\nProporcionar un ejemplo reproducible (“reprex”) es la clave para obtener ayuda cuando se publica en un foro o en un Issue de Github. La gente quiere ayudarte, pero tienes que darles un ejemplo con el que puedan trabajar en su propio ordenador. El ejemplo debe:\n\nDemostrar el problema que has encontrado\nSer mínimo, en el sentido de que incluya sólo los datos y el código necesarios para reproducir el problema\nSer reproducible, de manera que se incluyan todos los objetos (por ejemplo, los datos), las llamadas al paquete (por ejemplo, library() o p_load())\nAdemás, ¡asegúrate de no publicar ningún dato sensible con el reprex!* Puedes crear dataframes de ejemplo, o utilizar uno de los dataframes incorporados en R (escribe data() para ver una lista de estos set de datos).\n\n\nEl paquete reprex\nEl paquete reprex puede ayudarte a crear un ejemplo reproducible:\n\nreprex se instala con tidyverse, así que carga cualquiera de los dos paquetes\n\n\n# instalar/cargar tidyverse (que incluye reprex)\npacman::p_load(tidyverse)\n\n\nInicia un script de R que cree el problema, paso a paso, empezando por la carga de paquetes y datos.\n\n\n# cargar paquetes\npacman::p_load(\n     tidyverse,  # gestión y visualización de datos\n     outbreaks)  # datos de ejemplo de brotes\n\n#  lista de casos del brote de gripe\noutbreak_raw &lt;- outbreaks::fluH7N9_china_2013  # obtener datos del paquete de brotes\n\n# Limpiar los datos\noutbreak &lt;- outbreak_raw %&gt;% \n     mutate(across(contains(\"date\"), as.Date))\n\n# Graficar el brote\n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\n\nCopia todo el código en tu portapapeles y ejecuta el siguiente comando:\n\nreprex::reprex()\n\nVerás que aparece una salida HTML en el panel del visor de RStudio. Contendrá todo tu código y cualquier advertencia, error o salida de gráficos. Esta salida también se copia en el portapapeles, por lo que puedes publicarla directamente en un Issue de Github o en un mensaje del foro.\n\n\n\n\n\n\n\n\n\n\nSi estableces session_info = TRUE se incluirá la salida de sessioninfo::session_info() con tus versiones de R y del paquete utilizado\nPuedes proporcionar un directorio de trabajo con wd =\nPuedes leer más sobre los argumentos y las posibles variaciones en esta página o introduciendo ?reprex\n\nEn el ejemplo anterior, el comando ggplot() no se ejecutó porque el argumento date_format = no es correcto - debería ser date_labels =.\n\n\nDatos mínimos\nLos revisores tienen que ser capaces de utilizar tus datos - idealmente tienen que ser capaces de crearlos con código.\nPara crear unos datos mínimos, considera la posibilidad de anonimizarlos y utilizar sólo un subconjunto de las observaciones.\nEN CONSTRUCCIÓN - también puede utilizar la función dput() para crear unos datos mínimo.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Cómo obtener ayuda</span>"
    ]
  },
  {
    "objectID": "new_pages/help.es.html#posting-to-a-forum",
    "href": "new_pages/help.es.html#posting-to-a-forum",
    "title": "48  Cómo obtener ayuda",
    "section": "48.3 Publicar en un foro",
    "text": "48.3 Publicar en un foro\nLee muchos mensajes de foros. Comprende qué mensajes están bien escritos y cuáles no.\n\nEn primer lugar, decide si vas a formular la pregunta. Has revisado a fondo el sitio web del foro, probando con varios términos de búsqueda, para ver si tu pregunta ya ha sido formulada?\nDale a tu pregunta un título informativo (no “¡Ayuda! esto no funciona”).\nEscribe tu pregunta:\n\n\nPresenta la situación y tu problema\nEnlaza con posts de temas similares y explica cómo no responden a tu pregunta\nIncluye cualquier información relevante para ayudar a alguien que no conozca el contexto de tu trabajo\nDa un ejemplo mínimo reproducible con la información de tu sesión de R\nUtiliza la ortografía, la gramática y la puntuación adecuadas, y divide tu pregunta en párrafos para que sea más fácil de leer\n\n\nSupervisa tu pregunta una vez publicada para responder a cualquier solicitud de aclaración. Se cortés y amable: a menudo las personas que responden están ofreciendo su tiempo para ayudarte. Si tienes una pregunta de seguimiento, piensa si debe ser una pregunta publicada por separado.\nMarca la pregunta como respondida, si obtienes una respuesta que satisfaga la petición original. Esto ayuda a que otros reconozcan más tarde rápidamente la solución.\n\nLee estos posts sobre cómo hacer una buena pregunta el código de conducta de Stack overflow.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Cómo obtener ayuda</span>"
    ]
  },
  {
    "objectID": "new_pages/help.es.html#resources-40",
    "href": "new_pages/help.es.html#resources-40",
    "title": "48  Cómo obtener ayuda",
    "section": "48.4 Recursos",
    "text": "48.4 Recursos\nPágina de Tidyverse sobre cómo obtener ayuda\nConsejos para elaborar unos datos mínimos\nDocumentación de la función dput",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Cómo obtener ayuda</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.es.html",
    "href": "new_pages/network_drives.es.html",
    "title": "49  R en redes locales",
    "section": "",
    "text": "49.1 Resumen\nEl uso de R en unidades compartidas de la red o de la “empresa” puede presentar desafíos adicionales. Esta página contiene enfoques, errores comunes y sugerencias sobre la solución de problemas obtenidas a partir de nuestra experiencia trabajando con estos problemas. Se incluyen consejos para las situaciones especialmente delicadas relacionadas con R Markdown.\nUso de R en unidades de red: Principios generales",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R en redes locales</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.es.html#overview-9",
    "href": "new_pages/network_drives.es.html#overview-9",
    "title": "49  R en redes locales",
    "section": "",
    "text": "Debes tener acceso de administrador a tu ordenador. Configura RStudio específicamente para que se ejecute como administrador.\n\nGuarda los paquetes en una biblioteca en una unidad con letras (por ejemplo, “C:”) cuando sea posible. Uiliza lo menos posible una biblioteca de paquetes cuya ruta comience por “\\\".\n\nEl paquete rmarkdown debe no estar en una librería de paquetes “\\\", ya que entonces no puede conectarse a TinyTex o Pandoc.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R en redes locales</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.es.html#rstudio-as-administrator",
    "href": "new_pages/network_drives.es.html#rstudio-as-administrator",
    "title": "49  R en redes locales",
    "section": "49.2 RStudio como administrador",
    "text": "49.2 RStudio como administrador\nCuando clicas en el icono de RStudio para abrirlo, hazlo clicando con el botón derecho. Dependiendo de tu máquina, puedes ver una opción para “Ejecutar como administrador”. O si no, puedes ver una opción para seleccionar Propiedades (entonces debería aparecer una ventana con la opción “Compatibilidad”, y selecciona una casilla de verificación “Ejecutar como administrador”).",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R en redes locales</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.es.html#useful-commands",
    "href": "new_pages/network_drives.es.html#useful-commands",
    "title": "49  R en redes locales",
    "section": "49.3 Comandos útiles",
    "text": "49.3 Comandos útiles\nA continuación se presentan algunos comandos útiles cuando se trata de solucionar problemas utilizando R en unidades de red.\nPuedes devolver la(s) ruta(s) a las bibliotecas de paquetes que R está utilizando. Serán listadas en el orden que R está usando para instalar/cargar/buscar paquetes. Por lo tanto, si quieres que R utilice una biblioteca diferente por defecto, puedes cambiar el orden de estas rutas (ver más abajo).\n\n# Buscar librerías\n.libPaths()                   # Las rutas de las carpetas, listadas en el orden en que R las instala/busca. \n                              # Nota: Se listarán todas las unidades, pero para instalar en algunas (ej. C:) \n                              # puede que se necesite ejecutar RStudio como administrador (no aparecerá en el menú desplegable \n                              # de instalación de paquetes) \n\nEs posible que desees cambiar el orden de las bibliotecas de paquetes utilizados por R. Por ejemplo, si R está recogiendo una ubicación de la biblioteca que comienza con “\\\" y uno que comienza con una letra, por ejemplo,”D:“. Puedes ajustar el orden de .libPaths() con el siguiente código.\n\n# Cambiar el orden de las carpetas\n# esto puede afectar la prioridad de R al encontrar un paquete. Por ejemplo, puede que quiera que la unidad C: aparezca primera en la lista\nmyPaths &lt;- .libPaths() # obtiene las rutas\nmyPaths &lt;- c(myPaths[2], myPaths[1]) # las cambia\n.libPaths(myPaths) # las reasigna de nuevo\n\nSi tienes dificultades para que R Markdown se conecte a Pandoc, comienza con este código para averiguar dónde cree RStudio que está tu instalación de Pandoc.\n\n# Encontrar Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\") # Encuentra dónde cree RStudio que está la instalación de Pandoc\n\nSi quieres ver de qué biblioteca se está cargando un paquete, prueba con el siguiente código:\n\n# Encuentra un paquete\n# da la primera ubicación del paquete ( tener en cuenta el orden de las unidades o carpetas)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\"))",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R en redes locales</span>"
    ]
  },
  {
    "objectID": "new_pages/network_drives.es.html#troubleshooting-common-errors",
    "href": "new_pages/network_drives.es.html#troubleshooting-common-errors",
    "title": "49  R en redes locales",
    "section": "49.4 Solución de errores comunes",
    "text": "49.4 Solución de errores comunes\n“Fallo al compilar…tex en rmarkdown”\n\nComprueba la instalación de TinyTex, o instala TinyTex en la ubicación C:. Consulta la página de fundamentos de R sobre cómo instalar TinyTex.\n\n\n# comprueba/instala tinytex, en la ubicación C:.\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # debería devolver TRUE ( observar los tres dos puntos)\n\nNo se pueden cargar las rutinas de Internet.\nPor ejemplo, Error in tools::startDynamicHelp() : internet routines cannot be loaded\n\nIntenta seleccionar la versión de 32 bits de RStudio a través de Herramientas/Opciones Globales.\n\nnota: si la versión de 32 bits no aparece en el menú, asegúrate que no está utilizando RStudio v1.2.\n\nAlternativamente, intenta desinstalar R y volver a instalarlo con una versión de bits diferente (32 en lugar de 64)\n\nC: la biblioteca no aparece como opción cuando intento instalar los paquetes manualmente\n\nEjecuta RStudio como administrador, entonces aparecerá esta opción.\nPara configurar RStudio para que se ejecute siempre como administrador (lo que resulta ventajoso cuando se utiliza un proyecto R en el que no se clica en el icono de RStudio para abrirlo)… clica con el botón derecho en el icono de Rstudio\n\nLa imagen siguiente muestra cómo puedes seleccionar manualmente la biblioteca en la que instalar un paquete. Esta ventana aparece cuando se abre el panel de paquetes de RStudio y se clica en “Install”.\n\n\n\n\n\n\n\n\n\nError Pandoc 1\nSi aparece el error “pandoc error 1” al ejecutar R Markdowns scripts en unidades de red:\n\nDe las múltiples ubicaciones de las bibliotecas, que aparezca en primer lugar la que tenga una unidad de disco con letras (véanse los códigos anteriores)\nLa solución anterior funciona en una unidad de red local, si establece la conexión a Internet en la red\nMira más consejos aquí: https://ciser.cornell.edu/rmarkdown-knit-to-html-word-pdf/\n\nError Pandoc 83\nEl error será algo así: can't find file...rmarkdown...lua.... Esto significa que no se ha podido encontrar este archivo.\nVer https://stackoverflow.com/questions/58830927/rmarkdown-unable-to-locate-lua-filter-when-knitting-to-word\nPosibilidades:\n\nEl paquete Rmarkdown no está instalado\nEl paquete Rmarkdown no se encuentra\nUn problema de derechos de administración.\n\nEs posible que R no sea capaz de encontrar el archivo del paquete rmarkdown, así que comprueba en qué biblioteca está el paquete rmarkdown (vearel código anterior). Si el paquete está instalado en una biblioteca inaccesible (por ejemplo, comienza con “\\\") considera moverlo manualmente a C: o a otra biblioteca con nombre. Ten en cuenta que el paquete rmarkdown tiene que ser capaz de conectarse a la instalación de TinyTex, por lo que no puede valojarse en una biblioteca en una unidad de red.\nError Pandoc 61\nPor ejemplo: Error: pandoc document conversion failed with error 61 o Could not fetch...\n\nPrueba a ejecutar RStudio como administrador (clica con el botón derecho en el icono, selecciona ejecutar como administrador, vea las instrucciones anteriores)\nVer también si el paquete específico que no pudo ser alcanzado puede ser movido a la biblioteca C:.\n\nError de LaTex (ver más abajo)\nUn error como: ! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' not found: using draft setting. o Error: LaTeX failed to compile file_name.tex.\n\nConsulta https://yihui.org/tinytex/r/#debugging para obtener consejos de depuración.\nVer file_name.log para más información.\n\nError Pandoc 127\nPodría tratarse de un problema de RAM (espacio). Reinicia tu sesión de R e inténtelo de nuevo.\nAsignación de unidades de red\nMapear una unidad de red puede ser arriesgado. Consulta con tu departamento de TI antes de intentarlo.\nUn consejo tomado de este foro de discusión:\n¿Cómo se abre un archivo “a través de una unidad de red asignada”?\n\nEn primer lugar, tendrás que conocer la ubicación de la red a la que intentas acceder.\nA continuación, en el administrador de archivos de Windows, deberás clicar con el botón derecho en “Este PC” en el panel de la derecha, y seleccionar “Asignar una unidad de red”.\nAsigna la ubicación de red como una letra de unidad.\nAhora tienes dos maneras de llegar al archivo que estás abriendo. Usar la ruta de la letra de la unidad debería funcionar.\n\nError in install.packages()\nSi obtienes un error que incluya la mención de un directorio de “bloqueo”, por ejemplo Error in install.packages : ERROR: failed to lock directory...\nBusca en tu biblioteca de paquetes y verás una carpeta cuyo nombre empieza por “00LOCK”. Prueba los siguientes consejos:\n\nElimina manualmente el directorio de la carpeta “00LOCK” de tu biblioteca de paquetes. Intenta instalar el paquete de nuevo.\nTambién puedes probar el comando pacman::p_unlock() (también puedes poner este comando en el Rprofile para que se ejecute cada vez que se abra el proyecto). Luego intenta instalar el paquete de nuevo. Puedes necesitar varios intentos.\nPrueba a ejecutar RStudio en modo de administrador e intenta instalar los paquetes uno por uno.\nSi todo lo demás falla, instala el paquete en otra biblioteca o carpeta (por ejemplo, Temp) y luego copia manualmente la carpeta del paquete en la biblioteca deseada.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>R en redes locales</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html",
    "href": "new_pages/data_table.es.html",
    "title": "50  Data Table",
    "section": "",
    "text": "50.1 Introducción a data.table\nUna tabla de datos es una estructura de datos bidimensional como un dataframe que permite realizar operaciones de agrupación complejas. La sintaxis de data.table está estructurada de forma que se puedan realizar operaciones sobre filas, columnas y grupos.\nLa estructura es DT[i, j, by], separada por 3 partes; los argumentos i, j y by. El argumento i permite subconjuntar las filas necesarias, el argumento j permite operar sobre las columnas y el argumento by permite operar sobre las columnas por grupos.\nEn esta página se tratarán los siguientes temas:",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#intro-to-data-tables",
    "href": "new_pages/data_table.es.html#intro-to-data-tables",
    "title": "50  Data Table",
    "section": "",
    "text": "Importación de datos y uso de fread() y fwrite()\nSelección y filtrado de filas mediante el argumento i\nUso de las funciones de ayuda %like%, %chin%, %between%\nSelección y cálculo de columnas con el argumento j\nCálculo por grupos utilizando el argumento by\nAñadir y actualizar datos a las tablas de datos utilizando :=",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#load-packages-and-import-data",
    "href": "new_pages/data_table.es.html#load-packages-and-import-data",
    "title": "50  Data Table",
    "section": "50.2 Cargar paquetes e importar datos",
    "text": "50.2 Cargar paquetes e importar datos\n\nCargar paquetes\nUtilizando la función p_load() de pacman, cargamos (e instalamos si es necesario) los paquetes necesarios para este análisis.\n\npacman::p_load(\n  rio,        # para importar datos\n  data.table, # para agrupar y limpiar datos\n  tidyverse,  # permite el uso de la función pipe (%&gt;%) en este capítulo\n  here \n  ) \n\n\n\nImportar datos\nEsta página explorará algunas de las funciones principales de data.table utilizando la lista de casos referenciados a lo largo del manual.\nImportamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso a paso, consulta las instrucciones en la página [Descargar libro y datos]. Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos. A partir de aquí utilizamos data.table() para convertir el dataframe en una data.table.\n\nlinelist &lt;- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %&gt;% data.table()\n\nLa función fread() se utiliza para importar directamente archivos delimitados regulares, como los archivos .csv, directamente a un formato de tabla de datos. Esta función, y su homóloga, fwrite(), utilizada para escribir tablas de datos como archivos delimitados regulares, son opciones muy rápidas y eficientes desde el punto de vista computacional para bases de datos de gran tamaño.\nLas primeras 20 filas de linelist:\nLos comandos de R base, como dim(), que se utilizan para los dataframes, también pueden utilizarse para las tablas de datos\n\ndim(linelist) #gives the number of rows and columns in the data table\n\n[1] 5888   30",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#the-i-argument-selecting-and-filtering-rows",
    "href": "new_pages/data_table.es.html#the-i-argument-selecting-and-filtering-rows",
    "title": "50  Data Table",
    "section": "50.3 El argumento i: seleccionar y filtrar filas",
    "text": "50.3 El argumento i: seleccionar y filtrar filas\nRecordando la estructura **DT*[i, j, by], podemos filtrar filas utilizando números de fila o expresiones lógicas. El argumento i es el primero; por tanto, se puede utilizar la sintaxis DT[i] o DT[i,]**.\nEl primer ejemplo muestra las 5 primeras filas de la tabla de datos, el segundo ejemplo los casos de 18 años o más, y el tercer ejemplo los casos de 18 años o más pero no diagnosticados en el Central Hospital:\n\nlinelist[1:5] # devuelve de la 1ª a la 5ª fila\nlinelist[age &gt;= 18] # subconjunto de casos iguales o mayores de 18 años\nlinelist[age &gt;= 18 & hospital != \"Central Hospital\"] # subconjunto de casos iguales o mayores de 18 años pero no diagnosticados en el Hospital Central\n\nEl uso de .N en el argumento i representa el número total de filas en la tabla de datos. Esto se puede utilizar para subconjuntar los números de las filas:\n\nlinelist[.N] # devuelve la última fila\nlinelist[15:.N] # devuelve de la 15ª a la última fila\n\n\nUso de funciones de ayuda para el filtrado\nData table utiliza funciones de ayuda que facilitan el subconjunto de filas. La función %like% se utiliza para coincidir con un patrón en una columna, %chin% se utiliza para coincidir con un carácter específico, y la función de ayuda %between% se utiliza para coincidir con columnas numéricas dentro de un rango preestablecido.\nEn los siguientes ejemplos: * filtramos las filas en las que la variable hospital contiene “Hospital” * filtramos las filas en las que el resultado es “Recover” o “Death” * filtramos las filas en el rango de edad 40-60\n\nlinelist[hospital %like% \"Hospital\"] # filtrar filas donde la variable hospital contiene \"Hospital\"\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] # filtra las filas en las que el resultado es \"Recuperación\" o \" Fallecimiento\"\nlinelist[age %between% c(40, 60)] # filtra las filas en el rango de edad 40-60\n\n# %between% debe tomar un vector de longitud 2, mientras que %chin% puede tomar vectores de longitud &gt;= 1",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#the-j-argument-selecting-and-computing-on-columns",
    "href": "new_pages/data_table.es.html#the-j-argument-selecting-and-computing-on-columns",
    "title": "50  Data Table",
    "section": "50.4 El argumento j: seleccionar y calcular en columnas",
    "text": "50.4 El argumento j: seleccionar y calcular en columnas\nUtilizando la estructura DT[i, j, by], podemos seleccionar columnas utilizando números o nombres. El argumento j es el segundo; por lo tanto, se utiliza la sintaxis DT[, j]. Para facilitar los cálculos sobre el argumento j, la columna se envuelve utilizando list() o .().\n\nSelección de columnas\nEl primer ejemplo recupera la primera, tercera y quinta columnas de la tabla de datos, el segundo ejemplo selecciona todas las columnas excepto las de altura, peso y sexo. El tercer ejemplo utiliza la envoltura .() para seleccionar las columnas case_id y outcome.\n\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] works just as well\n\n\n\nCálculo en columnas\nCombinando los argumentos i y j es posible filtrar filas y calcular en sus columnas. El uso de .N en el argumento j también representa el número total de filas en la tabla de datos y puede ser útil para devolver el número de filas después del filtrado de filas.\nEn los siguientes ejemplos: * Contar el número de casos que permanecieron más de 7 días en el hospital * Calcular la edad media de los casos que murieron en el hospital militar * Calcular la desviación estándar, la mediana, la edad media de los casos que se recuperaron en el central hospital\n\nlinelist[days_onset_hosp &gt; 7 , .N]\n\n[1] 189\n\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] # na.rm = T elimina valores N/A\n\n        V1\n     &lt;num&gt;\n1: 15.9084\n\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] # esta sintaxis no utiliza las funciones de ayuda, pero funciona igual de bien\n\n   mean_age median_age   sd_age\n      &lt;num&gt;      &lt;num&gt;    &lt;num&gt;\n1: 16.85185         14 12.93857\n\n\nRecuerda que el uso de .() en el argumento j facilita el cálculo, devuelve una tabla de datos y permite nombrar las columnas.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#the-by-argument-computing-by-groups",
    "href": "new_pages/data_table.es.html#the-by-argument-computing-by-groups",
    "title": "50  Data Table",
    "section": "50.5 El argumento by: cálculo por grupos",
    "text": "50.5 El argumento by: cálculo por grupos\nEl argumento by es el tercer argumento de la estructura DT[i, j, by]. El argumento by acepta tanto un vector de caracteres como la sintaxis list() o .(). El uso de la sintaxis .() en el argumento by permite renombrar las columnas sobre la marcha.\nEn los siguientes ejemplos: * agrupamos el número de casos por hospital * en los casos de 18 años o más, calculamos la media de altura y peso de los casos según el sexo y si se recuperaron o murieron * en los ingresos que duraron más de 7 días, contamos el número de casos según el mes en que ingresaron y el hospital en el que lo hicieron\n\nlinelist[, .N, .(hospital)] # número de casos por hospital\n\n                               hospital     N\n                                 &lt;char&gt; &lt;int&gt;\n1:                                Other   885\n2:                              Missing  1469\n3: St. Mark's Maternity Hospital (SMMH)   422\n4:                        Port Hospital  1762\n5:                    Military Hospital   896\n6:                     Central Hospital   454\n\nlinelist[age &gt; 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] # NAs representan las categorías en las que faltan datos\n\n   gender outcome  mean_wt  mean_ht\n   &lt;char&gt;  &lt;char&gt;    &lt;num&gt;    &lt;num&gt;\n1:      m Recover 71.90227 178.1977\n2:      f   Death 63.27273 159.9448\n3:      m   Death 71.61770 175.4726\n4:      f    &lt;NA&gt; 64.49375 162.7875\n5:      m    &lt;NA&gt; 72.65505 176.9686\n6:      f Recover 62.86498 159.2996\n7:   &lt;NA&gt; Recover 67.21429 175.2143\n8:   &lt;NA&gt;   Death 69.16667 170.7917\n9:   &lt;NA&gt;    &lt;NA&gt; 70.25000 175.5000\n\nlinelist[days_onset_hosp &gt; 7, .N, .(month = month(date_hospitalisation), hospital)]\n\n    month                             hospital     N\n    &lt;num&gt;                               &lt;char&gt; &lt;int&gt;\n 1:     5                    Military Hospital     3\n 2:     6                        Port Hospital     4\n 3:     7                        Port Hospital     8\n 4:     8 St. Mark's Maternity Hospital (SMMH)     5\n 5:     8                    Military Hospital     9\n 6:     8                                Other    10\n 7:     8                        Port Hospital    10\n 8:     9                        Port Hospital    28\n 9:     9                              Missing    27\n10:     9                     Central Hospital    10\n11:     9 St. Mark's Maternity Hospital (SMMH)     6\n12:    10                              Missing     2\n13:    10                    Military Hospital     3\n14:     3                        Port Hospital     1\n15:     4                    Military Hospital     1\n16:     5                                Other     2\n17:     5                     Central Hospital     1\n18:     5                              Missing     1\n19:     6                              Missing     7\n20:     6 St. Mark's Maternity Hospital (SMMH)     2\n21:     6                    Military Hospital     1\n22:     7                    Military Hospital     3\n23:     7                                Other     1\n24:     7                              Missing     2\n25:     7 St. Mark's Maternity Hospital (SMMH)     1\n26:     8                     Central Hospital     2\n27:     8                              Missing     6\n28:     9                                Other     9\n29:     9                    Military Hospital    11\n30:    10                        Port Hospital     3\n31:    10                                Other     4\n32:    10 St. Mark's Maternity Hospital (SMMH)     1\n33:    10                     Central Hospital     1\n34:    11                              Missing     2\n35:    11                        Port Hospital     1\n36:    12                        Port Hospital     1\n    month                             hospital     N\n\n\nData.table también permite encadenar expresiones de la siguiente manera:\n\nlinelist[, .N, .(hospital)][order(-N)][1:3] # El 1º selecciona todos los casos por hospital, el 2º ordena los casos en orden descendente, el 3º incluye los 3 hospitales con mayor número de casos.\n\n            hospital     N\n              &lt;char&gt; &lt;int&gt;\n1:     Port Hospital  1762\n2:           Missing  1469\n3: Military Hospital   896\n\n\nEn estos ejemplos estamos siguiendo la suposición de que una fila en la tabla de datos es igual a un nuevo caso, y por lo tanto podemos utilizar el .N para representar el número de filas en la tabla de datos. Otra función útil para representar el número de casos únicos es uniqueN(), que devuelve el número de valores únicos en una entrada dada. Esto se ilustra aquí:\n\nlinelist[, .(uniqueN(gender))] # recuerda que .() en el argumento j devuelve una tabla de datos\n\n      V1\n   &lt;int&gt;\n1:     3\n\n\nLa respuesta es 3, ya que los valores únicos de la columna de género son m, f y N/A. Compárelo con la función R base unique(), que devuelve todos los valores únicos en una entrada dada:\n\nlinelist[, .(unique(gender))]\n\n       V1\n   &lt;char&gt;\n1:      m\n2:      f\n3:   &lt;NA&gt;\n\n\nPara hallar el número de casos únicos en un mes determinado escribiríamos lo siguiente:\n\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]\n\n    month    V1\n    &lt;num&gt; &lt;int&gt;\n 1:     5    62\n 2:     6   100\n 3:     7   198\n 4:     8   509\n 5:     9  1170\n 6:    10  1228\n 7:    11   813\n 8:    12   576\n 9:     1   434\n10:     2   310\n11:     3   290\n12:     4   198",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#adding-and-updating-to-data-tables",
    "href": "new_pages/data_table.es.html#adding-and-updating-to-data-tables",
    "title": "50  Data Table",
    "section": "50.6 Añadir y actualizar a las tablas de datos",
    "text": "50.6 Añadir y actualizar a las tablas de datos\nEl operador := se utiliza para añadir o actualizar datos en una tabla de datos. La adición de columnas a la tabla de datos puede hacerse de las siguientes maneras:\n\nlinelist[, adult := age &gt;= 18] # añade una columna\nlinelist[, c(\"child\", \"wt_lbs\") := .(age &lt; 18, wt_kg*2.204)] # para añadir múltiples columnas se requiere c(\"\") y la sintaxis list() o .()\nlinelist[, `:=` (bmi_in_range = (bmi &gt; 16 & bmi &lt; 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] # este método utiliza := como operador\nlinelist[, adult := NULL] # elimina la columna\n\nLas agregaciones más complejas están fuera del alcance de este capítulo introductorio, pero la idea es proporcionar una alternativa popular y viable a dplyr para agrupar y limpiar datos. El paquete data.table es un gran paquete que permite un código ordenado y legible.",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  },
  {
    "objectID": "new_pages/data_table.es.html#resources-41",
    "href": "new_pages/data_table.es.html#resources-41",
    "title": "50  Data Table",
    "section": "50.7 Recursos",
    "text": "50.7 Recursos\nA continuación, algunos recursos útiles para obtener más información:\n\nhttps://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\nhttps://github.com/Rdatatable/data.table\nhttps://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf\nhttps://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/\nhttps://www.datacamp.com/community/tutorials/data-table-r-tutorial\n\nPuedes realizar cualquier función de resumen sobre datos agrupados; consulta la hoja de trucos aquí para obtener más información:",
    "crumbs": [
      "Miscelánea",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Data Table</span>"
    ]
  }
]