[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"index.html","id":"r-for-applied-epidemiology-and-public-health","chapter":"","heading":"R for applied epidemiology and public health","text":"Usage: handbook used 1 million times 450,000 people around world.Objective: Serve quick R code reference manual (online offline) task-centered examples address common epidemiological problems.just starting R? Try free interactive tutorials synchronous, virtual intro course used US CDC, , 75+ health agencies Field Epi Training Programs worldwide.Languages: French (Français), Spanish (Español), Vietnamese (Tiếng Việt), Japanese (日本), Turkish (Türkçe)Written epidemiologists, epidemiologists \nApplied Epi nonprofit organisation grassroots movement frontline epis around world. write spare time offer resource community. encouragement feedback welcome:Visit website join contact listcontact@appliedepi.org, tweet @appliedepi, LinkedInSubmit issues Github repositoryWe offer live R training instructors decades applied epidemiology experience - email us discuss.","code":""},{"path":"index.html","id":"how-to-use-this-handbook","chapter":"","heading":"How to use this handbook","text":"Browse pages Table Contents, use search boxClick “copy” icons copy codeYou can follow-along example dataOffline versionSee instructions Download handbook data page.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"","heading":"Acknowledgements","text":"handbook produced independent collaboration epidemiologists around world drawing upon experience organizations including local, state, provincial, national health agencies, World Health Organization (), Doctors without Borders (MSF), hospital systems, academic institutions.handbook approved product specific organization. Although strive accuracy, provide guarantee content book.","code":""},{"path":"index.html","id":"contributors","chapter":"","heading":"Contributors","text":"Editor: Neale BatraAuthors: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen LinReviewers supporters: Pat Keating, Amrish Baidjoe, Annick Lenglet, Margot Charette, Danielly Xavier, Marie-Amélie Degail Chabrat, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao MuiangaIllustrations: Calder Fong","code":""},{"path":"index.html","id":"funding-and-support","chapter":"","heading":"Funding and support","text":"book primarily volunteer effort took thousands hours create.handbook received supportive funding via COVID-19 emergency capacity-building grant TEPHINET, global network Field Epidemiology Training Programs (FETPs).Administrative support provided EPIET Alumni Network (EAN), special thanks Annika Wendland. EPIET European Programme Intervention Epidemiology Training.Special thanks Médecins Sans Frontières (MSF) Operational Centre Amsterdam (OCA) support development handbook.publication supported Cooperative Agreement number NU2GGH001873, funded Centers Disease Control Prevention TEPHINET, program Task Force Global Health. contents solely responsibility authors necessarily represent official views Centers Disease Control Prevention, Department Health Human Services, Task Force Global Health, Inc. TEPHINET.","code":""},{"path":"index.html","id":"inspiration","chapter":"","heading":"Inspiration","text":"multitude tutorials vignettes provided knowledge development handbook content credited within respective pages.generally, following sources provided inspiration handbook:“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify hosts website","code":""},{"path":"index.html","id":"terms-of-use-and-contribution","chapter":"","heading":"Terms of Use and Contribution","text":"","code":""},{"path":"index.html","id":"license","chapter":"","heading":"License","text":" Applied Epi Incorporated, 2021 work licensed Applied Epi Incorporated Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.Academic courses epidemiologist training programs welcome contact us use adaptation material (email contact@appliedepi.org).","code":""},{"path":"index.html","id":"citation","chapter":"","heading":"Citation","text":"Batra, Neale, et al. Epidemiologist R Handbook. 2021. ","code":""},{"path":"index.html","id":"contribution","chapter":"","heading":"Contribution","text":"like make content contribution, please contact us first via Github issues email. implementing schedule updates creating contributor guide.Please note epiRhandbook project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"editorial-and-technical-notes.html","id":"editorial-and-technical-notes","chapter":"1 Editorial and technical notes","heading":"1 Editorial and technical notes","text":"page describe philosophical approach, style, specific editorial decisions made creation handbook.","code":""},{"path":"editorial-and-technical-notes.html","id":"approach-and-style","chapter":"1 Editorial and technical notes","heading":"1.1 Approach and style","text":"potential audience book large. surely used people new R, also experienced R users looking best practices tips. must accessible succinct. Therefore, approach provide just enough text explanation someone new R can apply code follow code .points:code reference book accompanied relatively brief examples - thorough textbook R data scienceThis R handbook use within applied epidemiology - manual methods science applied epidemiologyThis intended living document - optimal R packages given task change often welcome discussion emphasize handbook","code":""},{"path":"editorial-and-technical-notes.html","id":"r-packages","chapter":"1 Editorial and technical notes","heading":"R packages","text":"many choicesOne challenging aspects learning R knowing R package use given task. common occurrence struggle task later realize - hey, ’s R package one command line!handbook, try offer least two ways complete task: one tried--true method (probably base R tidyverse) one special R package custom-built purpose. want couple options case can’t download given package otherwise work .choosing packages use, prioritized R packages approaches tested vetted community, minimize number packages used typical work session, stable (changing often), accomplish task simply cleanlyThis handbook generally prioritizes R packages functions tidyverse. Tidyverse collection R packages designed data science share underlying grammar data structures. tidyverse packages can installed loaded via tidyverse package. Read tidyverse website.applicable, also offer code options using base R - packages functions come R installation. recognize book’s audience may reliable internet download extra packages.Linking functions packages explicitlyIt often frustrating R tutorials function shown code, don’t know package ! try avoid situation.narrative text, package names written bold (e.g. dplyr) functions written like : mutate(). strive explicit package function comes , either referencing package nearby text specifying package explicitly code like : dplyr::mutate(). may look redundant, purpose.See page R basics learn packages functions.","code":""},{"path":"editorial-and-technical-notes.html","id":"code-style","chapter":"1 Editorial and technical notes","heading":"Code style","text":"handbook, frequently utilize “new lines”, making code appear “long”. reasons:can write explanatory comments # adjacent little part codeGenerally, longer (vertical) code easier readIt easier read narrow screen (sideways scrolling needed)indentations, can easier know arguments belong functionAs result, code written like :…written like :R code generally affected new lines indentations. writing code, initiate new line comma apply automatic indentation patterns.also use lots spaces (e.g. n = 1 instead n=1) easier read. kind people reading code!","code":"\nlinelist %>% \n  group_by(hospital) %>%  # group rows by hospital\n  slice_max(date, n = 1, with_ties = F) # if there's a tie (of date), take the first row\nlinelist %>% \n  group_by(hospital) %>% # group rows by hospital\n  slice_max(\n    date,                # keep row per group with maximum date value \n    n = 1,               # keep only the single highest row \n    with_ties = F)       # if there's a tie (of date), take the first row"},{"path":"editorial-and-technical-notes.html","id":"nomenclature","chapter":"1 Editorial and technical notes","heading":"Nomenclature","text":"handbook, generally reference “columns” “rows” instead “variables” “observations”. explained primer “tidy data”, epidemiological statistical datasets consist structurally rows, columns, values.Variables contain values measure underlying attribute (like age group, outcome, date onset). Observations contain values measured unit (e.g. person, site, lab sample). aspects can difficult tangibly define.“tidy” datasets, column variable, row observation, cell single value. However datasets encounter fit mold - “wide” format dataset may variable split across several columns (see example Pivoting data page). Likewise, observations split across several rows.handbook managing transforming data, referring concrete data structures rows columns relevant abstract observations variables. Exceptions occur primarily pages data analysis, see references variables observations.","code":""},{"path":"editorial-and-technical-notes.html","id":"notes","chapter":"1 Editorial and technical notes","heading":"Notes","text":"types notes may encounter handbook:NOTE: noteTIP: tip.CAUTION: cautionary note.DANGER: warning.","code":""},{"path":"editorial-and-technical-notes.html","id":"editorial-decisions","chapter":"1 Editorial and technical notes","heading":"1.2 Editorial decisions","text":", track significant editorial decisions around package function choice. disagree want offer new tool consideration, please join/start conversation Github page.Table package, function, editorial decisions","code":""},{"path":"editorial-and-technical-notes.html","id":"major-revisions","chapter":"1 Editorial and technical notes","heading":"1.3 Major revisions","text":"NEWS\nversion 1.0.1 following changes implemented:Update R version 4.2Data cleaning: switched {linelist} {matchmaker}, removed unnecessary line case_when() exampleDates: switched {linelist} guess_date() {parsedate} parse_date()Pivoting: slight update pivot_wider() id_cols=Survey analysis: switched plot_age_pyramid() age_pyramid(), slight change alluvial plot codeHeat plots: added ungroup() agg_weeks chunkInteractive plots: added ungroup() chunk makes agg_weeks expand() works intendedTime series: added data.frame() around objects within trending::fit() predict() commandsCombinations analysis: Switch case_when() ifelse() added optional across() code preparing dataTransmission chains: Update recent version {epicontacts}","code":""},{"path":"editorial-and-technical-notes.html","id":"session-info-r-rstudio-packages","chapter":"1 Editorial and technical notes","heading":"1.4 Session info (R, RStudio, packages)","text":"information versions R, RStudio, R packages used rendering Handbook.","code":"\nsessioninfo::session_info()## ─ Session info ──────────────────────────────────────────────────────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.3.0 (2023-04-21 ucrt)\n##  os       Windows 11 x64 (build 22621)\n##  system   x86_64, mingw32\n##  ui       RStudio\n##  language (EN)\n##  collate  English_United States.utf8\n##  ctype    English_United States.utf8\n##  tz       Europe/Berlin\n##  date     2023-07-18\n##  rstudio  2023.06.1+524 Mountain Hydrangea (desktop)\n##  pandoc   3.1.1 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n## \n## ─ Packages ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n##  ! package              * version    date (UTC) lib source\n##    abind                * 1.4-5      2016-07-21 [1] CRAN (R 4.3.0)\n##    ada                    2.0-5      2016-05-13 [1] CRAN (R 4.3.0)\n##    adagio                 0.8.5      2022-10-03 [1] CRAN (R 4.3.0)\n##    ade4                   1.7-22     2023-02-06 [1] CRAN (R 4.3.0)\n##    anytime                0.3.9      2020-08-27 [1] CRAN (R 4.3.0)\n##    ape                  * 5.7-1      2023-03-13 [1] CRAN (R 4.3.0)\n##    aplot                  0.1.10     2023-03-08 [1] CRAN (R 4.3.0)\n##    apyramid             * 0.1.3      2023-02-14 [1] CRAN (R 4.3.0)\n##    arm                    1.13-1     2022-08-28 [1] CRAN (R 4.3.0)\n##    askpass                1.1        2019-01-13 [1] CRAN (R 4.3.0)\n##    assertive.base         0.0-9      2021-02-08 [1] CRAN (R 4.3.0)\n##    assertive.properties   0.0-5      2022-04-21 [1] CRAN (R 4.3.0)\n##    assertive.types        0.0-3      2016-12-30 [1] CRAN (R 4.3.0)\n##    assertthat             0.2.1      2019-03-21 [1] CRAN (R 4.3.0)\n##    aweek                * 1.0.3      2022-10-06 [1] CRAN (R 4.3.0)\n##    backports              1.4.1      2021-12-13 [1] CRAN (R 4.3.0)\n##    base64enc              0.1-3      2015-07-28 [1] CRAN (R 4.3.0)\n##    bayestestR           * 0.13.1     2023-04-07 [1] CRAN (R 4.3.0)\n##    bit                  * 4.0.5      2022-11-15 [1] CRAN (R 4.3.0)\n##    bit64                  4.0.5      2020-08-30 [1] CRAN (R 4.3.0)\n##    blob                   1.2.4      2023-03-17 [1] CRAN (R 4.3.0)\n##    bookdown               0.34       2023-05-09 [1] CRAN (R 4.3.1)\n##    boot                 * 1.3-28.1   2022-11-22 [2] CRAN (R 4.3.0)\n##    broom                * 1.0.4      2023-03-11 [1] CRAN (R 4.3.0)\n##    broom.helpers          1.13.0     2023-03-28 [1] CRAN (R 4.3.0)\n##    bslib                  0.5.0      2023-06-09 [1] CRAN (R 4.3.1)\n##    cachem                 1.0.8      2023-05-01 [1] CRAN (R 4.3.0)\n##    callr                  3.7.3      2022-11-02 [1] CRAN (R 4.3.0)\n##    car                    3.1-2      2023-03-30 [1] CRAN (R 4.3.0)\n##    carData                3.0-5      2022-01-06 [1] CRAN (R 4.3.0)\n##    cellranger             1.1.0      2016-07-27 [1] CRAN (R 4.3.0)\n##    ciTools                0.6.1      2020-10-25 [1] CRAN (R 4.3.0)\n##    class                  7.3-21     2023-01-23 [2] CRAN (R 4.3.0)\n##    classInt               0.4-9      2023-02-28 [1] CRAN (R 4.3.0)\n##    cli                    3.6.1      2023-03-23 [1] CRAN (R 4.3.0)\n##    clipr                  0.8.0      2022-02-22 [1] CRAN (R 4.3.0)\n##    cmprsk                 2.2-11     2022-01-06 [1] CRAN (R 4.3.0)\n##    coarseDataTools        0.6-6      2021-12-09 [1] CRAN (R 4.3.0)\n##    coda                   0.19-4     2020-09-30 [1] CRAN (R 4.3.0)\n##    codetools              0.2-19     2023-02-01 [2] CRAN (R 4.3.0)\n##    colorspace             2.1-0      2023-01-23 [1] CRAN (R 4.3.0)\n##    commonmark             1.9.0      2023-03-17 [1] CRAN (R 4.3.0)\n##    correlation          * 0.8.4      2023-04-06 [1] CRAN (R 4.3.0)\n##    corrr                * 0.4.4      2022-08-16 [1] CRAN (R 4.3.0)\n##    cowplot              * 1.1.1      2020-12-30 [1] CRAN (R 4.3.0)\n##    crayon                 1.5.2      2022-09-29 [1] CRAN (R 4.3.0)\n##    crosstalk              1.2.0      2021-11-04 [1] CRAN (R 4.3.0)\n##    crul                   1.4.0      2023-05-17 [1] CRAN (R 4.3.0)\n##    curl                   5.0.0      2023-01-12 [1] CRAN (R 4.3.0)\n##    data.table           * 1.14.8     2023-02-17 [1] CRAN (R 4.3.0)\n##    datawizard           * 0.7.1      2023-04-03 [1] CRAN (R 4.3.0)\n##    DBI                  * 1.1.3      2022-06-18 [1] CRAN (R 4.3.0)\n##    deldir                 1.0-9      2023-05-17 [1] CRAN (R 4.3.0)\n##    Deriv                  4.1.3      2021-02-24 [1] CRAN (R 4.3.0)\n##    DiagrammeR           * 1.0.10     2023-05-18 [1] CRAN (R 4.3.0)\n##    dichromat              2.0-0.1    2022-05-02 [1] CRAN (R 4.3.0)\n##    digest                 0.6.31     2022-12-11 [1] CRAN (R 4.3.0)\n##    distcrete            * 1.0.3      2017-11-23 [1] CRAN (R 4.3.0)\n##    distributional         0.3.2      2023-03-22 [1] CRAN (R 4.3.0)\n##    doBy                 * 4.6.16     2023-01-18 [1] CRAN (R 4.3.0)\n##    doParallel             1.0.17     2022-02-07 [1] CRAN (R 4.3.0)\n##    downlit                0.4.2      2022-07-05 [1] CRAN (R 4.3.0)\n##    dplyr                * 1.1.2      2023-04-20 [1] CRAN (R 4.3.0)\n##    dsr                  * 0.2.2      2019-08-23 [1] CRAN (R 4.3.0)\n##    DT                   * 0.28       2023-05-18 [1] CRAN (R 4.3.0)\n##    e1071                  1.7-13     2023-02-01 [1] CRAN (R 4.3.0)\n##    easystats            * 0.6.0      2022-11-29 [1] CRAN (R 4.3.0)\n##    ecmwfr               * 1.5.0      2023-01-19 [1] CRAN (R 4.3.0)\n##    effectsize           * 0.8.3      2023-01-28 [1] CRAN (R 4.3.0)\n##    ellipsis               0.3.2      2021-04-29 [1] CRAN (R 4.3.0)\n##    Epi                  * 2.47.1     2023-04-25 [1] CRAN (R 4.3.0)\n##    epicontacts          * 1.2.0      2023-05-21 [1] Github (reconhub/epicontacts@7df53e5)\n##    epidict                0.0.0.9001 2023-05-21 [1] Github (R4EPI/epidict@9cf5a53)\n##    EpiEstim             * 2.2-4      2021-01-07 [1] CRAN (R 4.3.0)\n##    epikit               * 0.1.5      2023-02-15 [1] CRAN (R 4.3.0)\n##    EpiNow2              * 1.3.5      2023-04-27 [1] CRAN (R 4.3.0)\n##    epitabulate            0.0.0.9007 2023-05-21 [1] Github (R4EPI/epitabulate@56370b8)\n##    epitrix              * 0.4.0      2023-01-13 [1] CRAN (R 4.3.0)\n##    etm                    1.1.1      2020-09-08 [1] CRAN (R 4.3.0)\n##    evaluate               0.21       2023-05-05 [1] CRAN (R 4.3.0)\n##    evd                    2.3-6.1    2022-07-04 [1] CRAN (R 4.3.0)\n##    fabletools           * 0.3.3      2023-04-04 [1] CRAN (R 4.3.0)\n##    FactoClass             1.2.7      2018-10-01 [1] CRAN (R 4.3.0)\n##    fansi                  1.0.4      2023-01-22 [1] CRAN (R 4.3.0)\n##    farver                 2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n##    fastLink             * 0.6.0      2020-04-29 [1] CRAN (R 4.3.0)\n##    fastmap                1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n##    feasts               * 0.3.1      2023-03-22 [1] CRAN (R 4.3.0)\n##    ff                   * 4.0.9      2023-01-25 [1] CRAN (R 4.3.0)\n##    fitdistrplus           1.1-11     2023-04-25 [1] CRAN (R 4.3.0)\n##    flexdashboard        * 0.6.1      2023-01-23 [1] CRAN (R 4.3.0)\n##    flextable            * 0.9.1      2023-04-02 [1] CRAN (R 4.3.0)\n##    fontBitstreamVera      0.1.1      2017-02-01 [1] CRAN (R 4.3.0)\n##    fontLiberation         0.1.0      2016-10-15 [1] CRAN (R 4.3.0)\n##    fontquiver             0.2.1      2017-02-01 [1] CRAN (R 4.3.0)\n##    forcats              * 1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n##    foreach                1.5.2      2022-02-02 [1] CRAN (R 4.3.0)\n##    forecast             * 8.21       2023-02-27 [1] CRAN (R 4.3.0)\n##    foreign                0.8-84     2022-12-06 [2] CRAN (R 4.3.0)\n##    formatR                1.14       2023-01-17 [1] CRAN (R 4.3.0)\n##    formattable          * 0.2.1      2021-01-07 [1] CRAN (R 4.3.0)\n##    Formula              * 1.2-5      2023-02-24 [1] CRAN (R 4.3.0)\n##    fracdiff               1.5-2      2022-10-31 [1] CRAN (R 4.3.0)\n##    frailtypack          * 3.5.0      2021-12-20 [1] CRAN (R 4.3.0)\n##    fs                   * 1.6.2      2023-04-25 [1] CRAN (R 4.3.0)\n##    futile.logger          1.4.3      2016-07-10 [1] CRAN (R 4.3.0)\n##    futile.options         1.0.1      2018-04-20 [1] CRAN (R 4.3.0)\n##    future                 1.32.0     2023-03-07 [1] CRAN (R 4.3.0)\n##    future.apply           1.11.0     2023-05-21 [1] CRAN (R 4.3.0)\n##    gdtools                0.3.3      2023-03-27 [1] CRAN (R 4.3.0)\n##    generics               0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n##    gfonts                 0.2.0      2023-01-08 [1] CRAN (R 4.3.0)\n##    ggExtra              * 0.10.0     2022-03-23 [1] CRAN (R 4.3.0)\n##    ggforce              * 0.4.1      2022-10-04 [1] CRAN (R 4.3.0)\n##    ggfun                  0.0.9      2022-11-21 [1] CRAN (R 4.3.0)\n##    gghighlight          * 0.4.0      2022-10-16 [1] CRAN (R 4.3.0)\n##    ggnewscale           * 0.4.8      2022-10-06 [1] CRAN (R 4.3.0)\n##    ggplot2              * 3.4.2      2023-04-03 [1] CRAN (R 4.3.0)\n##    ggplotify              0.1.0      2021-09-02 [1] CRAN (R 4.3.0)\n##    ggpubr               * 0.6.0      2023-02-10 [1] CRAN (R 4.3.0)\n##    ggrepel              * 0.9.3      2023-02-03 [1] CRAN (R 4.3.0)\n##    ggsignif               0.6.4      2022-10-13 [1] CRAN (R 4.3.0)\n##    ggtext                 0.1.2      2022-09-16 [1] CRAN (R 4.3.0)\n##    ggtree               * 3.8.0      2023-04-25 [1] Bioconductor\n##    ggupset              * 0.3.0      2020-05-05 [1] CRAN (R 4.3.0)\n##    globals                0.16.2     2022-11-21 [1] CRAN (R 4.3.0)\n##    glue                   1.6.2      2022-02-24 [1] CRAN (R 4.3.0)\n##    grates               * 1.0.1      2023-04-02 [1] CRAN (R 4.3.0)\n##    gridExtra              2.3        2017-09-09 [1] CRAN (R 4.3.0)\n##    gridGraphics           0.5-1      2020-12-13 [1] CRAN (R 4.3.0)\n##    gridtext               0.1.5      2022-09-16 [1] CRAN (R 4.3.0)\n##    gt                     0.9.0      2023-03-31 [1] CRAN (R 4.3.0)\n##    gtable                 0.3.3      2023-03-21 [1] CRAN (R 4.3.0)\n##    gtools                 3.9.4      2022-11-27 [1] CRAN (R 4.3.0)\n##    gtsummary            * 1.7.1      2023-04-27 [1] CRAN (R 4.3.0)\n##    haven                  2.5.2      2023-02-28 [1] CRAN (R 4.3.0)\n##    here                 * 1.0.1      2020-12-13 [1] CRAN (R 4.3.0)\n##    highcharter          * 0.9.4      2022-01-03 [1] CRAN (R 4.3.0)\n##    highr                  0.10       2022-12-22 [1] CRAN (R 4.3.0)\n##    hms                    1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n##    htmltools              0.5.5      2023-03-23 [1] CRAN (R 4.3.0)\n##    htmlwidgets            1.6.2      2023-03-17 [1] CRAN (R 4.3.0)\n##    httpcode               0.3.0      2020-04-10 [1] CRAN (R 4.3.0)\n##    httpuv                 1.6.11     2023-05-11 [1] CRAN (R 4.3.0)\n##    httr                   1.4.6      2023-05-08 [1] CRAN (R 4.3.0)\n##    i2extras             * 0.2.1      2023-03-17 [1] CRAN (R 4.3.0)\n##    igraph                 1.4.2      2023-04-07 [1] CRAN (R 4.3.0)\n##    imputeTS             * 3.3        2022-09-09 [1] CRAN (R 4.3.0)\n##    incidence              1.7.3      2020-11-04 [1] CRAN (R 4.3.0)\n##    incidence2           * 2.0.0      2023-03-17 [1] CRAN (R 4.3.0)\n##    inline                 0.3.19     2021-05-31 [1] CRAN (R 4.3.0)\n##    insight              * 0.19.1     2023-03-18 [1] CRAN (R 4.3.0)\n##    ipred                  0.9-14     2023-03-09 [1] CRAN (R 4.3.0)\n##    isoband                0.2.7      2022-12-20 [1] CRAN (R 4.3.0)\n##    iterators              1.0.14     2022-02-05 [1] CRAN (R 4.3.0)\n##    janitor              * 2.2.0      2023-02-02 [1] CRAN (R 4.3.0)\n##    jpeg                   0.1-10     2022-11-29 [1] CRAN (R 4.3.0)\n##    jquerylib              0.1.4      2021-04-26 [1] CRAN (R 4.3.0)\n##    jsonlite               1.8.4      2022-12-06 [1] CRAN (R 4.3.0)\n##    kableExtra           * 1.3.4      2021-02-20 [1] CRAN (R 4.3.0)\n##    KernSmooth             2.23-20    2021-05-03 [2] CRAN (R 4.3.0)\n##    km.ci                  0.5-6      2022-04-06 [1] CRAN (R 4.3.0)\n##    KMsurv                 0.1-5      2012-12-03 [1] CRAN (R 4.3.0)\n##    knitr                  1.42       2023-01-25 [1] CRAN (R 4.3.0)\n##    labeling               0.4.2      2020-10-20 [1] CRAN (R 4.3.0)\n##    labelled               2.11.0     2023-04-11 [1] CRAN (R 4.3.0)\n##    lambda.r               1.2.4      2019-09-18 [1] CRAN (R 4.3.0)\n##    later                  1.3.1      2023-05-02 [1] CRAN (R 4.3.0)\n##    lattice                0.21-8     2023-04-05 [2] CRAN (R 4.3.0)\n##    lava                   1.7.2.1    2023-02-27 [1] CRAN (R 4.3.0)\n##    lazyeval               0.2.2      2019-03-15 [1] CRAN (R 4.3.0)\n##    leafem                 0.2.0      2022-04-16 [1] CRAN (R 4.3.0)\n##    leaflet                2.1.2      2023-03-10 [1] CRAN (R 4.3.0)\n##    leaflet.providers      1.9.0      2019-11-09 [1] CRAN (R 4.3.0)\n##    leafsync               0.1.0      2019-03-05 [1] CRAN (R 4.3.0)\n##    lifecycle              1.0.3      2022-10-07 [1] CRAN (R 4.3.0)\n##    listenv                0.9.0      2022-12-16 [1] CRAN (R 4.3.0)\n##    lme4                   1.1-33     2023-04-25 [1] CRAN (R 4.3.0)\n##    lmtest               * 0.9-40     2022-03-21 [1] CRAN (R 4.3.0)\n##    loo                    2.6.0      2023-03-31 [1] CRAN (R 4.3.0)\n##    lpSolve                5.6.18     2023-02-01 [1] CRAN (R 4.3.0)\n##    lubridate            * 1.9.2      2023-02-10 [1] CRAN (R 4.3.0)\n##    lwgeom                 0.2-11     2023-01-14 [1] CRAN (R 4.3.0)\n##    magrittr             * 2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n##    markdown               1.7        2023-05-16 [1] CRAN (R 4.3.0)\n##    MASS                 * 7.3-58.4   2023-03-07 [2] CRAN (R 4.3.0)\n##    matchmaker           * 0.1.1      2020-02-21 [1] CRAN (R 4.3.0)\n##    Matrix               * 1.5-4      2023-04-04 [2] CRAN (R 4.3.0)\n##    MatrixModels           0.5-1      2022-09-11 [1] CRAN (R 4.3.0)\n##    matrixStats            0.63.0     2022-11-18 [1] CRAN (R 4.3.0)\n##    mcmc                   0.9-7      2020-03-21 [1] CRAN (R 4.3.0)\n##    MCMCpack               1.6-3      2022-04-13 [1] CRAN (R 4.3.0)\n##    memoise                2.0.1      2021-11-26 [1] CRAN (R 4.3.0)\n##    mgcv                   1.8-42     2023-03-02 [2] CRAN (R 4.3.0)\n##    mice                 * 3.15.0     2022-11-19 [1] CRAN (R 4.3.0)\n##    microbenchmark         1.4.10     2023-04-28 [1] CRAN (R 4.3.0)\n##    mime                   0.12       2021-09-28 [1] CRAN (R 4.3.0)\n##    miniUI                 0.1.1.1    2018-05-18 [1] CRAN (R 4.3.0)\n##    minqa                  1.2.5      2022-10-19 [1] CRAN (R 4.3.0)\n##    mitools                2.4        2019-04-26 [1] CRAN (R 4.3.0)\n##    modelbased           * 0.8.6      2023-01-13 [1] CRAN (R 4.3.0)\n##    munsell                0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n##    naniar               * 1.0.0      2023-02-02 [1] CRAN (R 4.3.0)\n##    networkD3            * 0.4        2017-03-18 [1] CRAN (R 4.3.0)\n##    nlme                   3.1-162    2023-01-31 [2] CRAN (R 4.3.0)\n##    nloptr                 2.0.3      2022-05-26 [1] CRAN (R 4.3.0)\n##    nnet                   7.3-18     2022-09-28 [2] CRAN (R 4.3.0)\n##    numDeriv               2016.8-1.1 2019-06-06 [1] CRAN (R 4.3.0)\n##    officer              * 0.6.2      2023-03-28 [1] CRAN (R 4.3.0)\n##    openssl                2.0.6      2023-03-09 [1] CRAN (R 4.3.0)\n##    OpenStreetMap        * 0.3.4      2019-05-31 [1] CRAN (R 4.3.0)\n##    openxlsx               4.2.5.2    2023-02-06 [1] CRAN (R 4.3.0)\n##    pacman                 0.5.1      2019-03-11 [1] CRAN (R 4.3.0)\n##    parallelly             1.35.0     2023-03-23 [1] CRAN (R 4.3.0)\n##    parameters           * 0.21.0     2023-04-19 [1] CRAN (R 4.3.0)\n##    parsedate            * 1.3.1      2022-10-27 [1] CRAN (R 4.3.0)\n##    patchwork            * 1.1.2      2022-08-19 [1] CRAN (R 4.3.0)\n##    performance          * 0.10.3     2023-04-07 [1] CRAN (R 4.3.0)\n##    PerformanceAnalytics * 2.0.4      2020-02-06 [1] CRAN (R 4.3.0)\n##    PHEindicatormethods  * 2.0.1      2023-05-05 [1] CRAN (R 4.3.0)\n##    pillar                 1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n##    pkgbuild               1.4.0      2022-11-27 [1] CRAN (R 4.3.0)\n##    pkgconfig              2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n##    plotly               * 4.10.1     2022-11-07 [1] CRAN (R 4.3.0)\n##    plotrix                3.8-2      2021-09-08 [1] CRAN (R 4.3.0)\n##    plyr                   1.8.8      2022-11-11 [1] CRAN (R 4.3.0)\n##    png                    0.1-8      2022-11-29 [1] CRAN (R 4.3.0)\n##    polyclip               1.10-4     2022-10-20 [1] CRAN (R 4.3.0)\n##    polyCub                0.8.1      2022-11-28 [1] CRAN (R 4.3.0)\n##    prettyunits            1.1.1      2020-01-24 [1] CRAN (R 4.3.0)\n##    processx               3.8.1      2023-04-18 [1] CRAN (R 4.3.0)\n##    prodlim                2023.03.31 2023-04-02 [1] CRAN (R 4.3.0)\n##    progressr              0.13.0     2023-01-10 [1] CRAN (R 4.3.0)\n##    projections          * 0.6.0      2023-03-23 [1] CRAN (R 4.3.0)\n##    promises               1.2.0.1    2021-02-11 [1] CRAN (R 4.3.0)\n##    proxy                  0.4-27     2022-06-09 [1] CRAN (R 4.3.0)\n##    ps                     1.7.5      2023-04-18 [1] CRAN (R 4.3.0)\n##    purrr                * 1.0.1      2023-01-10 [1] CRAN (R 4.3.0)\n##    quadprog               1.5-8      2019-11-20 [1] CRAN (R 4.3.0)\n##    Quandl                 2.11.0     2021-08-11 [1] CRAN (R 4.3.0)\n##    quantmod             * 0.4.22     2023-04-07 [1] CRAN (R 4.3.0)\n##    quantreg               5.95       2023-04-08 [1] CRAN (R 4.3.0)\n##    R.methodsS3            1.8.2      2022-06-13 [1] CRAN (R 4.3.0)\n##    R.oo                   1.25.0     2022-06-12 [1] CRAN (R 4.3.0)\n##    R.utils                2.12.2     2022-11-11 [1] CRAN (R 4.3.0)\n##    R6                     2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n##    ragg                   1.2.5      2023-01-12 [1] CRAN (R 4.3.0)\n##    raster                 3.6-20     2023-03-06 [1] CRAN (R 4.3.0)\n##    RColorBrewer         * 1.1-3      2022-04-03 [1] CRAN (R 4.3.0)\n##    Rcpp                 * 1.0.10     2023-01-22 [1] CRAN (R 4.3.0)\n##  D RcppParallel           5.1.7      2023-02-27 [1] CRAN (R 4.3.0)\n##    readr                * 2.1.4      2023-02-10 [1] CRAN (R 4.3.0)\n##    readxl               * 1.4.2      2023-02-09 [1] CRAN (R 4.3.0)\n##    RecordLinkage        * 0.4-12.4   2022-11-08 [1] CRAN (R 4.3.0)\n##    remotes                2.4.2      2021-11-30 [1] CRAN (R 4.3.0)\n##    report               * 0.5.7      2023-03-22 [1] CRAN (R 4.3.0)\n##    repr                   1.1.6      2023-01-26 [1] CRAN (R 4.3.0)\n##    reprex                 2.0.2      2022-08-17 [1] CRAN (R 4.3.0)\n##    reshape2               1.4.4      2020-04-09 [1] CRAN (R 4.3.0)\n##    rgdal                  1.6-6      2023-04-18 [1] CRAN (R 4.3.0)\n##    rio                  * 0.5.29     2021-11-22 [1] CRAN (R 4.3.0)\n##  D rJava                  1.0-6      2021-12-10 [1] CRAN (R 4.3.0)\n##    rlang                  1.1.1      2023-04-28 [1] CRAN (R 4.3.0)\n##    rlist                  0.4.6.2    2021-09-03 [1] CRAN (R 4.3.0)\n##    rmarkdown              2.21       2023-03-26 [1] CRAN (R 4.3.0)\n##    rootSolve              1.8.2.3    2021-09-29 [1] CRAN (R 4.3.0)\n##    rpart                  4.1.19     2022-10-21 [2] CRAN (R 4.3.0)\n##    rprojroot              2.0.3      2022-04-02 [1] CRAN (R 4.3.0)\n##    RSQLite              * 2.3.1      2023-04-03 [1] CRAN (R 4.3.0)\n##    rstan                  2.21.8     2023-01-17 [1] CRAN (R 4.3.0)\n##    rstantools             2.3.1      2023-03-30 [1] CRAN (R 4.3.0)\n##    rstatix              * 0.7.2      2023-02-01 [1] CRAN (R 4.3.0)\n##    rstudioapi             0.15.0     2023-07-07 [1] CRAN (R 4.3.1)\n##    runner                 0.4.3      2023-03-21 [1] CRAN (R 4.3.0)\n##    rvest                  1.0.3      2022-08-19 [1] CRAN (R 4.3.0)\n##    s2                     1.1.4      2023-05-17 [1] CRAN (R 4.3.0)\n##    sass                   0.4.6      2023-05-03 [1] CRAN (R 4.3.0)\n##    scales               * 1.2.1      2022-08-20 [1] CRAN (R 4.3.0)\n##    scatterplot3d          0.3-44     2023-05-05 [1] CRAN (R 4.3.0)\n##    see                  * 0.7.5      2023-03-23 [1] CRAN (R 4.3.0)\n##    SemiCompRisks        * 3.4        2021-02-03 [1] CRAN (R 4.3.0)\n##    sessioninfo            1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n##    sf                   * 1.0-12     2023-03-19 [1] CRAN (R 4.3.0)\n##    shiny                * 1.7.4      2022-12-15 [1] CRAN (R 4.3.0)\n##    shinyWidgets           0.7.6      2023-01-08 [1] CRAN (R 4.3.0)\n##    sitrep               * 0.2.3      2023-05-21 [1] Github (r4epi/sitrep@b96906b)\n##    skimr                * 2.1.5      2022-12-23 [1] CRAN (R 4.3.0)\n##    slider               * 0.3.0      2022-11-16 [1] CRAN (R 4.3.0)\n##    snakecase              0.11.0     2019-05-25 [1] CRAN (R 4.3.0)\n##    sp                   * 1.6-0      2023-01-19 [1] CRAN (R 4.3.0)\n##    SparseM                1.81       2021-02-18 [1] CRAN (R 4.3.0)\n##    spatstat.data          3.0-1      2023-03-12 [1] CRAN (R 4.3.0)\n##    spatstat.geom          3.2-1      2023-05-09 [1] CRAN (R 4.3.0)\n##    spatstat.utils         3.0-3      2023-05-09 [1] CRAN (R 4.3.0)\n##    spData               * 2.2.2      2023-03-01 [1] CRAN (R 4.3.0)\n##    spdep                * 1.2-8      2023-02-28 [1] CRAN (R 4.3.0)\n##    srvyr                * 1.2.0      2023-02-21 [1] CRAN (R 4.3.0)\n##    StanHeaders            2.26.25    2023-05-17 [1] CRAN (R 4.3.0)\n##    stars                * 0.6-1      2023-04-06 [1] CRAN (R 4.3.0)\n##    statmod                1.5.0      2023-01-06 [1] CRAN (R 4.3.0)\n##    stinepack              1.4        2018-07-30 [1] CRAN (R 4.3.0)\n##    stringdist           * 0.9.10     2022-11-07 [1] CRAN (R 4.3.0)\n##    stringi                1.7.12     2023-01-11 [1] CRAN (R 4.3.0)\n##    stringr              * 1.5.0      2022-12-02 [1] CRAN (R 4.3.0)\n##    survC1               * 1.0-3      2021-02-10 [1] CRAN (R 4.3.0)\n##    surveillance         * 1.21.1     2023-05-19 [1] CRAN (R 4.3.0)\n##    survey               * 4.2-1      2023-05-03 [1] CRAN (R 4.3.0)\n##    survival             * 3.5-5      2023-03-12 [2] CRAN (R 4.3.0)\n##    survminer            * 0.4.9      2021-03-09 [1] CRAN (R 4.3.0)\n##    survMisc               0.5.6      2022-04-07 [1] CRAN (R 4.3.0)\n##    svglite                2.1.1      2023-01-10 [1] CRAN (R 4.3.0)\n##    systemfonts            1.0.4      2022-02-11 [1] CRAN (R 4.3.0)\n##    terra                  1.7-29     2023-04-22 [1] CRAN (R 4.3.0)\n##    textshaping            0.3.6      2021-10-13 [1] CRAN (R 4.3.0)\n##    tibble               * 3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n##    tidyquant            * 1.0.7      2023-03-31 [1] CRAN (R 4.3.0)\n##    tidyr                * 1.3.0      2023-01-24 [1] CRAN (R 4.3.0)\n##    tidyselect             1.2.0      2022-10-10 [1] CRAN (R 4.3.0)\n##    tidytree               0.4.2      2022-12-18 [1] CRAN (R 4.3.0)\n##    tidyverse            * 2.0.0      2023-02-22 [1] CRAN (R 4.3.0)\n##    timechange             0.2.0      2023-01-11 [1] CRAN (R 4.3.0)\n##    timeDate               4022.108   2023-01-07 [1] CRAN (R 4.3.0)\n##    tinytex                0.45       2023-04-18 [1] CRAN (R 4.3.0)\n##    tmap                 * 3.3-3      2022-03-02 [1] CRAN (R 4.3.0)\n##    tmaptools            * 3.1-1      2021-01-19 [1] CRAN (R 4.3.0)\n##    treeio               * 1.24.0     2023-04-25 [1] Bioconductor\n##    trending             * 0.1.0      2023-04-03 [1] CRAN (R 4.3.0)\n##    truncnorm              1.0-9      2023-03-20 [1] CRAN (R 4.3.0)\n##    tseries                0.10-54    2023-05-02 [1] CRAN (R 4.3.0)\n##    tsibble              * 1.1.3      2022-10-09 [1] CRAN (R 4.3.0)\n##    TTR                  * 0.24.3     2021-12-12 [1] CRAN (R 4.3.0)\n##    tweenr                 2.0.2      2022-09-06 [1] CRAN (R 4.3.0)\n##    tzdb                   0.4.0      2023-05-12 [1] CRAN (R 4.3.0)\n##    units                * 0.8-2      2023-04-27 [1] CRAN (R 4.3.0)\n##    UpSetR               * 1.4.0      2019-05-22 [1] CRAN (R 4.3.0)\n##    urca                   1.3-3      2022-08-29 [1] CRAN (R 4.3.0)\n##    utf8                   1.2.3      2023-01-31 [1] CRAN (R 4.3.0)\n##    uuid                   1.1-0      2022-04-19 [1] CRAN (R 4.3.0)\n##    vctrs                  0.6.2      2023-04-19 [1] CRAN (R 4.3.0)\n##    viridis                0.6.3      2023-05-03 [1] CRAN (R 4.3.0)\n##    viridisLite            0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n##    visdat                 0.6.0      2023-02-02 [1] CRAN (R 4.3.0)\n##    visNetwork           * 2.1.2      2022-09-29 [1] CRAN (R 4.3.0)\n##    vistime              * 1.2.3      2022-10-16 [1] CRAN (R 4.3.0)\n##    warp                   0.2.0      2020-10-21 [1] CRAN (R 4.3.0)\n##    webshot              * 0.5.4      2022-09-26 [1] CRAN (R 4.3.0)\n##    withr                  2.5.0      2022-03-03 [1] CRAN (R 4.3.0)\n##    wk                     0.7.3      2023-05-06 [1] CRAN (R 4.3.0)\n##    writexl              * 1.4.2      2023-01-06 [1] CRAN (R 4.3.0)\n##    xfun                   0.39       2023-04-20 [1] CRAN (R 4.3.0)\n##    XML                    3.99-0.14  2023-03-19 [1] CRAN (R 4.3.0)\n##    xml2                   1.3.4      2023-04-27 [1] CRAN (R 4.3.0)\n##    xtable               * 1.8-4      2019-04-21 [1] CRAN (R 4.3.0)\n##    xts                  * 0.13.1     2023-04-16 [1] CRAN (R 4.3.0)\n##    yaml                   2.3.7      2023-01-23 [1] CRAN (R 4.3.0)\n##    yardstick            * 1.2.0      2023-04-21 [1] CRAN (R 4.3.0)\n##    yulab.utils            0.0.6      2022-12-20 [1] CRAN (R 4.3.0)\n##    zip                    2.3.0      2023-04-17 [1] CRAN (R 4.3.0)\n##    zoo                  * 1.8-12     2023-04-13 [1] CRAN (R 4.3.0)\n## \n##  [1] C:/Users/neale/AppData/Local/R/win-library/4.3\n##  [2] C:/Program Files/R/R-4.3.0/library\n## \n##  D ── DLL MD5 mismatch, broken installation.\n## \n## ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"},{"path":"download-handbook-and-data.html","id":"download-handbook-and-data","chapter":"2 Download handbook and data","heading":"2 Download handbook and data","text":"","code":""},{"path":"download-handbook-and-data.html","id":"download-offline-handbook","chapter":"2 Download handbook and data","heading":"2.1 Download offline handbook","text":"can download offline version handbook HTML file can view file web browser even longer internet access. considering offline use Epi R Handbook things consider:open file may take minute two images Table Contents loadThe offline handbook slightly different layout - one long page Table Contents left. search specific terms use Ctrl+f (Cmd-f)See Suggested packages page assist installing appropriate R packages lose internet connectivityInstall R package epirhandbook contains example data (install process described )two ways can download handbook:","code":""},{"path":"download-handbook-and-data.html","id":"use-download-link","chapter":"2 Download handbook and data","heading":"Use download link","text":"quick access, right-click link select “Save link ”.Mac, use Cmd+click. mobile, press hold link select “Save link”. handbook download device. screen raw HTML code appears, ensure followed instructions try Option 2.","code":""},{"path":"download-handbook-and-data.html","id":"use-our-r-package","chapter":"2 Download handbook and data","heading":"Use our R package","text":"offer R package called epirhandbook. includes function download_book() downloads handbook file Github repository computer.package also contains function get_data() downloads example data computer.Run following code install R package epirhandbook Github repository appliedepi. package CRAN, use special function p_install_gh() install Github.Now, load package use current R session:Next, run package’s function download_book() (empty parentheses) download handbook computer. Assuming RStudio, window appear allowing select save location.","code":"\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# load the package for use\npacman::p_load(epirhandbook)\n# download the offline handbook to your computer\ndownload_book()"},{"path":"download-handbook-and-data.html","id":"download-data-to-follow-along","chapter":"2 Download handbook and data","heading":"2.2 Download data to follow along","text":"“follow along” handbook pages, can download example data outputs.","code":""},{"path":"download-handbook-and-data.html","id":"use-our-r-package-1","chapter":"2 Download handbook and data","heading":"Use our R package","text":"easiest approach download data install R package epirhandbook. contains function get_data() saves example data folder choice computer.install R package epirhandbook, run following code. package CRAN, use function p_install_gh() install . input referencing Github organisation (“appliedepi”) epirhandbook package.Now, load package use current R session:Next, use package’s function get_data() download example data computer. Run get_data(\"\") get example data, provide specific file name extension within quotes retrieve one file.data already downloaded package, simply need transferred folder computer. pop-window appear, allowing select save folder location. suggest create new “data” folder 30 files (including example data example outputs).used get_data() save file computer, still need import R. See Import export page details.wish, can review data used handbook “data” folder Github repository.","code":"\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# load the package for use\npacman::p_load(epirhandbook)\n# download all the example data into a folder on your computer\nget_data(\"all\")\n\n# download only the linelist example data into a folder on your computer\nget_data(file = \"linelist_cleaned.rds\")\n# download a specific file into a folder on your computer\nget_data(\"linelist_cleaned.rds\")"},{"path":"download-handbook-and-data.html","id":"download-one-by-one","chapter":"2 Download handbook and data","heading":"Download one-by-one","text":"option involves downloading data file--file Github repository via either link R command specific file. file types allow download button, others can downloaded via R command.","code":""},{"path":"download-handbook-and-data.html","id":"case-linelist","chapter":"2 Download handbook and data","heading":"Case linelist","text":"fictional Ebola outbreak, expanded handbook team ebola_sim practice dataset outbreaks package.Click download “raw” linelist (.xlsx). “raw” case linelist Excel spreadsheet messy data. Use follow-along Cleaning data core functions page.Click download “raw” linelist (.xlsx). “raw” case linelist Excel spreadsheet messy data. Use follow-along Cleaning data core functions page.Click download “clean” linelist (.rds). Use file pages handbook use linelist. .rds file R-specific file type preserves column classes. ensures minimal cleaning importing data R.Click download “clean” linelist (.rds). Use file pages handbook use linelist. .rds file R-specific file type preserves column classes. ensures minimal cleaning importing data R.related files:Click download “clean” linelist Excel fileClick download “clean” linelist Excel filePart cleaning page uses “cleaning dictionary” (.csv file). can load directly R running following commands:Part cleaning page uses “cleaning dictionary” (.csv file). can load directly R running following commands:","code":"\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\ncleaning_dict <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv\")"},{"path":"download-handbook-and-data.html","id":"data_malaria","chapter":"2 Download handbook and data","heading":"Malaria count data","text":"data fictional counts malaria cases age group, facility, day. .rds file R-specific file type preserves column classes. ensures minimal cleaning importing data R.\nClick download\nmalaria count data (.rds file)\n","code":""},{"path":"download-handbook-and-data.html","id":"likert-scale-data","chapter":"2 Download handbook and data","heading":"Likert-scale data","text":"fictional data Likert-style survey, used page Demographic pyramids Likert-scales. can load data directly R running following commands:","code":"\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\nlikert_data <- import(\"https://raw.githubusercontent.com/appliedepi/epirhandbook_eng/master/data/likert_data.csv\")"},{"path":"download-handbook-and-data.html","id":"flexdashboard","chapter":"2 Download handbook and data","heading":"Flexdashboard","text":"links file associated page Dashboards R Markdown:download R Markdown outbreak dashboard, right-click link (Cmd+click Mac) select “Save link ”.download HTML dashboard, right-click link (Cmd+click Mac) select “Save link ”.","code":""},{"path":"download-handbook-and-data.html","id":"contact-tracing","chapter":"2 Download handbook and data","heading":"Contact Tracing","text":"Contact Tracing page demonstrated analysis contact tracing data, using example data Go.Data. data used page can downloaded .rds files clicking following links:\nClick download\ncase investigation data (.rds file)\n\nClick download\ncontact registration data (.rds file)\n\nClick download\ncontact follow-data (.rds file)\nNOTE: Structured contact tracing data software (e.g. KoBo, DHIS2 Tracker, CommCare) may look different. like contribute alternative sample data content page, please contact us.TIP: deploying Go.Data want connect instance’s API, see Import export page (API section) Go.Data Community Practice.","code":""},{"path":"download-handbook-and-data.html","id":"gis","chapter":"2 Download handbook and data","heading":"GIS","text":"Shapefiles many sub-component files, different file extention. One file “.shp” extension, others may “.dbf”, “.prj”, etc.GIS basics page provides links Humanitarian Data Exchange website can download shapefiles directly zipped files.example, health facility points data can downloaded . Download “hotosm_sierra_leone_health_facilities_points_shp.zip”. saved computer, “unzip” folder. see several files different extensions (e.g. “.shp”, “.prj”, “.shx”) - must saved folder computer. import R, provide file path name “.shp” file st_read() sf package (described GIS basics page).follow Option 1 download example data (via R package epirhandbook), shapefiles included.Alternatively, can download shapefiles R Handbook Github “data” folder (see “gis” sub-folder). However, aware need download sub-file individually computer. Github, click file individually download clicking “Download” button. , can see shapefile “sle_adm3” consists many files - need downloaded Github.","code":""},{"path":"download-handbook-and-data.html","id":"phylogenetic-trees","chapter":"2 Download handbook and data","heading":"Phylogenetic trees","text":"See page Phylogenetic trees. Newick file phylogenetic tree constructed whole genome sequencing 299 Shigella sonnei samples corresponding sample data (converted text file). Belgian samples resulting data kindly provided Belgian NRC Salmonella Shigella scope project conducted ECDC EUPHEM Fellow, also published manuscript. international data openly available public databases (ncbi) previously published.download “Shigella_tree.txt” phylogenetic tree file, right-click link (Cmd+click Mac) select “Save link ”.download “sample_data_Shigella_tree.csv” additional information sample, right-click link (Cmd+click Mac) select “Save link ”.see new, created subset-tree, right-click link (Cmd+click Mac) select “Save link ”. .txt file download computer.can import .txt files read.tree() ape package, explained page.","code":"\nape::read.tree(\"Shigella_tree.txt\")"},{"path":"download-handbook-and-data.html","id":"standardization","chapter":"2 Download handbook and data","heading":"Standardization","text":"See page Standardised rates. can load data directly Github repository internet R session following commands:","code":"\n# install/load the rio package\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# import demographics for country A directly from Github\nA_demo <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# import demographics for country B directly from Github\nB_demo <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Reference Pop\n###############\n# import demographics for country B directly from Github\nstandard_pop_data <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")"},{"path":"download-handbook-and-data.html","id":"data_outbreak","chapter":"2 Download handbook and data","heading":"Time series and outbreak detection","text":"See page Time series outbreak detection. use campylobacter cases reported Germany 2002-2011, available surveillance R package. (nb. dataset adapted original, 3 months data deleted end 2011 demonstration purposes)\nClick download\n Campylobacter Germany (.xlsx)\nalso use climate data Germany 2002-2011 (temperature degrees celsius rain fail millimetres) . downloaded EU Copernicus satellite reanalysis dataset using ecmwfr package. need download import stars::read_stars() explained time series page.\nClick download\n Germany weather 2002 (.nc file)\n\nClick download\n Germany weather 2003 (.nc file)\n\nClick download\n Germany weather 2004 (.nc file)\n\nClick download\n Germany weather 2005 (.nc file)\n\nClick download\n Germany weather 2006 (.nc file)\n\nClick download\n Germany weather 2007 (.nc file)\n\nClick download\n Germany weather 2008 (.nc file)\n\nClick download\n Germany weather 2009 (.nc file)\n\nClick download\n Germany weather 2010 (.nc file)\n\nClick download\n Germany weather 2011 (.nc file)\n","code":""},{"path":"download-handbook-and-data.html","id":"data_survey","chapter":"2 Download handbook and data","heading":"Survey analysis","text":"survey analysis page use fictional mortality survey data based MSF OCA survey templates. fictional data generated part “R4Epis” project.\nClick download\n Fictional survey data (.xlsx)\n\nClick download\n Fictional survey data dictionary (.xlsx)\n\nClick download\n Fictional survey population data (.xlsx)\n","code":""},{"path":"download-handbook-and-data.html","id":"data_shiny","chapter":"2 Download handbook and data","heading":"Shiny","text":"page Dashboards Shiny demonstrates construction simple app display malaria data.download R files produce Shiny app:can \nclick download app.R file contains UI Server code Shiny app.can \nclick download facility_count_data.rds file contains malaria data Shiny app. Note may need store within “data” folder () file paths work correctly.can \nclick download global.R file run prior app opening, explained page.can \nclick download plot_epicurve.R file sourced global.R. Note may need store within “funcs” folder () file paths work correctly.","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"3 R Basics","heading":"3 R Basics","text":"Welcome!page reviews essentials R. intended comprehensive tutorial, provides basics can useful refreshing memory. section Resources learning links comprehensive tutorials.Parts page adapted permission R4Epis project.See page Transition R tips switching R STATA, SAS, Excel.","code":""},{"path":"r-basics.html","id":"why-use-r","chapter":"3 R Basics","heading":"3.1 Why use R?","text":"stated R project website, R programming language environment statistical computing graphics. highly versatile, extendable, community-driven.CostR free use! strong ethic community free open-source material.ReproducibilityConducting data management analysis programming language (compared Excel another primarily point-click/manual tool) enhances reproducibility, makes error-detection easier, eases workload.CommunityThe R community users enormous collaborative. New packages tools address real-life problems developed daily, vetted community users. one example, R-Ladies worldwide organization whose mission promote gender diversity R community, one largest organizations R users. likely chapter near !","code":""},{"path":"r-basics.html","id":"key-terms","chapter":"3 R Basics","heading":"3.2 Key terms","text":"RStudio - RStudio Graphical User Interface (GUI) easier use R. Read RStudio section.Objects - Everything store R - datasets, variables, list village names, total population number, even outputs graphs - objects assigned name can referenced later commands. Read Objects section.Functions - function code operation accept inputs returns transformed output. Read Functions section.Packages - R package shareable bundle functions. Read Packages section.Scripts - script document file hold commands. Read Scripts section","code":""},{"path":"r-basics.html","id":"learning","chapter":"3 R Basics","heading":"3.3 Resources for learning","text":"","code":""},{"path":"r-basics.html","id":"resources-within-rstudio","chapter":"3 R Basics","heading":"Resources within RStudio","text":"Help documentationSearch RStudio “Help” tab documentation R packages specific functions. within pane also contains Files, Plots, Packages (typically lower-right pane). shortcut, can also type name package function R console question-mark open relevant Help page. include parentheses.example: ?filter ?diagrammeR.Interactive tutorialsThere several ways learn R interactively within RStudio.RStudio offers Tutorial pane powered learnr R package. Simply install package open tutorial via new “Tutorial” tab upper-right RStudio pane (also contains Environment History tabs).R package swirl offers interactive courses R Console. Install load package, run command swirl() (empty parentheses) R console. see prompts appear Console. Respond typing Console. guide course choice.","code":""},{"path":"r-basics.html","id":"cheatsheets","chapter":"3 R Basics","heading":"Cheatsheets","text":"many PDF “cheatsheets” available RStudio website, example:Factors forcats packageDates times lubridate packageStrings stringr packageiterative opertaions purrr packageData importData transformation cheatsheet dplyr packageR Markdown (create documents like PDF, Word, Powerpoint…)Shiny (build interactive web apps)Data visualization ggplot2 packageCartography (GIS)leaflet package (interactive maps)Python R (reticulate package)online R resource specifically Excel users","code":""},{"path":"r-basics.html","id":"twitter","chapter":"3 R Basics","heading":"Twitter","text":"R vibrant twitter community can learn tips, shortcuts, news - follow accounts:Follow us! @epiRhandbookR Function Day @rfuntionaday incredible resourceR Data Science @rstats4dsRStudio @RStudioRStudio Tips @rstudiotipsR-Bloggers @RbloggersR-ladies @RLadiesGlobalHadley Wickham @hadleywickhamAlso:#epitwitter #rstats","code":""},{"path":"r-basics.html","id":"free-online-resources","chapter":"3 R Basics","heading":"Free online resources","text":"definitive text R Data Science book Garrett Grolemund Hadley WickhamThe R4Epis project website aims “develop standardised data cleaning, analysis reporting tools cover common types outbreaks population-based surveys conducted MSF emergency response setting.” can find R basics training materials, templates RMarkdown reports outbreaks surveys, tutorials help set .","code":""},{"path":"r-basics.html","id":"languages-other-than-english","chapter":"3 R Basics","heading":"Languages other than English","text":"Materiales de RStudio en EspañolIntroduction à R et au tidyverse (Francais)","code":""},{"path":"r-basics.html","id":"installation","chapter":"3 R Basics","heading":"3.4 Installation","text":"","code":""},{"path":"r-basics.html","id":"r-and-rstudio","chapter":"3 R Basics","heading":"R and RStudio","text":"install RVisit website https://www.r-project.org/ download latest version R suitable computer.install RStudioVisit website https://rstudio.com/products/rstudio/download/ download latest free Desktop version RStudio suitable computer.Permissions\nNote install R RStudio drive read write permissions. Otherwise, ability install R packages (frequent occurrence) impacted. encounter problems, try opening RStudio right-clicking icon selecting “Run administrator”. tips can found page R network drives.update R RStudioYour version R printed R Console start-. can also run sessionInfo().update R, go website mentioned re-install R. Alternatively, can use installr package (Windows) running installr::updateR(). open dialog boxes help download latest R version update packages new R version. details can found installr documentation.aware old R version still exist computer. can temporarily run older version (older “installation”) R clicking “Tools” -> “Global Options” RStudio choosing R version. can useful want use package updated work newest version R.update RStudio, can go website re-download RStudio. Another option click “Help” -> “Check Updates” within RStudio, may show latest updates.see versions R, RStudio, packages used Handbook made, see page Editorial technical notes.","code":""},{"path":"r-basics.html","id":"other-software-you-may-need-to-install","chapter":"3 R Basics","heading":"Other software you may need to install","text":"TinyTeX (compiling RMarkdown document PDF)Pandoc (compiling RMarkdown documents)RTools (building packages R)phantomjs (saving still images animated networks, transmission chains)","code":""},{"path":"r-basics.html","id":"tinytex","chapter":"3 R Basics","heading":"TinyTex","text":"TinyTex custom LaTeX distribution, useful trying produce PDFs R.\nSee https://yihui.org/tinytex/ informaton.install TinyTex R:","code":"\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# to uninstall TinyTeX, run tinytex::uninstall_tinytex()"},{"path":"r-basics.html","id":"pandoc","chapter":"3 R Basics","heading":"Pandoc","text":"Pandoc document converter, separate software R. comes bundled RStudio need downloaded. helps process converting Rmarkdown documents formats like .pdf adding complex functionality.","code":""},{"path":"r-basics.html","id":"rtools","chapter":"3 R Basics","heading":"RTools","text":"RTools collection software building packages RInstall website: https://cran.r-project.org/bin/windows/Rtools/","code":""},{"path":"r-basics.html","id":"phantomjs","chapter":"3 R Basics","heading":"phantomjs","text":"often used take “screenshots” webpages. example make transmission chain epicontacts package, HTML file produced interactive dynamic. want static image, can useful use webshot package automate process. require external program “phantomjs”. can install phantomjs via webshot package command webshot::install_phantomjs().","code":""},{"path":"r-basics.html","id":"rstudio","chapter":"3 R Basics","heading":"3.5 RStudio","text":"","code":""},{"path":"r-basics.html","id":"rstudio-orientation","chapter":"3 R Basics","heading":"RStudio orientation","text":"First, open RStudio. icons can look similar, sure opening RStudio R.RStudio work must also R installed computer (see installation instructions).RStudio interface (GUI) easier use R. can think R engine vehicle, crucial work, RStudio body vehicle (seats, accessories, etc.) helps actually use engine move forward! can see complete RStudio user-interface cheatsheet (PDF) hereBy default RStudio displays four rectangle panes.TIP: RStudio displays one left pane scripts open yet.Source Pane\npane, default upper-left, space edit, run, save scripts. Scripts contain commands want run. pane can also display datasets (data frames) viewing.Stata users, pane similar -file Data Editor windows.R Console PaneThe R Console, default left lower-left pane R Studio, home R “engine”. commands actually run non-graphic outputs error/warning messages appear. can directly enter run commands R Console, realize commands saved running commands script.familiar Stata, R Console like Command Window also Results Window.Environment Pane\npane, default upper-right, often used see brief summaries objects R Environment current session. objects include imported, modified, created datasets, parameters defined (e.g. specific epi week analysis), vectors lists defined analysis (e.g. names regions). can click arrow next data frame name see variables.Stata, similar Variables Manager window.pane also contains History can see commands can previously. also “Tutorial” tab can complete interactive R tutorials learnr package installed. also “Connections” pane external connections, can “Git” pane choose interface Github.Plots, Viewer, Packages, Help Pane\nlower-right pane includes several important tabs. Typical plot graphics including maps display Plot pane. Interactive HTML outputs display Viewer pane. Help pane can display documentation help files. Files pane browser can used open delete files. Packages pane allows see, install, update, delete, load/unload R packages, see version package . learn packages see packages section .pane contains Stata equivalents Plots Manager Project Manager windows.","code":""},{"path":"r-basics.html","id":"rstudio-settings","chapter":"3 R Basics","heading":"RStudio settings","text":"Change RStudio settings appearance Tools drop-menu, selecting Global Options. can change default settings, including appearance/background color.RestartIf R freezes, can re-start R going Session menu clicking “Restart R”. avoids hassle closing opening RStudio. Everything R environment removed .","code":""},{"path":"r-basics.html","id":"keyboard-shortcuts","chapter":"3 R Basics","heading":"Keyboard shortcuts","text":"useful keyboard shortcuts . See keyboard shortcuts Windows, Max, Linux second page RStudio user interface cheatsheet.TIP: Use Tab key typing engage RStudio’s auto-complete functionality. can prevent spelling errors. Press Tab typing produce drop-menu likely functions objects, based typed far.","code":""},{"path":"r-basics.html","id":"functions","chapter":"3 R Basics","heading":"3.6 Functions","text":"Functions core using R. Functions perform tasks operations. Many functions come installed R, many available download packages (explained packages section), can even write custom functions!basics section functions explains:function workWhat function arguments areHow get help understanding functionA quick note syntax: handbook, functions written code-text open parentheses, like : filter(). explained packages section, functions downloaded within packages. handbook, package names written bold, like dplyr. Sometimes example code may see function name linked explicitly name package two colons (::) like : dplyr::filter(). purpose linkage explained packages section.","code":""},{"path":"r-basics.html","id":"simple-functions","chapter":"3 R Basics","heading":"Simple functions","text":"function like machine receives inputs, action inputs, produces output. output depends function.Functions typically operate upon object placed within function’s parentheses. example, function sqrt() calculates square root number:object provided function also can column dataset (see Objects section detail kinds objects). R can store multiple datasets, need specify dataset column. One way using $ notation link name dataset name column (dataset$column). example , function summary() applied numeric column age dataset linelist, output summary column’s numeric missing values.NOTE: Behind scenes, function represents complex additional code wrapped user one easy command.","code":"\nsqrt(49)## [1] 7\n# Print summary statistics of column 'age' in the dataset 'linelist'\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.07   23.00   84.00      86"},{"path":"r-basics.html","id":"functions-with-multiple-arguments","chapter":"3 R Basics","heading":"Functions with multiple arguments","text":"Functions often ask several inputs, called arguments, located within parentheses function, usually separated commas.arguments required function work correctly, others optionalOptional arguments default settingsArguments can take character, numeric, logical (TRUE/FALSE), inputsHere fun fictional function, called oven_bake(), example typical function. takes input object (e.g. dataset, example “dough”) performs operations specified additional arguments (minutes = temperature =). output can printed console, saved object using assignment operator <-.realistic example, age_pyramid() command produces age pyramid plot based defined age groups binary split column, gender. function given three arguments within parentheses, separated commas. values supplied arguments establish linelist dataframe use, age_cat5 column count, gender binary column use splitting pyramid color.command can equivalently written , longer style new line argument. style can easier read, easier write “comments” # explain part (commenting extensively good practice!). run longer command can highlight entire command click “Run”, just place cursor first line press Ctrl Enter keys simultaneously.first half argument assignment (e.g. data =) need specified arguments written specific order (specified function’s documentation). code produces exact pyramid , function expects argument order: data frame, age_group variable, split_by variable.complex age_pyramid() command might include optional arguments :Show proportions instead counts (set proportional = TRUE default FALSE)Specify two colors use (pal = short “palette” supplied vector two color names. See objects page function c() makes vector)NOTE: arguments specify parts argument (e.g. proportional = TRUE), order among arguments matter.","code":"\n# Create an age pyramid\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n# Create an age pyramid\nage_pyramid(\n  data = linelist,        # use case linelist\n  age_group = \"age_cat5\", # provide age group column\n  split_by = \"gender\"     # use gender column for two sides of pyramid\n  )\n# This command will produce the exact same graphic as above\nage_pyramid(linelist, \"age_cat5\", \"gender\")\nage_pyramid(\n  linelist,                    # use case linelist\n  \"age_cat5\",                  # age group column\n  \"gender\",                    # split by gender\n  proportional = TRUE,         # percents instead of counts\n  pal = c(\"orange\", \"purple\")  # colors\n  )"},{"path":"r-basics.html","id":"writing-functions","chapter":"3 R Basics","heading":"Writing Functions","text":"R language oriented around functions, feel empowered write functions. Creating functions brings several advantages:facilitate modular programming - separation code independent manageable piecesReplace repetitive copy--paste, can error proneGive pieces code memorable namesHow write function covered -depth Writing functions page.","code":""},{"path":"r-basics.html","id":"packages","chapter":"3 R Basics","heading":"3.7 Packages","text":"Packages contain functions.R package shareable bundle code documentation contains pre-defined functions. Users R community develop packages time catered specific problems, likely one can help work! install use hundreds packages use R.installation, R contains “base” packages functions perform common elementary tasks. many R users create specialized functions, verified R community can download package use. handbook, package names written bold. One challenging aspects R often many functions packages choose complete given task.","code":""},{"path":"r-basics.html","id":"install-and-load","chapter":"3 R Basics","heading":"Install and load","text":"Functions contained within packages can downloaded (“installed”) computer internet. package downloaded, stored “library”. can access functions contains current R session “loading” package.Think R personal library: download package, library gains new book functions, time want use function book, must borrow (“load”) book library.summary: use functions available R package, 2 steps must implemented:package must installed (), andThe package must loaded (R session)","code":""},{"path":"r-basics.html","id":"your-library","chapter":"3 R Basics","heading":"Your library","text":"“library” actually folder computer, containing folder package installed. Find R installed computer, look folder called “win-library”. example: R\\win-library\\4.0 (4.0 R version - ’ll different library R version ’ve downloaded).can print file path library entering .libPaths() (empty parentheses). becomes especially important working R network drives.","code":""},{"path":"r-basics.html","id":"install-from-cran","chapter":"3 R Basics","heading":"Install from CRAN","text":"often, R users download packages CRAN. CRAN (Comprehensive R Archive Network) online public warehouse R packages published R community members.worried viruses security downloading package CRAN? Read article topic.","code":""},{"path":"r-basics.html","id":"how-to-install-and-load","chapter":"3 R Basics","heading":"How to install and load","text":"handbook, suggest using pacman package (short “package manager”). offers convenient function p_load() install package necessary load use current R session.syntax quite simple. Just list names packages within p_load() parentheses, separated commas. command install rio, tidyverse, packages yet installed, load use. makes p_load() approach convenient concise sharing scripts others. Note package names case-sensitive.Note used syntax pacman::p_load() explicitly writes package name (pacman) prior function name (p_load()), connected two colons ::. syntax useful also loads pacman package (assuming already installed).alternative base R functions see often. base R function installing package install.packages(). name package install must provided parentheses quotes. want install multiple packages one command, must listed within character vector c().Note: command installs package, load use current session.Installation can also accomplished point--click going RStudio “Packages” pane clicking “Install” searching desired package name.base R function load package use (installed) library(). can load one package time (another reason use p_load()). can provide package name without quotes.check whether package installed /loaded, can view Packages pane RStudio. package installed, shown version number. box checked, loaded current session.Install GithubSometimes, need install package yet available CRAN. perhaps package available CRAN want development version new features yet offered stable published CRAN version. often hosted website github.com free, public-facing code “repository”. Read Github handbook page Version control collaboration Git Github.download R packages Github, can use function p_load_gh() pacman, install package necessary, load use current R session. Alternatives install include using remotes devtools packages. Read pacman functions package documentation.install Github, provide information. must provide:Github ID repository ownerThe name repository contains package(optional) name “branch” (specific development version) want downloadIn examples , first word quotation marks Github ID repository owner, slash name repository (name package).want install “branch” (version) main branch, add branch name “@”, repository name.difference Github version version computer, action taken. can “force” re-install instead using p_load_current_gh() argument update = TRUE. Read pacman online vignetteInstall ZIP TARYou install package URL:, download computer zipped file:Option 1: using install_local() remotes packageOption 2: using install.packages() base R, providing file path ZIP file setting type = \"source repos = NULL.","code":"\n# Install (if necessary) and load packages for use\npacman::p_load(rio, tidyverse, here)\n# install a single package with base R\ninstall.packages(\"tidyverse\")\n\n# install multiple packages with base R\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n# load packages for use, with base R\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n# install/load the epicontacts package from its Github repository\np_load_gh(\"reconhub/epicontacts\")\n# install the \"timeline\" branch of the epicontacts package from Github\np_load_gh(\"reconhub/epicontacts@timeline\")\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\ninstall.packages(\"~/Downloads/dplyr-master.zip\", repos=NULL, type=\"source\")"},{"path":"r-basics.html","id":"code-syntax","chapter":"3 R Basics","heading":"Code syntax","text":"clarity handbook, functions sometimes preceded name package using :: symbol following way: package_name::function_name()package loaded session, explicit style necessary. One can just use function_name(). However writing package name useful function name common may exist multiple packages (e.g. plot()). Writing package name also load package already loaded.","code":"\n# This command uses the package \"rio\" and its function \"import()\" to import a dataset\nlinelist <- rio::import(\"linelist.xlsx\", which = \"Sheet1\")"},{"path":"r-basics.html","id":"function-help","chapter":"3 R Basics","heading":"Function help","text":"read function, can search Help tab lower-right RStudio. can also run command like ?thefunctionname (put name function question mark) Help page appear Help pane. Finally, try searching online resources.","code":""},{"path":"r-basics.html","id":"update-packages","chapter":"3 R Basics","heading":"Update packages","text":"can update packages re-installing . can also click green “Update” button RStudio Packages pane see packages new versions install. aware old code may need updated major revision function works!","code":""},{"path":"r-basics.html","id":"delete-packages","chapter":"3 R Basics","heading":"Delete packages","text":"Use p_delete() pacman, remove.packages() base R. Alternatively, go find folder contains library manually delete folder.","code":""},{"path":"r-basics.html","id":"dependencies","chapter":"3 R Basics","heading":"Dependencies","text":"Packages often depend packages work. called dependencies. dependency fails install, package depending may also fail install.See dependencies package p_depends(), see packages depend p_depends_reverse()","code":""},{"path":"r-basics.html","id":"masked-functions","chapter":"3 R Basics","heading":"Masked functions","text":"uncommon two packages contain function name. example, package dplyr filter() function, package stats. default filter() function depends order packages first loaded R session - later one default command filter().can check order Environment pane R Studio - click drop-“Global Environment” see order packages. Functions packages lower drop-list mask functions name packages appear higher drop-list. first loading package, R warn console masking occurring, can easy miss.ways can fix masking:Specify package name command. example, use dplyr::filter()Re-arrange order packages loaded (e.g. within p_load()), start new R session","code":""},{"path":"r-basics.html","id":"detach-unload","chapter":"3 R Basics","heading":"Detach / unload","text":"detach (unload) package, use command, correct package name one colon. Note may resolve masking.","code":"\ndetach(package:PACKAGE_NAME_HERE, unload=TRUE)"},{"path":"r-basics.html","id":"install-older-version","chapter":"3 R Basics","heading":"Install older version","text":"See guide install older version particular package.","code":""},{"path":"r-basics.html","id":"suggested-packages","chapter":"3 R Basics","heading":"Suggested packages","text":"See page Suggested packages listing packages recommend everyday epidemiology.","code":""},{"path":"r-basics.html","id":"scripts","chapter":"3 R Basics","heading":"3.8 Scripts","text":"Scripts fundamental part programming. documents hold commands (e.g. functions create modify datasets, print visualizations, etc). can save script run later. many advantages storing running commands script (vs. typing commands one--one R console “command line”):Portability - can share work others sending scriptsReproducibility - others know exactly didVersion control - can track changes made colleaguesCommenting/annotation - explain colleagues done","code":""},{"path":"r-basics.html","id":"commenting","chapter":"3 R Basics","heading":"Commenting","text":"script can also annotate (“comment”) around R code. Commenting helpful explain readers . can add comment typing hash symbol (#) writing comment . commented text appear different color R code.code written # run. Therefore, placing # code also useful way temporarily block line code (“comment ”) want delete ). can comment /multiple lines highlighting pressing Ctrl+Shift+c (Cmd+Shift+c Mac).Comment .Break code logical sectionsAccompany code text step--step description (e.g. numbered steps)","code":"\n# A comment can be on a line by itself\n# import data\nlinelist <- import(\"linelist_raw.xlsx\") %>%   # a comment can also come after code\n# filter(age > 50)                          # It can also be used to deactivate / remove a line of code\n  count()"},{"path":"r-basics.html","id":"style","chapter":"3 R Basics","heading":"Style","text":"important conscious coding style - especially working team. advocate tidyverse style guide. also packages styler lintr help conform style.basic points make code readable others:\n* naming objects, use lowercase letters, numbers, underscores _, e.g. my_data\n* Use frequent spaces, including around operators, e.g. n = 1 age_new <- age_old + 3","code":""},{"path":"r-basics.html","id":"example-script","chapter":"3 R Basics","heading":"Example Script","text":"example short R script. Remember, better succinctly explain code comments, colleagues like !","code":""},{"path":"r-basics.html","id":"r-markdown","chapter":"3 R Basics","heading":"R markdown","text":"R markdown script type R script script becomes output document (PDF, Word, HTML, Powerpoint, etc.). incredibly useful versatile tools often used create dynamic automated reports. Even website handbook produced R markdown scripts!worth noting beginner R users can also use R Markdown - intimidated! learn , see handbook page Reports R Markdown documents.","code":""},{"path":"r-basics.html","id":"r-notebooks","chapter":"3 R Basics","heading":"R notebooks","text":"difference writing Rmarkdown vs R notebook. However execution document differs slightly. See site details.","code":""},{"path":"r-basics.html","id":"shiny","chapter":"3 R Basics","heading":"Shiny","text":"Shiny apps/websites contained within one script, must named app.R. file three components:user interface (ui)server functionA call shinyApp functionSee handbook page Dashboards Shiny, online tutorial: Shiny tutorialIn older times, file split two files (ui.R server.R)","code":""},{"path":"r-basics.html","id":"code-folding","chapter":"3 R Basics","heading":"Code folding","text":"can collapse portions code make script easier read., create text header #, write header, follow least 4 either dashes (-), hashes (#) equals (=). done , small arrow appear “gutter” left (row number). can click arrow code next header collapse dual-arrow icon appear place.expand code, either click arrow gutter , dual-arrow icon. also keyboard shortcuts explained RStudio section page.creating headers #, also activate Table Contents bottom script (see ) can use navigate script. can create sub-headers adding # symbols, example # primary, ## seconary, ### tertiary headers.two versions example script. left original commented headers. right, four dashes written header, making collapsible. Two collapsed, can see Table Contents bottom now shows section.areas code automatically eligible folding include “braced” regions brackets { } function definitions conditional blocks (else statements). can read code folding RStudio site.","code":""},{"path":"r-basics.html","id":"working-directory","chapter":"3 R Basics","heading":"3.9 Working directory","text":"working directory root folder location used R work - R looks saves files default. default, save new files outputs location, look files import (e.g. datasets) well.working directory appears grey text top RStudio Console pane. can also print current working directory running getwd() (leave parentheses empty).","code":""},{"path":"r-basics.html","id":"recommended-approach","chapter":"3 R Basics","heading":"Recommended approach","text":"See page R projects details recommended approach managing working directory.\ncommon, efficient, trouble-free way manage working directory file paths combine 3 elements R project-oriented workflow:R Project store files (see page R projects)package locate files (see page Import export)rio package import/export files (see page Import export)","code":""},{"path":"r-basics.html","id":"set-by-command","chapter":"3 R Basics","heading":"Set by command","text":"recently, many people learning R taught begin scripts setwd() command. Please instead consider using R project-oriented workflow read reasons using setwd(). brief, work becomes specific computer, file paths used import export files become “brittle”, severely hinders collaboration use code computer. easy alternatives!noted , although recommend approach circumstances, can use command setwd() desired folder file path quotations, example:DANGER: Setting working directory setwd() can “brittle” file path specific one computer. Instead, use file paths relative R Project root directory (package).","code":"\nsetwd(\"C:/Documents/R Files/My analysis\")"},{"path":"r-basics.html","id":"set-manually","chapter":"3 R Basics","heading":"Set manually","text":"set working directory manually (point--click equivalent setwd()), click Session drop-menu go “Set Working Directory” “Choose Directory”. set working directory specific R session. Note: using approach, manually time open RStudio.","code":""},{"path":"r-basics.html","id":"within-an-r-project","chapter":"3 R Basics","heading":"Within an R project","text":"using R project, working directory default R project root folder contains “.rproj” file. apply open RStudio clicking open R Project (file “.rproj” extension).","code":""},{"path":"r-basics.html","id":"working-directory-in-an-r-markdown","chapter":"3 R Basics","heading":"Working directory in an R markdown","text":"R markdown script, default working directory folder Rmarkdown file (.Rmd) saved within. using R project package, apply working directory () explained R projects page.want change working directory stand-alone R markdown (R project), use setwd() apply specific code chunk. make change code chunks R markdown, edit setup chunk add root.dir = parameter, :much easier just use R markdown within R project use package.","code":"\nknitr::opts_knit$set(root.dir = 'desired/directorypath')"},{"path":"r-basics.html","id":"providing-file-paths","chapter":"3 R Basics","heading":"Providing file paths","text":"Perhaps common source frustration R beginner (least Windows machine) typing file path import export data. thorough explanation best input file paths Import export page, key points:Broken pathsBelow example “absolute” “full address” file path. likely break used another computer. One exception using shared/network drive.Slash directionIf typing file path, aware direction slashes. Use forward slashes (/) separate components (“data/provincial.csv”). Windows users, default way file paths displayed back slashes (\\) - need change direction slash. use package described R projects page slash direction issue.Relative file pathsWe generally recommend providing “relative” filepaths instead - , path relative root R Project. can using package explained R projects page. relativel filepath might look like :Even using relative file paths within R project, can still use absolute paths import/export data outside R project.","code":"C:/Users/Name/Document/Analytic Software/R/Projects/Analysis2019/data/March2019.csv  \n# Import csv linelist from the data/linelist/clean/ sub-folders of an R project\nlinelist <- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))"},{"path":"r-basics.html","id":"objects","chapter":"3 R Basics","heading":"3.10 Objects","text":"Everything R object, R “object-oriented” language. sections explain:create objects (<-)Types objects (e.g. data frames, vectors..)access subparts objects (e.g. variables dataset)Classes objects (e.g. numeric, logical, integer, double, character, factor)","code":""},{"path":"r-basics.html","id":"everything-is-an-object","chapter":"3 R Basics","heading":"Everything is an object","text":"section adapted R4Epis project.\nEverything store R - datasets, variables, list village names, total population number, even outputs graphs - objects assigned name can referenced later commands.object exists assigned value (see assignment section ). assigned value, object appears Environment (see upper right pane RStudio). can operated upon, manipulated, changed, re-defined.","code":""},{"path":"r-basics.html","id":"defining-objects--","chapter":"3 R Basics","heading":"Defining objects (<-)","text":"Create objects assigning value <- operator.\ncan think assignment operator <- words “defined ”. Assignment commands generally follow standard order:object_name <- value (process/calculation produce value)example, may want record current epidemiological reporting week object reference later code. example, object current_week created assigned value \"2018-W10\" (quote marks make character value). object current_week appear RStudio Environment pane (upper-right) can referenced later commands.See R commands output boxes .NOTE: Note [1] R console output simply indicating viewing first item outputCAUTION: object’s value can -written time running assignment command re-define value. Thus, order commands run important.following command re-define value current_week:Equals signs =also see equals signs R code:double equals sign == two objects values asks logical question: “equal ?”.also see equals signs within functions used specify values function arguments (read sections ), example max(age, na.rm = TRUE).can use single equals sign = place <- create define objects, discouraged. can read discouraged .DatasetsDatasets also objects (typically “dataframes”) must assigned names imported. code , object linelist created assigned value CSV file imported rio package import() function.can read importing exporting datasets section Import export.CAUTION: quick note naming objects:Object names must contain spaces, use underscore (_) period (.) instead space.Object names case-sensitive (meaning Dataset_A different dataset_A).Object names must begin letter (begin number like 1, 2 3).OutputsOutputs like tables plots provide example outputs can saved objects, just printed without saved. cross-tabulation gender outcome using base R function table() can printed directly R console (without saved).table can saved named object. , optionally, can printed.ColumnsColumns dataset also objects can defined, -written, created described section Columns.can use assignment operator base R create new column. , new column bmi (Body Mass Index) created, row new value result mathematical operation row’s value wt_kg ht_cm columns.However, handbook, emphasize different approach defining columns, uses function mutate() dplyr package piping pipe operator (%>%). syntax easier read advantages explained page Cleaning data core functions. can read piping Piping section .","code":"\ncurrent_week <- \"2018-W10\"   # this command creates the object current_week by assigning it a value\ncurrent_week                 # this command prints the current value of current_week object in the console## [1] \"2018-W10\"\ncurrent_week <- \"2018-W51\"   # assigns a NEW value to the object current_week\ncurrent_week                 # prints the current value of current_week in the console## [1] \"2018-W51\"\n# linelist is created and assigned the value of the imported CSV file\nlinelist <- import(\"my_linelist.csv\")\n# printed to R console only\ntable(linelist$gender, linelist$outcome)##    \n##     Death Recover\n##   f  1227     953\n##   m  1228     950\n# save\ngen_out_table <- table(linelist$gender, linelist$outcome)\n\n# print\ngen_out_table##    \n##     Death Recover\n##   f  1227     953\n##   m  1228     950\n# create new \"bmi\" column using base R syntax\nlinelist$bmi <- linelist$wt_kg / (linelist$ht_cm/100)^2\n# create new \"bmi\" column using dplyr syntax\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)"},{"path":"r-basics.html","id":"object-structure","chapter":"3 R Basics","heading":"Object structure","text":"Objects can single piece data (e.g. my_number <- 24), can consist structured data.graphic borrowed online R tutorial. shows common data structures names. included image spatial data, discussed GIS basics page.epidemiology (particularly field epidemiology), commonly encounter data frames vectors:Note create vector “stands alone” (part data frame) function c() used combine different elements. example, creating vector colors plot’s color scale: vector_of_colors <- c(\"blue\", \"red2\", \"orange\", \"grey\")","code":""},{"path":"r-basics.html","id":"object-classes","chapter":"3 R Basics","heading":"Object classes","text":"objects stored R class tells R handle object. many possible classes, common ones include:can test class object providing name function class(). Note: can reference specific column within dataset using $ notation separate name dataset name column.Sometimes, column converted different class automatically R. Watch ! example, vector column numbers, character value inserted… entire column change class character.One common example manipulating data frame order print table - make total row try paste/glue together percents cell numbers (e.g. 23 (40%)), entire numeric column convert character can longer used mathematical calculations.Sometimes, need convert objects columns another class.Likewise, base R functions check whether object specific class, .numeric(), .character(), .double(), .factor(), .integer()online material classes data structures R.","code":"\nclass(linelist)         # class should be a data frame or tibble## [1] \"data.frame\"\nclass(linelist$age)     # class should be numeric## [1] \"numeric\"\nclass(linelist$gender)  # class should be character## [1] \"character\"\nnum_vector <- c(1,2,3,4,5) # define vector as all numbers\nclass(num_vector)          # vector is numeric class## [1] \"numeric\"\nnum_vector[3] <- \"three\"   # convert the third element to a character\nclass(num_vector)          # vector is now character class## [1] \"character\""},{"path":"r-basics.html","id":"columnsvariables","chapter":"3 R Basics","heading":"Columns/Variables ($)","text":"column data frame technically “vector” (see table ) - series values must class (either character, numeric, logical, etc).vector can exist independent data frame, example vector column names want include explanatory variables model. create “stand alone” vector, use c() function :Columns data frame also vectors can called, referenced, extracted, created using $ symbol. $ symbol connects name column name data frame. handbook, try use word “column” instead “variable”.typing name dataframe followed $ also see drop-menu columns data frame. can scroll using arrow key, select one Enter key, avoid spelling mistakes!ADVANCED TIP: complex objects (e.g. list, epicontacts object) may multiple levels can accessed multiple dollar signs. example epicontacts$linelist$date_onset","code":"\n# define the stand-alone vector of character values\nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# print the values in this named vector\nexplanatory_vars## [1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\"\n# Retrieve the length of the vector age_years\nlength(linelist$age) # (age is a column in the linelist data frame)"},{"path":"r-basics.html","id":"accessindex-with-brackets","chapter":"3 R Basics","heading":"Access/index with brackets ([ ])","text":"may need view parts objects, also called “indexing”, often done using square brackets [ ]. Using $ dataframe access column also type indexing.Square brackets also work return specific parts returned output, output summary() function:Brackets also work data frames view specific rows columns. can using syntax dataframe[rows, columns]:Note can also achieve row/column indexing data frames tibbles using dplyr syntax (functions filter() rows, select() columns). Read core functions Cleaning data core functions page.filter based “row number”, can use dplyr function row_number() open parentheses part logical filtering statement. Often use %% operator range numbers part logical statement, shown . see first N rows, can also use special dplyr function head().indexing object class list, single brackets always return class list, even single object returned. Double brackets, however, can used access single element return different class list.\nBrackets can also written one another, demonstrated .visual explanation lists indexing, pepper shakers humorous helpful.list looks printed console. See two named elements:hospitals, character vectoraddresses, data frame addressesNow extract, using various methods:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")  # define the vector\nmy_vector[5]                                  # print the 5th element## [1] \"e\"\n# All of the summary\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.07   23.00   84.00      86\n# Just the second element of the summary, with name (using only single brackets)\nsummary(linelist$age)[2]## 1st Qu. \n##       6\n# Just the second element, without name (using double brackets)\nsummary(linelist$age)[[2]]## [1] 6\n# Extract an element by name, without showing the name\nsummary(linelist$age)[[\"Median\"]]## [1] 13\n# View a specific row (2) from dataset, with all columns (don't forget the comma!)\nlinelist[2,]\n\n# View all rows, but just one column\nlinelist[, \"date_onset\"]\n\n# View values from row 2 and columns 5 through 10\nlinelist[2, 5:10] \n\n# View values from row 2 and columns 5 through 10 and 18\nlinelist[2, c(5:10, 18)] \n\n# View rows 2 through 20, and specific columns\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# View rows and columns based on criteria\n# *** Note the dataframe must still be named in the criteria!\nlinelist[linelist$age > 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Use View() to see the outputs in the RStudio Viewer pane (easier to read) \n# *** Note the capital \"V\" in View() function\nView(linelist[2:20, \"date_onset\"])\n\n# Save as a new object\nnew_table <- linelist[2:20, c(\"date_onset\")] \n# View first 100 rows\nlinelist %>% head(100)\n\n# Show row 5 only\nlinelist %>% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns (note no quotes necessary on column names)\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)\n# define demo list\nmy_list <- list(\n  # First element in the list is a character vector\n  hospitals = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n  # second element in the list is a data frame of addresses\n  addresses   = data.frame(\n    street = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n    city   = c(\"Andover\", \"Hamilton\", \"El Paso\")\n    )\n  )\nmy_list## $hospitals\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\n## \n## $addresses\n##            street     city\n## 1 145 Medical Way  Andover\n## 2  1048 Brown Ave Hamilton\n## 3   999 El Camino  El Paso\nmy_list[1] # this returns the element in class \"list\" - the element name is still displayed## $hospitals\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[1]] # this returns only the (unnamed) character vector## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[\"hospitals\"]] # you can also index by name of the list element## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[1]][3] # this returns the third element of the \"hospitals\" character vector## [1] \"Santa Anna\"\nmy_list[[2]][1] # This returns the first column (\"street\") of the address data frame##            street\n## 1 145 Medical Way\n## 2  1048 Brown Ave\n## 3   999 El Camino"},{"path":"r-basics.html","id":"remove-objects","chapter":"3 R Basics","heading":"Remove objects","text":"can remove individual objects R environment putting name rm() function (quote marks):can remove objects (clear workspace) running:","code":"\nrm(object_name)\nrm(list = ls(all = TRUE))"},{"path":"r-basics.html","id":"piping","chapter":"3 R Basics","heading":"3.11 Piping (%>%)","text":"Two general approaches working objects :Pipes/tidyverse - pipes send object function function - emphasis action, objectDefine intermediate objects - object re-defined - emphasis object","code":""},{"path":"r-basics.html","id":"pipes","chapter":"3 R Basics","heading":"Pipes","text":"Simply explained, pipe operator (%>%) passes intermediate output one function next.\ncan think saying “”. Many functions can linked together %>%.Piping emphasizes sequence actions, object actions performed onPipes best sequence actions must performed one objectPipes come package magrittr, automatically included packages dplyr tidyversePipes can make code clean easier read, intuitiveRead approach tidyverse style guideHere fake example comparison, using fictional functions “bake cake”. First, pipe method:another link describing utility pipes.Piping base function. use piping, magrittr package must installed loaded (typically done loading tidyverse dplyr package include ). can read piping magrittr documentation.Note just like R commands, pipes can used just display result, save/re-save object, depending whether assignment operator <- involved. See :%<>%\n“assignment pipe” magrittr package, pipes object forward also re-defines object. must first pipe operator chain. shorthand. two commands equivalent:","code":"\n# A fake example of how to bake a cake using piping syntax\n\ncake <- flour %>%       # to define cake, start with flour, and then...\n  add(eggs) %>%   # add eggs\n  add(oil) %>%    # add oil\n  add(water) %>%  # add water\n  mix_together(         # mix together\n    utensil = spoon,\n    minutes = 2) %>%    \n  bake(degrees = 350,   # bake\n       system = \"fahrenheit\",\n       minutes = 35) %>%  \n  let_cool()            # let it cool down\n# Create or overwrite object, defining as aggregate counts by age category (not printed)\nlinelist_summary <- linelist %>% \n  count(age_cat)\n# Print the table of counts in the console, but don't save it\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\nlinelist <- linelist %>%\n  filter(age > 50)\n\nlinelist %<>% filter(age > 50)"},{"path":"r-basics.html","id":"define-intermediate-objects","chapter":"3 R Basics","heading":"Define intermediate objects","text":"approach changing objects/dataframes may better :need manipulate multiple objectsThere intermediate steps meaningful deserve separate object namesRisks:Creating new objects step means creating lots objects. use wrong one might realize !Naming objects can confusingErrors may easily detectableEither name intermediate object, overwrite original, combine functions together. come risks.fake “cake” example , using style:Combine functions together - difficult read:","code":"\n# a fake example of how to bake a cake using this method (defining intermediate objects)\nbatter_1 <- left_join(flour, eggs)\nbatter_2 <- left_join(batter_1, oil)\nbatter_3 <- left_join(batter_2, water)\n\nbatter_4 <- mix_together(object = batter_3, utensil = spoon, minutes = 2)\n\ncake <- bake(batter_4, degrees = 350, system = \"fahrenheit\", minutes = 35)\n\ncake <- let_cool(cake)\n# an example of combining/nesting mutliple functions together - difficult to read\ncake <- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = \"fahrenheit\", minutes = 35))"},{"path":"r-basics.html","id":"operators","chapter":"3 R Basics","heading":"3.12 Key operators and functions","text":"section details operators R, :Definitional operatorsRelational operators (less , equal ..)Logical operators (, …)Handling missing valuesMathematical operators functions (+/-, >, sum(), median(), …)%% operator","code":""},{"path":"r-basics.html","id":"assignment-operators","chapter":"3 R Basics","heading":"Assignment operators","text":"<-basic assignment operator R <-. object_name <- value.\nassignment operator can also written =. advise use <- general R use.\nalso advise surrounding operators spaces, readability.<<-Writing functions, using R interactive way sourced scripts, may need use assignment operator <<- (base R). operator used define object higher ‘parent’ R Environment. See online reference.%<>%“assignment pipe” magrittr package, pipes object forward also re-defines object. must first pipe operator chain. shorthand, shown two equivalent examples:equivalent :%<+%used add data phylogenetic trees ggtree package. See page Phylogenetic trees online resource book.","code":"\nlinelist <- linelist %>% \n  mutate(age_months = age_years * 12)\nlinelist %<>% mutate(age_months = age_years * 12)"},{"path":"r-basics.html","id":"relational-and-logical-operators","chapter":"3 R Basics","heading":"Relational and logical operators","text":"Relational operators compare values often used defining new variables subsets datasets. common relational operators R:Logical operators, , often used connect relational operators create complicated criteria. Complex statements might require parentheses ( ) grouping order application.example, , linelist two variables want use create case definition, hep_e_rdt, test result other_cases_in_hh, tell us cases household. command uses function case_when() create new variable case_def :Note R case-sensitive, “Positive” different “positive”…","code":"\nlinelist_cleaned <- linelist %>%\n  mutate(case_def = case_when(\n    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,\n    rdt_result == \"Positive\"                                 ~ \"Confirmed\",\n    rdt_result != \"Positive\" & other_cases_in_home == \"Yes\"  ~ \"Probable\",\n    TRUE                                                     ~ \"Suspected\"\n  ))"},{"path":"r-basics.html","id":"missing-values","chapter":"3 R Basics","heading":"Missing values","text":"R, missing values represented special value NA (“reserved” value) (capital letters N - quotation marks). import data records missing data another way (e.g. 99, “Missing”, .), may want re-code values NA. addressed Import export page.test whether value NA, use special function .na(), returns TRUE FALSE.Read missing, infinite, NULL, impossible values page Missing data. Learn convert missing values importing data page Import export.","code":"\nrdt_result <- c(\"Positive\", \"Suspected\", \"Positive\", NA)   # two positive cases, one suspected, and one unknown\nis.na(rdt_result)  # Tests whether the value of rdt_result is NA## [1] FALSE FALSE FALSE  TRUE"},{"path":"r-basics.html","id":"mathematics-and-statistics","chapter":"3 R Basics","heading":"Mathematics and statistics","text":"operators functions page automatically available using base R.","code":""},{"path":"r-basics.html","id":"mathematical-operators","chapter":"3 R Basics","heading":"Mathematical operators","text":"often used perform addition, division, create new columns, etc. common mathematical operators R. Whether put spaces around operators important.","code":""},{"path":"r-basics.html","id":"mathematical-functions","chapter":"3 R Basics","heading":"Mathematical functions","text":"Note: round() digits = specifies number decimal placed. Use signif() round number significant figures.","code":""},{"path":"r-basics.html","id":"scientific-notation","chapter":"3 R Basics","heading":"Scientific notation","text":"likelihood scientific notation used depends value scipen option.documentation ?options: scipen penalty applied deciding print numeric values fixed exponential notation. Positive values bias towards fixed negative towards scientific notation: fixed notation preferred unless ‘scipen’ digits wider.set low number (e.g. 0) “turned ” always. “turn ” scientific notation R session, set high number, example:","code":"\n# turn off scientific notation\noptions(scipen=999)"},{"path":"r-basics.html","id":"rounding","chapter":"3 R Basics","heading":"Rounding","text":"DANGER: round() uses “banker’s rounding” rounds .5 upper number even. Use round_half_up() janitor consistently round halves nearest whole number. See explanation","code":"\n# use the appropriate rounding function for your work\nround(c(2.5, 3.5))## [1] 2 4\njanitor::round_half_up(c(2.5, 3.5))## [1] 3 4"},{"path":"r-basics.html","id":"statistical-functions","chapter":"3 R Basics","heading":"Statistical functions","text":"CAUTION: functions default include missing values calculations. Missing values result output NA, unless argument na.rm = TRUE specified. can written shorthand na.rm = T.Notes:*quantile(): x numeric vector examine, probs = numeric vector probabilities within 0 1.0, e.g c(0.5, 0.8, 0.85)**summary(): gives summary numeric vector including mean, median, common percentilesDANGER: providing vector numbers one functions, sure wrap numbers within c() .","code":"\n# If supplying raw numbers to a function, wrap them in c()\nmean(1, 6, 12, 10, 5, 0)    # !!! INCORRECT !!!  ## [1] 1\nmean(c(1, 6, 12, 10, 5, 0)) # CORRECT## [1] 5.666667"},{"path":"r-basics.html","id":"other-useful-functions","chapter":"3 R Basics","heading":"Other useful functions","text":"","code":""},{"path":"r-basics.html","id":"in","chapter":"3 R Basics","heading":"%in%","text":"useful operator matching values, quickly assessing value within vector dataframe.ask value %% vector, put exclamation mark (!) front logic statement:%% useful using dplyr function case_when(). can define vector previously, reference later. example:Note: want detect partial string, perhaps using str_detect() stringr, accept character vector like c(\"1\", \"Yes\", \"yes\", \"y\"). Instead, must given regular expression - one condensed string bars, “1|Yes|yes|y”. example, str_detect(hospitalized, \"1|Yes|yes|y\"). See page Characters strings information.can convert character vector named regular expression command:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\")\n\"a\" %in% my_vector## [1] TRUE\n\"h\" %in% my_vector## [1] FALSE\n# to negate, put an exclamation in front\n!\"a\" %in% my_vector## [1] FALSE\n!\"h\" %in% my_vector## [1] TRUE\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist <- linelist %>% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age < 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative## [1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\"\n# condense to \naffirmative_str_search <- paste0(affirmative, collapse = \"|\")  # option with base R\naffirmative_str_search <- str_c(affirmative, collapse = \"|\")   # option with stringr package\n\naffirmative_str_search## [1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\""},{"path":"r-basics.html","id":"errors-warnings","chapter":"3 R Basics","heading":"3.13 Errors & warnings","text":"section explains:difference errors warningsGeneral syntax tips writing R codeCode assistsCommon errors warnings troubleshooting tips can found page [Errors help].","code":""},{"path":"r-basics.html","id":"error-versus-warning","chapter":"3 R Basics","heading":"Error versus Warning","text":"command run, R Console may show warning error messages red text.warning means R completed command, take additional steps produced unusual output aware .warning means R completed command, take additional steps produced unusual output aware .error means R able complete command.error means R able complete command.Look clues:error/warning message often include line number problem.error/warning message often include line number problem.object “unknown” “found”, perhaps spelled incorrectly, forgot call package library(), forgot re-run script making changes.object “unknown” “found”, perhaps spelled incorrectly, forgot call package library(), forgot re-run script making changes.else fails, copy error message Google along key terms - chances someone else worked already!","code":""},{"path":"r-basics.html","id":"general-syntax-tips","chapter":"3 R Basics","heading":"General syntax tips","text":"things remember writing commands R, avoid errors warnings:Always close parentheses - tip: count number opening “(” closing parentheses “)” code chunkAvoid spaces column object names. Use underscore ( _ ) periods ( . ) insteadKeep track remember separate function’s arguments commasR case-sensitive, meaning Variable_A different variable_A","code":""},{"path":"r-basics.html","id":"code-assists","chapter":"3 R Basics","heading":"Code assists","text":"script (RMarkdown otherwise) give clues made mistake. example, forgot write comma needed, close parentheses, RStudio raise flag line, right side script, warn .","code":""},{"path":"transition-to-r.html","id":"transition-to-r","chapter":"4 Transition to R","heading":"4 Transition to R","text":", provide advice resources transitioning R.R introduced late 1990s since grown dramatically scope. capabilities extensive commercial alternatives reacted R developments order stay competitive! (read article comparing R, SPSS, SAS, STATA, Python).Moreover, R much easier learn 10 years ago. Previously, R reputation difficult beginners. now much easier friendly user-interfaces like RStudio, intuitive code like tidyverse, many tutorial resources.intimidated - come discover world R!","code":""},{"path":"transition-to-r.html","id":"from-excel","chapter":"4 Transition to R","heading":"4.1 From Excel","text":"Transitioning Excel directly R achievable goal. may seem daunting, can !true someone strong Excel skills can advanced activities Excel alone - even using scripting tools like VBA. Excel used across world essential tool epidemiologist. However, complementing R can dramatically improve expand work flows.","code":""},{"path":"transition-to-r.html","id":"benefits","chapter":"4 Transition to R","heading":"Benefits","text":"find using R offers immense benefits time saved, consistent accurate analysis, reproducibility, shareability, faster error-correction. Like new software learning “curve” time must invest become familiar. dividends significant immense scope new possibilities open R.Excel well-known software can easy beginner use produce simple analysis visualizations “point--click”. comparison, can take couple weeks become comfortable R functions interface. However, R evolved recent years become much friendly beginners.Many Excel workflows rely memory repetition - thus, much opportunity error. Furthermore, generally data cleaning, analysis methodology, equations used hidden view. can require substantial time new colleague learn Excel workbook troubleshoot . R, steps explicitly written script can easily viewed, edited, corrected, applied datasets.begin transition Excel R must adjust mindset important ways:","code":""},{"path":"transition-to-r.html","id":"tidy-data","chapter":"4 Transition to R","heading":"Tidy data","text":"Use machine-readable “tidy” data instead messy “human-readable” data. three main requirements “tidy” data, explained tutorial “tidy” data R:variable must columnEach observation must rowEach value must cellTo Excel users - think role Excel “tables” play standardizing data making format predictable.example “tidy” data case linelist used throughout handbook - variable contained within one column, observation (one case) ’s row, every value just one cell. can view first 50 rows linelist:main reason one encounters non-tidy data many Excel spreadsheets designed prioritize easy reading humans, easy reading machines/software.help see difference, fictional examples non-tidy data prioritize human-readability machine-readability:Problems: spreadsheet , merged cells easily digested R. row considered “header” clear. color-based dictionary right side cell values represented colors - also easily interpreted R (humans color-blindness!). Furthermore, different pieces information combined one cell (multiple partner organizations working one area, status “TBC” cell “Partner D”).Problems: spreadsheet , numerous extra empty rows columns within dataset - cause cleaning headaches R. Furthermore, GPS coordinates spread across two rows given treatment center. side note - GPS coordinates two different formats!“Tidy” datasets may readable human eye, make data cleaning analysis much easier! Tidy data can stored various formats, example “long” “wide”“(see page Pivoting data), principles still observed.","code":""},{"path":"transition-to-r.html","id":"functions-1","chapter":"4 Transition to R","heading":"Functions","text":"R word “function” might new, concept exists Excel formulas. Formulas Excel also require precise syntax (e.g. placement semicolons parentheses). need learn new functions work together R.","code":""},{"path":"transition-to-r.html","id":"scripts-1","chapter":"4 Transition to R","heading":"Scripts","text":"Instead clicking buttons dragging cells writing every step procedure “script”.\nExcel users may familiar “VBA macros” also employ scripting approach.R script consists step--step instructions. allows colleague read script easily see steps took. also helps de-bug errors inaccurate calculations. See R basics section scripts examples.example R script:","code":""},{"path":"transition-to-r.html","id":"excel-to-r-resources","chapter":"4 Transition to R","heading":"Excel-to-R resources","text":"links tutorials help transition R Excel:R vs. ExcelRStudio course R Excel users","code":""},{"path":"transition-to-r.html","id":"r-excel-interaction","chapter":"4 Transition to R","heading":"R-Excel interaction","text":"R robust ways import Excel workbooks, work data, export/save Excel files, work nuances Excel sheets.true aesthetic Excel formatting can get lost translation (e.g. italics, sideways text, etc.). work flow requires passing documents back--forth R Excel retaining original Excel formatting, try packages openxlsx.","code":""},{"path":"transition-to-r.html","id":"from-stata","chapter":"4 Transition to R","heading":"4.2 From Stata","text":"Coming R StataMany epidemiologists first taught use Stata, can seem daunting move R. However, comfortable Stata user jump R certainly manageable might think. key differences Stata R data can created modified, well analysis functions implemented – learning key differences able translate skills.key translations Stata R, may handy review guide.General notesWorking directoryImporting viewing dataBasic data manipulationDescriptive analysisWhile list gives overview basics translating Stata commands R, exhaustive. many great resources Stata users transitioning R interest:https://dss.princeton.edu/training/RStata.pdfhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.htmlhttp://r4stats.com/books/r4stata/","code":""},{"path":"transition-to-r.html","id":"from-sas","chapter":"4 Transition to R","heading":"4.3 From SAS","text":"Coming SAS RSAS commonly used public health agencies academic research fields. Although transitioning new language rarely simple process, understanding key differences SAS R may help start navigate new language using native language.\noutlines key translations data management descriptive analysis SAS R.General notesWorking directoryImporting viewing dataBasic data manipulationDescriptive analysisSome useful resources:R SAS SPSS Users (2011)SAS R, Second Edition (2014)","code":""},{"path":"transition-to-r.html","id":"data-interoperability","chapter":"4 Transition to R","heading":"4.4 Data interoperability","text":"See Import export page details R package rio can import export files STATA .dta files, SAS .xpt .sas7bdat files, SPSS .por .sav files, many others.","code":""},{"path":"suggested-packages-1.html","id":"suggested-packages-1","chapter":"5 Suggested packages","heading":"5 Suggested packages","text":"long list suggested packages common epidemiological work R. can copy code, run , packages install CRAN load use current R session. package already installed, loaded use .can modify code # symbols exclude packages want.note:Install pacman package first running code. can install.packages(\"pacman\"). handbook emphasize p_load() pacman, installs package necessary loads use current R session. can also load packages already installed library() base R.code , packages included installing/loading another package indicated indent hash. example ggplot2 listed tidyverse.multiple packages functions name, masking can occur function recently-loaded package takes precedent. Read R basics page. Consider using package conflicted manage conflicts.See R basics section packages information pacman masking.see versions R, RStudio, R packages used production handbook, see page Editorial technical notes.","code":""},{"path":"suggested-packages-1.html","id":"packages-from-cran","chapter":"5 Suggested packages","heading":"5.1 Packages from CRAN","text":"","code":"\n##########################################\n# List of useful epidemiology R packages #\n##########################################\n\n# This script uses the p_load() function from pacman R package, \n# which installs if package is absent, and loads for use if already installed\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# Packages available from CRAN\n##############################\npacman::p_load(\n     \n     # learning R\n     ############\n     learnr,   # interactive tutorials in RStudio Tutorial pane\n     swirl,    # interactive tutorials in R console\n        \n     # project and file management\n     #############################\n     here,     # file paths relative to R project root folder\n     rio,      # import/export of many types of data\n     openxlsx, # import/export of multi-sheet Excel workbooks \n     \n     # package install and management\n     ################################\n     pacman,   # package install/load\n     renv,     # managing versions of packages when working in collaborative groups\n     remotes,  # install from github\n     \n     # General data management\n     #########################\n     tidyverse,    # includes many packages for tidy data wrangling and presentation\n          #dplyr,      # data management\n          #tidyr,      # data management\n          #ggplot2,    # data visualization\n          #stringr,    # work with strings and characters\n          #forcats,    # work with factors \n          #lubridate,  # work with dates\n          #purrr       # iteration and working with lists\n     linelist,     # cleaning linelists\n     naniar,       # assessing missing data\n     \n     # statistics  \n     ############\n     janitor,      # tables and data cleaning\n     gtsummary,    # making descriptive and statistical tables\n     rstatix,      # quickly run statistical tests and summaries\n     broom,        # tidy up results from regressions\n     lmtest,       # likelihood-ratio tests\n     easystats,\n          # parameters, # alternative to tidy up results from regressions\n          # see,        # alternative to visualise forest plots \n     \n     # epidemic modeling\n     ###################\n     epicontacts,  # Analysing transmission networks\n     EpiNow2,      # Rt estimation\n     EpiEstim,     # Rt estimation\n     projections,  # Incidence projections\n     incidence2,   # Make epicurves and handle incidence data\n     i2extras,     # Extra functions for the incidence2 package\n     epitrix,      # Useful epi functions\n     distcrete,    # Discrete delay distributions\n     \n     \n     # plots - general\n     #################\n     #ggplot2,         # included in tidyverse\n     cowplot,          # combining plots  \n     # patchwork,      # combining plots (alternative)     \n     RColorBrewer,     # color scales\n     ggnewscale,       # to add additional layers of color schemes\n\n     \n     # plots - specific types\n     ########################\n     DiagrammeR,       # diagrams using DOT language\n     incidence2,       # epidemic curves\n     gghighlight,      # highlight a subset\n     ggrepel,          # smart labels\n     plotly,           # interactive graphics\n     gganimate,        # animated graphics \n\n     \n     # gis\n     ######\n     sf,               # to manage spatial data using a Simple Feature format\n     tmap,             # to produce simple maps, works for both interactive and static maps\n     OpenStreetMap,    # to add OSM basemap in ggplot map\n     spdep,            # spatial statistics \n     \n     # routine reports\n     #################\n     rmarkdown,        # produce PDFs, Word Documents, Powerpoints, and HTML files\n     reportfactory,    # auto-organization of R Markdown outputs\n     officer,          # powerpoints\n     \n     # dashboards\n     ############\n     flexdashboard,    # convert an R Markdown script into a dashboard\n     shiny,            # interactive web apps\n     \n     # tables for presentation\n     #########################\n     knitr,            # R Markdown report generation and html tables\n     flextable,        # HTML tables\n     #DT,              # HTML tables (alternative)\n     #gt,              # HTML tables (alternative)\n     #huxtable,        # HTML tables (alternative) \n     \n     # phylogenetics\n     ###############\n     ggtree,           # visualization and annotation of trees\n     ape,              # analysis of phylogenetics and evolution\n     treeio            # to visualize phylogenetic files\n \n)"},{"path":"suggested-packages-1.html","id":"packages-from-github","chapter":"5 Suggested packages","heading":"5.2 Packages from Github","text":"commmands install two packages directly Github repositories.development version epicontacts contains ability make transmission trees temporal x-axisThe epirhandbook package contains example data handbook can used download offline version handbook.","code":"\n# Packages to download from Github (not available on CRAN)\n##########################################################\n\n# Development version of epicontacts (for transmission chains with a time x-axis)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# The package for this handbook, which includes all the example data  \npacman::p_install_gh(\"appliedepi/epirhandbook\")"},{"path":"r-projects.html","id":"r-projects","chapter":"6 R projects","heading":"6 R projects","text":"R project enables work bundled portable, self-contained folder. Within project, relevant scripts, data files, figures/outputs, history stored sub-folders importantly - working directory project’s root folder.","code":""},{"path":"r-projects.html","id":"suggested-use","chapter":"6 R projects","heading":"6.1 Suggested use","text":"common, efficient, trouble-free way use R combine 3 elements. One discrete work project hosted within one R project. element described sections .R project\nself-contained working environment folders data, scripts, outputs, etc.\nself-contained working environment folders data, scripts, outputs, etc.package relative filepaths\nFilepaths written relative root folder R project - see Import export information\nFilepaths written relative root folder R project - see Import export informationThe rio package importing/exporting\nimport() export() handle file type extension (e.g. .csv, .xlsx, .png)\nimport() export() handle file type extension (e.g. .csv, .xlsx, .png)","code":""},{"path":"r-projects.html","id":"creating-an-r-project","chapter":"6 R projects","heading":"6.2 Creating an R project","text":"create R project, select “New Project” File menu.want create new folder project, select “New directory” indicate want created.want create project within existing folder, click “Existing directory” indicate folder.want clone Github repository, select third option “Version Control” “Git”. See page Version control collaboration Git Github details.R project create come form folder containing .Rproj file. file shortcut likely primary way open project. can also open project selecting “Open Project” File menu. Alternatively far upper right side RStudio see R project icon drop-menu available R projects.exit R project, either open new project, close project (File - Close Project).","code":""},{"path":"r-projects.html","id":"switch-projects","chapter":"6 R projects","heading":"Switch projects","text":"switch projects, click R project icon drop-menu top-right RStudio. see options Close Project, Open Project, list recent projects.","code":""},{"path":"r-projects.html","id":"settings","chapter":"6 R projects","heading":"Settings","text":"generally advised start RStudio time “clean slate” - , workspace preserved previous session. mean objects results persist session--session (must re-create running scripts). good, force write better scripts avoid errors long run.set RStudio “clean slate” time start-:Select “Project Options” Tools menu.“General” tab, set RStudio restore .RData workspace startup, save workspace .RData exit.","code":""},{"path":"r-projects.html","id":"organization","chapter":"6 R projects","heading":"Organization","text":"common subfolders project. Consider folders “data”, “scripts”, “figures”, “presentations”. can add folders typical way add new folder computer. Alternatively, see page Directory interactions learn create new folders R commands.","code":""},{"path":"r-projects.html","id":"version-control","chapter":"6 R projects","heading":"Version control","text":"Consider version control system. something simple dates names scripts (e.g. “transmission_analysis_2020-10-03.R”) “archive” folder. Consider also commented header text top script description, tags, authors, change log.complicated method involve using Github similar platform version control. See page Version control collaboration Git Github.One tip can search across entire project folder using “Find Files” tool (Edit menu). can search even replace strings across multiple files.","code":""},{"path":"r-projects.html","id":"examples","chapter":"6 R projects","heading":"6.3 Examples","text":"examples import/export/saving using () within R projct. Read using package Import export page.Importing linelist_raw.xlsx “data” folder R projectExporting R object linelist “my_linelist.rds” “clean” folder within “data” folder R project.Saving recently printed plot “epicurve_2021-02-15.png” within “epicurves” folder “outputs” folder R project.","code":"\nlinelist <- import(here(\"data\", \"linelist_raw.xlsx\"))\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))"},{"path":"r-projects.html","id":"resources","chapter":"6 R projects","heading":"6.4 Resources","text":"RStudio webpage using R projects","code":""},{"path":"import-and-export.html","id":"import-and-export","chapter":"7 Import and export","heading":"7 Import and export","text":"page describe ways locate, import, export files:Use rio package flexibly import() export() many types filesUse package locate files relative R project root - prevent complications file paths specific one computerSpecific import scenarios, :\nSpecific Excel sheets\nMessy headers skipping rows\nGoogle sheets\ndata posted websites\nAPIs\nImporting recent file\nSpecific Excel sheetsMessy headers skipping rowsFrom Google sheetsFrom data posted websitesWith APIsImporting recent fileManual data entryR-specific file types RDS RDataExporting/saving files plots","code":""},{"path":"import-and-export.html","id":"overview","chapter":"7 Import and export","heading":"7.1 Overview","text":"import “dataset” R, generally creating new data frame object R environment defining imported file (e.g. Excel, CSV, TSV, RDS) located folder directories certain file path/address.can import/export many types files, including created statistical programs (SAS, STATA, SPSS). can also connect relational databases.R even data formats:RDS file (.rds) stores single R object data frame. useful store cleaned data, maintain R column classes. Read section.RData file (.Rdata) can used store multiple objects, even complete R workspace. Read section.","code":""},{"path":"import-and-export.html","id":"the-rio-package","chapter":"7 Import and export","heading":"7.2 The rio package","text":"R package recommend : rio. name “rio” abbreviation “R /O” (input/output).functions import() export() can handle many different file types (e.g. .xlsx, .csv, .rds, .tsv). provide file path either functions (including file extension like “.csv”), rio read extension use correct tool import export file.alternative using rio use functions many packages, specific type file. example, read.csv() (base R), read.xlsx() (openxlsx package), write_csv() (readr pacakge), etc. alternatives can difficult remember, whereas using import() export() rio easy.rio’s functions import() export() use appropriate package function given file, based file extension. See end page complete table packages/functions rio uses background. can also used import STATA, SAS, SPSS files, among dozens file types.Import/export shapefiles requires packages, detailed page GIS basics.","code":""},{"path":"import-and-export.html","id":"here","chapter":"7 Import and export","heading":"7.3 The here package","text":"package function () make easy tell R find save files - essence, builds file paths.Used conjunction R project, allows describe location files R project relation R project’s root directory (top-level folder). useful R project may shared accessed multiple people/computers. prevents complications due unique file paths different computers (e.g. \"C:/Users/Laura/Documents...\" “starting” file path place common users (R project root).() works within R project:package first loaded within R project, places small file called “.” root folder R project “benchmark” “anchor”scripts, reference file R project’s sub-folders, use function () build file path relation anchorTo build file path, write names folders beyond root, within quotes, separated commas, finally ending file name file extension shown belowhere() file paths can used importing exportingFor example, , function import() provided file path constructed ().command (\"data\", \"linelists\", \"ebola_linelist.xlsx\") actually providing full file path unique user’s computer:beauty R command using () can successfully run computer accessing R project.TIP: unsure “.” root set , run function () empty parentheses.Read package link.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\""},{"path":"import-and-export.html","id":"file-paths","chapter":"7 Import and export","heading":"7.4 File paths","text":"importing exporting data, must provide file path. can one three ways:Recommended: provide “relative” file path packageProvide “full” / “absolute” file pathManual file selection","code":""},{"path":"import-and-export.html","id":"relative-file-paths","chapter":"7 Import and export","heading":"“Relative” file paths","text":"R, “relative” file paths consist file path relative root R project. allow simple file paths can work different computers (e.g. R project shared drive sent email). described , relative file paths facilitated use package.example relative file path constructed () . assume work R project contains sub-folder “data” within subfolder “linelists”, .xlsx file interest.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))"},{"path":"import-and-export.html","id":"absolute-file-paths","chapter":"7 Import and export","heading":"“Absolute” file paths","text":"Absolute “full” file paths can provided functions like import() “fragile” unique user’s specific computer therefore recommended.example absolute file path, Laura’s computer folder “analysis”, sub-folder “data” within sub-folder “linelists”, .xlsx file interest.things note absolute file paths:Avoid using absolute file paths break script run different computerUse forward slashes (/), example (note: default Windows file paths)File paths begin double slashes (e.g. “//…”) likely recognized R produce error. Consider moving work “named” “lettered” drive begins letter (e.g. “J:” “C:”). See page Directory interactions details issue.One scenario absolute file paths may appropriate want import file shared drive full file path users.TIP: quickly convert \\ /, highlight code interest, use Ctrl+f (Windows), check option box “selection”, use replace functionality convert .","code":"\nlinelist <- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")"},{"path":"import-and-export.html","id":"select-file-manually","chapter":"7 Import and export","heading":"Select file manually","text":"can import data manually via one methods:Environment RStudio Pane, click “Import Dataset”, select type dataClick File / Import Dataset / (select type data)hard-code manual selection, use base R command file.choose() (leaving parentheses empty) trigger appearance pop-window allows user manually select file computer. example:TIP: pop-window may appear BEHIND RStudio window.","code":"\n# Manual selection of a file. When this command is run, a POP-UP window will appear. \n# The file path selected will be supplied to the import() command.\n\nmy_data <- import(file.choose())"},{"path":"import-and-export.html","id":"import-data","chapter":"7 Import and export","heading":"7.5 Import data","text":"use import() import dataset quite simple. Simply provide path file (including file name file extension) quotes. using () build file path, follow instructions . examples:Importing csv file located “working directory” R project root folder:Importing first sheet Excel workbook located “data” “linelists” sub-folders R project (file path built using ()):Importing data frame (.rds file) using absolute file path:","code":"\nlinelist <- import(\"linelist_cleaned.csv\")\nlinelist <- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\nlinelist <- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")"},{"path":"import-and-export.html","id":"specific-excel-sheets","chapter":"7 Import and export","heading":"Specific Excel sheets","text":"default, provide Excel workbook (.xlsx) import(), workbook’s first sheet imported. want import specific sheet, include sheet name = argument. example:using () method provide relative pathway import(), can still indicate specific sheet adding = argument closing parentheses () function.export data frame R specific Excel sheet rest Excel workbook remain unchanged, import, edit, export alternative package catered purpose openxlsx. See information page Directory interactions github page.Excel workbook .xlsb (binary format Excel workbook) may able import using rio. Consider re-saving .xlsx, using package like readxlsb built purpose.","code":"\nmy_data <- import(\"my_excel_file.xlsx\", which = \"Sheetname\")# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\nlinelist_raw <- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  "},{"path":"import-and-export.html","id":"import_missing","chapter":"7 Import and export","heading":"Missing values","text":"may want designate value(s) dataset considered missing. explained page Missing data, value R missing data NA, perhaps dataset want import uses 99, “Missing”, just empty character space “” instead.Use na = argument import() provide value(s) within quotes (even numbers). can specify multiple values including within vector, using c() shown ., value “99” imported dataset considered missing converted NA R., values “Missing”, “” (empty cell), ” ” (single space) imported dataset converted NA R.","code":"\nlinelist <- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\nlinelist <- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))"},{"path":"import-and-export.html","id":"skip-rows","chapter":"7 Import and export","heading":"Skip rows","text":"Sometimes, may want avoid importing row data. can argument skip = using import() rio .xlsx .csv file. Provide number rows want skip.Unfortunately skip = accepts one integer value, range (e.g. “2:10” work). skip import specific rows consecutive top, consider importing multiple times using bind_rows() dplyr. See example skipping row 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row"},{"path":"import-and-export.html","id":"manage-a-second-header-row","chapter":"7 Import and export","heading":"Manage a second header row","text":"Sometimes, data may second row, example “data dictionary” row shown . situation can problematic can result columns imported class “character”.example kind dataset (first row data dictionary).","code":""},{"path":"import-and-export.html","id":"remove-the-second-header-row","chapter":"7 Import and export","heading":"Remove the second header row","text":"drop second header row, likely need import data twice.Import data order store correct column namesImport data , skipping first two rows (header second rows)Bind correct names onto reduced dataframeThe exact argument used bind correct column names depends type data file (.csv, .tsv, .xlsx, etc.). rio using different function different file types (see table ).Excel files: (col_names =)CSV files: (col.names =)Backup option - changing column names separate command","code":"\n# import first time; store the column names\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # save true column names\n\n# import second time; skip row 2, and assign column names to argument col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n# import first time; sotre column names\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# note argument for csv files is 'col.names = '\nlinelist_raw <- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"import-and-export.html","id":"make-a-data-dictionary","chapter":"7 Import and export","heading":"Make a data dictionary","text":"Bonus! second row data dictionary, can easily create proper data dictionary . tip adapted post.","code":"\ndict <- linelist_2headers %>%             # begin: linelist with dictionary as first row\n  head(1) %>%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")"},{"path":"import-and-export.html","id":"combine-the-two-header-rows","chapter":"7 Import and export","heading":"Combine the two header rows","text":"cases raw dataset two header rows (specifically, 2nd row data secondary header), may want “combine” add values second header row first header row.command define data frame’s column names combination (pasting together) first (true) headers value immediately underneath (first row).","code":"\nnames(my_data) <- paste(names(my_data), my_data[1, ], sep = \"_\")"},{"path":"import-and-export.html","id":"google-sheets","chapter":"7 Import and export","heading":"Google sheets","text":"can import data online Google spreadsheet googlesheet4 package authenticating access spreadsheet., demo Google sheet imported saved. command may prompt confirmation authentification Google account. Follow prompts pop-ups internet browser grant Tidyverse API packages permissions edit, create, delete spreadsheets Google Drive.sheet “viewable anyone link” can try import .sheet can also imported using sheet ID, shorter part URL:Another package, googledrive offers useful functions writing, editing, deleting Google sheets. example, using gs4_create() sheet_write() functions found package.helpful online tutorials:basic Google sheets importing tutorialmore detailed tutorialinteraction googlesheets4 tidyverse","code":"\npacman::p_load(\"googlesheets4\")\nGsheets_demo <- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\nGsheets_demo <- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")"},{"path":"import-and-export.html","id":"multiple-files---import-export-split-combine","chapter":"7 Import and export","heading":"7.6 Multiple files - import, export, split, combine","text":"See page Iteration, loops, lists examples import combine multiple files, multiple Excel workbook files. page also examples split data frame parts export one separately, named sheets Excel workbook.","code":""},{"path":"import-and-export.html","id":"import_github","chapter":"7 Import and export","heading":"7.7 Import from Github","text":"Importing data directly Github R can easy can require steps - depending file type. approaches:","code":""},{"path":"import-and-export.html","id":"csv-files","chapter":"7 Import and export","heading":"CSV files","text":"can easy import .csv file directly Github R R command.Go Github repo, locate file interest, click itClick “Raw” button (see “raw” csv data, shown )Copy URL (web address)Place URL quotes within import() R command","code":""},{"path":"import-and-export.html","id":"xlsx-files","chapter":"7 Import and export","heading":"XLSX files","text":"may able view “Raw” data files (e.g. .xlsx, .rds, .nwk, .shp)Go Github repo, locate file interest, click itClick “Download” button, shown belowSave file computer, import R","code":""},{"path":"import-and-export.html","id":"shapefiles","chapter":"7 Import and export","heading":"Shapefiles","text":"Shapefiles many sub-component files, different file extention. One file “.shp” extension, others may “.dbf”, “.prj”, etc. download shapefile Github, need download sub-component files individually, save folder computer. Github, click file individually download clicking “Download” button.saved computer can import shapefile shown GIS basics page using st_read() sf package. need provide filepath name “.shp” file - long related files within folder computer., can see shapefile “sle_adm3” consists many files - must downloaded Github.","code":""},{"path":"import-and-export.html","id":"manual-data-entry","chapter":"7 Import and export","heading":"7.8 Manual data entry","text":"","code":""},{"path":"import-and-export.html","id":"entry-by-rows","chapter":"7 Import and export","heading":"Entry by rows","text":"Use tribble function tibble package tidyverse (online tibble reference).Note column headers start tilde (~). Also note column must contain one class data (character, numeric, etc.). can use tabs, spacing, new rows make data entry intuitive readable. Spaces matter values, row represented new line code. example:now display new dataset:","code":"\n# create the dataset manually by row\nmanual_entry_rows <- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )"},{"path":"import-and-export.html","id":"entry-by-columns","chapter":"7 Import and export","heading":"Entry by columns","text":"Since data frame consists vectors (vertical columns), base approach manual dataframe creation R expects define column bind together. can counter-intuitive epidemiology, usually think data rows ().CAUTION: vectors must length (number values).vectors can bound together using function data.frame():now display new dataset:","code":"\n# define each vector (vertical column) separately, each with its own name\nPatientID <- c(235, 452, 778, 111)\nTreatment <- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     <- c(1, 0, 1, 0)\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols <- data.frame(PatientID, Treatment, Death)"},{"path":"import-and-export.html","id":"pasting-from-clipboard","chapter":"7 Import and export","heading":"Pasting from clipboard","text":"copy data elsewhere clipboard, can try one two ways :clipr package, can use read_clip_tbl() import data frame, just just read_clip() import character vector. cases, leave parentheses empty.can also easily export system’s clipboard clipr. See section Export.Alternatively, can use read.table() function base R file = \"clipboard\") import data frame:","code":"\nlinelist <- clipr::read_clip_tbl()  # imports current clipboard as data frame\nlinelist <- clipr::read_clip()      # imports as character vector\ndf_from_clipboard <- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row"},{"path":"import-and-export.html","id":"import-most-recent-file","chapter":"7 Import and export","heading":"7.9 Import most recent file","text":"Often may receive daily updates datasets. case want write code imports recent file. present two ways approach :Selecting file based date file nameSelecting file based file metadata (last modification)","code":""},{"path":"import-and-export.html","id":"dates-in-file-name","chapter":"7 Import and export","heading":"Dates in file name","text":"approach depends three premises:trust dates file namesThe dates numeric appear generally format (e.g. year month day)numbers file nameWe explain step, show combined end.First, use dir() base R extract just file names file folder interest. See page Directory interactions details dir(). example, folder interest folder “linelists” within folder “example” within “data” within R project.vector names, can extract dates applying str_extract() stringr using regular expression. extracts numbers file name (including characters middle dashes slashes). can read stringr [Strings characters] page.Assuming dates written generally date format (e.g. Year Month Day) years 4-digits, can use lubridate’s flexible conversion functions (ymd(), dmy(), mdy()) convert dates. functions, dashes, spaces, slashes matter, order numbers. Read Working dates page.base R function .max() can used return index position (e.g. 1st, 2nd, 3rd, …) maximum date value. latest file correctly identified 6th file - “case_linelist_2020-10-08.xlsx”.condense commands, complete code look like . Note . last line placeholder piped object point pipe sequence. point value simply number 6. placed double brackets extract 6th element vector file names produced dir().can now use name finish relative file path, ():can now import latest file:","code":"\nlinelist_filenames <- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print## [1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\"  \"case_linelist_2020-10-03.csv\" \n## [4] \"case_linelist_2020-10-04.csv\"  \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n## [7] \"case_linelist20201006.csv\"\nlinelist_dates_raw <- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print## [1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"20201006\"\nlinelist_dates_clean <- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean## [1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"2020-10-06\"\nindex_latest_file <- which.max(linelist_dates_clean)\nindex_latest_file## [1] 6\n# load packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extract the file name of latest file\nlatest_file <- dir(here(\"data\", \"example\", \"linelists\")) %>%  # file names from \"linelists\" sub-folder          \n  str_extract(\"[0-9].*[0-9]\") %>%                  # pull out dates (numbers)\n  ymd() %>%                                        # convert numbers to dates (assuming year-month-day format)\n  which.max() %>%                                  # get index of max date (latest file)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # return the filename of latest linelist\n\nlatest_file  # print name of latest file## [1] \"case_linelist_2020-10-08.xlsx\"\nhere(\"data\", \"example\", \"linelists\", latest_file) \n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import "},{"path":"import-and-export.html","id":"use-the-file-info","chapter":"7 Import and export","heading":"Use the file info","text":"files dates names (trust dates), can try extract last modification date file metadata. Use functions package fs examine metadata information file, includes last modification time file path., provide folder interest fs’s dir_info(). case, folder interest R project folder “data”, sub-folder “example”, sub-folder “linelists”. result data frame one line per file columns modification_time, path, etc. can see visual example page Directory interactions.can sort data frame files column modification_time, keep top/latest row (file) base R’s head(). can extract file path latest file dplyr function pull() column path. Finally can pass file path import(). imported file saved latest_file.","code":"\nlatest_file <- dir_info(here(\"data\", \"example\", \"linelists\")) %>%  # collect file info on all files in directory\n  arrange(desc(modification_time)) %>%      # sort by modification time\n  head(1) %>%                               # keep only the top (latest) file\n  pull(path) %>%                            # extract only the file path\n  import()                                  # import the file"},{"path":"import-and-export.html","id":"import_api","chapter":"7 Import and export","heading":"7.10 APIs","text":"“Automated Programming Interface” (API) can used directly request data website. APIs set rules allow one software application interact another. client () sends “request” receives “response” containing content. R packages httr jsonlite can facilitate process.API-enabled website documentation specifics become familiar . sites publicly available can accessed anyone. Others, platforms user IDs credentials, require authentication access data.Needless say, necessary internet connection import data via API. briefly give examples use APIs import data, link resources.Note: recall data may posted* website without API, may easier retrieve. example posted CSV file may accessible simply providing site URL import() described section importing Github.*","code":""},{"path":"import-and-export.html","id":"http-request","chapter":"7 Import and export","heading":"HTTP request","text":"API exchange commonly done HTTP request. HTTP Hypertext Transfer Protocol, underlying format request/response client server. exact input output may vary depending type API process - “Request” (often HTTP Request) user, often containing query, followed “Response”, containing status information request possibly requested content.components HTTP request:URL API endpointThe “Method” (“Verb”)HeadersBodyThe HTTP request “method” action want perform. two common HTTP methods GET POST others include PUT, DELETE, PATCH, etc. importing data R likely use GET.request, computer receive “response” format similar sent, including URL, HTTP status (Status 200 want!), file type, size, desired content. need parse response turn workable data frame within R environment.","code":""},{"path":"import-and-export.html","id":"packages-1","chapter":"7 Import and export","heading":"Packages","text":"httr package works well handling HTTP requests R. requires little prior knowledge Web APIs can used people less familiar software development terminology. addition, HTTP response .json, can use jsonlite parse response.","code":"\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)"},{"path":"import-and-export.html","id":"publicly-available-data","chapter":"7 Import and export","heading":"Publicly-available data","text":"example HTTP request, borrowed tutorial Trafford Data Lab. site several resources learn API exercises.Scenario: want import list fast food outlets city Trafford, UK. data can accessed API Food Standards Agency, provides food hygiene rating data United Kingdom.parameters request:HTTP verb: GETAPI endpoint URL: http://api.ratings.food.gov.uk/EstablishmentsSelected parameters: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityIdHeaders: “x-api-version”, 2Data format(s): JSON, XMLDocumentation: http://api.ratings.food.gov.uk/helpThe R code follows:can now clean use response data frame, contains one row per fast food facility.","code":"\n# prepare the request\npath <- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest <- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# check for any server error (\"200\" is good!)\nrequest$status_code\n\n# submit the request, parse the response, and convert to a data frame\nresponse <- content(request, as = \"text\", encoding = \"UTF-8\") %>%\n  fromJSON(flatten = TRUE) %>%\n  pluck(\"establishments\") %>%\n  as_tibble()"},{"path":"import-and-export.html","id":"authentication-required","chapter":"7 Import and export","heading":"Authentication required","text":"APIs require authentication - prove , can access restricted data. import data, may need first use POST method provide username, password, code. return access token, can used subsequent GET method requests retrieve desired data.example querying data Go.Data, outbreak investigation tool. Go.Data uses API interactions web front-end smartphone applications used data collection. Go.Data used throughout world. outbreak data sensitive able access data outbreak, authentication required.sample R code using httr jsonlite connecting Go.Data API import data contact follow-outbreak.CAUTION: importing large amounts data API requiring authentication, may time-. avoid , retrieve access_token API GET request try using filters limits query. TIP: fromJSON() function jsonlite package fully un-nest first time ’s executed, likely still list items resulting tibble. need un-nest certain variables; depending nested .json . view info , view documentation jsonlite package, flatten() function. details, View documentation LoopBack Explorer, Contact Tracing page API tips Go.Data Github repositoryYou can read httr package hereThis section also informed tutorial tutorial.","code":"\n# set credentials for authorization\nurl <- \"https://godatasampleURL.int/\"           # valid Go.Data instance url\nusername <- \"username\"                          # valid Go.Data username \npassword <- \"password\"                          # valid Go,Data password \noutbreak_id <- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # valid Go.Data outbreak ID\n\n# get access token\nurl_request <- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# prepare request\nresponse <- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # use saved username/password from above to authorize                               \n    password = password),                                       \n    encode = \"json\")\n\n# execute request and parse response\ncontent <-\n  content(response, as = \"text\") %>%\n  fromJSON(flatten = TRUE) %>%          # flatten nested JSON\n  glimpse()\n\n# Save access token from response\naccess_token <- content$access_token    # save access token to allow subsequent API calls below\n\n# import outbreak contacts\n# Use the access token \nresponse_contacts <- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # GET request\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts <- content(response_contacts, as = \"text\")         # convert to text JSON\n\ncontacts <- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # flatten JSON to tibble"},{"path":"import-and-export.html","id":"export","chapter":"7 Import and export","heading":"7.11 Export","text":"","code":""},{"path":"import-and-export.html","id":"with-rio-package","chapter":"7 Import and export","heading":"With rio package","text":"rio, can use export() function similar way import(). First give name R object want save (e.g. linelist) quotes put file path want save file, including desired file name file extension. example:saves data frame linelist Excel workbook working directory/R project root folder:save data frame csv file changing extension. example, also save file path constructed ():","code":"\nexport(linelist, \"my_linelist.xlsx\") # will save to working directory\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))"},{"path":"import-and-export.html","id":"to-clipboard","chapter":"7 Import and export","heading":"To clipboard","text":"export data frame computer’s “clipboard” (paste another software like Excel, Google Spreadsheets, etc.) can use write_clip() clipr package.","code":"\n# export the linelist data frame to your system's clipboard\nclipr::write_clip(linelist)"},{"path":"import-and-export.html","id":"import_rds","chapter":"7 Import and export","heading":"7.12 RDS files","text":"Along .csv, .xlsx, etc, can also export/save R data frames .rds files. file format specific R, useful know work exported data R.classes columns stored, don’t cleaning imported (Excel even CSV file can headache!). also smaller file, useful export import dataset large.example, work Epidemiology team need send files GIS team mapping, use R well, just send .rds file! column classes retained less work .","code":"\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))"},{"path":"import-and-export.html","id":"import_rdata","chapter":"7 Import and export","heading":"7.13 Rdata files and lists","text":".Rdata files can store multiple R objects - example multiple data frames, model results, lists, etc. can useful consolidate share lot data given project.example, multiple R objects stored within exported file “my_objects.Rdata”:Note: trying import list, use import_list() rio import complete original structure contents.","code":"\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\nrio::import_list(\"my_list.Rdata\")"},{"path":"import-and-export.html","id":"saving-plots","chapter":"7 Import and export","heading":"7.14 Saving plots","text":"Instructions save plots, created ggplot(), discussed depth ggplot basics page.brief, run ggsave(\"my_plot_filepath_and_name.png\") printing plot. can either provide saved plot object plot = argument, specify destination file path (file extension) save recently-displayed plot. can also control width =, height =, units =, dpi =.save network graph, transmission tree, addressed page Transmission chains.","code":""},{"path":"import-and-export.html","id":"resources-1","chapter":"7 Import and export","heading":"7.15 Resources","text":"R Data Import/Export ManualR 4 Data Science chapter data importggsave() documentationBelow table, taken rio online vignette. type data shows: expected file extension, package rio uses import export data, whether functionality included default installed version rio.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-data-and-core-functions","chapter":"8 Cleaning data and core functions","heading":"8 Cleaning data and core functions","text":"page demonstrates common steps used process “cleaning” dataset, also explains use many essential R data management functions.demonstrate data cleaning, page begins importing raw case linelist dataset, proceeds step--step cleaning process. R code, manifests “pipe” chain, references “pipe” operator %>% passes dataset one operation next.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"core-functions","chapter":"8 Cleaning data and core functions","heading":"Core functions","text":"handbook emphasizes use functions tidyverse family R packages. essential R functions demonstrated page listed .Many functions belong dplyr R package, provides “verb” functions solve data manipulation challenges (name reference “data frame-plier. dplyr part tidyverse family R packages (also includes ggplot2, tidyr, stringr, tibble, purrr, magrittr, forcats among others).want see functions compare Stata SAS commands, see page Transition R.may encounter alternative data management framework data.table R package operators like := frequent use brackets [ ]. approach syntax briefly explained Data Table page.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"nomenclature-1","chapter":"8 Cleaning data and core functions","heading":"Nomenclature","text":"handbook, generally reference “columns” “rows” instead “variables” “observations”. explained primer “tidy data”, epidemiological statistical datasets consist structurally rows, columns, values.Variables contain values measure underlying attribute (like age group, outcome, date onset). Observations contain values measured unit (e.g. person, site, lab sample). aspects can difficult tangibly define.“tidy” datasets, column variable, row observation, cell single value. However datasets encounter fit mold - “wide” format dataset may variable split across several columns (see example Pivoting data page). Likewise, observations split across several rows.handbook managing transforming data, referring concrete data structures rows columns relevant abstract observations variables. Exceptions occur primarily pages data analysis, see references variables observations.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-pipeline","chapter":"8 Cleaning data and core functions","heading":"8.1 Cleaning pipeline","text":"page proceeds typical cleaning steps, adding sequentially cleaning pipe chain.epidemiological analysis data processing, cleaning steps often performed sequentially, linked together. R, often manifests cleaning “pipeline”, raw dataset passed “piped” one cleaning step another.chains utilize dplyr “verb” functions magrittr pipe operator %>%. pipe begins “raw” data (“linelist_raw.xlsx”) ends “clean” R data frame (linelist) can used, saved, exported, etc.cleaning pipeline order steps important. Cleaning steps might include:Importing dataColumn names cleaned changedDe-duplicationColumn creation transformation (e.g. re-coding standardising values)Rows filtered added","code":""},{"path":"cleaning-data-and-core-functions.html","id":"load-packages","chapter":"8 Cleaning data and core functions","heading":"8.2 Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  matchmaker, # dictionary-based cleaning\n  epikit,     # age_categories() function\n  tidyverse   # data management and visualization\n)"},{"path":"cleaning-data-and-core-functions.html","id":"import-data-1","chapter":"8 Cleaning data and core functions","heading":"8.3 Import data","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"import","chapter":"8 Cleaning data and core functions","heading":"Import","text":"import “raw” case linelist Excel file using import() function package rio. rio package flexibly handles many types files (e.g. .xlsx, .csv, .tsv, .rds. See page Import export information tips unusual situations (e.g. skipping rows, setting missing values, importing Google sheets, etc).want follow along, click download “raw” linelist (.xlsx file).dataset large takes long time import, can useful import command separate pipe chain “raw” saved distinct file. also allows easy comparison original cleaned versions.import raw Excel file save data frame linelist_raw. assume file located working directory R project root, sub-folders specified file path.can view first 50 rows data frame . Note: base R function head(n) allow view just first n rows R console.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning-data-and-core-functions.html","id":"review","chapter":"8 Cleaning data and core functions","heading":"Review","text":"can use function skim() package skimr get overview entire dataframe (see page Descriptive tables info). Columns summarised class/type character, numeric. Note: “POSIXct” type raw date class (see Working dates.\nTable 8.1: Data summary\nVariable type: characterVariable type: numericVariable type: POSIXct","code":"\nskimr::skim(linelist_raw)"},{"path":"cleaning-data-and-core-functions.html","id":"column-names","chapter":"8 Cleaning data and core functions","heading":"8.4 Column names","text":"R, column names “header” “top” value column. used refer columns code, serve default label figures.statistical software SAS STATA use “labels” co-exist longer printed versions shorter column names. R offer possibility adding column labels data, emphasized practice. make column names “printer-friendly” figures, one typically adjusts display within plotting commands create outputs (e.g. axis legend titles plot, column headers printed table - see scales section ggplot tips page Tables presentation pages). want assign column labels data, read online .R column names used often, must “clean” syntax. suggest following:Short namesNo spaces (replace underscores _ )unusual characters (&, #, <, >, …)Similar style nomenclature (e.g. date columns named like date_onset, date_report, date_death…)columns names linelist_raw printed using names() base R. can see initially:names contain spaces (e.g. infection date)Different naming patterns used dates (date onset vs. infection date)must merged header across two last columns .xlsx. know name two merged columns (“merged_header”) assigned R first column, second column assigned placeholder name “…28” (empty 28th column).NOTE: reference column name includes spaces, surround name back-ticks, example: linelist$` '\\x60infection date\\x60'`. note keyboard, back-tick (`) different single quotation mark (’).","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"      \"hosp date\"       \"date_of_outcome\"\n##  [7] \"outcome\"         \"gender\"          \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n## [13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"         \"wt_kg\"           \"ht_cm\"          \n## [19] \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning-data-and-core-functions.html","id":"automatic-cleaning","chapter":"8 Cleaning data and core functions","heading":"Automatic cleaning","text":"function clean_names() package janitor standardizes column names makes unique following:Converts names consist underscores, numbers, lettersAccented characters transliterated ASCII (e.g. german o umlaut becomes “o”, spanish “enye” becomes “n”)Capitalization preference new column names can specified using case = argument (“snake” default, alternatives include “sentence”, “title”, “small_camel”…)can specify specific name replacements providing vector replace = argument (e.g. replace = c(onset = \"date_of_onset\"))online vignetteBelow, cleaning pipeline begins using clean_names() raw linelist.NOTE: last column name “…28” changed “x28”.","code":"\n# pipe the raw dataset through the function clean_names(), assign result as \"linelist\"  \nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new column names\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"      \"hosp_date\"       \"date_of_outcome\"\n##  [7] \"outcome\"         \"gender\"          \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n## [13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"         \"wt_kg\"           \"ht_cm\"          \n## [19] \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"manual-name-cleaning","chapter":"8 Cleaning data and core functions","heading":"Manual name cleaning","text":"Re-naming columns manually often necessary, even standardization step . , re-naming performed using rename() function dplyr package, part pipe chain. rename() uses style NEW = OLD - new column name given old column name., re-naming command added cleaning pipeline. Spaces added strategically align code easier reading.Now can see columns names changed:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n##  [6] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                 \n## [11] \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"                \"temp\"                \n## [26] \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"rename-by-column-position","chapter":"8 Cleaning data and core functions","heading":"Rename by column position","text":"can also rename column position, instead column name, example:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning-data-and-core-functions.html","id":"rename-via-select-and-summarise","chapter":"8 Cleaning data and core functions","heading":"Rename via select() and summarise()","text":"shortcut, can also rename columns within dplyr select() summarise() functions. select() used keep certain columns (covered later page). summarise() covered Grouping data Descriptive tables pages. functions also uses format new_name = old_name. example:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning-data-and-core-functions.html","id":"other-challenges","chapter":"8 Cleaning data and core functions","heading":"Other challenges","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"empty-excel-column-names","chapter":"8 Cleaning data and core functions","heading":"Empty Excel column names","text":"R dataset columns column names (headers). , import Excel dataset data column headers, R fill-headers names like “…1” “…2”. number represents column number (e.g. 4th column dataset header, R name “…4”).can clean names manually referencing position number (see example ), assigned name (linelist_raw$...1).","code":""},{"path":"cleaning-data-and-core-functions.html","id":"merged-excel-column-names-and-cells","chapter":"8 Cleaning data and core functions","heading":"Merged Excel column names and cells","text":"Merged cells Excel file common occurrence receiving data. explained Transition R, merged cells can nice human reading data, “tidy data” cause many problems machine reading data. R accommodate merged cells.Remind people data entry human-readable data machine-readable data. Strive train users principles tidy data. possible, try change procedures data arrive tidy format without merged cells.variable must column.observation must row.value must cell.using rio’s import() function, value merged cell assigned first cell subsequent cells empty.One solution deal merged cells import data function readWorkbook() package openxlsx. Set argument fillMergedCells = TRUE. gives value merged cell cells within merge range.DANGER: column names merged readWorkbook(), end duplicate column names, need fix manually - R work well duplicate column names! can re-name referencing position (e.g. column 5), explained section manual column name cleaning.","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning-data-and-core-functions.html","id":"select-or-re-order-columns","chapter":"8 Cleaning data and core functions","heading":"8.5 Select or re-order columns","text":"Use select() dplyr select columns want retain, specify order data frame.CAUTION: examples , linelist data frame modified select() displayed, saved. demonstration purposes. modified column names printed piping data frame names().column names linelist point cleaning pipe chain:","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n##  [6] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                 \n## [11] \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"                \"temp\"                \n## [26] \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"keep-columns","chapter":"8 Cleaning data and core functions","heading":"Keep columns","text":"Select columns want remainPut names select() command, quotation marks. appear data frame order provide. Note include column exist, R return error (see use any_of() want error situation).","code":"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"fever\""},{"path":"cleaning-data-and-core-functions.html","id":"clean_tidyselect","chapter":"8 Cleaning data and core functions","heading":"“tidyselect” helper functions","text":"helper functions exist make easy specify columns keep, discard, transform. package tidyselect, included tidyverse underlies columns selected dplyr functions.example, want re-order columns, everything() useful function signify “columns yet mentioned”. command moves columns date_onset date_hospitalisation beginning (left) dataset, keeps columns afterward. Note everything() written empty parentheses:“tidyselect” helper functions also work within dplyr functions like select(), across(), summarise():everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEcontains() - columns containing character string\nexample: select(contains(\"time\"))\nexample: select(contains(\"time\"))starts_with() - matches specified prefix\nexample: select(starts_with(\"date_\"))\nexample: select(starts_with(\"date_\"))ends_with() - matches specified suffix\nexample: select(ends_with(\"_post\"))\nexample: select(ends_with(\"_post\"))matches() - apply regular expression (regex)\nexample: select(matches(\"[pt]al\"))\nexample: select(matches(\"[pt]al\"))num_range() - numerical range like x01, x02, x03any_of() - matches column exists returns error found\nexample: select(any_of(date_onset, date_death, cardiac_arrest))\nexample: select(any_of(date_onset, date_death, cardiac_arrest))addition, use normal operators c() list several columns, : consecutive columns, ! opposite, & , | .Use () specify logical criteria columns. providing function inside (), include function’s empty parentheses. command selects columns class Numeric.Use contains() select columns column name contains specified character string. ends_with() starts_with() provide nuance.function matches() works similarly contains() can provided regular expression (see page Characters strings), multiple strings separated bars within parentheses:CAUTION: column name specifically provide exist data, can return error stop code. Consider using any_of() cite columns may may exist, especially useful negative (remove) selections.one columns exists, error produced code continues without stopping cleaning chain.","code":"\n# move date_onset and date_hospitalisation to beginning\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"              \"generation\"           \"date_infection\"      \n##  [6] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                 \n## [11] \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"                \"temp\"                \n## [26] \"time_admission\"       \"merged_header\"        \"x28\"\n# select columns that are class Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"      \"ct_blood\"   \"temp\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"             \"fever\"\nlinelist %>% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## [1] \"date_onset\""},{"path":"cleaning-data-and-core-functions.html","id":"remove-columns","chapter":"8 Cleaning data and core functions","heading":"Remove columns","text":"Indicate columns remove placing minus symbol “-” front column name (e.g. select(-outcome)), vector column names (). columns retained.can also remove column using base R syntax, defining NULL. example:","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove date_onset and all columns from fever to vomit\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_hospitalisation\" \"date_outcome\"        \n##  [6] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                 \n## [11] \"infector\"             \"source\"               \"age\"                  \"age_unit\"             \"row_num\"             \n## [16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"temp\"                 \"time_admission\"      \n## [21] \"merged_header\"        \"x28\"\nlinelist$date_onset <- NULL   # deletes column with base R syntax "},{"path":"cleaning-data-and-core-functions.html","id":"standalone","chapter":"8 Cleaning data and core functions","heading":"Standalone","text":"select() can also used independent command (pipe chain). case, first argument original dataframe operated upon.","code":"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\""},{"path":"cleaning-data-and-core-functions.html","id":"add-to-the-pipe-chain","chapter":"8 Cleaning data and core functions","heading":"Add to the pipe chain","text":"linelist_raw, columns need: row_num, merged_header, x28. remove select() command cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning-data-and-core-functions.html","id":"deduplication","chapter":"8 Cleaning data and core functions","heading":"8.6 Deduplication","text":"See handbook page De-duplication extensive options de-duplicate data. simple row de-duplication example presented .package dplyr offers distinct() function. function examines every row reduce data frame unique rows. , removes rows 100% duplicates.evaluating duplicate rows, takes account range columns - default considers columns. shown de-duplication page, can adjust column range uniqueness rows evaluated regards certain columns.simple example, just add empty command distinct() pipe chain. ensures rows 100% duplicates rows (evaluated across columns).begin nrow(linelist) rows linelist.de-duplication nrow(linelist) rows. removed rows 100% duplicates rows., distinct() command added cleaning pipe chain:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning-data-and-core-functions.html","id":"column-creation-and-transformation","chapter":"8 Cleaning data and core functions","heading":"8.7 Column creation and transformation","text":"recommend using dplyr function mutate() add new column, modify existing one.example creating new column mutate(). syntax : mutate(new_column_name = value transformation)Stata, similar command generate, R’s mutate() can also used modify existing column.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"new-columns","chapter":"8 Cleaning data and core functions","heading":"New columns","text":"basic mutate() command create new column might look like . creates new column new_col value every row 10.can also reference values columns, perform calculations. , new column bmi created hold Body Mass Index (BMI) case - calculated using formula BMI = kg/m^2, using column ht_cm column wt_kg.creating multiple new columns, separate comma new line. examples new columns, including ones consist values columns combined using str_glue() stringr package (see page Characters strings.Review new columns. demonstration purposes, new columns columns used create shown:TIP: variation mutate() function transmute(). function adds new column just like mutate(), also drops/removes columns mention within parentheses.","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nnew_col_demo <- linelist %>%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) %>% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # show only new columns, for demonstration purposes\n# HIDDEN FROM READER\n# removes new demo columns created above\n# linelist <- linelist %>% \n#   select(-contains(\"new_var\"))"},{"path":"cleaning-data-and-core-functions.html","id":"convert-column-class","chapter":"8 Cleaning data and core functions","heading":"Convert column class","text":"Columns containing values dates, numbers, logical values (TRUE/FALSE) behave expected correctly classified. difference “2” class character 2 class numeric!ways set column class import commands, often cumbersome. See R Basics section object classes learn converting class objects columns.First, let’s run checks important columns see correct class. also saw beginning ran skim().Currently, class age column character. perform quantitative analyses, need numbers recognized numeric!class date_onset column also character! perform analyses, dates must recognized dates!resolve , use ability mutate() re-define column transformation. define column , converted different class. basic example, converting ensuring column age class Numeric:similar way, can use .character() .logical(). convert class Factor, can use factor() base R as_factor() forcats. Read Factors page.must careful converting class Date. Several methods explained page Working dates. Typically, raw date values must format conversion work correctly (e.g “MM/DD/YYYY”, “DD MM YYYY”). converting class Date, check data confirm value converted correctly.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))"},{"path":"cleaning-data-and-core-functions.html","id":"grouped-data","chapter":"8 Cleaning data and core functions","heading":"Grouped data","text":"data frame already grouped (see page Grouping data), mutate() may behave differently data frame grouped. summarizing functions, like mean(), median(), max(), etc. calculate group, rows.Read using mutate () grouped dataframes tidyverse mutate documentation.","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning-data-and-core-functions.html","id":"clean_across","chapter":"8 Cleaning data and core functions","heading":"Transform multiple columns","text":"Often write concise code want apply transformation multiple columns . transformation can applied multiple columns using across() function package dplyr (also contained within tidyverse package). across() can used dplyr function, commonly used within select(), mutate(), filter(), summarise(). See applied summarise() page Descriptive tables.Specify columns argument .cols = function(s) apply .fns =. additional arguments provide .fns function can included comma, still within across().","code":""},{"path":"cleaning-data-and-core-functions.html","id":"across-column-selection","chapter":"8 Cleaning data and core functions","heading":"across() column selection","text":"Specify columns argument .cols =. can name individually, use “tidyselect” helper functions. Specify function .fns =. Note using function mode demonstrated , function written without parentheses ( ).transformation .character() applied specific columns named within across().“tidyselect” helper functions available assist specifying columns. detailed section Selecting re-ordering columns, include: everything(), last_col(), (), starts_with(), ends_with(), contains(), matches(), num_range() any_of().example one change columns character class:Convert character columns name contains string “date” (note placement commas parentheses):, example mutating columns currently class POSIXct (raw datetime class shows timestamps) - words, function .POSIXct() evaluates TRUE. want apply function .Date() columns convert normal class Date.Note within across() also use function () .POSIXct evaluating either TRUE FALSE.Note .POSIXct() package lubridate. similar “” functions like .character(), .numeric(), .logical() base R","code":"\nlinelist <- linelist %>% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = everything(), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\nlinelist <- linelist %>% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))"},{"path":"cleaning-data-and-core-functions.html","id":"across-functions","chapter":"8 Cleaning data and core functions","heading":"across() functions","text":"can read documentation ?across details provide functions across(). summary points: several ways specify function(s) perform column can even define functions:can provide function name alone (e.g. mean .character)can provide function purrr-style (e.g. ~ mean(.x, na.rm = TRUE)) (see page)can specify multiple functions providing list (e.g. list(mean = mean, n_miss = ~ sum(.na(.x))).\nprovide multiple functions, multiple transformed columns returned per input column, unique names format col_fn. can adjust new columns named .names = argument using glue syntax (see page Characters strings) {.col} {.fn} shorthand input column function.\nprovide multiple functions, multiple transformed columns returned per input column, unique names format col_fn. can adjust new columns named .names = argument using glue syntax (see page Characters strings) {.col} {.fn} shorthand input column function.online resources using across(): creator Hadley Wickham’s thoughts/rationale","code":""},{"path":"cleaning-data-and-core-functions.html","id":"coalesce","chapter":"8 Cleaning data and core functions","heading":"coalesce()","text":"dplyr function finds first non-missing value position. “fills-” missing values first available value order specify.example outside context data frame: Let us say two vectors, one containing patient’s village detection another containing patient’s village residence. can use coalesce pick first non-missing value index:works provide data frame columns: row, function assign new column value first non-missing value columns provided (order provided).example “row-wise” operation. complicated row-wise calculations, see section Row-wise calculations.","code":"\nvillage_detection <- c(\"a\", \"b\", NA,  NA)\nvillage_residence <- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage <- coalesce(village_detection, village_residence)\nvillage    # print## [1] \"a\" \"b\" \"a\" \"d\"\nlinelist <- linelist %>% \n  mutate(village = coalesce(village_detection, village_residence))"},{"path":"cleaning-data-and-core-functions.html","id":"cumulative-math","chapter":"8 Cleaning data and core functions","heading":"Cumulative math","text":"want column reflect cumulative sum/mean/min/max etc assessed rows dataframe point, use following functions:cumsum() returns cumulative sum, shown :can used dataframe making new column. example, calculate cumulative number cases per day outbreak, consider code like :first 10 rows:See page Epidemic curves plot cumulative incidence epicurve.See also:cumsum(), cummean(), cummin(), cummax(), cumany(), cumall()","code":"\nsum(c(2,4,15,10))     # returns only one number## [1] 31\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step## [1]  2  6 21 31\ncumulative_case_counts <- linelist %>%  # begin with case linelist\n  count(date_onset) %>%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\nhead(cumulative_case_counts, 10)##    date_onset n cumulative_cases\n## 1  2012-04-15 1                1\n## 2  2012-05-05 1                2\n## 3  2012-05-08 1                3\n## 4  2012-05-31 1                4\n## 5  2012-06-02 1                5\n## 6  2012-06-07 1                6\n## 7  2012-06-14 1                7\n## 8  2012-06-21 1                8\n## 9  2012-06-24 1                9\n## 10 2012-06-25 1               10"},{"path":"cleaning-data-and-core-functions.html","id":"using-base-r","chapter":"8 Cleaning data and core functions","heading":"Using base R","text":"define new column (re-define column) using base R, write name data frame, connected $, new column (column modified). Use assignment operator <- define new value(s). Remember using base R must specify data frame name column name every time (e.g. dataframe$column). example creating bmi column using base R:","code":"linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":", new column added pipe chain classes converted.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) "},{"path":"cleaning-data-and-core-functions.html","id":"re-code-values","chapter":"8 Cleaning data and core functions","heading":"8.8 Re-code values","text":"scenarios need re-code (change) values:edit one specific value (e.g. one date incorrect year format)reconcile values spelled sameto create new column categorical valuesto create new column numeric categories (e.g. age categories)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"specific-values","chapter":"8 Cleaning data and core functions","heading":"Specific values","text":"change values manually can use recode() function within mutate() function.Imagine nonsensical date data (e.g. “2014-14-15”): fix date manually raw source data, , write change cleaning pipeline via mutate() recode(). latter transparent reproducible anyone else seeking understand repeat analysis.mutate() line can read : “mutate column date_onset equal column date_onset re-coded OLD VALUE changed NEW VALUE”. Note pattern (OLD = NEW) recode() opposite R patterns (new = old). R development community working revising .another example re-coding multiple values within one column.linelist values column “hospital” must cleaned. several different spellings many missing values.recode() command re-defines column “hospital” current column “hospital”, specified recode changes. Don’t forget commas !Now see spellings hospital column corrected consolidated:TIP: number spaces equals sign matter. Make code easier read aligning = rows. Also, consider adding hashed comment row clarify future readers side OLD side NEW. TIP: Sometimes blank character value exists dataset (recognized R’s value missing - NA). can reference value two quotation marks space inbetween (““).","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")  # print table of all unique values, including missing  ## \n##                      Central Hopital                     Central Hospital                           Hospital A \n##                                   11                                  457                                  290 \n##                           Hospital B                     Military Hopital                    Military Hospital \n##                                  289                                   32                                  798 \n##                     Mitylira Hopital                    Mitylira Hospital                                Other \n##                                    1                                   79                                  907 \n##                         Port Hopital                        Port Hospital St. Mark's Maternity Hospital (SMMH) \n##                                   48                                 1756                                  417 \n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \n##                                   11                                 1512\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \n##                     Central Hospital                           Hospital A                           Hospital B \n##                                  468                                  290                                  289 \n##                    Military Hospital                                Other                        Port Hospital \n##                                  910                                  907                                 1804 \n## St. Mark's Maternity Hospital (SMMH)                                 <NA> \n##                                  428                                 1512"},{"path":"cleaning-data-and-core-functions.html","id":"by-logic","chapter":"8 Cleaning data and core functions","heading":"By logic","text":"demonstrate re-code values column using logic conditions:Using replace(), ifelse() if_else() simple logicUsing case_when() complex logic","code":""},{"path":"cleaning-data-and-core-functions.html","id":"simple-logic","chapter":"8 Cleaning data and core functions","heading":"Simple logic","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"replace","chapter":"8 Cleaning data and core functions","heading":"replace()","text":"re-code simple logical criteria, can use replace() within mutate(). replace() function base R. Use logic condition specify rows change . general syntax :mutate(col_to_change = replace(col_to_change, criteria rows, new value)).One common situation use replace() changing just one value one row, using unique row identifier. , gender changed “Female” row column case_id “2195”.equivalent command using base R syntax indexing brackets [ ] . reads “Change value dataframe linelist‘s column gender (rows linelist’s column case_id value ’2195’) ‘Female’”.","code":"\n# Example: change gender of one specific observation to \"Female\" \nlinelist <- linelist %>% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning-data-and-core-functions.html","id":"ifelse-and-if_else","chapter":"8 Cleaning data and core functions","heading":"ifelse() and if_else()","text":"Another tool simple logic ifelse() partner if_else(). However, cases re-coding clear use case_when() (detailed ). “else” commands simplified versions else programming statement. general syntax :ifelse(condition, value return condition evaluates TRUE, value return condition evaluates FALSE), column source_known defined. value given row set “known” row’s value column source missing. value source missing, value source_known set “unknown”.if_else() special version dplyr handles dates. Note ‘true’ value date, ‘false’ value must also qualify date, hence using special value NA_real_ instead just NA.Avoid stringing together many ifelse commands… use case_when() instead! case_when() much easier read ’ll make fewer errors.Outside context data frame, want object used code switch value, consider using switch() base R.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n# Create a date of death column, which is NA if patient has not died.\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"clean_case_when","chapter":"8 Cleaning data and core functions","heading":"Complex logic","text":"Use dplyr’s case_when() re-coding many new groups, need use complex logic statements re-code values. function evaluates every row data frame, assess whether rows meets specified criteria, assigns correct new value.case_when() commands consist statements Right-Hand Side (RHS) Left-Hand Side (LHS) separated “tilde” ~. logic criteria left side pursuant values right side statement. Statements separated commas.example, utilize columns age age_unit create column age_years:row data evaluated, criteria applied/evaluated order case_when() statements written - top--bottom. top criteria evaluates TRUE given row, RHS value assigned, remaining criteria even tested row data. Thus, best write specific criteria first, general last. data row meet RHS criteria assigned NA.Sometimes, may write final statement assigns value scenarios described one previous lines. , place TRUE left-side, capture row meet previous criteria. right-side statement assigned value like “check !” missing.another example case_when() used create new column patient classification, according case definition confirmed suspect cases:DANGER: Values right-side must class - either numeric, character, date, logical, etc. assign missing (NA), may need use special variations NA NA_character_, NA_real_ (numeric POSIX), .Date(NA). Read Working dates.","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n       age_unit == \"years\"  ~ age,       # if age unit is years\n       age_unit == \"months\" ~ age/12,    # if age unit is months, divide age by 12\n       is.na(age_unit)      ~ age))      # if age unit is missing, assume years\n                                         # any other circumstance, assign NA (missing)\nlinelist <- linelist %>% \n     mutate(case_status = case_when(\n          \n          # if patient had lab test and it is positive,\n          # then they are marked as a confirmed case \n          ct_blood < 20                   ~ \"Confirmed\",\n          \n          # given that a patient does not have a positive lab result,\n          # if patient has a \"source\" (epidemiological link) AND has fever, \n          # then they are marked as a suspect case\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # any other patient not addressed above \n          # is marked for follow up\n          TRUE                            ~ \"To investigate\"))"},{"path":"cleaning-data-and-core-functions.html","id":"missing-values-1","chapter":"8 Cleaning data and core functions","heading":"Missing values","text":"special functions handling missing values context data cleaning.See page Missing data detailed tips identifying handling missing values. example, .na() function logically tests missingness.replace_na()change missing values (NA) specific value, “Missing”, use dplyr function replace_na() within mutate(). Note used manner recode - name variable must repeated within replace_na().fct_explicit_na()function forcats package. forcats package handles columns class Factor. Factors R’s way handle ordered values c(\"First\", \"Second\", \"Third\") set order values (e.g. hospitals) appear tables plots. See page Factors.data class Factor try convert NA “Missing” using replace_na(), get error: invalid factor level, NA generated. tried add “Missing” value, defined possible level factor, rejected.easiest way solve use forcats function fct_explicit_na() converts column class factor, converts NA values character “(Missing)”.slower alternative add factor level using fct_expand() convert missing values.na_if()convert specific value NA, use dplyr’s na_if(). command performs opposite operation replace_na(). example , values “Missing” column hospital converted NA.Note: na_if() used logic criteria (e.g. “values > 99”) - use replace() case_when() :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist %>% \n  mutate(hospital = fct_explicit_na(hospital))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\nlinelist <- linelist %>% \n  mutate(date_onset = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-dictionary","chapter":"8 Cleaning data and core functions","heading":"Cleaning dictionary","text":"Use R package matchmaker function match_df() clean data frame cleaning dictionary.Create cleaning dictionary 3 columns:\n“” column (incorrect value)\n“” column (correct value)\ncolumn specifying column changes applied (“.global” apply columns)\n“” column (incorrect value)“” column (correct value)column specifying column changes applied (“.global” apply columns)Note: .global dictionary entries overridden column-specific dictionary entries.Import dictionary file R. example can downloaded via instructions Download handbook data page.Pipe raw linelist match_df(), specifying dictionary = cleaning dictionary data frame. = argument name dictionary column contains “old” values, = argument dictionary column contains corresponding “new” values, third column lists column make change. Use .global = column apply change across columns. fourth dictionary column order can used specify factor order new values.Read details package documentation running ?match_df. Note function can take long time run large dataset.Now scroll right see values changed - particularly gender (lowercase uppercase), symptoms columns transformed yes/1/0.Note column names cleaning dictionary must correspond names point cleaning script. See online reference linelist package details.","code":"\ncleaning_dict <- import(\"cleaning_dict.csv\")\nlinelist <- linelist %>%     # provide or pipe your dataset\n     matchmaker::match_df(\n          dictionary = cleaning_dict,  # name of your dictionary\n          from = \"from\",               # column with values to be replaced (default is col 1)\n          to = \"to\",                   # column with final values (default is col 2)\n          by = \"col\"                   # column with column names (default is col 3)\n  )"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-1","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":", new columns column transformations added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"num_cats","chapter":"8 Cleaning data and core functions","heading":"8.9 Numeric categories","text":"describe special approaches creating categories numerical columns. Common examples include age categories, groups lab values, etc. discuss:age_categories(), epikit packagecut(), base Rcase_when()quantile breaks quantile() ntile()","code":""},{"path":"cleaning-data-and-core-functions.html","id":"review-distribution","chapter":"8 Cleaning data and core functions","heading":"Review distribution","text":"example create age_cat column using age_years column.First, examine distribution data, make appropriate cut-points. See page ggplot basics.CAUTION: Sometimes, numeric variables import class “character”. occurs non-numeric characters values, example entry “2 months” age, (depending R locale settings) comma used decimals place (e.g. “4,5” mean four one half years)..","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.04   23.00   84.00     107"},{"path":"cleaning-data-and-core-functions.html","id":"age_categories","chapter":"8 Cleaning data and core functions","heading":"age_categories()","text":"epikit package, can use age_categories() function easily categorize label numeric columns (note: function can applied non-age numeric variables ). bonum, output column automatically ordered factor.required inputs:numeric vector (column)breakers = argument - provide numeric vector break points new groupsFirst, simplest example:break values specify default lower bounds - , included “higher” group / groups “open” lower/left side. shown , can add 1 break value achieve groups open top/right.can adjust labels displayed separator =. default “-”can adjust top numbers handled, ceiling = arguemnt. set upper cut-set ceiling = TRUE. use, highest break value provided “ceiling” category “XX+” created. values highest break value (upper =, defined) categorized NA. example ceiling = TRUE, category XX+ values 70 (highest break value) assigned NA.Alternatively, instead breakers =, can provide lower =, upper =, =:lower = lowest number want considered - default 0upper = highest number want consideredby = number years groupsSee function’s Help page details (enter ?age_categories R console).","code":"\n# Simple example\n################\npacman::p_load(epikit)                    # load package\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(             # create new column\n      age_years,                            # numeric column to make groups from\n      breakers = c(0, 5, 10, 15, 20,        # break points\n                   30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \n##  1227  1223  1048   827  1216   597   251    78    27     7   107\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \n##  1469  1195  1040   770  1149   547   231    70    24     6   107\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \n##  1227  1223  1048   827  1216   597   251    78    28   113\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  <NA> \n##  2450  1875  1216   597   251    78    27     6     1     0     0   107"},{"path":"cleaning-data-and-core-functions.html","id":"cut","chapter":"8 Cleaning data and core functions","heading":"cut()","text":"cut() base R alternative age_categories(), think see age_categories() developed simplify process. notable differences age_categories() :need install/load another packageYou can specify whether groups open/closed right/leftYou must provide accurate labels yourselfIf want 0 included lowest group must specify thisThe basic syntax within cut() first provide numeric column cut (age_years), breaks argument, numeric vector c() break points. Using cut(), resulting column ordered factor.default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). opposite behavior age_categories() function. default labels use notation “(, B]”, means included B . Reverse behavior providing right = TRUE argument.Thus, default, “0” values excluded lowest group, categorized NA! “0” values infants coded age 0 careful! change , add argument include.lowest = TRUE “0” values included lowest group. automatically-generated label lowest category “[],B]”. Note include include.lowest = TRUE argument right = TRUE, extreme inclusion now apply highest break point value category, lowest.can provide vector customized labels using labels = argument. manually written, careful ensure accurate! Check work using cross-tabulation, described .example cut() applied age_years make new variable age_cat :Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 16-20).Re-labeling NA valuesYou may want assign NA values label “Missing”. new column class Factor (restricted values), simply mutate replace_na(), value rejected. Instead, use fct_explicit_na() forcats explained Factors page.Quickly make breaks labelsFor fast way make breaks label vectors, use something like . See R basics page references seq() rep().Read cut() Help page entering ?cut R console.","code":"\n# Create new variable, by cutting the numeric age variable\n# lower break is excluded but upper break is included in each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \n##     1469     1195     1040      770     1149      778       94        6      107\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                     Categories\n## Numeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\n##   0                    136      0       0       0       0       0       0        0    0\n##   0.0833333333333333     1      0       0       0       0       0       0        0    0\n##   0.25                   2      0       0       0       0       0       0        0    0\n##   0.333333333333333      6      0       0       0       0       0       0        0    0\n##   0.416666666666667      1      0       0       0       0       0       0        0    0\n##   0.5                    6      0       0       0       0       0       0        0    0\n##   0.583333333333333      3      0       0       0       0       0       0        0    0\n##   0.666666666666667      3      0       0       0       0       0       0        0    0\n##   0.75                   3      0       0       0       0       0       0        0    0\n##   0.833333333333333      1      0       0       0       0       0       0        0    0\n##   0.916666666666667      1      0       0       0       0       0       0        0    0\n##   1                    275      0       0       0       0       0       0        0    0\n##   1.5                    2      0       0       0       0       0       0        0    0\n##   2                    308      0       0       0       0       0       0        0    0\n##   3                    246      0       0       0       0       0       0        0    0\n##   4                    233      0       0       0       0       0       0        0    0\n##   5                    242      0       0       0       0       0       0        0    0\n##   6                      0    241       0       0       0       0       0        0    0\n##   7                      0    256       0       0       0       0       0        0    0\n##   8                      0    239       0       0       0       0       0        0    0\n##   9                      0    245       0       0       0       0       0        0    0\n##   10                     0    214       0       0       0       0       0        0    0\n##   11                     0      0     220       0       0       0       0        0    0\n##   12                     0      0     224       0       0       0       0        0    0\n##   13                     0      0     191       0       0       0       0        0    0\n##   14                     0      0     199       0       0       0       0        0    0\n##   15                     0      0     206       0       0       0       0        0    0\n##   16                     0      0       0     186       0       0       0        0    0\n##   17                     0      0       0     164       0       0       0        0    0\n##   18                     0      0       0     141       0       0       0        0    0\n##   19                     0      0       0     130       0       0       0        0    0\n##   20                     0      0       0     149       0       0       0        0    0\n##   21                     0      0       0       0     158       0       0        0    0\n##   22                     0      0       0       0     149       0       0        0    0\n##   23                     0      0       0       0     125       0       0        0    0\n##   24                     0      0       0       0     144       0       0        0    0\n##   25                     0      0       0       0     107       0       0        0    0\n##   26                     0      0       0       0     100       0       0        0    0\n##   27                     0      0       0       0     117       0       0        0    0\n##   28                     0      0       0       0      85       0       0        0    0\n##   29                     0      0       0       0      82       0       0        0    0\n##   30                     0      0       0       0      82       0       0        0    0\n##   31                     0      0       0       0       0      68       0        0    0\n##   32                     0      0       0       0       0      84       0        0    0\n##   33                     0      0       0       0       0      78       0        0    0\n##   34                     0      0       0       0       0      58       0        0    0\n##   35                     0      0       0       0       0      58       0        0    0\n##   36                     0      0       0       0       0      33       0        0    0\n##   37                     0      0       0       0       0      46       0        0    0\n##   38                     0      0       0       0       0      45       0        0    0\n##   39                     0      0       0       0       0      45       0        0    0\n##   40                     0      0       0       0       0      32       0        0    0\n##   41                     0      0       0       0       0      34       0        0    0\n##   42                     0      0       0       0       0      26       0        0    0\n##   43                     0      0       0       0       0      31       0        0    0\n##   44                     0      0       0       0       0      24       0        0    0\n##   45                     0      0       0       0       0      27       0        0    0\n##   46                     0      0       0       0       0      25       0        0    0\n##   47                     0      0       0       0       0      16       0        0    0\n##   48                     0      0       0       0       0      21       0        0    0\n##   49                     0      0       0       0       0      15       0        0    0\n##   50                     0      0       0       0       0      12       0        0    0\n##   51                     0      0       0       0       0       0      13        0    0\n##   52                     0      0       0       0       0       0       7        0    0\n##   53                     0      0       0       0       0       0       4        0    0\n##   54                     0      0       0       0       0       0       6        0    0\n##   55                     0      0       0       0       0       0       9        0    0\n##   56                     0      0       0       0       0       0       7        0    0\n##   57                     0      0       0       0       0       0       9        0    0\n##   58                     0      0       0       0       0       0       6        0    0\n##   59                     0      0       0       0       0       0       5        0    0\n##   60                     0      0       0       0       0       0       4        0    0\n##   61                     0      0       0       0       0       0       2        0    0\n##   62                     0      0       0       0       0       0       1        0    0\n##   63                     0      0       0       0       0       0       5        0    0\n##   64                     0      0       0       0       0       0       1        0    0\n##   65                     0      0       0       0       0       0       5        0    0\n##   66                     0      0       0       0       0       0       3        0    0\n##   67                     0      0       0       0       0       0       2        0    0\n##   68                     0      0       0       0       0       0       1        0    0\n##   69                     0      0       0       0       0       0       3        0    0\n##   70                     0      0       0       0       0       0       1        0    0\n##   72                     0      0       0       0       0       0       0        1    0\n##   73                     0      0       0       0       0       0       0        3    0\n##   76                     0      0       0       0       0       0       0        1    0\n##   84                     0      0       0       0       0       0       0        1    0\n##   <NA>                   0      0       0       0       0       0       0        0  107\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # make missing values explicit\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n  )    \n\n# table to view counts\ntable(linelist$age_cat, useNA = \"always\")## \n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69      70-100 Missing age        <NA> \n##        1227        1223        1048         827        1216         848         105           7         107           0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)"},{"path":"cleaning-data-and-core-functions.html","id":"quantile-breaks","chapter":"8 Cleaning data and core functions","heading":"Quantile breaks","text":"common understanding, “quantiles” “percentiles” typically refer value proportion values fall. example, 95th percentile ages linelist age 95% age fall.However common speech, “quartiles” “deciles” can also refer groups data equally divided 4, 10 groups (note one break point group).get quantile break points, can use quantile() stats package base R. provide numeric vector (e.g. column dataset) vector numeric probability values ranging 0 1.0. break points returned numeric vector. Explore details statistical methodologies entering ?quantile.input numeric vector missing values best set na.rm = TRUESet names = FALSE get un-named numeric vectorYou can use results quantile() break points age_categories() cut(). create new column deciles using cut() breaks defined using quantiles() age_years. , display results using tabyl() janitor can see percentages (see Descriptive tables page). Note exactly 10% group.","code":"\nquantile(linelist$age_years,               # specify numeric vector to work on\n  probs = c(0, .25, .50, .75, .90, .95),   # specify the percentiles you want\n  na.rm = TRUE)                            # ignore missing values ##  0% 25% 50% 75% 90% 95% \n##   0   6  13  23  33  41\nlinelist %>%                                # begin with linelist\n  mutate(deciles = cut(age_years,           # create new column decile as cut() on column age_years\n    breaks = quantile(                      # define cut breaks using quantile()\n      age_years,                               # operate on age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 to 1.0 by 0.1\n      na.rm = TRUE),                           # ignore missing values\n    include.lowest = TRUE)) %>%             # for cut() include age 0\n  janitor::tabyl(deciles)                   # pipe to table to display##  deciles   n    percent valid_percent\n##    [0,2] 748 0.11319613    0.11505922\n##    (2,5] 721 0.10911017    0.11090601\n##    (5,7] 497 0.07521186    0.07644978\n##   (7,10] 698 0.10562954    0.10736810\n##  (10,13] 635 0.09609564    0.09767728\n##  (13,17] 755 0.11425545    0.11613598\n##  (17,21] 578 0.08746973    0.08890940\n##  (21,26] 625 0.09458232    0.09613906\n##  (26,33] 596 0.09019370    0.09167820\n##  (33,84] 648 0.09806295    0.09967697\n##     <NA> 107 0.01619249            NA"},{"path":"cleaning-data-and-core-functions.html","id":"evenly-sized-groups","chapter":"8 Cleaning data and core functions","heading":"Evenly-sized groups","text":"Another tool make numeric groups dplyr function ntile(), attempts break data n evenly-sized groups - aware unlike quantile() value appear one group. Provide numeric vector number groups. values new column created just group “numbers” (e.g. 1 10), range values using cut().","code":"\n# make groups with ntile()\nntile_data <- linelist %>% \n  mutate(even_groups = ntile(age_years, 10))\n\n# make table of counts and proportions by group\nntile_table <- ntile_data %>% \n  janitor::tabyl(even_groups)\n  \n# attach min/max values to demonstrate ranges\nntile_ranges <- ntile_data %>% \n  group_by(even_groups) %>% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )## Warning: There were 2 warnings in `summarise()`.\n## The first warning was:\n## ℹ In argument: `min = min(age_years, na.rm = T)`.\n## ℹ In group 11: `even_groups = NA`.\n## Caused by warning in `min()`:\n## ! no non-missing arguments to min; returning Inf\n## ℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n# combine and print - note that values are present in multiple groups\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")##  even_groups   n    percent valid_percent min  max\n##            1 651 0.09851695    0.10013844   0    2\n##            2 650 0.09836562    0.09998462   2    5\n##            3 650 0.09836562    0.09998462   5    7\n##            4 650 0.09836562    0.09998462   7   10\n##            5 650 0.09836562    0.09998462  10   13\n##            6 650 0.09836562    0.09998462  13   17\n##            7 650 0.09836562    0.09998462  17   21\n##            8 650 0.09836562    0.09998462  21   26\n##            9 650 0.09836562    0.09998462  26   33\n##           10 650 0.09836562    0.09998462  33   84\n##           NA 107 0.01619249            NA Inf -Inf"},{"path":"cleaning-data-and-core-functions.html","id":"case_when","chapter":"8 Cleaning data and core functions","heading":"case_when()","text":"possible use dplyr function case_when() create categories numeric column, easier use age_categories() epikit cut() create ordered factor automatically.using case_when(), please review proper use described earlier Re-code values section page. Also aware right-hand side values must class. Thus, want NA right-side either write “Missing” use special NA value NA_character_.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-2","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":", code create two categorical age columns added cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning-data-and-core-functions.html","id":"add-rows","chapter":"8 Cleaning data and core functions","heading":"8.10 Add rows","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"one-by-one","chapter":"8 Cleaning data and core functions","heading":"One-by-one","text":"Adding rows one--one manually tedious can done add_row() dplyr. Remember column must contain values one class (either character, numeric, logical, etc.). adding row requires nuance maintain .Use ... specify placement row want add. .= 3 put new row current 3rd row. default behavior add row end. Columns specified left empty (NA).new row number may look strange (“…23”) row numbers pre-existing rows changed. using command twice, examine/test insertion carefully.class provide see error like :(inserting row date value, remember wrap date function .Date() like .Date(\"2020-10-10\")).","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)Error: Can't combine ..1$infection date <date> and ..2$infection date <character>."},{"path":"cleaning-data-and-core-functions.html","id":"bind-rows","chapter":"8 Cleaning data and core functions","heading":"Bind rows","text":"combine datasets together binding rows one dataframe bottom another data frame, can use bind_rows() dplyr. explained detail page Joining data.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"filter-rows","chapter":"8 Cleaning data and core functions","heading":"8.11 Filter rows","text":"typical cleaning step cleaned columns re-coded values filter data frame specific rows using dplyr verb filter().Within filter(), specify logic must TRUE row dataset kept. show filter rows based simple complex logical conditions.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"simple-filter","chapter":"8 Cleaning data and core functions","heading":"Simple filter","text":"simple example re-defines dataframe linelist , filtered rows meet logical condition. rows logical statement within parentheses evaluates TRUE kept.example, logical statement gender == \"f\", asking whether value column gender equal “f” (case sensitive).filter applied, number rows linelist nrow(linelist).filter applied, number rows linelist linelist %>% filter(gender == \"f\") %>% nrow().","code":"\nlinelist <- linelist %>% \n  filter(gender == \"f\")   # keep only rows where gender is equal to \"f\""},{"path":"cleaning-data-and-core-functions.html","id":"filter-out-missing-values","chapter":"8 Cleaning data and core functions","heading":"Filter out missing values","text":"fairly common want filter rows missing values. Resist urge write filter(!.na(column) & !.na(column)) instead use tidyr function custom-built purpose: drop_na(). run empty parentheses, removes rows missing values. Alternatively, can provide names specific columns evaluated missingness, use “tidyselect” helper functions described .See page Missing data many techniques analyse manage missingness data.","code":"\nlinelist %>% \n  drop_na(case_id, age_years)  # drop rows with missing values for case_id or age_years"},{"path":"cleaning-data-and-core-functions.html","id":"filter-by-row-number","chapter":"8 Cleaning data and core functions","heading":"Filter by row number","text":"data frame tibble, row usually “row number” (seen R Viewer) appears left first column. true column data, can used filter() statement.filter based “row number”, can use dplyr function row_number() open parentheses part logical filtering statement. Often use %% operator range numbers part logical statement, shown . see first N rows, can also use special dplyr function head().can also convert row numbers true column piping data frame tibble function rownames_to_column() (put anything parentheses).","code":"\n# View first 100 rows\nlinelist %>% head(100)     # or use tail() to see the n last rows\n\n# Show row 5 only\nlinelist %>% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)"},{"path":"cleaning-data-and-core-functions.html","id":"complex-filter","chapter":"8 Cleaning data and core functions","heading":"Complex filter","text":"complex logical statements can constructed using parentheses ( ), |, negate !, %%, & operators. example :Note: can use ! operator front logical criteria negate . example, !.na(column) evaluates true column value missing. Likewise !column %% c(\"\", \"b\", \"c\") evaluates true column value vector.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"examine-the-data","chapter":"8 Cleaning data and core functions","heading":"Examine the data","text":"simple one-line command create histogram onset dates. See second smaller outbreak 2012-2013 also included raw dataset. analyses, want remove entries earlier outbreak.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning-data-and-core-functions.html","id":"how-filters-handle-missing-numeric-and-date-values","chapter":"8 Cleaning data and core functions","heading":"How filters handle missing numeric and date values","text":"Can just filter date_onset rows June 2013? Caution! Applying code filter(date_onset > .Date(\"2013-06-01\"))) remove rows later epidemic missing date onset!DANGER: Filtering greater (>) less (<) date number can remove rows missing values (NA)! NA treated infinitely large small.(See page Working dates information working dates package lubridate)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"design-the-filter","chapter":"8 Cleaning data and core functions","heading":"Design the filter","text":"Examine cross-tabulation make sure exclude correct rows:criteria can filter remove first outbreak (2012 & 2013) dataset? see :first epidemic 2012 & 2013 occurred Hospital , Hospital B, also 10 cases Port Hospital.Hospitals & B cases second epidemic, Port Hospital .want exclude:nrow(linelist %>% filter(hospital %% c(\"Hospital \", \"Hospital B\") | date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013 either hospital , B, Port:\nExclude nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013\nExclude nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows Hospitals & B missing onset dates\nexclude nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows missing onset dates.\nExclude nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013Exclude nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows Hospitals & B missing onset datesDo exclude nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows missing onset dates.start linelist nrow(linelist)`. filter statement:re-make cross-tabulation, see Hospitals & B removed completely, 10 Port Hospital cases 2012 & 2013 removed, values - just wanted.Multiple statements can included within one filter command (separated commas), can always pipe separate filter() command clarity.Note: readers may notice easier just filter date_hospitalisation 100% complete missing values. true. date_onset used purposes demonstrating complex filter.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2012 2013 2014 2015 <NA>\n##   Central Hospital                        0    0  351   99   18\n##   Hospital A                            229   46    0    0   15\n##   Hospital B                            227   47    0    0   15\n##   Military Hospital                       0    0  676  200   34\n##   Missing                                 0    0 1117  318   77\n##   Other                                   0    0  684  177   46\n##   Port Hospital                           9    1 1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 6019\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2014 2015 <NA>\n##   Central Hospital                      351   99   18\n##   Military Hospital                     676  200   34\n##   Missing                              1117  318   77\n##   Other                                 684  177   46\n##   Port Hospital                        1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)  322   93   13\n##   <NA>                                    0    0    0"},{"path":"cleaning-data-and-core-functions.html","id":"standalone-1","chapter":"8 Cleaning data and core functions","heading":"Standalone","text":"Filtering can also done stand-alone command (part pipe chain). Like dplyr verbs, case first argument must dataset .can also use base R subset using square brackets reflect [rows, columns] want retain.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning-data-and-core-functions.html","id":"quickly-review-records","chapter":"8 Cleaning data and core functions","heading":"Quickly review records","text":"Often want quickly review records, columns. base R function View() print data frame viewing RStudio.View linelist RStudio:two examples viewing specific cells (specific rows, specific columns):dplyr functions filter() select():Within View(), pipe dataset filter() keep certain rows, select() keep certain columns. example, review onset hospitalization dates 3 specific cases:can achieve base R syntax, using brackets [ ] subset want see.","code":"\nView(linelist)\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-3","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning-data-and-core-functions.html","id":"row-wise-calculations","chapter":"8 Cleaning data and core functions","heading":"8.12 Row-wise calculations","text":"want perform calculation within row, can use rowwise() dplyr. See online vignette row-wise calculations.\nexample, code applies rowwise() creates new column sums number specified symptom columns value “yes”, row linelist. columns specified within sum() name within vector c(). rowwise() essentially special kind group_by(), best use ungroup() done (page Grouping data).specify column evaluate, may want use “tidyselect” helper functions described select() section page. just make one adjustment (using within dplyr function like select() summarise()).Put column-specification criteria within dplyr function c_across(). c_across (documentation) designed work rowwise() specifically. example, following code:Applies rowwise() following operation (sum()) applied within row (summing entire columns)Creates new column num_NA_dates, defined row number columns (name containing “date”) .na() evaluated TRUE (missing data).ungroup() remove effects rowwise() subsequent stepsYou also provide functions, max() get latest recent date row:","code":"\nlinelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %>% \n  ungroup() %>% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display## # A tibble: 5,888 × 6\n##    fever chills cough aches vomit num_symptoms\n##    <chr> <chr>  <chr> <chr> <chr>        <int>\n##  1 no    no     yes   no    yes              2\n##  2 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  3 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  4 no    no     no    no    no               0\n##  5 no    no     yes   no    yes              2\n##  6 no    no     yes   no    yes              2\n##  7 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  8 no    no     yes   no    yes              2\n##  9 no    no     yes   no    yes              2\n## 10 no    no     yes   no    no               1\n## # ℹ 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %>% \n  ungroup() %>% \n  select(num_NA_dates, contains(\"date\")) # for display## # A tibble: 5,888 × 5\n##    num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n##           <int> <date>         <date>     <date>               <date>      \n##  1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n##  2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n##  3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n##  4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n##  5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n## 10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n## # ℹ 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %>% \n  ungroup() %>% \n  select(latest_date, contains(\"date\"))  # for display## # A tibble: 5,888 × 5\n##    latest_date date_infection date_onset date_hospitalisation date_outcome\n##    <date>      <date>         <date>     <date>               <date>      \n##  1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n##  2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n##  3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n##  4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n##  5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n## 10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n## # ℹ 5,878 more rows"},{"path":"cleaning-data-and-core-functions.html","id":"arrange-and-sort","chapter":"8 Cleaning data and core functions","heading":"8.13 Arrange and sort","text":"Use dplyr function arrange() sort order rows column values.Simple list columns order sorted . Specify .by_group = TRUE want sorting first occur groupings applied data (see page Grouping data).default, column sorted “ascending” order (applies numeric also character columns). can sort variable “descending” order wrapping desc().Sorting data arrange() particularly useful making Tables presentation, using slice() take “top” rows per group, setting factor level order order appearance.example, sort linelist rows hospital, date_onset descending order, use:","code":"\nlinelist %>% \n   arrange(hospital, desc(date_onset))"},{"path":"working-with-dates.html","id":"working-with-dates","chapter":"9 Working with dates","heading":"9 Working with dates","text":"Working dates R requires attention working object classes. , offer tools example make process less painful. Luckily, dates can wrangled easily practice, set helpful packages lubridate.Upon import raw data, R often interprets dates character objects - means used general date operations making time series calculating time intervals. make matters difficult, many ways date can formatted must help R know part date represents (month, day, hour, etc.).Dates R class object - Date class. noted also class stores objects date time. Date time objects formally referred POSIXt, POSIXct, /POSIXlt classes (difference isn’t important). objects informally referred datetime classes.important make R recognize column contains dates.Dates object class can tricky work .present several ways convert date columns Date class.","code":""},{"path":"working-with-dates.html","id":"preparation","chapter":"9 Working with dates","heading":"9.1 Preparation","text":"","code":""},{"path":"working-with-dates.html","id":"load-packages-1","chapter":"9 Working with dates","heading":"Load packages","text":"code chunk shows loading packages required page. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\n# Checks if package is installed, installs if necessary, and loads package for current session\n\npacman::p_load(\n  lubridate,  # general package for handling and converting dates  \n  parsedate,   # has function to \"guess\" messy dates\n  aweek,      # another option for converting dates to weeks, and weeks to dates\n  zoo,        # additional date/time functions\n  tidyverse,  # data management and visualization  \n  rio)        # data import/export"},{"path":"working-with-dates.html","id":"import-data-2","chapter":"9 Working with dates","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow along step--step, see instruction Download handbook data page. assume file working directory sub-folders specified file path.","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"working-with-dates.html","id":"current-date","chapter":"9 Working with dates","heading":"9.2 Current date","text":"can get current “system” date system datetime computer following base R.lubridate package can also returned today() now(), respectively. date() returns current date time weekday month names.","code":"\n# get the system date - this is a DATE class\nSys.Date()## [1] \"2023-07-18\"\n# get the system time - this is a DATETIME class\nSys.time()## [1] \"2023-07-18 15:34:00 CEST\""},{"path":"working-with-dates.html","id":"convert-to-date","chapter":"9 Working with dates","heading":"9.3 Convert to Date","text":"importing dataset R, date column values may look like “1989/12/30”, “05/06/2014”, “13 Jan 2020”. cases, R likely still treating values Character values. R must told values dates… format date (part Day, Month, Year, etc).told, R converts values class Date. background, R store dates numbers (number days “origin” date 1 Jan 1970). interface date number often, allows R treat dates continuous variables allow special operations calculating distance dates.default, values class Date R displayed YYYY-MM-DD. Later section discuss change display date values.present two approaches converting column character values class Date.TIP: can check current class column base R function class(), like class(linelist$date_onset).","code":""},{"path":"working-with-dates.html","id":"base-r","chapter":"9 Working with dates","heading":"base R","text":".Date() standard, base R function convert object column class Date (note capitalization “D”).Use .Date() requires :specify existing format raw character date origin date supplying dates numbers (see section Excel dates)used character column, date values must exact format (case, try parse_date() parsedate package)First, check class column class() base R. unsure confused class data (e.g. see “POSIXct”, etc.) can easiest first convert column class Character .character(), convert class Date.Second, within .Date() function, use format = argument tell R current format character date components - characters refer month, day, year, separated. values already one R’s standard date formats (“YYYY-MM-DD” “YYYY/MM/DD”) format = argument necessary.format =, provide character string (quotes) represents current date format using special “strptime” abbreviations . example, character dates currently format “DD/MM/YYYY”, like “24/04/1968”, use format = \"%d/%m/%Y\" convert values dates. Putting format quotation marks necessary. don’t forget slashes dashes!strptime abbreviations listed . can see complete list running ?strptime.%d = Day number month (5, 17, 28, etc.)\n%j = Day number year (Julian day 001-366)\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\n%= Full weekday (Monday, Tuesday, etc.)\n%w = Weekday number (0-6, Sunday 0)\n%u = Weekday number (1-7, Monday 1)\n%W = Week number (00-53, Monday week start)\n%U = Week number (01-53, Sunday week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds\n%z = offset GMT\n%Z = Time zone (character)TIP: format = argument .Date() telling R format want dates , rather identify date parts run command.TIP: sure format = argument use date-part separator (e.g. /, -, space) present dates.values class Date, R default display standard format, YYYY-MM-DD.","code":"\n# Convert to class date\nlinelist <- linelist %>% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))"},{"path":"working-with-dates.html","id":"lubridate","chapter":"9 Working with dates","heading":"lubridate","text":"Converting character objects dates can made easier using lubridate package. tidyverse package designed make working dates times simple consistent base R. reasons, lubridate often considered gold-standard package dates time, recommended whenever working .lubridate package provides several different helper functions designed convert character objects dates intuitive, lenient way specifying format .Date(). functions specific rough date format, allow variety separators, synonyms dates (e.g. 01 vs Jan vs January) - named abbreviations date formats.ymd() function flexibly converts date values supplied year, month, day.mdy() function flexibly converts date values supplied month, day, year.dmy() function flexibly converts date values supplied day, month, year.using piping, conversion character column dates lubridate might look like :complete, can run class() verify class columnOnce values class Date, R default display standard format, YYYY-MM-DD.Note functions work best 4-digit years. 2-digit years can produce unexpected results, lubridate attempts guess century.convert 2-digit year 4-digit year (century) can convert class character combine existing digits pre-fix using str_glue() stringr package (see Characters strings). convert date.","code":"\n# install/load lubridate \npacman::p_load(lubridate)\n# read date in year-month-day format\nymd(\"2020-10-11\")## [1] \"2020-10-11\"\nymd(\"20201011\")## [1] \"2020-10-11\"\n# read date in month-day-year format\nmdy(\"10/11/2020\")## [1] \"2020-10-11\"\nmdy(\"Oct 11 20\")## [1] \"2020-10-11\"\n# read date in day-month-year format\ndmy(\"11 10 2020\")## [1] \"2020-10-11\"\ndmy(\"11 October 2020\")## [1] \"2020-10-11\"\nlinelist <- linelist %>%\n  mutate(date_onset = lubridate::dmy(date_onset))\n# Check the class of the column\nclass(linelist$date_onset)  \ntwo_digit_years <- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")## 2015\n## 2015\n## 2016\n## 2017"},{"path":"working-with-dates.html","id":"combine-columns","chapter":"9 Working with dates","heading":"Combine columns","text":"can use lubridate functions make_date() make_datetime() combine multiple numeric columns one date column. example numeric columns onset_day, onset_month, onset_year data frame linelist:","code":"\nlinelist <- linelist %>% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))"},{"path":"working-with-dates.html","id":"excel-dates","chapter":"9 Working with dates","heading":"9.4 Excel dates","text":"background, software store dates numbers. R stores dates origin 1st January, 1970. Thus, run .numeric(.Date(\"1970-01-01)) get 0.Microsoft Excel stores dates origin either December 30, 1899 (Windows) January 1, 1904 (Mac), depending operating system. See Microsoft guidance information.Excel dates often import R numeric values instead characters. dataset imported Excel shows dates numbers characters like “41369”… use .Date() (lubridate’s as_date() function) convert, instead supplying “format” , supply Excel origin date argument origin =.work Excel date stored R character type, sure ensure number class Numeric!NOTE: provide origin date R’s default date format (“YYYY-MM-DD”).","code":"\n# An example of providing the Excel 'origin date' when converting Excel number dates\ndata_cleaned <- data %>% \n  mutate(date_onset = as.numeric(date_onset)) %>%   # ensure class is numeric\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convert to date using Excel origin"},{"path":"working-with-dates.html","id":"messy-dates","chapter":"9 Working with dates","heading":"9.5 Messy dates","text":"function parse_date() parsedate package attempts read “messy” date column containing dates many different formats convert dates standard format. can read online parse_date().example parse_date() see vector following character dates “03 Jan 2018”, “07/03/1982”, “08/20/85” convert class Date : 2018-01-03, 1982-03-07, 1985-08-20.","code":"\nparsedate::parse_date(c(\"03 January 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))## [1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n# An example using parse_date() on the column date_onset\nlinelist <- linelist %>%      \n  mutate(date_onset = parse_date(date_onset))"},{"path":"working-with-dates.html","id":"working-with-date-time-class","chapter":"9 Working with dates","heading":"9.6 Working with date-time class","text":"previously mentioned, R also supports datetime class - column contains date time information. Date class, often need converted character objects datetime objects.","code":""},{"path":"working-with-dates.html","id":"convert-dates-with-times","chapter":"9 Working with dates","heading":"Convert dates with times","text":"standard datetime object formatted date first, followed time component - example 01 Jan 2020, 16:30. dates, many ways can formatted, numerous levels precision (hours, minutes, seconds) can supplied.Luckily, lubridate helper functions also exist help convert strings datetime objects. functions extensions date helper functions, _h (hours supplied), _hm (hours minutes supplied), _hms (hours, minutes, seconds supplied) appended end (e.g. dmy_hms()). can used shown:Convert datetime hours datetime objectConvert datetime hours minutes datetime objectConvert datetime hours, minutes, seconds datetime objectYou can supply time zone ignored. See section later page time zones.working data frame, time date columns can combined create datetime column using str_glue() stringr package appropriate lubridate function. See page Characters strings details stringr.example, linelist data frame column format “hours:minutes”. convert datetime follow steps:Create “clean” time admission column missing values filled-column median. lubridate won’t operate missing values. Combine column date_hospitalisation, use function ymd_hm() convert.","code":"\nymd_h(\"2020-01-01 16hrs\")## [1] \"2020-01-01 16:00:00 UTC\"\nymd_h(\"2020-01-01 4PM\")## [1] \"2020-01-01 16:00:00 UTC\"\ndmy_hm(\"01 January 2020 16:20\")## [1] \"2020-01-01 16:20:00 UTC\"\nmdy_hms(\"01 January 2020, 16:20:40\")## [1] \"2020-01-20 16:20:40 UTC\"\nmdy_hms(\"01 January 2020, 16:20:40 PST\")## [1] \"2020-01-20 16:20:40 UTC\"# packages\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission is a column in hours:minutes\nlinelist <- linelist %>%\n  \n  # when time of admission is not given, assign the median admission time\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # if time is missing\n      median(time_admission),        # assign the median\n      time_admission                 # if not missing keep as is\n  ) %>%\n  \n    # use str_glue() to combine date and time columns to create one character column\n    # and then use ymd_hm() to convert it to datetime\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %>% \n      ymd_hm()\n  )"},{"path":"working-with-dates.html","id":"convert-times-alone","chapter":"9 Working with dates","heading":"Convert times alone","text":"data contain character time (hours minutes), can convert manipulate times using strptime() base R. example, get difference two times:Note however without date value provided, assumes date today. combine string date string time together see use stringr section just . Read strptime() .convert single-digit numbers double-digits (e.g. “pad” hours minutes leading zeros achieve 2 digits), see “Pad length” section Characters strings page.","code":"\n# raw character times\ntime1 <- \"13:45\" \ntime2 <- \"15:20\"\n\n# Times converted to a datetime class\ntime1_clean <- strptime(time1, format = \"%H:%M\")\ntime2_clean <- strptime(time2, format = \"%H:%M\")\n\n# Difference is of class \"difftime\" by default, here converted to numeric hours \nas.numeric(time2_clean - time1_clean)   # difference in hours## [1] 1.583333"},{"path":"working-with-dates.html","id":"extract-time","chapter":"9 Working with dates","heading":"Extract time","text":"can extract elements time hour(), minute(), second() lubridate.example extracting hour, classifing part day. begin column time_admission, class Character format “HH:MM”. First, strptime() used described convert characters datetime class. , hour extracted hour(), returning number 0-24. Finally, column time_period created using logic case_when() classify rows Morning/Afternoon/Evening/Night based hour admission.learn case_when() see page Cleaning data core functions.","code":"\nlinelist <- linelist %>%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %>%\n  mutate(time_period = case_when(\n    hour_admit > 06 & hour_admit < 12 ~ \"Morning\",\n    hour_admit >= 12 & hour_admit < 17 ~ \"Afternoon\",\n    hour_admit >= 17 & hour_admit < 21 ~ \"Evening\",\n    hour_admit >=21 | hour_admit <= 6 ~ \"Night\"))"},{"path":"working-with-dates.html","id":"working-with-dates-1","chapter":"9 Working with dates","heading":"9.7 Working with dates","text":"lubridate can also used variety functions, extracting aspects date/datetime, performing date arithmetic, calculating date intervalsHere define date use examples:","code":"\n# create object of class Date\nexample_date <- ymd(\"2020-03-01\")"},{"path":"working-with-dates.html","id":"extract-date-components","chapter":"9 Working with dates","heading":"Extract date components","text":"can extract common aspects month, day, weekday:can also extract time components datetime object column. can useful want view distribution admission times.several options retrieve weeks. See section Epidemiological weeks .Note seeking display date certain way (e.g. “Jan 2020” “Thursday 20 March” “Week 20, 1977”) can flexibly described section Date display.","code":"\nmonth(example_date)  # month number## [1] 3\nday(example_date)    # day (number) of the month## [1] 1\nwday(example_date)   # day number of the week (1-7)## [1] 1\nexample_datetime <- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # extract hour\nminute(example_datetime)   # extract minute\nsecond(example_datetime)   # extract second"},{"path":"working-with-dates.html","id":"date-math","chapter":"9 Working with dates","heading":"Date math","text":"can add certain numbers days weeks using respective function lubridate.","code":"\n# add 3 days to this date\nexample_date + days(3)## [1] \"2020-03-04\"\n# add 7 weeks and subtract two days from this date\nexample_date + weeks(7) - days(2)## [1] \"2020-04-17\""},{"path":"working-with-dates.html","id":"date-intervals","chapter":"9 Working with dates","heading":"Date intervals","text":"difference dates can calculated :Ensure dates class dateUse subtraction return “difftime” difference two datesIf necessary, convert result numeric class perform subsequent mathematical calculationsBelow interval two dates calculated displayed. can find intervals using subtraction “minus” symbol values class Date. Note, however class returned value “difftime” displayed , must converted numeric.subsequent operations “difftime”, convert numeric .numeric().can brought together work data - example:data frame context, either dates missing, operation fail row. result NA instead numeric value. using column calculations, sure set na.rm = argument TRUE. example:","code":"\n# find the interval between this date and Feb 20 2020 \noutput <- example_date - ymd(\"2020-02-20\")\noutput    # print## Time difference of 10 days\nclass(output)## [1] \"difftime\"\npacman::p_load(lubridate, tidyverse)   # load packages\n\nlinelist <- linelist %>%\n  \n  # convert date of onset from character to date objects by specifying dmy format\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %>%\n  \n  # filter out all cases without onset in march\n  filter(month(date_onset) == 3) %>%\n    \n  # find the difference in days between onset and hospitalisation\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n# calculate the median number of days to hospitalisation for all cases where data are available\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)"},{"path":"working-with-dates.html","id":"date-display","chapter":"9 Working with dates","heading":"9.8 Date display","text":"dates correct class, often want display differently, example display “Monday 05 January” instead “2018-01-05”. may also want adjust display order group rows date elements displayed - example group month-year.","code":""},{"path":"working-with-dates.html","id":"format","chapter":"9 Working with dates","heading":"format()","text":"Adjust date display base R function format(). function accepts character string (quotes) specifying desired output format “%” strptime abbreviations (syntax used .Date()). common abbreviations.Note: using format() convert values class Character, generally used towards end analysis display purposes ! can see complete list running ?strptime.%d = Day number month (5, 17, 28, etc.)\n%j = Day number year (Julian day 001-366)\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\n%= Full weekday (Monday, Tuesday, etc.)\n%w = Weekday number (0-6, Sunday 0)\n%u = Weekday number (1-7, Monday 1)\n%W = Week number (00-53, Monday week start)\n%U = Week number (01-53, Sunday week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds\n%z = offset GMT\n%Z = Time zone (character)example formatting today’s date:Note using str_glue(), aware within expected double quotes ” use single quotes ().","code":"\n# today's date, with formatting\nformat(Sys.Date(), format = \"%d %B %Y\")## [1] \"18 July 2023\"\n# easy way to get full date and time (default formatting)\ndate()## [1] \"Tue Jul 18 15:34:01 2023\"\n# formatted combined date, time, and time zone using str_glue() function\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")## Tuesday, July 18 2023, +0000  UTC, 15:34:01\n# Using format to display weeks\nformat(Sys.Date(), \"%Y Week %W\")## [1] \"2023 Week 29\""},{"path":"working-with-dates.html","id":"month-year","chapter":"9 Working with dates","heading":"Month-Year","text":"convert Date column Month-year format, suggest use function .yearmon() zoo package. converts date class “yearmon” retains proper ordering. contrast, using format(column, \"%Y %B\") convert class Character order values alphabetically (incorrectly)., new column yearmonth created column date_onset, using .yearmon() function. default (correct) ordering resulting values shown table.contrast, can see using format() achieve desired display format, correct ordering.Note: working within ggplot() want adjust dates displayed , may sufficient provide strptime format date_labels = argument scale_x_date() - can use \"%b %Y\" \"%Y %b\". See ggplot tips page.zoo also offers function .yearqtr(), can use scale_x_yearmon() using ggplot().","code":"\n# create new column \ntest_zoo <- linelist %>% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# print table\ntable(test_zoo$yearmon)## \n## Apr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 Dec 2014 Jan 2015 Feb 2015 Mar 2015 Apr 2015 \n##        7       64      100      226      528     1070     1112      763      562      431      306      277      186\n# create new column\ntest_format <- linelist %>% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# print table\ntable(test_format$yearmon)## \n## Apr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 Mar 2015 May 2014 Nov 2014 Oct 2014 Sep 2014 \n##        7      186      528      562      306      431      226      100      277       64      763     1112     1070"},{"path":"working-with-dates.html","id":"dates_epi_wks","chapter":"9 Working with dates","heading":"9.9 Epidemiological weeks","text":"","code":""},{"path":"working-with-dates.html","id":"lubridate-1","chapter":"9 Working with dates","heading":"lubridate","text":"See page Grouping data extensive examples grouping data date. briefly describe grouping data weeks.generally recommend using floor_date() function lubridate, argument unit = \"week\". rounds date “start” week, defined argument week_start =. default week start 1 (Mondays) can specify day week start (e.g. 7 Sundays). floor_date() versitile can used round time units setting unit = “second”, “minute”, “hour”, “day”, “month”, “year”.returned value start date week, Date class. Date class useful plotting data, easily recognized ordered correctly ggplot().interested adjusting dates display week plot, see section page Date display. example plotting epicurve can format date display providing desired strptime “%” nomenclature. example, use “%Y-%W” “%Y-%U” return year week number (given Monday Sunday week start, respectively).","code":""},{"path":"working-with-dates.html","id":"weekly-counts","chapter":"9 Working with dates","heading":"Weekly counts","text":"See page Grouping data thorough explanation grouping data count(), group_by(), summarise(). brief example .Create new ‘week’ column mutate(), using floor_date() unit = \"week\"Get counts rows (cases) per week count(); filter cases missing dateFinish complete() tidyr ensure weeks appear data - even rows/cases. default count values “new” rows NA, can make 0 fill = argument, expects named list (, n name counts column).first rows resulting data frame:","code":"\n# Make aggregated dataset of weekly case counts\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%             # remove cases missing onset date\n  mutate(weekly_cases = floor_date(   # make new column, week of onset\n    date_onset,\n    unit = \"week\")) %>%            \n  count(weekly_cases) %>%           # group data by week and count rows per group (creates column 'n')\n  tidyr::complete(                  # ensure all weeks are present, even those with no cases reported\n    weekly_cases = seq.Date(          # re-define the \"weekly_cases\" column as a complete sequence,\n      from = min(weekly_cases),       # from the minimum date\n      to = max(weekly_cases),         # to the maxiumum date\n      by = \"week\"),                   # by weeks\n    fill = list(n = 0))             # fill-in NAs in the n counts column with 0"},{"path":"working-with-dates.html","id":"epiweek-alternatives","chapter":"9 Working with dates","heading":"Epiweek alternatives","text":"Note lubridate also functions week(), epiweek(), isoweek(), slightly different start dates nuances. Generally speaking though, floor_date() need. Read details functions entering ?week console reading documentation .might consider using package aweek set epidemiological weeks. can read RECON website. functions date2week() week2date() can set week start day week_start = \"Monday\". package easiest want “week”-style outputs (e.g. “2020-W12”). Another advantage aweek date2week() applied date column, returned column (week format) automatically class Factor includes levels weeks time span (avoids extra step complete() described ). However, aweek functionality round dates time units months, years, etc.Another alternative time series also works well show “week” format (“2020 W12”) yearweek() package tsibble, demonstrated page Time series outbreak detection.","code":""},{"path":"working-with-dates.html","id":"converting-datestime-zones","chapter":"9 Working with dates","heading":"9.10 Converting dates/time zones","text":"data present different time time zones, can often important standardise data unified time zone. can present challenge, time zone component data must coded manually cases.R, datetime object timezone component. default, datetime objects carry local time zone computer used - generally specific location rather named timezone, time zones often change locations due daylight savings time. possible accurately compensate time zones without time component date, event date column represents attributed specific time, therefore time shifts measured hours reasonably accounted .deal time zones, number helper functions lubridate can used change time zone datetime object local time zone different time zone. Time zones set attributing valid tz database time zone datetime object. list can found - location using data list, nearby large cities time zone available serve purpose.https://en.wikipedia.org/wiki/List_of_tz_database_time_zonesThis may seem largely abstract, often needed user isn’t working across time zones.","code":"\n# assign the current time to a column\ntime_now <- Sys.time()\ntime_now## [1] \"2023-07-18 15:34:02 CEST\"\n# use with_tz() to assign a new timezone to the column, while CHANGING the clock time\ntime_london_real <- with_tz(time_now, \"Europe/London\")\n\n# use force_tz() to assign a new timezone to the column, while KEEPING the clock time\ntime_london_local <- force_tz(time_now, \"Europe/London\")\n\n\n# note that as long as the computer that was used to run this code is NOT set to London time,\n# there will be a difference in the times \n# (the number of hours difference from the computers time zone to london)\ntime_london_real - time_london_local## Time difference of -1 hours"},{"path":"working-with-dates.html","id":"lagging-and-leading-calculations","chapter":"9 Working with dates","heading":"9.11 Lagging and leading calculations","text":"lead() lag() functions dplyr package help find previous (lagged) subsequent (leading) values vector - typically numeric date vector. useful calculations change/difference time units.Let’s say want calculate difference cases current week previous one. data initially provided weekly counts shown .using lag() lead() order rows dataframe important! - pay attention whether dates/numbers ascending descendingFirst, create new column containing value previous (lagged) week.Control number units back/forward n = (must non-negative integer)Use default = define value placed non-existing rows (e.g. first row lagged value). default NA.Use order_by = TRUE rows ordered reference columnNext, create new column difference two cases columns:can read lead() lag() documentation entering ?lag console.","code":"\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)"},{"path":"working-with-dates.html","id":"resources-2","chapter":"9 Working with dates","heading":"9.12 Resources","text":"lubridate tidyverse pagelubridate RStudio cheatsheet\nR Data Science page dates timesOnline tutorial\nDate formats","code":""},{"path":"characters-and-strings.html","id":"characters-and-strings","chapter":"10 Characters and strings","heading":"10 Characters and strings","text":"page demonstrates use stringr package evaluate handle character values (“strings”).Combine, order, split, arrange - str_c(), str_glue(), str_order(), str_split()Clean standardise\nAdjust length - str_pad(), str_trunc(), str_wrap()\nChange case - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()\nAdjust length - str_pad(), str_trunc(), str_wrap()Change case - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()Evaluate extract position - str_length(), str_sub(), word()Patterns\nDetect locate - str_detect(), str_subset(), str_match(), str_extract()\nModify replace - str_sub(), str_replace_all()\nDetect locate - str_detect(), str_subset(), str_match(), str_extract()Modify replace - str_sub(), str_replace_all()Regular expressions (“regex”)ease display examples shown acting short defined character vector, however can easily adapted column within data frame.stringr vignette provided much inspiration page.","code":""},{"path":"characters-and-strings.html","id":"preparation-1","chapter":"10 Characters and strings","heading":"10.1 Preparation","text":"","code":""},{"path":"characters-and-strings.html","id":"load-packages-2","chapter":"10 Characters and strings","heading":"Load packages","text":"Install load stringr tidyverse packages.","code":"\n# install/load packages\npacman::p_load(\n  stringr,    # many functions for handling strings\n  tidyverse,  # for optional data manipulation\n  tools)      # alternative for converting to title case"},{"path":"characters-and-strings.html","id":"import-data-3","chapter":"10 Characters and strings","heading":"Import data","text":"page occassionally reference cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"characters-and-strings.html","id":"unite-split-and-arrange","chapter":"10 Characters and strings","heading":"10.2 Unite, split, and arrange","text":"section covers:Using str_c(), str_glue(), unite() combine stringsUsing str_order() arrange stringsUsing str_split() separate() split strings","code":""},{"path":"characters-and-strings.html","id":"combine-strings","chapter":"10 Characters and strings","heading":"Combine strings","text":"combine concatenate multiple strings one string, suggest using str_c stringr. distinct character values combine, simply provide unique arguments, separated commas.argument sep = inserts character value arguments provided (e.g. inserting comma, space, newline \"\\n\")argument collapse = relevant inputting multiple vectors arguments str_c(). used separate elements output vector, output vector one long character element.example shows combination two vectors one (first names last names). Another similar example might jurisdictions case counts. example:sep = value appears first last nameThe collapse = value appears personNote: Depending desired display context, printing combined string newlines, may need wrap whole phrase cat() newlines print properly:","code":"\nstr_c(\"String1\", \"String2\", \"String3\")## [1] \"String1String2String3\"\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")## [1] \"String1, String2, String3\"\nfirst_names <- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  <- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep displays between the respective input strings, while collapse displays between the elements produced\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")## [1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n# For newlines to print correctly, the phrase may need to be wrapped in cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))## abdul hussein;\n## fahruk akinleye;\n## janice okeke"},{"path":"characters-and-strings.html","id":"dynamic-strings","chapter":"10 Characters and strings","heading":"Dynamic strings","text":"Use str_glue() insert dynamic R code string. useful function creating dynamic plot captions, demonstrated .content goes double quotation marks str_glue(\"\")dynamic code references pre-defined values placed within curly brackets {} within double quotation marks. can many curly brackets str_glue() command.display character quotes ’’, use single quotes within surrounding double quotes (e.g. providing date format - see example )Tip: can use \\n force new lineTip: use format() adjust date display, use Sys.Date() display current dateA simple example, dynamic plot caption:alternative format use placeholders within brackets define code separate arguments end str_glue() function, . can improve code readability text long.Pulling data frameSometimes, useful pull data data frame pasted together sequence. example data frame. use make summary statement jurisdictions new total case counts.Use str_glue_data(), specially made taking data data frame rows:Combine strings across rowsIf trying “roll-” values data frame column, e.g. combine values multiple rows just one row pasting together separator, see section De-duplication page “rolling-” values.Data frame one lineYou can make statement appear one line using str_c() (specifying data frame column names), providing sep = collapse = arguments.add pre-fix text “New Cases:” beginning statement wrapping separate str_c() (“New Cases:” within original str_c() appear multiple times).","code":"\nstr_glue(\"Data include {nrow(linelist)} cases and are current to {format(Sys.Date(), '%d %b %Y')}.\")## Data include 5888 cases and are current to 18 Jul 2023.\nstr_glue(\"Linelist as of {current_date}.\\nLast case hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))\n         )## Linelist as of 18 Jul 2023.\n## Last case hospitalized on 30 Apr 2015.\n## 256 cases are missing date of onset and not shown\n# make case data frame\ncase_table <- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\ncase_table %>% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")## Zone 1: 3 (40 total cases)\n## Zone 2: 0 (4 total cases)\n## Zone 3: 7 (25 total cases)\n## Zone 4: 0 (10 total cases)\n## Zone 5: 15 (103 total cases)\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")## [1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))## [1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\""},{"path":"characters-and-strings.html","id":"str_unite","chapter":"10 Characters and strings","heading":"Unite columns","text":"Within data frame, bringing together character values multiple columns can achieved unite() tidyr. opposite separate().Provide name new united column. provide names columns wish unite.default, separator used united column underscore _, can changed sep = argument.remove = removes input columns data frame (TRUE default)na.rm = removes missing values uniting (FALSE default), define mini-data frame demonstrate :example data frame:, unite three symptom columns:","code":"\ndf <- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # patient 1\n                \"chills, aches, pains\",        # patient 2 \n                \"fever\",                       # patient 3\n                \"vomiting, diarrhoea\",         # patient 4\n                \"bleeding from gums, fever\",   # patient 5\n                \"rapid pulse, headache\"),      # patient 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\ndf_split <- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\ndf_split %>% \n  unite(\n    col = \"all_symptoms\",         # name of the new united column\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # columns to unite\n    sep = \", \",                   # separator to use in united column\n    remove = TRUE,                # if TRUE, removes input cols from the data frame\n    na.rm = TRUE                  # if TRUE, missing values are removed before uniting\n  )##   case_ID                all_symptoms outcome\n## 1       1     jaundice, fever, chills Recover\n## 2       2        chills, aches, pains   Death\n## 3       3                       fever   Death\n## 4       4         vomiting, diarrhoea Recover\n## 5       5 bleeding, from, gums, fever Recover\n## 6       6      rapid, pulse, headache Recover"},{"path":"characters-and-strings.html","id":"split","chapter":"10 Characters and strings","heading":"Split","text":"split string based pattern, use str_split(). evaluates string(s) returns list character vectors consisting newly-split values.simple example evaluates one string splits three. default returns object class list one element (character vector) string initially provided. simplify = TRUE returns character matrix.example, one string provided, function returns list one element - character vector three values.output saved, can access nth split value bracket syntax. access specific value can use syntax like : the_returned_object[[1]][2], access second value first evaluated string (“fever”). See R basics page detail accessing elements.multiple strings provided str_split(), one element returned list.return “character matrix” instead, may useful creating data frame columns, set argument simplify = TRUE shown :can also adjust number splits create n = argument. example, restricts number splits 2. commas remain within second values.Note - outputs can achieved str_split_fixed(), give simplify argument, must instead designate number columns (n).","code":"\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\"\npt1_symptoms <- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extracts 2nd value from 1st (and only) element of the list## [1] \" fever\"\nsymptoms <- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\" \n## \n## [[2]]\n## [1] \"chills\" \" aches\" \" pains\"\n## \n## [[3]]\n## [1] \"fever\"\n## \n## [[4]]\n## [1] \"vomiting\"   \" diarrhoea\"\n## \n## [[5]]\n## [1] \"bleeding from gums\" \" fever\"            \n## \n## [[6]]\n## [1] \"rapid pulse\" \" headache\"\nstr_split(symptoms, \",\", simplify = TRUE)##      [,1]                 [,2]         [,3]     \n## [1,] \"jaundice\"           \" fever\"     \" chills\"\n## [2,] \"chills\"             \" aches\"     \" pains\" \n## [3,] \"fever\"              \"\"           \"\"       \n## [4,] \"vomiting\"           \" diarrhoea\" \"\"       \n## [5,] \"bleeding from gums\" \" fever\"     \"\"       \n## [6,] \"rapid pulse\"        \" headache\"  \"\"\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)##      [,1]                 [,2]            \n## [1,] \"jaundice\"           \" fever, chills\"\n## [2,] \"chills\"             \" aches, pains\" \n## [3,] \"fever\"              \"\"              \n## [4,] \"vomiting\"           \" diarrhoea\"    \n## [5,] \"bleeding from gums\" \" fever\"        \n## [6,] \"rapid pulse\"        \" headache\"\nstr_split_fixed(symptoms, \",\", n = 2)"},{"path":"characters-and-strings.html","id":"split-columns","chapter":"10 Characters and strings","heading":"Split columns","text":"trying split data frame column, best use separate() function dplyr. used split one character column columns.Let’s say simple data frame df (defined united unite section) containing case_ID column, one character column many symptoms, one outcome column. goal separate symptoms column many columns - one containing one symptom.Assuming data piped separate(), first provide column separated. provide = vector c( ) containing new columns names, shown .sep = separator, can character, number (interpreted character position split )remove = FALSE default, removes input columnconvert = FALSE default, cause string “NA”s become NAextra = controls happens values created separation new columns named.\nextra = \"warn\" means see warning drop excess values (default)\nextra = \"drop\" means excess values dropped warning\nextra = \"merge\" split number new columns listed - setting preserve data\nextra = \"warn\" means see warning drop excess values (default)extra = \"drop\" means excess values dropped warningextra = \"merge\" split number new columns listed - setting preserve dataAn example extra = \"merge\" - data lost. Two new columns defined third symptoms left second new column:default extra = \"drop\" used , warning given third symptoms lost:CAUTION: provide enough values new columns, data may truncated.","code":"\n# third symptoms combined into second new column\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1          sym_2 outcome\n## 1       1           jaundice  fever, chills Recover\n## 2       2             chills   aches, pains   Death\n## 3       3              fever           <NA>   Death\n## 4       4           vomiting      diarrhoea Recover\n## 5       5 bleeding from gums          fever Recover\n## 6       6        rapid pulse       headache Recover\n# third symptoms are lost\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")## Warning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1      sym_2 outcome\n## 1       1           jaundice      fever Recover\n## 2       2             chills      aches   Death\n## 3       3              fever       <NA>   Death\n## 4       4           vomiting  diarrhoea Recover\n## 5       5 bleeding from gums      fever Recover\n## 6       6        rapid pulse   headache Recover"},{"path":"characters-and-strings.html","id":"arrange-alphabetically","chapter":"10 Characters and strings","heading":"Arrange alphabetically","text":"Several strings can sorted alphabetical order. str_order() returns order, str_sort() returns strings order.use different alphabet, add argument locale =. See full list locales entering stringi::stri_locale_list() R console.","code":"\n# strings\nhealth_zones <- c(\"Alba\", \"Takota\", \"Delta\")\n\n# return the alphabetical order\nstr_order(health_zones)## [1] 1 3 2\n# return the strings in alphabetical order\nstr_sort(health_zones)## [1] \"Alba\"   \"Delta\"  \"Takota\""},{"path":"characters-and-strings.html","id":"base-r-functions","chapter":"10 Characters and strings","heading":"base R functions","text":"common see base R functions paste() paste0(), concatenate vectors converting parts character. act similarly str_c() syntax arguably complicated - parentheses part separated comma. parts either character text (quotes) pre-defined code objects (quotes). example:sep = collapse = arguments can specified. paste() simply paste0() default sep = \" \" (one space).","code":"\nn_beds <- 10\nn_masks <- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")## [1] \"Regional hospital needs 10 beds and 20 masks.\""},{"path":"characters-and-strings.html","id":"clean-and-standardise","chapter":"10 Characters and strings","heading":"10.3 Clean and standardise","text":"","code":""},{"path":"characters-and-strings.html","id":"change-case","chapter":"10 Characters and strings","heading":"Change case","text":"Often one must alter case/capitalization string value, example names jursidictions. Use str_to_upper(), str_to_lower(), str_to_title(), stringr, shown :Using *base** R, can also achieved toupper(), tolower().Title caseTransforming string word capitalized can achieved str_to_title():Use toTitleCase() tools package achieve nuanced capitalization (words like “”, “”, “” capitalized).can also use str_to_sentence(), capitalizes first letter string.","code":"\nstr_to_upper(\"California\")## [1] \"CALIFORNIA\"\nstr_to_lower(\"California\")## [1] \"california\"\nstr_to_title(\"go to the US state of california \")## [1] \"Go To The Us State Of California \"\ntools::toTitleCase(\"This is the US state of california\")## [1] \"This is the US State of California\"\nstr_to_sentence(\"the patient must be transported\")## [1] \"The patient must be transported\""},{"path":"characters-and-strings.html","id":"str_pad","chapter":"10 Characters and strings","heading":"Pad length","text":"Use str_pad() add characters string, minimum length. default spaces added, can also pad characters using pad = argument.example, pad numbers leading zeros (hours minutes), can pad number minimum length 2 pad = \"0\".","code":"\n# ICD codes of differing length\nICD_codes <- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# ICD codes padded to 7 characters on the right side\nstr_pad(ICD_codes, 7, \"right\")## [1] \"R10.13 \" \"R10.819\" \"R17    \"\n# Pad with periods instead of spaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")## [1] \"R10.13.\" \"R10.819\" \"R17....\"\n# Add leading zeros to two digits (e.g. for times minutes/hours)\nstr_pad(\"4\", 2, pad = \"0\") ## [1] \"04\"\n# example using a numeric column named \"hours\"\n# hours <- str_pad(hours, 2, pad = \"0\")"},{"path":"characters-and-strings.html","id":"truncate","chapter":"10 Characters and strings","heading":"Truncate","text":"str_trunc() sets maximum length string. string exceeds length, truncated (shortened) ellipsis (…) included indicate string previously longer. Note ellipsis counted length. ellipsis characters can changed argument ellipsis =. optional side = argument specifies ellipsis appear within truncated string (“left”, “right”, “center”).","code":"\noriginal <- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")## [1] \"Symp...ing\""},{"path":"characters-and-strings.html","id":"standardize-length","chapter":"10 Characters and strings","heading":"Standardize length","text":"Use str_trunc() set maximum length, use str_pad() expand short strings truncated length. example , 6 set maximum length (one value truncated), one short value padded achieve length 6.","code":"\n# ICD codes of differing length\nICD_codes   <- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# truncate to maximum length of 6\nICD_codes_2 <- str_trunc(ICD_codes, 6)\nICD_codes_2## [1] \"R10.13\" \"R10...\" \"R17\"\n# expand to minimum length of 6\nICD_codes_3 <- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3## [1] \"R10.13\" \"R10...\" \"R17   \""},{"path":"characters-and-strings.html","id":"remove-leadingtrailing-whitespace","chapter":"10 Characters and strings","heading":"Remove leading/trailing whitespace","text":"Use str_trim() remove spaces, newlines (\\n) tabs (\\t) sides string input. Add \"right\" \"left\", \"\" command specify side trim (e.g. str_trim(x, \"right\").","code":"\n# ID numbers with excess spaces on right\nIDs <- c(\"provA_1852  \", # two excess spaces\n         \"provA_2345\",   # zero excess spaces\n         \"provA_9460 \")  # one excess space\n\n# IDs trimmed to remove excess spaces on right side only\nstr_trim(IDs)## [1] \"provA_1852\" \"provA_2345\" \"provA_9460\""},{"path":"characters-and-strings.html","id":"remove-repeated-whitespace-within","chapter":"10 Characters and strings","heading":"Remove repeated whitespace within","text":"Use str_squish() remove repeated spaces appear inside string. example, convert double spaces single spaces. also removes spaces, newlines, tabs outside string like str_trim().Enter ?str_trim, ?str_pad R console see details.","code":"\n# original contains excess spaces within string\nstr_squish(\"  Pt requires   IV saline\\n\") ## [1] \"Pt requires IV saline\""},{"path":"characters-and-strings.html","id":"wrap-into-paragraphs","chapter":"10 Characters and strings","heading":"Wrap into paragraphs","text":"Use str_wrap() wrap long unstructured text structured paragraph fixed line length. Provide ideal character length line, applies algorithm insert newlines (\\n) within paragraph, seen example .base function cat() can wrapped around command order print output, displaying new lines added.","code":"\npt_course <- \"Symptom onset 1/4/2020 vomiting chills fever. Pt saw traditional healer in home village on 2/4/2020. On 5/4/2020 pt symptoms worsened and was admitted to Lumta clinic. Sample was taken and pt was transported to regional hospital on 6/4/2020. Pt died at regional hospital on 7/4/2020.\"\n\nstr_wrap(pt_course, 40)## [1] \"Symptom onset 1/4/2020 vomiting chills\\nfever. Pt saw traditional healer in\\nhome village on 2/4/2020. On 5/4/2020\\npt symptoms worsened and was admitted\\nto Lumta clinic. Sample was taken and pt\\nwas transported to regional hospital on\\n6/4/2020. Pt died at regional hospital\\non 7/4/2020.\"\ncat(str_wrap(pt_course, 40))## Symptom onset 1/4/2020 vomiting chills\n## fever. Pt saw traditional healer in\n## home village on 2/4/2020. On 5/4/2020\n## pt symptoms worsened and was admitted\n## to Lumta clinic. Sample was taken and pt\n## was transported to regional hospital on\n## 6/4/2020. Pt died at regional hospital\n## on 7/4/2020."},{"path":"characters-and-strings.html","id":"handle-by-position","chapter":"10 Characters and strings","heading":"10.4 Handle by position","text":"","code":""},{"path":"characters-and-strings.html","id":"extract-by-character-position","chapter":"10 Characters and strings","heading":"Extract by character position","text":"Use str_sub() return part string. function takes three main arguments:character vector(s)start positionend positionA notes position numbers:position number positive, position counted starting left end string.position number negative, counted starting right end string.Position numbers inclusive.Positions extending beyond string truncated (removed).examples applied string “pneumonia”:","code":"\n# start and end third from left (3rd letter from left)\nstr_sub(\"pneumonia\", 3, 3)## [1] \"e\"\n# 0 is not present\nstr_sub(\"pneumonia\", 0, 0)## [1] \"\"\n# 6th from left, to the 1st from right\nstr_sub(\"pneumonia\", 6, -1)## [1] \"onia\"\n# 5th from right, to the 2nd from right\nstr_sub(\"pneumonia\", -5, -2)## [1] \"moni\"\n# 4th from left to a position outside the string\nstr_sub(\"pneumonia\", 4, 15)## [1] \"umonia\""},{"path":"characters-and-strings.html","id":"extract-by-word-position","chapter":"10 Characters and strings","heading":"Extract by word position","text":"extract nth ‘word’, use word(), also stringr. Provide string(s), first word position extract, last word position extract.default, separator ‘words’ assumed space, unless otherwise indicated sep = (e.g. sep = \"_\" words separated underscores.","code":"\n# strings to evaluate\nchief_complaints <- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")## [1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\""},{"path":"characters-and-strings.html","id":"replace-by-character-position","chapter":"10 Characters and strings","heading":"Replace by character position","text":"str_sub() paired assignment operator (<-) can used modify part string:example applied multiple strings (e.g. column). Note expansion length “HIV”.","code":"\nword <- \"pneumonia\"\n\n# convert the third and fourth characters to X \nstr_sub(word, 3, 4) <- \"XX\"\n\n# print\nword## [1] \"pnXXmonia\"\nwords <- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convert the third and fourth characters to X \nstr_sub(words, 3, 4) <- \"XX\"\n\nwords## [1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\""},{"path":"characters-and-strings.html","id":"evaluate-length","chapter":"10 Characters and strings","heading":"Evaluate length","text":"Alternatively, use nchar() base R","code":"\nstr_length(\"abc\")## [1] 3"},{"path":"characters-and-strings.html","id":"patterns","chapter":"10 Characters and strings","heading":"10.5 Patterns","text":"Many stringr functions work detect, locate, extract, match, replace, split based specified pattern.","code":""},{"path":"characters-and-strings.html","id":"detect-a-pattern","chapter":"10 Characters and strings","heading":"Detect a pattern","text":"Use str_detect() detect presence/absence pattern within string. First provide string vector search (string =), pattern look (pattern =). Note default search case sensitive!argument negate = can included set TRUE want know pattern present.ignore case/capitalization, wrap pattern within regex(), within regex() add argument ignore_case = TRUE (T shorthand).str_detect() applied character vector data frame column, return TRUE FALSE values.need count TRUEs, simply sum() output. counts number TRUE.search inclusive multiple terms, include separated bars (|) within pattern = argument, shown :need build long list search terms, can combine using str_c() sep = |, define character object, reference vector later succinctly. example includes possible occupation search terms front-line medical providers.command returns number occupations contain one search terms front-line medical providers (occupation_med_frontline):Base R string search functionsThe base function grepl() works similarly str_detect(), searches matches pattern returns logical vector. basic syntax grepl(pattern, strings_to_search, ignore.case = FALSE, ...). One advantage ignore.case argument easier write (need involve regex() function).Likewise, base functions sub() gsub() act similarly str_replace(). basic syntax : gsub(pattern, replacement, strings_to_search, ignore.case = FALSE). sub() replace first instance pattern, whereas gsub() replace instances pattern.","code":"\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")## [1] TRUE\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)## [1] FALSE\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))## [1] TRUE\n# a vector/column of occupations \noccupations <- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# Detect presence of pattern \"teach\" in each string - output is vector of TRUE/FALSE\nstr_detect(occupations, \"teach\")##  [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nsum(str_detect(occupations, \"teach\"))## [1] 1\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))## [1] 3\n# search terms\noccupation_med_frontline <- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline## [1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))## [1] 2"},{"path":"characters-and-strings.html","id":"convert-commas-to-periods","chapter":"10 Characters and strings","heading":"Convert commas to periods","text":"example using gsub() convert commas periods vector numbers. useful data come parts world United States Great Britain.inner gsub() acts first lengths converting periods space ““. period character”.” “escaped” two slashes actually signify period, “.” regex means “character”. , result (commas) passed outer gsub() commas replaced periods.","code":"\nlengths <- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # find commas     \n                replacement = \".\",            # replace with periods\n                x = gsub(\"\\\\.\", \"\", lengths)  # vector with other periods removed (periods escaped)\n                )\n           )                                  # convert outcome to numeric"},{"path":"characters-and-strings.html","id":"replace-all","chapter":"10 Characters and strings","heading":"Replace all","text":"Use str_replace_all() “find replace” tool. First, provide strings evaluated string =, pattern replaced pattern =, replacement value replacement =. example replaces instances “dead” “deceased”. Note, case sensitive.Notes:replace pattern NA, use str_replace_na().function str_replace() replaces first instance pattern within evaluated string.","code":"\noutcome <- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")## [1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\""},{"path":"characters-and-strings.html","id":"detect-within-logic","chapter":"10 Characters and strings","heading":"Detect within logic","text":"Within case_when()str_detect() often used within case_when() (dplyr). Let’s say occupations column linelist. mutate() creates new column called is_educator using conditional logic via case_when(). See page data cleaning learn case_when().reminder, may important add exclusion criteria conditional logic (negate = F):","code":"\ndf <- df %>% \n  mutate(is_educator = case_when(\n    # term search within occupation, not case sensitive\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))df <- df %>% \n  # value in new column is_educator is based on conditional logic\n  mutate(is_educator = case_when(\n    \n    # occupation column must meet 2 criteria to be assigned \"Educator\":\n    # it must have a search term AND NOT any exclusion term\n    \n    # Must have a search term\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # AND must NOT have an exclusion term\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # All rows not meeting above criteria\n    TRUE                                            ~ \"Not an educator\"))"},{"path":"characters-and-strings.html","id":"locate-pattern-position","chapter":"10 Characters and strings","heading":"Locate pattern position","text":"locate first position pattern, use str_locate(). outputs start end position.Like str functions, “_all” version (str_locate_all()) return positions instances pattern within string. outputs list.","code":"\nstr_locate(\"I wish\", \"sh\")##      start end\n## [1,]     5   6\nphrases <- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # position of *first* instance of the pattern##      start end\n## [1,]     6   6\n## [2,]     3   3\n## [3,]     1   1\n## [4,]     4   4\nstr_locate_all(phrases, \"h\" ) # position of *every* instance of the pattern## [[1]]\n##      start end\n## [1,]     6   6\n## \n## [[2]]\n##      start end\n## [1,]     3   3\n## \n## [[3]]\n##      start end\n## [1,]     1   1\n## [2,]     4   4\n## \n## [[4]]\n##      start end\n## [1,]     4   4"},{"path":"characters-and-strings.html","id":"extract-a-match","chapter":"10 Characters and strings","heading":"Extract a match","text":"str_extract_all() returns matching patterns , useful offered several patterns via “” conditions. example, looking string vector occupations (see previous tab) either “teach”, “prof”, “tutor”.str_extract_all() returns list contains matches evaluated string. See occupation 3 two pattern matches within .str_extract() extracts first match evaluated string, producing character vector one element evaluated string. returns NA match. NAs can removed wrapping returned vector na.exclude(). Note second occupation 3’s matches shown.","code":"\nstr_extract_all(occupations, \"teach|prof|tutor\")## [[1]]\n## character(0)\n## \n## [[2]]\n## [1] \"prof\"\n## \n## [[3]]\n## [1] \"teach\" \"tutor\"\n## \n## [[4]]\n## [1] \"tutor\"\n## \n## [[5]]\n## character(0)\n## \n## [[6]]\n## character(0)\n## \n## [[7]]\n## character(0)\n## \n## [[8]]\n## character(0)\n## \n## [[9]]\n## character(0)\n## \n## [[10]]\n## character(0)\nstr_extract(occupations, \"teach|prof|tutor\")##  [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA      NA"},{"path":"characters-and-strings.html","id":"subset-and-count","chapter":"10 Characters and strings","heading":"Subset and count","text":"Aligned functions include str_subset() str_count().str_subset() returns actual values contained pattern:str_count() returns vector numbers: number times search term appears evaluated value.","code":"\nstr_subset(occupations, \"teach|prof|tutor\")## [1] \"university professor\"           \"primary school teacher & tutor\" \"tutor\"\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))##  [1] 0 1 2 1 0 0 0 0 0 0"},{"path":"characters-and-strings.html","id":"regex-groups","chapter":"10 Characters and strings","heading":"Regex groups","text":"CONSTRUCTION","code":""},{"path":"characters-and-strings.html","id":"special-characters","chapter":"10 Characters and strings","heading":"10.6 Special characters","text":"Backslash \\ escapeThe backslash \\ used “escape” meaning next character. way, backslash can used quote mark display within quote marks (\\\") - middle quote mark “break” surrounding quote marks.Note - thus, want display backslash, must escape ’s meaning another backslash. must write two backslashes \\\\ display one.Special charactersRun ?\"'\" R Console display complete list special characters (appear RStudio Help pane).","code":""},{"path":"characters-and-strings.html","id":"regular-expressions-regex","chapter":"10 Characters and strings","heading":"10.7 Regular expressions (regex)","text":"","code":""},{"path":"characters-and-strings.html","id":"regex-and-special-characters","chapter":"10 Characters and strings","heading":"10.8 Regex and special characters","text":"Regular expressions, “regex”, concise language describing patterns strings. familiar , regular expression can look like alien language. try de-mystify language little bit.Much section adapted tutorial cheatsheet. selectively adapt knowing handbook might viewed people without internet access view tutorials.regular expression often applied extract specific patterns “unstructured” text - example medical notes, chief complaints, patient history, free text columns data frameThere four basic tools one can use create basic regular expression:Character setsMeta charactersQuantifiersGroupsCharacter setsCharacter sets, way expressing listing options character match, within brackets. match triggered characters within brackets found string. example, look vowels one use character set: “[aeiou]”. common character sets :Character sets can combined within one bracket (spaces!), \"[-Za-z]\" (upper lowercase letter), another example \"[t-z0-5]\" (lowercase t z number 0 5).Meta charactersMeta characters shorthand character sets. important ones listed :QuantifiersTypically want search match one character. Quantifiers allow designate length letters/numbers allow match.Quantifiers numbers written within curly brackets { } character quantifying, example,\"{2}\" return instances two capital letters.\"{2,4}\" return instances two four capital letters (put spaces!).\"{2,}\" return instances two capital letters.\"+\" return instances one capital letters (group extended different character encountered).Precede * asterisk return zero matches (useful sure pattern present)Using + plus symbol quantifier, match occur different character encountered. example, expression return words (alpha characters: \"[-Za-z]+\"quantifier {2} used, pairs consecutive ’s returned. Two pairs identified within AAAA.quantifier {2,4} used, groups consecutive ’s two four length returned.quantifier +, groups one returned:Relative positionThese express requirements precedes follows pattern. example, extract sentences, “two numbers followed period” (\"\"). (?<=\\.)\\s(?=[-Z])GroupsCapturing groups regular expression way organized output upon extraction.Regex examplesBelow free text examples. try extract useful information using regular expression search term.expression matches words (character hitting non-character space):expression \"[0-9]{1,2}\" matches consecutive numbers 1 2 digits length. also written \"\\\\d{1,2}\", \"[:digit:]{1,2}\".can view useful list regex expressions tips page 2 cheatsheetAlso see tutorial.","code":"\n# test string for quantifiers\ntest <- \"A-AA-AAA-AAAA\"\nstr_extract_all(test, \"A{2}\")## [[1]]\n## [1] \"AA\" \"AA\" \"AA\" \"AA\"\nstr_extract_all(test, \"A{2,4}\")## [[1]]\n## [1] \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"A+\")## [[1]]\n## [1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"\")## [[1]]\n##  [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\npt_note <- \"Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute.\"\nstr_extract_all(pt_note, \"[A-Za-z]+\")## [[1]]\n##  [1] \"Patient\"     \"arrived\"     \"at\"          \"Broward\"     \"Hospital\"    \"emergency\"   \"ward\"        \"at\"         \n##  [9] \"on\"          \"Patient\"     \"presented\"   \"with\"        \"radiating\"   \"abdominal\"   \"pain\"        \"from\"       \n## [17] \"LR\"          \"quadrant\"    \"Patient\"     \"skin\"        \"was\"         \"pale\"        \"cool\"        \"and\"        \n## [25] \"clammy\"      \"Patient\"     \"temperature\" \"was\"         \"degrees\"     \"farinheit\"   \"Patient\"     \"pulse\"      \n## [33] \"rate\"        \"was\"         \"bpm\"         \"and\"         \"thready\"     \"Respiratory\" \"rate\"        \"was\"        \n## [41] \"per\"         \"minute\"\nstr_extract_all(pt_note, \"[0-9]{1,2}\")## [[1]]\n##  [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\""},{"path":"characters-and-strings.html","id":"resources-3","chapter":"10 Characters and strings","heading":"10.9 Resources","text":"reference sheet stringr functions can found hereA vignette stringr can found ","code":""},{"path":"factors.html","id":"factors","chapter":"11 Factors","heading":"11 Factors","text":"R, factors class data allow ordered categories fixed set acceptable values.Typically, convert column character numeric class factor want set intrinsic order values (“levels”) can displayed non-alphabetically plots tables. Another common use factors standardise legends plots fluctuate certain values temporarily absent data.page demonstrates use functions package forcats (short name “categorical variables”) base R functions. also touch upon use lubridate aweek special factor cases related epidemiological weeks.complete list forcats functions can found online . demonstrate common ones.","code":""},{"path":"factors.html","id":"preparation-2","chapter":"11 Factors","heading":"11.1 Preparation","text":"","code":""},{"path":"factors.html","id":"load-packages-3","chapter":"11 Factors","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,           # import/export\n  here,          # filepaths\n  lubridate,     # working with dates\n  forcats,       # factors\n  aweek,         # create epiweeks with automatic factor levels\n  janitor,       # tables\n  tidyverse      # data mgmt and viz\n  )"},{"path":"factors.html","id":"import-data-4","chapter":"11 Factors","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).","code":"\n# import your dataset\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"factors.html","id":"fct_newcat","chapter":"11 Factors","heading":"New categorical variable","text":"demonstration page use common scenario - creation new categorical variable.Note convert numeric column class factor, able calculate numeric statistics .","code":""},{"path":"factors.html","id":"create-column","chapter":"11 Factors","heading":"Create column","text":"use existing column days_onset_hosp (days symptom onset hospital admission) create new column delay_cat classifying row one several categories. dplyr function case_when(), sequentially applies logical criteria (right-side) row returns corresponding left-side value new column delay_cat. Read case_when() Cleaning data core functions.","code":"\nlinelist <- linelist %>% \n  mutate(delay_cat = case_when(\n    # criteria                                   # new value if TRUE\n    days_onset_hosp < 2                        ~ \"<2 days\",\n    days_onset_hosp >= 2 & days_onset_hosp < 5 ~ \"2-5 days\",\n    days_onset_hosp >= 5                       ~ \">5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  "},{"path":"factors.html","id":"default-value-order","chapter":"11 Factors","heading":"Default value order","text":"created case_when(), new column delay_cat categorical column class Character - yet factor. Thus, frequency table, see unique values appear default alpha-numeric order - order make much intuitive sense:Likewise, make bar plot, values also appear order x-axis (see ggplot basics page ggplot2 - common visualization package R).","code":"\ntable(linelist$delay_cat, useNA = \"always\")## \n##  <2 days  >5 days 2-5 days     <NA> \n##     2990      602     2040      256\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"convert-to-factor","chapter":"11 Factors","heading":"11.2 Convert to factor","text":"convert character numeric column class factor, can use function forcats package (many detailed ). convert class factor also perform allow certain ordering levels - example using fct_relevel() lets manually specify level order. function as_factor() simply converts class without capabilities.base R function factor() converts column factor allows manually specify order levels, character vector levels = argument.use mutate() fct_relevel() convert column delay_cat class character class factor. column delay_cat created Preparation section .unique “values” column now considered “levels” factor. levels order, can printed base R function levels(), alternatively viewed count table via table() base R tabyl() janitor. default, order levels alpha-numeric, . Note NA factor level.function fct_relevel() additional utility allowing manually specify level order. Simply write level values order, quotation marks, separated commas, shown . Note spelling must exactly match values. want create levels exist data, use fct_expand() instead).can now see levels ordered, specified previous command, sensible order.Now plot order makes intuitive sense well.","code":"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \">5 days\"  \"2-5 days\"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", \"2-5 days\", \">5 days\"))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"add-or-drop-levels","chapter":"11 Factors","heading":"11.3 Add or drop levels","text":"","code":""},{"path":"factors.html","id":"fct_add","chapter":"11 Factors","heading":"Add","text":"need add levels factor, can fct_expand(). Just write column name followed new levels (separated commas). tabulating values, can see new levels zero counts. can use table() base R, tabyl() janitor:Note: special forcats function easily add missing values (NA) level. See section Missing values .","code":"\nlinelist %>% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %>% \n  tabyl(delay_cat)   # print table##                       delay_cat    n    percent valid_percent\n##                         <2 days 2990 0.50781250     0.5308949\n##                        2-5 days 2040 0.34646739     0.3622159\n##                         >5 days  602 0.10224185     0.1068892\n##        Not admitted to hospital    0 0.00000000     0.0000000\n##  Transfer to other jurisdiction    0 0.00000000     0.0000000\n##                            <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"drop","chapter":"11 Factors","heading":"Drop","text":"use fct_drop(), “unused” levels zero counts dropped set levels. levels added (“admitted hospital”) exists level rows actually values. dropped applying fct_drop() factor column:","code":"\nlinelist %>% \n  mutate(delay_cat = fct_drop(delay_cat)) %>% \n  tabyl(delay_cat)##  delay_cat    n    percent valid_percent\n##    <2 days 2990 0.50781250     0.5308949\n##   2-5 days 2040 0.34646739     0.3622159\n##    >5 days  602 0.10224185     0.1068892\n##       <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"fct_adjust","chapter":"11 Factors","heading":"11.4 Adjust level order","text":"package forcats offers useful functions easily adjust order factor’s levels (column defined class factor):functions can applied factor column two contexts:column data frame, usual, transformation available subsequent use dataInside plot, change applied within plot","code":""},{"path":"factors.html","id":"manually","chapter":"11 Factors","heading":"Manually","text":"function used manually order factor levels. used non-factor column, column first converted class factor.Within parentheses first provide factor column name, provide either:levels desired order (character vector c()), orOne level ’s corrected placement using = argumentHere example redefining column delay_cat (already class Factor) specifying desired order levels.want move one level, can specify fct_relevel() alone give number = argument indicate order . example, command shifts “<2 days” second position:","code":"\n# re-define level order\nlinelist <- linelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\")))\n# re-define level order\nlinelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", after = 1)) %>% \n  tabyl(delay_cat)"},{"path":"factors.html","id":"within-a-plot","chapter":"11 Factors","heading":"Within a plot","text":"forcats commands can used set level order data frame, within plot. using command “wrap around” column name within ggplot() plotting command, can reverse/relevel/etc. transformation apply within plot., two plots created ggplot() (see ggplot basics page). first, delay_cat column mapped x-axis plot, ’s default level order data linelist. second example wrapped within fct_relevel() order changed plot.Note default x-axis title now quite complicated - can overwrite title ggplot2 labs() argument.","code":"\n# Alpha-numeric default order - no adjustment within ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Factor level order adjusted within ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\"))))"},{"path":"factors.html","id":"reverse","chapter":"11 Factors","heading":"Reverse","text":"rather common want reverse level order. Simply wrap factor fct_rev().Note want reverse plot legend actual factor levels, can guides() (see ggplot tips).","code":""},{"path":"factors.html","id":"by-frequency","chapter":"11 Factors","heading":"By frequency","text":"order frequency value appears data, use fct_infreq(). missing values (NA) automatically included end, unless converted explicit level (see section). can reverse order wrapping fct_rev().function can used within ggplot(), shown .","code":"\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# reversed frequency\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")"},{"path":"factors.html","id":"by-appearance","chapter":"11 Factors","heading":"By appearance","text":"Use fct_inorder() set level order match order appearance data, starting first row. can useful first carefully arrange() data data frame, use set factor order.","code":""},{"path":"factors.html","id":"by-summary-statistic-of-another-column","chapter":"11 Factors","heading":"By summary statistic of another column","text":"can use fct_reorder() order levels one column summary statistic another column. Visually, can result pleasing plots bars/points ascend descend steadily across plot.examples , x-axis delay_cat, y-axis numeric column ct_blood (cycle-threshold value). Box plots show CT value distribution delay_cat group. want order box plots ascending order group median CT value.first example , default order alpha-numeric level order used. can see box plot heights jumbled particular order. second example, delay_cat column (mapped x-axis) wrapped fct_reorder(), column ct_blood given second argument, “median” given third argument (also use “max”, “mean”, “min”, etc). Thus, order levels delay_cat now reflect ascending median CT values delay_cat group’s median CT value. reflected second plot - box plots re-arranged ascend. Note NA (missing) appear end, unless converted explicit level.Note example steps required prior ggplot() call - grouping calculations done internally ggplot command.","code":"\n# boxplots ordered by original factor levels\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by original alpha-numeric levels\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordered by median CT value\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")"},{"path":"factors.html","id":"by-end-value","chapter":"11 Factors","heading":"By “end” value","text":"Use fct_reorder2() grouped line plots. orders levels (therefore legend) align vertical ordering lines “end” plot. Technically speaking, “orders y-values associated largest x values.”example, lines showing case counts hospital time, can apply fct_reorder2() color = argument within aes(), vertical order hospitals appearing legend aligns order lines terminal end plot. Read online documentation.","code":"\nepidemic_data <- linelist %>%         # begin with the linelist   \n    filter(date_onset < as.Date(\"2014-09-21\")) %>%    # cut-off date, for visual clarity\n    count(                                            # get case counts per week and by hospital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # start plot\n  geom_line(                                        # make lines\n    aes(\n      x = epiweek,                                  # x-axis epiweek\n      y = n,                                        # height is number of cases per week\n      color = fct_reorder2(hospital, epiweek, n)))+ # data grouped and colored by hospital, with factor order by height at end of plot\n  labs(title = \"Factor levels (and legend display) by line height at end of plot\",\n       color = \"Hospital\")                          # change legend title"},{"path":"factors.html","id":"fct_missing","chapter":"11 Factors","heading":"11.5 Missing values","text":"NA values factor column, can easily convert named level “Missing” fct_explicit_na(). NA values converted “(Missing)” end level order default. can adjust level name argument na_level =., opertation performed column delay_cat table printed tabyl() NA converted “Missing delay”.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %>% \n  tabyl(delay_cat)##      delay_cat    n    percent\n##       2-5 days 2040 0.34646739\n##        <2 days 2990 0.50781250\n##        >5 days  602 0.10224185\n##  Missing delay  256 0.04347826"},{"path":"factors.html","id":"combine-levels","chapter":"11 Factors","heading":"11.6 Combine levels","text":"","code":""},{"path":"factors.html","id":"manually-1","chapter":"11 Factors","heading":"Manually","text":"can adjust level displays manually manually fct_recode(). like dplyr function recode() (see Cleaning data core functions), allows creation new factor levels. use simple recode() factor, new re-coded values rejected unless already set permissible levels.tool can also used “combine” levels, assigning multiple levels re-coded value. Just careful lose information! Consider combining steps new column (-writing existing column).fct_recode() different syntax recode(). recode() uses OLD = NEW, whereas fct_recode() uses NEW = OLD.current levels delay_cat :new levels created using syntax fct_recode(column, \"new\" = \"old\", \"new\" = \"old\", \"new\" = \"old\") printed:manually combined fct_recode(). Note error raised creation new level “Less 5 days”.","code":"\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"<2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 2 days 2990 0.50781250     0.5308949\n##       2 to 5 days 2040 0.34646739     0.3622159\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"<2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 5 days 5030 0.85427989     0.8931108\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"reduce-into-other","chapter":"11 Factors","heading":"Reduce into “Other”","text":"can use fct_other() manually assign factor levels “” level. , levels column hospital, aside “Port Hospital” “Central Hospital”, combined “”. can provide vector either keep =, drop =. can change display “” level other_level =.","code":"\nlinelist %>%    \n  mutate(hospital = fct_other(                      # adjust levels\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # keep these separate\n    other_level = \"Other Hospital\")) %>%            # All others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table##          hospital    n    percent\n##  Central Hospital  454 0.07710598\n##     Port Hospital 1762 0.29925272\n##    Other Hospital 3672 0.62364130"},{"path":"factors.html","id":"reduce-by-frequency","chapter":"11 Factors","heading":"Reduce by frequency","text":"can combine least-frequent factor levels automatically using fct_lump().“lump” together many low-frequency levels “” group, one following:Set n = number groups want keep. n -frequent levels kept, others combine “”.Set prop = threshold frequency proportion levels want keep. values combine “”.can change display “” level other_level =. , two -frequent hospitals combined “Hospital”., warn\n## Show levelsOne benefit using factors standardise appearance plot legends tables, regardless values actually present dataset.preparing many figures (e.g. multiple jurisdictions) want legends tables appear identically even varying levels data completion data composition.","code":"\nlinelist %>%    \n  mutate(hospital = fct_lump(                      # adjust levels\n    hospital,\n    n = 2,                                          # keep top 2 levels\n    other_level = \"Other Hospital\")) %>%            # all others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table##        hospital    n   percent\n##         Missing 1469 0.2494905\n##   Port Hospital 1762 0.2992527\n##  Other Hospital 2657 0.4512568"},{"path":"factors.html","id":"in-plots","chapter":"11 Factors","heading":"In plots","text":"ggplot() figure, simply add argument drop = FALSE relevant scale_xxxx() function. factor levels displayed, regardless whether present data. factor column levels displayed using fill =, scale_fill_discrete() include drop = FALSE, shown . levels displayed x = (x-axis) color = size = provide scale_color_discrete() scale_size_discrete() accordingly.example stacked bar plot age category, hospital. Adding scale_fill_discrete(drop = FALSE) ensures age groups appear legend, even present data.","code":"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # show all age groups in the legend, even those not present\n  labs(\n    title = \"All age groups will appear in legend, even if not present in data\")"},{"path":"factors.html","id":"in-tables","chapter":"11 Factors","heading":"In tables","text":"base R table() tabyl() janitor show factor levels (even unused levels).use count() summarise() dplyr make table, add argument .drop = FALSE include counts factor levels even unused.Read Descriptive tables page, scale_discrete documentation, count() documentation. can see another example Contact tracing page.","code":""},{"path":"factors.html","id":"epiweeks","chapter":"11 Factors","heading":"11.7 Epiweeks","text":"Please see extensive discussion create epidemiological weeks Grouping data page.\nPlease also see Working dates page tips create format epidemiological weeks.","code":""},{"path":"factors.html","id":"epiweeks-in-a-plot","chapter":"11 Factors","heading":"Epiweeks in a plot","text":"goal create epiweeks display plot, can simply lubridate’s floor_date(), explained Grouping data page. values returned class Date format YYYY-MM-DD. use column plot, dates naturally order correctly, need worry levels converting class Factor. See ggplot() histogram onset dates .approach, can adjust display dates axis scale_x_date(). See page Epidemic curves information. can specify “strptime” display format date_labels = argument scale_x_date(). formats use “%” placeholders covered Working dates page. Use “%Y” represent 4-digit year, either “%W” “%U” represent week number (Monday Sunday weeks respectively).","code":"\nlinelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %>%  # create week column\n  ggplot()+                                                  # begin ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogram of date of onset\n  scale_x_date(date_labels = \"%Y-W%W\")                       # adjust disply of dates to be YYYY-WWw"},{"path":"factors.html","id":"epiweeks-in-the-data","chapter":"11 Factors","heading":"Epiweeks in the data","text":"However, purpose factoring plot, can approach one two ways:fine control display, convert lubridate epiweek column (YYYY-MM-DD) desired display format (YYYY-WWw) within data frame , convert class Factor.First, use format() base R convert date display YYYY-MM-DD YYYY-Www display (see Working dates page). process class converted character. , convert character class Factor factor().DANGER: place weeks ahead years (“Www-YYYY”) (“%W-%Y”), default alpha-numeric level ordering incorrect (e.g. 01-2015 35-2014). need manually adjust order, long painful process.fast default display, use aweek package ’s function date2week(). can set week_start = day, set factor = TRUE output column ordered factor. bonus, factor includes levels possible weeks span - even cases week.See Working dates page information aweek. also offers reverse function week2date().","code":"\nlinelist <- linelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # create epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convert to display (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convert to factor\n\n# Display levels\nlevels(linelist$epiweek_formatted)##  [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\" \"2014-W19\" \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\"\n## [12] \"2014-W24\" \"2014-W25\" \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\" \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\"\n## [23] \"2014-W35\" \"2014-W36\" \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\" \"2014-W41\" \"2014-W42\" \"2014-W43\" \"2014-W44\" \"2014-W45\"\n## [34] \"2014-W46\" \"2014-W47\" \"2014-W48\" \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\" \"2015-W03\" \"2015-W04\"\n## [45] \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\" \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\" \"2015-W15\"\n## [56] \"2015-W16\"\ndf <- linelist %>% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)"},{"path":"factors.html","id":"resources-4","chapter":"11 Factors","heading":"11.8 Resources","text":"R Data Science page factorsaweek package vignette","code":""},{"path":"pivoting-data.html","id":"pivoting-data","chapter":"12 Pivoting data","heading":"12 Pivoting data","text":"managing data, pivoting can understood refer one two processes:creation pivot tables, tables statistics summarise data extensive tableThe conversion table long wide format, vice versa.page, focus latter definition. former crucial step data analysis, covered elsewhere Grouping data Descriptive tables pages.page discusses formats data. useful aware idea “tidy data”, variable ’s column, observation ’s row, value ’s cell. topic can found online chapter R Data Science.","code":""},{"path":"pivoting-data.html","id":"preparation-3","chapter":"12 Pivoting data","heading":"12.1 Preparation","text":"","code":""},{"path":"pivoting-data.html","id":"load-packages-4","chapter":"12 Pivoting data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  kableExtra,   # Build and manipulate complex tables\n  tidyverse)    # data management + ggplot2 graphics"},{"path":"pivoting-data.html","id":"import-data-5","chapter":"12 Pivoting data","heading":"Import data","text":"","code":""},{"path":"pivoting-data.html","id":"malaria-count-data","chapter":"12 Pivoting data","heading":"Malaria count data","text":"page, use fictional dataset daily malaria cases, facility age group. want follow along, click download (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows displayed .","code":"\n# Import data\ncount_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"pivoting-data.html","id":"linelist-case-data","chapter":"12 Pivoting data","heading":"Linelist case data","text":"later part page, also use dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).","code":"\n# import your dataset\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"pivoting-data.html","id":"wide-to-long","chapter":"12 Pivoting data","heading":"12.2 Wide-to-long","text":"","code":""},{"path":"pivoting-data.html","id":"wide-format","chapter":"12 Pivoting data","heading":"“Wide” format","text":"Data often entered stored “wide” format - subject’s characteristics responses stored single row. may useful presentation, ideal types analysis.Let us take count_data dataset imported Preparation section example. can see row represents “facility-day”. actual case counts (right-columns) stored “wide” format information every age group given facility-day stored single row.observation dataset refers malaria counts one 65 facilities given date, ranging count_data$data_date %>% min() count_data$data_date %>% max(). facilities located one Province (North) four Districts (Spring, Bolo, Dingo, Barnard). dataset provides overall counts malaria, well age-specific counts three age groups - <4 years, 5-14 years, 15 years older.“Wide” data like adhering “tidy data” standards, column headers actually represent “variables” - represent values hypothetical “age group” variable.format can useful presenting information table, entering data (e.g. Excel) case report forms. However, analysis stage, data typically transformed “longer” format aligned “tidy data” standards. plotting R package ggplot2 particular works best data “long” format.Visualising total malaria counts time poses difficulty data ’s current format:However, wanted display relative contributions age group total count? case, need ensure variable interest (age group), appears dataset single column can passed ggplot2’s “mapping aesthetics” aes() argument.","code":"\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)"},{"path":"pivoting-data.html","id":"pivot_longer","chapter":"12 Pivoting data","heading":"pivot_longer()","text":"tidyr function pivot_longer() makes data “longer”. tidyr part tidyverse R packages.accepts range columns transform (specified cols =). Therefore, can operate part dataset. useful malaria data, want pivot case count columns.process, end two “new” columns - one categories (former column names), one corresponding values (e.g. case counts). can accept default names new columns, can specify names_to = values_to = respectively.Let’s see pivot_longer() action…","code":""},{"path":"pivoting-data.html","id":"standard-pivoting","chapter":"12 Pivoting data","heading":"Standard pivoting","text":"want use tidyr’s pivot_longer() function convert “wide” data “long” format. Specifically, convert four numeric columns data malaria counts two new columns: one holds age groups one holds corresponding values.Notice newly created data frame (df_long) rows (12,152 vs 3,038); become longer. fact, precisely four times long, row original dataset now represents four rows df_long, one malaria count observations (<4y, 5-14y, 15y+, total).addition becoming longer, new dataset fewer columns (8 vs 10), data previously stored four columns (beginning prefix malaria_) now stored two.Since names four columns begin prefix malaria_, made use handy “tidyselect” function starts_with() achieve result (see page Cleaning data core functions helper functions).position:named range:two new columns given default names name value, can override defaults provide meaningful names, can help remember stored within, using names_to values_to arguments. Let’s use names age_group counts:can now pass new dataset ggplot2, map new column count y-axis new column age_group fill = argument (column internal color). display malaria counts stacked bar chart, age group:Examine new plot, compare plot created earlier - gone wrong?encountered common problem wrangling surveillance data - also included total counts malaria_tot column, magnitude bar plot twice high .can handle number ways. simply filter totals dataset pass ggplot():Alternatively, excluded variable ran pivot_longer(), thereby maintaining dataset separate variable. See values “expand” fill new rows.","code":"\ndf_long <- count_data %>% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n# provide column with a tidyselect helper function\ncount_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )## # A tibble: 12,152 × 8\n##    location_name data_date  submitted_date Province District newid name             value\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>            <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4     11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-14    12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15      23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot         46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4     11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-14    10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15       5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot         26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4      8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-14     5\n## # ℹ 12,142 more rows\n# provide columns by position\ncount_data %>% \n  pivot_longer(\n    cols = 6:9\n  )\n# provide range of consecutive columns\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\ndf_long <- \n  count_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long## # A tibble: 12,152 × 8\n##    location_name data_date  submitted_date Province District newid age_group        counts\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>             <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4      11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-14     12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15       23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot          46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4      11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-14     10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15        5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot          26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4       8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-14      5\n## # ℹ 12,142 more rows\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\ndf_long %>% \n  filter(age_group != \"malaria_tot\") %>% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )## # A tibble: 9,114 × 9\n##    location_name data_date  submitted_date Province District malaria_tot newid age_group        counts\n##    <chr>         <date>     <date>         <chr>    <chr>          <int> <int> <chr>             <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rdt_0-4      11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rdt_5-14     12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rdt_15       23\n##  4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rdt_0-4      11\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rdt_5-14     10\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rdt_15        5\n##  7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rdt_0-4       8\n##  8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rdt_5-14      5\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rdt_15        5\n## 10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4 malaria_rdt_0-4      16\n## # ℹ 9,104 more rows"},{"path":"pivoting-data.html","id":"pivoting-data-of-multiple-classes","chapter":"12 Pivoting data","heading":"Pivoting data of multiple classes","text":"example works well situations columns want “pivot longer” class (character, numeric, logical…).However, many cases , field epidemiologist, working data prepared non-specialists follow non-standard logic - Hadley Wickham noted (referencing Tolstoy) seminal article Tidy Data principles: “Like families, tidy datasets alike every messy dataset messy way.”One particularly common problem encounter need pivot columns contain different classes data. pivot result storing different data types single column, good situation. various approaches one can take separate mess creates, important step can take using pivot_longer() avoid creating situation .Take situation series observations different time steps three items , B C. Examples items individuals (e.g. contacts Ebola case traced day 21 days) remote village health posts monitored per year ensure still functional. Let’s use contact tracing example. Imagine data stored follows:can seen, data bit complicated. row stores information one item, time series running away right time progresses. Moreover, column classes alternate date character values.One particularly bad example encountered author involved cholera surveillance data, 8 new columns observations added day course 4 years. Simply opening Excel file data stored took >10 minuntes laptop!order work data, need transform data frame long format, keeping separation date column character (status) column, observation item. don’t, might end mixture variable types single column (big “-” comes data management tidy data):, pivot merged dates characters single value column. R react converting entire column class character, utility dates lost.prevent situation, can take advantage syntax structure original column names. common naming structure, observation number, underscore, either “status” “date”. can leverage syntax keep two data types separate columns pivot.:Providing character vector names_to = argument, second item (\".value\" ). special term indicates pivoted columns split based character name…must also provide “splitting” character names_sep = argument. case, underscore “_“.Thus, naming split new columns based around underscore existing variable names.Finishing touches:Note date column currently character class - can easily convert ’s proper date class using mutate() as_date() functions described Working dates page.may also want convert observation column numeric format dropping “obs” prefix converting numeric. cando str_remove_all() stringr package (see Characters strings page).now, can start work data format, e.g. plotting descriptive heat tile:","code":"\ndf %>% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\")\n  )## # A tibble: 18 × 3\n##    id    observation value     \n##    <chr> <chr>       <chr>     \n##  1 A     obs1_date   2021-04-23\n##  2 A     obs1_status Healthy   \n##  3 A     obs2_date   2021-04-24\n##  4 A     obs2_status Healthy   \n##  5 A     obs3_date   2021-04-25\n##  6 A     obs3_status Unwell    \n##  7 B     obs1_date   2021-04-23\n##  8 B     obs1_status Healthy   \n##  9 B     obs2_date   2021-04-24\n## 10 B     obs2_status Healthy   \n## 11 B     obs3_date   2021-04-25\n## 12 B     obs3_status Healthy   \n## 13 C     obs1_date   2021-04-23\n## 14 C     obs1_status Missing   \n## 15 C     obs2_date   2021-04-24\n## 16 C     obs2_status Healthy   \n## 17 C     obs3_date   2021-04-25\n## 18 C     obs3_status Healthy\ndf_long <- \n  df %>% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long## # A tibble: 9 × 4\n##   id    observation date       status \n##   <chr> <chr>       <chr>      <chr>  \n## 1 A     obs1        2021-04-23 Healthy\n## 2 A     obs2        2021-04-24 Healthy\n## 3 A     obs3        2021-04-25 Unwell \n## 4 B     obs1        2021-04-23 Healthy\n## 5 B     obs2        2021-04-24 Healthy\n## 6 B     obs3        2021-04-25 Healthy\n## 7 C     obs1        2021-04-23 Missing\n## 8 C     obs2        2021-04-24 Healthy\n## 9 C     obs3        2021-04-25 Healthy\ndf_long <- \n  df_long %>% \n  mutate(\n    date = date %>% lubridate::as_date(),\n    observation = \n      observation %>% \n      str_remove_all(\"obs\") %>% \n      as.numeric()\n  )\n\ndf_long## # A tibble: 9 × 4\n##   id    observation date       status \n##   <chr>       <dbl> <date>     <chr>  \n## 1 A               1 2021-04-23 Healthy\n## 2 A               2 2021-04-24 Healthy\n## 3 A               3 2021-04-25 Unwell \n## 4 B               1 2021-04-23 Healthy\n## 5 B               2 2021-04-24 Healthy\n## 6 B               3 2021-04-25 Healthy\n## 7 C               1 2021-04-23 Missing\n## 8 C               2 2021-04-24 Healthy\n## 9 C               3 2021-04-25 Healthy\nggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\" = \"red\", \n        \"Missing\" = \"orange\")\n  )"},{"path":"pivoting-data.html","id":"long-to-wide","chapter":"12 Pivoting data","heading":"12.3 Long-to-wide","text":"instances, may wish convert dataset wider format. , can use pivot_wider() function.typical use-case want transform results analysis format digestible reader (Table presentation). Usually, involves transforming dataset information one subject spread multiple rows format information stored single row.","code":""},{"path":"pivoting-data.html","id":"data","chapter":"12 Pivoting data","heading":"Data","text":"section page, use case linelist (see Preparation section), contains one row per case.first 50 rows:Suppose want know counts individuals different age groups, gender:gives us long dataset great producing visualisations ggplot2, ideal presentation table:","code":"\ndf_wide <- \n  linelist %>% \n  count(age_cat, gender)\n\ndf_wide##    age_cat gender   n\n## 1      0-4      f 640\n## 2      0-4      m 416\n## 3      0-4   <NA>  39\n## 4      5-9      f 641\n## 5      5-9      m 412\n## 6      5-9   <NA>  42\n## 7    10-14      f 518\n## 8    10-14      m 383\n## 9    10-14   <NA>  40\n## 10   15-19      f 359\n## 11   15-19      m 364\n## 12   15-19   <NA>  20\n## 13   20-29      f 468\n## 14   20-29      m 575\n## 15   20-29   <NA>  30\n## 16   30-49      f 179\n## 17   30-49      m 557\n## 18   30-49   <NA>  18\n## 19   50-69      f   2\n## 20   50-69      m  91\n## 21   50-69   <NA>   2\n## 22     70+      m   5\n## 23     70+   <NA>   1\n## 24    <NA>   <NA>  86\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))"},{"path":"pivoting-data.html","id":"pivot-wider","chapter":"12 Pivoting data","heading":"Pivot wider","text":"Therefore, can use pivot_wider() transform data better format inclusion tables reports.argument names_from specifies column generate new column names, argument values_from specifies column take values populate cells. argument id_cols = optional, can provided vector column names pivoted, thus identify row.table much reader-friendly, therefore better inclusion reports. can convert pretty table several packages including flextable knitr. process elaborated page Tables presentation.","code":"\ntable_wide <- \n  df_wide %>% \n  pivot_wider(\n    id_cols = age_cat,\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide## # A tibble: 9 × 4\n##   age_cat     f     m  `NA`\n##   <fct>   <int> <int> <int>\n## 1 0-4       640   416    39\n## 2 5-9       641   412    42\n## 3 10-14     518   383    40\n## 4 15-19     359   364    20\n## 5 20-29     468   575    30\n## 6 30-49     179   557    18\n## 7 50-69       2    91     2\n## 8 70+        NA     5     1\n## 9 <NA>       NA    NA    86\ntable_wide %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% # adds row and column totals\n  knitr::kable() %>% \n  kableExtra::row_spec(row = 10, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) "},{"path":"pivoting-data.html","id":"fill","chapter":"12 Pivoting data","heading":"12.4 Fill","text":"situations pivot, commonly bind, left gaps cells like fill.","code":""},{"path":"pivoting-data.html","id":"data-1","chapter":"12 Pivoting data","heading":"Data","text":"example, take two datasets, observations measurement number, name facility, case count time. However, second dataset also variable Year.perform bind_rows() join two datasets together, Year variable filled NA rows prior information (.e. first dataset):","code":"\ndf1 <- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 ## # A tibble: 9 × 3\n##   Measurement Facility Cases\n##         <dbl> <chr>    <dbl>\n## 1           1 Hosp 1      66\n## 2           2 Hosp 1      26\n## 3           3 Hosp 1       8\n## 4           1 Hosp 2      71\n## 5           2 Hosp 2      62\n## 6           3 Hosp 2      70\n## 7           1 Hosp 3      47\n## 8           2 Hosp 3      70\n## 9           3 Hosp 3      38\ndf2 <- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2## # A tibble: 3 × 4\n##    Year Measurement Facility Cases\n##   <dbl>       <dbl> <chr>    <dbl>\n## 1  2000           1 Hosp 4      82\n## 2  2001           2 Hosp 4      87\n## 3  2002           3 Hosp 4      46\ndf_combined <- \n  bind_rows(df1, df2) %>% \n  arrange(Measurement, Facility)\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66    NA\n##  2           1 Hosp 2      71    NA\n##  3           1 Hosp 3      47    NA\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26    NA\n##  6           2 Hosp 2      62    NA\n##  7           2 Hosp 3      70    NA\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8    NA\n## 10           3 Hosp 2      70    NA\n## 11           3 Hosp 3      38    NA\n## 12           3 Hosp 4      46  2002"},{"path":"pivoting-data.html","id":"fill-1","chapter":"12 Pivoting data","heading":"fill()","text":"case, Year useful variable include, particularly want explore trends time. Therefore, use fill() fill empty cells, specifying column fill direction (case ):Alternatively, can rearrange data need fill downward direction:now useful dataset plotting:less useful presenting table, let’s practice converting long, untidy dataframe wider, tidy dataframe:N.B. case, specify include three variables Facility, Year, Cases additional variable Measurement interfere creation table:","code":"\ndf_combined %>% \n  fill(Year, .direction = \"up\")## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66  2000\n##  2           1 Hosp 2      71  2000\n##  3           1 Hosp 3      47  2000\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26  2001\n##  6           2 Hosp 2      62  2001\n##  7           2 Hosp 3      70  2001\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8  2002\n## 10           3 Hosp 2      70  2002\n## 11           3 Hosp 3      38  2002\n## 12           3 Hosp 4      46  2002\ndf_combined <- \n  df_combined %>% \n  arrange(Measurement, desc(Facility))\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47    NA\n##  3           1 Hosp 2      71    NA\n##  4           1 Hosp 1      66    NA\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70    NA\n##  7           2 Hosp 2      62    NA\n##  8           2 Hosp 1      26    NA\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38    NA\n## 11           3 Hosp 2      70    NA\n## 12           3 Hosp 1       8    NA\ndf_combined <- \n  df_combined %>% \n  fill(Year, .direction = \"down\")\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47  2000\n##  3           1 Hosp 2      71  2000\n##  4           1 Hosp 1      66  2000\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70  2001\n##  7           2 Hosp 2      62  2001\n##  8           2 Hosp 1      26  2001\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38  2002\n## 11           3 Hosp 2      70  2002\n## 12           3 Hosp 1       8  2002\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\ndf_combined %>% \n  pivot_wider(\n    id_cols = c(Measurement, Facility),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  arrange(Facility) %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% \n  knitr::kable() %>% \n  kableExtra::row_spec(row = 5, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) \ndf_combined %>% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  knitr::kable()"},{"path":"pivoting-data.html","id":"resources-5","chapter":"12 Pivoting data","heading":"12.5 Resources","text":"helpful tutorial","code":""},{"path":"grouping-data.html","id":"grouping-data","chapter":"13 Grouping data","heading":"13 Grouping data","text":"page covers group aggregate data descriptive analysis. makes use tidyverse family packages common easy--use functions.Grouping data core component data management analysis. Grouped data statistically summarised group, can plotted group. Functions dplyr package (part tidyverse) make grouping subsequent operations quite easy.page address following topics:Group data group_by() functionUn-group datasummarise() grouped data statisticsThe difference count() tally()arrange() applied grouped datafilter() applied grouped datamutate() applied grouped dataselect() applied grouped dataThe base R aggregate() command alternative","code":""},{"path":"grouping-data.html","id":"preparation-4","chapter":"13 Grouping data","heading":"13.1 Preparation","text":"","code":""},{"path":"grouping-data.html","id":"load-packages-5","chapter":"13 Grouping data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,       # to import data\n  here,      # to locate files\n  tidyverse, # to clean, handle, and plot the data (includes dplyr)\n  janitor)   # adding total rows and columns"},{"path":"grouping-data.html","id":"import-data-6","chapter":"13 Grouping data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist:","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"grouping-data.html","id":"grouping","chapter":"13 Grouping data","heading":"13.2 Grouping","text":"function group_by() dplyr groups rows unique values column specified . multiple columns specified, rows grouped unique combinations values across columns. unique value (combination values) constitutes group. Subsequent changes dataset calculations can performed within context group.example, command takes linelist groups rows unique values column outcome, saving output new data frame ll_by_outcome. grouping column(s) placed inside parentheses function group_by().Note perceptible change dataset running group_by(), another dplyr verb mutate(), summarise(), arrange() applied “grouped” data frame.can however “see” groupings printing data frame. print grouped data frame, see transformed tibble class object , printed, displays groupings applied many groups - written just header row.","code":"\nll_by_outcome <- linelist %>% \n  group_by(outcome)\n# print to see which groups are active\nll_by_outcome## # A tibble: 5,888 × 30\n## # Groups:   outcome [3]\n##    case_id generation date_infection date_onset date_hospitalisation date_outcome outcome gender   age age_unit age_years\n##    <chr>        <dbl> <date>         <date>     <date>               <date>       <chr>   <chr>  <dbl> <chr>        <dbl>\n##  1 5fe599           4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>    m          2 years            2\n##  2 8689b7           4 NA             2014-05-13 2014-05-14           2014-05-18   Recover f          3 years            3\n##  3 11f8ea           2 NA             2014-05-16 2014-05-18           2014-05-30   Recover m         56 years           56\n##  4 b8812a           3 2014-05-04     2014-05-18 2014-05-20           NA           <NA>    f         18 years           18\n##  5 893f25           3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover m          3 years            3\n##  6 be99c8           3 2014-05-03     2014-05-22 2014-05-23           2014-05-24   Recover f         16 years           16\n##  7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29           2014-06-01   Recover f         16 years           16\n##  8 369449           4 2014-05-28     2014-06-02 2014-06-03           2014-06-07   Death   f          0 years            0\n##  9 f393b4           4 NA             2014-06-05 2014-06-06           2014-06-18   Recover m         61 years           61\n## 10 1389ca           4 NA             2014-06-05 2014-06-07           2014-06-09   Death   f         27 years           27\n## # ℹ 5,878 more rows\n## # ℹ 19 more variables: age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>,\n## #   wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping-data.html","id":"unique-groups","chapter":"13 Grouping data","heading":"Unique groups","text":"groups created reflect unique combination values across grouping columns.see groups number rows group, pass grouped data tally(). see just unique groups without counts can pass group_keys().See three unique values grouping column outcome: “Death”, “Recover”, NA. See nrow(linelist %>% filter(outcome == \"Death\")) deaths, nrow(linelist %>% filter(outcome == \"Recover\")) recoveries, nrow(linelist %>% filter(.na(outcome))) outcome recorded.can group one column. , data frame grouped outcome gender, tallied. Note unique combination outcome gender registered group - including missing values either column.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  tally()## # A tibble: 3 × 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally()## # A tibble: 9 × 3\n## # Groups:   outcome [3]\n##   outcome gender     n\n##   <chr>   <chr>  <int>\n## 1 Death   f       1227\n## 2 Death   m       1228\n## 3 Death   <NA>     127\n## 4 Recover f        953\n## 5 Recover m        950\n## 6 Recover <NA>      80\n## 7 <NA>    f        627\n## 8 <NA>    m        625\n## 9 <NA>    <NA>      71"},{"path":"grouping-data.html","id":"new-columns-1","chapter":"13 Grouping data","heading":"New columns","text":"can also create new grouping column within group_by() statement. equivalent calling mutate() group_by(). quick tabulation style can handy, clarity code consider creating column mutate() step piping group_by().","code":"\n# group dat based on a binary column created *within* the group_by() command\nlinelist %>% \n  group_by(\n    age_class = ifelse(age >= 18, \"adult\", \"child\")) %>% \n  tally(sort = T)## # A tibble: 3 × 2\n##   age_class     n\n##   <chr>     <int>\n## 1 child      3618\n## 2 adult      2184\n## 3 <NA>         86"},{"path":"grouping-data.html","id":"adddrop-grouping-columns","chapter":"13 Grouping data","heading":"Add/drop grouping columns","text":"default, run group_by() data already grouped, old groups removed new one(s) apply. want add new groups existing ones, include argument .add = TRUE.** Keep groups**group column class factor may levels factor currently present data. group column, default non-present levels dropped included groups. change levels appear groups (even present data), set .drop = FALSE group_by() command.","code":"\n# Grouped by outcome\nby_outcome <- linelist %>% \n  group_by(outcome)\n\n# Add grouping by gender in addition\nby_outcome_gender <- by_outcome %>% \n  group_by(gender, .add = TRUE)"},{"path":"grouping-data.html","id":"un-group","chapter":"13 Grouping data","heading":"13.3 Un-group","text":"Data grouped remain grouped specifically ungrouped via ungroup(). forget ungroup, can lead incorrect calculations! example removing groupings:can also remove grouping specific columns, placing column name inside ungroup().NOTE: verb count() automatically ungroups data counting.","code":"\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup()\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup(gender) # remove the grouping by gender, leave grouping by outcome"},{"path":"grouping-data.html","id":"group_summarise","chapter":"13 Grouping data","heading":"13.4 Summarise","text":"See dplyr section Descriptive tables page detailed description produce summary tables summarise(). briefly address behavior changes applied grouped data.dplyr function summarise() (summarize()) takes data frame converts new summary data frame, columns containing summary statistics define. ungrouped data frame, summary statistics calculated rows. Applying summarise() grouped data produces summary statistics group.syntax summarise() provide name(s) new summary column(s), equals sign, statistical function apply data, shown . example, min(), max(), median(), sd(). Within statistical function, list column operated relevant argument (e.g. na.rm = TRUE). can use sum() count number rows meet logical criteria (double equals ==).example summarise() applied without grouped data. statistics returned produced entire dataset.contrast, summarise() statement applied grouped data. statistics calculated outcome group. Note grouping columns carry new data frame.TIP: summarise function works UK US spelling - summarise() summarize() call function.","code":"\n# summary statistics on ungrouped linelist\nlinelist %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))##   n_cases mean_age max_age min_age n_males\n## 1    5888 16.01831      84       0    2803\n# summary statistics on grouped linelist\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))## # A tibble: 3 × 6\n##   outcome n_cases mean_age max_age min_age n_males\n##   <chr>     <int>    <dbl>   <dbl>   <dbl>   <int>\n## 1 Death      2582     15.9      76       0    1228\n## 2 Recover    1983     16.1      84       0     950\n## 3 <NA>       1323     16.2      69       0     625"},{"path":"grouping-data.html","id":"counts-and-tallies","chapter":"13 Grouping data","heading":"13.5 Counts and tallies","text":"count() tally() provide similar functionality different. Read distinction tally() count() ","code":""},{"path":"grouping-data.html","id":"tally","chapter":"13 Grouping data","heading":"tally()","text":"tally() shorthand summarise(n = n()), group data. Thus, achieve grouped tallys must follow group_by() command. can add sort = TRUE see largest groups first.","code":"\nlinelist %>% \n  tally()##      n\n## 1 5888\nlinelist %>% \n  group_by(outcome) %>% \n  tally(sort = TRUE)## # A tibble: 3 × 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323"},{"path":"grouping-data.html","id":"count","chapter":"13 Grouping data","heading":"count()","text":"contrast, count() following:applies group_by() specified column(s)applies summarise() returns column n number rows per groupapplies ungroup()Just like group_by() can create new column within count() command:count() can called multiple times, functionality “rolling ”. example, summarise number hospitals present gender, run following. Note, name final column changed default “n” clarity (name  =).","code":"\nlinelist %>% \n  count(outcome)##   outcome    n\n## 1   Death 2582\n## 2 Recover 1983\n## 3    <NA> 1323\nlinelist %>% \n  count(age_class = ifelse(age >= 18, \"adult\", \"child\"), sort = T)##   age_class    n\n## 1     child 3618\n## 2     adult 2184\n## 3      <NA>   86\nlinelist %>% \n  # produce counts by unique outcome-gender groups\n  count(gender, hospital) %>% \n  # gather rows by gender (3) and count number of hospitals per gender (6)\n  count(gender, name = \"hospitals per gender\" ) ##   gender hospitals per gender\n## 1      f                    6\n## 2      m                    6\n## 3   <NA>                    6"},{"path":"grouping-data.html","id":"add-counts","chapter":"13 Grouping data","heading":"Add counts","text":"contrast count() summarise(), can use add_count() add new column n counts rows per group retaining data frame columns.means group’s count number, new column n, printed row group. demonstration purposes, add column re-arrange columns easier viewing. See section filter group size another example.","code":"\nlinelist %>% \n  as_tibble() %>%                   # convert to tibble for nicer printing \n  add_count(hospital) %>%           # add column n with counts by hospital\n  select(hospital, n, everything()) # re-arrange for demo purposes## # A tibble: 5,888 × 31\n##    hospital      n case_id generation date_infection date_onset date_hospitalisation date_outcome outcome gender   age age_unit\n##    <chr>     <int> <chr>        <dbl> <date>         <date>     <date>               <date>       <chr>   <chr>  <dbl> <chr>   \n##  1 Other       885 5fe599           4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>    m          2 years   \n##  2 Missing    1469 8689b7           4 NA             2014-05-13 2014-05-14           2014-05-18   Recover f          3 years   \n##  3 St. Mark…   422 11f8ea           2 NA             2014-05-16 2014-05-18           2014-05-30   Recover m         56 years   \n##  4 Port Hos…  1762 b8812a           3 2014-05-04     2014-05-18 2014-05-20           NA           <NA>    f         18 years   \n##  5 Military…   896 893f25           3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover m          3 years   \n##  6 Port Hos…  1762 be99c8           3 2014-05-03     2014-05-22 2014-05-23           2014-05-24   Recover f         16 years   \n##  7 Missing    1469 07e3e8           4 2014-05-22     2014-05-27 2014-05-29           2014-06-01   Recover f         16 years   \n##  8 Missing    1469 369449           4 2014-05-28     2014-06-02 2014-06-03           2014-06-07   Death   f          0 years   \n##  9 Missing    1469 f393b4           4 NA             2014-06-05 2014-06-06           2014-06-18   Recover m         61 years   \n## 10 Missing    1469 1389ca           4 NA             2014-06-05 2014-06-07           2014-06-09   Death   f         27 years   \n## # ℹ 5,878 more rows\n## # ℹ 19 more variables: age_years <dbl>, age_cat <fct>, age_cat5 <fct>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>,\n## #   wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping-data.html","id":"add-totals","chapter":"13 Grouping data","heading":"Add totals","text":"easily add total sum rows columns using tally() count(), see janitor section Descriptive tables page. package offers functions like adorn_totals() adorn_percentages() add totals convert show percentages. brief example:add complex totals rows involve summary statistics sums, see section Descriptive Tables page.","code":"\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts of two columns\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions with column denominator\n  adorn_pct_formatting() %>%                  # convert proportions to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                       Gender                            \n##  Age Category              f              m          NA_\n##           0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n##           5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n##         10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n##         15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n##         20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n##         30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n##         50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n##           70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n##          <NA>     0   (0.0%)     0   (0.0%)  86  (30.9%)\n##         Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)"},{"path":"grouping-data.html","id":"grouping-by-date","chapter":"13 Grouping data","heading":"13.6 Grouping by date","text":"grouping data date, must (create) column date unit interest - example “day”, “epiweek”, “month”, etc. can make column using floor_date() lubridate, explained Epidemiological weeks section Working dates page. column, can use count() dplyr group rows unique date values achieve aggregate counts.One additional step common date situations, “fill-” dates sequence present data. Use complete() tidyr aggregated date series complete including possible date units within range. Without step, week cases reported might appear data!Within complete() re-define date column sequence dates seq.Date() minimum maximum - thus dates expanded. default, case count values new “expanded” rows NA. can set 0 using fill = argument complete(), expects named list (counts column named n, provide fill = list(n = 0). See ?complete details Working dates page example.","code":""},{"path":"grouping-data.html","id":"linelist-cases-into-days","chapter":"13 Grouping data","heading":"Linelist cases into days","text":"example grouping cases days without using complete(). Note first rows skip dates cases.add complete() command ensure every day range represented.","code":"\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%        # remove that were missing date_onset\n  count(date_onset)              # count number of rows per unique date\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%                 # remove case missing date_onset\n  count(date_onset) %>%                   # count number of rows per unique date\n  complete(                               # ensure all days appear even if no cases\n    date_onset = seq.Date(                # re-define date colume as daily sequence of dates\n      from = min(date_onset, na.rm=T), \n      to = max(date_onset, na.rm=T),\n      by = \"day\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) "},{"path":"grouping-data.html","id":"linelist-cases-into-weeks","chapter":"13 Grouping data","heading":"Linelist cases into weeks","text":"principle can applied weeks. First create new column week case using floor_date() unit = \"week\". , use count() achieve weekly case counts. Finish complete() ensure weeks represented, even contain cases.first 50 rows resulting data frame:","code":"\n# Make dataset of weekly case counts\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%                 # remove cases missing date_onset\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %>%  # new column of week of onset\n  count(week) %>%                         # group data by week and count rows per group\n  complete(                               # ensure all days appear even if no cases\n    week = seq.Date(                      # re-define date colume as daily sequence of dates\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) "},{"path":"grouping-data.html","id":"linelist-cases-into-months","chapter":"13 Grouping data","heading":"Linelist cases into months","text":"aggregate cases months, use floor_date() lubridate package, argument unit = \"months\". rounds date 1st month. output class Date. Note complete() step also use = \"months\".","code":"\n# Make dataset of monthly case counts\nmonthly_counts <- linelist %>% \n  drop_na(date_onset) %>% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %>%  # new column, 1st of month of onset\n  count(month) %>%                          # count cases by month\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # include all months with no cases reported\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))"},{"path":"grouping-data.html","id":"daily-counts-into-weeks","chapter":"13 Grouping data","heading":"Daily counts into weeks","text":"aggregate daily counts weekly counts, use floor_date() . However, use group_by() summarize() instead count() need sum() daily case counts instead just counting number rows per week.","code":""},{"path":"grouping-data.html","id":"daily-counts-into-months","chapter":"13 Grouping data","heading":"Daily counts into months","text":"aggregate daily counts months counts, use floor_date() unit = \"month\" . However, use group_by() summarize() instead count() need sum() daily case counts instead just counting number rows per month.","code":""},{"path":"grouping-data.html","id":"arranging-grouped-data","chapter":"13 Grouping data","heading":"13.7 Arranging grouped data","text":"Using dplyr verb arrange() order rows data frame behaves data grouped, unless set argument .by_group =TRUE. case rows ordered first grouping columns columns specify arrange().","code":""},{"path":"grouping-data.html","id":"filter-on-grouped-data","chapter":"13 Grouping data","heading":"13.8 Filter on grouped data","text":"","code":""},{"path":"grouping-data.html","id":"filter","chapter":"13 Grouping data","heading":"filter()","text":"applied conjunction functions evaluate data frame (like max(), min(), mean()), functions now applied groups. example, want filter keep rows patients median age, now apply per group - filtering keep rows group’s median age.","code":""},{"path":"grouping-data.html","id":"slice-rows-per-group","chapter":"13 Grouping data","heading":"Slice rows per group","text":"dplyr function slice(), filters rows based position data, can also applied per group. Remember account sorting data within group get desired “slice”.example, retrieve latest 5 admissions hospital:Group linelist column hospitalArrange records latest earliest date_hospitalisation within hospital groupSlice retrieve first 5 rows hospitalslice_head() - selects n rows topslice_tail() - selects n rows endslice_sample() - randomly selects n rowsslice_min() - selects n rows highest values order_by = column, use with_ties = TRUE keep tiesslice_max() - selects n rows lowest values order_by = column, use with_ties = TRUE keep tiesSee De-duplication page examples detail slice().","code":"\nlinelist %>%\n  group_by(hospital) %>%\n  arrange(hospital, date_hospitalisation) %>%\n  slice_head(n = 5) %>% \n  arrange(hospital) %>%                            # for display\n  select(case_id, hospital, date_hospitalisation)  # for display## # A tibble: 30 × 3\n## # Groups:   hospital [6]\n##    case_id hospital          date_hospitalisation\n##    <chr>   <chr>             <date>              \n##  1 20b688  Central Hospital  2014-05-06          \n##  2 d58402  Central Hospital  2014-05-10          \n##  3 b8f2fd  Central Hospital  2014-05-13          \n##  4 acf422  Central Hospital  2014-05-28          \n##  5 275cc7  Central Hospital  2014-05-28          \n##  6 d1fafd  Military Hospital 2014-04-17          \n##  7 974bc1  Military Hospital 2014-05-13          \n##  8 6a9004  Military Hospital 2014-05-13          \n##  9 09e386  Military Hospital 2014-05-14          \n## 10 865581  Military Hospital 2014-05-15          \n## # ℹ 20 more rows"},{"path":"grouping-data.html","id":"group_filter_grp_size","chapter":"13 Grouping data","heading":"Filter on group size","text":"function add_count() adds column n original data giving number rows row’s group.Shown , add_count() applied column hospital, values new column n reflect number rows row’s hospital group. Note values column n repeated. example , column name n changed using name = within add_count(). demonstration purposes re-arrange columns select().becomes easy filter case rows hospitalized “small” hospital, say, hospital admitted fewer 500 patients:","code":"\nlinelist %>% \n  as_tibble() %>% \n  add_count(hospital) %>%          # add \"number of rows admitted to same hospital as this row\" \n  select(hospital, n, everything())## # A tibble: 5,888 × 31\n##    hospital      n case_id generation date_infection date_onset date_hospitalisation date_outcome outcome gender   age age_unit\n##    <chr>     <int> <chr>        <dbl> <date>         <date>     <date>               <date>       <chr>   <chr>  <dbl> <chr>   \n##  1 Other       885 5fe599           4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>    m          2 years   \n##  2 Missing    1469 8689b7           4 NA             2014-05-13 2014-05-14           2014-05-18   Recover f          3 years   \n##  3 St. Mark…   422 11f8ea           2 NA             2014-05-16 2014-05-18           2014-05-30   Recover m         56 years   \n##  4 Port Hos…  1762 b8812a           3 2014-05-04     2014-05-18 2014-05-20           NA           <NA>    f         18 years   \n##  5 Military…   896 893f25           3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover m          3 years   \n##  6 Port Hos…  1762 be99c8           3 2014-05-03     2014-05-22 2014-05-23           2014-05-24   Recover f         16 years   \n##  7 Missing    1469 07e3e8           4 2014-05-22     2014-05-27 2014-05-29           2014-06-01   Recover f         16 years   \n##  8 Missing    1469 369449           4 2014-05-28     2014-06-02 2014-06-03           2014-06-07   Death   f          0 years   \n##  9 Missing    1469 f393b4           4 NA             2014-06-05 2014-06-06           2014-06-18   Recover m         61 years   \n## 10 Missing    1469 1389ca           4 NA             2014-06-05 2014-06-07           2014-06-09   Death   f         27 years   \n## # ℹ 5,878 more rows\n## # ℹ 19 more variables: age_years <dbl>, age_cat <fct>, age_cat5 <fct>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>,\n## #   wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\nlinelist %>% \n  add_count(hospital) %>% \n  filter(n < 500)"},{"path":"grouping-data.html","id":"mutate-on-grouped-data","chapter":"13 Grouping data","heading":"13.9 Mutate on grouped data","text":"retain columns rows (summarise) add new column containing group statistics, use mutate() group_by() instead summarise().useful want group statistics original dataset columns present - e.g. calculations compare one row group.example, code calculates difference row’s delay--admission median delay hospital. steps :Group data hospitalUse column days_onset_hosp (delay hospitalisation) create new column containing mean delay hospital rowCalculate difference two columnsWe select() certain columns display, demonstration purposes.","code":"\nlinelist %>% \n  # group data by hospital (no change to linelist yet)\n  group_by(hospital) %>% \n  \n  # new columns\n  mutate(\n    # mean days to admission per hospital (rounded to 1 decimal)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # difference between row's delay and mean delay at their hospital (rounded to 1 decimal)\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %>%\n  \n  # select certain rows only - for demonstration/viewing purposes\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)## # A tibble: 5,888 × 5\n## # Groups:   hospital [6]\n##    case_id hospital                             days_onset_hosp group_delay_admit diff_to_group\n##    <chr>   <chr>                                          <dbl>             <dbl>         <dbl>\n##  1 5fe599  Other                                              2               2             0  \n##  2 8689b7  Missing                                            1               2.1          -1.1\n##  3 11f8ea  St. Mark's Maternity Hospital (SMMH)               2               2.1          -0.1\n##  4 b8812a  Port Hospital                                      2               2.1          -0.1\n##  5 893f25  Military Hospital                                  1               2.1          -1.1\n##  6 be99c8  Port Hospital                                      1               2.1          -1.1\n##  7 07e3e8  Missing                                            2               2.1          -0.1\n##  8 369449  Missing                                            1               2.1          -1.1\n##  9 f393b4  Missing                                            1               2.1          -1.1\n## 10 1389ca  Missing                                            2               2.1          -0.1\n## # ℹ 5,878 more rows"},{"path":"grouping-data.html","id":"select-on-grouped-data","chapter":"13 Grouping data","heading":"13.10 Select on grouped data","text":"verb select() works grouped data, grouping columns always included (even mentioned select()). want grouping columns, use ungroup() first.","code":""},{"path":"grouping-data.html","id":"resources-6","chapter":"13 Grouping data","heading":"13.11 Resources","text":"useful resources information:can perform summary function grouped data; see RStudio data transformation cheat sheetThe Data Carpentry page dplyr\ntidyverse reference pages group_by() groupingThis page Data manipulationSummarize conditions dplyr","code":""},{"path":"joining-data.html","id":"joining-data","chapter":"14 Joining data","heading":"14 Joining data","text":": animated example left join (image source)page describes ways “join”, “match”, “link” “bind”, otherwise combine data frames.uncommon epidemiological analysis workflow involve multiple sources data, linkage multiple datasets. Perhaps need connect laboratory data patient clinical outcomes, Google mobility data infectious disease trends, even dataset one stage analysis transformed version .page demonstrate code :Conduct joins two data frames rows matched based common values identifier columnsJoin two data frames based probabilistic (likely) matches valuesExpand data frame directly binding (“appending”) rows columns another data frame","code":""},{"path":"joining-data.html","id":"preparation-5","chapter":"14 Joining data","heading":"14.1 Preparation","text":"","code":""},{"path":"joining-data.html","id":"load-packages-6","chapter":"14 Joining data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,            # import and export\n  here,           # locate files \n  tidyverse,      # data management and visualisation\n  RecordLinkage,  # probabilistic matches\n  fastLink        # probabilistic matches\n)"},{"path":"joining-data.html","id":"import-data-7","chapter":"14 Joining data","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"joining-data.html","id":"example-datasets","chapter":"14 Joining data","heading":"Example datasets","text":"joining section , use following datasets:“miniature” version case linelist, containing columns case_id, date_onset, hospital, first 10 rowsA separate data frame named hosp_info, contains details hospitalIn section probabilistic matching, use two different small datasets. code create datasets given section.","code":""},{"path":"joining-data.html","id":"joins_llmini","chapter":"14 Joining data","heading":"“Miniature” case linelist","text":"miniature case linelist, contains 10 rows columns case_id, date_onset, hospital.","code":"\nlinelist_mini <- linelist %>%                 # start with original linelist\n  select(case_id, date_onset, hospital) %>%   # select columns\n  head(10)                                    # only take the first 10 rows"},{"path":"joining-data.html","id":"joins_hosp_info","chapter":"14 Joining data","heading":"Hospital information data frame","text":"code create separate data frame additional information seven hospitals (catchment population, level care available). Note name “Military Hospital” belongs two different hospitals - one primary level serving 10000 residents secondary level serving 50280 residents.data frame:","code":"\n# Make the hospital information data frame\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)"},{"path":"joining-data.html","id":"pre-cleaning","chapter":"14 Joining data","heading":"Pre-cleaning","text":"Traditional joins (non-probabilistic) case-sensitive require exact character matches values two data frames. demonstrate cleaning steps might need initiating join, clean align linelist_mini hosp_info datasets now.Identify differencesWe need values hosp_name column hosp_info data frame match values hospital column linelist_mini data frame.values linelist_mini data frame, printed base R function unique():values hosp_info data frame:can see hospitals exist data frames, many differences spelling.Align valuesWe begin cleaning values hosp_info data frame. explained Cleaning data core functions page, can re-code values logical criteria using dplyr’s case_when() function. four hospitals exist data frames change values align values linelist_mini. hospitals leave values (TRUE ~ hosp_name).CAUTION: Typically cleaning one create new column (e.g. hosp_name_clean), ease demonstration show modification old columnThe hospital names appear data frames aligned. two hospitals hosp_info present linelist_mini - deal later, join.Prior join, often easiest convert column lowercase uppercase. need convert values column UPPER lower case, use mutate() wrap column one functions stringr, shown page Characters strings.str_to_upper()str_to_upper()str_to_title()","code":"\nunique(linelist_mini$hospital)## [1] \"Other\"                                \"Missing\"                              \"St. Mark's Maternity Hospital (SMMH)\"\n## [4] \"Port Hospital\"                        \"Military Hospital\"\nunique(hosp_info$hosp_name)## [1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"       \"ignace\"           \"sisters\"\nhosp_info <- hosp_info %>% \n  mutate(\n    hosp_name = case_when(\n      # criteria                         # new value\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\nunique(hosp_info$hosp_name)## [1] \"Central Hospital\"                     \"Military Hospital\"                    \"Port Hospital\"                       \n## [4] \"St. Mark's Maternity Hospital (SMMH)\" \"ignace\"                               \"sisters\""},{"path":"joining-data.html","id":"dplyr-joins","chapter":"14 Joining data","heading":"14.2 dplyr joins","text":"dplyr package offers several different join functions. dplyr included tidyverse package. join functions described , simple use cases.Many thanks https://github.com/gadenbuie informative gifs!","code":""},{"path":"joining-data.html","id":"general-syntax","chapter":"14 Joining data","heading":"General syntax","text":"join commands can run standalone commands join two data frames new object, can used within pipe chain (%>%) merge one data frame another cleaned otherwise modified.example , function left_join() used standalone command create new joined_data data frame. inputs data frames 1 2 (df1 df2). first data frame listed baseline data frame, second one listed joined .third argument = specify columns data frame used aligns rows two data frames. names columns different, provide within c() vector shown , rows matched basis common values column ID df1 column identifier df2.columns data frames exact name, can just provide one name, within quotes.joining data frames based common values across multiple fields, list fields within c() vector. example joins rows values three columns dataset align exactly.join commands can also run within pipe chain. modify data frame piped.example , df1 passed pipes, df2 joined , df thus modified re-defined.CAUTION: Joins case-specific! Therefore useful convert values lowercase uppercase prior joining. See page characters/strings.","code":"\n# Join based on common values between column \"ID\" (first data frame) and column \"identifier\" (second data frame)\njoined_data <- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\n# Joint based on common values in column \"ID\" in both data frames\njoined_data <- left_join(df1, df2, by = \"ID\")\n# join based on same first name, last name, and age\njoined_data <- left_join(df1, df2, by = c(\"name\" = \"firstname\", \"surname\" = \"lastname\", \"Age\" = \"age\"))\ndf1 <- df1 %>%\n  filter(date_onset < as.Date(\"2020-03-05\")) %>% # miscellaneous cleaning \n  left_join(df2, by = c(\"ID\" = \"identifier\"))    # join df2 to df1"},{"path":"joining-data.html","id":"left-and-right-joins","chapter":"14 Joining data","heading":"Left and right joins","text":"left right join commonly used add information data frame - new information added rows already existed baseline data frame. common joins epidemiological work used add information one dataset another.using joins, written order data frames command important*.left join, first data frame written baselineIn right join, second data frame written baselineAll rows baseline data frame kept. Information (secondary) data frame joined baseline data frame match via identifier column(s). addition:Rows secondary data frame match dropped.many baseline rows match one row secondary data frame (many--one), secondary information added matching baseline row.baseline row matches multiple rows secondary data frame (one--many), combinations given, meaning new rows may added returned data frame!Animated examples left right joins (image source)ExampleBelow output left_join() hosp_info (secondary data frame, view ) linelist_mini (baseline data frame, view ). original linelist_mini nrow(linelist_mini) rows. modified linelist_mini displayed. Note following:Two new columns, catchment_pop level added left side linelist_miniAll original rows baseline data frame linelist_mini keptAny original rows linelist_mini “Military Hospital” duplicated matched two rows secondary data frame, combinations returnedThe join identifier column secondary dataset (hosp_name) disappeared redundant identifier column primary dataset (hospital)baseline row match secondary row (e.g. hospital “” “Missing”), NA (blank) fills columns secondary data frameRows secondary data frame match baseline data frame (“sisters” “ignace” hospitals) dropped","code":"\nlinelist_mini %>% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in left_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning."},{"path":"joining-data.html","id":"should-i-use-a-right-join-or-a-left-join","chapter":"14 Joining data","heading":"“Should I use a right join, or a left join?”","text":"answer question, ask “data frame retain rows?” - use one baseline. left join keep rows first data frame written command, whereas right join keeps rows second data frame.two commands achieve output - 10 rows hosp_info joined linelist_mini baseline, use different joins. result column order differ based whether hosp_info arrives right (left join) arrives left (right join). order rows may also shift accordingly. consequences can subsequently addressed, using select() re-order columns arrange() sort rows.result hosp_info linelist_mini via left join (new columns incoming right)result hosp_info linelist_mini via right join (new columns incoming left)Also consider whether use-case within pipe chain (%>%). dataset pipes baseline, likely use left join add data .","code":"\n# The two commands below achieve the same data, but with differently ordered rows and columns\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))## Warning in left_join(linelist_mini, hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning.## Warning in right_join(hosp_info, linelist_mini, by = c(hosp_name = \"hospital\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 4 of `x` matches multiple rows in `y`.\n## ℹ Row 5 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning."},{"path":"joining-data.html","id":"full-join","chapter":"14 Joining data","heading":"Full join","text":"full join inclusive joins - returns rows data frames.rows present one (match found), data frame include become longer. NA missing values used fill-gaps created. join, watch number columns rows carefully troubleshoot case-sensitivity exact character matches.“baseline” data frame one written first command. Adjustment impact records returned join, can impact resulting column order, row order, identifier columns retained.Animated example full join (image source)ExampleBelow output full_join() hosp_info (originally nrow(hosp_info), view ) linelist_mini (originally nrow(linelist_mini), view ). Note following:baseline rows kept (linelist_mini)Rows secondary match baseline kept (“ignace” “sisters”), values corresponding baseline columns case_id onset filled missing valuesLikewise, rows baseline data frame match secondary (“” “Missing”) kept, secondary columns catchment_pop level filled-missing valuesIn case one--many many--one matches (e.g. rows “Military Hospital”), possible combinations returned (lengthening final data frame)identifier column baseline kept (hospital)","code":"\nlinelist_mini %>% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in full_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning."},{"path":"joining-data.html","id":"inner-join","chapter":"14 Joining data","heading":"Inner join","text":"inner join restrictive joins - returns rows matches across data frames.\nmeans number rows baseline data frame may actually reduce. Adjustment data frame “baseline” (written first function) impact rows returned, impact column order, row order, identifier columns retained.Animated example inner join (image source)ExampleBelow output inner_join() linelist_mini (baseline) hosp_info (secondary). Note following:Baseline rows match secondary data removed (rows hospital “Missing” “”)Likewise, rows secondary data frame match baseline removed (rows hosp_name “sisters” “ignace”)identifier column baseline kept (hospital)","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning."},{"path":"joining-data.html","id":"semi-join","chapter":"14 Joining data","heading":"Semi join","text":"semi join “filtering join” uses another dataset add rows columns, perform filtering.semi-join keeps observations baseline data frame match secondary data frame (add new columns duplicate rows multiple matches). Read “filtering” joins .Animated example semi join (image source)example, code returns rows hosp_info data frame matches linelist_mini based hospital name.","code":"\nhosp_info %>% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))##                              hosp_name catchment_pop     level\n## 1                    Military Hospital         40500 Secondary\n## 2                    Military Hospital         10000   Primary\n## 3                        Port Hospital         50280 Secondary\n## 4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary"},{"path":"joining-data.html","id":"anti-join","chapter":"14 Joining data","heading":"Anti join","text":"anti join another “filtering join” returns rows baseline data frame match secondary data frame.Read filtering joins .Common scenarios anti-join include identifying records present another data frame, troubleshooting spelling join (reviewing records matched), examining records excluded another join.right_join() left_join(), baseline data frame (listed first) important. returned rows baseline data frame . Notice gif row secondary data frame (purple row 4) returned even though match baseline.Animated example anti join (image source)","code":""},{"path":"joining-data.html","id":"simple-anti_join-example","chapter":"14 Joining data","heading":"Simple anti_join() example","text":"simple example, let’s find hosp_info hospitals cases present linelist_mini. list hosp_info first, baseline data frame. hospitals present linelist_mini returned.","code":"\nhosp_info %>% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-data.html","id":"complex-anti_join-example","chapter":"14 Joining data","heading":"Complex anti_join() example","text":"another example, let us say ran inner_join() linelist_mini hosp_info. returns subset original linelist_mini records, present hosp_info.review linelist_mini records excluded inner join, can run anti-join settings (linelist_mini baseline).see hosp_info records excluded inner join, also run anti-join hosp_info baseline data frame.","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning.\nlinelist_mini %>% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"probabalistic-matching","chapter":"14 Joining data","heading":"14.3 Probabalistic matching","text":"unique identifier common across datasets join , consider using probabilistic matching algorithm. find matches records based similarity (e.g. Jaro–Winkler string distance, numeric distance). simple example using package fastLink .Load packagesHere two small example datasets use demonstrate probabilistic matching (cases test_results):code used make datasets:cases dataset 9 records patients awaiting test results.test_results dataset 14 records contains column result, want add records cases based probabilistic matching records.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualization\n  fastLink        # record matching\n  )\n# make datasets\n\ncases <- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults <- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )"},{"path":"joining-data.html","id":"probabilistic-matching","chapter":"14 Joining data","heading":"Probabilistic matching","text":"fastLink() function fastLink package can used apply matching algorithm. basic information. can read detail entering ?fastLink console.Define two data frames comparison arguments dfA = dfB =varnames = give column names used matching. must exist dfA dfB.stringdist.match = give columns varnames evaluated string “distance”.numeric.match = give columns varnames evaluated numeric distance.Missing values ignoredBy default, row either data frame matched one row data frame. want see evaluated matches, set dedupe.matches = FALSE. deduplication done using Winkler’s linear assignment solution.Tip: split one date column three separate numeric columns using day(), month(), year() lubridate packageThe default threshold matches 0.94 (threshold.match =) can adjust higher lower. define threshold, consider higher thresholds yield false-negatives (rows match actually match) likewise lower threshold yield false-positive matches., data matched string distance across name district columns, numeric distance year, month, day birth. match threshold 95% probability set.Review matchesWe defined object returned fastLink() fl_output. class list, actually contains several data frames within , detailing results matching. One data frames matches, contains likely matches across cases results. can access “matches” data frame fl_output$matches. , saved my_matches ease accessing later.my_matches printed, see two column vectors: pairs row numbers/indices (also called “rownames”) cases (“inds.”) results (“inds.b”) representing best matches. row number datafrane missing, match found data frame specified match threshold.Things note:Matches occurred despite slight differences name spelling dates birth:\n“Tony B. Smith” matched “Anthony B Smith”\n“Maria Rodriguez” matched “Marialisa Rodrigues”\n“Betty Chase” matched “Elizabeth Chase”\n“Olivier Laurent De Bordeaux” matched “Oliver Laurent De Bordow” (missing date birth ignored)\n“Tony B. Smith” matched “Anthony B Smith”“Maria Rodriguez” matched “Marialisa Rodrigues”“Betty Chase” matched “Elizabeth Chase”“Olivier Laurent De Bordeaux” matched “Oliver Laurent De Bordow” (missing date birth ignored)One row cases (“Blessing Adebayo”, row 9) good match results, present my_matches.Join based probabilistic matchesTo use matches join results cases, one strategy :Use left_join() join my_matches cases (matching rownames cases “inds.” my_matches)use another left_join() join results cases (matching newly-acquired “inds.b” cases rownames results)joins, clean three data frames:dfA dfB row numbers (“rowname”) converted proper column.columns my_matches converted class character, can joined character rownamesAs performed using code , resulting data frame complete contain columns cases results. Many appended suffixes “.x” “.y”, column names otherwise duplicated.Alternatively, achieve “original” 9 records cases new column(s) results, use select() results joins, contains rownames columns want add cases (e.g. column result).want subset either dataset rows matched, can use codes :, see rows match:","code":"\nfl_output <- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Deduping the estimated matches.\n## Getting the match patterns for each estimated match.\n# print matches\nmy_matches <- fl_output$matches\nmy_matches##   inds.a inds.b\n## 1      1      1\n## 2      2      2\n## 3      3      3\n## 4      4      4\n## 5      8      8\n## 6      7      9\n## 7      6     10\n## 8      5     12\n# Clean data prior to joining\n#############################\n\n# convert cases rownames to a column \ncases_clean <- cases %>% rownames_to_column()\n\n# convert test_results rownames to a column\nresults_clean <- results %>% rownames_to_column()  \n\n# convert all columns in matches dataset to character, so they can be joined to the rownames\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n\n\n# Join matches to dfA, then add dfB\n###################################\n# column \"inds.b\" is added to dfA\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# column(s) from dfB are added \ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_clean <- cases %>% rownames_to_column()\n\nresults_clean <- results %>%\n  rownames_to_column() %>% \n  select(rowname, result)    # select only certain columns \n\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n# joins\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_matched <- cases[my_matches$inds.a,]  # Rows in cases that matched to a row in results\nresults_matched <- results[my_matches$inds.b,]  # Rows in results that matched to a row in cases\ncases_not_matched <- cases[!rownames(cases) %in% my_matches$inds.a,]  # Rows in cases that did NOT match to a row in results\nresults_not_matched <- results[!rownames(results) %in% my_matches$inds.b,]  # Rows in results that did NOT match to a row in cases"},{"path":"joining-data.html","id":"probabilistic-deduplication","chapter":"14 Joining data","heading":"Probabilistic deduplication","text":"Probabilistic matching can used deduplicate dataset well. See page deduplication methods deduplication.began cases dataset, now calling cases_dup, 2 additional rows duplicates previous rows:\nSee “Tony” “Anthony”, “Marialisa Rodrigues” “Maria Rodriguez”.Run fastLink() like , compare cases_dup data frame . two data frames provided identical, function assumes want de-duplicate. Note specify stringdist.match = numeric.match = previously.Now, can review potential duplicates getMatches(). Provide data frame dfA = dfB =, provide output fastLink() function fl.=. fl.must class fastLink.dedupe, words, result fastLink().See right-column, indicates duplicate IDs - final two rows identified likely duplicates rows 2 3.return row numbers rows likely duplicates, can count number rows per unique value dedupe.ids column, filter keep one row. case leaves rows 2 3.inspect whole rows likely duplicates, put row number command:","code":"\n## Run fastLink on the same dataset\ndedupe_output <- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## dfA and dfB are identical, assuming deduplication of a single data set.\n## Setting return.all to FALSE.\n## \n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Calculating the posterior for each pair of matched observations.\n## Getting the match patterns for each estimated match.\n## Run getMatches()\ncases_dedupe <- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\ncases_dedupe %>% \n  count(dedupe.ids) %>% \n  filter(n > 1)##   dedupe.ids n\n## 1          2 2\n## 2          3 2\n# displays row 2 and all likely duplicates of it\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   ##    gender   first middle  last   yr mon day district dedupe.ids\n## 2       M Anthony     B. Smith 1970   9  19    River          2\n## 10      M    Tony     B. Smith 1970   9  19    River          2"},{"path":"joining-data.html","id":"binding-and-aligning","chapter":"14 Joining data","heading":"14.4 Binding and aligning","text":"Another method combining two data frames “binding” together. can also think “appending” “adding” rows columns.section also discuss “align” order rows one data frame order another data frame. topic discussed section Binding columns.","code":""},{"path":"joining-data.html","id":"bind-rows-1","chapter":"14 Joining data","heading":"Bind rows","text":"bind rows one data frame bottom another data frame, use bind_rows() dplyr. inclusive, column present either data frame included output. notes:Unlike base R version row.bind(), dplyr’s bind_rows() require order columns data frames. long column names spelled identically, align correctly.can optionally specify argument .id =. Provide character column name. produce new column serves identify data frame row originally came .can use bind_rows() list similarly-structured data frames combine one data frame. See example Iteration, loops, lists page involving import multiple linelists purrr.One common example row binding bind “total” row onto descriptive table made dplyr’s summarise() function. create table case counts median CT values hospital total row.function summarise() used data grouped hospital return summary data frame hospital. function summarise() automatically produce “totals” row, create summarising data , data grouped hospital. produces second data frame just one row. can bind data frames together achieve final table.See worked examples like Descriptive tables Tables presentation pages.hosp_summary data frame:Create data frame “total” statistics (grouped hospital). return just one row.totals data frame. Note two columns. columns also hosp_summary, one column hosp_summary totals (hospital).Now can bind rows together bind_rows().Now can view result. See final row, empty NA value fills column hospital hosp_summary. explained Tables presentation page, “fill-” cell “Total” using replace_na().","code":"\n# Create core table\n###################\nhosp_summary <- linelist %>% \n  group_by(hospital) %>%                        # Group data by hospital\n  summarise(                                    # Create new summary columns of indicators of interest\n    cases = n(),                                  # Number of rows per hospital-outcome group     \n    ct_value_med = median(ct_blood, na.rm=T))     # median CT value per group\n# create totals\n###############\ntotals <- linelist %>% \n  summarise(\n    cases = n(),                               # Number of rows for whole dataset     \n    ct_value_med = median(ct_blood, na.rm=T))  # Median CT for whole dataset\n# Bind data frames together\ncombined <- bind_rows(hosp_summary, totals)"},{"path":"joining-data.html","id":"bind-columns","chapter":"14 Joining data","heading":"Bind columns","text":"similar dplyr function bind_cols() can use combine two data frames sideways. Note rows matched position (like join ) - example 12th row data frame aligned.example, bind several summary tables together. order , also demonstrate re-arrange order rows one data frame match order another data frame, match().define case_info summary data frame linelist cases, hospital, number cases number deaths.let’s say different data frame contact_fu containing information percent exposed contacts investigated “followed-”, hospital.Note hospitals , different orders data frame. easiest solution use left_join() hospital column, also use bind_cols() one extra step.","code":"\n# Case information\ncase_info <- linelist %>% \n  group_by(hospital) %>% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\ncontact_fu <- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)"},{"path":"joining-data.html","id":"use-match-to-align-ordering","chapter":"14 Joining data","heading":"Use match() to align ordering","text":"row orders different, simple bind_cols() command result mis-match data. fix can use match() base R align rows data frame order another. assume approach duplicate values either data frame.use match(), syntax match(TARGET ORDER VECTOR, DATA FRAME COLUMN CHANGE), first argument desired order (either stand-alone vector, case column data frame), second argument data frame column data frame re-ordered. output match() vector numbers representing correct position ordering. can read ?match.can use numeric vector re-order data frame - place within subset brackets [ ] comma. Read base R bracket subset syntax R basics page. command creates new data frame, defined old one rows ordered numeric vector .Now can bind data frame columns together, correct row order. Note columns duplicated require cleaning rename(). Read aboout bind_rows() .base R alternative bind_cols cbind(), performs operation.","code":"\nmatch(case_info$hospital, contact_fu$hospital)## [1] 4 2 3 6 5 1\ncontact_fu_aligned <- contact_fu[match(case_info$hospital, contact_fu$hospital),]\nbind_cols(case_info, contact_fu)## New names:\n## • `hospital` -> `hospital...1`\n## • `hospital` -> `hospital...4`## # A tibble: 6 × 6\n##   hospital...1                         cases deaths hospital...4                         investigated per_fu\n##   <chr>                                <int>  <int> <chr>                                <chr>        <chr> \n## 1 Central Hospital                       454    193 St. Mark's Maternity Hospital (SMMH) 80%          60%   \n## 2 Military Hospital                      896    399 Military Hospital                    82%          25%   \n## 3 Missing                               1469    611 Missing                              <NA>         <NA>  \n## 4 Other                                  885    395 Central Hospital                     78%          20%   \n## 5 Port Hospital                         1762    785 Port Hospital                        64%          75%   \n## 6 St. Mark's Maternity Hospital (SMMH)   422    199 Other                                55%          80%"},{"path":"joining-data.html","id":"resources-7","chapter":"14 Joining data","heading":"14.5 Resources","text":"tidyverse page joinsThe R Data Science page relational dataTh tidyverse page dplyr bindingA vignette fastLink package’s Github pagePublication describing methodology fastLinkPublication describing RecordLinkage package","code":""},{"path":"de-duplication.html","id":"de-duplication","chapter":"15 De-duplication","heading":"15 De-duplication","text":"page covers following de-duplication techniques:Identifying removing duplicate rows“Slicing” rows keep certain rows (e.g. min max) group rows“Rolling-”, combining values multiple rows one row","code":""},{"path":"de-duplication.html","id":"preparation-6","chapter":"15 De-duplication","heading":"15.1 Preparation","text":"","code":""},{"path":"de-duplication.html","id":"load-packages-7","chapter":"15 De-duplication","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,   # deduplication, grouping, and slicing functions\n  janitor,     # function for reviewing duplicates\n  stringr)      # for string searches, can be used in \"rolling-up\" values"},{"path":"de-duplication.html","id":"import-data-8","chapter":"15 De-duplication","heading":"Import data","text":"demonstration, use example dataset created R code .data records COVID-19 phone encounters, including encounters contacts cases. columns include recordID (computer-generated), personID, name, date encounter, time encounter, purpose encounter (either interview case contact), symptoms_ever (whether person encounter reported ever symptoms).code create obs dataset:","code":"\nobs <- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %>% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))"},{"path":"de-duplication.html","id":"dedup_data","chapter":"15 De-duplication","heading":"Here is the data frame","text":"Use filter boxes along top review encounters person.things note review data:first two records 100% complete duplicates including duplicate recordID (must computer glitch!)second two rows duplicates, columns except recordIDSeveral people multiple phone encounters, various dates times, contacts /casesAt encounter, person asked ever symptoms, information missing.quick summary people purposes encounters, using tabyl() janitor:","code":"\nobs %>% \n  tabyl(name, purpose)##     name case contact\n##     adam    1       2\n##   amrish    1       3\n##    brian    1       2\n##   mariah    1       2\n##  natalie    1       0\n##   nikhil    0       2\n##   raquel    0       2\n##    smita    0       1"},{"path":"de-duplication.html","id":"deduplication-1","chapter":"15 De-duplication","heading":"15.2 Deduplication","text":"section describes review remove duplicate rows data frame. also show handle duplicate elements vector.","code":""},{"path":"de-duplication.html","id":"examine-duplicate-rows","chapter":"15 De-duplication","heading":"Examine duplicate rows","text":"quickly review rows duplicates, can use get_dupes() janitor package. default, columns considered duplicates evaluated - rows returned function 100% duplicates considering values columns.obs data frame, first two rows 100% duplicates - value every column (including recordID column, supposed unique - must computer glitch). returned data frame automatically includes new column dupe_count right side, showing number rows combination duplicate values.See original dataHowever, choose ignore recordID, 3rd 4th rows rows also duplicates . , values columns except recordID. can specify specific columns ignored function using - minus symbol.can also positively specify columns consider. , rows values name purpose columns returned. Notice “amrish” now dupe_count equal 3 reflect three “contact” encounters.*Scroll left rows**See original data.See ?get_dupes details, see online reference","code":"\n# 100% duplicates across all columns\nobs %>% \n  janitor::get_dupes()\n# Duplicates when column recordID is not considered\nobs %>% \n  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()\n# duplicates based on name and purpose columns ONLY\nobs %>% \n  janitor::get_dupes(name, purpose)"},{"path":"de-duplication.html","id":"keep-only-unique-rows","chapter":"15 De-duplication","heading":"Keep only unique rows","text":"keep unique rows data frame, use distinct() dplyr (demonstrated Cleaning data core functions page). Rows duplicates removed first rows kept. default, “first” means highest rownumber (order rows top--bottom). unique rows remain.example , run distinct() column recordID excluded consideration - thus two duplicate rows removed. first row (“adam”) 100% duplicated removed. Also row 3 (“amrish”) duplicate every column except recordID (considered) also removed. obs dataset n now nrow(obs)-2, nrow(obs) rows).Scroll left see entire data frameCAUTION: using distinct() grouped data, function apply group.Deduplicate based specific columnsYou can also specify columns basis de-duplication. way, de-duplication applies rows duplicates within specified columns. Unless set .keep_all = TRUE, columns mentioned dropped.example , de-duplication applies rows identical values name purpose columns. Thus, “brian” 2 rows instead 3 - first “contact” encounter “case” encounter. adjust brian’s latest encounter purpose kept, see tab Slicing within groups.Scroll left see entire data frameSee original data.","code":"\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(across(-recordID), # reduces data frame to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) \n\n# if outside pipes, include the data as first argument \n# distinct(obs)\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns\n  arrange(name)                                  # arrange for easier viewing"},{"path":"de-duplication.html","id":"deduplicate-elements-in-a-vector","chapter":"15 De-duplication","heading":"Deduplicate elements in a vector","text":"function duplicated() base R evaluate vector (column) return logical vector length (TRUE/FALSE). first time value appears, return FALSE (duplicate), subsequent times value appears return TRUE. Note NA treated value.return duplicated elements, can use brackets subset original vector:return unique elements, use unique() base R. remove NAs output, nest na.omit() within unique().","code":"\nx <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)##  [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\nx[duplicated(x)]## [1]  1 NA  4  4  1  2\nunique(x)           # alternatively, use x[!duplicated(x)]## [1]  1  2 NA  4  5\nunique(na.omit(x))  # remove NAs ## [1] 1 2 4 5"},{"path":"de-duplication.html","id":"using-base-r-1","chapter":"15 De-duplication","heading":"Using base R","text":"return duplicate rowsIn base R, can also see rows 100% duplicates data frame df command duplicated(df) (returns logical vector rows).Thus, can also use base subset [ ] data frame see duplicated rows df[duplicated(df),] (don’t forget comma, meaning want see columns!).return unique rowsSee notes . see unique rows add logical negator ! front duplicated() function:df[!duplicated(df),]return rows duplicates certain columnsSubset df within duplicated() parentheses, function operate certain columns df.specify columns, provide column numbers names comma (remember, within duplicated() function).sure keep comma , outside duplicated() function well!example, evaluate columns 2 5 duplicates: df[!duplicated(df[, 2:5]),]\nevaluate columns name purpose duplicates: df[!duplicated(df[, c(\"name\", \"purpose)]),]","code":""},{"path":"de-duplication.html","id":"slicing","chapter":"15 De-duplication","heading":"15.3 Slicing","text":"“slice” data frame apply filter rows row number/position. becomes particularly useful multiple rows per functional group (e.g. per “person”) want keep one .basic slice() function accepts numbers returns rows positions. numbers provided positive, returned. negative, rows returned. Numbers must either positive negative.See original data.several variations: provided column number rows return (n =).slice_min() slice_max() keep row(s) minimium maximum value(s) specified column. also works return “min” “max” ordered factors.slice_head() slice_tail() - keep first last row(s).slice_sample() - keep random sample rows.Use arguments n = prop = specify number proportion rows keep. using function pipe chain, provide data argument first (e.g. slice(data, n = 2)). See ?slice information.arguments:.order_by = used slice_min() slice_max() column order slicing.with_ties = TRUE default, meaning ties kept..preserve = FALSE default. TRUE grouping structure re-calculated slicing.weight_by = Optional, numeric column weight (bigger number likely get sampled). Also replace = whether sampling done /without replacement.TIP: using slice_max() slice_min(), sure specify/write n = (e.g. n = 2, just 2). Otherwise may get error Error:…empty. NOTE: may encounter function top_n(), superseded slice functions.","code":"\nobs %>% slice(4)  # return the 4th row##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        3        2 amrish 2020-01-02 14:20         1 contact            No\nobs %>% slice(c(2,4))  # return rows 2 and 4##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        1        1   adam 2020-01-01 09:00         1 contact          <NA>\n## 2        3        2 amrish 2020-01-02 14:20         1 contact            No\n#obs %>% slice(c(2:4))  # return rows 2 through 4\nobs %>% slice_max(encounter, n = 1)  # return rows with the largest encounter number##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n## 2       13        3 mariah 2020-01-06 08:32         3 contact            No\n## 3       16        5  brian 2020-01-07 07:59         3    case            No"},{"path":"de-duplication.html","id":"slice-with-groups","chapter":"15 De-duplication","heading":"Slice with groups","text":"slice_*() functions can useful applied grouped data frame slice operation performed group separately. Use function group_by() conjunction slice() group data take slice group.helpful de-duplication multiple rows per person want keep one . first use group_by() key columns per person, use slice function column differ among grouped rows.example , keep latest encounter per person, group rows name use slice_max() n = 1 date column. aware! apply function like slice_max() dates, date column must class Date.default, “ties” (e.g. date scenario) kept, still get multiple rows people (e.g. adam). avoid set with_ties = FALSE. get back one row per person.CAUTION: using arrange(), specify .by_group = TRUE data arranged within group.DANGER: with_ties = FALSE, first row tie kept. may deceptive. See Mariah, two encounters latest date (6 Jan) first (earliest) one kept. Likely, want keep later encounter day. See “break” ties next example. , example can see Amrish’s row 5 Jan kept, Brian’s row 7 Jan kept. See original data.Breaking “ties”Multiple slice statements can run “break ties”. case, person multiple encounters latest date, encounter latest time kept (lubridate::hm() used convert character times sortable time class).\nNote now, one row kept “Mariah” 6 Jan encounter 3 08:32, encounter 2 07:25.example , also possible slice encounter number, showed slice date time example purposes.TIP: use slice_max() slice_min() “character” column, mutate ordered factor class!See original data.","code":"\nobs %>% \n  group_by(name) %>%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) # if there's a tie (of date), take the first row\n# Example of multiple slice statements to \"break ties\"\nobs %>%\n  group_by(name) %>%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)"},{"path":"de-duplication.html","id":"keep-all-but-mark-them","chapter":"15 De-duplication","heading":"Keep all but mark them","text":"want keep records mark analysis, consider two-step approach utilizing unique recordID/encounter number:Reduce/slice orginal data frame rows analysis. Save/retain reduced data frame.original data frame, mark rows appropriate case_when(), based whether record unique identifier (recordID example) present reduced data frame.See original data.","code":"\n# 1. Define data frame of rows to keep for analysis\nobs_keep <- obs %>%\n  group_by(name) %>%\n  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person\n\n\n# 2. Mark original data frame\nobs_marked <- obs %>%\n\n  # make new dup_record column\n  mutate(dup_record = case_when(\n    \n    # if record is in obs_keep data frame\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # all else marked as \"Ignore\" for analysis purposes\n    TRUE                            ~ \"Ignore\"))\n\n# print\nobs_marked##    recordID personID    name       date  time encounter purpose symptoms_ever   dup_record\n## 1         1        1    adam 2020-01-01 09:00         1 contact          <NA>       Ignore\n## 2         1        1    adam 2020-01-01 09:00         1 contact          <NA>       Ignore\n## 3         2        2  amrish 2020-01-02 14:20         1 contact            No       Ignore\n## 4         3        2  amrish 2020-01-02 14:20         1 contact            No       Ignore\n## 5         4        3  mariah 2020-01-05 12:00         1    case            No       Ignore\n## 6         5        2  amrish 2020-01-05 16:10         3    case           Yes For analysis\n## 7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes       Ignore\n## 8         7        5   brian 2020-01-05 15:20         1 contact            No       Ignore\n## 9         8        6   smita 2020-01-05 14:20         1 contact           Yes For analysis\n## 10        9        7  raquel 2020-01-05 12:30         1 contact          <NA>       Ignore\n## 11       10        2  amrish 2020-01-02 10:24         2 contact           Yes       Ignore\n## 12       11        1    adam 2020-01-05 09:40         2    case            No For analysis\n## 13       12        3  mariah 2020-01-06 07:25         2 contact            No       Ignore\n## 14       13        3  mariah 2020-01-06 08:32         3 contact            No For analysis\n## 15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes For analysis\n## 16       15        5   brian 2020-01-06 15:31         2 contact           Yes       Ignore\n## 17       16        5   brian 2020-01-07 07:59         3    case            No For analysis\n## 18       17        7  raquel 2020-01-07 11:13         2 contact            No For analysis\n## 19       18        8 natalie 2020-01-07 17:12         1    case            No For analysis"},{"path":"de-duplication.html","id":"calculate-row-completeness","chapter":"15 De-duplication","heading":"Calculate row completeness","text":"Create column contains metric row’s completeness (non-missingness). helpful deciding rows prioritize others de-duplicating/slicing.example, “key” columns want measure completeness saved vector column names.new column key_completeness created mutate(). new value row defined calculated fraction: number non-missing values row among key columns, divided number key columns.involves function rowSums() base R. Also used ., within piping refers data frame point pipe (case, subset brackets []).*Scroll right see rows**See original data.","code":"\n# create a \"key variable completeness\" column\n# this is a *proportion* of the columns designated as \"key_cols\" that have non-missing values\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) "},{"path":"de-duplication.html","id":"str_rollup","chapter":"15 De-duplication","heading":"15.4 Roll-up values","text":"section describes:“roll-” values multiple rows just one row, variationsOnce “rolled-” values, overwrite/prioritize values cellThis tab uses example dataset Preparation tab.","code":""},{"path":"de-duplication.html","id":"roll-up-values-into-one-row","chapter":"15 De-duplication","heading":"Roll-up values into one row","text":"code example uses group_by() summarise() group rows person, paste together unique values within grouped rows. Thus, get one summary row per person. notes:suffix appended new columns (“_roll” example)want show unique values per cell, wrap na.omit() unique()na.omit() removes NA values, desired can removed paste0(.x)…result one row per group (ID), entries arranged date pasted together. Scroll left see rowsSee original data.variation shows unique values :variation appends suffix column.\ncase “_roll” signify rolled:","code":"\n# \"Roll-up\" values into one row per group (per \"personID\") \ncases_rolled <- obs %>% \n  \n  # create groups by name\n  group_by(personID) %>% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                           # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) # function is defined which combines non-NA values\n# Variation - show unique values only \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # function is defined which combines unique non-NA values\n# Variation - suffix added to column names \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll is appended to column names"},{"path":"de-duplication.html","id":"overwrite-valueshierarchy","chapter":"15 De-duplication","heading":"Overwrite values/hierarchy","text":"want evaluate rolled values, keep specific value (e.g. “best” “maximum” value), can use mutate() across desired columns, implement case_when(), uses str_detect() stringr package sequentially look string patterns overwrite cell content.Now can see column symptoms_ever person EVER said “Yes” symptoms, “Yes” displayed.See original data.","code":"\n# CLEAN CASES\n#############\ncases_clean <- cases_rolled %>% \n    \n    # clean Yes-No-Unknown vars: replace text with \"highest\" value present in the string\n    mutate(across(c(contains(\"symptoms_ever\")),                     # operates on specified columns (Y/N/U)\n             list(mod = ~case_when(                                 # adds suffix \"_mod\" to new cols; implements case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # if \"Yes\" is detected, then cell value converts to yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # then, if \"No\" is detected, then cell value converts to no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # then, if \"Unknown\" is detected, then cell value converts to Unknown\n               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is\n      .keep = \"unused\")                                             # old columns removed, leaving only _mod columns"},{"path":"de-duplication.html","id":"probabilistic-de-duplication","chapter":"15 De-duplication","heading":"15.5 Probabilistic de-duplication","text":"Sometimes, may want identify “likely” duplicates based similarity (e.g. string “distance”) across several columns name, age, sex, date birth, etc. can apply probabilistic matching algorithm identify likely duplicates.See page Joining data explanation method. section Probabilistic Matching contains example applying algorithms compare data frame , thus performing probabilistic de-duplication.","code":""},{"path":"de-duplication.html","id":"resources-8","chapter":"15 De-duplication","heading":"15.6 Resources","text":"Much information page adapted resources vignettes online:datanoviadplyr tidyverse referencecran janitor vignette","code":""},{"path":"iteration-loops-and-lists.html","id":"iteration-loops-and-lists","chapter":"16 Iteration, loops, and lists","heading":"16 Iteration, loops, and lists","text":"Epidemiologists often faced repeating analyses subgroups countries, districts, age groups. many situations involving iteration. Coding iterative operations using approaches help perform repetitive tasks faster, reduce chance error, reduce code length.page introduce two approaches iterative operations - using loops using package purrr.loops iterate code across series inputs, less common R programming languages. Nevertheless, introduce learning tool referenceThe purrr package tidyverse approach iterative operations - works “mapping” function across many inputs (values, columns, datasets, etc.)Along way, ’ll show examples like:Importing exporting multiple filesCreating epicurves multiple jurisdictionsRunning T-tests several columns data frameIn purrr section also provide several examples creating handling lists.","code":""},{"path":"iteration-loops-and-lists.html","id":"preparation-7","chapter":"16 Iteration, loops, and lists","heading":"16.1 Preparation","text":"","code":""},{"path":"iteration-loops-and-lists.html","id":"load-packages-8","chapter":"16 Iteration, loops, and lists","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n     rio,         # import/export\n     here,        # file locator\n     purrr,       # iteration\n     grates,      # scales in ggplot\n     tidyverse    # data management and visualization\n)"},{"path":"iteration-loops-and-lists.html","id":"import-data-9","chapter":"16 Iteration, loops, and lists","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"iteration-loops-and-lists.html","id":"for-loops","chapter":"16 Iteration, loops, and lists","heading":"16.2 for loops","text":"","code":""},{"path":"iteration-loops-and-lists.html","id":"iter_loops","chapter":"16 Iteration, loops, and lists","heading":"for loops in R","text":"loops emphasized R, common programming languages. beginner, can helpful learn practice easier “explore”, “de-bug”, otherwise grasp exactly happening iteration, especially yet comfortable writing functions.may move quickly loops iterating mapped functions purrr (see section ).","code":""},{"path":"iteration-loops-and-lists.html","id":"core-components","chapter":"16 Iteration, loops, and lists","heading":"Core components","text":"loop three core parts:sequence items iterate throughThe operations conduct per item sequenceThe container results (optional)basic syntax : (item sequence) {operations using item}. Note parentheses curly brackets. results printed console, stored container R object.simple loop example .","code":"\nfor (num in c(1,2,3,4,5)) {  # the SEQUENCE is defined (numbers 1 to 5) and loop is opened with \"{\"\n  print(num + 2)             # The OPERATIONS (add two to each sequence number and print)\n}                            # The loop is closed with \"}\"                            ## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7\n                             # There is no \"container\" in this example"},{"path":"iteration-loops-and-lists.html","id":"sequence","chapter":"16 Iteration, loops, and lists","heading":"Sequence","text":"“” part loop - operations run “” item sequence. sequence can series values (e.g. names jurisdictions, diseases, column names, list elements, etc), can series consecutive numbers (e.g. 1,2,3,4,5). approach utilities, described .basic structure sequence statement item vector.can write character word place “item” (e.g. “”, “num”, “hosp”, “district”, etc.). value “item” changes iteration loop, proceeding value vector.vector character values, column names, perhaps sequence numbers - values change iteration. can use within loop operations using “item” term.Example: sequence character valuesIn example, loop performed value pre-defined character vector hospital names.chosen term hosp represent values vector hospital_names. first iteration loop, value hosp hospital_names[[1]]. second loop hospital_names[[2]]. …Example: sequence column namesThis variation character sequence , names existing R object extracted become vector. example, column names data frame. Conveniently, operations code loop, column names can used index (subset) original data frameBelow, sequence names() (column names) linelist data frame. “item” name col, represent column name loops proceeds.purposes example, include operations code inside loop, run every value sequence. code, sequence values (column names) used index (subset) linelist, one---time. taught R basics page, double branckets [[ ]] used subset. resulting column passed .na(), sum() produce number values column missing. result printed console - one number column.note indexing column names - whenever referencing column just write “col”! col represents just character column name! refer entire column must use column name index linelist via linelist[[col]].Sequence numbersIn approach, sequence series consecutive numbers. Thus, value “item” character value (e.g. “Central Hospital” “date_onset”) number. useful looping data frames, can use “item” number inside loop index data frame row number.example, let’s say want loop every row data frame extract certain information. “items” numeric row numbers. Often, “items” case written .loop process explained words “every item sequence numbers 1 total number rows data frame, X”. first iteration loop, value “item” 1. second iteration, 2, etc.sequence looks like code: (1:nrow(linelist)) {OPERATIONS CODE} represents “item” 1:nrow(linelist) produces sequence consecutive numbers 1 number rows linelist.want sequence numbers, starting vector (data frame), use shortcut seq_along() return sequence numbers element vector. example, (seq_along(hospital_names) {OPERATIONS CODE}.code actually returns numbers, become value respective loop.One advantage using numbers sequence easy also use number index container stores loop outputs. example Operations section .","code":"\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\nhospital_names # print## [1] \"Other\"                                \"Missing\"                              \"St. Mark's Maternity Hospital (SMMH)\"\n## [4] \"Port Hospital\"                        \"Military Hospital\"                    \"Central Hospital\"\n# a 'for loop' with character sequence\n\nfor (hosp in hospital_names){       # sequence\n  \n       # OPERATIONS HERE\n  }\nfor (col in names(linelist)){        # loop runs for each column in linelist; column name represented by \"col\" \n  \n  # Example operations code - print number of missing values in column\n  print(sum(is.na(linelist[[col]])))  # linelist is indexed by current value of \"col\"\n     \n}## [1] 0\n## [1] 0\n## [1] 2087\n## [1] 256\n## [1] 0\n## [1] 936\n## [1] 1323\n## [1] 278\n## [1] 86\n## [1] 0\n## [1] 86\n## [1] 86\n## [1] 86\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 2088\n## [1] 2088\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 149\n## [1] 765\n## [1] 0\n## [1] 256\nfor (i in 1:nrow(linelist)) {  # use on a data frame\n  # OPERATIONS HERE\n}  \nseq_along(hospital_names)  # use on a named vector## [1] 1 2 3 4 5 6"},{"path":"iteration-loops-and-lists.html","id":"operations","chapter":"16 Iteration, loops, and lists","heading":"Operations","text":"code within curly brackets { } loop. want code run “item” sequence. Therefore, careful every part code changes “item” correctly coded actually changes! E.g. remember use [[ ]] indexing.example , iterate row linelist. gender age values row pasted together stored container character vector cases_demographics. Note also use indexing [[]] save loop output correct position “container” vector.","code":"\n# create container to store results - a character vector\ncases_demographics <- vector(mode = \"character\", length = nrow(linelist))\n\n# the for loop\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extract values from linelist for row i, using brackets for indexing\n  row_gender  <- linelist$gender[[i]]\n  row_age     <- linelist$age_years[[i]]    # don't forget to index!\n     \n  # combine gender-age and store in container vector at indexed location\n  cases_demographics[[i]] <- str_c(row_gender, row_age, sep = \",\") \n\n}  # end for loop\n\n\n# display first 10 rows of container\nhead(cases_demographics, 10)##  [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\""},{"path":"iteration-loops-and-lists.html","id":"container","chapter":"16 Iteration, loops, and lists","heading":"Container","text":"Sometimes results loop printed console RStudio Plots pane. times, want store outputs “container” later use. container vector, data frame, even list.efficient create container results even beginning loop. practice, means creating empty vector, data frame, list. can created functions vector() vectors lists, matrix() data.frame() data frame.Empty vectorUse vector() specify mode = based expected class objects insert - either “double” (hold numbers), “character”, “logical”. also set length = advance. length loop sequence.Say want store median delay--admission hospital. use “double” set length number expected outputs (number unique hospitals data set).Empty data frameYou can make empty data frame specifying number rows columns like :Empty listYou may want store plots created loop list. list like vector, holds R objects within can different classes. Items list single number, dataframe, vector, even another list.actually initialize empty list using vector() command , mode = \"list\". Specify length however wish.","code":"\ndelays <- vector(\n  mode = \"double\",                            # we expect to store numbers\n  length = length(unique(linelist$hospital))) # the number of unique hospitals in the dataset\ndelays <- data.frame(matrix(ncol = 2, nrow = 3))\nplots <- vector(mode = \"list\", length = 16)"},{"path":"iteration-loops-and-lists.html","id":"printing","chapter":"16 Iteration, loops, and lists","heading":"Printing","text":"Note print within loop likely need explicitly wrap function print().example , sequence explicit character vector, used subset linelist hospital. results stored container, rather printed console print() function.","code":"\nfor (hosp in hospital_names){ \n     hospital_cases <- linelist %>% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}## [1] 885\n## [1] 1469\n## [1] 422\n## [1] 1762\n## [1] 896\n## [1] 454"},{"path":"iteration-loops-and-lists.html","id":"testing-your-for-loop","chapter":"16 Iteration, loops, and lists","heading":"Testing your for loop","text":"test loop, can run command make temporary assignment “item”, <- 10 hosp <- \"Central Hospital\". outside loop run operations code (code within curly brackets) see expected results produced.","code":""},{"path":"iteration-loops-and-lists.html","id":"looping-plots","chapter":"16 Iteration, loops, and lists","heading":"Looping plots","text":"put three components together (container, sequence, operations) let’s try plot epicurve hospital (see page Epidemic curves).can make nice epicurve cases gender using incidence2 package :produce separate plot hospital’s cases, can put epicurve code within loop.First, save named vector unique hospital names, hospital_names. loop run names: (hosp hospital_names). iteration loop, current hospital name vector represented hosp use within loop.Within loop operations, can write R code normal, use “item” (hosp case) knowing value changing. Within loop:filter() applied linelist, column hospital must equal current value hospThe incidence object created filtered linelistThe plot current hospital created, auto-adjusting title uses hospThe plot current hospital temporarily saved printedThe loop moves onward repeat next hospital hospital_names","code":"\n# create 'incidence' object\noutbreak <- incidence2::incidence(   \n     x = linelist,                   # dataframe - complete linelist\n     date_index = \"date_onset\",        # date column\n     interval = \"week\",              # aggregate counts weekly\n     groups = \"gender\")               # group values by gender\n     #na_as_group = TRUE)             # missing gender is own group\n\n# tracer la courbe d'épidémie\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # Fill colour of bars by gender\n       color = \"black\"      # Contour colour of bars\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\n\n# for each name (\"hosp\") in hospital_names, create and print the epi curve\nfor (hosp in hospital_names) {\n     \n     # create incidence object specific to the current hospital\n     outbreak_hosp <- incidence2::incidence(\n          x = linelist %>% filter(hospital == hosp),   # linelist is filtered to the current hospital\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\"#,\n          #na_as_group = TRUE\n     )\n     \n      plot_hosp <- ggplot(outbreak_hosp, # incidence object name\n                         aes(x = date_index, #axes\n                             y = count, \n                             fill = gender), # fill colour by gender\n                         color = \"black\"      # colour of bar contour\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #title\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # With older versions of R, remove the # before na_as_group and use this plot command instead.\n    # plot_hosp <- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     #print the plot for hospitals\n     print(plot_hosp)\n     \n} # end the for loop when it has been run for every hospital in hospital_names "},{"path":"iteration-loops-and-lists.html","id":"tracking-progress-of-a-loop","chapter":"16 Iteration, loops, and lists","heading":"Tracking progress of a loop","text":"loop many iterations can run many minutes even hours. Thus, can helpful print progress R console. statement can placed within loop operations print every 100th number. Just adjust “item” loop.","code":"# loop with code to print progress every 100 iterations\nfor (i in seq_len(nrow(linelist))){\n\n  # print progress\n  if(i %% 100==0){    # The %% operator is the remainder\n    print(i)\n\n}"},{"path":"iteration-loops-and-lists.html","id":"iter_purrr","chapter":"16 Iteration, loops, and lists","heading":"16.3 purrr and lists","text":"Another approach iterative operations purrr package - tidyverse approach iteration.faced performing task several times, probably worth creating generalised solution can use across many inputs. example, producing plots multiple jurisdictions, importing combining many files.also advantages purrr - can use pipes %>%, handles errors better normal loops, syntax quite clean simple! using loop, can probably clearly succinctly purrr!Keep mind purrr functional programming tool. , operations iteratively applied wrapped functions. See Writing functions page learn write functions.purrr also almost entirely based around lists vectors - think applying function element list/vector!","code":""},{"path":"iteration-loops-and-lists.html","id":"load-packages-9","chapter":"16 Iteration, loops, and lists","heading":"Load packages","text":"purrr part tidyverse, need install/load separate package.","code":"\npacman::p_load(\n     rio,            # import/export\n     here,           # relative filepaths\n     tidyverse,      # data mgmt and viz\n     writexl,        # write Excel file with multiple sheets\n     readxl          # import Excel with multiple sheets\n)"},{"path":"iteration-loops-and-lists.html","id":"map","chapter":"16 Iteration, loops, and lists","heading":"map()","text":"One core purrr function map(), “maps” (applies) function input element list/vector provide.basic syntax map(.x = SEQUENCE, .f = FUNCTION, ARGUMENTS). bit detail:.x = inputs upon .f function iteratively applied - e.g. vector jurisdiction names, columns data frame, list data frames.f = function apply element .x input - function like print() already exists, custom function define. function often written tilde ~ (details ).notes syntax:function needs arguments specified, can written parentheses tilde (e.g. .f = mean). provide arguments value iteration, provide within map() outside .f = argument, na.rm = T map(.x = my_list, .f = mean, na.rm=T).can use .x (simply .) within .f = function placeholder .x value iterationUse tilde syntax (~) greater control function - write function normal parentheses, : map(.x = my_list, .f = ~mean(., na.rm = T)). Use syntax particularly value argument change iteration, value .x (see examples )output using map() list - list object class like vector whose elements can different classes. , list produced map() contain many data frames, many vectors, many single values, even many lists! alternative versions map() explained produce types outputs (e.g. map_dfr() produce data frame, map_chr() produce character vectors, map_dbl() produce numeric vectors).","code":""},{"path":"iteration-loops-and-lists.html","id":"iter_combined","chapter":"16 Iteration, loops, and lists","heading":"Example - import and combine Excel sheets","text":"Let’s demonstrate common epidemiologist task: - want import Excel workbook case data, data split across different named sheets workbook. efficiently import combine sheets one data frame?Let’s say sent Excel workbook. sheet contains cases given hospital.one approach uses map():map() function import() runs Excel sheetCombine imported data frames one using bind_rows()Along way, preserve original sheet name row, storing information new column final data frameFirst, need extract sheet names save . provide Excel workbook’s file path function excel_sheets() package readxl, extracts sheet names. store character vector called sheet_names.names:Now vector names, map() can provide one--one function import(). example, sheet_names .x import() function .f.Recall Import export page used Excel workbooks, import() can accept argument = specifying sheet import. Within .f function import(), provide = .x, whose value change iteration vector sheet_names - first “Central Hospital”, “Military Hospital”, etc.note - used map(), data Excel sheet saved separate data frame within list. want list elements (data frames) name, pass sheet_names map() pass set_names() purrr, ensures list element gets appropriate name.save output list combined.inspect output, see data Excel sheet saved list name. good, quite finished.Lastly, use function bind_rows() (dplyr) accepts list similarly-structured data frames combines one data frame. create new column list element names, use argument .id = provide desired name new column.whole sequence commands:now one data frame column containing sheet origin!variations map() aware . example, map_dfr() returns data frame, list. Thus, used task bind rows. able capture sheet (hospital) case came .variations include map_chr(), map_dbl(). useful functions two reasons. Firstly. automatically convert output iterative function vector (list). Secondly, can explicitly control class data comes back - ensure data comes back character vector map_chr(), numeric vector map_dbl(). Lets return later section!functions map_at() map_if() also useful iteration - allow specify elements list iterate ! work simply applying vector indexes/names (case map_at()) logical test (case map_if()).Lets use example didn’t want read first sheet hospital data. use map_at() instead map(), specify .= argument c(-1) means use first element .x. Alternatively, can provide vector positive numbers, names, .= specify elements use.Note first sheet name still appear element output list - single character name (data frame). need remove element binding rows. cover remove modify list elements later section.","code":"\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\nsheet_names## [1] \"Central Hospital\"              \"Military Hospital\"             \"Missing\"                      \n## [4] \"Other\"                         \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\ncombined <- sheet_names %>% \n  purrr::set_names() %>% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # extract sheet names\n \ncombined <- sheet_names %>%                                     # begin with sheet names\n  purrr::set_names() %>%                                        # set their names\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %>%  # iterate, import, save in list\n  bind_rows(.id = \"origin_sheet\") # combine list of data frames, preserving origin in new column  \nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined <- sheet_names %>% \n     purrr::set_names() %>% \n     # exclude the first sheet\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))"},{"path":"iteration-loops-and-lists.html","id":"split-dataset-and-export","chapter":"16 Iteration, loops, and lists","heading":"Split dataset and export","text":", give example split dataset parts use map() iteration export part separate Excel sheet, separate CSV file.","code":""},{"path":"iteration-loops-and-lists.html","id":"split-dataset","chapter":"16 Iteration, loops, and lists","heading":"Split dataset","text":"Let’s say complete case linelist data frame, now want create separate linelist hospital export separate CSV file. , following steps:Use group_split() (dplyr) split linelist data frame unique values column hospital. output list containing one data frame per hospital subset.can run View(linelist_split) see list contains 6 data frames (“tibbles”), representing cases one hospital.However, note data frames list names default! want name, use name saving CSV file.One approach extracting names use pull() (dplyr) extract hospital column data frame list. , safe, convert values character use unique() get name particular data frame. steps applied data frame via map().can now see list elements name. names can accessed via names(linelist_split).","code":"\nlinelist_split <- linelist %>% \n     group_split(hospital)\nnames(linelist_split) <- linelist_split %>%   # Assign to names of listed data frames \n     # Extract the names by doing the following to each data frame: \n     map(.f = ~pull(.x, hospital)) %>%        # Pull out hospital column\n     map(.f = ~as.character(.x)) %>%          # Convert to character, just in case\n     map(.f = ~unique(.x))                    # Take the unique hospital name\nnames(linelist_split)## [1] \"Central Hospital\"                     \"Military Hospital\"                    \"Missing\"                             \n## [4] \"Other\"                                \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\""},{"path":"iteration-loops-and-lists.html","id":"more-than-one-group_split-column","chapter":"16 Iteration, loops, and lists","heading":"More than one group_split() column","text":"wanted split linelist one grouping column, produce subset linelist intersection hospital gender, need different approach naming list elements. involves collecting unique “group keys” using group_keys() dplyr - returned data frame. can combine group keys values unite() shown , assign conglomerate names linelist_split.Now combine groupings together, separated dashes, assign names list elements linelist_split. takes extra lines replace NA “Missing”, use unite() dplyr combine column values together (separated dashes), convert un-named vector can used names linelist_split.","code":"\n# split linelist by unique hospital-gender combinations\nlinelist_split <- linelist %>% \n     group_split(hospital, gender)\n\n# extract group_keys() as a dataframe\ngroupings <- linelist %>% \n     group_by(hospital, gender) %>%       \n     group_keys()\n\ngroupings      # show unique groupings ## # A tibble: 18 × 2\n##    hospital                             gender\n##    <chr>                                <chr> \n##  1 Central Hospital                     f     \n##  2 Central Hospital                     m     \n##  3 Central Hospital                     <NA>  \n##  4 Military Hospital                    f     \n##  5 Military Hospital                    m     \n##  6 Military Hospital                    <NA>  \n##  7 Missing                              f     \n##  8 Missing                              m     \n##  9 Missing                              <NA>  \n## 10 Other                                f     \n## 11 Other                                m     \n## 12 Other                                <NA>  \n## 13 Port Hospital                        f     \n## 14 Port Hospital                        m     \n## 15 Port Hospital                        <NA>  \n## 16 St. Mark's Maternity Hospital (SMMH) f     \n## 17 St. Mark's Maternity Hospital (SMMH) m     \n## 18 St. Mark's Maternity Hospital (SMMH) <NA>\n# Combine into one name value \nnames(linelist_split) <- groupings %>% \n     mutate(across(everything(), replace_na, \"Missing\")) %>%  # replace NA with \"Missing\" in all columns\n     unite(\"combined\", sep = \"-\") %>%                         # Unite all column values into one\n     setNames(NULL) %>% \n     as_vector() %>% \n     as.list()"},{"path":"iteration-loops-and-lists.html","id":"export-as-excel-sheets","chapter":"16 Iteration, loops, and lists","heading":"Export as Excel sheets","text":"export hospital linelists Excel workbook one linelist per sheet, can just provide named list linelist_split write_xlsx() function writexl package. ability save one Excel workbook multiple sheets. list element names automatically applied sheet names.can now open Excel file see hospital sheet.","code":"\nlinelist_split %>% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))"},{"path":"iteration-loops-and-lists.html","id":"export-as-csv-files","chapter":"16 Iteration, loops, and lists","heading":"Export as CSV files","text":"bit complex command, can also export hospital-specific linelist separate CSV file, file name specific hospital.use map(): take vector list element names (shown ) use map() iterate , applying export() (rio package, see Import export page) data frame list linelist_split name. also use name create unique file name. works:begin vector character names, passed map() .xThe .f function export() , requires data frame file path write toThe input .x (hospital name) used within .f extract/index specific element linelist_split list. results one data frame time provided export().example, map() iterates “Military Hospital”, linelist_split[[.x]] actually linelist_split[[\"Military Hospital\"]], thus returning second element linelist_split - cases Military Hospital.file path provided export() dynamic via use str_glue() (see Characters strings page):\n() used get base file path specify “data” folder (note single quotes interrupt str_glue() double quotes)\n() used get base file path specify “data” folder (note single quotes interrupt str_glue() double quotes)slash /, .x prints current hospital name make file identifiableFinally extension “.csv” export() uses create CSV fileNow can see file saved “data” folder R Project “Epi_R_handbook”!","code":"\nnames(linelist_split) %>%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))"},{"path":"iteration-loops-and-lists.html","id":"custom-functions","chapter":"16 Iteration, loops, and lists","heading":"Custom functions","text":"may want create function provide map().Let’s say want create epidemic curves hospital’s cases. using purrr, .f function can ggplot() extensions + usual. output map() always list, plots stored list. plots, can extracted plotted ggarrange() function ggpubr package (documentation).map() code looks messy, can achieve result saving specific ggplot() command custom user-defined function, example can name make_epicurve()). function used within map(). .x iteratively replaced hospital name, used hosp_name make_epicurve() function. See page Writing functions.","code":"\n# load package for plotting elements from list\npacman::p_load(ggpubr)\n\n# map across the vector of 6 hospital \"names\" (created earlier)\n# use the ggplot function specified\n# output is a list with 6 ggplots\n\nhospital_names <- unique(linelist$hospital)\n\nmy_plots <- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %>% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n# Create function\nmake_epicurve <- function(hosp_name){\n  \n  ggplot(data = linelist %>% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n# mapping\nmy_plots <- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)"},{"path":"iteration-loops-and-lists.html","id":"mapping-a-function-across-columns","chapter":"16 Iteration, loops, and lists","heading":"Mapping a function across columns","text":"Another common use-case map function across many columns. , map() function t.test() across numeric columns data frame linelist, comparing numeric values gender.Recall page Simple statistical tests t.test() can take inputs formula format, t.test(numeric column ~ binary column). example, following:numeric columns interest selected linelist - become .x inputs map()function t.test() supplied .f function, applied numeric columnWithin parentheses t.test():\nfirst ~ precedes .f map() iterate .x\n.x represents current column supplied function t.test()\nsecond ~ part t-test equation described \nt.test() function expects binary column right-hand side equation. supply vector linelist$gender independently statically (note included select()).\nfirst ~ precedes .f map() iterate .xthe .x represents current column supplied function t.test()second ~ part t-test equation described abovethe t.test() function expects binary column right-hand side equation. supply vector linelist$gender independently statically (note included select()).map() returns list, output list t-test results - one list element numeric column analysed.list t.test_results looks like opened (Viewed) RStudio. highlighted parts important examples page.can see top whole list named t.test_results five elements. five elements named age, wt_km, ht_cm, ct_blood, temp variable used t-test gender linelist.five elements lists, elements within p.value conf.int. elements like p.value single numbers, whereas estimate consist two elements (mean group f mean group m).Note: Remember want apply function certain columns data frame, can also simply use mutate() across(), explained Cleaning data core functions page. example applying .character() “age” columns. Note placement parentheses commas.","code":"\n# Results are saved as a list\nt.test_results <- linelist %>% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %>%  # keep only some numeric columns to map across\n  map(.f = ~t.test(.x ~ linelist$gender))        # t.test function, with equation NUMERIC ~ CATEGORICAL\n# convert columns with column name containing \"age\" to class Character\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  "},{"path":"iteration-loops-and-lists.html","id":"extract-from-lists","chapter":"16 Iteration, loops, and lists","heading":"Extract from lists","text":"map() produces output class List, spend time discussing extract data lists using accompanying purrr functions. demonstrate , use list t.test_results previous section. list 5 lists - 5 lists contains results t-test column linelist data frame binary column gender. See image section visual list structure.","code":""},{"path":"iteration-loops-and-lists.html","id":"names-of-elements","chapter":"16 Iteration, loops, and lists","heading":"Names of elements","text":"extract names elements , simply use names() base R. case, use names() t.test_results return names sub-list, names 5 variables t-tests performed.","code":"\nnames(t.test_results)## [1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\""},{"path":"iteration-loops-and-lists.html","id":"elements-by-name-or-position","chapter":"16 Iteration, loops, and lists","heading":"Elements by name or position","text":"extract list elements name position can use brackets [[ ]] described R basics page. use double brackets index list t.tests_results display first element results t-test age.However, demonstrate use simple flexible purrr functions map() pluck() achieve outcomes.","code":"\nt.test_results[[1]] # first element by position## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results[[1]][\"p.value\"] # return element named \"p.value\" from first element  ## $p.value\n## [1] 2.350374e-96"},{"path":"iteration-loops-and-lists.html","id":"pluck","chapter":"16 Iteration, loops, and lists","heading":"pluck()","text":"pluck() pulls elements name position. example - extract t-test results age, can use pluck() like :Index deeper levels specifying levels commas. extracts element named “p.value” list age within list t.test_results. can also use numbers instead character names.can extract inner elements first-level elements using map() run pluck() function across first-level element. example, code extracts “p.value” elements lists within t.test_results. list t-test results .x iterated across, pluck() .f function iterated, value “p-value” provided function.another alternative, map() offers shorthand can write element name quotes, pluck . use map() output list, whereas use map_chr() named character vector use map_dbl() named numeric vector.can read pluck() ’s purrr documentation. sibling function chuck() return error instead NULL element exist.","code":"\nt.test_results %>% \n  pluck(\"age\")        # alternatively, use pluck(1)## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results %>% \n  pluck(\"age\", \"p.value\")## [1] 2.350374e-96\nt.test_results %>%\n  map(pluck, \"p.value\")   # return every p-value## $age\n## [1] 2.350374e-96\n## \n## $wt_kg\n## [1] 2.664367e-182\n## \n## $ht_cm\n## [1] 3.515713e-144\n## \n## $ct_blood\n## [1] 0.4473498\n## \n## $temp\n## [1] 0.5735923\nt.test_results %>% \n  map_dbl(\"p.value\")   # return p-values as a named numeric vector##           age         wt_kg         ht_cm      ct_blood          temp \n##  2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01"},{"path":"iteration-loops-and-lists.html","id":"convert-list-to-data-frame","chapter":"16 Iteration, loops, and lists","heading":"Convert list to data frame","text":"complex topic - see Resources section complete tutorials. Nevertheless, demonstrate converting list t-test results data frame. create data frame columns variable, p-value, means two groups (male female).new approaches functions used:function tibble() used create tibble (like data frame)\nsurround tibble() function curly brackets { } prevent entire t.test_results stored first tibble column\nsurround tibble() function curly brackets { } prevent entire t.test_results stored first tibble columnWithin tibble(), column created explicitly, similar syntax mutate():\n. represents t.test_results\ncreate column t-test variable names (names list element) use names() described \ncreate column p-values use map_dbl() described pull p.value elements convert numeric vector\n. represents t.test_resultsTo create column t-test variable names (names list element) use names() described aboveTo create column p-values use map_dbl() described pull p.value elements convert numeric vectorBut now let’s add columns containing means group (males females).need extract element estimate, actually contains two elements within (mean group f mean group m). , simplified vector map_chr() map_dbl(). Instead, use map(), used within tibble() create column class list within tibble! Yes, possible!list column, several tidyr functions (part tidyverse) help “rectangle” “un-nest” “nested list” columns. Read , running vignette(\"rectangle\"). brief:unnest_wider() - gives element list-column columnunnest_longer() - gives element list-column rowhoist() - acts like unnest_wider() specify elements unnestBelow, pass tibble unnest_wider() specifying tibble’s means column (nested list). result means replaced two new columns, reflecting two elements previously means cell.","code":"\nt.test_results %>% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }## # A tibble: 5 × 2\n##   variables         p\n##   <chr>         <dbl>\n## 1 age       2.35e- 96\n## 2 wt_kg     2.66e-182\n## 3 ht_cm     3.52e-144\n## 4 ct_blood  4.47e-  1\n## 5 temp      5.74e-  1\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}## # A tibble: 5 × 3\n##   variables         p means       \n##   <chr>         <dbl> <named list>\n## 1 age       2.35e- 96 <dbl [2]>   \n## 2 wt_kg     2.66e-182 <dbl [2]>   \n## 3 ht_cm     3.52e-144 <dbl [2]>   \n## 4 ct_blood  4.47e-  1 <dbl [2]>   \n## 5 temp      5.74e-  1 <dbl [2]>\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %>% \n  unnest_wider(means)## # A tibble: 5 × 4\n##   variables         p `mean in group f` `mean in group m`\n##   <chr>         <dbl>             <dbl>             <dbl>\n## 1 age       2.35e- 96              12.7              19.6\n## 2 wt_kg     2.66e-182              45.8              59.6\n## 3 ht_cm     3.52e-144             109.              142. \n## 4 ct_blood  4.47e-  1              21.2              21.2\n## 5 temp      5.74e-  1              38.6              38.6"},{"path":"iteration-loops-and-lists.html","id":"discard-keep-and-compact-lists","chapter":"16 Iteration, loops, and lists","heading":"Discard, keep, and compact lists","text":"working purrr often involves lists, briefly explore purrr functions modify lists. See Resources section complete tutorials purrr functions.list_modify() many uses, one can remove list elementkeep() retains elements specified .p =, function supplied .p = evaluates TRUEdiscard() removes elements specified .p, function supplied .p = evaluates TRUEcompact() removes empty elementsHere examples using combined list created section using map() import combine multiple files (contains 6 case linelist data frames):Elements can removed name list_modify() setting name equal NULL.can also remove elements criteria, providing “predicate” equation .p = (equation evaluates either TRUE FALSE). Place tilde ~ function use .x represent list element. Using keep() list elements evaluate TRUE kept. Inversely, using discard() list elements evaluate TRUE removed.example, list elements discarded class data frames.predicate function can also reference elements/columns within list item. example, , list elements mean column ct_blood 25 discarded.command remove empty list elements:","code":"\ncombined %>% \n  list_modify(\"Central Hospital\" = NULL)   # remove list element by name\n# keep only list elements with more than 500 rows\ncombined %>% \n  keep(.p = ~nrow(.x) > 500)  \n# Discard list elements that are not data frames\ncombined %>% \n  discard(.p = ~class(.x) != \"data.frame\")\n# keep only list elements where ct_blood column mean is over 25\ncombined %>% \n  discard(.p = ~mean(.x$ct_blood) > 25)  \n# Remove all empty list elements\ncombined %>% \n  compact()"},{"path":"iteration-loops-and-lists.html","id":"pmap","chapter":"16 Iteration, loops, and lists","heading":"pmap()","text":"SECTION CONSTRUCTION","code":""},{"path":"iteration-loops-and-lists.html","id":"apply-functions","chapter":"16 Iteration, loops, and lists","heading":"16.4 Apply functions","text":"“apply” family functions base R alternative purrr iterative operations. can read .","code":""},{"path":"iteration-loops-and-lists.html","id":"resources-9","chapter":"16 Iteration, loops, and lists","heading":"16.5 Resources","text":"loops Data CarpentryThe R Data Science page iterationVignette write/read Excel filesA purrr tutorial jennybcAnother purrr tutorial Rebecca BarterA purrr tutorial map, pmap, imappurrr cheatsheetpurrr tips trickskeep discard","code":""},{"path":"descriptive-tables.html","id":"descriptive-tables","chapter":"17 Descriptive tables","heading":"17 Descriptive tables","text":"page demonstrates use janitor, dplyr, gtsummary, rstatix, base R summarise data create tables descriptive statistics.page covers create* underlying tables, whereas Tables presentation page covers nicely format print .*packages advantages disadvantages areas code simplicity, accessibility outputs, quality printed outputs. Use page decide approach works scenario.several choices producing tabulation cross-tabulation summary tables. factors consider include code simplicity, customizeability, desired output (printed R console, data frame, “pretty” .png/.jpeg/.html image), ease post-processing. Consider points choose tool situation.Use tabyl() janitor produce “adorn” tabulations cross-tabulationsUse get_summary_stats() rstatix easily generate data frames numeric summary statistics multiple columns /groupsUse summarise() count() dplyr complex statistics, tidy data frame outputs, preparing data ggplot()Use tbl_summary() gtsummary produce detailed publication-ready tablesUse table() base R access packages","code":""},{"path":"descriptive-tables.html","id":"preparation-8","chapter":"17 Descriptive tables","heading":"17.1 Preparation","text":"","code":""},{"path":"descriptive-tables.html","id":"load-packages-10","chapter":"17 Descriptive tables","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics \n  gtsummary,    # summary statistics and tests\n  rstatix,      # summary statistics and statistical tests\n  janitor,      # adding totals and percents to tables\n  scales,       # easily convert proportions to percents  \n  flextable     # converting tables to pretty images\n  )"},{"path":"descriptive-tables.html","id":"import-data-10","chapter":"17 Descriptive tables","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"descriptive-tables.html","id":"browse-data","chapter":"17 Descriptive tables","heading":"17.2 Browse data","text":"","code":""},{"path":"descriptive-tables.html","id":"skimr-package","chapter":"17 Descriptive tables","heading":"skimr package","text":"using skimr package, can get detailed aesthetically pleasing overview variables dataset. Read skimr github page., function skim() applied entire linelist data frame. overview data frame summary every column (class) produced.\nTable 17.1: Data summary\nVariable type: characterVariable type: DateVariable type: factorVariable type: numericYou can also use summary() function, base R, get information entire dataset, output can difficult read using skimr. Therefore output shown , conserve page space.","code":"\n## get information about each variable in a dataset \nskim(linelist)\n## get information about each column in a dataset \nsummary(linelist)"},{"path":"descriptive-tables.html","id":"summary-statistics","chapter":"17 Descriptive tables","heading":"Summary statistics","text":"can use base R functions return summary statistics numeric column. can return useful summary statistics numeric column using summary(), . Note data frame name must also specified shown .can access save one specific part index brackets [ ]:can return individual statistics base R functions like max(), min(), median(), mean(), quantile(), sd(), range(). See R basics page complete list.CAUTION: data contain missing values, R wants know return NA unless specify mathematical functions want R ignore missing values, via argument na.rm = TRUE.can use get_summary_stats() function rstatix return summary statistics data frame format. can helpful performing subsequent operations plotting numbers. See Simple statistical tests page details rstatix package functions.","code":"\nsummary(linelist$age_years)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.02   23.00   84.00      86\nsummary(linelist$age_years)[[2]]            # return only the 2nd element## [1] 6\n# equivalent, alternative to above by element name\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \nlinelist %>% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # columns to calculate for\n    type = \"common\")                    # summary stats to return## # A tibble: 5 × 10\n##   variable     n   min   max median   iqr  mean     sd    se    ci\n##   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n## 2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n## 3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n## 4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n## 5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025"},{"path":"descriptive-tables.html","id":"tbl_janitor","chapter":"17 Descriptive tables","heading":"17.3 janitor package","text":"janitor packages offers tabyl() function produce tabulations cross-tabulations, can “adorned” modified helper functions display percents, proportions, counts, etc., pipe linelist data frame janitor functions print result. desired, can also save resulting tables assignment operator <-.","code":""},{"path":"descriptive-tables.html","id":"simple-tabyl","chapter":"17 Descriptive tables","heading":"Simple tabyl","text":"default use tabyl() specific column produces unique values, counts, column-wise “percents” (actually proportions). proportions may many digits. can adjust number decimals adorn_rounding() described .can see , missing values display row labeled <NA>. can suppress show_na = FALSE. missing values, row appear. missing values, proportions given raw (denominator inclusive NA counts) “valid” (denominator excludes NA counts).column class Factor certain levels present data, levels still appear table. can suppress feature specifying show_missing_levels = FALSE. Read Factors page.","code":"\nlinelist %>% tabyl(age_cat)##  age_cat    n     percent valid_percent\n##      0-4 1095 0.185971467   0.188728025\n##      5-9 1095 0.185971467   0.188728025\n##    10-14  941 0.159816576   0.162185453\n##    15-19  743 0.126188859   0.128059290\n##    20-29 1073 0.182235054   0.184936229\n##    30-49  754 0.128057065   0.129955188\n##    50-69   95 0.016134511   0.016373664\n##      70+    6 0.001019022   0.001034126\n##     <NA>   86 0.014605978            NA"},{"path":"descriptive-tables.html","id":"cross-tabulation","chapter":"17 Descriptive tables","heading":"Cross-tabulation","text":"Cross-tabulation counts achieved adding one additional columns within tabyl(). Note now counts returned - proportions percents can added additional steps shown .","code":"\nlinelist %>% tabyl(age_cat, gender)##  age_cat   f   m NA_\n##      0-4 640 416  39\n##      5-9 641 412  42\n##    10-14 518 383  40\n##    15-19 359 364  20\n##    20-29 468 575  30\n##    30-49 179 557  18\n##    50-69   2  91   2\n##      70+   0   5   1\n##     <NA>   0   0  86"},{"path":"descriptive-tables.html","id":"tbl_adorn","chapter":"17 Descriptive tables","heading":"“Adorning” the tabyl","text":"Use janitor’s “adorn” functions add totals convert proportions, percents, otherwise adjust display. Often, pipe tabyl several functions.conscious order apply functions. examples.simple one-way table percents instead default proportions.cross-tabulation total row row percents.cross-tabulation adjusted counts percents displayed.","code":"\nlinelist %>%               # case linelist\n  tabyl(age_cat) %>%       # tabulate counts and proportions by age category\n  adorn_pct_formatting()   # convert proportions to percents##  age_cat    n percent valid_percent\n##      0-4 1095   18.6%         18.9%\n##      5-9 1095   18.6%         18.9%\n##    10-14  941   16.0%         16.2%\n##    15-19  743   12.6%         12.8%\n##    20-29 1073   18.2%         18.5%\n##    30-49  754   12.8%         13.0%\n##    50-69   95    1.6%          1.6%\n##      70+    6    0.1%          0.1%\n##     <NA>   86    1.5%             -\nlinelist %>%                                  \n  tabyl(age_cat, gender) %>%                  # counts by age and gender\n  adorn_totals(where = \"row\") %>%             # add total row\n  adorn_percentages(denominator = \"row\") %>%  # convert counts to proportions\n  adorn_pct_formatting(digits = 1)            # convert proportions to percents##  age_cat     f     m    NA_\n##      0-4 58.4% 38.0%   3.6%\n##      5-9 58.5% 37.6%   3.8%\n##    10-14 55.0% 40.7%   4.3%\n##    15-19 48.3% 49.0%   2.7%\n##    20-29 43.6% 53.6%   2.8%\n##    30-49 23.7% 73.9%   2.4%\n##    50-69  2.1% 95.8%   2.1%\n##      70+  0.0% 83.3%  16.7%\n##     <NA>  0.0%  0.0% 100.0%\n##    Total 47.7% 47.6%   4.7%\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions\n  adorn_pct_formatting() %>%                  # convert to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                       Gender                            \n##  Age Category              f              m          NA_\n##           0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n##           5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n##         10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n##         15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n##         20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n##         30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n##         50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n##           70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n##          <NA>     0   (0.0%)     0   (0.0%)  86  (30.9%)\n##         Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)"},{"path":"descriptive-tables.html","id":"printing-the-tabyl","chapter":"17 Descriptive tables","heading":"Printing the tabyl","text":"default, tabyl print raw R console.Alternatively, can pass tabyl flextable similar package print “pretty” image RStudio Viewer, exported .png, .jpeg, .html, etc. discussed page Tables presentation. Note printing manner using adorn_titles(), must specify placement = \"combined\".Age Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1,095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1,095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%)941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%)743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1,073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%)754 (12.8%)50-692  (0.1%)91  (3.2%)2  (0.7%)95  (1.6%)70+0  (0.0%)5  (0.2%)1  (0.4%)6  (0.1%)0  (0.0%)0  (0.0%)86 (30.9%)86  (1.5%)","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% # this is necessary to print as image\n  flextable::flextable() %>%    # convert to pretty image\n  flextable::autofit()          # format to one line per row "},{"path":"descriptive-tables.html","id":"use-on-other-tables","chapter":"17 Descriptive tables","heading":"Use on other tables","text":"can use janitor’s adorn_*() functions tables, created summarise() count() dplyr, table() base R. Simply pipe table desired janitor function. example:","code":"\nlinelist %>% \n  count(hospital) %>%   # dplyr function\n  adorn_totals()        # janitor function##                              hospital    n\n##                      Central Hospital  454\n##                     Military Hospital  896\n##                               Missing 1469\n##                                 Other  885\n##                         Port Hospital 1762\n##  St. Mark's Maternity Hospital (SMMH)  422\n##                                 Total 5888"},{"path":"descriptive-tables.html","id":"saving-the-tabyl","chapter":"17 Descriptive tables","heading":"Saving the tabyl","text":"convert table “pretty” image package like flextable, can save functions package - like save_as_html(), save_as_word(), save_as_ppt(), save_as_image() flextable (discussed extensively Tables presentation page). , table saved Word document, can hand-edited.","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% \n  flextable::flextable() %>%                     # convert to image\n  flextable::autofit() %>%                       # ensure only one line per row\n  flextable::save_as_docx(path = \"tabyl.docx\")   # save as Word document to filepath"},{"path":"descriptive-tables.html","id":"janitor_age_out_stats","chapter":"17 Descriptive tables","heading":"Statistics","text":"can apply statistical tests tabyls, like chisq.test() fisher.test() stats package, shown . Note missing values allowed excluded tabyl show_na = FALSE.See page Simple statistical tests code tips statistics.","code":"\nage_by_outcome <- linelist %>% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)## \n##  Pearson's Chi-squared test\n## \n## data:  age_by_outcome\n## X-squared = 6.4931, df = 7, p-value = 0.4835"},{"path":"descriptive-tables.html","id":"other-tips","chapter":"17 Descriptive tables","heading":"Other tips","text":"Include argument na.rm = TRUE exclude missing values calculations.applying adorn_*() helper functions tables created tabyl(), can specify particular column(s) apply like adorn_percentage(,,,c(cases,deaths)) (specify 4th unnamed argument). syntax simple. Consider using summarise() instead.can read detail janitor page tabyl vignette.","code":""},{"path":"descriptive-tables.html","id":"dplyr-package","chapter":"17 Descriptive tables","heading":"17.4 dplyr package","text":"dplyr part tidyverse packages common data management tool. Creating tables dplyr functions summarise() count() useful approach calculating summary statistics, summarize group, pass tables ggplot().summarise() creates new, summary data frame. data ungrouped, return one-row dataframe specified summary statistics entire data frame. data grouped, new data frame one row per group (see Grouping data page).Within summarise() parentheses, provide names new summary column followed equals sign statistical function apply.TIP: summarise function works UK US spelling (summarise() summarize()).","code":""},{"path":"descriptive-tables.html","id":"get-counts","chapter":"17 Descriptive tables","heading":"Get counts","text":"simple function apply within summarise() n(). Leave parentheses empty count number rows.gets interesting grouped data beforehand.command can shortened using count() function instead. count() following:Groups data columns provided itSummarises n() (creating column n)Un-groups dataYou can change name counts column default n something else specifying name =.Tabulating counts two grouping columns still returned “long” format, counts n column. See page Pivoting data learn “long” “wide” data formats.","code":"\nlinelist %>%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows##   n_rows\n## 1   5888\nlinelist %>% \n  group_by(age_cat) %>%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*## # A tibble: 9 × 2\n##   age_cat n_rows\n##   <fct>    <int>\n## 1 0-4       1095\n## 2 5-9       1095\n## 3 10-14      941\n## 4 15-19      743\n## 5 20-29     1073\n## 6 30-49      754\n## 7 50-69       95\n## 8 70+          6\n## 9 <NA>        86\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\nlinelist %>% \n  count(age_cat, outcome)##    age_cat outcome   n\n## 1      0-4   Death 471\n## 2      0-4 Recover 364\n## 3      0-4    <NA> 260\n## 4      5-9   Death 476\n## 5      5-9 Recover 391\n## 6      5-9    <NA> 228\n## 7    10-14   Death 438\n## 8    10-14 Recover 303\n## 9    10-14    <NA> 200\n## 10   15-19   Death 323\n## 11   15-19 Recover 251\n## 12   15-19    <NA> 169\n## 13   20-29   Death 477\n## 14   20-29 Recover 367\n## 15   20-29    <NA> 229\n## 16   30-49   Death 329\n## 17   30-49 Recover 238\n## 18   30-49    <NA> 187\n## 19   50-69   Death  33\n## 20   50-69 Recover  38\n## 21   50-69    <NA>  24\n## 22     70+   Death   3\n## 23     70+ Recover   3\n## 24    <NA>   Death  32\n## 25    <NA> Recover  28\n## 26    <NA>    <NA>  26"},{"path":"descriptive-tables.html","id":"show-all-levels","chapter":"17 Descriptive tables","heading":"Show all levels","text":"tabling column class factor can ensure levels shown (just levels values data) adding .drop = FALSE summarise() count() command.technique useful standardise tables/plots. example creating figures multiple sub-groups, repeatedly creating figure routine reports. circumstances, presence values data may fluctuate, can define levels remain constant.See page Factors information.","code":""},{"path":"descriptive-tables.html","id":"tbl_dplyr_prop","chapter":"17 Descriptive tables","heading":"Proportions","text":"Proportions can added piping table mutate() create new column. Define new column counts column (n default) divided sum() counts column (return proportion).Note case, sum() mutate() command return sum whole column n use proportion denominator. explained Grouping data page, sum() used grouped data (e.g. mutate() immediately followed group_by() command), return sums group. stated just , count() finishes actions ungrouping. Thus, scenario get full column proportions.easily display percents, can wrap proportion function percent() package scales (note convert class character).method calculate proportions within groups. relies different levels data grouping selectively applied removed. First, data grouped outcome via group_by(). , count() applied. function groups data age_cat returns counts outcome-age-cat combination. Importantly - finishes process, count() also ungroups age_cat grouping, remaining data grouping original grouping outcome. Thus, final step calculating proportions (denominator sum(n)) still grouped outcome.","code":"\nage_summary <- linelist %>% \n  count(age_cat) %>%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # create percent of column - note the denominator\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary##   age_cat    n percent\n## 1     0-4 1095  18.60%\n## 2     5-9 1095  18.60%\n## 3   10-14  941  15.98%\n## 4   15-19  743  12.62%\n## 5   20-29 1073  18.22%\n## 6   30-49  754  12.81%\n## 7   50-69   95   1.61%\n## 8     70+    6   0.10%\n## 9    <NA>   86   1.46%\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group"},{"path":"descriptive-tables.html","id":"plotting","chapter":"17 Descriptive tables","heading":"Plotting","text":"display “long” table output like ggplot() relatively straight-forward. data naturally “long” format, naturally accepted ggplot(). See examples pages ggplot basics ggplot tips.","code":"\nlinelist %>%                      # begin with linelist\n  count(age_cat, outcome) %>%     # group and tabulate counts by two columns\n  ggplot()+                       # pass new data frame to ggplot\n    geom_col(                     # create bar plot\n      mapping = aes(   \n        x = outcome,              # map outcome to x-axis\n        fill = age_cat,           # map age_cat to the fill\n        y = n))                   # map the counts column `n` to the height"},{"path":"descriptive-tables.html","id":"summary-statistics-1","chapter":"17 Descriptive tables","heading":"Summary statistics","text":"One major advantage dplyr summarise() ability return advanced statistical summaries like median(), mean(), max(), min(), sd() (standard deviation), percentiles. can also use sum() return number rows meet certain logical criteria. , outputs can produced whole data frame set, group.syntax - within summarise() parentheses provide names new summary column followed equals sign statistical function apply. Within statistical function, give column(s) operated relevant arguments (e.g. na.rm = TRUE mathematical functions).can also use sum() return number rows meet logical criteria. expression within counted evaluates TRUE. example:sum(age_years < 18, na.rm=T)sum(gender == \"male\", na.rm=T)sum(response %% c(\"Likely\", \"Likely\")), linelist data summarised describe days delay symptom onset hospital admission (column days_onset_hosp), hospital.tips:Use sum() logic statement “count” rows meet certain criteria (==)Note use na.rm = TRUE within mathematical functions like sum(), otherwise NA returned missing valuesUse function percent() scales package easily convert percents\nSet accuracy = 0.1 0.01 ensure 1 2 decimal places respectively\nSet accuracy = 0.1 0.01 ensure 1 2 decimal places respectivelyUse round() base R specify decimalsTo calculate statistics entire dataset, use summarise() without group_by()may create columns purposes later calculations (e.g. denominators) eventually drop data frame select().","code":"\nsummary_table <- linelist %>%                                        # begin with linelist, save out as new object\n  group_by(hospital) %>%                                             # group all calculations by hospital\n  summarise(                                                         # only the below summary columns will be returned\n    cases       = n(),                                                # number of rows per group\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_onset_hosp >= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convert previously-defined delay column to percent \n  )\n\nsummary_table  # print## # A tibble: 6 × 7\n##   hospital                             cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n##   <chr>                                <int>     <dbl>      <dbl>    <dbl>   <int> <chr>      \n## 1 Central Hospital                       454        12        1.9      1.9     108 24%        \n## 2 Military Hospital                      896        15        2.1      2.4     253 28%        \n## 3 Missing                               1469        22        2.1      2.3     399 27%        \n## 4 Other                                  885        18        2        2.2     234 26%        \n## 5 Port Hospital                         1762        16        2.1      2.2     470 27%        \n## 6 St. Mark's Maternity Hospital (SMMH)   422        18        2.1      2.3     116 27%"},{"path":"descriptive-tables.html","id":"conditional-statistics","chapter":"17 Descriptive tables","heading":"Conditional statistics","text":"may want return conditional statistics - e.g. maximum rows meet certain criteria. can done subsetting column brackets [ ]. example returns maximum temperature patients classified fever. aware however - may appropriate add another column group_by() command pivot_wider() (demonstrated ).","code":"\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )## # A tibble: 6 × 3\n##   hospital                             max_temp_fvr max_temp_no\n##   <chr>                                       <dbl>       <dbl>\n## 1 Central Hospital                             40.4        38  \n## 2 Military Hospital                            40.5        38  \n## 3 Missing                                      40.6        38  \n## 4 Other                                        40.8        37.9\n## 5 Port Hospital                                40.6        38  \n## 6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9"},{"path":"descriptive-tables.html","id":"glueing-together","chapter":"17 Descriptive tables","heading":"Glueing together","text":"function str_glue() stringr useful combine values several columns one new column. context typically used summarise() command.Characters strings page, various options combining columns discussed, including unite(), paste0(). use case, advocate str_glue() flexible unite() simple syntax paste0()., summary_table data frame (created ) mutated columns delay_mean delay_sd combined, parentheses formating added new column, respective old columns removed., make table presentable, total row added adorn_totals() janitor (ignores non-numeric columns). Lastly, use select() dplyr re-order rename nicer column names.Now pass flextable print table Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc.! (see Tables presentation page).","code":"\nsummary_table %>% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %>%  # combine and format other values\n  select(-c(delay_mean, delay_sd)) %>%                       # remove two old columns   \n  adorn_totals(where = \"row\") %>%                            # add total row\n  select(                                                    # order and rename cols\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )##                         Hospital Name Cases Max delay Mean (sd) Delay 3+ days % delay 3+ days\n##                      Central Hospital   454        12 1.9 (1.9)           108             24%\n##                     Military Hospital   896        15 2.1 (2.4)           253             28%\n##                               Missing  1469        22 2.1 (2.3)           399             27%\n##                                 Other   885        18   2 (2.2)           234             26%\n##                         Port Hospital  1762        16 2.1 (2.2)           470             27%\n##  St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116             27%\n##                                 Total  5888       101         -          1580               -"},{"path":"descriptive-tables.html","id":"percentiles","chapter":"17 Descriptive tables","heading":"Percentiles","text":"Percentiles quantiles dplyr deserve special mention. return quantiles, use quantile() defaults specify value(s) like probs =.want return quantiles group, may encounter long less useful outputs simply add another column group_by(). , try approach instead - create column quantile level desired.dplyr summarise() certainly offers fine control, may find summary statistics need can produced get_summary_stat() rstatix package. operating grouped data, return 0%, 25%, 50%, 75%, 100%. applied ungrouped data, can specify percentiles probs = c(.05, .5, .75, .98).","code":"\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nlinelist %>% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr 1.1.0.\n## ℹ Please use `reframe()` instead.\n## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always returns an ungrouped data frame and\n##   adjust accordingly.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.##   age_percentiles\n## 1               0\n## 2               6\n## 3              13\n## 4              23\n## 5              84\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr 1.1.0.\n## ℹ Please use `reframe()` instead.\n## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always returns an ungrouped data frame and\n##   adjust accordingly.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.##   age_percentiles\n## 1               1\n## 2              13\n## 3              23\n## 4              48\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )## # A tibble: 6 × 5\n##   hospital                               p05   p50   p75   p98\n##   <chr>                                <dbl> <dbl> <dbl> <dbl>\n## 1 Central Hospital                         1    12    21  48  \n## 2 Military Hospital                        1    13    24  45  \n## 3 Missing                                  1    13    23  48.2\n## 4 Other                                    1    13    23  50  \n## 5 Port Hospital                            1    14    24  49  \n## 6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\nlinelist %>% \n  group_by(hospital) %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## # A tibble: 6 × 8\n##   hospital                             variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <chr>                                <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 Central Hospital                     age        445     0     6    12    21     58\n## 2 Military Hospital                    age        884     0     6    14    24     72\n## 3 Missing                              age       1441     0     6    13    23     76\n## 4 Other                                age        873     0     6    13    23     69\n## 5 Port Hospital                        age       1739     0     6    14    24     68\n## 6 St. Mark's Maternity Hospital (SMMH) age        420     0     7    12    22     84\nlinelist %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## # A tibble: 1 × 7\n##   variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 age       5802     0     6    13    23     84"},{"path":"descriptive-tables.html","id":"summarise-aggregated-data","chapter":"17 Descriptive tables","heading":"Summarise aggregated data","text":"begin aggregated data, using n() return number rows, sum aggregated counts. get sums, use sum() data’s counts column.example, let’s say beginning data frame counts , called linelist_agg - shows “long” format case counts outcome gender.create example data frame linelist case counts outcome gender (missing values removed clarity).sum counts (column n) group can use summarise() set new column equal sum(n, na.rm=T). add conditional element sum operation, can use subset bracket [ ] syntax counts column.","code":"\nlinelist_agg <- linelist %>% \n  drop_na(gender, outcome) %>% \n  count(outcome, gender)\n\nlinelist_agg##   outcome gender    n\n## 1   Death      f 1227\n## 2   Death      m 1228\n## 3 Recover      f  953\n## 4 Recover      m  950\nlinelist_agg %>% \n  group_by(outcome) %>% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))## # A tibble: 2 × 4\n##   outcome total_cases male_cases female_cases\n##   <chr>         <int>      <int>        <int>\n## 1 Death          2455       1228         1227\n## 2 Recover        1903        950          953"},{"path":"descriptive-tables.html","id":"across-multiple-columns","chapter":"17 Descriptive tables","heading":"across() multiple columns","text":"can use summarise() across multiple columns using across(). makes life easier want calculate statistics many columns. Place across() within summarise() specify following:.cols = either vector column names c() “tidyselect” helper functions (explained ).fns = function perform (parentheses) - can provide multiple within list(), mean() applied several numeric columns. vector columns named explicitly .cols = single function mean specified (parentheses) .fns =. additional arguments function (e.g. na.rm=TRUE) provided .fns =, separated comma.can difficult get order parentheses commas correct using across(). Remember within across() must include columns, functions, extra arguments needed functions.Multiple functions can run . functions mean sd provided .fns = within list(). opportunity provide character names (e.g. “mean” “sd”) appended new column names.“tidyselect” helper functions can provide .cols = select columns:everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix. Example: starts_with(\"date\")ends_with() - matches specified suffix. Example: ends_with(\"_end\")contains() - columns containing character string. Example: contains(\"time\")matches() - apply regular expression (regex). Example: contains(\"[pt]al\")num_range() -any_of() - matches column named. Useful name might exist. Example: any_of(date_onset, date_death, cardiac_arrest)example, return mean every numeric column use () provide function .numeric() (without parentheses). remains within across() command.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # columns\n                   .fns = mean,                               # function\n                   na.rm=T))                                  # extra arguments## # A tibble: 3 × 5\n##   outcome age_years  temp wt_kg ht_cm\n##   <chr>       <dbl> <dbl> <dbl> <dbl>\n## 1 Death        15.9  38.6  52.6  125.\n## 2 Recover      16.1  38.6  52.5  125.\n## 3 <NA>         16.2  38.6  53.0  125.\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments## # A tibble: 3 × 9\n##   outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd ht_cm_mean ht_cm_sd\n##   <chr>            <dbl>        <dbl>     <dbl>   <dbl>      <dbl>    <dbl>      <dbl>    <dbl>\n## 1 Death             15.9         12.3      38.6   0.962       52.6     18.4       125.     48.7\n## 2 Recover           16.1         13.0      38.6   0.997       52.5     18.6       125.     50.1\n## 3 <NA>              16.2         12.8      38.6   0.976       53.0     18.9       125.     50.4\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))## # A tibble: 3 × 12\n##   outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp   bmi days_onset_hosp\n##   <chr>        <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> <dbl>           <dbl>\n## 1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6  45.6            1.84\n## 2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6  47.7            2.34\n## 3 <NA>          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6  48.3            2.07"},{"path":"descriptive-tables.html","id":"tbls_pivot_wider","chapter":"17 Descriptive tables","heading":"Pivot wider","text":"prefer table “wide” format can transform using tidyr pivot_wider() function. likely need re-name columns rename(). information see page Pivoting data.example begins “long” table age_by_outcome proportions section. create print, clarity:pivot wider, create new columns values existing column age_cat (setting names_from = age_cat). also specify new table values come existing column n, values_from = n. columns mentioned pivoting command (outcome) remain unchanged far left side.","code":"\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group\nage_by_outcome %>% \n  select(-percent) %>%   # keep only counts for simplicity\n  pivot_wider(names_from = age_cat, values_from = n)  ## # A tibble: 3 × 10\n## # Groups:   outcome [3]\n##   outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n##   <chr>   <int> <int>   <int>   <int>   <int>   <int>   <int> <int> <int>\n## 1 Death     471   476     438     323     477     329      33     3    32\n## 2 Recover   364   391     303     251     367     238      38     3    28\n## 3 <NA>      260   228     200     169     229     187      24    NA    26"},{"path":"descriptive-tables.html","id":"tbl_dplyr_totals","chapter":"17 Descriptive tables","heading":"Total rows","text":"summarise() operates grouped data automatically produce “total” statistics. , two approaches adding total row presented:","code":""},{"path":"descriptive-tables.html","id":"janitors-adorn_totals","chapter":"17 Descriptive tables","heading":"janitor’s adorn_totals()","text":"table consists counts proportions/percents can summed total, can add sum totals using janitor’s adorn_totals() described section . Note function can sum numeric columns - want calculate total summary statistics see next approach dplyr., linelist grouped gender summarised table described number cases known outcome, deaths, recovered. Piping table adorn_totals() adds total row bottom reflecting sum column. adorn_*() functions adjust display noted code.","code":"\nlinelist %>% \n  group_by(gender) %>%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Number of rows in group where outcome is not missing\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Number of rows in group where outcome is Death\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Number of rows in group where outcome is Recovered\n  ) %>% \n  adorn_totals() %>%                                # Adorn total row (sums of each numeric column)\n  adorn_percentages(\"col\") %>%                      # Get column proportions\n  adorn_pct_formatting() %>%                        # Convert proportions to percents\n  adorn_ns(position = \"front\")                      # display % and counts (with counts in front)##  gender  known_outcome        n_death      n_recover\n##       f 2,180  (47.8%) 1,227  (47.5%)   953  (48.1%)\n##       m 2,178  (47.7%) 1,228  (47.6%)   950  (47.9%)\n##    <NA>   207   (4.5%)   127   (4.9%)    80   (4.0%)\n##   Total 4,565 (100.0%) 2,582 (100.0%) 1,983 (100.0%)"},{"path":"descriptive-tables.html","id":"summarise-on-total-data-and-then-bind_rows","chapter":"17 Descriptive tables","heading":"summarise() on “total” data and then bind_rows()","text":"table consists summary statistics median(), mean(), etc, adorn_totals() approach shown sufficient. Instead, get summary statistics entire dataset must calculate separate summarise() command bind results original grouped summary table. binding can use bind_rows() dplyr s described Joining data page. example:can make summary table outcome hospital group_by() summarise() like :get totals, run summarise() command group data outcome (hospital), like :can bind two data frames together. Note by_hospital 4 columns whereas totals 3 columns. using bind_rows(), columns combined name, extra space filled NA (e.g column hospital values two new totals rows). binding rows, convert empty spaces “Total” using replace_na() (see Cleaning data core functions page).new table “Total” rows bottom.table “long” format, may want. Optionally, can pivot table wider make readable. See section pivoting wider , Pivoting data page. can also add columns, arrange nicely. code .can print nicely image - output printed flextable. can read depth example achieve “pretty” table Tables presentation page.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nby_hospital <- linelist %>% \n  filter(!is.na(outcome) & hospital != \"Missing\") %>%  # Remove cases with missing outcome or hospital\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T))               # median CT value per group\n  \nby_hospital # print table## # A tibble: 10 × 4\n## # Groups:   hospital [5]\n##    hospital                             outcome     N ct_value\n##    <chr>                                <chr>   <int>    <dbl>\n##  1 Central Hospital                     Death     193       22\n##  2 Central Hospital                     Recover   165       22\n##  3 Military Hospital                    Death     399       21\n##  4 Military Hospital                    Recover   309       22\n##  5 Other                                Death     395       22\n##  6 Other                                Recover   290       21\n##  7 Port Hospital                        Death     785       22\n##  8 Port Hospital                        Recover   579       21\n##  9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n## 10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\ntotals <- linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # These statistics are now by outcome only     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table## # A tibble: 2 × 3\n##   outcome     N ct_value\n##   <chr>   <int>    <dbl>\n## 1 Death    1971       22\n## 2 Recover  1469       22\ntable_long <- bind_rows(by_hospital, totals) %>% \n  mutate(hospital = replace_na(hospital, \"Total\"))\ntable_long %>% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                  # Arrange rows from lowest to highest (Total row at bottom)## # A tibble: 6 × 8\n## # Groups:   hospital [6]\n##   hospital                             N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death ct_value_Death\n##   <chr>                                  <int>     <int> <chr>                  <dbl>   <int> <chr>              <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH)     325       126 38.8%                     22     199 61.2%                 22\n## 2 Central Hospital                         358       165 46.1%                     22     193 53.9%                 22\n## 3 Other                                    685       290 42.3%                     21     395 57.7%                 22\n## 4 Military Hospital                        708       309 43.6%                     22     399 56.4%                 21\n## 5 Port Hospital                           1364       579 42.4%                     21     785 57.6%                 22\n## 6 Total                                   3440      1469 42.7%                     22    1971 57.3%                 22"},{"path":"descriptive-tables.html","id":"tbl_gt","chapter":"17 Descriptive tables","heading":"17.5 gtsummary package","text":"want print summary statistics pretty, publication-ready graphic, can use gtsummary package function tbl_summary(). code can seem complex first, outputs look nice print RStudio Viewer panel HTML image. Read vignette .can also add results statistical tests gtsummary tables. process described gtsummary section Simple statistical tests page.introduce tbl_summary() show basic behavior first, actually produces large beautiful table. , examine detail make adjustments tailored tables.","code":""},{"path":"descriptive-tables.html","id":"summary-table","chapter":"17 Descriptive tables","heading":"Summary table","text":"default behavior tbl_summary() quite incredible - takes columns provide creates summary table one command. function prints statistics appropriate column class: median inter-quartile range (IQR) numeric columns, counts (%) categorical columns. Missing values converted “Unknown”. Footnotes added bottom explain statistics, total N shown top.","code":"\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>%  # keep only the columns of interest\n  tbl_summary()                                                  # default"},{"path":"descriptive-tables.html","id":"adjustments","chapter":"17 Descriptive tables","heading":"Adjustments","text":"Now explain function works make adjustments. key arguments detailed :=\ncan stratify table column (e.g. outcome), creating 2-way table.statistic =\nUse equations specify statistics show display . two sides equation, separated tilde ~. right side, quotes, statistical display desired, left columns display apply.right side equation uses syntax str_glue() stringr (see Characters Strings), desired display string quotes statistics within curly brackets. can include statistics like “n” (counts), “N” (denominator), “mean”, “median”, “sd”, “max”, “min”, percentiles “p##” like “p25”, percent total “p”. See ?tbl_summary details.left side equation, can specify columns name (e.g. age c(age, gender)) using helpers all_continuous(), all_categorical(), contains(), starts_with(), etc.simple example statistic = equation might look like , print mean column age_years:slightly complex equation might look like \"({min}, {max})\", incorporating max min values within parentheses separated comma:can also differentiate syntax separate columns types columns. complex example , value provided statistc = list indicating continuous columns table print mean standard deviation parentheses, categorical columns print n, denominator, percent.digits =\nAdjust digits rounding. Optionally, can specified continuous columns ().label =\nAdjust column name displayed. Provide column name desired label separated tilde. default column name.missing_text =\nAdjust missing values displayed. default “Unknown”.type =\nused adjust many levels statistics shown. syntax similar statistic = provide equation columns left value right. Two common scenarios include:type = all_categorical() ~ \"categorical\" Forces dichotomous columns (e.g. fever yes/) show levels instead “yes” rowtype = all_continuous() ~ \"continuous2\" Allows multi-line statistics per variable, shown later sectionIn example , arguments used modify original summary table:","code":"\nlinelist %>% \n  select(age_years) %>%         # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age_years ~ \"{mean}\") # print mean of age\nlinelist %>% \n  select(age_years) %>%                       # keep only columns of interest \n  tbl_summary(                                # create summary table\n    statistic = age_years ~ \"({min}, {max})\") # print min and max of age\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>% # keep only columns of interest\n  tbl_summary(     \n    by = outcome,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # how missing values should display\n  )## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"descriptive-tables.html","id":"multi-line-stats-for-continuous-variables","chapter":"17 Descriptive tables","heading":"Multi-line stats for continuous variables","text":"want print multiple lines statistics continuous variables, can indicate setting type = “continuous2”. can combine previously shown elements one table choosing statistics want show. need tell function want get table back entering type “continuous2”. number missing values shown “Unknown”.many ways modify tables, including adding p-values, adjusting color headings, etc. Many described documentation (enter ?tbl_summary Console), given section statistical tests.","code":"\nlinelist %>% \n  select(age_years, temp) %>%                      # keep only columns of interest\n  tbl_summary(                                     # create summary table\n    type = all_continuous() ~ \"continuous2\",       # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",                   # line 2: median and IQR\n      \"{min}, {max}\")                              # line 3: min and max\n    )"},{"path":"descriptive-tables.html","id":"base-r-1","chapter":"17 Descriptive tables","heading":"17.6 base R","text":"can use function table() tabulate cross-tabulate columns. Unlike options , must specify dataframe time reference column name, shown .CAUTION: NA (missing) values tabulated unless include argument useNA = \"always\" (also set “” “ifany”).TIP: can use %$% magrittr remove need repeating data frame calls within base functions. example written linelist %$% table(outcome, useNA = \"always\") Multiple columns can cross-tabulated listing one , separated commas. Optionally, can assign column “name” like Outcome = linelist$outcome.","code":"\ntable(linelist$outcome, useNA = \"always\")## \n##   Death Recover    <NA> \n##    2582    1983    1323\nage_by_outcome <- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # save table as object\nage_by_outcome   # print table##        \n##         Death Recover <NA>\n##   0-4     471     364  260\n##   5-9     476     391  228\n##   10-14   438     303  200\n##   15-19   323     251  169\n##   20-29   477     367  229\n##   30-49   329     238  187\n##   50-69    33      38   24\n##   70+       3       3    0\n##   <NA>     32      28   26"},{"path":"descriptive-tables.html","id":"proportions","chapter":"17 Descriptive tables","heading":"Proportions","text":"return proportions, passing table function prop.table(). Use margins = argument specify whether want proportions rows (1), columns (2), whole table (3). clarity, pipe table round() function base R, specifying 2 digits.","code":"\n# get proportions of table defined above, by rows, rounded\nprop.table(age_by_outcome, 1) %>% round(2)##        \n##         Death Recover <NA>\n##   0-4    0.43    0.33 0.24\n##   5-9    0.43    0.36 0.21\n##   10-14  0.47    0.32 0.21\n##   15-19  0.43    0.34 0.23\n##   20-29  0.44    0.34 0.21\n##   30-49  0.44    0.32 0.25\n##   50-69  0.35    0.40 0.25\n##   70+    0.50    0.50 0.00\n##   <NA>   0.37    0.33 0.30"},{"path":"descriptive-tables.html","id":"totals","chapter":"17 Descriptive tables","heading":"Totals","text":"add row column totals, pass table addmargins(). works counts proportions.","code":"\naddmargins(age_by_outcome)##        \n##         Death Recover <NA>  Sum\n##   0-4     471     364  260 1095\n##   5-9     476     391  228 1095\n##   10-14   438     303  200  941\n##   15-19   323     251  169  743\n##   20-29   477     367  229 1073\n##   30-49   329     238  187  754\n##   50-69    33      38   24   95\n##   70+       3       3    0    6\n##   <NA>     32      28   26   86\n##   Sum    2582    1983 1323 5888"},{"path":"descriptive-tables.html","id":"convert-to-data-frame","chapter":"17 Descriptive tables","heading":"Convert to data frame","text":"Converting table() object directly data frame straight-forward. One approach demonstrated :Create table, without using useNA = \"always\". Instead convert NA values “(Missing)” fct_explicit_na() forcats.Add totals (optional) piping addmargins()Pipe base R function .data.frame.matrix()Pipe table tibble function rownames_to_column(), specifying name first columnPrint, View, export desired. example use flextable() package flextable described Tables presentation page. print RStudio viewer pane pretty HTML image.Age CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888","code":"\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %>% \n  addmargins() %>% \n  as.data.frame.matrix() %>% \n  tibble::rownames_to_column(var = \"Age Category\") %>% \n  flextable::flextable()"},{"path":"descriptive-tables.html","id":"resources-10","chapter":"17 Descriptive tables","heading":"17.7 Resources","text":"Much information page adapted resources vignettes online:gtsummarydplyr","code":""},{"path":"simple-statistical-tests.html","id":"simple-statistical-tests","chapter":"18 Simple statistical tests","heading":"18 Simple statistical tests","text":"page demonstrates conduct simple statistical tests using base R, rstatix, gtsummary.T-testShapiro-Wilk testWilcoxon rank sum testKruskal-Wallis testChi-squared testCorrelations numeric variables…many tests can performed, showcase just common ones link documentation.packages bring certain advantages disadvantages:Use base R functions print statistical outputs R ConsoleUse rstatix functions return results data frame, want tests run groupUse gtsummary want quickly print publication-ready tables","code":""},{"path":"simple-statistical-tests.html","id":"preparation-9","chapter":"18 Simple statistical tests","heading":"18.1 Preparation","text":"","code":""},{"path":"simple-statistical-tests.html","id":"load-packages-11","chapter":"18 Simple statistical tests","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  rstatix,      # statistics\n  corrr,        # correlation analayis for numeric variables\n  janitor,      # adding totals and percents to tables\n  flextable     # converting tables to HTML\n  )"},{"path":"simple-statistical-tests.html","id":"import-data-11","chapter":"18 Simple statistical tests","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"simple-statistical-tests.html","id":"base-r-2","chapter":"18 Simple statistical tests","heading":"18.2 base R","text":"can use base R functions conduct statistical tests. commands relatively simple results print R Console simple viewing. However, outputs usually lists harder manipulate want use results subsequent operations.","code":""},{"path":"simple-statistical-tests.html","id":"t-tests","chapter":"18 Simple statistical tests","heading":"T-tests","text":"t-test, also called “Student’s t-Test”, typically used determine significant difference means numeric variable two groups. ’ll show syntax test depending whether columns data frame.Syntax 1: syntax numeric categorical columns data frame. Provide numeric column left side equation categorical column right side. Specify dataset data =. Optionally, set paired = TRUE, conf.level = (0.95 default), alternative = (either “two.sided”, “less”, “greater”). Enter ?t.test details.Syntax 2: can compare two separate numeric vectors using alternative syntax. example, two columns different data sets.can also use t-test determine whether sample mean significantly different specific value. conduct one-sample t-test known/hypothesized population mean mu =:","code":"\n## compare mean age by outcome group with a t-test\nt.test(age_years ~ gender, data = linelist)## \n##  Welch Two Sample t-test\n## \n## data:  age_years by gender\n## t = -21.344, df = 4902.3, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.571920 -6.297975\n## sample estimates:\n## mean in group f mean in group m \n##        12.60207        19.53701\nt.test(df1$age_years, df2$age_years)\nt.test(linelist$age_years, mu = 45)"},{"path":"simple-statistical-tests.html","id":"shapiro-wilk-test","chapter":"18 Simple statistical tests","heading":"Shapiro-Wilk test","text":"Shapiro-Wilk test can used determine whether sample came normally-distributed population (assumption many tests analysis, t-test). However, can used sample 3 5000 observations. larger samples quantile-quantile plot may helpful.","code":"\nshapiro.test(linelist$age_years)"},{"path":"simple-statistical-tests.html","id":"wilcoxon-rank-sum-test","chapter":"18 Simple statistical tests","heading":"Wilcoxon rank sum test","text":"Wilcoxon rank sum test, also called Mann–Whitney U test, often used help determine two numeric samples distribution populations normally distributed unequal variance.","code":"\n## compare age distribution by outcome group with a wilcox test\nwilcox.test(age_years ~ outcome, data = linelist)## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  age_years by outcome\n## W = 2501868, p-value = 0.8308\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"simple-statistical-tests.html","id":"kruskal-wallis-test","chapter":"18 Simple statistical tests","heading":"Kruskal-Wallis test","text":"Kruskal-Wallis test extension Wilcoxon rank sum test can used test differences distribution two samples. two samples used gives identical results Wilcoxon rank sum test.","code":"\n## compare age distribution by outcome group with a kruskal-wallis test\nkruskal.test(age_years ~ outcome, linelist)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  age_years by outcome\n## Kruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308"},{"path":"simple-statistical-tests.html","id":"chi-squared-test","chapter":"18 Simple statistical tests","heading":"Chi-squared test","text":"Pearson’s Chi-squared test used testing significant differences categorical croups.","code":"\n## compare the proportions in each group with a chi-squared test\nchisq.test(linelist$gender, linelist$outcome)## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  linelist$gender and linelist$outcome\n## X-squared = 0.0011841, df = 1, p-value = 0.9725"},{"path":"simple-statistical-tests.html","id":"rstatix-package","chapter":"18 Simple statistical tests","heading":"18.3 rstatix package","text":"rstatix package offers ability run statistical tests retrieve results “pipe-friendly” framework. results automatically data frame can perform subsequent operations results. also easy group data passed functions, statistics run group.","code":""},{"path":"simple-statistical-tests.html","id":"summary-statistics-2","chapter":"18 Simple statistical tests","heading":"Summary statistics","text":"function get_summary_stats() quick way return summary statistics. Simply pipe dataset function provide columns analyse. columns specified, statistics calculated columns.default, full range summary statistics returned: n, max, min, median, 25%ile, 75%ile, IQR, median absolute deviation (mad), mean, standard deviation, standard error, confidence interval mean.can specify subset summary statistics return providing one following values type =: “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.can used grouped data well, row returned grouping-variable:can also use rstatix conduct statistical tests:","code":"\nlinelist %>%\n  rstatix::get_summary_stats(age, temp)## # A tibble: 2 × 13\n##   variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se    ci\n##   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166 0.325\n## 2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013 0.025\nlinelist %>%\n  group_by(hospital) %>%\n  rstatix::get_summary_stats(age, temp, type = \"common\")## # A tibble: 12 × 11\n##    hospital                             variable     n   min   max median   iqr  mean     sd    se    ci\n##    <chr>                                <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n##  1 Central Hospital                     age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n##  2 Central Hospital                     temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n##  3 Military Hospital                    age        884   0    72     14    18    16.1 12.4   0.417 0.818\n##  4 Military Hospital                    temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n##  5 Missing                              age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n##  6 Missing                              temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n##  7 Other                                age        873   0    69     13    17    16.0 12.5   0.422 0.828\n##  8 Other                                temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n##  9 Port Hospital                        age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n## 10 Port Hospital                        temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n## 11 St. Mark's Maternity Hospital (SMMH) age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n## 12 St. Mark's Maternity Hospital (SMMH) temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095"},{"path":"simple-statistical-tests.html","id":"t-test","chapter":"18 Simple statistical tests","heading":"T-test","text":"Use formula syntax specify numeric categorical columns:use ~ 1 specify mu = one-sample T-test. can also done group.applicable, statistical tests can done group, shown :","code":"\nlinelist %>% \n  t_test(age_years ~ gender)## # A tibble: 1 × 10\n##   .y.       group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl> <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****\nlinelist %>% \n  t_test(age_years ~ 1, mu = 30)## # A tibble: 1 × 7\n##   .y.       group1 group2         n statistic    df     p\n## * <chr>     <chr>  <chr>      <int>     <dbl> <dbl> <dbl>\n## 1 age_years 1      null model  5802     -84.2  5801     0\nlinelist %>% \n  group_by(gender) %>% \n  t_test(age_years ~ 1, mu = 18)## # A tibble: 3 × 8\n##   gender .y.       group1 group2         n statistic    df         p\n## * <chr>  <chr>     <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n## 1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n## 2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n## 3 <NA>   age_years 1      null model   192     -3.80   191 1.96e-  4"},{"path":"simple-statistical-tests.html","id":"shapiro-wilk-test-1","chapter":"18 Simple statistical tests","heading":"Shapiro-Wilk test","text":"stated , sample size must 3 5000.","code":"\nlinelist %>% \n  head(500) %>%            # first 500 rows of case linelist, for example only\n  shapiro_test(age_years)## # A tibble: 1 × 3\n##   variable  statistic        p\n##   <chr>         <dbl>    <dbl>\n## 1 age_years     0.917 6.67e-16"},{"path":"simple-statistical-tests.html","id":"wilcoxon-rank-sum-test-1","chapter":"18 Simple statistical tests","heading":"Wilcoxon rank sum test","text":"","code":"\nlinelist %>% \n  wilcox_test(age_years ~ gender)## # A tibble: 1 × 9\n##   .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****"},{"path":"simple-statistical-tests.html","id":"kruskal-wallis-test-1","chapter":"18 Simple statistical tests","heading":"Kruskal-Wallis test","text":"Also known Mann-Whitney U test.","code":"\nlinelist %>% \n  kruskal_test(age_years ~ outcome)## # A tibble: 1 × 6\n##   .y.           n statistic    df     p method        \n## * <chr>     <int>     <dbl> <int> <dbl> <chr>         \n## 1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis"},{"path":"simple-statistical-tests.html","id":"chi-squared-test-1","chapter":"18 Simple statistical tests","heading":"Chi-squared test","text":"chi-square test function accepts table, first create cross-tabulation. many ways create cross-tabulation (see Descriptive tables) use tabyl() janitor remove left-column value labels passing chisq_test().Many many functions statistical tests can run rstatix functions. See documentation rstatix online entering ?rstatix.","code":"\nlinelist %>% \n  tabyl(gender, outcome) %>% \n  select(-1) %>% \n  chisq_test()## # A tibble: 1 × 6\n##       n statistic     p    df method          p.signif\n## * <dbl>     <dbl> <dbl> <int> <chr>           <chr>   \n## 1  5888      3.53 0.473     4 Chi-square test ns"},{"path":"simple-statistical-tests.html","id":"stats_gt","chapter":"18 Simple statistical tests","heading":"18.4 gtsummary package","text":"Use gtsummary looking add results statistical test pretty table created package (described gtsummary section Descriptive tables page).Performing statistical tests comparison tbl_summary done adding \nadd_p function table specifying test use. possible get p-values corrected multiple testing using \nadd_q function. Run ?tbl_summary details.","code":""},{"path":"simple-statistical-tests.html","id":"chi-squared-test-2","chapter":"18 Simple statistical tests","heading":"Chi-squared test","text":"Compare proportions categorical variable two groups. default statistical test add_p() applied categorical variable perform chi-squared test independence continuity correction, expected call count 5 Fisher’s exact test used.","code":"\nlinelist %>% \n  select(gender, outcome) %>%    # keep variables of interest\n  tbl_summary(by = outcome) %>%  # produce summary table and specify grouping variable\n  add_p()                        # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"t-tests-1","chapter":"18 Simple statistical tests","heading":"T-tests","text":"Compare difference means continuous variable two groups.\nexample, compare mean age patient outcome.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%             # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age_years ~ \"{mean} ({sd})\", # specify what statistics to show\n    by = outcome) %>%                        # specify the grouping variable\n  add_p(age_years ~ \"t.test\")                # specify what tests to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"wilcoxon-rank-sum-test-2","chapter":"18 Simple statistical tests","heading":"Wilcoxon rank sum test","text":"Compare distribution continuous variable two groups. default\nuse Wilcoxon rank sum test median (IQR) comparing two\ngroups. However non-normally distributed data comparing multiple groups,\nKruskal-wallis test appropriate.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"kruskal-wallis-test-2","chapter":"18 Simple statistical tests","heading":"Kruskal-wallis test","text":"Compare distribution continuous variable two groups,\nregardless whether data normally distributed.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"kruskal.test\")                    # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"correlations","chapter":"18 Simple statistical tests","heading":"18.5 Correlations","text":"Correlation numeric variables can investigated using tidyversecorrr package. allows compute correlations using Pearson, Kendall\ntau Spearman rho. package creates table also function \nautomatically plot values.","code":"\ncorrelation_tab <- linelist %>% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %>%   # keep numeric variables of interest\n  correlate()      # create correlation table (using default pearson)\n\ncorrelation_tab    # print## # A tibble: 6 × 7\n##   term            generation       age ct_blood days_onset_hosp    wt_kg    ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>    <dbl>    <dbl>\n## 1 generation        NA       -0.0222    0.179         -0.288    -0.0302  -0.00942\n## 2 age               -0.0222  NA         0.00849       -0.000635  0.833    0.877  \n## 3 ct_blood           0.179    0.00849  NA             -0.600    -0.00636  0.0181 \n## 4 days_onset_hosp   -0.288   -0.000635 -0.600         NA         0.0153  -0.00953\n## 5 wt_kg             -0.0302   0.833    -0.00636        0.0153   NA        0.884  \n## 6 ht_cm             -0.00942  0.877     0.0181        -0.00953   0.884   NA\n## remove duplicate entries (the table above is mirrored) \ncorrelation_tab <- correlation_tab %>% \n  shave()\n\n## view correlation table \ncorrelation_tab## # A tibble: 6 × 7\n##   term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>  <dbl> <dbl>\n## 1 generation        NA       NA        NA              NA       NA        NA\n## 2 age               -0.0222  NA        NA              NA       NA        NA\n## 3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n## 4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n## 5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n## 6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n## plot correlations \nrplot(correlation_tab)"},{"path":"simple-statistical-tests.html","id":"resources-11","chapter":"18 Simple statistical tests","heading":"18.6 Resources","text":"Much information page adapted resources vignettes online:gtsummary\ndplyr\ncorrr\nsthda correlation","code":""},{"path":"univariate-and-multivariable-regression.html","id":"univariate-and-multivariable-regression","chapter":"19 Univariate and multivariable regression","heading":"19 Univariate and multivariable regression","text":"page demonstrates use base R regression functions glm() gtsummary package \nlook associations variables (e.g. odds ratios, risk ratios hazard\nratios). also uses functions like tidy() broom package clean-regression outputs.Univariate: two--two tablesStratified: mantel-haenszel estimatesMultivariable: variable selection, model selection, final tableForest plotsFor Cox proportional hazard regression, see Survival analysis page.NOTE: use term multivariable refer regression multiple explanatory variables. sense multivariate model regression several outcomes - see editorial detail ","code":""},{"path":"univariate-and-multivariable-regression.html","id":"preparation-10","chapter":"19 Univariate and multivariable regression","heading":"19.1 Preparation","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"load-packages-12","chapter":"19 Univariate and multivariable regression","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse,    # data management + ggplot2 graphics, \n  stringr,      # manipulate text strings \n  purrr,        # loop over objects in a tidy way\n  gtsummary,    # summary statistics and tests \n  broom,        # tidy up results from regressions\n  lmtest,       # likelihood-ratio tests\n  parameters,   # alternative to tidy up results from regressions\n  see          # alternative to visualise forest plots\n  )"},{"path":"univariate-and-multivariable-regression.html","id":"import-data-12","chapter":"19 Univariate and multivariable regression","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"univariate-and-multivariable-regression.html","id":"clean-data","chapter":"19 Univariate and multivariable regression","heading":"Clean data","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"store-explanatory-variables","chapter":"19 Univariate and multivariable regression","heading":"Store explanatory variables","text":"store names explanatory columns character vector. referenced later.","code":"\n## define variables of interest \nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")"},{"path":"univariate-and-multivariable-regression.html","id":"convert-to-1s-and-0s","chapter":"19 Univariate and multivariable regression","heading":"Convert to 1’s and 0’s","text":"convert explanatory columns “yes”/“”, “m”/“f”, “dead”/“alive” 1 / 0, cooperate expectations logistic regression models. efficiently, used across() dplyr transform multiple columns one time. function apply column case_when() (also dplyr) applies logic convert specified values 1’s 0’s. See sections across() case_when() Cleaning data core functions page).Note: “.” represents column processed across() moment.","code":"\n## convert dichotomous variables to 0/1 \nlinelist <- linelist %>%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## for each column listed and \"outcome\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recode male, yes and death to 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0,           ## female, no and recover to 0\n      TRUE                            ~ NA_real_)    ## otherwise set to missing\n    )\n  )"},{"path":"univariate-and-multivariable-regression.html","id":"drop-rows-with-missing-values","chapter":"19 Univariate and multivariable regression","heading":"Drop rows with missing values","text":"drop rows missing values, can use tidyr function drop_na(). However, want rows missing values columns interest.first thing must make sure explanatory_vars vector includes column age (age produced error previous case_when() operation, dichotomous variables). pipe linelist drop_na() remove rows missing values outcome column explanatory_vars columns.running code, number rows linelist nrow(linelist).number rows remaining linelist nrow(linelist).","code":"\n## add in age_category to the explanatory vars \nexplanatory_vars <- c(explanatory_vars, \"age_cat\")\n\n## drop rows with missing information for variables of interest \nlinelist <- linelist %>% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))"},{"path":"univariate-and-multivariable-regression.html","id":"univariate","chapter":"19 Univariate and multivariable regression","heading":"19.2 Univariate","text":"Just like page Descriptive tables, use case determine R package use. present two options univariate analysis:Use functions available base R quickly print results console. Use broom package tidy outputs.Use gtsummary package model get publication-ready outputs","code":""},{"path":"univariate-and-multivariable-regression.html","id":"base-r-3","chapter":"19 Univariate and multivariable regression","heading":"base R","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"linear-regression","chapter":"19 Univariate and multivariable regression","heading":"Linear regression","text":"base R function lm() perform linear regression, assessing relationship numeric response explanatory variables assumed linear relationship.Provide equation formula, response explanatory column names separated tilde ~. Also, specify dataset data =. Define model results R object, use later.can run summary() model results see coefficients (Estimates), P-value, residuals, measures.Alternatively can use tidy() function broom package pull\nresults table. results tell us year increase age height increases\n3.5 cm statistically significant.can also use regression add ggplot, \nfirst pull points observed data fitted line one data frame\nusing augment() function broom.also possible add simple linear regression straight straight ggplot\nusing geom_smooth() function.See Resource section end chapter detailed tutorials.","code":"\nlm_results <- lm(ht_cm ~ age, data = linelist)\nsummary(lm_results)## \n## Call:\n## lm(formula = ht_cm ~ age, data = linelist)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -128.579  -15.854    1.177   15.887  175.483 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  69.9051     0.5979   116.9   <2e-16 ***\n## age           3.4354     0.0293   117.2   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 23.75 on 4165 degrees of freedom\n## Multiple R-squared:  0.7675, Adjusted R-squared:  0.7674 \n## F-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: < 2.2e-16\ntidy(lm_results)## # A tibble: 2 × 5\n##   term        estimate std.error statistic p.value\n##   <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n## 1 (Intercept)    69.9     0.598       117.       0\n## 2 age             3.44    0.0293      117.       0\n## pull the regression points and observed data in to one dataset\npoints <- augment(lm_results)\n\n## plot the data using age as the x-axis \nggplot(points, aes(x = age)) + \n  ## add points for height \n  geom_point(aes(y = ht_cm)) + \n  ## add your regression line \n  geom_line(aes(y = .fitted), colour = \"red\")\n## add your data to a plot \n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## show points\n  geom_point() + \n  ## add a linear regression \n  geom_smooth(method = \"lm\", se = FALSE)## `geom_smooth()` using formula = 'y ~ x'"},{"path":"univariate-and-multivariable-regression.html","id":"logistic-regression","chapter":"19 Univariate and multivariable regression","heading":"Logistic regression","text":"function glm() stats package (part base R) used fit Generalized Linear Models (GLM).glm() can used univariate multivariable logistic regression (e.g. get Odds Ratios). core parts:formula = model provided glm() equation, outcome left explanatory variables right tilde ~.family = determines type model run. logistic regression, use family = \"binomial\", poisson use family = \"poisson\". examples table .data = Specify data frameIf necessary, can also specify link function via syntax family = familytype(link = \"linkfunction\")). can read documentation families optional arguments weights = subset = (?glm).running glm() common save results named R object. can print results console using summary() shown , perform operations results (e.g. exponentiate).need run negative binomial regression can use MASS package; glm.nb() uses syntax glm().\nwalk-different regressions, see UCLA stats page.","code":"\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)"},{"path":"univariate-and-multivariable-regression.html","id":"univariate-glm","chapter":"19 Univariate and multivariable regression","heading":"Univariate glm()","text":"example assessing association different age categories outcome death (coded 1 Preparation section). univariate model outcome age_cat. save model output model print summary() console. Note estimates provided log odds baseline level first factor level age_cat (“0-4”).alter baseline level given variable, ensure column class Factor move desired level first position fct_relevel() (see page Factors). example, take column age_cat set “20-29” baseline piping modified data frame glm().","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)   \n## (Intercept)   0.233738   0.072805   3.210  0.00133 **\n## age_cat5-9   -0.062898   0.101733  -0.618  0.53640   \n## age_cat10-14  0.138204   0.107186   1.289  0.19726   \n## age_cat15-19 -0.005565   0.113343  -0.049  0.96084   \n## age_cat20-29  0.027511   0.102133   0.269  0.78765   \n## age_cat30-49  0.063764   0.113771   0.560  0.57517   \n## age_cat50-69 -0.387889   0.259240  -1.496  0.13459   \n## age_cat70+   -0.639203   0.915770  -0.698  0.48518   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4\nlinelist %>% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %>% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %>% \n  summary()## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)   0.26125    0.07163   3.647 0.000265 ***\n## age_cat0-4   -0.02751    0.10213  -0.269 0.787652    \n## age_cat5-9   -0.09041    0.10090  -0.896 0.370220    \n## age_cat10-14  0.11069    0.10639   1.040 0.298133    \n## age_cat15-19 -0.03308    0.11259  -0.294 0.768934    \n## age_cat30-49  0.03625    0.11302   0.321 0.748390    \n## age_cat50-69 -0.41540    0.25891  -1.604 0.108625    \n## age_cat70+   -0.66671    0.91568  -0.728 0.466546    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4"},{"path":"univariate-and-multivariable-regression.html","id":"printing-results","chapter":"19 Univariate and multivariable regression","heading":"Printing results","text":"uses, several modifications must made outputs. function tidy() package broom convenient making model results presentable.demonstrate combine model outputs table counts.Get exponentiated log odds ratio estimates confidence intervals passing model tidy() setting exponentiate = TRUE conf.int = TRUE.outputted tibble model:Combine model results table counts. , create counts cross-table tabyl() function janitor, covered Descriptive tables page.counts_table data frame looks like:Now can bind counts_table model results together horizontally bind_cols() (dplyr). Remember bind_cols() rows two data frames must aligned perfectly. code, binding within pipe chain, use . represent piped object counts_table bind model. finish process, use select() pick desired columns order, finally apply base R round() function across numeric columns specify 2 decimal places.combined data frame looks like, printed nicely image function flextable. Tables presentation explains customize tables flextable, can use numerous packages knitr GT.","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # exponentiate and produce CIs\n  mutate(across(where(is.numeric), round, digits = 2))  # round all numeric columns\ncounts_table <- linelist %>% \n  janitor::tabyl(age_cat, outcome)\ncombined <- counts_table %>%           # begin with table of counts\n  bind_cols(., model) %>%              # combine with the outputs of the regression \n  select(term, 2:3, estimate,          # select and re-order cols\n         conf.low, conf.high, p.value) %>% \n  mutate(across(where(is.numeric), round, digits = 2)) ## round to 2 decimal places\ncombined <- combined %>% \n  flextable::qflextable()"},{"path":"univariate-and-multivariable-regression.html","id":"looping-multiple-univariate-models","chapter":"19 Univariate and multivariable regression","heading":"Looping multiple univariate models","text":"present method using glm() tidy() simple approach, see section gtsummary.run models several exposure variables produce univariate odds ratios (.e. controlling ), can use approach . uses str_c() stringr create univariate formulas (see Characters strings), runs glm() regression formula, passes glm() output tidy() finally collapses model outputs together bind_rows() tidyr. approach uses map() package purrr iterate - see page Iteration, loops, lists information tool.Create vector column names explanatory variables. already explanatory_vars Preparation section page.Create vector column names explanatory variables. already explanatory_vars Preparation section page.Use str_c() create multiple string formulas, outcome left, column name explanatory_vars right. period . substitutes column name explanatory_vars.Use str_c() create multiple string formulas, outcome left, column name explanatory_vars right. period . substitutes column name explanatory_vars.Pass string formulas map() set ~glm() function apply input. Within glm(), set regression formula .formula(.x) .x replaced string formula defined step . map() loop string formulas, running regressions one.Pass string formulas map() set ~glm() function apply input. Within glm(), set regression formula .formula(.x) .x replaced string formula defined step . map() loop string formulas, running regressions one.outputs first map() passed second map() command, applies tidy() regression outputs.outputs first map() passed second map() command, applies tidy() regression outputs.Finally output second map() (list tidied data frames) condensed bind_rows(), resulting one data frame univariate results.Finally output second map() (list tidied data frames) condensed bind_rows(), resulting one data frame univariate results.time, end object models longer now represents combined results several univariate regressions. Click see rows model., can create counts table linelist explanatory variable, bind models, make nice table. begin variables, iterate map(). iterate user-defined function involves creating counts table dplyr functions. results combined bound models model results.data frame looks like. See page Tables presentation ideas convert table pretty HTML output (e.g. flextable).","code":"\nexplanatory_vars %>% str_c(\"outcome ~ \", .)## [1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\"  \"outcome ~ cough\"   \"outcome ~ aches\"   \"outcome ~ vomit\"  \n## [7] \"outcome ~ age_cat\"\nmodels <- explanatory_vars %>%       # begin with variables of interest\n  str_c(\"outcome ~ \", .) %>%         # combine each variable into formula (\"outcome ~ variable of interest\")\n  \n  # iterate through each univariate formula\n  map(                               \n    .f = ~glm(                       # pass the formulas one-by-one to glm()\n      formula = as.formula(.x),      # within glm(), the string formula is .x\n      family = \"binomial\",           # specify type of glm (logistic)\n      data = linelist)) %>%          # dataset\n  \n  # tidy up each of the glm regression outputs from above\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiate \n      conf.int = TRUE)) %>%          # return confidence intervals\n  \n  # collapse the list of regression outputs in to one data frame\n  bind_rows() %>% \n  \n  # round all numeric columns\n  mutate(across(where(is.numeric), round, digits = 2))\n## for each explanatory variable\nuniv_tab_base <- explanatory_vars %>% \n  map(.f = \n    ~{linelist %>%                ## begin with linelist\n        group_by(outcome) %>%     ## group data set by outcome\n        count(.data[[.x]]) %>%    ## produce counts for variable of interest\n        pivot_wider(              ## spread to wide format (as in cross-tabulation)\n          names_from = outcome,\n          values_from = n) %>% \n        drop_na(.data[[.x]]) %>%         ## drop rows with missings\n        rename(\"variable\" = .x) %>%      ## change variable of interest column to \"variable\"\n        mutate(variable = as.character(variable))} ## convert to character, else non-dichotomous (categorical) variables come out as factor and cant be merged\n      ) %>% \n  \n  ## collapse the list of count outputs in to one data frame\n  bind_rows() %>% \n  \n  ## merge with the outputs of the regression \n  bind_cols(., models) %>% \n  \n  ## only keep columns interested in \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% \n  \n  ## round decimal places\n  mutate(across(where(is.numeric), round, digits = 2))"},{"path":"univariate-and-multivariable-regression.html","id":"reg_gt_uni","chapter":"19 Univariate and multivariable regression","heading":"gtsummary package","text":"present use tbl_uvregression() gtsummary package. Just like page Descriptive tables, gtsummary functions good job running statistics producing professional-looking outputs. function produces table univariate regression results.select necessary columns linelist (explanatory variables outcome variable) pipe tbl_uvregression(). going run univariate regression columns defined explanatory_vars data Preparation section (gender, fever, chills, cough, aches, vomit, age_cat).Within function , provide method = glm (quotes), y = outcome column (outcome), specify method.args = want run logistic regression via family = binomial, tell exponentiate results.output HTML contains countsThere many modifications can make table output, adjusting text labels, bolding rows p-value, etc. See tutorials elsewhere online.","code":"\nuniv_tab <- linelist %>% \n  dplyr::select(explanatory_vars, outcome) %>% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = outcome,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab"},{"path":"univariate-and-multivariable-regression.html","id":"stratified","chapter":"19 Univariate and multivariable regression","heading":"19.3 Stratified","text":"Stratified analysis currently still worked gtsummary,\npage updated due course.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"multivariable","chapter":"19 Univariate and multivariable regression","heading":"19.4 Multivariable","text":"multivariable analysis, present two approaches:glm() tidy()gtsummary packageThe workflow similar last step pulling together final table different.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"conduct-multivariable","chapter":"19 Univariate and multivariable regression","heading":"Conduct multivariable","text":"use glm() add variables right side equation, separated plus symbols (+).run model explanatory variables run:want include two variables interaction can separate asterisk * instead +. Separate colon : specifying interaction. example:Optionally, can use code leverage pre-defined vector column names re-create command using str_c(). might useful explanatory variable names changing, don’t want type .","code":"\nmv_reg <- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)## \n## Call:\n## glm(formula = outcome ~ gender + fever + chills + cough + aches + \n##     vomit + age_cat, family = \"binomial\", data = linelist)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)\n## (Intercept)   0.069054   0.131726   0.524    0.600\n## gender        0.002448   0.065133   0.038    0.970\n## fever         0.004309   0.080522   0.054    0.957\n## chills        0.034112   0.078924   0.432    0.666\n## cough         0.138584   0.089909   1.541    0.123\n## aches        -0.070705   0.104078  -0.679    0.497\n## vomit         0.086098   0.062618   1.375    0.169\n## age_cat5-9   -0.063562   0.101851  -0.624    0.533\n## age_cat10-14  0.136372   0.107275   1.271    0.204\n## age_cat15-19 -0.011074   0.113640  -0.097    0.922\n## age_cat20-29  0.026552   0.102780   0.258    0.796\n## age_cat30-49  0.059569   0.116402   0.512    0.609\n## age_cat50-69 -0.388964   0.262384  -1.482    0.138\n## age_cat70+   -0.647443   0.917375  -0.706    0.480\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5700.2  on 4153  degrees of freedom\n## AIC: 5728.2\n## \n## Number of Fisher Scoring iterations: 4\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n## run a regression with all variables of interest \nmv_reg <- explanatory_vars %>%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %>%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"outcome ~ \", .) %>%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = linelist)          ## define your dataset"},{"path":"univariate-and-multivariable-regression.html","id":"building-the-model","chapter":"19 Univariate and multivariable regression","heading":"Building the model","text":"can build model step--step, saving various models include certain explanatory variables. can compare models likelihood-ratio tests using lrtest() package lmtest, :NOTE: Using base anova(model1, model2, test = \"Chisq) produces results Another option take model object apply step() function stats package. Specify variable selection direction want use building model.can also turn scientific notation R session, clarity:described section univariate analysis, pass model output tidy() exponentiate log odds CIs. Finally round numeric columns two decimal places. Scroll see rows.resulting data frame looks like:","code":"\nmodel1 <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 <- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)## Likelihood ratio test\n## \n## Model 1: outcome ~ age_cat\n## Model 2: outcome ~ age_cat + gender\n##   #Df  LogLik Df  Chisq Pr(>Chisq)\n## 1   8 -2852.6                     \n## 2   9 -2852.6  1 0.0002     0.9883\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_mv_reg <- mv_reg %>%\n  step(direction = \"forward\", trace = FALSE)\noptions(scipen=999)\nmv_tab_base <- final_mv_reg %>% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## round "},{"path":"univariate-and-multivariable-regression.html","id":"combine-univariate-and-multivariable","chapter":"19 Univariate and multivariable regression","heading":"Combine univariate and multivariable","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"combine-with-gtsummary","chapter":"19 Univariate and multivariable regression","heading":"Combine with gtsummary","text":"gtsummary package provides tbl_regression() function, \ntake outputs regression (glm() case) produce nice\nsummary table.Let’s see table:can also combine several different output tables produced gtsummary \ntbl_merge() function. now combine multivariable results gtsummary univariate results created :","code":"\n## show results table of final regression \nmv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)\nmv_tab\n## combine with univariate results \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names"},{"path":"univariate-and-multivariable-regression.html","id":"combine-with-dplyr","chapter":"19 Univariate and multivariable regression","heading":"Combine with dplyr","text":"alternative way combining glm()/tidy() univariate multivariable outputs dplyr join functions.Join univariate results earlier (univ_tab_base, contains counts) tidied multivariable results mv_tab_baseUse select() keep columns want, specify order, re-name themUse round() two decimal places column class Double","code":"\n## combine univariate and multivariable tables \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %>% \n  ## choose columns and rename them\n  select( # new name =  old name\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %>% \n  mutate(across(where(is.double), round, 2))   ## # A tibble: 20 × 11\n##    characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval mv_or mvv_ci_low mv_ci_high mv_pval\n##    <chr>              <dbl> <dbl>   <dbl>       <dbl>        <dbl>     <dbl> <dbl>      <dbl>      <dbl>   <dbl>\n##  1 (Intercept)          909  1168    1.28        1.18         1.4       0     1.07       0.83       1.39    0.6 \n##  2 gender               916  1174    1           0.88         1.13      0.97  1          0.88       1.14    0.97\n##  3 (Intercept)          340   436    1.28        1.11         1.48      0     1.07       0.83       1.39    0.6 \n##  4 fever               1485  1906    1           0.85         1.17      0.99  1          0.86       1.18    0.96\n##  5 (Intercept)         1472  1877    1.28        1.19         1.37      0     1.07       0.83       1.39    0.6 \n##  6 chills               353   465    1.03        0.89         1.21      0.68  1.03       0.89       1.21    0.67\n##  7 (Intercept)          272   309    1.14        0.97         1.34      0.13  1.07       0.83       1.39    0.6 \n##  8 cough               1553  2033    1.15        0.97         1.37      0.11  1.15       0.96       1.37    0.12\n##  9 (Intercept)         1636  2114    1.29        1.21         1.38      0     1.07       0.83       1.39    0.6 \n## 10 aches                189   228    0.93        0.76         1.14      0.51  0.93       0.76       1.14    0.5 \n## 11 (Intercept)          931  1144    1.23        1.13         1.34      0     1.07       0.83       1.39    0.6 \n## 12 vomit                894  1198    1.09        0.96         1.23      0.17  1.09       0.96       1.23    0.17\n## 13 (Intercept)          338   427    1.26        1.1          1.46      0     1.07       0.83       1.39    0.6 \n## 14 age_cat5-9           365   433    0.94        0.77         1.15      0.54  0.94       0.77       1.15    0.53\n## 15 age_cat10-14         273   396    1.15        0.93         1.42      0.2   1.15       0.93       1.41    0.2 \n## 16 age_cat15-19         238   299    0.99        0.8          1.24      0.96  0.99       0.79       1.24    0.92\n## 17 age_cat20-29         345   448    1.03        0.84         1.26      0.79  1.03       0.84       1.26    0.8 \n## 18 age_cat30-49         228   307    1.07        0.85         1.33      0.58  1.06       0.85       1.33    0.61\n## 19 age_cat50-69          35    30    0.68        0.41         1.13      0.13  0.68       0.4        1.13    0.14\n## 20 age_cat70+             3     2    0.53        0.07         3.2       0.49  0.52       0.07       3.19    0.48"},{"path":"univariate-and-multivariable-regression.html","id":"forest-plot","chapter":"19 Univariate and multivariable regression","heading":"19.5 Forest plot","text":"section shows produce plot outputs regression.\ntwo options, can build plot using ggplot2 use \nmeta-package called easystats (package includes many packages).See page ggplot basics unfamiliar ggplot2 plotting package.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"ggplot2-package","chapter":"19 Univariate and multivariable regression","heading":"ggplot2 package","text":"can build forest plot ggplot() plotting elements multivariable regression results. Add layers plots using “geoms”:estimates geom_point()confidence intervals geom_errorbar()vertical line = 1 geom_vline()plotting, may want use fct_relevel() forcats package set order variables/levels y-axis. ggplot() may display alpha-numeric order work well age category values (“30” appear “5”). See page Factors details.","code":"\n## remove the intercept term from your multivariable results\nmv_tab_base %>% \n  \n  #set order of levels to appear along y-axis\n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %>%\n  \n  # remove \"intercept\" row from plot\n  filter(term != \"(Intercept)\") %>% \n  \n  ## plot with variable on the y axis and estimate (OR) on the x axis\n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## show the estimate as a point\n  geom_point() + \n  \n  ## add in an error bar for the confidence intervals\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## show where OR = 1 is for reference as a dashed line\n  geom_vline(xintercept = 1, linetype = \"dashed\")"},{"path":"univariate-and-multivariable-regression.html","id":"easystats-packages","chapter":"19 Univariate and multivariable regression","heading":"easystats packages","text":"alternative, want fine level control ggplot2 provides, use combination easystats packages.function model_parameters() parameters package equivalent\nbroom package function tidy(). see package accepts outputs\ncreates default forest plot ggplot() object.","code":"\npacman::p_load(easystats)\n\n## remove the intercept term from your multivariable results\nfinal_mv_reg %>% \n  model_parameters(exponentiate = TRUE) %>% \n  plot()"},{"path":"univariate-and-multivariable-regression.html","id":"resources-12","chapter":"19 Univariate and multivariable regression","heading":"19.6 Resources","text":"content page informed resources vignettes online:Linear regression RgtsummaryUCLA stats pagesthda stepwise regression","code":""},{"path":"missing-data.html","id":"missing-data","chapter":"20 Missing data","heading":"20 Missing data","text":"page cover :Assess missingnessFilter rows missingnessPlot missingness timeHandle NA displayed plotsPerform missing value imputation: MCAR, MAR, MNAR","code":""},{"path":"missing-data.html","id":"preparation-11","chapter":"20 Missing data","heading":"20.1 Preparation","text":"","code":""},{"path":"missing-data.html","id":"load-packages-13","chapter":"20 Missing data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,           # import/export\n  tidyverse,     # data mgmt and viz\n  naniar,        # assess and visualize missingness\n  mice           # missing data imputation\n)"},{"path":"missing-data.html","id":"import-data-13","chapter":"20 Missing data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"missing-data.html","id":"convert-missing-on-import","chapter":"20 Missing data","heading":"Convert missing on import","text":"importing data, aware values classified missing. example, 99, 999, “Missing”, blank cells (““), cells empty space (” “). can convert NA (R’s version missing data) data import command.\nSee page importing page section Missing data details, exact syntax varies file type.","code":""},{"path":"missing-data.html","id":"missing-values-in-r","chapter":"20 Missing data","heading":"20.2 Missing values in R","text":"explore ways missingness presented assessed R, along adjacent values functions.","code":""},{"path":"missing-data.html","id":"na","chapter":"20 Missing data","heading":"NA","text":"R, missing values represented reserved (special) value - NA. Note typed without quotes. “NA” different just normal character value (also Beatles lyric song Hey Jude).data may ways representing missingness, “99”, “Missing”, “Unknown” - may even empty character value “” looks “blank”, single space ” “. aware consider whether convert NA import data cleaning na_if().data cleaning, may also want convert way - changing NA “Missing” similar replace_na() fct_explicit_na() factors.","code":""},{"path":"missing-data.html","id":"versions-of-na","chapter":"20 Missing data","heading":"Versions of NA","text":"time, NA represents missing value everything works fine. However, circumstances may encounter need variations NA specific object class (character, numeric, etc). rare, aware.\ntypical scenario creating new column dplyr function case_when(). described Cleaning data core functions page, function evaluates every row data frame, assess whether rows meets specified logical criteria (right side code), assigns correct new value (left side code). Importantly: values right side must class.want NA right side, may need specify one special NA options listed . right side values character, consider using “Missing” instead otherwise use NA_character_. numeric, use NA_real_. dates logical, can use NA.NA - use dates logical TRUE/FALSENA_character_ - use charactersNA_real_ - use numericAgain, likely encounter variations unless using case_when() create new column. See R documentation NA information.","code":"\nlinelist <- linelist %>% \n  \n  # Create new \"age_years\" column from \"age\" column\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,       # if age is given in years, assign original value\n    age_unit == \"months\" ~ age/12,    # if age is given in months, divide by 12\n    is.na(age_unit)      ~ age,       # if age UNIT is missing, assume years\n    TRUE                 ~ NA_real_)) # any other circumstance, assign missing"},{"path":"missing-data.html","id":"null","chapter":"20 Missing data","heading":"NULL","text":"NULL another reserved value R. logical representation statement neither true false. returned expressions functions whose values undefined. Generally assign NULL value, unless writing functions perhaps writing shiny app return NULL specific scenarios.Null-ness can assessed using .null() conversion can made .null().See blog post difference NULL NA.","code":""},{"path":"missing-data.html","id":"nan","chapter":"20 Missing data","heading":"NaN","text":"Impossible values represented special value NaN. example force R divide 0 0. can assess .nan(). may also encounter complementary functions including .infinite() .finite().","code":""},{"path":"missing-data.html","id":"inf","chapter":"20 Missing data","heading":"Inf","text":"Inf represents infinite value, divide number 0.example might impact work: let’s say vector/column z contains values: z <- c(1, 22, NA, Inf, NaN, 5)want use max() column find highest value, can use na.rm = TRUE remove NA calculation, Inf NaN remain Inf returned. resolve , can use brackets [ ] .finite() subset finite values used calculation: max(z[.finite(z)]).","code":"\nz <- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # returns NA\nmax(z, na.rm=T)                  # returns Inf\nmax(z[is.finite(z)])             # returns 22"},{"path":"missing-data.html","id":"examples-1","chapter":"20 Missing data","heading":"Examples","text":"“NAs introduced coercion” common warning message. can happen attempt make illegal conversion like inserting character value vector otherwise numeric.NULL ignored vector.Variance one number results NA.","code":"\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))## Warning: NAs introduced by coercion## [1] 10 20 NA 40\nmy_vector <- c(25, NA, 10, NULL)  # define\nmy_vector                         # print## [1] 25 NA 10\nvar(22)## [1] NA"},{"path":"missing-data.html","id":"useful-functions","chapter":"20 Missing data","heading":"20.3 Useful functions","text":"following useful base R functions assessing handling missing values:","code":""},{"path":"missing-data.html","id":"is.na-and-is.na","chapter":"20 Missing data","heading":"is.na() and !is.na()","text":"Use .na()identify missing values, use opposite (! front) identify non-missing values. return logical value (TRUE FALSE). Remember can sum() resulting vector count number TRUE, e.g. sum(.na(linelist$date_outcome)).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)## [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n!is.na(my_vector)## [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\nsum(is.na(my_vector))## [1] 2"},{"path":"missing-data.html","id":"na.omit","chapter":"20 Missing data","heading":"na.omit()","text":"function, applied data frame, remove rows missing values. also base R.\napplied vector, remove NA values vector applied . example:","code":"\nna.omit(my_vector)## [1]  1  4 56  5 22\n## attr(,\"na.action\")\n## [1] 4 6\n## attr(,\"class\")\n## [1] \"omit\""},{"path":"missing-data.html","id":"drop_na","chapter":"20 Missing data","heading":"drop_na()","text":"tidyr function useful data cleaning pipeline. run parentheses empty, removes rows missing values. column names specified parentheses, rows missing values columns dropped. can also use “tidyselect” syntax specify columns.","code":"\nlinelist %>% \n  drop_na(case_id, date_onset, age) # drops rows missing values for any of these columns"},{"path":"missing-data.html","id":"na.rm-true","chapter":"20 Missing data","heading":"na.rm = TRUE","text":"run mathematical function max(), min(), sum() mean(), NA values present returned value NA. default behavior intentional, alerted data missing.can avoid removing missing values calculation. , include argument na.rm = TRUE (“na.rm” stands “remove NA”).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     ## [1] NA\nmean(my_vector, na.rm = TRUE)## [1] 17.6"},{"path":"missing-data.html","id":"assess-missingness-in-a-data-frame","chapter":"20 Missing data","heading":"20.4 Assess missingness in a data frame","text":"can use package naniar assess visualize missingness data frame linelist.","code":"\n# install and/or load package\npacman::p_load(naniar)"},{"path":"missing-data.html","id":"quantifying-missingness","chapter":"20 Missing data","heading":"Quantifying missingness","text":"find percent values missing use pct_miss(). Use n_miss() get number missing values.two functions return percent rows missing value, entirely complete, respectively. Remember NA means missing, `\"\" \" \" counted missing.","code":"\n# percent of ALL data frame values that are missing\npct_miss(linelist)## [1] 6.688745\n# Percent of rows with any value missing\npct_miss_case(linelist)   # use n_complete() for counts## [1] 69.12364\n# Percent of rows that are complete (no values missing)  \npct_complete_case(linelist) # use n_complete() for counts## [1] 30.87636"},{"path":"missing-data.html","id":"visualizing-missingness","chapter":"20 Missing data","heading":"Visualizing missingness","text":"gg_miss_var() function show number (%) missing values column. nuances:can add column name (quote) argument facet = see plot groupsBy default, counts shown instead percents, change show_pct = TRUEYou can add axis title labels normal ggplot() + labs(...)data piped %>% function. facet = argument also used split data.can use vis_miss() visualize data frame heatmap, showing whether value missing . can also select() certain columns data frame provide columns function.","code":"\ngg_miss_var(linelist, show_pct = TRUE)\nlinelist %>% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n# Heatplot of missingness across the entire data frame  \nvis_miss(linelist)"},{"path":"missing-data.html","id":"explore-and-visualize-missingness-relationships","chapter":"20 Missing data","heading":"Explore and visualize missingness relationships","text":"visualize something ??? default, ggplot() removes points missing values plots.naniar offers solution via geom_miss_point(). creating scatterplot two columns, records one values missing value present shown setting missing values 10% lower lowest value column, coloring distinctly.scatterplot , red dots records value one column present value column missing. allows see distribution missing values relation non-missing values.assess missingness data frame stratified another column, consider gg_miss_fct(), returns heatmap percent missingness data frame factor/categorical (date) column:function can also used date column see missingness changed time:","code":"\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\ngg_miss_fct(linelist, age_cat5)\ngg_miss_fct(linelist, date_onset)## Warning: Removed 29 rows containing missing values (`geom_tile()`)."},{"path":"missing-data.html","id":"shadow-columns","chapter":"20 Missing data","heading":"“Shadow” columns","text":"Another way visualize missingness one column values second column using “shadow” naniar can create. bind_shadow() creates binary NA/NA column every existing column, binds new columns original dataset appendix “_NA”. doubles number columns - see :“shadow” columns can used plot proportion values missing, another column.example, plot shows proportion records missing days_onset_hosp (number days symptom onset hospitalisation), record’s value date_hospitalisation. Essentially, plotting density x-axis column, stratifying results (color =) shadow column interest. analysis works best x-axis numeric date column.can also use “shadow” columns stratify statistical summary, shown :alternative way plot proportion column’s values missing time shown . involve naniar. example shows percent weekly observations missing).Aggregate data useful time unit (days, weeks, etc.), summarizing proportion observations NA (values interest)Plot proportion missing line using ggplot(), take linelist, add new column week, group data week, calculate percent week’s records value missing. (note: want % 7 days calculation slightly different).plot proportion missing line, week. ggplot basics page unfamiliar ggplot2 plotting package.","code":"\nshadowed_linelist <- linelist %>% \n  bind_shadow()\n\nnames(shadowed_linelist)##  [1] \"case_id\"                 \"generation\"              \"date_infection\"          \"date_onset\"             \n##  [5] \"date_hospitalisation\"    \"date_outcome\"            \"outcome\"                 \"gender\"                 \n##  [9] \"age\"                     \"age_unit\"                \"age_years\"               \"age_cat\"                \n## [13] \"age_cat5\"                \"hospital\"                \"lon\"                     \"lat\"                    \n## [17] \"infector\"                \"source\"                  \"wt_kg\"                   \"ht_cm\"                  \n## [21] \"ct_blood\"                \"fever\"                   \"chills\"                  \"cough\"                  \n## [25] \"aches\"                   \"vomit\"                   \"temp\"                    \"time_admission\"         \n## [29] \"bmi\"                     \"days_onset_hosp\"         \"case_id_NA\"              \"generation_NA\"          \n## [33] \"date_infection_NA\"       \"date_onset_NA\"           \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n## [37] \"outcome_NA\"              \"gender_NA\"               \"age_NA\"                  \"age_unit_NA\"            \n## [41] \"age_years_NA\"            \"age_cat_NA\"              \"age_cat5_NA\"             \"hospital_NA\"            \n## [45] \"lon_NA\"                  \"lat_NA\"                  \"infector_NA\"             \"source_NA\"              \n## [49] \"wt_kg_NA\"                \"ht_cm_NA\"                \"ct_blood_NA\"             \"fever_NA\"               \n## [53] \"chills_NA\"               \"cough_NA\"                \"aches_NA\"                \"vomit_NA\"               \n## [57] \"temp_NA\"                 \"time_admission_NA\"       \"bmi_NA\"                  \"days_onset_hosp_NA\"\nggplot(data = shadowed_linelist,          # data frame with shadow columns\n  mapping = aes(x = date_hospitalisation, # numeric or date column\n                colour = age_years_NA)) + # shadow column of interest\n  geom_density()                          # plots the density curves\nlinelist %>%\n  bind_shadow() %>%                # create the shows cols\n  group_by(date_outcome_NA) %>%    # shadow col for stratifying\n  summarise(across(\n    .cols = age_years,             # variable of interest for calculations\n    .fns = list(\"mean\" = mean,     # stats to calculate\n                \"sd\" = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # other arguments for the stat calculations## # A tibble: 2 × 6\n##   date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min age_years_max\n##   <fct>                    <dbl>        <dbl>         <dbl>         <dbl>         <dbl>\n## 1 !NA                       16.0         12.6          158.             0            84\n## 2 NA                        16.2         12.9          167.             0            69\noutcome_missing <- linelist %>%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %>%   # create new week column\n  group_by(week) %>%                                             # group the rows by week\n  summarise(                                                     # summarize each week\n    n_obs = n(),                                                  # number of records\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),        # number of records missing the value\n    outcome_p_miss  = outcome_missing / n_obs,                    # proportion of records missing the value\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),           # number of records as dead\n    outcome_p_dead  = outcome_dead / n_obs) %>%                   # proportion of records as dead\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %>%         # pivot all columns except week, to long format for ggplot\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # keep only the proportion values\nggplot(data = outcome_missing)+\n    geom_line(\n      mapping = aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")"},{"path":"missing-data.html","id":"using-data-with-missing-values","chapter":"20 Missing data","heading":"20.5 Using data with missing values","text":"","code":""},{"path":"missing-data.html","id":"filter-out-rows-with-missing-values","chapter":"20 Missing data","heading":"Filter out rows with missing values","text":"quickly remove rows missing values, use dplyr function drop_na().original linelist nrow(linelist) rows. adjusted number rows shown :can specify drop rows missingness certain columns:can list columns one , use “tidyselect” helper functions:","code":"\nlinelist %>% \n  drop_na() %>%     # remove rows with ANY missing values\n  nrow()## [1] 1818\nlinelist %>% \n  drop_na(date_onset) %>% # remove rows missing date_onset \n  nrow()## [1] 5632\nlinelist %>% \n  drop_na(contains(\"date\")) %>% # remove rows missing values in any \"date\" column \n  nrow()## [1] 3029"},{"path":"missing-data.html","id":"handling-na-in-ggplot","chapter":"20 Missing data","heading":"Handling NA in ggplot()","text":"often wise report number values excluded plot caption. example:ggplot(), can add labs() within caption =. caption, can use str_glue() stringr package paste values together sentence dynamically adjust data. example :Note use \\n new line.Note multiple column contribute values plotted (e.g. age sex reflected plot), must filter columns well correctly calculate number shown.Sometimes, can easier save string object commands prior ggplot() command, simply reference named string object within str_glue().","code":"\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  "},{"path":"missing-data.html","id":"na-in-factors","chapter":"20 Missing data","heading":"NA in factors","text":"column interest factor, use fct_explicit_na() forcats package convert NA values character value. See detail Factors page. default, new value “(Missing)” can adjusted via na_level = argument.","code":"\npacman::p_load(forcats)   # load package\n\nlinelist <- linelist %>% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)## [1] \"f\"       \"m\"       \"Missing\""},{"path":"missing-data.html","id":"imputation","chapter":"20 Missing data","heading":"20.6 Imputation","text":"Sometimes, analyzing data, important “fill gaps” impute missing data can always simply analyze dataset removing missing values, can cause problems many ways. two examples:removing observations missing values variables large amount missing data, might reduce power ability types analysis. example, discovered earlier, small fraction observations linelist dataset missing data across variables. removed majority dataset ’d losing lot information! , variables amount missing data–analysis ’s probably reasonable drop every variable lot missing data either.removing observations missing values variables large amount missing data, might reduce power ability types analysis. example, discovered earlier, small fraction observations linelist dataset missing data across variables. removed majority dataset ’d losing lot information! , variables amount missing data–analysis ’s probably reasonable drop every variable lot missing data either.Depending data missing, analysis non-missing data might lead biased misleading results. example, learned earlier missing data patients whether ’ve important symptoms like fever cough. , one possibility, maybe information wasn’t recorded people just obviously weren’t sick. case, just removed observations ’d excluding healthiest people dataset might really bias results.Depending data missing, analysis non-missing data might lead biased misleading results. example, learned earlier missing data patients whether ’ve important symptoms like fever cough. , one possibility, maybe information wasn’t recorded people just obviously weren’t sick. case, just removed observations ’d excluding healthiest people dataset might really bias results.’s important think data might missing addition seeing much missing. can help decide important might impute missing data, also method imputing missing data might best situation.","code":""},{"path":"missing-data.html","id":"types-of-missing-data","chapter":"20 Missing data","heading":"Types of missing data","text":"three general types missing data:Missing Completely Random (MCAR). means relationship probability data missing variables data. probability missing cases rare situation. , strong reason believe data MCAR analyzing non-missing data without imputing won’t bias results (although may lose power). [TODO: consider discussing statistical tests MCAR]Missing Completely Random (MCAR). means relationship probability data missing variables data. probability missing cases rare situation. , strong reason believe data MCAR analyzing non-missing data without imputing won’t bias results (although may lose power). [TODO: consider discussing statistical tests MCAR]Missing Random (MAR). name actually bit misleading MAR means data missing systematic, predictable way based information . example, maybe every observation dataset missing value fever actually recorded every patient chills aches just assumed fever temperature never taken. true, easily predict every missing observation chills aches fever well use information impute missing data. practice, spectrum. Maybe patient chills aches likely fever well didn’t temperature taken, always. still predictable even isn’t perfectly predictable. common type missing dataMissing Random (MAR). name actually bit misleading MAR means data missing systematic, predictable way based information . example, maybe every observation dataset missing value fever actually recorded every patient chills aches just assumed fever temperature never taken. true, easily predict every missing observation chills aches fever well use information impute missing data. practice, spectrum. Maybe patient chills aches likely fever well didn’t temperature taken, always. still predictable even isn’t perfectly predictable. common type missing dataMissing Random (MNAR). Sometimes, also called Missing Random (NMAR). assumes probability value missing systematic predictable using information also isn’t missing randomly. situation data missing unknown reasons reasons don’t information . example, dataset maybe information age missing elderly patients either don’t know refuse say old . situation, missing data age related value (thus isn’t random) isn’t predictable based information . MNAR complex often best way dealing try collect data information data missing rather attempt impute .Missing Random (MNAR). Sometimes, also called Missing Random (NMAR). assumes probability value missing systematic predictable using information also isn’t missing randomly. situation data missing unknown reasons reasons don’t information . example, dataset maybe information age missing elderly patients either don’t know refuse say old . situation, missing data age related value (thus isn’t random) isn’t predictable based information . MNAR complex often best way dealing try collect data information data missing rather attempt impute .general, imputing MCAR data often fairly simple, MNAR challenging impossible. Many common data imputation methods assume MAR.","code":""},{"path":"missing-data.html","id":"useful-packages","chapter":"20 Missing data","heading":"Useful packages","text":"useful packages imputing missing data Mmisc, missForest (uses random forests impute missing data), mice (Multivariate Imputation Chained Equations). section ’ll just use mice package, implements variety techniques. maintainer mice package published online book imputing missing data goes detail (https://stefvanbuuren.name/fimd/).code load mice package:","code":"\npacman::p_load(mice)"},{"path":"missing-data.html","id":"mean-imputation","chapter":"20 Missing data","heading":"Mean Imputation","text":"Sometimes simple analysis strong reason think can assume MCAR, can simply set missing numerical values mean variable. Perhaps can assume missing temperature measurements dataset either MCAR just normal values. code create new variable replaces missing temperature values mean temperature value dataset. However, many situations replacing data mean can lead bias, careful.also similar process replacing categorical data specific value. dataset, imagine knew observations missing value outcome (can “Death” “Recover”) actually people died (note: actually true dataset):","code":"\nlinelist <- linelist %>%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\nlinelist <- linelist %>%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))"},{"path":"missing-data.html","id":"regression-imputation","chapter":"20 Missing data","heading":"Regression imputation","text":"somewhat advanced method use sort statistical model predict missing value likely replace predicted value. example creating predicted values observations temperature missing, age fever , using simple linear regression using fever status age years predictors. practice ’d want use better model sort simple approach., using modeling approach mice package create imputed values missing temperature observations:type approach advanced methods like using missForest package replace missing data predicted values. case, prediction model random forest instead linear regression. can use types models well. However, approach works well MCAR bit careful believe MAR MNAR accurately describes situation. quality imputation depend good prediction model even good model variability imputed data may underestimated.","code":"\nsimple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)\n\n#using our simple temperature model to predict values just for the observations where temp is missing\npredictions_for_missing_temps <- predict(simple_temperature_model_fit,\n                                        newdata = linelist %>% filter(is.na(temp))) \nmodel_dataset <- linelist %>%\n  select(temp, fever, age_years)  \n\ntemp_imputed <- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)## Warning: Number of logged events: 1\ntemp_imputed_values <- temp_imputed$imp$temp"},{"path":"missing-data.html","id":"locf-and-bocf","chapter":"20 Missing data","heading":"LOCF and BOCF","text":"Last observation carried forward (LOCF) baseline observation carried forward (BOCF) imputation methods time series/longitudinal data. idea take previous observed value replacement missing data. multiple values missing succession, method searches last observed value.fill() function tidyr package can used LOCF BOCF imputation (however, packages HMISC, zoo, data.table also include methods ). show fill() syntax ’ll make simple time series dataset containing number cases disease quarter years 2000 2001. However, year value subsequent quarters Q1 missing ’ll need impute . fill() junction also demonstrated Pivoting data page.Note: make sure data sorted correctly using fill() function. fill() defaults filling “” can also impute values different directions changing .direction parameter. can make similar dataset year value recorded end year missing earlier quarters:example, LOCF BOCF clearly right things , complicated situations may harder decide methods appropriate. example, may missing laboratory values hospital patient first day. Sometimes, can mean lab values didn’t change…also mean patient recovered values different first day! Use methods caution.","code":"\n#creating our simple dataset\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n#imputing the missing year values:\ndisease %>% fill(year)## # A tibble: 8 × 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197\n#creating our slightly different dataset\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n#imputing the missing year values in the \"up\" direction:\ndisease %>% fill(year, .direction = \"up\")## # A tibble: 8 × 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197"},{"path":"missing-data.html","id":"multiple-imputation","chapter":"20 Missing data","heading":"Multiple Imputation","text":"online book mentioned earlier author mice package (https://stefvanbuuren.name/fimd/) contains detailed explanation multiple imputation ’d want use . , basic explanation method:multiple imputation, create multiple datasets missing values imputed plausible data values (depending research data might want create less imputed datasets, mice package sets default number 5). difference rather single, specific value imputed value drawn estimated distribution (includes randomness). result, datasets slightly different different imputed values (however, non-missing data imputed datasets). still use sort predictive model imputation new datasets (mice many options prediction methods including Predictive Mean Matching, logistic regression, random forest) mice package can take care many modeling details., created new imputed datasets, can apply apply whatever statistical model analysis planning new imputed datasets pool results models together. works well reduce bias MCAR many MAR settings often results accurate standard error estimates.example applying Multiple Imputation process predict temperature linelist dataset using age fever status (simplified model_dataset ):used mice default method imputation, Predictive Mean Matching. used imputed datasets separately estimate pool results simple linear regressions datasets. many details ’ve glossed many settings can adjust Multiple Imputation process using mice package. example, won’t always numerical data might need use imputation methods (can still use mice package many types data methods). , robust analysis missing data significant concern, Multiple Imputation good solution isn’t always much work complete case analysis.","code":"\n# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) ## Warning: Number of logged events: 1\nmodel_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))##          term     estimate    std.error     statistic        df       p.value\n## 1 (Intercept) 3.703143e+01 0.0270863456 1367.16240465  26.83673  1.583113e-66\n## 2   age_years 3.867829e-05 0.0006090202    0.06350905 171.44363  9.494351e-01\n## 3    feveryes 1.978044e+00 0.0193587115  102.17849544 176.51325 5.666771e-159"},{"path":"missing-data.html","id":"resources-13","chapter":"20 Missing data","heading":"20.7 Resources","text":"Vignette naniar packageGallery missing value visualizationsOnline book multiple imputation R maintainer mice package","code":""},{"path":"standardised-rates.html","id":"standardised-rates","chapter":"21 Standardised rates","heading":"21 Standardised rates","text":"page show two ways standardize outcome, hospitalizations mortality, characteristics age sex.Using dsr packageUsing PHEindicatormethods packageWe begin extensively demonstrating processes data preparation/cleaning/joining, common combining population data multiple countries, standard population data, deaths, etc.","code":""},{"path":"standardised-rates.html","id":"overview-1","chapter":"21 Standardised rates","heading":"21.1 Overview","text":"two main ways standardize: direct indirect standardization.\nLet’s say like standardize mortality rate age sex country country B, compare standardized rates countries.direct standardization, know number -risk population number deaths stratum age sex, country country B. One stratum example females ages 15-44.indirect standardization, need know total number deaths age- sex structure country. option therefore feasible age- sex-specific mortality rates population numbers available. Indirect standardization furthermore preferable case small numbers per stratum, estimates direct standardization influenced substantial sampling variation.","code":""},{"path":"standardised-rates.html","id":"preparation-12","chapter":"21 Standardised rates","heading":"21.2 Preparation","text":"show standardization done, use fictitious population counts death counts country country B, age (5 year categories) sex (female, male). make datasets ready use, perform following preparation steps:Load packagesLoad datasetsJoin population death data two countriesPivot longer one row per age-sex stratumClean reference population (world standard population) join country dataIn scenario, data may come different format. Perhaps data province, city, catchment area. may one row death information age sex (significant proportion) deaths. case, see pages Grouping data, Pivoting data, Descriptive tables create dataset event population counts per age-sex stratum.also need reference population, standard population. purposes exercise use world_standard_population_by_sex. World standard population based populations 46 countries developed 1960. many “standard” populations - one example, website NHS Scotland quite informative European Standard Population, World Standard Population Scotland Standard Population.","code":""},{"path":"standardised-rates.html","id":"load-packages-14","chapter":"21 Standardised rates","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.CAUTION: newer version R, dsr package directly downloaded CRAN. However, still available CRAN archive. can install use one. non-Mac users:Mac users:","code":"\npacman::p_load(\n     rio,                 # import/export data\n     here,                # locate files\n     tidyverse,           # data management and visualization\n     stringr,             # cleaning characters and strings\n     frailtypack,         # needed for dsr, for frailty models\n     dsr,                 # standardise rates\n     PHEindicatormethods) # alternative for rate standardisation\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n# Other solution that may work\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")"},{"path":"standardised-rates.html","id":"load-population-data","chapter":"21 Standardised rates","heading":"Load population data","text":"See Download handbook data page instructions download example data handbook. can import Standardisation page data directly R Github repository running following import() commands:First load demographic data (counts males females 5-year age category) two countries comparing, “Country ” “Country B”.","code":"\n# import demographics for country A directly from Github\nA_demo <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n# import demographics for country B directly from Github\nB_demo <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n# import demographics for country B directly from Github\nstandard_pop_data <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n# Country A\nA_demo <- import(\"country_demographics.csv\")\n# Country B\nB_demo <- import(\"country_demographics_2.csv\")"},{"path":"standardised-rates.html","id":"load-death-counts","chapter":"21 Standardised rates","heading":"Load death counts","text":"Conveniently, also counts deaths time period interest, age sex. country’s counts separate file, shown .Deaths Country ADeaths Country B","code":""},{"path":"standardised-rates.html","id":"clean-populations-and-deaths","chapter":"21 Standardised rates","heading":"Clean populations and deaths","text":"need join transform data following ways:Combine country populations one dataset pivot “long” age-sex stratum one rowCombine country death counts one dataset pivot “long” age-sex stratum one rowJoin deaths populationsFirst, combine country populations datasets, pivot longer, minor cleaning. See page Pivoting data detail.combined population data now look like (click see countries B):now perform similar operations two deaths datasets.deaths data now look like , contain data countries:now join deaths population data based common columns Country, age_cat5, Sex. adds column Deaths.can now classify Sex, age_cat5, Country factors set level order using fct_relevel() function forcats package, described page Factors. Note, classifying factor levels doesn’t visibly change data, arrange() command sort Country, age category, sex.CAUTION: deaths per stratum, consider using 10-, 15-year categories, instead 5-year categories age.","code":"\npop_countries <- A_demo %>%  # begin with country A dataset\n     bind_rows(B_demo) %>%        # bind rows, because cols are identically named\n     pivot_longer(                       # pivot longer\n          cols = c(m, f),                   # columns to combine into one\n          names_to = \"Sex\",                 # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Population\") %>%     # name for new column containing the numeric values pivoted\n     mutate(Sex = recode(Sex,            # re-code values for clarity\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\ndeaths_countries <- A_deaths %>%    # begin with country A deaths dataset\n     bind_rows(B_deaths) %>%        # bind rows with B dataset, because cols are identically named\n     pivot_longer(                  # pivot longer\n          cols = c(Male, Female),        # column to transform into one\n          names_to = \"Sex\",              # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Deaths\") %>%      # name for new column containing the numeric values pivoted\n     rename(age_cat5 = AgeCat)      # rename for clarity\ncountry_data <- pop_countries %>% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\ncountry_data <- country_data %>% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %>% \n          \n  arrange(Country, age_cat5, Sex)"},{"path":"standardised-rates.html","id":"load-reference-population","chapter":"21 Standardised rates","heading":"Load reference population","text":"Lastly, direct standardisation, import reference population (world “standard population” sex)","code":"\n# Reference population\nstandard_pop_data <- import(\"world_standard_population_by_sex.csv\")"},{"path":"standardised-rates.html","id":"clean-reference-population","chapter":"21 Standardised rates","heading":"Clean reference population","text":"age category values country_data standard_pop_data data frames need aligned.Currently, values column age_cat5 standard_pop_data data frame contain word “years” “plus”, country_data data frame . make age category values match. use str_replace_all() stringr package, described page Characters strings, replace patterns space \"\".Furthermore, package dsr expects standard population, column containing counts called \"pop\". rename column accordingly.CAUTION: try use str_replace_all() remove plus symbol, won’t work special symbol. “Escape” specialnes putting two back slashes front, str_replace_call(column, \"\\\\+\", \"\"). ","code":"\n# Remove specific string from column values\nstandard_pop_clean <- standard_pop_data %>%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),   # remove \"year\"\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),    # remove \"plus\"\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %>%   # remove \" \" space\n     \n     rename(pop = WorldStandardPopulation)   # change col name to \"pop\", as this is expected by dsr package"},{"path":"standardised-rates.html","id":"standard_all","chapter":"21 Standardised rates","heading":"Create dataset with standard population","text":"Finally, package PHEindicatormethods, detailed , expects standard populations joined country event population counts. , create dataset all_data purpose.complete dataset looks like :","code":"\nall_data <- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))"},{"path":"standardised-rates.html","id":"dsr-package","chapter":"21 Standardised rates","heading":"21.3 dsr package","text":"demonstrate calculating comparing directly standardized rates using dsr package. dsr package allows calculate compare directly standardized rates (indirectly standardized rates!).data Preparation section, made separate datasets country counts standard population:country_data object, population table number population number deaths per stratum per countrythe standard_pop_clean object, containing number population per stratum reference population, World Standard PopulationWe use separate datasets dsr approach.","code":""},{"path":"standardised-rates.html","id":"standardized-rates","chapter":"21 Standardised rates","heading":"Standardized rates","text":", calculate rates per country directly standardized age sex. use dsr() function.note - dsr() expects one data frame country populations event counts (deaths), separate data frame reference population. also expects reference population dataset unit-time column name “pop” (assured data Preparation section).many arguments, annotated code . Notably, event = set column Deaths, fu = (“follow-”) set Population column. set subgroups comparison column Country standardize based age_cat5 Sex. last two columns assigned particular named argument. See ?dsr details., see country lower crude mortality rate country B, higher standardized rate direct age sex standardization.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_rate <- dsr::dsr(\n     data = country_data,  # specify object containing number of deaths per stratum\n     event = Deaths,       # column containing number of deaths per stratum \n     fu = Population,      # column containing number of population per stratum\n     subgroup = Country,   # units we would like to compare\n     age_cat5,             # other columns - rates will be standardized by these\n     Sex,\n     refdata = standard_pop_clean, # reference population data frame, with column called pop\n     method = \"gamma\",      # method to calculate 95% CI\n     sig = 0.95,            # significance level\n     mp = 100000,           # we want rates per 100.000 population\n     decimals = 2)          # number of decimals)\n\n\n# Print output as nice-looking HTML table\nknitr::kable(mortality_rate) # show mortality rate before and after direct standardization"},{"path":"standardised-rates.html","id":"standardized-rate-ratios","chapter":"21 Standardised rates","heading":"Standardized rate ratios","text":"standardized mortality rate 1.22 times higher country compared country B (95% CI 1.17-1.27).","code":"\n# Calculate RR\nmortality_rr <- dsr::dsrr(\n     data = country_data, # specify object containing number of deaths per stratum\n     event = Deaths,      # column containing number of deaths per stratum \n     fu = Population,     # column containing number of population per stratum\n     subgroup = Country,  # units we would like to compare\n     age_cat5,\n     Sex,                 # characteristics to which we would like to standardize \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",      # reference for comparison\n     estimate = \"ratio\",  # type of estimate\n     sig = 0.95,          # significance level\n     mp = 100000,         # we want rates per 100.000 population\n     decimals = 2)        # number of decimals\n\n# Print table\nknitr::kable(mortality_rr) "},{"path":"standardised-rates.html","id":"standardized-rate-difference","chapter":"21 Standardised rates","heading":"Standardized rate difference","text":"Country 4.24 additional deaths per 100.000 population (95% CI 3.24-5.24) compared country .","code":"\n# Calculate RD\nmortality_rd <- dsr::dsrr(\n     data = country_data,       # specify object containing number of deaths per stratum\n     event = Deaths,            # column containing number of deaths per stratum \n     fu = Population,           # column containing number of population per stratum\n     subgroup = Country,        # units we would like to compare\n     age_cat5,                  # characteristics to which we would like to standardize\n     Sex,                        \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",            # reference for comparison\n     estimate = \"difference\",   # type of estimate\n     sig = 0.95,                # significance level\n     mp = 100000,               # we want rates per 100.000 population\n     decimals = 2)              # number of decimals\n\n# Print table\nknitr::kable(mortality_rd) "},{"path":"standardised-rates.html","id":"standard_phe","chapter":"21 Standardised rates","heading":"21.4 PHEindicatormethods package","text":"Another way calculating standardized rates PHEindicatormethods package. package allows calculate directly well indirectly standardized rates. show .section use all_data data frame created end Preparation section. data frame includes country populations, death events, world standard reference population. can view .","code":""},{"path":"standardised-rates.html","id":"directly-standardized-rates","chapter":"21 Standardised rates","heading":"Directly standardized rates","text":", first group data Country pass function phe_dsr() get directly standardized rates per country.note - reference (standard) population can provided column within country-specific data frame separate vector. provided within country-specific data frame, set stdpoptype = \"field\". provided vector, set stdpoptype = \"vector\". latter case, make sure ordering rows strata similar country-specific data frame reference population, records matched position. example , provided reference population column within country-specific data frame.See help ?phr_dsr links References section information.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_ds_rate_phe <- all_data %>%\n     group_by(Country) %>%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          stdpop = pop,               # standard populations for each stratum\n          stdpoptype = \"field\")       # either \"vector\" for a standalone vector or \"field\" meaning std populations are in the data  \n\n# Print table\nknitr::kable(mortality_ds_rate_phe)"},{"path":"standardised-rates.html","id":"standard_indirect","chapter":"21 Standardised rates","heading":"Indirectly standardized rates","text":"indirect standardization, need reference population number deaths number population per stratum. example, calculating rates country using country B reference population, standard_pop_clean reference population include number deaths per stratum., first create reference population country B. , pass mortality population data country , combine reference population, pass function calculate_ISRate(), get indirectly standardized rates. course, can also vice versa.note - example , reference population provided separate data frame. case, make sure x =, n =, x_ref = n_ref = vectors ordered standardization category (stratum) values country-specific data frame, records matched position.See help ?phr_isr links References section information.","code":"\n# Create reference population\nrefpopCountryB <- country_data %>% \n  filter(Country == \"B\") \n\n# Calculate rates for country A indirectly standardized by age and sex\nmortality_is_rate_phe_A <- country_data %>%\n     filter(Country == \"A\") %>%\n     PHEindicatormethods::calculate_ISRate(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          x_ref = refpopCountryB$Deaths,  # reference number of deaths for each stratum\n          n_ref = refpopCountryB$Population)  # reference population for each stratum\n\n# Print table\nknitr::kable(mortality_is_rate_phe_A)"},{"path":"standardised-rates.html","id":"resources-14","chapter":"21 Standardised rates","heading":"21.5 Resources","text":"like see another reproducible example using dsr please see vignetteFor another example using PHEindicatormethods, please go websiteSee PHEindicatormethods reference pdf file","code":""},{"path":"moving-averages.html","id":"moving-averages","chapter":"22 Moving averages","heading":"22 Moving averages","text":"page cover two methods calculate visualize moving averages:Calculate slider packageCalculate within ggplot() command tidyquant package","code":""},{"path":"moving-averages.html","id":"preparation-13","chapter":"22 Moving averages","heading":"22.1 Preparation","text":"","code":""},{"path":"moving-averages.html","id":"load-packages-15","chapter":"22 Moving averages","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,      # for data management and viz\n  slider,         # for calculating moving averages\n  tidyquant       # for calculating moving averages within ggplot\n)"},{"path":"moving-averages.html","id":"import-data-14","chapter":"22 Moving averages","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"moving-averages.html","id":"calculate-with-slider","chapter":"22 Moving averages","heading":"22.2 Calculate with slider","text":"Use approach calculate moving average data frame prior plotting.slider package provides several “sliding window” functions compute rolling averages, cumulative sums, rolling regressions, etc. treats data frame vector rows, allowing iteration row-wise data frame.common functions:slide_dbl() - iterates numeric (hence “_dbl”) column performing operation using sliding window\nslide_sum() - rolling sum shortcut function slide_dbl()\nslide_mean() - rolling average shortcut function slide_dbl()\nslide_sum() - rolling sum shortcut function slide_dbl()slide_mean() - rolling average shortcut function slide_dbl()slide_index_dbl() - applies rolling window numeric column using separate column index window progression (useful rolling date dates absent)\nslide_index_sum() - rolling sum shortcut function indexing\nslide_index_mean() - rolling mean shortcut function indexing\nslide_index_sum() - rolling sum shortcut function indexingslide_index_mean() - rolling mean shortcut function indexingThe slider package many functions covered Resources section page. briefly touch upon common.Core arguments.x, first argument default, vector iterate apply function .= “index” versions slider functions - provide column “index” roll (see section ).f =, second argument default, either:\nfunction, written without parentheses, like mean, \nformula, converted function. example ~ .x - mean(.x) return result current value minus mean window’s value\nfunction, written without parentheses, like mean, orA formula, converted function. example ~ .x - mean(.x) return result current value minus mean window’s valueFor details see reference materialWindow sizeSpecify size window using either ., ., arguments:.= - Provide integer.= - Provide integer.complete = - Set TRUE want calculation performed complete windowsFor example, achieve 7-day window including current value six previous, use .= 6. achieve “centered” window provide number .= .=.default, .complete = FALSE full window rows exist, functions use available rows perform calculation. Setting TRUE restricts calculations performed complete windows.Expanding windowTo achieve cumulative operations, set .= argument Inf. conduct operation current value coming .","code":""},{"path":"moving-averages.html","id":"roll_index","chapter":"22 Moving averages","heading":"Rolling by date","text":"likely use-case rolling calculation applied epidemiology examine metric time. example, rolling measurement case incidence, based daily case counts.clean time series data values every date, may OK use slide_dbl(), demonstrated Time series outbreak detection page.However, many applied epidemiology circumstances may dates absent data, events recorded. cases, best use “index” versions slider functions.","code":""},{"path":"moving-averages.html","id":"indexed-data","chapter":"22 Moving averages","heading":"Indexed data","text":", show example using slide_index_dbl() case linelist. Let us say objective calculate rolling 7-day incidence - sum cases using rolling 7-day window. looking example rolling average, see section grouped rolling.begin, dataset daily_counts created reflect daily case counts linelist, calculated count() dplyr.daily_counts data frame - nrow(daily_counts) rows, day represented one row, especially early epidemic days present (cases admitted days).crucial recognize standard rolling function (like slide_dbl() use window 7 rows, 7 days. , absent dates, windows actually extend 7 calendar days!“smart” rolling window can achieved slide_index_dbl(). “index” means function uses separate column “index” rolling window. window simply based rows data frame.index column date, added ability specify window extent .= /.= units lubridate days() months(). things, function include absent days windows (NA values).Let’s show comparison. , calculate rolling 7-day case incidence regular indexed windows.Observe regular column first 7 rows count steadily increases despite rows within 7 days ! adjacent “indexed” column accounts absent calendar days, 7-day sums much lower, least period epidemic cases farther .Now can plot data using ggplot():","code":"\n# make dataset of daily counts\ndaily_counts <- linelist %>% \n  count(date_hospitalisation, name = \"new_cases\")\nrolling <- daily_counts %>% \n  mutate(                                # create new columns\n    # Using slide_dbl()\n    ###################\n    reg_7day = slide_dbl(\n      new_cases,                         # calculate on new_cases\n      .f = ~sum(.x, na.rm = T),          # function is sum() with missing values removed\n      .before = 6),                      # window is the ROW and 6 prior ROWS\n    \n    # Using slide_index_dbl()\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases,                       # calculate on new_cases\n        .i = date_hospitalisation,       # indexed with date_onset \n        .f = ~sum(.x, na.rm = TRUE),     # function is sum() with missing values removed\n        .before = days(6))               # window is the DAY and 6 prior DAYS\n    )\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)"},{"path":"moving-averages.html","id":"roll_slider_group","chapter":"22 Moving averages","heading":"Rolling by group","text":"group data prior using slider function, sliding windows applied group. careful arrange rows desired order group.time new group begins, sliding window re-start. Therefore, one nuance aware data grouped set .complete = TRUE, empty values transition groups. function moved downward rows, every transition grouping column re-start accrual minimum window size allow calculation.See handbook page Grouping data details grouping data., count linelist cases date hospital. arrange rows ascending order, first ordering hospital within date. Next set group_by(). can create new rolling average.new dataset:can now plot moving averages, displaying data group specifying ~ hospital facet_wrap() ggplot(). fun, plot two geometries - geom_col() showing daily case counts geom_line() showing 7-day moving average.DANGER: get error saying “slide() deprecated tsibble 0.9.0 now defunct. Please use slider::slide() instead.”, means slide() function tsibble package masking slide() function slider package. Fix specifying package command, slider::slide_dbl().","code":"\ngrouped_roll <- linelist %>%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %>% \n\n  arrange(hospital, date_hospitalisation) %>%   # arrange rows by hospital and then by date\n  \n  group_by(hospital) %>%              # group by hospital \n    \n  mutate(                             # rolling average  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases,                 # the count of cases per hospital-day\n      .i = date_hospitalisation,      # index on date of admission\n      .f = mean,                      # use mean()                   \n      .before = days(6)               # use the day and the 6 days prior\n      )\n  )\nggplot(data = grouped_roll)+\n  geom_col(                       # plot daly case counts as grey bars\n    mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(                      # plot rolling average as line colored by hospital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # create mini-plots per hospital\n  theme_classic()+                 # simplify background  \n  theme(legend.position = \"none\")+ # remove legend\n  labs(                            # add plot labels\n    title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")"},{"path":"moving-averages.html","id":"calculate-with-tidyquant-within-ggplot","chapter":"22 Moving averages","heading":"22.3 Calculate with tidyquant within ggplot()","text":"package tidyquant offers another approach calculating moving averages - time within ggplot() command .linelist data counted date onset, plotted faded line (alpha < 1). Overlaid top line created geom_ma() package tidyquant, set window 7 days (n = 7) specified color thickness.default geom_ma() uses simple moving average (ma_fun = \"SMA\"), types can specified, :“EMA” - exponential moving average (weight recent observations)“WMA” - weighted moving average (wts used weight observations moving average)Others can found function documentationSee vignette details options available within tidyquant.","code":"\nlinelist %>% \n  count(date_onset) %>%                 # count cases per day\n  drop_na(date_onset) %>%               # remove cases missing onset date\n  ggplot(aes(x = date_onset, y = n))+   # start ggplot\n    geom_line(                          # plot raw values\n      size = 1,\n      alpha = 0.2                       # semi-transparent line\n      )+             \n    tidyquant::geom_ma(                 # plot moving average\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # simple background"},{"path":"moving-averages.html","id":"resources-15","chapter":"22 Moving averages","heading":"22.4 Resources","text":"See helpful online vignette slider packageThe slider github pageA slider vignettetidyquant vignetteIf use case requires “skip ” weekends even holidays, might like almanac package.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"time-series-and-outbreak-detection","chapter":"23 Time series and outbreak detection","heading":"23 Time series and outbreak detection","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"overview-2","chapter":"23 Time series and outbreak detection","heading":"23.1 Overview","text":"tab demonstrates use several packages time series analysis.\nprimarily relies packages tidyverts\nfamily, also use RECON trending\npackage fit models appropriate infectious disease epidemiology.Note example use dataset surveillance package\nCampylobacter Germany (see data chapter,\nhandbook details). However, wanted run code dataset\nmultiple countries strata, example code template \nr4epis github repo.Topics covered include:Time series dataDescriptive analysisFitting regressionsRelation two time seriesOutbreak detectionInterrupted time series","code":""},{"path":"time-series-and-outbreak-detection.html","id":"preparation-14","chapter":"23 Time series and outbreak detection","heading":"23.2 Preparation","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"packages-2","chapter":"23 Time series and outbreak detection","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               slider,       # for calculating moving averages\n               imputeTS,     # for filling in missing values\n               feasts,       # for time series decomposition and autocorrelation\n               forecast,     # fit sin and cosin terms to data (note: must load after feasts)\n               trending,     # fit and assess models \n               tmaptools,    # for getting geocoordinates (lon/lat) based on place names\n               ecmwfr,       # for interacting with copernicus sateliate CDS API\n               stars,        # for reading in .nc (climate data) files\n               units,        # for defining units of measurement (climate data)\n               yardstick,    # for looking at model accuracy\n               surveillance  # for aberration detection\n               )"},{"path":"time-series-and-outbreak-detection.html","id":"load-data","chapter":"23 Time series and outbreak detection","heading":"Load data","text":"can download data used handbook via instructions Download handbook data page.example dataset used section weekly counts campylobacter cases reported Germany 2001 2011. \ncan click download data file (.xlsx).dataset reduced version dataset available surveillance package.\n(details load surveillance package see ?campyDE)Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 10 rows counts displayed .","code":"\n# import the counts into R\ncounts <- rio::import(\"campylobacter_germany.xlsx\")"},{"path":"time-series-and-outbreak-detection.html","id":"clean-data-1","chapter":"23 Time series and outbreak detection","heading":"Clean data","text":"code makes sure date column appropriate format.\ntab using tsibble package yearweek\nfunction used create calendar week variable. several \nways (see Working dates\npage details), however time series best keep within one framework (tsibble).","code":"\n## ensure the date column is in the appropriate format\ncounts$date <- as.Date(counts$date)\n\n## create a calendar week variable \n## fitting ISO definitons of weeks starting on a monday\ncounts <- counts %>% \n     mutate(epiweek = yearweek(date, week_start = 1))"},{"path":"time-series-and-outbreak-detection.html","id":"download-climate-data","chapter":"23 Time series and outbreak detection","heading":"Download climate data","text":"relation two time series section page, comparing\ncampylobacter case counts climate data.Climate data anywhere world can downloaded EU’s Copernicus\nSatellite. exact measurements, based model (similar \ninterpolation), however benefit global hourly coverage well forecasts.can download climate data files Download handbook data page.purposes demonstration , show R code use ecmwfr package pull data Copernicus\nclimate data store. need create free account order \nwork. package website useful walkthrough\n. example code go , \nappropriate API keys. replace X’s account\nIDs. need download one year data time otherwise server times-.sure coordinates location want download data\n, can use tmaptools package pull coordinates open street\nmaps. alternative option photon\npackage, however released CRAN yet; nice thing \nphoton provides contextual data several\nmatches search.","code":"\n## retrieve location coordinates\ncoords <- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## pull together long/lats in format for ERA-5 querying (bounding box) \n## (as just want a single point can repeat coords)\nrequest_coords <- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Pulling data modelled from copernicus satellite (ERA-5 reanalysis)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## set up key for weather data \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## run for each year of interest (otherwise server times out)\nfor (i in 2002:2011) {\n  \n  ## pull together a query \n  ## see here for how to do: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## change request to a list using addin button above (python to list)\n  ## Target is the name of the output file!!\n  request <- request <- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## download the file and store it in the current working directory\n  file <- wf_request(user     = \"XXXXX\",  # user ID (for authentication)\n                     request  = request,  # the request\n                     transfer = TRUE,     # download the file\n                     path     = here::here(\"data\", \"Weather\")) ## path to save the data\n  }"},{"path":"time-series-and-outbreak-detection.html","id":"load-climate-data","chapter":"23 Time series and outbreak detection","heading":"Load climate data","text":"Whether downloaded climate data via handbook, used code , now 10 years “.nc” climate data files stored folder computer.Use code import files R stars package.files imported object data, convert data frame.","code":"\n## define path to weather folder \nfile_paths <- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # replace with your own file path \n  full.names = TRUE)\n\n## only keep those with the current name of interest \nfile_paths <- file_paths[str_detect(file_paths, \"germany\")]\n\n## read in all the files as a stars object \ndata <- stars::read_stars(file_paths)## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp,\n## change to a data frame \ntemp_data <- as_tibble(data) %>% \n  ## add in variables and correct units\n  mutate(\n    ## create an calendar week variable \n    epiweek = tsibble::yearweek(time), \n    ## create a date variable (start of calendar week)\n    date = as.Date(epiweek),\n    ## change temperature from kelvin to celsius\n    t2m = set_units(t2m, celsius), \n    ## change precipitation from metres to millimetres \n    tp  = set_units(tp, mm)) %>% \n  ## group by week (keep the date too though)\n  group_by(epiweek, date) %>% \n  ## get the average per week\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))## `summarise()` has grouped output by 'epiweek'. You can override using the `.groups` argument."},{"path":"time-series-and-outbreak-detection.html","id":"time-series-data","chapter":"23 Time series and outbreak detection","heading":"23.3 Time series data","text":"number different packages structuring handling time series\ndata. said, focus tidyverts family packages \nuse tsibble package define time series object. data set\ndefined time series object means much easier structure analysis.use tsibble() function specify “index”, .e. variable\nspecifying time unit interest. case epiweek variable.data set weekly counts province, example, also\nable specify grouping variable using key = argument.\nallow us analysis group.Looking class(counts) tells top tidy data frame\n(“tbl_df”, “tbl”, “data.frame”), additional properties time series\ndata frame (“tbl_ts”).can take quick look data using ggplot2. see plot \nclear seasonal pattern, missings. However, \nseems issue reporting beginning year; cases drop\nlast week year increase first week next year.DANGER: datasets aren’t clean example.\nneed check duplicates missings . ","code":"\n## define time series object \ncounts <- tsibble(counts, index = epiweek)\n## plot a line graph of cases by week\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"duplicates","chapter":"23 Time series and outbreak detection","heading":"Duplicates","text":"tsibble allow duplicate observations. row need \nunique, unique within group (key variable).\npackage functions help identify duplicates. include\nare_duplicated() gives TRUE/FALSE vector whether row \nduplicate, duplicates() gives data frame duplicated rows.See page De-duplication\ndetails select rows want.","code":"\n## get a vector of TRUE/FALSE whether rows are duplicates\nare_duplicated(counts, index = epiweek) \n\n## get a data frame of any duplicated rows \nduplicates(counts, index = epiweek) "},{"path":"time-series-and-outbreak-detection.html","id":"missings","chapter":"23 Time series and outbreak detection","heading":"Missings","text":"saw brief inspection missings, also\nsaw seems problem reporting delay around new year.\nOne way address problem set values missing \nimpute values. simplest form time series imputation draw\nstraight line last non-missing next non-missing value.\nuse imputeTS package function na_interpolation().See Missing data page options imputation.Another alternative calculate moving average, try smooth\napparent reporting issues (see next section, page Moving averages).","code":"\n## create a variable with missings instead of weeks with reporting issues\ncounts <- counts %>% \n     mutate(case_miss = if_else(\n          ## if epiweek contains 52, 53, 1 or 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## then set to missing \n          NA_real_, \n          ## otherwise keep the value in case\n          case\n     ))\n\n## alternatively interpolate missings by linear trend \n## between two nearest adjacent points\ncounts <- counts %>% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## to check what values have been imputed compared to the original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis","chapter":"23 Time series and outbreak detection","heading":"23.4 Descriptive analysis","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"timeseries_moving","chapter":"23 Time series and outbreak detection","heading":"Moving averages","text":"data noisy (counts jumping ) can helpful \ncalculate moving average. example , week calculate \naverage number cases four previous weeks. smooths data, \nmake interpretable. case really add much, \nstick interpolated data analysis.\nSee Moving averages page detail.","code":"\n## create a moving average variable (deals with missings)\ncounts <- counts %>% \n     ## create the ma_4w variable \n     ## slide over each row of the case variable\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## for each row calculate the name\n                               ~ mean(.x, na.rm = TRUE),\n                               ## use the four previous weeks\n                               .before = 4))\n\n## make a quick visualisation of the difference \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")"},{"path":"time-series-and-outbreak-detection.html","id":"periodicity","chapter":"23 Time series and outbreak detection","heading":"Periodicity","text":"define custom function create periodogram. See Writing functions page information write functions R.First, function defined. arguments include dataset column counts, start_week = first week dataset, number indicate many periods per year (e.g. 52, 12), lastly output style (see details code ).NOTE: possible use weeks add sin cosine terms, however use function generate terms (see regression section ) ","code":"\n## Function arguments\n#####################\n## x is a dataset\n## counts is variable with count data or rates within x \n## start_week is the first week in your dataset\n## period is how many units in a year \n## output is whether you want return spectral periodogram or the peak weeks\n  ## \"periodogram\" or \"weeks\"\n\n# Define function\nperiodogram <- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## make sure is not a tsibble, filter to project and only keep columns of interest\n    prepare_data <- dplyr::as_tibble(x)\n    \n    # prepare_data <- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data <- dplyr::select(prepare_data, {{counts}})\n    \n    ## create an intermediate \"zoo\" time series to be able to use with spec.pgram\n    zoo_cases <- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## get a spectral periodogram not using fast fourier transform \n    periodo <- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## return the peak weeks \n    periodo_weeks <- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## get spectral periodogram for extracting weeks with the highest frequencies \n## (checking of seasonality) \nperiodo <- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## pull spectrum and frequence in to a dataframe for plotting\nperiodo <- data.frame(periodo$freq, periodo$spec)\n\n## plot a periodogram showing the most frequently occuring periodicity \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n## get a vector weeks in ascending order \npeak_weeks <- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")"},{"path":"time-series-and-outbreak-detection.html","id":"decomposition","chapter":"23 Time series and outbreak detection","heading":"Decomposition","text":"Classical decomposition used break time series several parts, \ntaken together make pattern see.\ndifferent parts :trend-cycle (long-term direction data)seasonality (repeating patterns)random (left removing trend season)","code":"\n## decompose the counts dataset \ncounts %>% \n  # using an additive classical decomposition model\n  model(classical_decomposition(case_int, type = \"additive\")) %>% \n  ## extract the important information from the model\n  components() %>% \n  ## generate a plot \n  autoplot()"},{"path":"time-series-and-outbreak-detection.html","id":"autocorrelation","chapter":"23 Time series and outbreak detection","heading":"Autocorrelation","text":"Autocorrelation tells relation counts week\nweeks (called lags).Using ACF() function, can produce plot shows us number lines\nrelation different lags. lag 0 (x = 0), line \nalways 1 shows relation observation (shown ).\nfirst line shown (x = 1) shows relation observation\nobservation (lag 1), second shows relation \nobservation observation last (lag 2) lag \n52 shows relation observation observation 1\nyear (52 weeks ).Using PACF() function (partial autocorrelation) shows type relation\nadjusted weeks . less informative determining\nperiodicity.can formally test null hypothesis independence time series (.e. \nautocorrelated) using Ljung-Box test (stats package).\nsignificant p-value suggests autocorrelation data.","code":"\n## using the counts dataset\ncounts %>% \n  ## calculate autocorrelation using a full years worth of lags\n  ACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## using the counts data set \ncounts %>% \n  ## calculate the partial autocorrelation using a full years worth of lags\n  PACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## test for independance \nBox.test(counts$case_int, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  counts$case_int\n## X-squared = 462.65, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"fitting-regressions","chapter":"23 Time series and outbreak detection","heading":"23.5 Fitting regressions","text":"possible fit large number different regressions time series,\nhowever, demonstrate fit negative binomial regression - \noften appropriate counts data infectious diseases.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"fourier-terms","chapter":"23 Time series and outbreak detection","heading":"Fourier terms","text":"Fourier terms equivalent sin cosin curves. difference \nfit based finding appropriate combination curves explain\ndata.fitting one fourier term, equivalent fitting sin\ncosin frequently occurring lag seen periodogram (\ncase 52 weeks). use fourier() function forecast package.code assign using $, fourier() returns two columns (one\nsin one cosin) added dataset list, called\n“fourier” - list can used normal variable regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  fourier(K = 1)"},{"path":"time-series-and-outbreak-detection.html","id":"negative-binomial","chapter":"23 Time series and outbreak detection","heading":"Negative binomial","text":"possible fit regressions using base stats MASS\nfunctions (e.g. lm(), glm() glm.nb()). However using \ntrending package, allows calculating appropriate confidence\nprediction intervals (otherwise available).\nsyntax , specify outcome variable tilde (~)\nadd various exposure variables interest separated plus (+).difference first define model fit() \ndata. useful allows comparing multiple different models\nsyntax.TIP: wanted use rates, rather \ncounts include population variable logarithmic offset term, adding\noffset(log(population). need set population 1, \nusing predict() order produce rate. TIP: fitting complex models \nARIMA prophet, see fable package.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier)\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, data.frame(counts))\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n\nestimate_res <- data.frame(observed$result)\n\n## plot your regression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuals","chapter":"23 Time series and outbreak detection","heading":"Residuals","text":"see well model fits observed data need look residuals.\nresiduals difference observed counts counts\nestimated model. calculate simply using case_int - estimate,\nresiduals() function extracts directly regression us.see , explaining variation\nmodel. might fit fourier terms,\naddress amplitude. However example leave .\nplots show model worse peaks troughs (counts \nhighest lowest) might likely underestimate\nobserved counts.","code":"\n## calculate the residuals \nestimate_res <- estimate_res %>% \n  mutate(resid = fitted_model$result[[1]]$residuals)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nestimate_res %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nestimate_res %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nestimate_res %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nestimate_res %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(estimate_res$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  estimate_res$resid\n## X-squared = 336.25, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"relation-of-two-time-series","chapter":"23 Time series and outbreak detection","heading":"23.6 Relation of two time series","text":"look using weather data (specifically temperature) explain\ncampylobacter case counts.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"merging-datasets","chapter":"23 Time series and outbreak detection","heading":"Merging datasets","text":"can join datasets using week variable. merging see \nhandbook section joining.","code":"\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts <- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis-1","chapter":"23 Time series and outbreak detection","heading":"Descriptive analysis","text":"First plot data see obvious relation.\nplot shows clear relation seasonality two\nvariables, temperature might peak weeks case number.\npivoting data, see handbook section pivoting data.","code":"\ncounts %>% \n  ## keep the variables we are interested \n  select(epiweek, case_int, t2m) %>% \n  ## change your data in to long format\n  pivot_longer(\n    ## use epiweek as your key\n    !epiweek,\n    ## move column names to the new \"measure\" column\n    names_to = \"measure\", \n    ## move cell values to the new \"values\" column\n    values_to = \"value\") %>% \n  ## create a plot with the dataset above\n  ## plot epiweek on the x axis and values (counts/celsius) on the y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## create a separate plot for temperate and case counts \n    ## let them set their own y-axes\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## plot both as a line\n    geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"lags-and-cross-correlation","chapter":"23 Time series and outbreak detection","heading":"Lags and cross-correlation","text":"formally test weeks highly related cases temperature.\ncan use cross-correlation function (CCF()) feasts package.\nalso visualise (rather using arrange) using autoplot() function.see lag 4 weeks highly correlated,\nmake lagged temperature variable include regression.DANGER: Note first four weeks data\nlagged temperature variable missing (NA) - four\nweeks prior get data . order use dataset trending\npredict() function, need use simulate_pi = FALSE argument within\npredict() . want use simulate option, \ndrop missings store new data set adding drop_na(t2m_lag4)\ncode chunk .","code":"\ncounts %>% \n  ## calculate cross-correlation between interpolated counts and temperature\n  CCF(case_int, t2m,\n      ## set the maximum lag to be 52 weeks\n      lag_max = 52, \n      ## return the correlation coefficient \n      type = \"correlation\") %>% \n  ## arange in decending order of the correlation coefficient \n  ## show the most associated lags\n  arrange(-ccf) %>% \n  ## only show the top ten \n  slice_head(n = 10)## # A tsibble: 10 x 2 [1W]\n##         lag   ccf\n##    <cf_lag> <dbl>\n##  1      -4W 0.749\n##  2      -5W 0.745\n##  3      -3W 0.735\n##  4      -6W 0.729\n##  5      -2W 0.727\n##  6      -7W 0.704\n##  7      -1W 0.695\n##  8      -8W 0.671\n##  9       0W 0.649\n## 10      47W 0.638\ncounts <- counts %>% \n  ## create a new variable for temperature lagged by four weeks\n  mutate(t2m_lag4 = lag(t2m, n = 4))"},{"path":"time-series-and-outbreak-detection.html","id":"negative-binomial-with-two-variables","chapter":"23 Time series and outbreak detection","heading":"Negative binomial with two variables","text":"fit negative binomial regression done previously. time add \ntemperature variable lagged four weeks.CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. investigate individual terms, can pull original negative binomial\nregression trending format using get_model() pass \nbroom package tidy() function retrieve exponentiated estimates associated\nconfidence intervals.shows us lagged temperature, controlling trend seasonality,\nsimilar case counts (estimate ~ 1) significantly associated.\nsuggests might good variable use predicting future case\nnumbers (climate forecasts readily available).quick visual inspection model shows might better job \nestimating observed case counts.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier + \n    ## use the temperature lagged by four weeks \n    t2m_lag4\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, data.frame(counts))\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_fitted_model() #%>% ## [[1]]\n## \n## Call:  glm.nb(formula = case_int ~ epiweek + fourier + t2m_lag4, data = data.frame(counts), \n##     init.theta = 32.80689607, link = log)\n## \n## Coefficients:\n##  (Intercept)       epiweek  fourierS1-52  fourierC1-52      t2m_lag4  \n##   5.82535083    0.00008464   -0.28502594   -0.19537827    0.00667157  \n## \n## Degrees of Freedom: 504 Total (i.e. Null);  500 Residual\n##   (4 observations deleted due to missingness)\n## Null Deviance:       2015 \n## Residual Deviance: 508.2     AIC: 6784\n  ## get a tidy dataframe of results\n  #tidy(exponentiate = TRUE, \n  #     conf.int = TRUE)\nestimate_res <- data.frame(observed$result)\n\n## plot your regression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuals-1","chapter":"23 Time series and outbreak detection","heading":"Residuals","text":"investigate residuals see well model fits observed data.\nresults interpretation similar previous regression,\nmay feasible stick simpler model without temperature.","code":"\n## calculate the residuals \nestimate_res <- estimate_res %>% \n  mutate(resid = case_int - estimate)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nestimate_res %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nestimate_res %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nestimate_res %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nestimate_res %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(estimate_res$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  estimate_res$resid\n## X-squared = 339.52, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"outbreak-detection","chapter":"23 Time series and outbreak detection","heading":"23.7 Outbreak detection","text":"demonstrate two (similar) methods detecting outbreaks .\nfirst builds sections .\nuse trending package fit regressions previous years, \npredict expect see following year. observed counts \nexpect, suggest outbreak.\nsecond method based similar principles uses surveillance package,\nnumber different algorithms aberration detection.CAUTION: Normally, interested current year (know counts present week). example pretending week 39 2011.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"trending-package","chapter":"23 Time series and outbreak detection","heading":"trending package","text":"method define baseline (usually 5 years data).\nfit regression baseline data, use predict estimates\nnext year.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"cut-off-date","chapter":"23 Time series and outbreak detection","heading":"Cut-off date","text":"easier define dates one place use throughout \nrest code.define start date (observations started) cut-date\n(end baseline period - period want predict starts).\n~also define many weeks year interest (one going \npredicting)~.\nalso define many weeks baseline cut-end date\ninterested predicting .NOTE: example pretend currently end September 2011 (“2011 W39”).","code":"\n## define start date (when observations began)\nstart_date <- min(counts$epiweek)\n\n## define a cut-off week (end of baseline, start of prediction period)\ncut_off <- yearweek(\"2010-12-31\")\n\n## define the last date interested in (i.e. end of prediction)\nend_date <- yearweek(\"2011-12-31\")\n\n## find how many weeks in period (year) of interest\nnum_weeks <- as.numeric(end_date - cut_off)"},{"path":"time-series-and-outbreak-detection.html","id":"add-rows-1","chapter":"23 Time series and outbreak detection","heading":"Add rows","text":"able forecast tidyverse format, need right number\nrows dataset, .e. one row week end_datedefined .\ncode allows add rows grouping variable - example\nmultiple countries one dataset, group country \nadd rows appropriately .\ngroup_by_key() function tsibble allows us grouping\npass grouped data dplyr functions, group_modify() \nadd_row(). specify sequence weeks one maximum week\ncurrently available data end week.","code":"\n## add in missing weeks till end of year \ncounts <- counts %>%\n  ## group by the region\n  group_by_key() %>%\n  ## for each group add rows from the highest epiweek to the end of year\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))"},{"path":"time-series-and-outbreak-detection.html","id":"fourier-terms-1","chapter":"23 Time series and outbreak detection","heading":"Fourier terms","text":"need redefine fourier terms - want fit baseline\ndate predict (extrapolate) terms next year.\nneed combine two output lists fourier() function together;\nfirst one baseline data, second one predicts \nyear interest (defining h argument).N.b. bind rows use rbind() (rather tidyverse bind_rows) \nfourier columns list (named individually).","code":"\n## define fourier terms (sincos) \ncounts <- counts %>% \n  mutate(\n    ## combine fourier terms for weeks prior to  and after 2010 cut-off date\n    ## (nb. 2011 fourier terms are predicted)\n    fourier = rbind(\n      ## get fourier terms for previous years\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for 2011 (using baseline data)\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = num_weeks\n        )\n      )\n    )"},{"path":"time-series-and-outbreak-detection.html","id":"split-data-and-fit-regression","chapter":"23 Time series and outbreak detection","heading":"Split data and fit regression","text":"now split dataset baseline period prediction\nperiod. done using dplyr group_split() function group_by(),\ncreate list two data frames, one cut-one\n.use purrr package pluck() function pull datasets \nlist (equivalent using square brackets, e.g. dat[[1]]), can fit\nmodel baseline data, use predict() function data\ninterest cut-.See page Iteration, loops, lists learn purrr.CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. previously, can visualise model ggplot. highlight alerts \nred dots observed counts 95% prediction interval.\ntime also add vertical line label forecast starts.","code":"\n# split data for fitting and prediction\ndat <- counts %>% \n  group_by(epiweek <= cut_off) %>%\n  group_split()\n\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier\n)\n\n# define which data to use for fitting and which for predicting\nfitting_data <- pluck(dat, 2)\npred_data <- pluck(dat, 1) %>% \n  select(case_int, epiweek, fourier)\n\n# fit model \nfitted_model <- trending::fit(model, data.frame(fitting_data))\n\n# get confint and estimates for fitted data\nobserved <- fitted_model %>% \n  predict(simulate_pi = FALSE)\n\n# forecast with data want to predict with \nforecasts <- fitted_model %>% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## combine baseline and predicted datasets\nobserved <- bind_rows(observed$result, forecasts$result)\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## plot in points for the observed counts above expected\n  geom_point(\n    data = filter(observed, case_int > upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 rows containing missing values (`geom_line()`)."},{"path":"time-series-and-outbreak-detection.html","id":"prediction-validation","chapter":"23 Time series and outbreak detection","heading":"Prediction validation","text":"Beyond inspecting residuals, important investigate good model \npredicting cases future. gives idea reliable \nthreshold alerts .traditional way validating see well can predict latest\nyear present one (don’t yet know counts “current year”).\nexample data set use data 2002 2009 predict 2010,\nsee accurate predictions . refit model include\n2010 data use predict 2011 counts.can seen figure Hyndman et al “Forecasting principles\npractice”.figure reproduced permission authorsThe downside using data available , \nfinal model using prediction.alternative use method called cross-validation. scenario \nroll data available fit multiple models predict one year ahead.\nuse data model, seen figure \n[Hyndman et al text]((https://otexts.com/fpp3/).\nexample, first model uses 2002 predict 2003, second uses 2002 \n2003 predict 2004, .\nfigure reproduced permission authorsIn use purrr package map() function loop dataset.\nput estimates one data set merge original case counts,\nuse yardstick package compute measures accuracy.\ncompute four measures including: Root mean squared error (RMSE), Mean absolute error\n(MAE), Mean absolute scaled error (MASE), Mean absolute percent error (MAPE).CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. ","code":"\n## Cross validation: predicting week(s) ahead based on sliding window\n\n## expand your data by rolling over in 52 week windows (before + after) \n## to predict 52 week ahead\n## (creates longer and longer chains of observations - keeps older data)\n\n## define window want to roll over\nroll_window <- 52\n\n## define weeks ahead want to predict \nweeks_ahead <- 52\n\n## create a data set of repeating, increasingly long data\n## label each data set with a unique id\n## only use cases before year of interest (i.e. 2011)\ncase_roll <- counts %>% \n  filter(epiweek < cut_off) %>% \n  ## only keep the week and case counts variables\n  select(epiweek, case_int) %>% \n    ## drop the last x observations \n    ## depending on how many weeks ahead forecasting \n    ## (otherwise will be an actual forecast to \"unknown\")\n    slice(1:(n() - weeks_ahead)) %>%\n    as_tsibble(index = epiweek) %>% \n    ## roll over each week in x after windows to create grouping ID \n    ## depending on what rolling window specify\n    stretch_tsibble(.init = roll_window, .step = 1) %>% \n  ## drop the first couple - as have no \"before\" cases\n  filter(.id > roll_window)\n\n\n## for each of the unique data sets run the code below\nforecasts <- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## only keep the current fold being fit \n  mini_data <- filter(case_roll, .id == i) %>% \n    as_tibble()\n  \n  ## create an empty data set for forecasting on \n  forecast_data <- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## add the forecast data to the original \n  mini_data <- bind_rows(mini_data, forecast_data)\n  \n  ## define the cut off based on latest non missing count data \n  cv_cut_off <- mini_data %>% \n    ## only keep non-missing rows\n    drop_na(case_int) %>% \n    ## get the latest week\n    summarise(max(epiweek)) %>% \n    ## extract so is not in a dataframe\n    pull()\n  \n  ## make mini_data back in to a tsibble\n  mini_data <- tsibble(mini_data, index = epiweek)\n  \n  ## define fourier terms (sincos) \n  mini_data <- mini_data %>% \n    mutate(\n    ## combine fourier terms for weeks prior to  and after cut-off date\n    fourier = rbind(\n      ## get fourier terms for previous years\n      forecast::fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for following year (using baseline data)\n      fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # split data for fitting and prediction\n  dat <- mini_data %>% \n    group_by(epiweek <= cv_cut_off) %>%\n    group_split()\n\n  ## define the model you want to fit (negative binomial) \n  model <- glm_nb_model(\n    ## set number of cases as outcome of interest\n    case_int ~\n      ## use epiweek to account for the trend\n      epiweek +\n      ## use the furier terms to account for seasonality\n      fourier\n  )\n\n  # define which data to use for fitting and which for predicting\n  fitting_data <- pluck(dat, 2)\n  pred_data <- pluck(dat, 1)\n  \n  # fit model \n  fitted_model <- trending::fit(model, fitting_data)\n  \n  # forecast with data want to predict with \n  forecasts <- fitted_model %>% \n    predict(data.frame(pred_data), simulate_pi = FALSE)\n  forecasts <- data.frame(forecasts$result[[1]]) %>% \n       ## only keep the week and the forecast estimate\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## make the list in to a data frame with all the forecasts\nforecasts <- bind_rows(forecasts)\n\n## join the forecasts with the observed\nforecasts <- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## using {yardstick} compute metrics\n  ## RMSE: Root mean squared error\n  ## MAE:  Mean absolute error  \n  ## MASE: Mean absolute scaled error\n  ## MAPE: Mean absolute percent error\nmodel_metrics <- bind_rows(\n  ## in your forcasted dataset compare the observed to the predicted\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %>% \n  ## only keep the metric type and its output\n  select(Metric  = .metric, \n         Measure = .estimate) %>% \n  ## make in to wide format so can bind rows after\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## return model metrics \nmodel_metrics## # A tibble: 1 × 4\n##    rmse   mae  mase  mape\n##   <dbl> <dbl> <dbl> <dbl>\n## 1  252.  199.  1.96  17.3"},{"path":"time-series-and-outbreak-detection.html","id":"surveillance-package","chapter":"23 Time series and outbreak detection","heading":"surveillance package","text":"section use surveillance package create alert thresholds\nbased outbreak detection algorithms. several different methods\navailable package, however focus two options .\ndetails, see papers application\ntheory\nalogirthms used.first option uses improved Farrington method. fits negative\nbinomial glm (including trend) -weights past outbreaks (outliers) \ncreate threshold level.second option use glrnb method. also fits negative binomial glm\nincludes trend fourier terms (favoured ). regression used\ncalculate “control mean” (~fitted values) - uses computed\ngeneralized likelihood ratio statistic assess shift mean\nweek. Note threshold week takes account previous\nweeks sustained shift alarm triggered.\n(Also note alarm algorithm reset)order work surveillance package, first need define \n“surveillance time series” object (using sts() function) fit within \nframework.","code":"\n## define surveillance time series object\n## nb. you can include a denominator with the population object (see ?sts)\ncounts_sts <- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## subset to only keep the year from start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subset to only keep the week from start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define the type of data (in this case weekly)\n                  freq = 52)\n\n## define the week range that you want to include (ie. prediction period)\n## nb. the sts object only counts observations without assigning a week or \n## year identifier to them - so we use our data to define the appropriate observations\nweekrange <- cut_off - start_date"},{"path":"time-series-and-outbreak-detection.html","id":"farrington-method","chapter":"23 Time series and outbreak detection","heading":"Farrington method","text":"define parameters Farrington method list.\nrun algorithm using farringtonFlexible() can extract \nthreshold alert using farringtonmethod@upperboundto include \ndataset. also possible extract TRUE/FALSE week triggered\nalert (threshold) using farringtonmethod@alarm.can visualise results ggplot done previously.","code":"\n## define control\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  b = 9, ## how many years backwards for baseline\n  w = 2, ## rolling window size in weeks\n  weightsThreshold = 2.58, ## reweighting past outbreaks (improved noufaily method - original suggests 1)\n  ## pastWeeksNotIncluded = 3, ## use all weeks available (noufaily suggests drop 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normally, however 1 is advised in the improved method (i.e. always keep)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## apply farrington flexible method\nfarringtonmethod <- farringtonFlexible(counts_sts, ctrl)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from farrington \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] <- farringtonmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"glrnb-method","chapter":"23 Time series and outbreak detection","heading":"GLRNB method","text":"Similarly GLRNB method define parameters list,\nfit algorithm extract upper bounds.CAUTION: method uses “brute force” (similar bootstrapping) calculating thresholds, can take long time!See GLRNB vignette\ndetails.Visualise outputs previously.","code":"\n## define control options\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  mu0 = list(S = 1,    ## number of fourier terms (harmonics) to include\n  trend = TRUE,   ## whether to include trend or not\n  refit = FALSE), ## whether to refit model after each alarm\n  ## cARL = threshold for GLR statistic (arbitrary)\n     ## 3 ~ middle ground for minimising false positives\n     ## 1 fits to the 99%PI of glm.nb - with changes after peaks (threshold lowered for alert)\n   c.ARL = 2,\n   # theta = log(1.5), ## equates to a 50% increase in cases in an outbreak\n   ret = \"cases\"     ## return threshold upperbound as case counts\n  )\n\n## apply the glrnb method\nglrnbmethod <- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from glrnb \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] <- glrnbmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"interrupted-timeseries","chapter":"23 Time series and outbreak detection","heading":"23.8 Interrupted timeseries","text":"Interrupted timeseries (also called segmented regression intervention analysis),\noften used assessing impact vaccines incidence disease.\ncan used assessing impact wide range interventions introductions.\nexample changes hospital procedures introduction new disease\nstrain population.\nexample pretend new strain Campylobacter introduced\nGermany end 2008, see affects number cases.\nuse negative binomial regression . regression time \nsplit two parts, one intervention (introduction new strain )\none (pre post-periods). allows us calculate incidence rate ratio comparing \ntwo time periods. Explaining equation might make clearer (just\nignore!).negative binomial regression can defined follows:\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]:\n\\(Y_t\\)number cases observed time \\(t\\)\\(pop_t\\) population size 100,000s time \\(t\\) (used )\\(t_0\\) last year pre-period (including transition time )\\(δ(x\\) indicator function (0 x≤0 1 x>0)\\((x)^+\\) cut operator (x x>0 0 otherwise)\\(e_t\\) denotes residual\nAdditional terms trend season can added needed.\\(β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+\\) generalised linear\npart post-period zero pre-period.\nmeans \\(β_2\\) \\(β_3\\) estimates effects intervention.need re-calculate fourier terms without forecasting , use\ndata available us (.e. retrospectively). Additionally need calculate\nextra terms needed regression.use terms fit negative binomial regression, produce \ntable percentage change. example shows \nsignificant change.CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. previously can visualise outputs regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  as_tsibble(index = epiweek) %>% \n  fourier(K = 1)\n\n## define intervention week \nintervention_week <- yearweek(\"2008-12-31\")\n\n## define variables for regression \ncounts <- counts %>% \n  mutate(\n    ## corresponds to t in the formula\n      ## count of weeks (could probably also just use straight epiweeks var)\n    # linear = row_number(epiweek), \n    ## corresponds to delta(t-t0) in the formula\n      ## pre or post intervention period\n    intervention = as.numeric(epiweek >= intervention_week), \n    ## corresponds to (t-t0)^+ in the formula\n      ## count of weeks post intervention\n      ## (choose the larger number between 0 and whatever comes from calculation)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## add in whether in the pre- or post-period \n    intervention + \n    ## add in the time post intervention \n    time_post\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n## show estimates and percentage change in a table\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %>% \n  ## only keep the intervention value \n  filter(term == \"intervention\") %>% \n  ## change the IRR to percentage change for estimate and CIs \n  mutate(\n    ## for each of the columns of interest - create a new column\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## apply the formula to calculate percentage change\n            .f = function(i) 100 * (i - 1), \n      ## add a suffix to new column names with \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %>% \n  ## only keep (and rename) certain columns \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)\nestimate_res <- data.frame(observed$result)\n\nggplot(estimate_res, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Unknown or uninitialised column: `upper_pi`.## Warning in max(observed$upper_pi): no non-missing arguments to max; returning -Inf"},{"path":"time-series-and-outbreak-detection.html","id":"resources-16","chapter":"23 Time series and outbreak detection","heading":"23.9 Resources","text":"forecasting: principles practice textbookEPIET timeseries analysis case studiesPenn State course\nSurveillance package manuscript","code":""},{"path":"epidemic-modeling.html","id":"epidemic-modeling","chapter":"24 Epidemic modeling","heading":"24 Epidemic modeling","text":"","code":""},{"path":"epidemic-modeling.html","id":"overview-3","chapter":"24 Epidemic modeling","heading":"24.1 Overview","text":"exists growing body tools epidemic modelling lets us conduct\nfairly complex analyses minimal effort. section provide \noverview use tools :estimate effective reproduction number Rt related statistics\ndoubling timeproduce short-term projections future incidenceIt intended overview methodologies statistical methods\nunderlying tools, please refer Resources tab links \npapers covering . Make sure understanding \nmethods using tools; ensure can accurately\ninterpret results.example one outputs ’ll producing section.","code":""},{"path":"epidemic-modeling.html","id":"preparation-15","chapter":"24 Epidemic modeling","heading":"24.2 Preparation","text":"use two different methods packages Rt estimation,\nnamely EpiNow EpiEstim, well projections package \nforecasting case incidence.code chunk shows loading packages required analyses.\nhandbook emphasize p_load() pacman, installs package necessary loads use.\ncan also load installed packages library() base R. See page R basics information R packages.use cleaned case linelist analyses section. want follow along, click download “clean” linelist (.rds file). See Download handbook data page download example data used handbook.","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   epicontacts,  # Analysing transmission networks\n   EpiNow2,      # Rt estimation\n   EpiEstim,     # Rt estimation\n   projections,  # Incidence projections\n   incidence2,   # Handling incidence data\n   epitrix,      # Useful epi functions\n   distcrete     # Discrete delay distributions\n)\n# import the cleaned linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"epidemic-modeling.html","id":"estimating-rt","chapter":"24 Epidemic modeling","heading":"24.3 Estimating Rt","text":"","code":""},{"path":"epidemic-modeling.html","id":"epinow2-vs.-epiestim","chapter":"24 Epidemic modeling","heading":"EpiNow2 vs. EpiEstim","text":"reproduction number R measure transmissibility disease \ndefined expected number secondary cases per infected case. \nfully susceptible population, value represents basic reproduction\nnumber R0. However, number susceptible individuals \npopulation changes course outbreak pandemic, various\nresponse measures implemented, commonly used measure \ntransmissibility effective reproduction number Rt; \ndefined expected number secondary cases per infected case given\ntime t.EpiNow2 package provides sophisticated framework estimating\nRt. two key advantages commonly used package,\nEpiEstim:accounts delays reporting can therefore estimate Rt\neven recent data incomplete.estimates Rt dates infection rather dates \nonset reporting, means effect intervention \nimmediately reflected change Rt, rather \ndelay.However, also two key disadvantages:requires knowledge generation time distribution (.e. distribution\ndelays infection primary secondary cases), incubation\nperiod distribution (.e. distribution delays infection symptom\nonset) delay distribution relevant data (e.g. \ndates reporting, require distribution delays symptom\nonset reporting). allow accurate estimation \nRt, EpiEstim requires serial interval distribution\n(.e. distribution delays symptom onset primary \nsecondary case), may distribution available .EpiNow2 significantly slower EpiEstim, anecdotally factor\n100-1000! example, estimating Rt sample outbreak\nconsidered section takes four hours (run large\nnumber iterations ensure high accuracy probably reduced \nnecessary, however points stands algorithm slow \ngeneral). may unfeasible regularly updating \nRt estimates.package choose use therefore depend data, time \ncomputational resources available .","code":""},{"path":"epidemic-modeling.html","id":"epinow2","chapter":"24 Epidemic modeling","heading":"EpiNow2","text":"","code":""},{"path":"epidemic-modeling.html","id":"estimating-delay-distributions","chapter":"24 Epidemic modeling","heading":"Estimating delay distributions","text":"delay distributions required run EpiNow2 depend data \n. Essentially, need able describe delay date \ninfection date event want use estimate Rt. \nusing dates onset, simply incubation period\ndistribution. using dates reporting, require \ndelay infection reporting. distribution unlikely known\ndirectly, EpiNow2 lets chain multiple delay distributions together; \ncase, delay infection symptom onset (e.g. incubation\nperiod, likely known) symptom onset reporting (\ncan often estimate data).dates onset cases example linelist, \nrequire incubation period distribution link data (e.g. dates \nsymptom onset) date infection. can either estimate distribution\ndata use values literature.literature estimate incubation period Ebola (taken\npaper) \nmean 9.1, standard deviation 7.3 maximum value 30 \nspecified follows:Note EpiNow2 requires delay distributions provided log\nscale, hence log call around value (except max parameter ,\nconfusingly, provided natural scale). mean_sd sd_sd\ndefine standard deviation mean standard deviation estimates. \nknown case, choose fairly arbitrary value 0.1.analysis, instead estimate incubation period distribution\nlinelist using function bootstrapped_dist_fit, \nfit lognormal distribution observed delays infection onset\nlinelist.distribution require generation time. data \ninfection times transmission links, can estimate \ndistribution linelist calculating delay infection times\ninfector-infectee pairs. , use handy get_pairwise function\npackage epicontacts, allows us calculate pairwise\ndifferences linelist properties transmission pairs. first create \nepicontacts object (see Transmission chains page \ndetails):fit difference infection times transmission pairs,\ncalculated using get_pairwise, gamma distribution:","code":"\nincubation_period_lit <- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n## estimate incubation period\nincubation_period <- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma generation time\ngeneration_time <- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)"},{"path":"epidemic-modeling.html","id":"running-epinow2","chapter":"24 Epidemic modeling","heading":"Running EpiNow2","text":"Now just need calculate daily incidence linelist, can \neasily dplyr functions group_by() n(). Note\nEpiNow2 requires column names date confirm.can estimate Rt using epinow function. notes \ninputs:can provide number ‘chained’ delay distributions delays\nargument; simply insert alongside incubation_period object\nwithin delay_opts function.return_output ensures output returned within R just saved \nfile.verbose specifies want readout progress.horizon indicates many days want project future incidence .pass additional options stan argument specify long\nwant run inference . Increasing samples chains give\naccurate estimate better characterises uncertainty, however\ntake longer run.","code":"\n## get incidence from onset dates\ncases <- linelist %>%\n  group_by(date = date_onset) %>%\n  summarise(confirm = n())\n## run epinow\nepinow_res <- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)"},{"path":"epidemic-modeling.html","id":"analysing-outputs","chapter":"24 Epidemic modeling","heading":"Analysing outputs","text":"code finished running, can plot summary easily follows. Scroll image see full extent.can also look various summary statistics:analyses custom plotting, can access summarised daily\nestimates via $estimates$summarised. convert default\ndata.table tibble ease use dplyr.example, let’s make plot doubling time Rt. \nlook first months outbreak Rt well\none, avoid plotting extremely high doublings times.use formula log(2)/growth_rate calculate doubling time \nestimated growth rate.","code":"\n## plot summary figure\nplot(epinow_res)\n## summary table\nepinow_res$summary##                                  measure                  estimate  numeric_estimate\n## 1: New confirmed cases by infection date                4 (2 -- 6) <data.table[1x9]>\n## 2:        Expected change in daily cases                    Unsure              0.56\n## 3:            Effective reproduction no.        0.88 (0.73 -- 1.1) <data.table[1x9]>\n## 4:                        Rate of growth -0.012 (-0.028 -- 0.0052) <data.table[1x9]>\n## 5:          Doubling/halving time (days)          -60 (130 -- -25) <data.table[1x9]>\n## extract summary and convert to tibble\nestimates <- as_tibble(epinow_res$estimates$summarised)\nestimates\n## make wide df for median plotting\ndf_wide <- estimates %>%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date < as.Date(\"2014-09-01\")\n  ) %>%\n  ## convert growth rates to doubling times\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## rename variable to reflect transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## make long df for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-modeling.html","id":"epiestim","chapter":"24 Epidemic modeling","heading":"EpiEstim","text":"run EpiEstim, need provide data daily incidence specify \nserial interval (.e. distribution delays symptom onset \nprimary secondary cases).Incidence data can provided EpiEstim vector, data frame, incidence\nobject original incidence package. can even distinguish imports\nlocally acquired infections; see documentation ?estimate_R \ndetails.create input using incidence2. See page Epidemic curves examples incidence2 package. Since updates incidence2 package don’t completely align estimateR()’s expected input, minor additional steps needed. incidence object consists tibble dates respective case counts. use complete() tidyr ensure dates included (even cases), rename() columns align expected estimate_R() later step.package provides several options specifying serial interval, \ndetails provided documentation ?estimate_R. \ncover two .","code":"\n## get incidence from onset date\ncases <- incidence2::incidence(linelist, date_index = \"date_onset\") %>% # get case counts by day\n  tidyr::complete(date_index = seq.Date(                              # ensure all dates are represented\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %>%                                       # convert NA counts to 0\n  rename(I = count,                                                   # rename to names expected by estimateR\n         dates = date_index)"},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-literature","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the literature","text":"Using option method = \"parametric_si\", can manually specify mean \nstandard deviation serial interval config object created using \nfunction make_config. use mean standard deviation 12.0 5.2, respectively, defined \npaper:can estimate Rt estimate_R function:plot summary outputs:","code":"\n## make config\nconfig_lit <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\ncases <- cases %>% \n     filter(!is.na(date))\n\n\n#create a dataframe for the function estimate_R()\ncases_incidence <- data.frame(dates = seq.Date(from = min(cases$dates),\n                               to = max(cases$dates), \n                               by = 1))\n\ncases_incidence <- left_join(cases_incidence, cases) %>% \n     select(dates, I) %>% \n     mutate(I = ifelse(is.na(I), 0, I))## Joining with `by = join_by(dates)`\nepiestim_res_lit <- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_lit\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\nplot(epiestim_res_lit)"},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-data","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the data","text":"data dates symptom onset transmission links, can\nalso estimate serial interval linelist calculating delay\nonset dates infector-infectee pairs. EpiNow2\nsection, use get_pairwise function epicontacts\npackage, allows us calculate pairwise differences linelist\nproperties transmission pairs. first create epicontacts object\n(see Transmission chains page details):fit difference onset dates transmission pairs, calculated\nusing get_pairwise, gamma distribution. use handy fit_disc_gamma\nepitrix package fitting procedure, require \ndiscretised distribution.pass information config object, run EpiEstim\nplot results:","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n## make config\nconfig_emp <- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## run epiestim\nepiestim_res_emp <- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_emp\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\n## plot outputs\nplot(epiestim_res_emp)"},{"path":"epidemic-modeling.html","id":"specifying-estimation-time-windows","chapter":"24 Epidemic modeling","heading":"Specifying estimation time windows","text":"default options provide weekly sliding estimate might act \nwarning estimating Rt early outbreak \nprecise estimate. can change setting later start date \nestimation shown . Unfortunately, EpiEstim provides \nclunky way specifying estimations times, provide \nvector integers referring start end dates time\nwindow.Now re-run EpiEstim can see estimates start June:","code":"\n## define a vector of dates starting on June 1st\nstart_dates <- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %>%\n  ## subtract the starting date to convert to numeric\n  `-`(min(cases$dates)) %>%\n  ## convert to integer\n  as.integer()\n\n## add six days for a one week sliding window\nend_dates <- start_dates + 6\n  \n## make config\nconfig_partial <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n## run epiestim\nepiestim_res_partial <- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## plot outputs\nplot(epiestim_res_partial)"},{"path":"epidemic-modeling.html","id":"analysing-outputs-1","chapter":"24 Epidemic modeling","heading":"Analysing outputs","text":"main outputs can accessed via $R. example, create plot \nRt measure “transmission potential” given product \nRt number cases reported day; represents \nexpected number cases next generation infection.","code":"\n## make wide dataframe for median\ndf_wide <- epiestim_res_lit$R %>%\n  rename_all(clean_labels) %>%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %>%\n  mutate(\n    ## extract the median date from t_start and t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %>%\n  ## merge in daily incidence data\n  left_join(cases, \"dates\") %>%\n  ## calculate risk across all r estimates\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %>%\n  ## seperate r estimates and risk estimates\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %>%\n  ## assign factor levels\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make long dataframe from quantiles\ndf_long <- df_wide %>%\n  select(-variable, -median) %>%\n  ## seperate r/risk estimates and quantile levels\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %>%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-modeling.html","id":"projecting-incidence","chapter":"24 Epidemic modeling","heading":"24.4 Projecting incidence","text":"","code":""},{"path":"epidemic-modeling.html","id":"epinow2-1","chapter":"24 Epidemic modeling","heading":"EpiNow2","text":"Besides estimating Rt, EpiNow2 also supports forecasting \nRt projections case numbers integration \nEpiSoon package hood. need specify horizon\nargument epinow function call, indicating many days want \nproject future; see EpiNow2 section “Estimating\nRt” details get EpiNow2 running. \nsection, just plot outputs analysis, stored \nepinow_res object.","code":"\n## define minimum date for plot\nmin_date <- as.Date(\"2015-03-01\")\n\n## extract summarised estimates\nestimates <-  as_tibble(epinow_res$estimates$summarised)\n\n## extract raw data on case incidence\nobservations <- as_tibble(epinow_res$estimates$observations) %>%\n  filter(date > min_date)\n\n## extract forecasted estimates of case numbers\ndf_wide <- estimates %>%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date > min_date\n  )\n\n## convert to even longer format for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)"},{"path":"epidemic-modeling.html","id":"projections","chapter":"24 Epidemic modeling","heading":"projections","text":"projections package developed RECON makes easy make short\nterm incidence forecasts, requiring knowledge effective reproduction\nnumber Rt serial interval. cover use\nserial interval estimates literature use estimates\nlinelist.","code":""},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-literature-1","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the literature","text":"projections requires discretised serial interval distribution class\ndistcrete package distcrete. use gamma distribution\nmean 12.0 standard deviation 5.2 defined \npaper. \nconvert values shape scale parameters required gamma\ndistribution, use function gamma_mucv2shapescale \nepitrix package.quick check make sure serial interval looks correct. \naccess density gamma distribution just defined $d, \nequivalent calling dgamma:","code":"\n## get shape and scale parameters from the mean mu and the coefficient of\n## variation (e.g. the ratio of the standard deviation to the mean)\nshapescale <- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## make distcrete object\nserial_interval_lit <- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n## check to make sure the serial interval looks correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)"},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-data-1","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the data","text":"data dates symptom onset transmission links, can\nalso estimate serial interval linelist calculating delay\nonset dates infector-infectee pairs. EpiNow2\nsection, use get_pairwise function epicontacts\npackage, allows us calculate pairwise differences linelist\nproperties transmission pairs. first create epicontacts object\n(see Transmission chains page details):fit difference onset dates transmission pairs, calculated\nusing get_pairwise, gamma distribution. use handy fit_disc_gamma\nepitrix package fitting procedure, require \ndiscretised distribution.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspect estimate\nserial_interval[c(\"mu\", \"sd\")]## $mu\n## [1] 11.51047\n## \n## $sd\n## [1] 7.696056"},{"path":"epidemic-modeling.html","id":"projecting-incidence-1","chapter":"24 Epidemic modeling","heading":"Projecting incidence","text":"project future incidence, still need provide historical incidence \nform incidence object, well sample plausible\nRt values. generate values using Rt\nestimates generated EpiEstim previous section (“Estimating\nRt”) stored epiestim_res_emp object. code ,\nextract mean standard deviation estimates Rt \nlast time window outbreak (using tail function access last\nelement vector), simulate 1000 values gamma distribution using\nrgamma. can also provide vector Rt values \nwant use forward projections.use project() function make actual forecast. specify \nmany days want project via n_days arguments, specify \nnumber simulations using n_sim argument.can handily plot incidence projections using plot() \nadd_projections() functions. can easily subset incidence object \nshow recent cases using square bracket operator.can also easily extract raw estimates daily case numbers \nconverting output dataframe.","code":"\n## create incidence object from dates of onset\ninc <- incidence::incidence(linelist$date_onset)## 256 missing observations were removed.\n## extract plausible r values from most recent estimate\nmean_r <- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r <- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale <- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r <- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## check distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## make projection\nproj <- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n## plot incidence and projections\nplot(inc[inc$dates > as.Date(\"2015-03-01\")]) %>%\n  add_projections(proj)\n## convert to data frame for raw data\nproj_df <- as.data.frame(proj)\nproj_df"},{"path":"epidemic-modeling.html","id":"resources-17","chapter":"24 Epidemic modeling","heading":"24.5 Resources","text":"paper describing\nmethodology implemented EpiEstim.paper describing\nmethodology implemented EpiNow2.paper describing\nvarious methodological practical considerations estimating Rt.","code":""},{"path":"contact-tracing-1.html","id":"contact-tracing-1","chapter":"25 Contact tracing","heading":"25 Contact tracing","text":"page demonstrates descriptive analysis contact tracing data, addessing key considerations approaches unique kinds data.page references many core R data management visualisation competencies covered pages (e.g. data cleaning, pivoting, tables, time-series analyses), highlight examples specific contact tracing useful operational decision making. example, includes visualizing contact tracing follow-data time across geographic areas, producing clean Key Performance Indicator (KPI) tables contact tracing supervisors.demonstration purposes use sample contact tracing data Go.Data platform. principles covered apply contact tracing data platforms - may just need undergo different data pre-processing steps depending structure data.can read Go.Data project Github Documentation site Community Practice.","code":""},{"path":"contact-tracing-1.html","id":"preparation-16","chapter":"25 Contact tracing","heading":"25.1 Preparation","text":"","code":""},{"path":"contact-tracing-1.html","id":"load-packages-16","chapter":"25 Contact tracing","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # importing data  \n  here,         # relative file pathways  \n  janitor,      # data cleaning and tables\n  lubridate,    # working with dates\n  epikit,       # age_categories() function\n  apyramid,     # age pyramids\n  tidyverse,    # data manipulation and visualization\n  RColorBrewer, # color palettes\n  formattable,  # fancy tables\n  kableExtra    # table formatting\n)"},{"path":"contact-tracing-1.html","id":"import-data-15","chapter":"25 Contact tracing","heading":"Import data","text":"import sample datasets contacts, “follow-”. data retrieved un-nested Go.Data API stored “.rds” files.can download example data handbook Download handbook data page.want download example contact tracing data specific page, use three download links :\nClick download\ncase investigation data (.rds file)\n\nClick download\ncontact registration data (.rds file)\n\nClick download\ncontact follow-data (.rds file)\noriginal form downloadable files, data reflect data provided Go.Data API (learn APIs ). example purposes , clean data make easier read page. using Go.Data instance, can view complete instructions retrieve data ., datasets imported using import() function rio package. See page Import export various ways import data. use () specify file path - provide file path specific computer. use select() select certain columns data, simplify purposes demonstration.","code":""},{"path":"contact-tracing-1.html","id":"case-data","chapter":"25 Contact tracing","heading":"Case data","text":"data table cases, information .nrow(cases) cases:","code":"\ncases <- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %>% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)"},{"path":"contact-tracing-1.html","id":"contacts-data","chapter":"25 Contact tracing","heading":"Contacts data","text":"data table contacts information . , provide file path. importing perform preliminary data cleaning steps including:Set age_class factor reverse level order younger ages firstSelect certain column, re-naming one themArtificially assign rows missing admin level 2 “Djembe”, improve clarity example visualisationsHere nrow(contacts) rows contacts dataset:","code":"\ncontacts <- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %>% \n  mutate(age_class = forcats::fct_rev(age_class)) %>% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %>% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))"},{"path":"contact-tracing-1.html","id":"follow-up-data","chapter":"25 Contact tracing","heading":"Follow-up data","text":"data records “follow-” interactions contacts. contact supposed encounter day 14 days exposure.import perform cleaning steps. select certain columns, also convert character column lowercase values.first 50 rows nrow(followups)-row followups dataset (row follow-interaction, outcome status followup_status column):","code":"\nfollowups <- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %>% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %>% \n  mutate(followup_status = str_to_lower(followup_status))"},{"path":"contact-tracing-1.html","id":"relationships-data","chapter":"25 Contact tracing","heading":"Relationships data","text":"import data showing relationship cases contacts. select certain column show.first 50 rows relationships dataset, records relationships cases contacts.","code":"\nrelationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)"},{"path":"contact-tracing-1.html","id":"descriptive-analyses","chapter":"25 Contact tracing","heading":"25.2 Descriptive analyses","text":"can use techniques covered pages handbook conduct descriptive analyses cases, contacts, relationships. examples.","code":""},{"path":"contact-tracing-1.html","id":"demographics","chapter":"25 Contact tracing","heading":"Demographics","text":"demonstrated page covering Demographic pyramids, can visualise age gender distribution (use apyramid package).","code":""},{"path":"contact-tracing-1.html","id":"age-and-gender-of-contacts","chapter":"25 Contact tracing","heading":"Age and Gender of contacts","text":"pyramid compares age distribution contacts, gender. Note contacts missing age included bar top. can change default behavior, consider listing number missing caption.Go.Data data structure, relationships dataset contains ages cases contacts, use dataset create age pyramid showing differences two groups people. relationships data frame mutated transform numberic age columns categories (see Cleaning data core functions page). also pivot dataframe longer facilitate easy plotting ggplot2 (see Pivoting data).Now can plot transformed dataset age_pyramid() , replacing gender category (contact, case).can also view characteristics occupational breakdown (e.g. form pie chart).","code":"\napyramid::age_pyramid(\n  data = contacts,                                   # use contacts dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"gender\") +                             # gender for halfs of pyramid\n  labs(\n    fill = \"Gender\",                                 # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # title of the plot\n  theme_minimal()                                    # simple background\nrelation_age <- relationships %>% \n  select(source_age, target_age) %>% \n  transmute(                              # transmute is like mutate() but removes all other columns not mentioned\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %>% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivot longer\n\n\nrelation_age## # A tibble: 200 × 2\n##    category         age_class\n##    <chr>            <fct>    \n##  1 source_age_class 80+      \n##  2 target_age_class 15-19    \n##  3 source_age_class <NA>     \n##  4 target_age_class 50-54    \n##  5 source_age_class <NA>     \n##  6 target_age_class 20-24    \n##  7 source_age_class 30-34    \n##  8 target_age_class 45-49    \n##  9 source_age_class 40-44    \n## 10 target_age_class 30-34    \n## # ℹ 190 more rows\napyramid::age_pyramid(\n  data = relation_age,                               # use modified relationship dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"category\") +                           # by cases and contacts\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # to specify colors AND labels\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts and cases\")+ # title of the plot\n  theme_minimal()                                              # simple background\n# Clean dataset and get counts by occupation\nocc_plot_data <- cases %>% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # make NA missing values a category\n         occupation = forcats::fct_infreq(occupation)) %>%   # order factor levels in order of frequency\n  count(occupation)                                          # get counts by occupation\n  \n# Make pie chart\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Known occupations of COVID-19 cases\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())"},{"path":"contact-tracing-1.html","id":"contacts-per-case","chapter":"25 Contact tracing","heading":"Contacts per case","text":"number contacts per case can important metric assess quality contact enumeration compliance population toward public health response.Depending data structure, can assessed dataset contains cases contacts. Go.Data datasets, links cases (“sources”) contacts (“targets”) stored relationships dataset.dataset, row contact, source case listed row. contacts relationships multiple cases, exists may need account plotting (explore !).begin counting number rows (contacts) per source case. saved data frame.use geom_histogram() plot data histogram.","code":"\ncontacts_per_case <- relationships %>% \n  count(source_visualid)\n\ncontacts_per_case## # A tibble: 23 × 2\n##    source_visualid     n\n##    <chr>           <int>\n##  1 CASE-2020-0001     13\n##  2 CASE-2020-0002      5\n##  3 CASE-2020-0003      2\n##  4 CASE-2020-0004      4\n##  5 CASE-2020-0005      5\n##  6 CASE-2020-0006      3\n##  7 CASE-2020-0008      3\n##  8 CASE-2020-0009      3\n##  9 CASE-2020-0010      3\n## 10 CASE-2020-0012      3\n## # ℹ 13 more rows\nggplot(data = contacts_per_case)+        # begin with count data frame created above\n  geom_histogram(mapping = aes(x = n))+  # print histogram of number of contacts per case\n  scale_y_continuous(expand = c(0,0))+   # remove excess space below 0 on y-axis\n  theme_light()+                         # simplify background\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )"},{"path":"contact-tracing-1.html","id":"contact-follow-up","chapter":"25 Contact tracing","heading":"25.3 Contact Follow Up","text":"Contact tracing data often contain “follow-” data, record outcomes daily symptom checks persons quarantine. Analysis data can inform response strategy, identify contacts -risk loss--follow--risk developing disease.","code":""},{"path":"contact-tracing-1.html","id":"data-cleaning","chapter":"25 Contact tracing","heading":"Data cleaning","text":"data can exist variety formats. may exist “wide” format Excel sheet one row per contact, one column per follow-“day”. See Pivoting data descriptions “long” “wide” data pivot data wider longer.Go.Data example, data stored followups data frame, “long” format one row per follow-interaction. first 50 rows look like :CAUTION: Beware duplicates dealing followup data; several erroneous followups day given contact. Perhaps seems error reflects reality - e.g. contact tracer submit follow-form early day reach contact, submit second form later reached. depend operational context want handle duplicates - just make sure document approach clearly. Let’s see many instances “duplicate” rows :example data, records applies ones missing ID! can remove . , purposes demonstration go show steps de-duplication one follow-encoutner per person per day. See page De-duplication detail. assume recent encounter record correct one. also take opportunity clean followup_number column (“day” follow-range 1 - 14).follow-encounter, follow-status (whether encounter occurred , contact symptoms ). see values can run quick tabyl() (janitor) table() (base R) (see Descriptive tables) followup_status see frequency outcomes.dataset, “seen_not_ok” means “seen symptoms”, “seen_ok” means “seen without symptoms”.","code":"\nfollowups %>% \n  count(contact_id, date_of_followup) %>%   # get unique contact_days\n  filter(n > 1)                             # view records where count is more than 1  ## # A tibble: 3 × 3\n##   contact_id date_of_followup     n\n##   <chr>      <date>           <int>\n## 1 <NA>       2020-09-03           2\n## 2 <NA>       2020-09-04           2\n## 3 <NA>       2020-09-05           2\nfollowups_clean <- followups %>%\n  \n  # De-duplicate\n  group_by(contact_id, date_of_followup) %>%        # group rows per contact-day\n  arrange(contact_id, desc(date_of_followup)) %>%   # arrange rows, per contact-day, by date of follow-up (most recent at top)\n  slice_head() %>%                                  # keep only the first row per unique contact id  \n  ungroup() %>% \n  \n  # Other cleaning\n  mutate(followup_number = replace(followup_number, followup_number > 14, NA)) %>% # clean erroneous data\n  drop_na(contact_id)                               # remove rows with missing contact_id\nfollowups_clean %>% \n  tabyl(followup_status)##  followup_status   n    percent\n##           missed  10 0.02325581\n##    not_attempted   5 0.01162791\n##    not_performed 319 0.74186047\n##      seen_not_ok   6 0.01395349\n##          seen_ok  90 0.20930233"},{"path":"contact-tracing-1.html","id":"plot-over-time","chapter":"25 Contact tracing","heading":"Plot over time","text":"dates data continuous, use histogram plot date_of_followup assigned x-axis. can achieve “stacked” histogram specifying fill = argument within aes(), assign column followup_status. Consequently, can set legend title using fill = argument labs().can see contacts identified waves (presumably corresponding epidemic waves cases), follow-completion seemingly improve course epidemic.CAUTION: preparing many plots (e.g. multiple jurisdictions) want legends appear identically even varying levels data completion data composition. may plots follow-statuses present data, still want categories appear legends. ggplots (like ), can specify drop = FALSE argument scale_fill_discrete(). tables, use tabyl() shows counts factor levels, using count() dplyr add argument .drop = FALSE include counts factor levels.","code":"\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # show all factor levels (followup_status) in the legend, even those not used\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # dynamic subtitle"},{"path":"contact-tracing-1.html","id":"daily-individual-tracking","chapter":"25 Contact tracing","heading":"Daily individual tracking","text":"outbreak small enough, may want look contact individually see status course follow-. Fortunately, followups dataset already contains column day “number” follow-(1-14). exist data, create calculating difference encounter date date follow-intended begin contact.convenient visualisation mechanism (number cases large) can heat plot, made geom_tile(). See details [heat plot] page.","code":"\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # grey gridlines\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))"},{"path":"contact-tracing-1.html","id":"analyse-by-group","chapter":"25 Contact tracing","heading":"Analyse by group","text":"Perhaps follow-data viewed daily weekly basis operational decision-making. may want meaningful disaggregations geographic area contact-tracing team. can adjusting columns provided group_by().","code":"\nplot_by_region <- followups_clean %>%                                        # begin with follow-up dataset\n  count(admin_1_name, admin_2_name, followup_status) %>%   # get counts by unique region-status (creates column 'n' with counts)\n  \n  # begin ggplot()\n  ggplot(                                         # begin ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # reorder admin factor levels by the numeric values in column 'n'\n                  y = n,                            # heights of bar from column 'n'\n                  fill = followup_status,           # color stacked bars by their status\n                  label = n))+                      # to pass to geom_label()              \n  geom_col()+                                     # stacked bars, mapping inherited from above \n  geom_text(                                      # add text, mapping inherited from above\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # Simplify background\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduce facets \n\nplot_by_region"},{"path":"contact-tracing-1.html","id":"kpi-tables","chapter":"25 Contact tracing","heading":"25.4 KPI Tables","text":"number different Key Performance Indicators (KPIs) can calculated tracked varying levels disaggregations across different time periods monitor contact tracing performance. calculations basic table format; fairly easy swap different KPIs.numerous sources contact tracing KPIs, one ResolveToSaveLives.org. majority work walking data structure thinking inclusion/exclusion criteria. show examples ; using Go.Data metadata structure:walk sample exercise creating nice table visual show contact follow-across admin areas. end, make fit presentation formattable package (use packages like flextable - see Tables presentation).create table like depend structure contact tracing data. Use Descriptive tables page learn summarise data using dplyr functions.create table dynamic change data change. make results interesting, set report_date allow us simulate running table certain day (pick 10th June 2020). data filtered date.Now, based data structure, following:Begin followups data summarise contain, unique contact:date latest record (matter status encounter)date latest encounter contact “seen”encounter status final “seen” encounter (e.g. symptoms, without symptoms)Join data contacts data, contains information overall contact status, date last exposure case, etc. Also calculate metrics interest contact days since last exposureWe group enhanced contact data geographic region (admin_2_name) calculate summary statistics per regionFinally, format table nicely presentationFirst summarise follow-data get information interest:data look:Now add information contacts dataset, calculate additional columns.data look. Note contacts column right, new calculated column far right.Next summarise contacts data region, achieve concise data frame summary statistic columns.now apply styling formattable knitr packages, including footnote shows “” date.","code":"\n# Set \"Report date\" to simulate running the report with data \"as of\" this date\nreport_date <- as.Date(\"2020-06-10\")\n\n# Create follow-up data to reflect the report date.\ntable_data <- followups_clean %>% \n  filter(date_of_followup <= report_date)\nfollowup_info <- table_data %>% \n  group_by(contact_id) %>% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %>% \n  ungroup()\ncontacts_info <- followup_info %>% \n  right_join(contacts, by = \"contact_id\") %>% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\ncontacts_table <- contacts_info %>% \n  \n  group_by(`Admin 2` = admin_2_name) %>%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure < 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure >= 8 & days_since_exposure < 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen >= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %>% \n    \n  arrange(desc(`Registered contacts`))\ncontacts_table %>%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %>%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %>%\n  kable_styling(\"hover\", full_width = FALSE) %>%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %>% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))"},{"path":"contact-tracing-1.html","id":"transmission-matrices","chapter":"25 Contact tracing","heading":"25.5 Transmission Matrices","text":"discussed Heat plots page, can create matrix “infected ” using geom_tile().new contacts created, Go.Data stores relationship information relationships API endpoint; can see first 50 rows dataset . means can create heat plot relatively steps given contact already joined ’s source case.done age pyramid comparing cases contacts, can select variables need create columns categorical age groupings sources (cases) targets (contacts).described previously, create cross-tabulation;convert long format proportions;create heat-map age.","code":"\nheatmap_ages <- relationships %>% \n  select(source_age, target_age) %>% \n  mutate(                              # transmute is like mutate() but removes all other columns\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \ncross_tab <- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab##             target_cases\n## source_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79 80+\n##        0-4     0   0     0     0     0     0     0     0     0     1     0     1     0     0     0     0   0\n##        5-9     0   0     1     0     0     0     0     1     0     0     0     1     0     0     0     0   0\n##        10-14   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        15-19   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        20-24   1   1     0     1     2     0     2     1     0     0     0     1     0     0     0     0   1\n##        25-29   1   2     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        30-34   0   0     0     0     0     0     0     0     1     1     0     1     0     0     0     0   0\n##        35-39   0   2     0     0     0     0     0     0     0     1     0     0     0     0     0     0   0\n##        40-44   0   0     0     0     1     0     2     1     0     3     1     1     0     0     0     1   1\n##        45-49   1   2     2     0     0     0     3     0     1     0     3     2     1     0     0     0   1\n##        50-54   1   2     1     2     0     0     1     0     0     3     4     1     0     1     0     0   1\n##        55-59   0   1     0     0     1     1     2     0     0     0     0     0     0     0     0     0   0\n##        60-64   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        65-69   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        70-74   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        75-79   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   0\n##        80+     1   0     0     2     1     0     0     0     1     0     0     0     0     0     0     0   0\nlong_prop <- data.frame(prop.table(cross_tab))\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = target_cases,         # x-axis is case age\n      y = source_cases,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # labels\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"contact-tracing-1.html","id":"resources-18","chapter":"25 Contact tracing","heading":"25.6 Resources","text":"https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reportinghttps://worldhealthorganization.github.io/godata/https://community-godata..int/","code":""},{"path":"survey-analysis.html","id":"survey-analysis","chapter":"26 Survey analysis","heading":"26 Survey analysis","text":"","code":""},{"path":"survey-analysis.html","id":"overview-4","chapter":"26 Survey analysis","heading":"26.1 Overview","text":"page demonstrates use several packages survey analysis.survey R packages rely survey package\nweighted analysis.\nuse survey well srvyr\n(wrapper survey allowing tidyverse-style coding) \ngtsummary\n(wrapper survey allowing publication ready tables).\noriginal survey package allow tidyverse-style coding,\nadded benefit allowing survey-weighted generalised linear\nmodels (added page later date).\nalso demonstrate using function sitrep\npackage create sampling weights (n.b package currently yet CRAN,\ncan installed github).page based work done “R4Epis” project;\ndetailed code R-markdown templates see “R4Epis” github page.\nsurvey package based code based early versions \nEPIET case studies.current page address sample size calculations sampling.\nsimple use sample size calculator see OpenEpi.\nGIS basics page handbook\neventually section spatial random sampling, page \neventually section sampling frames well sample size calculations.Survey dataObservation timeWeightingSurvey design objectsDescriptive analysisWeighted proportionsWeighted rates","code":""},{"path":"survey-analysis.html","id":"preparation-17","chapter":"26 Survey analysis","heading":"26.2 Preparation","text":"","code":""},{"path":"survey-analysis.html","id":"packages-3","chapter":"26 Survey analysis","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.\nalso demonstrate using p_load_gh() function pacman install load package github yet published CRAN.","code":"\n## load packages from CRAN\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               survey,       # for survey functions\n               srvyr,        # dplyr wrapper for survey package\n               gtsummary,    # wrapper for survey package to produce tables\n               apyramid,     # a package dedicated to creating age pyramids\n               patchwork,    # for combining ggplots\n               ggforce       # for alluvial/sankey plots\n               ) \n\n## load packages from github\npacman::p_load_gh(\n     \"R4EPI/sitrep\"          # for observation time / weighting functions\n)"},{"path":"survey-analysis.html","id":"load-data-1","chapter":"26 Survey analysis","heading":"Load data","text":"example dataset used section:fictional mortality survey data.fictional population counts survey area.data dictionary fictional mortality survey data.based MSF OCA ethical review board pre-approved survey. \nfictional dataset produced part “R4Epis” project.\nbased data collected using KoboToolbox,\ndata collection software based Open Data Kit.Kobo allows export collected data, well data dictionary\ndataset. strongly recommend simplifies data cleaning\nuseful looking variables/questions.TIP: Kobo data dictionary variable\nnames “name” column survey sheet.\nPossible values variable specified choices sheet.\nchoices tab, “name” shortened value “label::english” \n“label::french” columns appropriate long versions.\nUsing epidict package msf_dict_survey() function import Kobo\ndictionary excel file re-format can used easily recode. CAUTION: example dataset \nexport (Kobo export different questionnaire levels individually)\n- see survey data section merge different levels.dataset imported using import() function rio package. See page Import export various ways import data.first 10 rows survey displayed .also want import data sampling population can produce\nappropriate weights. data can different formats, however \nsuggest seen (can just typed excel).first 10 rows survey displayed .cluster surveys may want add survey weights cluster level.\nread data .\nAlternatively counts, entered \ntibble.\ncase need one column cluster identifier \nmatches survey data, another column number households \ncluster.","code":"\n# import the survey data\nsurvey_data <- rio::import(\"survey_data.xlsx\")\n\n# import the dictionary into R\nsurvey_dict <- rio::import(\"survey_dict.xlsx\") \n# import the population data\npopulation <- rio::import(\"population.xlsx\")\n## define the number of households in each cluster\ncluster_counts <- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))"},{"path":"survey-analysis.html","id":"clean-data-2","chapter":"26 Survey analysis","heading":"Clean data","text":"makes sure date column appropriate format.\nseveral ways (see Working dates\npage details), however using dictionary define dates quick easy.also create age group variable using age_categories() function \nepikit - see cleaning data\nhandbook section details.\naddition, create character variable defining district various clusters\n.Finally, recode yes/variables TRUE/FALSE variables - otherwise\ncant used survey proportion functions.","code":"\n## select the date variable names from the dictionary \nDATEVARS <- survey_dict %>% \n  filter(type == \"date\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filter to match the column names of your data\n  pull(name) # select date vars\n  \n## change to dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## add those with only age in months to the year variable (divide by twelve)\nsurvey_data <- survey_data %>% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## define age group variable\nsurvey_data <- survey_data %>% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## create a character variable based off groups of a different variable \nsurvey_data <- survey_data %>% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## select the yes/no variable names from the dictionary \nYNVARS <- survey_dict %>% \n  filter(type == \"yn\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filter to match the column names of your data\n  pull(name) # select yn vars\n  \n## change to dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))"},{"path":"survey-analysis.html","id":"survey-data","chapter":"26 Survey analysis","heading":"26.3 Survey data","text":"numerous different sampling designs can used surveys. \ndemonstrate code :\n- Stratified\n- Cluster\n- Stratified clusterAs described (depending design questionnaire) data \nlevel exported separate dataset Kobo. example \none level households one level individuals within households.two levels linked unique identifier.\nKobo dataset variable “_index” household level, \nmatches “_parent_index” individual level.\ncreate new rows household matching individual,\nsee handbook section joining\ndetails.","code":"\n## join the individual and household data to form a complete data set\nsurvey_data <- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## create a unique identifier by combining indeces of the two levels \nsurvey_data <- survey_data %>% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))"},{"path":"survey-analysis.html","id":"observation-time","chapter":"26 Survey analysis","heading":"26.4 Observation time","text":"mortality surveys want now long individual present \nlocation able calculate appropriate mortality rate period\ninterest. relevant surveys, particularly mortality\nsurveys important conducted frequently among mobile displaced\npopulations.first define time period interest, also known recall\nperiod (.e. time participants asked report answering\nquestions).\ncan use period set inappropriate dates missing, .e. deaths\nreported outside period interest.can use date variables define start end dates individual.\ncan use find_start_date() function sitrep fine causes \ndates use calculate difference days (person-time).start date:\nEarliest appropriate arrival event within recall period\nEither beginning recall period (define advance), \ndate start recall applicable (e.g. arrivals births)end date:\nEarliest appropriate departure event within recall period\nEither end recall period, date end recall\napplicable (e.g. departures, deaths)","code":"\n## set the start/end of recall period\n## can be changed to date variables from dataset \n## (e.g. arrival date & date questionnaire)\nsurvey_data <- survey_data %>% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end   = as.Date(\"2018-05-01\")\n  )\n\n\n# set inappropriate dates to NA based on rules \n## e.g. arrivals before start, departures departures after end\nsurvey_data <- survey_data %>%\n      mutate(\n           arrived_date = if_else(arrived_date < recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date < recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date > recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date > recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n## create new variables for start and end dates/causes\nsurvey_data <- survey_data %>% \n     ## choose earliest date entered in survey\n     ## from births, household arrivals, and camp arrivals \n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end   = \"recall_end\",\n                  datecol      = \"startdate\",\n                  datereason   = \"startcause\" \n                 ) %>%\n     ## choose earliest date entered in survey\n     ## from camp departures, death and end of the study\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end   = \"recall_end\",\n                datecol      = \"enddate\",\n                datereason   = \"endcause\" \n               )\n\n\n## label those that were present at the start/end (except births/deaths)\nsurvey_data <- survey_data %>% \n     mutate(\n       ## fill in start date to be the beginning of recall period (for those empty) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## set the start cause to present at start if equal to recall period \n       ## unless it is equal to the birth date \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## fill in end date to be end of recall period (for those empty) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## set the end cause to present at end if equall to recall end \n       ## unless it is equal to the death date\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Define observation time in days\nsurvey_data <- survey_data %>% \n  mutate(obstime = as.numeric(enddate - startdate))"},{"path":"survey-analysis.html","id":"weighting","chapter":"26 Survey analysis","heading":"26.5 Weighting","text":"important drop erroneous observations adding survey weights.\nexample observations negative observation time, need\ncheck (can assert_positive_timespan() function\nsitrep.\nAnother thing want drop empty rows (e.g. drop_na(uid))\nremove duplicates (see handbook section De-duplication\ndetails).\nwithout consent need dropped .example filter cases want drop store separate\ndata frame - way can describe excluded survey.\nuse anti_join() function dplyr remove dropped cases\nsurvey data.DANGER: cant missing values weight variable, variables relevant survey design (e.g. age, sex, strata cluster variables).mentioned demonstrate add weights three different study\ndesigns (stratified, cluster stratified cluster). require information\nsource population /clusters surveyed.\nuse stratified cluster code example, use whichever \nappropriate study design.","code":"\n## store the cases that you drop so you can describe them (e.g. non-consenting \n## or wrong village/cluster)\ndropped <- survey_data %>% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## use the dropped cases to remove the unused rows from the survey data set  \nsurvey_data <- anti_join(survey_data, dropped, by = names(dropped))\n# stratified ------------------------------------------------------------------\n# create a variable called \"surv_weight_strata\"\n# contains weights for each individual - by age group, sex and health district\nsurvey_data <- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# get the number of people of individuals interviewed per household\n# adds a variable with counts of the household (parent) index variable\nsurvey_data <- survey_data %>%\n  add_count(index, name = \"interviewed\")\n\n\n## create cluster weights\nsurvey_data <- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# stratified and cluster ------------------------------------------------------\n# create a survey weight for cluster and strata\nsurvey_data <- survey_data %>%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)"},{"path":"survey-analysis.html","id":"survey-design-objects","chapter":"26 Survey analysis","heading":"26.6 Survey design objects","text":"Create survey object according study design.\nUsed way data frames calculate weight proportions etc.\nMake sure necessary variables created .four options, comment use:\n- Simple random\n- Stratified\n- Cluster\n- Stratified clusterFor template - pretend cluster surveys two separate\nstrata (health districts B).\nget overall estimates need combined cluster strata weights.mentioned previously, two packages available . \nclassic one survey wrapper package called srvyr\nmakes tidyverse-friendly objects functions. demonstrate ,\nnote code chapter use srvyr based objects.\none exception gtsummary package accepts survey objects.","code":""},{"path":"survey-analysis.html","id":"survey-package","chapter":"26 Survey analysis","heading":"26.6.1 Survey package","text":"survey package effectively uses base R coding, \npossible use pipes (%>%) dplyr syntax.\nsurvey package use svydesign() function define survey\nobject appropriate clusters, weights strata.NOTE: need use tilde (~) front variables, package uses base R syntax assigning variables based formulae. ","code":"\n# simple random ---------------------------------------------------------------\nbase_survey_design_simple <- svydesign(ids = ~1, # 1 for no cluster ids\n                   weights = NULL,               # No weight added\n                   strata = NULL,                # sampling was simple (no strata)\n                   data = survey_data            # have to specify the dataset\n                  )\n\n## stratified ------------------------------------------------------------------\nbase_survey_design_strata <- svydesign(ids = ~1,  # 1 for no cluster ids\n                   weights = ~surv_weight_strata, # weight variable created above\n                   strata = ~health_district,     # sampling was stratified by district\n                   data = survey_data             # have to specify the dataset\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster <- svydesign(ids = ~village_name, # cluster ids\n                   weights = ~surv_weight_cluster, # weight variable created above\n                   strata = NULL,                 # sampling was simple (no strata)\n                   data = survey_data              # have to specify the dataset\n                  )\n\n# stratified cluster ----------------------------------------------------------\nbase_survey_design <- svydesign(ids = ~village_name,      # cluster ids\n                   weights = ~surv_weight_cluster_strata, # weight variable created above\n                   strata = ~health_district,             # sampling was stratified by district\n                   data = survey_data                     # have to specify the dataset\n                  )"},{"path":"survey-analysis.html","id":"srvyr-package","chapter":"26 Survey analysis","heading":"26.6.2 Srvyr package","text":"srvyr package can use as_survey_design() function, \narguments allows pipes (%>%), \nneed use tilde (~).","code":"\n## simple random ---------------------------------------------------------------\nsurvey_design_simple <- survey_data %>% \n  as_survey_design(ids = 1, # 1 for no cluster ids \n                   weights = NULL, # No weight added\n                   strata = NULL # sampling was simple (no strata)\n                  )\n## stratified ------------------------------------------------------------------\nsurvey_design_strata <- survey_data %>%\n  as_survey_design(ids = 1, # 1 for no cluster ids\n                   weights = surv_weight_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster <- survey_data %>%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster, # weight variable created above\n                   strata = NULL # sampling was simple (no strata)\n                  )\n\n## stratified cluster ----------------------------------------------------------\nsurvey_design <- survey_data %>%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )"},{"path":"survey-analysis.html","id":"descriptive-analysis-2","chapter":"26 Survey analysis","heading":"26.7 Descriptive analysis","text":"Basic descriptive analysis visualisation covered extensively \nchapters handbook, dwell .\ndetails see chapters descriptive tables,\nstatistical tests,\ntables presentation,\nggplot basics \nR markdown reports.section focus investigate bias sample visualise .\nalso look visualising population flow survey setting using\nalluvial/sankey diagrams.general, consider including following descriptive analyses:Final number clusters, households individuals includedNumber excluded individuals reasons exclusionMedian (range) number households per cluster individuals per household","code":""},{"path":"survey-analysis.html","id":"sampling-bias","chapter":"26 Survey analysis","heading":"26.7.1 Sampling bias","text":"Compare proportions age group sample \nsource population.\nimportant able highlight potential sampling bias.\nsimilarly repeat looking distributions sex.Note p-values just indicative, descriptive discussion (\nvisualisation age-pyramids ) distributions study sample\ncompared source population important binomial test .\nincreasing sample size often lead \ndifferences may irrelevant weighting data.","code":"\n## counts and props of the study population\nag <- survey_data %>% \n  group_by(age_group) %>% \n  drop_na(age_group) %>% \n  tally() %>% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## counts and props of the source population\npropcount <- population %>% \n  group_by(age_group) %>%\n    tally(population) %>%\n    mutate(proportion = n / sum(n))\n\n## bind together the columns of two tables, group by age, and perform a \n## binomial test to see if n/total is significantly different from population\n## proportion.\n  ## suffix here adds to text to the end of columns in each of the two datasets\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %>%\n  group_by(age_group) %>%\n  ## broom::tidy(binom.test()) makes a data frame out of the binomial test and\n  ## will add the variables p.value, parameter, conf.low, conf.high, method, and\n  ## alternative. We will only use p.value here. You can include other\n  ## columns if you want to report confidence intervals\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %>%\n  unnest(cols = c(binom)) %>% # important for expanding the binom.test data frame\n  mutate(proportion_pop = proportion_pop * 100) %>%\n  ## Adjusting the p-values to correct for false positives \n  ## (because testing multiple age groups). This will only make \n  ## a difference if you have many age categories\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %>%\n                      \n  ## Only show p-values over 0.001 (those under report as <0.001)\n  mutate(p.value = ifelse(p.value < 0.001, \n                          \"<0.001\", \n                          as.character(round(p.value, 3)))) %>% \n  \n  ## rename the columns appropriately\n  select(\n    \"Age group\" = age_group,\n    \"Study population (n)\" = n,\n    \"Study population (%)\" = proportion,\n    \"Source population (n)\" = n_pop,\n    \"Source population (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )## # A tibble: 5 × 6\n## # Groups:   Age group [5]\n##   `Age group` `Study population (n)` `Study population (%)` `Source population (n)` `Source population (%)` `P-value`\n##   <chr>                        <int>                  <dbl>                   <dbl>                   <dbl> <chr>    \n## 1 0-2                             12                 0.0256                    1360                     6.8 <0.001   \n## 2 3-14                            42                 0.0896                    7244                    36.2 <0.001   \n## 3 15-29                           64                 0.136                     5520                    27.6 <0.001   \n## 4 30-44                           52                 0.111                     3232                    16.2 0.002    \n## 5 45+                            299                 0.638                     2644                    13.2 <0.001"},{"path":"survey-analysis.html","id":"demographic-pyramids","chapter":"26 Survey analysis","heading":"26.7.2 Demographic pyramids","text":"Demographic (age-sex) pyramids easy way visualising distribution\nsurvey population. also worth considering creating\ndescriptive tables age\nsex survey strata.\ndemonstrate using apyramid package allows weighted\nproportions using survey design object created . options creating\ndemographic pyramids\ncovered extensively chapter handbook. also use \nwrapper function apyramid called age_pyramid() saves lines\ncoding producing plot proportions.formal binomial test difference, seen sampling bias\nsection, interested visualising whether sampled population\nsubstantially different source population whether weighting corrects\ndifference. use patchwork package show \nggplot visualisations side--side; details see section \ncombining plots ggplot tips\nchapter handbook.\nvisualise source population, un-weighted survey population \nweighted survey population.\nmay also consider visualising strata survey - example\nusing argument stack_by  = \"health_district\"\n(see ?plot_age_pyramid details).NOTE: x y axes flipped pyramids ","code":"\n## define x-axis limits and labels ---------------------------------------------\n## (update these numbers to be the values for your graph)\nmax_prop <- 35      # choose the highest proportion you want to show \nstep <- 5           # choose the space you want beween labels \n\n## this part defines vector using the above numbers with axis breaks\nbreaks <- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## this part defines vector using the above numbers with axis limits\nlimits <- c(max_prop/100 * -1, max_prop/100)\n\n## this part defines vector using the above numbers with axis labels\nlabels <-  c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## create plots individually  --------------------------------------------------\n\n## plot the source population \n## nb: this needs to be collapsed for the overall population (i.e. removing health districts)\nsource_population <- population %>%\n  ## ensure that age and sex are factors\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %>% \n  group_by(age_group, sex) %>% \n  ## add the counts for each health district together \n  summarise(population = sum(population)) %>% \n  ## remove the grouping so can calculate overall proportion\n  ungroup() %>% \n  mutate(proportion = population / sum(population)) %>% \n  ## plot pyramid \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## only show the y axis label (otherwise repeated in all three plots)\n  labs(title = \"Source population\", \n       y = \"\", \n       x = \"Age group (years)\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## plot the unweighted sample population \nsample_population <- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Unweighted sample population\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## plot the weighted sample population \nweighted_population <- survey_design %>% \n  ## make sure the variables are factors\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %>%\n  age_pyramid(\n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Weighted sample population\", \n       y = \"\", \n       x = \"\")  + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combine all three plots  ----------------------------------------------------\n## combine three plots next to eachother using + \nsource_population + sample_population + weighted_population + \n  ## only show one legend and define theme \n  ## note the use of & for combining theme with plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\",                    # move legend to bottom\n        legend.title = element_blank(),                # remove title\n        text = element_text(size = 18),                # change text size\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # turn x-axis text\n       )"},{"path":"survey-analysis.html","id":"alluvialsankey-diagram","chapter":"26 Survey analysis","heading":"26.7.3 Alluvial/sankey diagram","text":"Visualising starting points outcomes individuals can helpful \nget overview. quite obvious application mobile populations,\nhowever numerous applications cohorts situation\ntransitions states individuals. diagrams several\ndifferent names including alluvial, sankey parallel sets - details \nhandbook chapter diagrams charts.","code":"\n## summarize data\nflow_table <- survey_data %>%\n  count(startcause, endcause, sex) %>%  # get counts \n  gather_set_data(x = c(\"startcause\", \"endcause\"))     # change format for plotting\n\n\n## plot your dataset \n  ## on the x axis is the start and end causes\n  ## gather_set_data generates an ID for each possible combination\n  ## splitting by y gives the possible start/end combos\n  ## value as n gives it as counts (could also be changed to proportion)\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colour lines by sex \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +\n  ## fill in the label boxes grey\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") +\n  ## change text colour and angle (needs to be adjusted)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) +\n  ## remove axis labels\n  theme_void()+\n  ## move legend to bottom\n  theme(legend.position = \"bottom\")               "},{"path":"survey-analysis.html","id":"weighted-proportions","chapter":"26 Survey analysis","heading":"26.8 Weighted proportions","text":"section detail produce tables weighted counts proportions,\nassociated confidence intervals design effect.\nfour different options using functions following packages:\nsurvey, srvyr, sitrep gtsummary.\nminimal coding produce standard epidemiology style table, \nrecommend sitrep function - wrapper srvyr code; note\nhowever yet CRAN may change future.\nOtherwise, survey code likely stable long-term, whereas\nsrvyr fit nicely within tidyverse work-flows. gtsummary\nfunctions hold lot potential, appear experimental incomplete\ntime writing.","code":""},{"path":"survey-analysis.html","id":"survey-package-1","chapter":"26 Survey analysis","heading":"26.8.1 Survey package","text":"can use svyciprop() function survey get weighted proportions\naccompanying 95% confidence intervals. appropriate design effect can \nextracted using svymean() rather svyprop() function.\nworth noting svyprop() appears accept variables 0 \n1 (TRUE/FALSE), categorical variables work.NOTE: Functions survey also accept srvyr design objects, used survey design object just consistency can combine functions survey shown function \ndefine , called svy_prop; can use function\ntogether map() purrr package iterate several variables\ncreate table. See handbook iteration\nchapter details purrr.","code":"\n## produce weighted counts \nsvytable(~died, base_survey_design)## died\n##      FALSE       TRUE \n## 1406244.43   76213.01\n## produce weighted proportions\nsvyciprop(~died, base_survey_design, na.rm = T)##               2.5% 97.5%\n## died 0.0514 0.0208  0.12\n## get the design effect \nsvymean(~died, base_survey_design, na.rm = T, deff = T) %>% \n  deff()## diedFALSE  diedTRUE \n##  3.755508  3.755508\n# Define function to calculate weighted counts, proportions, CI and design effect\n# x is the variable in quotation marks \n# design is your survey design object\n\nsvy_prop <- function(design, x) {\n  \n  ## put the variable of interest in a formula \n  form <- as.formula(paste0( \"~\" , x))\n  ## only keep the TRUE column of counts from svytable\n  weighted_counts <- svytable(form, design)[[2]]\n  ## calculate proportions (multiply by 100 to get percentages)\n  weighted_props <- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extract the confidence intervals and multiply to get percentages\n  weighted_confint <- confint(weighted_props) * 100\n  ## use svymean to calculate design effect and only keep the TRUE column\n  design_eff <- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combine in to one data frame\n  full_table <- cbind(\n    \"Variable\"        = x,\n    \"Count\"           = weighted_counts,\n    \"Proportion\"      = weighted_props,\n    weighted_confint, \n    \"Design effect\"   = design_eff\n    )\n  \n  ## return table as a dataframe\n  full_table <- data.frame(full_table, \n             ## remove the variable names from rows (is a separate column now)\n             row.names = NULL)\n  \n  ## change numerics back to numeric\n  full_table[ , 2:6] <- as.numeric(full_table[, 2:6])\n  \n  ## return dataframe\n  full_table\n}\n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  svy_prop, design = base_survey_design) %>% \n  ## collapse list in to a single data frame\n  bind_rows() %>% \n  ## round \n  mutate(across(where(is.numeric), round, digits = 1))##   Variable    Count Proportion X2.5. X97.5. Design.effect\n## 1     left 701199.1       47.3  39.2   55.5           2.4\n## 2     died  76213.0        5.1   2.1   12.1           3.8\n## 3  arrived 761799.0       51.4  40.9   61.7           3.9"},{"path":"survey-analysis.html","id":"srvyr-package-1","chapter":"26 Survey analysis","heading":"26.8.2 Srvyr package","text":"srvyr can use dplyr syntax create table. Note \nsurvey_mean() function used proportion argument specified, \nalso function used calculate design effect. \nsrvyr wraps around survey package functions svyciprop() \nsvymean(), used section.NOTE: seem possible get proportions categorical variables using srvyr either, need check section using sitrep write function iterate multiple variables using\npurrr package.\nSee handbook iteration\nchapter details purrr.","code":"\n## use the srvyr design object\nsurvey_design %>% \n  summarise(\n    ## produce the weighted counts \n    counts = survey_total(died), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(died, deff = TRUE)) %>% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(counts, props, props_low, props_upp, deff_deff)## # A tibble: 1 × 5\n##   counts props props_low props_upp deff_deff\n##    <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n## 1 76213.  5.14      2.08      12.1      3.76\n# Define function to calculate weighted counts, proportions, CI and design effect\n# design is your survey design object\n# x is the variable in quotation marks \n\n\nsrvyr_prop <- function(design, x) {\n  \n  summarise(\n    ## using the survey design object\n    design, \n    ## produce the weighted counts \n    counts = survey_total(.data[[x]]), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(.data[[x]], deff = TRUE)) %>% \n  ## add in the variable name\n  mutate(variable = x) %>% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  ~srvyr_prop(.x, design = survey_design)) %>% \n  ## collapse list in to a single data frame\n  bind_rows()## # A tibble: 3 × 6\n##   variable  counts props props_low props_upp deff_deff\n##   <chr>      <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n## 1 left     701199. 47.3      39.2       55.5      2.38\n## 2 died      76213.  5.14      2.08      12.1      3.76\n## 3 arrived  761799. 51.4      40.9       61.7      3.93"},{"path":"survey-analysis.html","id":"sitrep-package","chapter":"26 Survey analysis","heading":"26.8.3 Sitrep package","text":"tab_survey() function sitrep wrapper srvyr, allowing\ncreate weighted tables minimal coding. also allows calculate\nweighted proportions categorical variables.","code":"\n## using the survey design object\nsurvey_design %>% \n  ## pass the names of variables of interest unquoted\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE,   # calculate the design effect\n             pretty = TRUE  # merge the proportion and 95%CI\n             )## Warning: removing 257 missing value(s) from `education_level`## # A tibble: 9 × 5\n##   variable        value            n  deff ci               \n##   <chr>           <chr>        <dbl> <dbl> <chr>            \n## 1 arrived         TRUE       761799.  3.93 51.4% (40.9-61.7)\n## 2 arrived         FALSE      720658.  3.93 48.6% (38.3-59.1)\n## 3 left            TRUE       701199.  2.38 47.3% (39.2-55.5)\n## 4 left            FALSE      781258.  2.38 52.7% (44.5-60.8)\n## 5 died            TRUE        76213.  3.76 5.1% (2.1-12.1)  \n## 6 died            FALSE     1406244.  3.76 94.9% (87.9-97.9)\n## 7 education_level higher     171644.  4.70 42.4% (26.9-59.7)\n## 8 education_level primary    102609.  2.37 25.4% (16.2-37.3)\n## 9 education_level secondary  130201.  6.68 32.2% (16.5-53.3)"},{"path":"survey-analysis.html","id":"gtsummary-package","chapter":"26 Survey analysis","heading":"26.8.4 Gtsummary package","text":"gtsummary seem inbuilt functions yet add confidence\nintervals design effect.\nshow define function adding confidence intervals \nadd confidence intervals gtsummary table created using tbl_svysummary()\nfunction.","code":"\nconfidence_intervals <- function(data, variable, by, ...) {\n  \n  ## extract the confidence intervals and multiply to get percentages\n  props <- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## extract the confidence intervals \n  as.numeric(confint(props) * 100) %>% ## make numeric and multiply for percentage\n    round(., digits = 1) %>%           ## round to one digit\n    c(.) %>%                           ## extract the numbers from matrix\n    paste0(., collapse = \"-\")          ## combine to single character\n}\n\n## using the survey package design object\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died),   ## define variables want to include\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %>% ## define stats of interest\n  add_n() %>%  ## add the weighted total \n  add_stat(fns = everything() ~ confidence_intervals) %>% ## add CIs\n  ## modify the column headers\n  modify_header(\n    list(\n      n ~ \"**Weighted total (N)**\",\n      stat_0 ~ \"**Weighted Count**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )"},{"path":"survey-analysis.html","id":"weighted-ratios","chapter":"26 Survey analysis","heading":"26.9 Weighted ratios","text":"Similarly weighted ratios (mortality ratios) can use \nsurvey srvyr package.\nsimilarly write functions (similar ) iterate \nseveral variables. also create function gtsummary \ncurrently inbuilt functionality.","code":""},{"path":"survey-analysis.html","id":"survey-package-2","chapter":"26 Survey analysis","heading":"26.9.1 Survey package","text":"","code":"\nratio <- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci <- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)##       obstime    2.5 %   97.5 %\n## died 5.981922 1.194294 10.76955"},{"path":"survey-analysis.html","id":"srvyr-package-2","chapter":"26 Survey analysis","heading":"26.9.2 Srvyr package","text":"","code":"\nsurvey_design %>% \n  ## survey ratio used to account for observation time \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )## # A tibble: 1 × 3\n##   mortality mortality_low mortality_upp\n##       <dbl>         <dbl>         <dbl>\n## 1      5.98         0.349          11.6"},{"path":"survey-analysis.html","id":"resources-19","chapter":"26 Survey analysis","heading":"26.10 Resources","text":"UCLA stats pageAnalyze survey data freesrvyr packgegtsummary packageEPIET survey case studies","code":""},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"27 Survival analysis","heading":"27 Survival analysis","text":"","code":""},{"path":"survival-analysis.html","id":"overview-5","chapter":"27 Survival analysis","heading":"27.1 Overview","text":"Survival analysis focuses describing given individual group individuals, defined point event called failure (occurrence disease, cure disease, death, relapse response treatment…) occurs period time called failure time (follow-time cohort/population-based studies) individuals observed. determine failure time, necessary define time origin (can inclusion date, date diagnosis…).target inference survival analysis time origin event.\ncurrent medical research, widely used clinical studies assess effect treatment instance, cancer epidemiology assess large variety cancer survival measures.usually expressed survival probability probability event interest occurred duration t.Censoring: Censoring occurs end follow-, individuals event interest, thus true time event unknown. mostly focus right censoring details censoring survival analysis general, can see references.","code":""},{"path":"survival-analysis.html","id":"preparation-18","chapter":"27 Survival analysis","heading":"27.2 Preparation","text":"","code":""},{"path":"survival-analysis.html","id":"load-packages-17","chapter":"27 Survival analysis","heading":"Load packages","text":"run survival analyses R, one widely used package survival package. first install load well packages used section:handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.page explores survival analyses using linelist used previous pages apply changes proper survival data.","code":""},{"path":"survival-analysis.html","id":"import-dataset","chapter":"27 Survival analysis","heading":"Import dataset","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).","code":"\n# import linelist\nlinelist_case_data <- rio::import(\"linelist_cleaned.rds\")"},{"path":"survival-analysis.html","id":"data-management-and-transformation","chapter":"27 Survival analysis","heading":"Data management and transformation","text":"short, survival data can described following three characteristics:dependent variable response waiting time occurrence well-defined event,observations censored, sense units event interest occurred time data analyzed, andthere predictors explanatory variables whose effect waiting time wish assess control.Thus, create different variables needed respect structure run survival analysis.define:new data frame linelist_surv analysisour event interest “death” (hence survival probability probability alive certain time time origin),follow-time (futime) time time onset time outcome days,censored patients recovered final outcome known ie event “death” observed (event=0).CAUTION: Since real cohort study, information time origin end follow-known given individuals observed, remove observations date onset date outcome unknown. Also cases date onset later date outcome removed since considered wrong.TIP: Given filtering greater (>) less (<) date can remove rows missing values, applying filter wrong dates also remove rows missing dates.use case_when() create column age_cat_small 3 age categories.TIP: can verify new columns created summary futime cross-tabulation event outcome created. Besides verification good habit communicate median follow-time interpreting survival analysis results.Now cross-tabulate new age_cat_small var old age_cat col ensure correct assingmentsNow review 10 first observations linelist_surv data looking specific variables (including newly created).can also cross-tabulate columns age_cat_small gender details distribution new column gender. use tabyl() adorn functions janitor described Descriptive tables page.","code":"\n#create a new data called linelist_surv from the linelist_case_data\n\nlinelist_surv <-  linelist_case_data %>% \n     \n  dplyr::filter(\n       # remove observations with wrong or missing dates of onset or date of outcome\n       date_outcome > date_onset) %>% \n  \n  dplyr::mutate(\n       # create the event var which is 1 if the patient died and 0 if he was right censored\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # create the var on the follow-up time in days\n       futime = as.double(date_outcome - date_onset), \n    \n       # create a new age category variable with only 3 strata levels\n       age_cat_small = dplyr::case_when( \n            age_years < 5  ~ \"0-4\",\n            age_years >= 5 & age_years < 20 ~ \"5-19\",\n            age_years >= 20   ~ \"20+\"),\n       \n       # previous step created age_cat_small var as character.\n       # now convert it to factor and specify the levels.\n       # Note that the NA values remain NA's and are not put in a level \"unknown\" for example,\n       # since in the next analyses they have to be removed.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\nsummary(linelist_surv$futime)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    6.00   10.00   11.98   16.00   64.00\n# cross tabulate the new event var and the outcome var from which it was created\n# to make sure the code did what it was intended to\nlinelist_surv %>% \n  tabyl(outcome, event)##  outcome    0    1\n##    Death    0 1952\n##  Recover 1547    0\n##     <NA> 1040    0\nlinelist_surv %>% \n  tabyl(age_cat_small, age_cat)##  age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n##            0-4 834   0     0     0     0     0     0   0   0\n##           5-19   0 852   717   575     0     0     0   0   0\n##            20+   0   0     0     0   862   554    69   5   0\n##           <NA>   0   0     0     0     0     0     0   0  71\nlinelist_surv %>% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %>% \n  head(10)##    case_id age_cat_small date_onset date_outcome outcome event futime\n## 1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n## 2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n## 3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n## 4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n## 5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n## 6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n## 7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n## 8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n## 9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n## 10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\nlinelist_surv %>% \n  tabyl(gender, age_cat_small, show_na = F) %>% \n  adorn_totals(where = \"both\") %>% \n  adorn_percentages() %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\")##  gender         0-4          5-19           20+          Total\n##       f 482 (22.4%) 1,184 (54.9%)   490 (22.7%) 2,156 (100.0%)\n##       m 325 (15.0%)   880 (40.6%)   960 (44.3%) 2,165 (100.0%)\n##   Total 807 (18.7%) 2,064 (47.8%) 1,450 (33.6%) 4,321 (100.0%)"},{"path":"survival-analysis.html","id":"basics-of-survival-analysis","chapter":"27 Survival analysis","heading":"27.3 Basics of survival analysis","text":"","code":""},{"path":"survival-analysis.html","id":"building-a-surv-type-object","chapter":"27 Survival analysis","heading":"Building a surv-type object","text":"first use Surv() survival build survival object follow-time event columns.result step produce object type Surv condenses time information whether event interest (death) observed. object ultimately used right-hand side subsequent model formulae (see documentation).review, first 10 rows linelist_surv data, viewing important columns.first 10 elements survobj. prints essentially vector follow-time, “+” represent observation right-censored. See numbers align .","code":"\n# Use Suv() syntax for right-censored data\nsurvobj <- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\nlinelist_surv %>% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %>% \n  head(10)##    case_id date_onset date_outcome futime outcome event\n## 1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n## 2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n## 3   893f25 2014-05-21   2014-05-29      8 Recover     0\n## 4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n## 5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n## 6   369449 2014-06-02   2014-06-07      5   Death     1\n## 7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n## 8   1389ca 2014-06-05   2014-06-09      4   Death     1\n## 9   2978ac 2014-06-06   2014-06-15      9   Death     1\n## 10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n#print the 50 first elements of the vector to see how it presents\nhead(survobj, 10)##  [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+"},{"path":"survival-analysis.html","id":"running-initial-analyses","chapter":"27 Survival analysis","heading":"Running initial analyses","text":"start analysis using survfit() function produce survfit object, fits default calculations Kaplan Meier (KM) estimates overall (marginal) survival curve, fact step function jumps observed event times. final survfit object contains one survival curves created using Surv object response variable model formula.NOTE: Kaplan-Meier estimate nonparametric maximum likelihood estimate (MLE) survival function. . (see resources information).summary survfit object give called life table. time step follow-(time) event happened (ascending order):number people risk developing event (people event yet censored: n.risk)develop event (n.event): probability developing event (probability dying, surviving past specific time)finally, standard error confidence interval probability derived displayedWe fit KM estimates using formula previously Surv object “survobj” response variable. “~ 1” precises run model overall survival.using summary() can add option times specify certain times want see survival informationWe can also use print() function. print.rmean = TRUE argument used obtain mean survival time standard error (se).NOTE: restricted mean survival time (RMST) specific survival measure used cancer survival analysis often defined area survival curve, given observe patients restricted time T (details Resources section).TIP: can create surv object directly survfit() function save line code. look like: linelistsurv_quick <-  survfit(Surv(futime, event) ~ 1, data=linelist_surv).","code":"\n# fit the KM estimates using a formula where the Surv object \"survobj\" is the response variable.\n# \"~ 1\" signifies that we run the model for the overall survival  \nlinelistsurv_fit <-  survival::survfit(survobj ~ 1)\n\n#print its summary for more details\nsummary(linelistsurv_fit)## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     1   4539      30    0.993 0.00120        0.991        0.996\n##     2   4500      69    0.978 0.00217        0.974        0.982\n##     3   4394     149    0.945 0.00340        0.938        0.952\n##     4   4176     194    0.901 0.00447        0.892        0.910\n##     5   3899     214    0.852 0.00535        0.841        0.862\n##     6   3592     210    0.802 0.00604        0.790        0.814\n##     7   3223     179    0.757 0.00656        0.745        0.770\n##     8   2899     167    0.714 0.00700        0.700        0.728\n##     9   2593     145    0.674 0.00735        0.660        0.688\n##    10   2311     109    0.642 0.00761        0.627        0.657\n##    11   2081     119    0.605 0.00788        0.590        0.621\n##    12   1843      89    0.576 0.00809        0.560        0.592\n##    13   1608      55    0.556 0.00823        0.540        0.573\n##    14   1448      43    0.540 0.00837        0.524        0.556\n##    15   1296      31    0.527 0.00848        0.511        0.544\n##    16   1152      48    0.505 0.00870        0.488        0.522\n##    17   1002      29    0.490 0.00886        0.473        0.508\n##    18    898      21    0.479 0.00900        0.462        0.497\n##    19    798       7    0.475 0.00906        0.457        0.493\n##    20    705       4    0.472 0.00911        0.454        0.490\n##    21    626      13    0.462 0.00932        0.444        0.481\n##    22    546       8    0.455 0.00948        0.437        0.474\n##    23    481       5    0.451 0.00962        0.432        0.470\n##    24    436       4    0.447 0.00975        0.428        0.466\n##    25    378       4    0.442 0.00993        0.423        0.462\n##    26    336       3    0.438 0.01010        0.419        0.458\n##    27    297       1    0.436 0.01017        0.417        0.457\n##    29    235       1    0.435 0.01030        0.415        0.455\n##    38     73       1    0.429 0.01175        0.406        0.452\n#print its summary at specific times\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     5   3899     656    0.852 0.00535        0.841        0.862\n##    10   2311     810    0.642 0.00761        0.627        0.657\n##    20    705     446    0.472 0.00911        0.454        0.490\n##    30    210      39    0.435 0.01030        0.415        0.455\n##    60      2       1    0.429 0.01175        0.406        0.452\n# print linelistsurv_fit object with mean survival time and its se. \nprint(linelistsurv_fit, print.rmean = TRUE)## Call: survfit(formula = survobj ~ 1)\n## \n##         n events rmean* se(rmean) median 0.95LCL 0.95UCL\n## [1,] 4539   1952   33.1     0.539     17      16      18\n##     * restricted mean with upper limit =  64"},{"path":"survival-analysis.html","id":"cumulative-hazard","chapter":"27 Survival analysis","heading":"Cumulative hazard","text":"Besides summary() function, can also use str() function gives details structure survfit() object. list 16 elements.Among elements important one: cumhaz, numeric vector. plotted allow show cumulative hazard, hazard instantaneous rate event occurrence (see references).","code":"\nstr(linelistsurv_fit)## List of 16\n##  $ n        : int 4539\n##  $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n##  $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n##  $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n##  $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n##  $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n##  $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n##  $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n##  $ type     : chr \"right\"\n##  $ logse    : logi TRUE\n##  $ conf.int : num 0.95\n##  $ conf.type: chr \"log\"\n##  $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n##  $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n##  $ call     : language survfit(formula = survobj ~ 1)\n##  - attr(*, \"class\")= chr \"survfit\""},{"path":"survival-analysis.html","id":"plotting-kaplan-meir-curves","chapter":"27 Survival analysis","heading":"Plotting Kaplan-Meir curves","text":"KM estimates fitted, can visualize probability alive given time using basic plot() function draws “Kaplan-Meier curve”. words, curve conventional illustration survival experience whole patient group.can quickly verify follow-time min max curve.easy way interpret say time zero, participants still alive survival probability 100%. probability decreases time patients die. proportion participants surviving past 60 days follow-around 40%.confidence interval KM survival estimates also plotted default can dismissed adding option conf.int = FALSE plot() command.Since event interest “death”, drawing curve describing complements survival proportions lead drawing cumulative mortality proportions. can done lines(), adds information existing plot.","code":"\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",    # x-axis label\n     ylab=\"Survival Probability\",   # y-axis label\n     main= \"Overall survival curve\" # figure title\n     )\n# original plot\nplot(\n  linelistsurv_fit,\n  xlab = \"Days of follow-up\",       \n  ylab = \"Survival Probability\",       \n  mark.time = TRUE,              # mark events on the curve: a \"+\" is printed at every event\n  conf.int = FALSE,              # do not plot the confidence interval\n  main = \"Overall survival curve and cumulative mortality\"\n  )\n\n# draw an additional curve to the previous plot\nlines(\n  linelistsurv_fit,\n  lty = 3,             # use different line type for clarity\n  fun = \"event\",       # draw the cumulative events instead of the survival \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# add a legend to the plot\nlegend(\n  \"topright\",                               # position of legend\n  legend = c(\"Survival\", \"Cum. Mortality\"), # legend text \n  lty = c(1, 3),                            # line types to use in the legend\n  cex = .85,                                # parametes that defines size of legend text\n  bty = \"n\"                                 # no box type to be drawn for the legend\n  )"},{"path":"survival-analysis.html","id":"comparison-of-survival-curves","chapter":"27 Survival analysis","heading":"27.4 Comparison of survival curves","text":"compare survival within different groups observed participants patients, might need first look respective survival curves run tests evaluate difference independent groups. comparison can concern groups based gender, age, treatment, comorbidity…","code":""},{"path":"survival-analysis.html","id":"log-rank-test","chapter":"27 Survival analysis","heading":"Log rank test","text":"log rank test popular test compares entire survival experience two independent groups can thought test whether survival curves identical (overlapping) (null hypothesis difference survival groups). survdiff() function survival package allows running log-rank test specify rho = 0 (default). test results gives chi-square statistic along p-value since log rank statistic approximately distributed chi-square test statistic.first try compare survival curves gender group. , first try visualize (check whether two survival curves overlapping). new survfit object created slightly different formula. survdiff object created.supplying ~ gender right side formula, longer plot overall survival instead gender.Now can plot survival curves gender. look order strata levels gender column defining colors legend.now can compute test difference survival curves using survdiff()see survival curve women one men overlap log-rank test give evidence survival difference women men.R packages allow illustrating survival curves different groups testing difference . Using ggsurvplot() function survminer package, can also include curve printed risk tables group, well p-value log-rank test.CAUTION: survminer functions require specify survival object specify data used fit survival object. Remember avoid non-specific error messages. may also want test differences survival source infection (source contamination).case, Log rank test gives enough evidence difference survival probabilities alpha= 0.005. survival probabilities patients infected funerals higher survival probabilities patients got infected places, suggesting survival benefit.","code":"\n# create the new survfit object based on gender\nlinelistsurv_fit_sex <-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n# set colors\ncol_sex <- c(\"lightgreen\", \"darkgreen\")\n\n# create plot\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Days of follow-up\",\n  ylab = \"Survival Probability\")\n\n# add legend\nlegend(\n  \"topright\",\n  legend = c(\"Female\",\"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n#compute the test of the difference between the survival curves\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )## Call:\n## survival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n## \n## n=4321, 218 observations deleted due to missingness.\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## gender=f 2156      924      909     0.255     0.524\n## gender=m 2165      929      944     0.245     0.524\n## \n##  Chisq= 0.5  on 1 degrees of freedom, p= 0.5\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv,          # again specify the data used to fit linelistsurv_fit_sex \n    conf.int = FALSE,              # do not show confidence interval of KM estimates\n    surv.scale = \"percent\",        # present probabilities in the y axis in %\n    break.time.by = 10,            # present the time axis with an increment of 10 days\n    xlab = \"Follow-up days\",\n    ylab = \"Survival Probability\",\n    pval = T,                      # print p-value of Log-rank test \n    pval.coord = c(40,.91),        # print p-value at these plot coordinates\n    risk.table = T,                # print the risk table at bottom \n    legend.title = \"Gender\",       # legend characteristics\n    legend.labs = c(\"Female\",\"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\",             # specify color palette \n    surv.median.line = \"hv\",       # draw horizontal and vertical lines to the median survivals\n    ggtheme = theme_light()        # simplify plot background\n)\nlinelistsurv_fit_source <-  survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# plot\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\",   # line types\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Follow-up days\",\n  ylab= \"Survival Probability\",\n  pval = T,\n  pval.coord = c(40,.91),\n  risk.table = T,\n  legend.title = \"Source of \\ninfection\",\n  legend.labs = c(\"Funeral\", \"Other\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\",\"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)"},{"path":"survival-analysis.html","id":"cox-regression-analysis","chapter":"27 Survival analysis","heading":"27.5 Cox regression analysis","text":"Cox proportional hazards regression one popular regression techniques survival analysis. models can also used since Cox model requires important assumptions need verified appropriate use proportional hazards assumption: see references.Cox proportional hazards regression model, measure effect hazard rate (HR), risk failure (risk death example), given participant survived specific time. Usually, interested comparing independent groups respect hazards, use hazard ratio, analogous odds ratio setting multiple logistic regression analysis. cox.ph() function survival package used fit model. function cox.zph() survival package may used test proportional hazards assumption Cox regression model fit.NOTE: probability must lie range 0 1. However, hazard represents expected number events per one unit time.hazard ratio predictor close 1 predictor affect survival,HR less 1, predictor protective (.e., associated improved survival),HR greater 1, predictor associated increased risk (decreased survival).","code":""},{"path":"survival-analysis.html","id":"fitting-a-cox-model","chapter":"27 Survival analysis","heading":"Fitting a Cox model","text":"can first fit model assess effect age gender survival. just printing model, information :estimated regression coefficients coef quantifies association predictors outcome,exponential (interpretability, exp(coef)) produces hazard ratio,standard error se(coef),z-score: many standard errors estimated coefficient away 0,p-value: probability estimated coefficient 0.summary() function applied cox model object gives information, confidence interval estimated HR different test scores.effect first covariate gender presented first row. genderm (male) printed, implying first strata level (“f”), .e female group, reference group gender. Thus interpretation test parameter men compared women. p-value indicates enough evidence effect gender expected hazard association gender -cause mortality.lack evidence noted regarding age-group.interesting run model look results first look verify whether proportional hazards assumptions respected help saving time.NOTE: second argument called method can specified computing cox model, determines ties handled. default “efron”, options “breslow” “exact”.another model add risk factors source infection number days date onset admission. time, first verify proportional hazards assumption going forward.model, included continuous predictor (days_onset_hosp). case interpret parameter estimates increase expected log relative hazard one unit increase predictor, holding predictors constant. first verify proportional hazards assumption.graphical verification assumption may performed function ggcoxzph() survminer package.model results indicate negative association onset admission duration -cause mortality. expected hazard 0.9 times lower person one day later admitted another, holding gender constant. straightforward explanation, one unit increase duration onset admission associated 10.7% (coef *100) decrease risk death.Results show also positive association source infection -cause mortality. say increased risk death (1.21x) patients got source infection funerals.can verify relationship table:need consider investigate association exists data. One possible explanation patients live long enough admitted later less severe disease begin . Another perhaps likely explanation since used simulated fake dataset, pattern reflect reality!","code":"\n#fitting the cox model\nlinelistsurv_cox_sexage <-  survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#printing the model fitted\nlinelistsurv_cox_sexage## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##                       coef exp(coef) se(coef)      z     p\n## genderm           -0.03149   0.96900  0.04767 -0.661 0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n## \n## Likelihood ratio test=2.8  on 3 df, p=0.4243\n## n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n#summary of the model\nsummary(linelistsurv_cox_sexage)## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##   n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n## \n##                       coef exp(coef) se(coef)      z Pr(>|z|)\n## genderm           -0.03149   0.96900  0.04767 -0.661    0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n## \n##                   exp(coef) exp(-coef) lower .95 upper .95\n## genderm               0.969     1.0320    0.8826     1.064\n## age_cat_small5-19     1.099     0.9103    0.9680     1.247\n## age_cat_small20+      1.052     0.9509    0.9176     1.205\n## \n## Concordance= 0.514  (se = 0.007 )\n## Likelihood ratio test= 2.8  on 3 df,   p=0.4\n## Wald test            = 2.78  on 3 df,   p=0.4\n## Score (logrank) test = 2.78  on 3 df,   p=0.4\ntest_ph_sexage <- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage##               chisq df    p\n## gender        0.454  1 0.50\n## age_cat_small 0.838  2 0.66\n## GLOBAL        1.399  3 0.71\n#fit the model\nlinelistsurv_cox <-  coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#test the proportional hazard model\nlinelistsurv_ph_test <- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test##                    chisq df       p\n## gender           0.45062  1    0.50\n## age_years        0.00199  1    0.96\n## source           1.79622  1    0.18\n## days_onset_hosp 31.66167  1 1.8e-08\n## GLOBAL          34.08502  4 7.2e-07\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n#print the summary of the model\nsummary(linelistsurv_cox)## Call:\n## coxph(formula = Surv(futime, event) ~ gender + age_years + source + \n##     days_onset_hosp, data = linelist_surv)\n## \n##   n= 2772, number of events= 1180 \n##    (1767 observations deleted due to missingness)\n## \n##                      coef exp(coef)  se(coef)      z Pr(>|z|)    \n## genderm          0.004710  1.004721  0.060827  0.077   0.9383    \n## age_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \n## sourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \n## days_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                 exp(coef) exp(-coef) lower .95 upper .95\n## genderm            1.0047     0.9953    0.8918    1.1319\n## age_years          0.9978     1.0023    0.9930    1.0025\n## sourceother        1.1953     0.8366    1.0133    1.4100\n## days_onset_hosp    0.9012     1.1097    0.8764    0.9267\n## \n## Concordance= 0.566  (se = 0.009 )\n## Likelihood ratio test= 71.31  on 4 df,   p=1e-14\n## Wald test            = 59.22  on 4 df,   p=4e-12\n## Score (logrank) test = 59.54  on 4 df,   p=4e-12\nlinelist_case_data %>% \n  tabyl(days_onset_hosp, outcome) %>% \n  adorn_percentages() %>%  \n  adorn_pct_formatting()##  days_onset_hosp Death Recover   NA_\n##                0 44.3%   31.4% 24.3%\n##                1 46.6%   32.2% 21.2%\n##                2 43.0%   32.8% 24.2%\n##                3 45.0%   32.3% 22.7%\n##                4 41.5%   38.3% 20.2%\n##                5 40.0%   36.2% 23.8%\n##                6 32.2%   48.7% 19.1%\n##                7 31.8%   38.6% 29.5%\n##                8 29.8%   38.6% 31.6%\n##                9 30.3%   51.5% 18.2%\n##               10 16.7%   58.3% 25.0%\n##               11 36.4%   45.5% 18.2%\n##               12 18.8%   62.5% 18.8%\n##               13 10.0%   60.0% 30.0%\n##               14 10.0%   50.0% 40.0%\n##               15 28.6%   42.9% 28.6%\n##               16 20.0%   80.0%  0.0%\n##               17  0.0%  100.0%  0.0%\n##               18  0.0%  100.0%  0.0%\n##               22  0.0%  100.0%  0.0%\n##               NA 52.7%   31.2% 16.0%"},{"path":"survival-analysis.html","id":"forest-plots","chapter":"27 Survival analysis","heading":"Forest plots","text":"can visualize results cox model using practical forest plots ggforest() function survminer package.","code":"\nggforest(linelistsurv_cox, data = linelist_surv)"},{"path":"survival-analysis.html","id":"time-dependent-covariates-in-survival-models","chapter":"27 Survival analysis","heading":"27.6 Time-dependent covariates in survival models","text":"following sections adapted permission excellent introduction survival analysis R Dr. Emily ZaborIn last section covered using Cox regression examine associations covariates interest survival outcomes.analyses rely covariate measured baseline, , follow-time event begins.happens interested covariate measured follow-time begins? , covariate can change time?example, maybe working clinical data repeated measures hospital laboratory values can change time. example Time Dependent Covariate. order address need special setup, fortunately cox model flexible type data can also modeled tools survival package.","code":""},{"path":"survival-analysis.html","id":"time-dependent-covariate-setup","chapter":"27 Survival analysis","heading":"Time-dependent covariate setup","text":"Analysis time-dependent covariates R requires setup special dataset. interested, see detailed paper author survival package Using Time Dependent Covariates Time Dependent Coefficients Cox Model., ’ll use new dataset SemiCompRisks package named BMT, includes data 137 bone marrow transplant patients. variables ’ll focus :T1 - time (days) death last follow-updelta1 - death indicator; 1-Dead, 0-AliveTA - time (days) acute graft-versus-host diseasedeltaA - acute graft-versus-host disease indicator;\n1 - Developed acute graft-versus-host disease\n0 - Never developed acute graft-versus-host disease\n1 - Developed acute graft-versus-host disease0 - Never developed acute graft-versus-host diseaseWe’ll load dataset survival package using base R command data(), can used loading data already included R package loaded. data frame BMT appear R environment.","code":"\ndata(BMT, package = \"SemiCompRisks\")"},{"path":"survival-analysis.html","id":"add-unique-patient-identifier","chapter":"27 Survival analysis","heading":"Add unique patient identifier","text":"unique ID column BMT data, needed create type dataset want. use function rowid_to_column() tidyverse package tibble create new id column called my_id (adds column start data frame sequential row ids, starting 1). name data frame bmt.dataset now looks like :","code":"\nbmt <- rowid_to_column(BMT, \"my_id\")"},{"path":"survival-analysis.html","id":"expand-patient-rows","chapter":"27 Survival analysis","heading":"Expand patient rows","text":"Next, ’ll use tmerge() function event() tdc() helper functions create restructured dataset. goal restructure dataset create separate row patient time interval different value deltaA. case, patient can two rows depending whether developed acute graft-versus-host disease data collection period. ’ll call new indicator development acute graft-versus-host disease agvhd.tmerge() creates long dataset multiple time intervals different covariate values patientevent() creates new event indicator go newly-created time intervalstdc() creates time-dependent covariate column, agvhd, go newly created time intervalsTo see , let’s look data first 5 individual patients.variables interest original data looked like :new dataset patients looks like :Now patients two rows dataset corresponding intervals different value new variable, agvhd. example, Patient 1 now two rows agvhd value zero time 0 time 67, value 1 time 67 time 2081.","code":"\ntd_dat <- \n  tmerge(\n    data1 = bmt %>% select(my_id, T1, delta1), \n    data2 = bmt %>% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\nbmt %>% \n  select(my_id, T1, delta1, TA, deltaA) %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1   TA deltaA\n## 1     1 2081      0   67      1\n## 2     2 1602      0 1602      0\n## 3     3 1496      0 1496      0\n## 4     4 1462      0   70      1\n## 5     5 1433      0 1433      0\ntd_dat %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1 tstart tstop death agvhd\n## 1     1 2081      0      0    67     0     0\n## 2     1 2081      0     67  2081     0     1\n## 3     2 1602      0      0  1602     0     0\n## 4     3 1496      0      0  1496     0     0\n## 5     4 1462      0      0    70     0     0\n## 6     4 1462      0     70  1462     0     1\n## 7     5 1433      0      0  1433     0     0"},{"path":"survival-analysis.html","id":"cox-regression-with-time-dependent-covariates","chapter":"27 Survival analysis","heading":"Cox regression with time-dependent covariates","text":"Now ’ve reshaped data added new time-dependent aghvd variable, let’s fit simple single variable cox regression model. can use coxph() function , just need change Surv() function specify start stop time interval using time1 = time2 = arguments., ’ll visualize cox model results using ggforest() function survminer package.:can see forest plot, confidence interval, p-value, appear strong association death acute graft-versus-host disease context simple model.","code":"\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)## Call:\n## coxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n##     agvhd, data = td_dat)\n## \n##   n= 163, number of events= 80 \n## \n##         coef exp(coef) se(coef)    z Pr(>|z|)\n## agvhd 0.3351    1.3980   0.2815 1.19    0.234\n## \n##       exp(coef) exp(-coef) lower .95 upper .95\n## agvhd     1.398     0.7153    0.8052     2.427\n## \n## Concordance= 0.535  (se = 0.024 )\n## Likelihood ratio test= 1.33  on 1 df,   p=0.2\n## Wald test            = 1.42  on 1 df,   p=0.2\n## Score (logrank) test = 1.43  on 1 df,   p=0.2\nggforest(bmt_td_model, data = td_dat)"},{"path":"survival-analysis.html","id":"resources-20","chapter":"27 Survival analysis","heading":"27.7 Resources","text":"Survival Analysis Part : Basic concepts first analysesSurvival Analysis RSurvival analysis infectious disease research: Describing events timeChapter advanced survival models PrincetonUsing Time Dependent Covariates Time Dependent Coefficients Cox ModelSurvival analysis cheatsheet RSurvminer cheatsheetPaper different survival measures cancer registry data Rcode provided supplementary materials","code":""},{"path":"gis-basics.html","id":"gis-basics","chapter":"28 GIS basics","heading":"28 GIS basics","text":"","code":""},{"path":"gis-basics.html","id":"overview-6","chapter":"28 GIS basics","heading":"28.1 Overview","text":"Spatial aspects data can provide lot insights situation outbreak, answer questions :current disease hotspots?hotspots changed time?access health facilities? improvements needed?current focus GIS page address needs applied epidemiologists outbreak response. explore basic spatial data visualization methods using tmap ggplot2 packages. also walk basic spatial data management querying methods sf package. Lastly, briefly touch upon concepts spatial statistics spatial relationships, spatial autocorrelation, spatial regression using spdep package.","code":""},{"path":"gis-basics.html","id":"key-terms-1","chapter":"28 GIS basics","heading":"28.2 Key terms","text":"introduce key terminology. thorough introduction GIS spatial analysis, suggest review one longer tutorials courses listed References section.Geographic Information System (GIS) - GIS framework environment gathering, managing, analyzing, visualizing spatial data.","code":""},{"path":"gis-basics.html","id":"gis-software","chapter":"28 GIS basics","heading":"GIS software","text":"popular GIS software allow point--click interaction map development spatial analysis. tools comes advantages needing learn code ease manually selecting placing icons features map. two popular ones:ArcGIS - commercial GIS software developed company ESRI, popular quite expensiveQGIS - free open-source GIS software can almost anything ArcGIS can . can download QGIS hereUsing R GIS can seem intimidating first instead “point--click”, “command-line interface” (must code acquire desired outcome). However, major advantage need repetitively produce maps create analysis reproducible.","code":""},{"path":"gis-basics.html","id":"spatial-data","chapter":"28 GIS basics","heading":"Spatial data","text":"two primary forms spatial data used GIS vector raster data:Vector Data - common format spatial data used GIS, vector data comprised geometric features vertices paths. Vector spatial data can divided three widely-used types:Points - point consists coordinate pair (x,y) representing specific location coordinate system. Points basic form spatial data, may used denote case (.e. patient home) location (.e. hospital) map.Points - point consists coordinate pair (x,y) representing specific location coordinate system. Points basic form spatial data, may used denote case (.e. patient home) location (.e. hospital) map.Lines - line composed two connected points. Lines length, may used denote things like roads rivers.Lines - line composed two connected points. Lines length, may used denote things like roads rivers.Polygons - polygon composed least three line segments connected points. Polygon features length (.e. perimeter area) well area measurement. Polygons may used note area (.e. village) structure (.e. actual area hospital).Polygons - polygon composed least three line segments connected points. Polygon features length (.e. perimeter area) well area measurement. Polygons may used note area (.e. village) structure (.e. actual area hospital).Raster Data - alternative format spatial data, raster data matrix cells (e.g. pixels) cell containing information height, temperature, slope, forest cover, etc. often aerial photographs, satellite imagery, etc. Rasters can also used “base maps” vector data.","code":""},{"path":"gis-basics.html","id":"visualizing-spatial-data","chapter":"28 GIS basics","heading":"Visualizing spatial data","text":"visually represent spatial data map, GIS software requires provide sufficient information different features , relation one another. using vector data, true use cases, information typically stored shapefile:Shapefiles - shapefile common data format storing “vector” spatial data consisting lines, points, polygons. single shapefile actually collection least three files - .shp, .shx, .dbf. sub-component files must present given directory (folder) shapefile readable. associated files can compressed ZIP folder sent via email download website.shapefile contain information features , well locate Earth’s surface. important Earth globe, maps typically two-dimensional; choices “flatten” spatial data can big impact look interpretation resulting map.Coordinate Reference Systems (CRS) - CRS coordinate-based system used locate geographical features Earth’s surface. key components:Coordinate System - many many different coordinate systems, make sure know system coordinates . Degrees latitude/longitude common, also see UTM coordinates.Coordinate System - many many different coordinate systems, make sure know system coordinates . Degrees latitude/longitude common, also see UTM coordinates.Units - Know units coordinate system (e.g. decimal degrees, meters)Units - Know units coordinate system (e.g. decimal degrees, meters)Datum - particular modeled version Earth. revised years, ensure map layers using datum.Datum - particular modeled version Earth. revised years, ensure map layers using datum.Projection - reference mathematical equation used project truly round earth onto flat surface (map).Projection - reference mathematical equation used project truly round earth onto flat surface (map).Remember can summarise spatial data without using mapping tools shown . Sometimes simple table geography (e.g. district, country, etc.) needed!","code":""},{"path":"gis-basics.html","id":"getting-started-with-gis","chapter":"28 GIS basics","heading":"28.3 Getting started with GIS","text":"couple key items need think make map. include:dataset – can spatial data format (shapefiles, noted ) may spatial format (instance just csv).dataset – can spatial data format (shapefiles, noted ) may spatial format (instance just csv).dataset spatial format also need reference dataset. Reference data consists spatial representation data related attributes, include material containing location address information specific features.\nworking pre-defined geographic boundaries (example, administrative regions), reference shapefiles often freely available download government agency data sharing organization. doubt, good place start Google “[regions] shapefile”\naddress information, latitude longitude, may need use geocoding engine get spatial reference data records.\ndataset spatial format also need reference dataset. Reference data consists spatial representation data related attributes, include material containing location address information specific features.working pre-defined geographic boundaries (example, administrative regions), reference shapefiles often freely available download government agency data sharing organization. doubt, good place start Google “[regions] shapefile”working pre-defined geographic boundaries (example, administrative regions), reference shapefiles often freely available download government agency data sharing organization. doubt, good place start Google “[regions] shapefile”address information, latitude longitude, may need use geocoding engine get spatial reference data records.address information, latitude longitude, may need use geocoding engine get spatial reference data records.idea want present information datasets target audience. many different types maps, important think type map best fits needs.idea want present information datasets target audience. many different types maps, important think type map best fits needs.","code":""},{"path":"gis-basics.html","id":"types-of-maps-for-visualizing-your-data","chapter":"28 GIS basics","heading":"Types of maps for visualizing your data","text":"Choropleth map - type thematic map colors, shading, patterns used represent geographic regions relation value attribute. instance larger value indicated darker colour smaller value. type map particularly useful visualizing variable changes across defined regions geopolitical areas.Case density heatmap - type thematic map colours used represent intensity value, however, use defined regions geopolitical boundaries group data. type map typically used showing ‘hot spots’ areas high density concentration points.Dot density map - thematic map type uses dots represent attribute values data. type map best used visualize scatter data visually scan clusters.Proportional symbols map (graduated symbols map) - thematic map similar choropleth map, instead using colour indicate value attribute uses symbol (usually circle) relation value. instance larger value indicated larger symbol smaller value. type map best used want visualize size quantity data across geographic regions.can also combine several different types visualizations show complex geographic patterns. example, cases (dots) map colored according closest health facility (see legend). large red circles show health facility catchment areas certain radius, bright red case-dots outside catchment range:Note: primary focus GIS page based context field outbreak response. Therefore contents page cover basic spatial data manipulations, visualizations, analyses.","code":""},{"path":"gis-basics.html","id":"preparation-19","chapter":"28 GIS basics","heading":"28.4 Preparation","text":"","code":""},{"path":"gis-basics.html","id":"load-packages-18","chapter":"28 GIS basics","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.can see overview R packages deal spatial data CRAN “Spatial Task View”.","code":"\npacman::p_load(\n  rio,           # to import data\n  here,          # to locate files\n  tidyverse,     # to clean, handle, and plot the data (includes ggplot2 package)\n  sf,            # to manage spatial data using a Simple Feature format\n  tmap,          # to produce simple maps, works for both interactive and static maps\n  janitor,       # to clean column names\n  OpenStreetMap, # to add OSM basemap in ggplot map\n  spdep          # spatial statistics\n  )"},{"path":"gis-basics.html","id":"sample-case-data","chapter":"28 GIS basics","heading":"Sample case data","text":"demonstration purposes, work random sample 1000 cases simulated Ebola epidemic linelist dataframe (computationally, working fewer cases easier display handbook). want follow along, click download “clean” linelist (.rds file).Since taking random sample cases, results may look slightly different demonstrated run codes .Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).Next select random sample 1000 rows using sample() base R.Now want convert linelist class dataframe, object class “sf” (spatial features). Given linelist two columns “lon” “lat” representing longitude latitude case’s residence, easy.use package sf (spatial features) function st_as_sf() create new object call linelist_sf. new object looks essentially linelist, columns lon lat designated coordinate columns, coordinate reference system (CRS) assigned points displayed. 4326 identifies coordinates based World Geodetic System 1984 (WGS84) - standard GPS coordinates.original linelist dataframe looks like. demonstration, use column date_onset geometry (constructed longitude latitude fields last column data frame).","code":"\n# import clean case linelist\nlinelist <- import(\"linelist_cleaned.rds\")  \n# generate 1000 random row numbers, from the number of rows in linelist\nsample_rows <- sample(nrow(linelist), 1000)\n\n# subset linelist to keep only the sample rows, and all columns\nlinelist <- linelist[sample_rows,]\n# Create sf object\nlinelist_sf <- linelist %>%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )"},{"path":"gis-basics.html","id":"admin-boundary-shapefiles","chapter":"28 GIS basics","heading":"Admin boundary shapefiles","text":"Sierra Leone: Admin boundary shapefilesIn advance, downloaded administrative boundaries Sierra Leone Humanitarian Data Exchange (HDX) website . Alternatively, can download example data handbook via R package, explained Download handbook data page.Now going following save Admin Level 3 shapefile R:Import shapefileClean column namesFilter rows keep areas interestTo import shapefile use read_sf() function sf. provided filepath via (). - case file within R project “data”, “gis”, “shp” subfolders, filename “sle_adm3.shp” (see pages Import export R projects information). need provide file path.Next use clean_names() janitor package standardize column names shapefile. also use filter() keep rows admin2name “Western Area Urban” “Western Area Rural”.can see shapefile looks import cleaning. Scroll right see columns admin level 0 (country), admin level 1, admin level 2, finally admin level 3. level character name unique identifier “pcode”. pcode expands increasing admin level e.g. SL (Sierra Leone) -> SL04 (Western) -> SL0410 (Western Area Rural) -> SL040101 (Koya Rural).","code":"\n# ADM3 level clean\nsle_adm3 <- sle_adm3_raw %>%\n  janitor::clean_names() %>% # standardize column names\n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filter to keep certain areas"},{"path":"gis-basics.html","id":"population-data","chapter":"28 GIS basics","heading":"Population data","text":"Sierra Leone: Population ADM3These data can downloaded HDX (link ) via epirhandbook R package explained page. use import() load .csv file. also pass imported file clean_names() standardize column name syntax.population file looks like. Scroll right see jurisdiction columns male population, female populaton, total population, population break-columns age group.","code":"\n# Population by ADM3\nsle_adm3_pop <- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %>%\n  janitor::clean_names()"},{"path":"gis-basics.html","id":"health-facilities","chapter":"28 GIS basics","heading":"Health Facilities","text":"Sierra Leone: Health facility data OpenStreetMapAgain downloaded locations health facilities HDX via instructions Download handbook data page.import facility points shapefile read_sf(), clean column names, filter keep points tagged either “hospital”, “clinic”, “doctors”.resulting dataframe - scroll right see facility name geometry coordinates.","code":"\n# OSM health facility shapefile\nsle_hf <- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %>% \n  janitor::clean_names() %>%\n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))"},{"path":"gis-basics.html","id":"plotting-coordinates","chapter":"28 GIS basics","heading":"28.5 Plotting coordinates","text":"easiest way plot X-Y coordinates (longitude/latitude, points), case cases, draw points directly linelist_sf object created preparation section.package tmap offers simple mapping capabilities static (“plot” mode) interactive (“view” mode) just lines code. tmap syntax similar ggplot2, commands added +. Read detail vignette.Set tmap mode. case use “plot” mode, produces static outputs., points plotted alone.tm_shape() provided linelist_sf objects. add points via tm_dots(), specifying size color. linelist_sf sf object, already designated two columns contain lat/long coordinates coordinate reference system (CRS):Alone, points tell us much. also map administrative boundaries:use tm_shape() (see documentation) instead providing case points shapefile, provide administrative boundary shapefile (polygons).bbox = argument (bbox stands “bounding box”) can specify coordinate boundaries. First show map display without bbox, .now points polygons together:read good comparison mapping options R, see blog post.","code":"\ntmap_mode(\"plot\") # choose either \"view\" or \"plot\"\n# Just the cases (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n# Just the administrative boundaries (polygons)\ntm_shape(sle_adm3) +               # admin boundaries shapefile\n  tm_polygons(col = \"#F7F7F7\")+    # show polygons in light grey\n  tm_borders(col = \"#000000\",      # show borders with color and line weight\n             lwd = 2) +\n  tm_text(\"admin3name\")            # column text to display for each polygon\n\n\n# Same as above, but with zoom from bounding box\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # corner\n                  -13.2, 8.5)) +  # corner\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n# All together\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # give title to map"},{"path":"gis-basics.html","id":"spatial-joins","chapter":"28 GIS basics","heading":"28.6 Spatial joins","text":"may familiar joining data one dataset another one. Several methods discussed Joining data page handbook. spatial join serves similar purpose leverages spatial relationships. Instead relying common values columns correctly match observations, can utilize spatial relationships, one feature within another, nearest neighbor another, within buffer certain radius another, etc.sf package offers various methods spatial joins. See documentation st_join method spatial join types reference.","code":""},{"path":"gis-basics.html","id":"points-in-polygon","chapter":"28 GIS basics","heading":"Points in polygon","text":"Spatial assign administrative units casesHere interesting conundrum: case linelist contain information administrative units cases. Although ideal collect information initial data collection phase, can also assign administrative units individual cases based spatial relationships (.e. point intersects polygon)., spatially intersect case locations (points) ADM3 boundaries (polygons):Begin linelist (points)Spatial join boundaries, setting type join “st_intersects”Use select() keep certain new administrative boundary columnsAll columns sle_adms added linelist! case now columns detailing administrative levels falls within. example, want keep two new columns (admin level 3), select() old column names just two additional interest:, just display purposes can see first ten cases admin level 3 (ADM3) jurisdictions attached, based point spatially intersected polygon shapes.Now can describe cases administrative unit - something able spatial join!can also create bar plot case counts administrative unit.example, begin ggplot() linelist_adm, can apply factor functions like fct_infreq() orders bars frequency (see page Factors tips).","code":"\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects)\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects) %>% \n  \n  # Keep the old column names and two new admin ones of interest\n  select(names(linelist_sf), admin3name, admin3pcod)\n# Now you will see the ADM3 names attached to each case\nlinelist_adm %>% select(case_id, admin3name, admin3pcod)## Simple feature collection with 1000 features and 3 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -13.27276 ymin: 8.447753 xmax: -13.20545 ymax: 8.490227\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##      case_id     admin3name admin3pcod                   geometry\n## 1804  fc6146       West III   SL040208 POINT (-13.26622 8.467828)\n## 3370  7b7e0c        East II   SL040204 POINT (-13.21043 8.476803)\n## 675   6254ff Mountain Rural   SL040102 POINT (-13.20937 8.462601)\n## 1035  64ad98 Mountain Rural   SL040102 POINT (-13.21327 8.468354)\n## 4213  fd4705       West III   SL040208 POINT (-13.26002 8.455182)\n## 279   04ebc8      Central I   SL040201  POINT (-13.23286 8.47862)\n## 2855  c70ead Mountain Rural   SL040102 POINT (-13.22476 8.479803)\n## 4939  198a37        West II   SL040207 POINT (-13.23424 8.466239)\n## 1380  d6f195        East II   SL040204 POINT (-13.21833 8.479677)\n## 1912  097ab6 Mountain Rural   SL040102 POINT (-13.24052 8.453057)\n# Make new dataframe containing counts of cases by administrative unit\ncase_adm3 <- linelist_adm %>%          # begin with linelist with new admin cols\n  as_tibble() %>%                      # convert to tibble for better display\n  group_by(admin3pcod, admin3name) %>% # group by admin unit, both by name and pcode \n  summarise(cases = n()) %>%           # summarize and count rows\n  arrange(desc(cases))                     # arrange in descending order\n\ncase_adm3## # A tibble: 10 × 3\n## # Groups:   admin3pcod [10]\n##    admin3pcod admin3name     cases\n##    <chr>      <chr>          <int>\n##  1 SL040102   Mountain Rural   279\n##  2 SL040208   West III         243\n##  3 SL040207   West II          157\n##  4 SL040204   East II          128\n##  5 SL040201   Central I         57\n##  6 SL040206   West I            48\n##  7 SL040203   East I            45\n##  8 SL040202   Central II        20\n##  9 SL040205   East III          19\n## 10 <NA>       <NA>               4\nggplot(\n    data = linelist_adm,                       # begin with linelist containing admin unit info\n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # x-axis is admin units, ordered by frequency (reversed)\n  geom_bar()+                                # create bars, height is number of rows\n  coord_flip()+                              # flip X and Y axes for easier reading of adm units\n  theme_classic()+                           # simplify background\n  labs(                                      # titles and labels\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )"},{"path":"gis-basics.html","id":"nearest-neighbor","chapter":"28 GIS basics","heading":"Nearest neighbor","text":"Finding nearest health facility / catchment areaIt might useful know health facilities located relation disease hot spots.can use st_nearest_feature join method st_join() function (sf package) visualize closest health facility individual cases.begin shapefile linelist linelist_sfWe spatially join sle_hf, locations health facilities clinics (points)can see (first 50 rows) case now data nearest clinic/hospitalWe can see “Den Clinic” closest health facility ~30% cases.visualize results, can use tmap - time interactive mode easier viewing","code":"\n# Closest health facility to each case\nlinelist_sf_hf <- linelist_sf %>%                  # begin with linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %>%   # data from nearest clinic joined to case data \n  select(case_id, osm_id, name, amenity) %>%       # keep columns of interest, including id, name, type, and geometry of healthcare facility\n  rename(\"nearest_clinic\" = \"name\")                # re-name for clarity\n# Count cases by health facility\nhf_catchment <- linelist_sf_hf %>%   # begin with linelist including nearest clinic data\n  as.data.frame() %>%                # convert from shapefile to dataframe\n  count(nearest_clinic,              # count rows by \"name\" (of clinic)\n        name = \"case_n\") %>%         # assign new counts column as \"case_n\"\n  arrange(desc(case_n))              # arrange in descending order\n\nhf_catchment                         # print to console##                          nearest_clinic case_n\n## 1                            Den Clinic    376\n## 2       Shriners Hospitals for Children    305\n## 3         GINER HALL COMMUNITY HOSPITAL    179\n## 4                             panasonic     61\n## 5 Princess Christian Maternity Hospital     33\n## 6                     ARAB EGYPT CLINIC     21\n## 7                                  <NA>     16\n## 8                  MABELL HEALTH CENTER      9\ntmap_mode(\"view\")   # set tmap mode to interactive  \n\n# plot the cases and clinic points \ntm_shape(linelist_sf_hf) +            # plot cases\n  tm_dots(size=0.08,                  # cases colored by nearest clinic\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # plot clinic facilities in large black dots\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # overlay with name of facility\ntm_view(set.view = c(-13.2284, 8.4699, 13), # adjust zoom (center coords, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cases, colored by nearest clinic\")"},{"path":"gis-basics.html","id":"buffers","chapter":"28 GIS basics","heading":"Buffers","text":"can also explore many cases located within 2.5km (~30 mins) walking distance closest health facility.Note: accurate distance calculations, better re-project sf object respective local map projection system UTM (Earth projected onto planar surface). example, simplicity stick World Geodetic System (WGS84) Geograhpic coordinate system (Earth represented spherical / round surface, therefore units decimal degrees). use general conversion : 1 decimal degree = ~111km.See information map projections coordinate systems esri article. blog talks different types map projection one can choose suitable projection depending area interest context map / analysis.First, create circular buffer radius ~2.5km around health facility. done function st_buffer() tmap. unit map lat/long decimal degrees, “0.02” interpreted. map coordinate system meters, number must provided meters.plot buffer zones , :**Second, intersect buffers cases (points) using st_join() join type st_intersects*. , data buffers joined points intersect .Now can count results: nrow(linelist_sf_hf_2k[.na(linelist_sf_hf_2k$osm_id.y),]) 1000 cases intersect buffer (value missing), live 30 mins walk nearest health facility.can visualize results cases intersect buffer appear red.","code":"\nsle_hf_2k <- sle_hf %>%\n  st_buffer(dist=0.02)       # decimal degrees translating to approximately 2.5km \ntmap_mode(\"plot\")\n# Create circular buffers\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # plot clinic facilities in large red dots\n  tm_dots(size=0.3, col='black')      \n# Intersect the cases with the buffers\nlinelist_sf_hf_2k <- linelist_sf_hf %>%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %>%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %>%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n# Cases which did not get intersected with any of the health facility buffers\nlinelist_sf_hf_2k %>% \n  filter(is.na(osm_id.y)) %>%\n  nrow()## [1] 1000\ntmap_mode(\"view\")\n\n# First display the cases in points\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# plot clinic facilities in large black dots\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# Then overlay the health facility buffers in polylines\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Highlight cases that are not part of any health facility buffers\n# in red dots  \ntm_shape(linelist_sf_hf_2k %>%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# add title  \ntm_layout(title = \"Cases by clinic catchment area\")"},{"path":"gis-basics.html","id":"other-spatial-joins","chapter":"28 GIS basics","heading":"Other spatial joins","text":"Alternative values argument join include (documentation)st_contains_properlyst_containsst_covered_byst_coversst_crossesst_disjointst_equals_exactst_equalsst_is_within_distancest_nearest_featurest_overlapsst_touchesst_within","code":""},{"path":"gis-basics.html","id":"choropleth-maps","chapter":"28 GIS basics","heading":"28.7 Choropleth maps","text":"Choropleth maps can useful visualize data pre-defined area, usually administrative unit health area. outbreak response can help target resource allocation specific areas high incidence rates, example.Now administrative unit names assigned cases (see section spatial joins, ), can start mapping case counts area (choropleth maps).Since also population data ADM3, can add information case_adm3 table created previously.begin dataframe created previous step case_adm3, summary table administrative unit number cases.population data sle_adm3_pop joined using left_join() dplyr basis common values across column admin3pcod case_adm3 dataframe, column adm_pcode sle_adm3_pop dataframe. See page Joining data).select() applied new dataframe, keep useful columns - total total populationCases per 10,000 populaton calculated new column mutate()Join table ADM3 polygons shapefile mappingMapping resultsWe can also map incidence rates","code":"\n# Add population data and calculate cases per 10K population\ncase_adm3 <- case_adm3 %>% \n     left_join(sle_adm3_pop,                             # add columns from pop dataset\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %>%  # join based on common values across these two columns\n     select(names(case_adm3), total) %>%                 # keep only important columns, including total population\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # make new column with case rate per 10000, rounded to 3 decimals\n\ncase_adm3                                                # print to console for viewing## # A tibble: 10 × 5\n## # Groups:   admin3pcod [10]\n##    admin3pcod admin3name     cases  total case_10kpop\n##    <chr>      <chr>          <int>  <int>       <dbl>\n##  1 SL040102   Mountain Rural   279  33993       82.1 \n##  2 SL040208   West III         243 210252       11.6 \n##  3 SL040207   West II          157 145109       10.8 \n##  4 SL040204   East II          128  99821       12.8 \n##  5 SL040201   Central I         57  69683        8.18\n##  6 SL040206   West I            48  60186        7.98\n##  7 SL040203   East I            45  68284        6.59\n##  8 SL040202   Central II        20  23874        8.38\n##  9 SL040205   East III          19 500134        0.38\n## 10 <NA>       <NA>               4     NA       NA\ncase_adm3_sf <- case_adm3 %>%                 # begin with cases & rate by admin unit\n  left_join(sle_adm3, by=\"admin3pcod\") %>%    # join to shapefile data by common column\n  select(objectid, admin3pcod,                # keep only certain columns of interest\n         admin3name = admin3name.x,           # clean name of one column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %>%                        # keep geometry so polygons can be plotted\n  drop_na(objectid) %>%                       # drop any empty rows\n  st_as_sf()                                  # convert to shapefile\n# tmap mode\ntmap_mode(\"plot\")               # view static map\n\n# plot polygons\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # color by number of cases column\n        tm_text(\"admin3name\")   # name display\n# Cases per 10K population\ntmap_mode(\"plot\")             # static viewing mode\n\n# plot\ntm_shape(case_adm3_sf) +                # plot polygons\n  tm_polygons(\"case_10kpop\",            # color by column containing case rate\n              breaks=c(0, 10, 50, 100), # define break points for colors\n              palette = \"Purples\"       # use a purple color palette\n              ) +\n  tm_text(\"admin3name\")                 # display text"},{"path":"gis-basics.html","id":"mapping-with-ggplot2","chapter":"28 GIS basics","heading":"28.8 Mapping with ggplot2","text":"already familiar using ggplot2, can use package instead create static maps data. geom_sf() function draw different objects based features (points, lines, polygons) data. example, can use geom_sf() ggplot() using sf data polygon geometry create choropleth map.illustrate works, can start ADM3 polygons shapefile used earlier. Recall Admin Level 3 regions Sierra Leone:can use left_join() function dplyr add data like map shapefile object. case, going use case_adm3 data frame created earlier summarize case counts administrative region; however, can use approach map data stored data frame.make column chart case counts region, using ggplot2, call geom_col() follows:want use ggplot2 instead make choropleth map case counts, can use similar syntax call geom_sf() function:can customize appearance map using grammar consistent across ggplot2, example:R users comfortable working ggplot2, geom_sf() offers simple direct implementation suitable basic map visualizations. learn , read geom_sf() vignette ggplot2 book.","code":"\nsle_adm3## Simple feature collection with 12 features and 19 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 12 × 20\n##    objectid admin3name     admin3pcod admin3ref_n  admin2name admin2pcod admin1name admin1pcod admin0name admin0pcod date      \n##  *    <dbl> <chr>          <chr>      <chr>        <chr>      <chr>      <chr>      <chr>      <chr>      <chr>      <date>    \n##  1      155 Koya Rural     SL040101   Koya Rural   Western A… SL0401     Western    SL04       Sierra Le… SL         2016-08-01\n##  2      156 Mountain Rural SL040102   Mountain Ru… Western A… SL0401     Western    SL04       Sierra Le… SL         2016-08-01\n##  3      157 Waterloo Rural SL040103   Waterloo Ru… Western A… SL0401     Western    SL04       Sierra Le… SL         2016-08-01\n##  4      158 York Rural     SL040104   York Rural   Western A… SL0401     Western    SL04       Sierra Le… SL         2016-08-01\n##  5      159 Central I      SL040201   Central I    Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n##  6      160 East I         SL040203   East I       Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n##  7      161 East II        SL040204   East II      Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n##  8      162 Central II     SL040202   Central II   Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n##  9      163 West III       SL040208   West III     Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n## 10      164 West I         SL040206   West I       Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n## 11      165 West II        SL040207   West II      Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n## 12      167 East III       SL040205   East III     Western A… SL0402     Western    SL04       Sierra Le… SL         2016-08-01\n## # ℹ 9 more variables: valid_on <date>, valid_to <date>, shape_leng <dbl>, shape_area <dbl>, rowcacode0 <chr>,\n## #   rowcacode1 <chr>, rowcacode2 <chr>, rowcacode3 <chr>, geometry <MULTIPOLYGON [°]>\nsle_adm3_dat <- sle_adm3 %>% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join = retain only if in both data objects\n\nselect(sle_adm3_dat, admin3name.x, cases) # print selected variables to console## Simple feature collection with 9 features and 2 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 9 × 3\n##   admin3name.x   cases                                                                                geometry\n##   <chr>          <int>                                                                      <MULTIPOLYGON [°]>\n## 1 Mountain Rural   279 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.474296, -13.21455 8.474298, -...\n## 2 Central I         57 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.489513, -13.22663 8.489229, -1...\n## 3 East I            45 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.494041, -13.2096 8.494025, -13...\n## 4 East II          128 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.49186, -13.22633 8.491814, -1...\n## 5 Central II        20 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.49146, -13.23131 8.491294, -1...\n## 6 West III         243 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.49621, -13.28338 8.496086, -1...\n## 7 West I            48 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.493132, -13.24627 8.493131, -1...\n## 8 West II          157 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.485505, -13.25657 8.485504, -...\n## 9 East III          19 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.485757, -13.20431 8.485577, -...\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # reorder x axis by descending 'cases'\n               y=cases)) +                                  # y axis is number of cases by region\n  theme_bw() +\n  labs(                                                     # set figure text\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # angle x-axis labels 45 degrees to fit better\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # set fill to vary by case count variable\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # change color gradient\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # set figure text\n       subtitle = \"Admin level 3\"\n  )"},{"path":"gis-basics.html","id":"basemaps","chapter":"28 GIS basics","heading":"28.9 Basemaps","text":"","code":""},{"path":"gis-basics.html","id":"openstreetmap","chapter":"28 GIS basics","heading":"OpenStreetMap","text":"describe achieve basemap ggplot2 map using OpenStreetMap features. Alternative methods include using ggmap requires free registration Google (details).OpenStreetMap collaborative project create free editable map world. underlying geolocation data (e.g. locations cities, roads, natural features, airports, schools, hospitals, roads etc) considered primary output project.First load OpenStreetMap package, get basemap., create object map, define using function openmap() OpenStreetMap package (documentation). provide following:upperLeft lowerRight Two coordinate pairs specifying limits basemap tile\ncase ’ve put max min linelist rows, map respond dynamically data\ncase ’ve put max min linelist rows, map respond dynamically datazoom = (null determined automatically)type = type basemap - listed several possibilities code currently using first one ([1]) “osm”mergeTiles = chose TRUE basetiles merged oneIf plot basemap right now, using autoplot.OpenStreetMap() OpenStreetMap package, see units axes latitude/longitude coordinates. using different coordinate system. correctly display case residences (stored lat/long), must changed.\nThus, want convert map latitude/longitude openproj() function OpenStreetMap package. provide basemap map also provide Coordinate Reference System (CRS) want. providing “proj.4” character string WGS 1984 projection, can provide CRS ways well. (see page better understand proj.4 string )Now create plot see along axes latitude longitude coordinate. coordinate system converted. Now cases plot correctly overlaid!See tutorials info.","code":"\n# load package\npacman::p_load(OpenStreetMap)\n\n# Fit basemap by range of lat/long coordinates. Choose tile type\nmap <- OpenStreetMap::openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\nautoplot.OpenStreetMap(map)\n# Projection WGS84\nmap_latlon <- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n# Plot map. Must use \"autoplot\" in order to work with ggplot\nautoplot.OpenStreetMap(map_latlon)"},{"path":"gis-basics.html","id":"contoured-density-heatmaps","chapter":"28 GIS basics","heading":"28.10 Contoured density heatmaps","text":"describe achieve contoured density heatmap cases, basemap, beginning linelist (one row per case).Create basemap tile OpenStreetMap, described abovePlot cases linelist using latitude longitude columnsConvert points density heatmap stat_density_2d() ggplot2,basemap lat/long coordinates, can plot cases top using lat/long coordinates residence.Building function autoplot.OpenStreetMap() create basemap, ggplot2 functions easily add top, shown geom_point() :\nmap might difficult interpret, especially points overlapping. can instead plot 2d density map using ggplot2 function stat_density_2d(). still using linelist lat/lon coordinates, 2D kernel density estimation performed results displayed contour lines - like topographical map. Read full documentation .","code":"\n# Plot map. Must be autoplotted to work with ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # begin with the basemap\n  geom_point(                                       # add xy points from linelist lon and lat columns \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # drop legend entirely\n  labs(x = \"Longitude\",                             # titles & labels\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")"},{"path":"gis-basics.html","id":"time-series-heatmap","chapter":"28 GIS basics","heading":"Time series heatmap","text":"density heatmap shows cumulative cases. can examine outbreak time space faceting heatmap based month symptom onset, derived linelist.begin linelist, creating new column Year Month onset. format() function base R changes date displayed. case want “YYYY-MM”.Now, simply introduce facetting via ggplot2 density heatmap. facet_wrap() applied, using new column rows. set number facet columns 3 clarity.","code":"\n# Extract month of onset\nlinelist <- linelist %>% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examine the values \ntable(linelist$date_onset_ym, useNA = \"always\")## \n## 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 2015-02 2015-03 2015-04    <NA> \n##       7       9      31      90     199     179     128     112      60      52      53      29      51\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facet the plot by month-year of onset\n  facet_wrap(~ date_onset_ym, ncol = 4)               "},{"path":"gis-basics.html","id":"spatial-statistics","chapter":"28 GIS basics","heading":"28.11 Spatial statistics","text":"discussion far focused visualization spatial data. cases, may also interested using spatial statistics quantify spatial relationships attributes data. section provide brief overview key concepts spatial statistics, suggest resources helpful explore wish comprehensive spatial analyses.","code":""},{"path":"gis-basics.html","id":"spatial-relationships","chapter":"28 GIS basics","heading":"Spatial relationships","text":"can calculate spatial statistics, need specify relationships features data. many ways conceptualize spatial relationships, simple commonly-applicable model use adjacency - specifically, expect geographic relationship areas share border “neighbour” one another.can quantify adjacency relationships administrative region polygons sle_adm3 data using spdep package. specify queen contiguity, means regions neighbors share least one point along borders. alternative rook contiguity, requires regions share edge - case, irregular polygons, distinction trivial, cases choice queen rook can influential.matrix printed shows relationships 9 regions sle_adm3 data. score 0 indicates two regions neighbors, value 0 indicates neighbor relationship. values matrix scaled region total row weight 1.better way visualize neighbor relationships plotting :used adjacency approach identify neighboring polygons; neighbors identified also sometimes called contiguity-based neighbors. just one way choosing regions expected geographic relationship. common alternative approaches identifying geographic relationships generate distance-based neighbors; briefly, :K-nearest neighbors - Based distance centroids (geographically-weighted center polygon region), select n closest regions neighbors. maximum-distance proximity threshold may also specified. spdep, can use knearneigh() (see documentation).K-nearest neighbors - Based distance centroids (geographically-weighted center polygon region), select n closest regions neighbors. maximum-distance proximity threshold may also specified. spdep, can use knearneigh() (see documentation).Distance threshold neighbors - Select neighbors within distance threshold. spdep, neighbor relationships can identified using dnearneigh() (see documentation).Distance threshold neighbors - Select neighbors within distance threshold. spdep, neighbor relationships can identified using dnearneigh() (see documentation).","code":"\nsle_nb <- spdep::poly2nb(sle_adm3_dat, queen=T) # create neighbors \nsle_adjmat <- spdep::nb2mat(sle_nb)    # create matrix summarizing neighbor relationships\nsle_listw <- spdep::nb2listw(sle_nb)   # create listw (list of weights) object -- we will need this later\n\nsle_nb## Neighbour list object:\n## Number of regions: 9 \n## Number of nonzero links: 30 \n## Percentage nonzero weights: 37.03704 \n## Average number of links: 3.333333\nround(sle_adjmat, digits = 2)##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n## 1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n## 2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n## 3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n## 4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n## 5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n## 6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n## 7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n## 8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n## 9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\n## attr(,\"call\")\n## spdep::nb2mat(neighbours = sle_nb)\nplot(sle_adm3_dat$geometry) +                                           # plot region boundaries\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # add neighbor relationships"},{"path":"gis-basics.html","id":"spatial-autocorrelation","chapter":"28 GIS basics","heading":"Spatial autocorrelation","text":"Tobler’s oft-cited first law geography states “everything related everything else, near things related distant things.” epidemiology, often means risk particular health outcome given region similar neighboring regions far away. concept formalized spatial autocorrelation - statistical property geographic features similar values clustered together space. Statistical measures spatial autocorrelation can used quantify extent spatial clustering data, locate clustering occurs, identify shared patterns spatial autocorrelation distinct variables data. section gives overview common measures spatial autocorrelation calculate R.Moran’s - global summary statistic correlation value variable one region, values variable neighboring regions. Moran’s statistic typically ranges -1 1. value 0 indicates pattern spatial correlation, values closer 1 -1 indicate stronger spatial autocorrelation (similar values close together) spatial dispersion (dissimilar values close together), respectively.example, calculate Moran’s statistic quantify spatial autocorrelation Ebola cases mapped earlier (remember, subset cases simulated epidemic linelist dataframe). spdep package function, moran.test, can calculation us:output moran.test() function shows us Moran statistic round(moran_i$estimate[1],2). indicates presence spatial autocorrelation data - specifically, regions similar numbers Ebola cases likely close together. p-value provided moran.test() generated comparison expectation null hypothesis spatial autocorrelation, can used need report results formal hypothesis test.Local Moran’s - can decompose (global) Moran’s statistic calculated identify localized spatial autocorrelation; , identify specific clusters data. statistic, sometimes called Local Indicator Spatial Association (LISA) statistic, summarizes extent spatial autocorrelation around individual region. can useful finding “hot” “cold” spots map.show example, can calculate map Local Moran’s Ebola case counts used , local_moran() function spdep:Getis-Ord Gi* - another statistic commonly used hotspot analysis; large part, popularity statistic relates use Hot Spot Analysis tool ArcGIS. based assumption typically, difference variable’s value neighboring regions follow normal distribution. uses z-score approach identify regions significantly higher (hot spot) significantly lower (cold spot) values specified variable, compared neighbors.can calculate map Gi* statistic using localG() function spdep:can see, map Getis-Ord Gi* looks slightly different map Local Moran’s produced earlier. reflects method used calculate two statistics slightly different; one use depends specific use case research question interest.Lee’s L test - statistical test bivariate spatial correlation. allows test whether spatial pattern given variable x similar spatial pattern another variable, y, hypothesized related spatially x.give example, let’s test whether spatial pattern Ebola cases simulated epidemic correlated spatial pattern population. start, need population variable sle_adm3 data. can use total variable sle_adm3_pop dataframe loaded earlier.can quickly visualize spatial patterns two variables side side, see whether look similar:Visually, patterns seem dissimilar. can use lee.test() function spdep test statistically whether pattern spatial autocorrelation two variables related. L statistic close 0 correlation patterns, close 1 strong positive correlation (.e. patterns similar), close -1 strong negative correlation (.e. patterns inverse).output shows Lee’s L statistic two variables round(lee_test$estimate[1],2), indicates weak negative correlation. confirms visual assessment pattern cases population related one another, provides evidence spatial pattern cases strictly result population density high-risk areas.Lee L statistic can useful making kinds inferences relationship spatially distributed variables; however, describe nature relationship two variables detail, adjust confounding, spatial regression techniques needed. described briefly following section.","code":"\nmoran_i <-spdep::moran.test(sle_adm3_dat$cases,    # numeric vector with variable of interest\n                            listw=sle_listw)       # listw object summarizing neighbor relationships\n\nmoran_i                                            # print results of Moran's I test## \n##  Moran I test under randomisation\n## \n## data:  sle_adm3_dat$cases  \n## weights: sle_listw    \n## \n## Moran I statistic standard deviate = 1.6673, p-value = 0.04773\n## alternative hypothesis: greater\n## sample estimates:\n## Moran I statistic       Expectation          Variance \n##        0.22324408       -0.12500000        0.04362563\n# calculate local Moran's I\nlocal_moran <- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable of interest\n  listw=sle_listw                                  # listw object with neighbor weights\n)\n\n# join results to sf data\nsle_adm3_dat<- cbind(sle_adm3_dat, local_moran)    \n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n# Perform local G analysis\ngetis_ord <- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# join results to sf data\nsle_adm3_dat$getis_ord <- as.numeric(getis_ord)\n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\nsle_adm3_dat <- sle_adm3_dat %>% \n  rename(population = total)                          # rename 'total' to 'population'\ntmap_mode(\"plot\")\n\ncases_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arrange into 2x1 facets\nlee_test <- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 to compare\n  y=sle_adm3_dat$population,     # variable 2 to compare\n  listw=sle_listw                # listw object with neighbor weights\n)\n\nlee_test## \n##  Lee's L statistic randomisation\n## \n## data:  sle_adm3_dat$cases ,  sle_adm3_dat$population \n## weights: sle_listw  \n## \n## Lee's L statistic standard deviate = -0.74905, p-value = 0.7731\n## alternative hypothesis: greater\n## sample estimates:\n## Lee's L statistic       Expectation          Variance \n##       -0.12330323       -0.04007484        0.01234575"},{"path":"gis-basics.html","id":"spatial-regression","chapter":"28 GIS basics","heading":"Spatial regression","text":"may wish make statistical inferences relationships variables spatial data. cases, useful consider spatial regression techniques - , approaches regression explicitly consider spatial organization units data. reasons may need consider spatial regression models, rather standard regression models GLMs, include:Standard regression models assume residuals independent one another. presence strong spatial autocorrelation, residuals standard regression model likely spatially autocorrelated well, thus violating assumption. can lead problems interpreting model results, case spatial model preferred.Standard regression models assume residuals independent one another. presence strong spatial autocorrelation, residuals standard regression model likely spatially autocorrelated well, thus violating assumption. can lead problems interpreting model results, case spatial model preferred.Regression models also typically assume effect variable x constant observations. case spatial heterogeneity, effects wish estimate may vary space, may interested quantifying differences. case, spatial regression models offer flexibility estimating interpreting effects.Regression models also typically assume effect variable x constant observations. case spatial heterogeneity, effects wish estimate may vary space, may interested quantifying differences. case, spatial regression models offer flexibility estimating interpreting effects.details spatial regression approaches beyond scope handbook. section instead provide overview common spatial regression models uses, refer references may use wish explore area .Spatial error models - models assume error terms across spatial units correlated, case data violate assumptions standard OLS model. Spatial error models also sometimes referred simultaneous autoregressive (SAR) models. can fit using errorsarlm() function spatialreg package (spatial regression functions used part spdep).Spatial lag models - models assume dependent variable region influenced value independent variables , also values variables regions neighboring . Like spatial error models, spatial lag models also sometimes described simultaneous autoregressive (SAR) models. can fit using lagsarlm() function spatialreg package.spdep package contains several useful diagnostic tests deciding standard OLS, spatial lag, spatial error models. tests, called Lagrange Multiplier diagnostics, can used identify type spatial dependence data choose model appropriate. function lm.LMtests() can used calculate Lagrange Multiplier tests. Anselin (1988) also provides useful flow chart tool decide spatial regression model use based results Lagrange Multiplier tests:Bayesian hierarchical models - Bayesian approaches commonly used applications spatial analysis, commonly disease mapping. preferred cases case data sparsely distributed (example, case rare outcome) statistically “noisy”, can used generate “smoothed” estimates disease risk accounting underlying latent spatial process. may improve quality estimates. also allow investigator pre-specification (via choice prior) complex spatial correlation patterns may exist data, can account spatially-dependent -independent variation independent dependent variables. R, Bayesian hierarchical models can fit using CARbayes package (see vignette) R-INLA (see website textbook). R can also used call external software Bayesian estimation, JAGS WinBUGS.","code":""},{"path":"gis-basics.html","id":"resources-21","chapter":"28 GIS basics","heading":"28.12 Resources","text":"R Simple Features sf package vignetteR Simple Features sf package vignetteR tmap package vignetteR tmap package vignetteggmap: Spatial Visualization ggplot2ggmap: Spatial Visualization ggplot2Intro making maps R, overview different packagesIntro making maps R, overview different packagesSpatial Data R (EarthLab course)Spatial Data R (EarthLab course)Applied Spatial Data Analysis R textbookApplied Spatial Data Analysis R textbookSpatialEpiApp - Shiny app downloadable R package, allowing provide data conduct mapping, cluster analysis, spatial statistics.SpatialEpiApp - Shiny app downloadable R package, allowing provide data conduct mapping, cluster analysis, spatial statistics.Introduction Spatial Econometrics R workshopAn Introduction Spatial Econometrics R workshop","code":""},{"path":"tables-for-presentation.html","id":"tables-for-presentation","chapter":"29 Tables for presentation","heading":"29 Tables for presentation","text":"HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22This page demonstrates convert summary data frames presentation-ready tables flextable package. tables can inserted powerpoint slides, HTML pages, PDF Word documents, etc.Understand using flextable, must create summary table data frame. Use methods Descriptive tables Pivoting data pages tabulations, cross-tabulations, pivoting, calculating descriptive statistics. resulting data frame can passed flextable display formatting.many R packages can used craft tables presentation - chose highlight flextable page. example using knitr package kable() function can found Contact Tracing page. Likewise, DT package highlighted page Dashboards Shiny. Others GT huxtable mentione Suggested packages page.","code":""},{"path":"tables-for-presentation.html","id":"preparation-20","chapter":"29 Tables for presentation","heading":"29.1 Preparation","text":"","code":""},{"path":"tables-for-presentation.html","id":"load-packages-19","chapter":"29 Tables for presentation","heading":"Load packages","text":"Install load flextable. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization"},{"path":"tables-for-presentation.html","id":"import-data-16","chapter":"29 Tables for presentation","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"tables-for-presentation.html","id":"prepare-table","chapter":"29 Tables for presentation","heading":"Prepare table","text":"beginning use flextable need create table data frame. See page Descriptive tables Pivoting data learn create data frame using packages janitor dplyr. must arrange content rows columns want displayed. , data frame passed flextable display colors, headers, fonts, etc.example Descriptive tables page converting case linelist data frame summarises patient outcomes CT values hospital, Totals row bottom. output saved table.","code":"\ntable <- linelist %>% \n  \n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                    # Arrange rows from lowest to highest (Total row at bottom)\n\ntable  # print## # A tibble: 7 × 8\n## # Groups:   hospital [7]\n##   hospital                             N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death ct_value_Death\n##   <chr>                                  <int>     <int> <chr>                  <dbl>   <int> <chr>              <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH)     325       126 38.8%                     22     199 61.2%                 22\n## 2 Central Hospital                         358       165 46.1%                     22     193 53.9%                 22\n## 3 Other                                    685       290 42.3%                     21     395 57.7%                 22\n## 4 Military Hospital                        708       309 43.6%                     22     399 56.4%                 21\n## 5 Missing                                 1125       514 45.7%                     21     611 54.3%                 21\n## 6 Port Hospital                           1364       579 42.4%                     21     785 57.6%                 22\n## 7 Total                                   3440      1469 42.7%                     22    1971 57.3%                 22"},{"path":"tables-for-presentation.html","id":"basic-flextable","chapter":"29 Tables for presentation","heading":"29.2 Basic flextable","text":"","code":""},{"path":"tables-for-presentation.html","id":"create-a-flextable","chapter":"29 Tables for presentation","heading":"Create a flextable","text":"create manage flextable objects, first pass data frame flextable() function. save result my_table.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22After , can progressively pipe my_table object flextable formatting functions.page sake clarity save table intermediate steps my_table, adding flextable functions bit--bit. want see code beginning end written one chunk, visit code together section .general syntax line flextable code follows:function(table, = X, j = X, part = \"X\"), :\n‘function’ can one many different functions, width() determine column widths, bg() set background colours, align() set whether text centre/right/left aligned, .\ntable = name data frame, although need stated data frame piped function.\npart = refers part table function applied . E.g. “header”, “body” “”.\n= specifies row apply function , ‘X’ row number. multiple rows, e.g. first third rows, one can specify: = c(1:3). Note ‘body’ selected, first row starts underneath header section.\nj = specifies column apply function , ‘x’ column number name. multiple columns, e.g. fifth sixth, one can specify: j = c(5,6).\n‘function’ can one many different functions, width() determine column widths, bg() set background colours, align() set whether text centre/right/left aligned, .table = name data frame, although need stated data frame piped function.part = refers part table function applied . E.g. “header”, “body” “”.= specifies row apply function , ‘X’ row number. multiple rows, e.g. first third rows, one can specify: = c(1:3). Note ‘body’ selected, first row starts underneath header section.j = specifies column apply function , ‘x’ column number name. multiple columns, e.g. fifth sixth, one can specify: j = c(5,6).can find complete list flextable formatting function review documentation entering ?flextable.","code":"\nmy_table <- flextable(table) \nmy_table"},{"path":"tables-for-presentation.html","id":"column-width","chapter":"29 Tables for presentation","heading":"Column width","text":"can use autofit() function, nicely stretches table cell one row text. function qflextable() convenient shorthand flextable() autofit().hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22However, might always appropriate, especially long values within cells, meaning table might fit page.Instead, can specify widths width() function. can take playing around know width value put. example , specify different widths column 1, column 2, columns 4 8.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% autofit()\nmy_table <- my_table %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table"},{"path":"tables-for-presentation.html","id":"column-headers","chapter":"29 Tables for presentation","heading":"Column headers","text":"want clearer headers easier interpretation table contents.table, want add second header layer columns covering subgroups can grouped together. add_header_row() function top = TRUE. provide new name column values =, leaving empty values \"\" columns know merge together later.also rename header names now-second header separate set_header_labels() command.Finally, “combine” certain column headers top header use merge_at() merge column headers top header row.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  \n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    \n  set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Horizontally merge columns 6 to 8 in new header row\n\nmy_table  # print"},{"path":"tables-for-presentation.html","id":"borders-and-background","chapter":"29 Tables for presentation","heading":"Borders and background","text":"can adjust borders, internal lines, etc. various flextable functions. often easier start removing existing borders border_remove()., can apply default border themes passing table theme_box(), theme_booktabs(), theme_alafoli().can add vertical horizontal lines variety functions. hline() vline() add lines specified row column, respectively. Within , must specify part = either “”, “body”, “header”. vertical lines, specify column j =, horizontal lines row =. functions like vline_right(), vline_left(), hline_top(), hline_bottom() add lines outsides .functions, actual line style must specified border = must output separate command using fp_border() function officer package. function helps define width color line. can define table commands, shown .HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\n# define style for border line\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# add border lines to table\nmy_table <- my_table %>% \n\n  # Remove all existing borders\n  border_remove() %>%  \n  \n  # add horizontal lines via a pre-determined theme setting\n  theme_booktabs() %>% \n  \n  # add vertical lines to separate Recovered and Died sections\n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style)       # at column 5\n\nmy_table"},{"path":"tables-for-presentation.html","id":"font-and-alignment","chapter":"29 Tables for presentation","heading":"Font and alignment","text":"centre-align columns aside left-column hospital names, using align() function flextable.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Additionally, can increase header font size change bold. can also change total row bold.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22We can ensure proportion columns display one decimal place using function colformat_num(). Note also done data management stage round() function.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\nmy_table <-  my_table %>%  \n  fontsize(i = 1, size = 12, part = \"header\") %>%   # adjust font size of header\n  bold(i = 1, bold = TRUE, part = \"header\") %>%     # adjust bold face of header\n  bold(i = 7, bold = TRUE, part = \"body\")           # adjust bold face of total row (row 7 of body)\n\nmy_table\nmy_table <- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table"},{"path":"tables-for-presentation.html","id":"merge-cells","chapter":"29 Tables for presentation","heading":"Merge cells","text":"Just merge cells horizontally header row, can also merge cells vertically using merge_at() specifying rows () column (j). merge “Hospital” “Total cases known outcome” values vertically give space.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table"},{"path":"tables-for-presentation.html","id":"background-color","chapter":"29 Tables for presentation","heading":"Background color","text":"distinguish content table headers, may want add additional formatting. e.g. changing background color. example change table body gray.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table "},{"path":"tables-for-presentation.html","id":"conditional-formatting","chapter":"29 Tables for presentation","heading":"29.3 Conditional formatting","text":"can highlight values column meet certain rule, e.g. 55% cases died. Simply put criteria = j = argument, preceded tilde ~. Reference column data frame, display heading values.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Or, can highlight entire row meeting certain criterion, hospital interest. just remove column (j) specification criteria apply columns.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% \n  bg(j = 7, i = ~ Pct_Death >= 55, part = \"body\", bg = \"red\") \nmy_table %>% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") "},{"path":"tables-for-presentation.html","id":"tbl_pres_all","chapter":"29 Tables for presentation","heading":"29.4 All code together","text":"show code sections together.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization\n\ntable <- linelist %>% \n\n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known) %>%                                 # Arrange rows from lowest to highest (Total row at bottom)\n\n  # formatting\n  ############\n  flextable() %>%              # table is piped in from above\n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\") %>%  \n  border_remove() %>%  \n  theme_booktabs() %>% \n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style) %>%   # at column 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\") %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1) %>% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %>% \n  bg(., part = \"body\", bg = \"gray95\")  %>% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %>% \n  colformat_num(., j = c(4,7), digits = 1) %>%\n  bold(i = 1, bold = TRUE, part = \"header\") %>% \n  bold(i = 7, bold = TRUE, part = \"body\")## `summarise()` has grouped output by 'hospital'. You can override using the `.groups` argument.\ntable"},{"path":"tables-for-presentation.html","id":"saving-your-table","chapter":"29 Tables for presentation","heading":"29.5 Saving your table","text":"different ways table can integrated output.","code":""},{"path":"tables-for-presentation.html","id":"save-single-table","chapter":"29 Tables for presentation","heading":"Save single table","text":"can export tables Word, PowerPoint HTML image (PNG) files. , use one following functions:save_as_docx()save_as_pptx()save_as_image()save_as_html()instance save table word document. Note syntax first argument - can just provide name flextable object e.g. my_table, can give “name” shown (name “table”). name, appear title table Word. also demonstrate code save PNG image.Note packages webshot webshot2 required save flextable image. Images may come transparent backgrounds.want view ‘live’ version flextable output intended document format, use print() specify one preview =. document “pop-” open computer specified software program, saved. can useful check table fits one page/slide can quickly copy another document, can use print method argument preview set “pptx” “docx”.","code":"\n# Edit the 'my table' as needed for the title of table.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\nprint(my_table, preview = \"docx\") # Word document example\nprint(my_table, preview = \"pptx\") # Powerpoint example"},{"path":"tables-for-presentation.html","id":"print-table-in-r-markdown","chapter":"29 Tables for presentation","heading":"Print table in R markdown","text":"table can integrated automated document, R markdown output, table object called within R markdown chunk. means table can updated part report data might change, numbers can refreshed.See detail Reports R Markdown page handbook.","code":""},{"path":"tables-for-presentation.html","id":"resources-22","chapter":"29 Tables for presentation","heading":"29.6 Resources","text":"full flextable book : https://ardata-fr.github.io/flextable-book/\nGithub site \nmanual flextable functions can found hereA gallery beautiful example flextable tables code can accessed ","code":""},{"path":"ggplot-basics.html","id":"ggplot-basics","chapter":"30 ggplot basics","heading":"30 ggplot basics","text":"ggplot2 popular data visualisation R package. ggplot() function core package, whole approach colloquially known “ggplot” resulting figures sometimes affectionately called “ggplots”. “gg” names reflects “grammar graphics” used construct figures. ggplot2 benefits wide variety supplementary R packages enhance functionality.syntax significantly different base R plotting, learning curve associated . Using ggplot2 generally requires user format data way highly tidyverse compatible, ultimately makes using packages together effective.page cover fundamentals plotting ggplot2. See page ggplot tips suggestions advanced techniques make plots really look nice.several extensive ggplot2 tutorials linked resources section. can also download data visualization ggplot cheatsheet RStudio website. want inspiration ways creatively visualise data, suggest reviewing websites like R graph gallery Data--viz.","code":""},{"path":"ggplot-basics.html","id":"preparation-21","chapter":"30 ggplot basics","heading":"30.1 Preparation","text":"","code":""},{"path":"ggplot-basics.html","id":"load-packages-20","chapter":"30 ggplot basics","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other data management tools\n  janitor,        # cleaning and summary tables\n  ggforce,        # ggplot extras\n  rio,            # import/export\n  here,           # file locator\n  stringr         # working with characters   \n)"},{"path":"ggplot-basics.html","id":"import-data-17","chapter":"30 ggplot basics","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).first 50 rows linelist displayed . focus continuous variables age, wt_kg (weight kilos), ct_blood (CT values), days_onset_hosp (difference onset date hospitalisation).","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot-basics.html","id":"general-cleaning","chapter":"30 ggplot basics","heading":"General cleaning","text":"preparing data plot, best make data adhere “tidy” data standards much possible. achieve expanded data management pages handbook, Cleaning data core functions.simple ways can prepare data make better plotting can include making contents data better display - necessarily equate better data manipulation. example:Replace NA values character column character string “Unknown”Consider converting column class factor values prescribed ordinal levelsClean columns “data friendly” values underscores etc changed normal text title case (see Characters strings)examples action:","code":"\n# make display version of columns with more friendly names\nlinelist <- linelist %>%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m to Male \n                            gender == \"f\" ~ \"Female\",      # f to Female,\n                            is.na(gender) ~ \"Unknown\"),    # NA to Unknown\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # replace NA outcome with \"unknown\"\n  )"},{"path":"ggplot-basics.html","id":"pivoting-longer","chapter":"30 ggplot basics","heading":"Pivoting longer","text":"matter data structure, ggplot2 often also want pivot data longer formats. Read page Pivoting data.example, say want plot data “wide” format, case linelist symptoms. create mini-linelist called symptoms_data contains case_id symptoms columns.first 50 rows mini-linelist look - see formatted “wide” symptom column:wanted plot number cases specific symptoms, limited fact symptom specific column. However, can pivot symptoms columns longer format like :first 50 rows. Note case 5 rows - one possible symptom. new columns symptom_name symptom_is_present result pivot. Note format may useful operations, useful plotting.","code":"\nsymptoms_data <- linelist %>% \n  select(c(case_id, fever, chills, cough, aches, vomit))\nsymptoms_data_long <- symptoms_data %>%    # begin with \"mini\" linelist called symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivot all columns except case_id (all the symptoms columns)\n    names_to = \"symptom_name\",             # assign name for new column that holds the symptoms\n    values_to = \"symptom_is_present\") %>%  # assign name for new column that holds the values (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convert NA to \"unknown\""},{"path":"ggplot-basics.html","id":"basics-of-ggplot","chapter":"30 ggplot basics","heading":"30.2 Basics of ggplot","text":"“Grammar graphics” - ggplot2Plotting ggplot2 based “adding” plot layers design elements top one another, command added previous ones plus symbol (+). result multi-layer plot object can saved, modified, printed, exported, etc.ggplot objects can highly complex, basic order layers usually look like :Begin baseline ggplot() command - “opens” ggplot allow subsequent functions added +. Typically dataset also specified commandAdd “geom” layers - functions visualize data geometries (shapes), e.g. bar graph, line plot, scatter plot, histogram (combination!). functions start geom_ prefix.Add design elements plot axis labels, title, fonts, sizes, color schemes, legends, axes rotationA simple example skeleton code follows. explain component sections .","code":"\n# plot data from my_data columns as red points\nggplot(data = my_data)+                   # use the dataset \"my_data\"\n  geom_point(                             # add a layer of points (dots)\n    mapping = aes(x = col1, y = col2),    # \"map\" data column to axes\n    color = \"red\")+                       # other specification for the geom\n  labs()+                                 # here you add titles, axes labels, etc.\n  theme()                                 # here you adjust color, font, size etc of non-data plot elements (axes, title, etc.) "},{"path":"ggplot-basics.html","id":"ggplot","chapter":"30 ggplot basics","heading":"30.3 ggplot()","text":"opening command ggplot2 plot ggplot(). command simply creates blank canvas upon add layers. “opens” way layers added + symbol.Typically, command ggplot() includes data = argument plot. sets default dataset used subsequent layers plot.command end + closing parentheses. leaves command “open”. ggplot execute/appear full command includes final layer without + end.","code":"\n# This will create plot that is a blank canvas\nggplot(data = linelist)"},{"path":"ggplot-basics.html","id":"geoms","chapter":"30 ggplot basics","heading":"30.4 Geoms","text":"blank canvas certainly sufficient - need create geometries (shapes) data (e.g. bar plots, histograms, scatter plots, box plots).done adding layers “geoms” initial ggplot() command. many ggplot2 functions create “geoms”. functions begins “geom_”, refer generically geom_XXXX(). 40 geoms ggplot2 many others created fans. View ggplot2 gallery. common geoms listed :Histograms - geom_histogram()Bar charts - geom_bar() geom_col() (see “Bar plot” section)Box plots - geom_boxplot()Points (e.g. scatter plots) - geom_point()Line graphs - geom_line() geom_path()Trend lines - geom_smooth()one plot can display one multiple geoms. added previous ggplot2 commands +, plotted sequentially later geoms plotted top previous ones.","code":""},{"path":"ggplot-basics.html","id":"ggplot_basics_mapping","chapter":"30 ggplot basics","heading":"30.5 Mapping data to the plot","text":"geom functions must told use create shapes - must tell map (assign) columns data components plot like axes, shape colors, shape sizes, etc. geoms, essential components must mapped columns data x-axis, (necessary) y-axis.“mapping” occurs mapping = argument. mappings provide mapping must wrapped aes() function, write something like mapping = aes(x = col1, y = col2), shown ., ggplot() command data set case linelist. mapping = aes() argument column age mapped x-axis, column wt_kg mapped y-axis.+, plotting commands continue. shape created “geom” function geom_point(). geom inherits mappings ggplot() command - knows axis-column assignments proceeds visualize relationships points canvas.another example, following commands utilize data, slightly different mapping, different geom. geom_histogram() function requires column mapped x-axis, counts y-axis generated automatically.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()"},{"path":"ggplot-basics.html","id":"plot-aesthetics","chapter":"30 ggplot basics","heading":"Plot aesthetics","text":"ggplot terminology plot “aesthetic” specific meaning. refers visual property plotted data. Note “aesthetic” refers data plotted geoms/shapes - surrounding display titles, axis labels, background color, might associate word “aesthetics” common English. ggplot details called “themes” adjusted within theme() command (see section).Therefore, plot object aesthetics can colors, sizes, transparencies, placement, etc. plotted data. geoms aesthetic options, many can used geoms. examples:shape = Display point geom_point() dot, star, triangle, square…fill = interior color (e.g. bar boxplot)color = exterior line bar, boxplot, etc., point color using geom_point()size = Size (e.g. line thickness, point size)alpha = Transparency (1 = opaque, 0 = invisible)binwidth = Width histogram binswidth = Width “bar plot” columnslinetype = Line type (e.g. solid, dashed, dotted)plot object aesthetics can assigned values two ways:Assigned static value (e.g. color = \"blue\") apply across plotted observationsAssigned column data (e.g. color = hospital) display observation depends value column","code":""},{"path":"ggplot-basics.html","id":"set-to-a-static-value","chapter":"30 ggplot basics","heading":"Set to a static value","text":"want plot object aesthetic static, - every observation data, write assignment within geom outside mapping = aes() statement. assignments look like size = 1 color = \"blue\". two examples:first example, mapping = aes() ggplot() command axes mapped age weight columns data. plot aesthetics color =, size =, alpha = (transparency) assigned static values. clarity, done geom_point() function, may add geoms afterward take different values plot aesthetics.second example, histogram requires x-axis mapped column. histogram binwidth =, color =, fill = (internal color), alpha = set within geom static values.","code":"\n# scatterplot\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # set data and axes mapping\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # set static point aesthetics\n\n# histogram\nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"blue\",               # bin interior color\n    alpha = 0.1)                 # bin transparency"},{"path":"ggplot-basics.html","id":"scaled-to-column-values","chapter":"30 ggplot basics","heading":"Scaled to column values","text":"alternative scale plot object aesthetic values column. approach, display aesthetic depend observation’s value column data. column values continuous, display scale (legend) aesthetic continuous. column values discrete, legend display value plotted data appear distinctly “grouped” (read grouping section page).achieve , map plot aesthetic column name (quotes). must done within mapping = aes() function (note: several places code can make mapping assignments, discussed ).Two examples .first example, color = aesthetic (point) mapped column age - scale appeared legend! now just note scale exists - show modify later sections.second example two new plot aesthetics also mapped columns (color = size =), plot aesthetics shape = alpha = mapped static values outside mapping = aes() function.Note: Axes assignments always assigned columns data (static values), always done within mapping = aes().becomes important keep track plot layers aesthetics making complex plots - example plots multiple geoms. example , size = aesthetic assigned twice - geom_point() geom_smooth() - times static value.","code":"\n# scatterplot\nggplot(data = linelist,   # set data\n       mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age)\n       )+     # map color to age\n  geom_point()         # display data as points \n\n# scatterplot\nggplot(data = linelist,   # set data\n       mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age,       # map color to age\n         size = age))+      # map size to age\n  geom_point(             # display data as points\n    shape = \"diamond\",      # points display as diamonds\n    alpha = 0.3)            # point transparency at 30%\nggplot(data = linelist,\n       mapping = aes(           # map aesthetics to columns\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # add points for each row of data\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # add a trend line \n    method = \"lm\",              # with linear method\n    size = 2)                   # size (width of line) of 2"},{"path":"ggplot-basics.html","id":"ggplot_basics_map_loc","chapter":"30 ggplot basics","heading":"Where to make mapping assignments","text":"Aesthetic mapping within mapping = aes() can written several places plotting commands can even written . can written top ggplot() command, /individual geom beneath. nuances include:Mapping assignments made top ggplot() command inherited defaults across geom , like x = y = inheritedMapping assignments made within one geom apply geomLikewise, data = specified top ggplot() apply default geom , also specify data geom (difficult).Thus, following commands create plot:","code":"\n# These commands will produce the exact same plot\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))"},{"path":"ggplot-basics.html","id":"ggplotgroups","chapter":"30 ggplot basics","heading":"Groups","text":"can easily group data “plot group”. fact, already done !Assign “grouping” column appropriate plot aesthetic, within mapping = aes(). , demonstrated using continuous values assigned point size = column age. However works way discrete/categorical columns.example, want points displayed gender, set mapping = aes(color = gender). legend automatically appears. assignment can made within mapping = aes() top ggplot() command (inherited geom), set separate mapping = aes() within geom. approaches shown :Note depending geom, need use different arguments group data. geom_point() likely use color =, shape = size =. Whereas geom_bar() likely use fill =. just depends geom plot aesthetic want reflect groupings.information - basic way grouping data using group = argument within mapping = aes(). However, change colors, fill, shapes. create legend. Yet data grouped, statistical displays may affected.adjust order groups plot, see ggplot tips page page Factors. many examples grouped plots sections plotting continuous categorical data.","code":"\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n# This alternative code produces the same plot\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)"},{"path":"ggplot-basics.html","id":"ggplot_basics_facet","chapter":"30 ggplot basics","heading":"30.6 Facets / Small-multiples","text":"Facets, “small-multiples”, used split one plot multi-panel figure, one panel (“facet”) per group data. type plot created multiple times, one using sub-group dataset.Faceting functionality comes ggplot2, legends axes facet “panels” automatically aligned. packages discussed ggplot tips page used combine completely different plots (cowplot patchwork) one figure.Faceting done one following ggplot2 functions:facet_wrap() show different panel level single variable. One example showing different epidemic curve hospital region. Facets ordered alphabetically, unless variable factor ordering defined.can invoke certain options determine layout facets, e.g. nrow = 1 ncol = 1 control number rows columns faceted plots arranged within.facet_grid() used want bring second variable faceting arrangement. panel grid shows intersection values two columns. example, epidemic curves hospital-age group combination hospitals along top (columns) age groups along sides (rows).nrow ncol relevant, subgroups presented gridEach functions accept formula syntax specify column(s) faceting. accept two columns, one side tilde ~.facet_wrap() often write one column preceded tilde ~ like facet_wrap(~hospital). However can write two columns facet_wrap(outcome ~ hospital) - unique combination display separate panel, arranged grid. headings show combined terms won’t specific logic columns vs. rows. providing one faceting variable, period . used placeholder side formula - see code examples.facet_wrap() often write one column preceded tilde ~ like facet_wrap(~hospital). However can write two columns facet_wrap(outcome ~ hospital) - unique combination display separate panel, arranged grid. headings show combined terms won’t specific logic columns vs. rows. providing one faceting variable, period . used placeholder side formula - see code examples.facet_grid() can also specify one two columns formula (grid rows ~ columns). want specify one, can place period . side tilde like facet_grid(. ~ hospital) facet_grid(hospital ~ .).facet_grid() can also specify one two columns formula (grid rows ~ columns). want specify one, can place period . side tilde like facet_grid(. ~ hospital) facet_grid(hospital ~ .).Facets can quickly contain overwhelming amount information - good ensure don’t many levels variable choose facet . quick examples malaria dataset (see Download handbook data) consists daily case counts malaria facilities, age group.import quick modifications simplicity:first 50 rows malaria data . Note column malaria_tot, also columns counts age group (used second, facet_grid() example).","code":"\n# These data are daily counts of malaria cases, by facility-day\nmalaria_data <- import(here(\"data\", \"malaria_facility_count_data.rds\")) %>%  # import\n  select(-submitted_date, -Province, -newid)                                 # remove unneeded columns"},{"path":"ggplot-basics.html","id":"facet_wrap","chapter":"30 ggplot basics","heading":"facet_wrap()","text":"moment, let’s focus columns malaria_tot District. Ignore age-specific count columns now. plot epidemic curves geom_col(), produces column day specified y-axis height given column malaria_tot (data already daily counts, use geom_col() - see “Bar plot” section ).add command facet_wrap(), specify tilde column facet (District case). can place another column left side tilde, - create one facet combination - recommend facet_grid() instead. use case, one facet created unique value District.","code":"\n# A plot with facets by district\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # plot the count data as columns\n  theme_minimal()+                              # simplify the background panels\n  labs(                                         # add plot labels, title, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # the facets are created"},{"path":"ggplot-basics.html","id":"facet_grid","chapter":"30 ggplot basics","heading":"facet_grid()","text":"can use facet_grid() approach cross two variables. Let’s say want cross District age. Well, need data transformations age columns get data ggplot-preferred “long” format. age groups columns - want single column called age_group another called num_cases. See page Pivoting data information process.Now first 50 rows data look like :pass two variables facet_grid(), easiest use formula notation (e.g. x ~ y) x rows y columns. plot, using facet_grid() show plots combination columns age_group District.","code":"\nmalaria_age <- malaria_data %>%\n  select(-malaria_tot) %>% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # choose columns to pivot longer\n    names_to = \"age_group\",      # column names become age group\n    values_to = \"num_cases\"      # values to a single column (num_cases)\n  ) %>%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(District ~ age_group)"},{"path":"ggplot-basics.html","id":"free-or-fixed-axes","chapter":"30 ggplot basics","heading":"Free or fixed axes","text":"axes scales displayed faceting default (fixed) across facets. helpful cross-comparison, always appropriate.using facet_wrap() facet_grid(), can add scales = \"free_y\" “free” release y-axes panels scale appropriately data subset. particularly useful actual counts small one subcategories trends otherwise hard see. Instead “free_y” can also write “free_x” x-axis (e.g. dates) “free” axes. Note facet_grid, y scales facets row, x scales facets column.using facet_grid , can add space = \"free_y\" space = \"free_x\" actual height width facet weighted values figure within. works scales = \"free\" (y x) already applied.","code":"\n# Free y-axis\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # plot the count data as columns\n  theme_minimal()+                              # simplify the background panels\n  labs(                                         # add plot labels, title, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # the facets are created"},{"path":"ggplot-basics.html","id":"factor-level-order-in-facets","chapter":"30 ggplot basics","heading":"Factor level order in facets","text":"See post re-order factor levels within facets.","code":""},{"path":"ggplot-basics.html","id":"storing-plots","chapter":"30 ggplot basics","heading":"30.7 Storing plots","text":"","code":""},{"path":"ggplot-basics.html","id":"saving-plots-1","chapter":"30 ggplot basics","heading":"Saving plots","text":"default run ggplot() command, plot printed Plots RStudio pane. However, can also save plot object using assignment operator <- giving name. print unless object name run. can also print wrapping plot name print(), necessary certain circumstances plot created inside loop used print multiple plots (see Iteration, loops, lists page).","code":"\n# define plot\nage_by_wt <- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# print\nage_by_wt    "},{"path":"ggplot-basics.html","id":"modifying-saved-plots","chapter":"30 ggplot basics","heading":"Modifying saved plots","text":"One nice thing ggplot2 can define plot (), add layers starting name. repeat commands created original plot!example, modify plot age_by_wt defined , include vertical line age 50, just add + begin adding additional layers plot.","code":"\nage_by_wt+\n  geom_vline(xintercept = 50)"},{"path":"ggplot-basics.html","id":"exporting-plots","chapter":"30 ggplot basics","heading":"Exporting plots","text":"Exporting ggplots made easy ggsave() function ggplot2. can work two ways, either:Specify name plot object, file path name extension\nexample: ggsave(my_plot, (\"plots\", \"my_plot.png\"))\nexample: ggsave(my_plot, (\"plots\", \"my_plot.png\"))Run command file path, save last plot printed\nexample: ggsave((\"plots\", \"my_plot.png\"))\nexample: ggsave((\"plots\", \"my_plot.png\"))can export png, pdf, jpeg, tiff, bmp, svg, several file types, specifying file extension file path.can also specify arguments width =, height =, units = (either “”, “cm”, “mm”). can also specify dpi = number plot resolution (e.g. 300). See function details entering ?ggsave reading documentation online.Remember can use () syntax provide desired file path. See Import export page information.","code":""},{"path":"ggplot-basics.html","id":"labels","chapter":"30 ggplot basics","heading":"30.8 Labels","text":"Surely want add adjust plot’s labels. easily done within labs() function added plot + just geoms .Within labs() can provide character strings arguements:x = y = x-axis y-axis title (labels)title = main plot titlesubtitle = subtitle plot, smaller text titlecaption = caption plot, bottom-right defaultHere plot made earlier, nicer labels:Note caption assignment used str_glue() stringr package implant dynamic R code within string text. caption show “Data :” date reflects maximum hospitalization date linelist. Read page Characters strings.note specifying legend title: one “legend title” argument, multiple scales legend. Within labs(), can write argument plot aesthetic used create legend, provide title way. example, assigned color = age create legend. Therefore, provide color = labs() assign legend title desired (“Age” capital ). create legend aes(fill = COLUMN), labs() write fill = adjust title legend. section color scales ggplot tips page provides details editing legends, alternative approach using scales_() functions.","code":"\nage_by_wt <- ggplot(\n  data = linelist,   # set data\n  mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age))+     # map color to age\n  geom_point()+           # display data as points\n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt"},{"path":"ggplot-basics.html","id":"ggplot_basics_themes","chapter":"30 ggplot basics","heading":"30.9 Themes","text":"One best parts ggplot2 amount control plot - can define anything! mentioned , design plot related data shapes/geometries adjusted within theme() function. example, plot background color, presence/absence gridlines, font/size/color/alignment text (titles, subtitles, captions, axis text…). adjustments can done one two ways:Add complete theme theme_() function make sweeping adjustments - include theme_classic(), theme_minimal(), theme_dark(), theme_light() theme_grey(), theme_bw() among othersAdjust tiny aspect plot individually within theme()","code":""},{"path":"ggplot-basics.html","id":"complete-themes","chapter":"30 ggplot basics","heading":"Complete themes","text":"quite straight-forward, demonstrate complete theme functions describe . Note micro-adjustments theme() made use complete theme.Write empty parentheses.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()"},{"path":"ggplot-basics.html","id":"modify-theme","chapter":"30 ggplot basics","heading":"Modify theme","text":"theme() function can take large number arguments, edits specific aspect plot. way cover arguments, describe general pattern show find argument name need. basic syntax :Within theme() write argument name plot element want edit, like plot.title =Provide element_() function argumentMost often, use element_text(), others include element_rect() canvas background colors, element_blank() remove plot elementsWithin element_() function, write argument assignments make fine adjustments desireSo, description quite abstract, examples.plot looks quite silly, serves show variety ways can adjust plot.begin plot age_by_wt defined just add theme_classic()finer adjustments add theme() include one argument plot element adjustIt can nice organize arguments logical sections. describe just used :legend.position = unique accepts simple values like “bottom”, “top”, “left”, “right”. generally, text-related arguments require place details within element_text().Title size element_text(size = 30)caption horizontal alignment element_text(hjust = 0) (right left)subtitle italicized element_text(face = \"italic\")especially common theme() arguments. recognize patterns, appending .x .y apply change one axis.many theme arguments! remember ? worry - impossible remember . Luckily tools help :tidyverse documentation modifying theme, complete list.TIP: Run theme_get() ggplot2 print list 90+ theme() arguments console.TIP: ever want remove element plot, can also theme(). Just pass element_blank() argument disappear completely. legends, set legend.position = \"none\".","code":"\nage_by_wt + \n  theme_classic()+                                 # pre-defined theme adjustments\n  theme(\n    legend.position = \"bottom\",                    # move legend to bottom\n    \n    plot.title = element_text(size = 30),          # size of title to 30\n    plot.caption = element_text(hjust = 0),        # left-align caption\n    plot.subtitle = element_text(face = \"italic\"), # italicize subtitle\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # adjusts only x-axis text\n    axis.text.y = element_text(size = 15),         # adjusts only y-axis text\n    \n    axis.title = element_text(size = 20)           # adjusts both axes titles\n    )     "},{"path":"ggplot-basics.html","id":"colors","chapter":"30 ggplot basics","heading":"30.10 Colors","text":"Please see section color scales ggplot tips page.","code":""},{"path":"ggplot-basics.html","id":"piping-into-ggplot2","chapter":"30 ggplot basics","heading":"30.11 Piping into ggplot2","text":"using pipes clean transform data, easy pass transformed data ggplot().pipes pass dataset function--function transition + ggplot() function called. Note case, need specify data = argument, automatically defined piped-dataset.might look:","code":"\nlinelist %>%                                                     # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )"},{"path":"ggplot-basics.html","id":"plot-continuous-data","chapter":"30 ggplot basics","heading":"30.12 Plot continuous data","text":"Throughout page, already seen many examples plotting continuous data. briefly consolidate present variations.\nVisualisations covered include:Plots one continuous variable:\nHistogram, classic graph present distribution continuous variable.\nBox plot (also called box whisker), show 25th, 50th, 75th percentiles, tail ends distribution, outliers (important limitations).\nJitter plot, show values points ‘jittered’ can (mostly) seen, even two value.\nViolin plot, show distribution continuous variable based symmetrical width ‘violin’.\nSina plot, combination jitter violin plots, individual points shown symmetrical shape distribution (via ggforce package).\nHistogram, classic graph present distribution continuous variable.Box plot (also called box whisker), show 25th, 50th, 75th percentiles, tail ends distribution, outliers (important limitations).Jitter plot, show values points ‘jittered’ can (mostly) seen, even two value.Violin plot, show distribution continuous variable based symmetrical width ‘violin’.Sina plot, combination jitter violin plots, individual points shown symmetrical shape distribution (via ggforce package).Scatter plot two continuous variables.Heat plots three continuous variables (linked Heat plots page)","code":""},{"path":"ggplot-basics.html","id":"histograms","chapter":"30 ggplot basics","heading":"Histograms","text":"Histograms may look like bar charts, distinct measure distribution continuous variable. spaces “bars”, one column provided geom_histogram().code generating histograms, group continuous data ranges display adjacent bars varying height. done using geom_histogram(). See “Bar plot” section ggplot basics page understand difference geom_histogram(), geom_bar(), geom_col().show distribution ages cases. Within mapping = aes() specify column want see distribution . can assign column either x y axis.rows assigned “bins” based numeric age, bins graphically represented bars. specify number bins bins = plot aesthetic, break points evenly spaced minimum maximum values histogram. bins = unspecified, appropriate number bins guessed message displayed plot:want specify number bins bins =, alternatively specify binwidth = units axis. give examples showing different bins bin widths:get smoothed proportions, can use geom_density():get “stacked” histogram (continuous column data), can one following:Use geom_histogram() fill = argument within aes() assigned grouping column, orUse geom_freqpoly(), likely easier read (can still set binwidth =)see proportions values, set y = after_stat(density) (use syntax exactly - changed data). Note: proportions show per group.shown (*note use color = vs. fill = ):want fun, try geom_density_ridges ggridges package (vignette .Read detail histograms tidyverse page geom_histogram().","code":"## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n# A) Regular histogram\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Fewer bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# D) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Stacked frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n# \"Stacked\" histogram\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frequency \nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frequency with proportion axis\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")"},{"path":"ggplot-basics.html","id":"box-plots","chapter":"30 ggplot basics","heading":"Box plots","text":"Box plots common, important limitations. can obscure actual distribution - e.g. bi-modal distribution. See R graph gallery data--viz article details. However, nicely display inter-quartile range outliers - can overlaid top types plots show distribution detail.remind various components boxplot:using geom_boxplot() create box plot, generally map one axis (x y) within aes(). axis specified determines plots horizontal vertical.geoms, create plot per group mapping aesthetic like color = fill = column within aes(). However, box plots achieve assigning grouping column un-assigned axis (x y). code boxplot age values dataset, second code display one box plot (non-missing) gender dataset. Note NA (missing) values appear separate box plot unless removed. example also set fill column outcome plot different color - necessary.code add box plot edges scatter plot (“marginal” plots) see page ggplot tips.","code":"\n# A) Overall boxplot\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # only y axis mapped (not x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Box plot by group\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # remove legend (redundant)\n  labs(title = \"B) Boxplot by gender\")      "},{"path":"ggplot-basics.html","id":"violin-jitter-and-sina-plots","chapter":"30 ggplot basics","heading":"Violin, jitter, and sina plots","text":"code creating violin plots (geom_violin) jitter plots (geom_jitter) show distributions. can specify fill color also determined data, inserting options within aes().can combine two using geom_sina() function ggforce package. sina plots jitter points shape violin plot. overlaid violin plot (adjusting transparencies) can easier visually interpret.","code":"\n# A) Jitter plot by group\nggplot(data = linelist %>% drop_na(outcome),      # remove missing values\n       mapping = aes(y = age,                     # Continuous variable\n           x = outcome,                           # Grouping variable\n           color = outcome))+                     # Color variable\n  geom_jitter()+                                  # Create the violin plot\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) Violin plot by group\nggplot(data = linelist %>% drop_na(outcome),       # remove missing values\n       mapping = aes(y = age,                      # Continuous variable\n           x = outcome,                            # Grouping variable\n           fill = outcome))+                       # fill variable (color)\n  geom_violin()+                                   # create the violin plot\n  labs(title = \"B) violin plot by gender\")    \n# A) Sina plot by group\nggplot(\n  data = linelist %>% drop_na(outcome), \n  aes(y = age,           # numeric variable\n      x = outcome)) +    # group variable\n  geom_violin(\n    aes(fill = outcome), # fill (color of violin background)\n    color = \"white\",     # white outline\n    alpha = 0.2)+        # transparency\n  geom_sina(\n    size=1,                # Change the size of the jitter\n    aes(color = outcome))+ # color (color of dots)\n  scale_fill_manual(       # Define fill for violin background by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Define colours for points by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Remove the gray background\n  theme(legend.position = \"none\") +                # Remove unnecessary legend\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      "},{"path":"ggplot-basics.html","id":"two-continuous-variables","chapter":"30 ggplot basics","heading":"Two continuous variables","text":"Following similar syntax, geom_point() allow plot two continuous variables scatter plot. useful showing actual values rather distributions. basic scatter plot age vs weight shown (). (B) use facet_grid() show relationship two continuous variables linelist.","code":"\n# Basic scatter plot of weight and age\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Scatter plot of weight and age by gender and Ebola outcome\nggplot(data = linelist %>% drop_na(gender, outcome), # filter retains non-missing gender/outcome\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) "},{"path":"ggplot-basics.html","id":"three-continuous-variables","chapter":"30 ggplot basics","heading":"Three continuous variables","text":"can display three continuous variables utilizing fill = argument create heat plot. color “cell” reflect value third continuous column data. See ggplot tips page page Heat plots details several examples.ways make 3D plots R, applied epidemiology often difficult interpret therefore less useful decision-making.","code":""},{"path":"ggplot-basics.html","id":"plot-categorical-data","chapter":"30 ggplot basics","heading":"30.13 Plot categorical data","text":"Categorical data can character values, logical (TRUE/FALSE), factors (see Factors page).","code":""},{"path":"ggplot-basics.html","id":"preparation-22","chapter":"30 ggplot basics","heading":"Preparation","text":"","code":""},{"path":"ggplot-basics.html","id":"data-structure","chapter":"30 ggplot basics","heading":"Data structure","text":"first thing understand categorical data whether exists raw observations like linelist cases, summary aggregate data frame holds counts proportions. state data impact plotting function use:data raw observations one row per observation, likely use geom_bar()data already aggregated counts proportions, likely use geom_col()","code":""},{"path":"ggplot-basics.html","id":"column-class-and-value-ordering","chapter":"30 ggplot basics","heading":"Column class and value ordering","text":"Next, examine class columns want plot. look hospital, first class() base R, tabyl() janitor.can see values within characters, hospital names, default ordered alphabetically. ‘’ ‘missing’ values, prefer last subcategories presenting breakdowns. change column factor re-order . covered detail Factors page.","code":"\n# View class of hospital column - we can see it is a character\nclass(linelist$hospital)## [1] \"character\"\n# Look at values and proportions within hospital column\nlinelist %>% \n  tabyl(hospital)##                              hospital    n    percent\n##                      Central Hospital  454 0.07710598\n##                     Military Hospital  896 0.15217391\n##                               Missing 1469 0.24949049\n##                                 Other  885 0.15030571\n##                         Port Hospital 1762 0.29925272\n##  St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n# Convert to factor and define level order so \"Other\" and \"Missing\" are last\nlinelist <- linelist %>% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\nlevels(linelist$hospital)## [1] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                        \"Central Hospital\"                    \n## [4] \"Military Hospital\"                    \"Other\"                                \"Missing\""},{"path":"ggplot-basics.html","id":"ggplot_basics_bars","chapter":"30 ggplot basics","heading":"geom_bar()","text":"Use geom_bar() want bar height (height stacked bar components) reflect number relevant rows data. bars gaps , unless width = plot aesthetic adjusted.Provide one axis column assignment (typically x-axis). provide x y, get Error: stat_count() can x y aesthetic.can create stacked bars adding fill = column assignment within mapping = aes()opposite axis titled “count” default, represents number rowsBelow, assigned outcome y-axis, just easily x-axis. longer character values, can sometimes look better flip bars sideways put legend bottom. may impact factor levels ordered - case reverse fct_rev() put missing bottom.","code":"\n# A) Outcomes in all cases\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Outcomes in all cases by hosptial\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")"},{"path":"ggplot-basics.html","id":"geom_col","chapter":"30 ggplot basics","heading":"geom_col()","text":"Use geom_col() want bar height (height stacked bar components) reflect pre-calculated values exists data. Often, summary “aggregated” counts, proportions.Provide column assignments axes geom_col(). Typically x-axis column discrete y-axis column numeric.Let’s say dataset outcomes:code using geom_col creating simple bar charts show distribution Ebola patient outcomes. geom_col, x y need specified. x categorical variable along x axis, y generated proportions column proportion.show breakdowns hospital, need table contain information, “long” format. create table frequencies combined categories outcome hospital (see Grouping data page grouping tips).create ggplot added formatting:Axis flip: Swapped axis around coord_flip() can read hospital names.Columns side--side: Added position = \"dodge\" argument bars death recover presented side side rather stacked. Note stacked bars default.Column width: Specified ‘width’, columns half thin full possible width.Column order: Reversed order categories y axis ‘’ ‘Missing’ bottom, scale_x_discrete(limits=rev). Note used rather scale_y_discrete hospital stated x argument aes(), even visually y axis. Ggplot seems present categories backwards unless tell .details: Labels/titles colours added within labs scale_fill_color respectively.Note proportions binary, may prefer drop ‘recover’ just show proportion died. just illustration purposes.using geom_col() dates data (e.g. epicurve aggregated data) - want adjust width = argument remove “gap” lines bars. using daily data set width = 1. weekly, width = 7. Months possible month different number days.","code":"## # A tibble: 2 × 3\n##   outcome     n proportion\n##   <chr>   <int>      <dbl>\n## 1 Death    1022       56.2\n## 2 Recover   796       43.8\n# Outcomes in all cases\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\noutcomes2 <- linelist %>% \n  drop_na(outcome) %>% \n  count(hospital, outcome) %>%  # get counts by hospital and outcome\n  group_by(hospital) %>%        # Group so proportions are out of hospital total\n  mutate(proportion = n/sum(n)*100) # calculate proportions of hospital total\n\nhead(outcomes2) # Preview data## # A tibble: 6 × 4\n## # Groups:   hospital [3]\n##   hospital                             outcome     n proportion\n##   <fct>                                <chr>   <int>      <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n## 2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n## 3 Port Hospital                        Death     785       57.6\n## 4 Port Hospital                        Recover   579       42.4\n## 5 Central Hospital                     Death     193       53.9\n## 6 Central Hospital                     Recover   165       46.1\n# Outcomes in all cases by hospital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # show pre-calculated proportion values\n      y = fct_rev(hospital),          # reverse level order so missing/other at bottom\n      fill = outcome),                # stacked by outcome\n    width = 0.5)+                    # thinner bars (out of 1)\n  theme_minimal() +                  # Minimal theme \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # legend title\n       y = \"Count\",                  # y axis title\n       x = \"Hospital of admission\")+ # x axis title\n  scale_fill_manual(                 # adding colors manually\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) "},{"path":"ggplot-basics.html","id":"geom_histogram","chapter":"30 ggplot basics","heading":"geom_histogram()","text":"Histograms may look like bar charts, distinct measure distribution continuous variable. spaces “bars”, one column provided geom_histogram(). arguments specific histograms bin_width = breaks = specify data binned. section continuous data page Epidemic curves provide additional detail.","code":""},{"path":"ggplot-basics.html","id":"resources-23","chapter":"30 ggplot basics","heading":"30.14 Resources","text":"huge amount help online, especially ggplot. See:ggplot2 cheat sheetanother cheat sheettidyverse ggplot basics pageplotting continuous variablesR Data Science pages data visualizationgraphics communicaton","code":""},{"path":"ggplot-tips.html","id":"ggplot-tips","chapter":"31 ggplot tips","heading":"31 ggplot tips","text":"page cover tips tricks make ggplots sharp fancy. See page ggplot basics fundamentals.several extensive ggplot2 tutorials linked Resources section. can also download data visualization ggplot cheatsheet RStudio website. strongly recommend peruse inspiration R graph gallery Data--viz.","code":""},{"path":"ggplot-tips.html","id":"preparation-23","chapter":"31 ggplot tips","heading":"31.1 Preparation","text":"","code":""},{"path":"ggplot-tips.html","id":"load-packages-21","chapter":"31 ggplot tips","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other\n  rio,            # import/export\n  here,           # file locator\n  stringr,        # working with characters   \n  scales,         # transform numbers\n  ggrepel,        # smartly-placed labels\n  gghighlight,    # highlight one part of plot\n  RColorBrewer    # color scales\n)"},{"path":"ggplot-tips.html","id":"import-data-18","chapter":"31 ggplot tips","heading":"Import data","text":"page, import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot-tips.html","id":"ggplot_tips_colors","chapter":"31 ggplot tips","heading":"31.2 Scales for color, fill, axes, etc.","text":"ggplot2, aesthetics plotted data (e.g. size, color, shape, fill, plot axis) mapped columns data, exact display can adjusted corresponding “scale” command. section explain common scale adjustments.","code":""},{"path":"ggplot-tips.html","id":"color-schemes","chapter":"31 ggplot tips","heading":"31.2.1 Color schemes","text":"One thing can initially difficult understand ggplot2 control color schemes. Note section discusses color plot objects (geoms/shapes) points, bars, lines, tiles, etc. adjust color accessory text, titles, background color see Themes section ggplot basics page.control “color” plot objects adjusting either color = aesthetic (exterior color) fill = aesthetic (interior color). One exception pattern geom_point(), really get control color =, controls color point (interior exterior).setting colour fill can use colour names recognized R like \"red\" (see complete list enter ?colors), specific hex colour \"#ff0505\".explained ggplot basics section mapping data plot, aesthetics fill = color = can defined either outside mapping = aes() statement inside one. outside aes(), assigned value static (e.g. color = \"blue\") apply data plotted geom. inside, aesthetic mapped column, like color = hospital, expression vary value row data. examples:","code":"\n# histogram - \nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"lightblue\")          # bin interior color (fill) \n# Static color for points and for line\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Color mapped to continuous column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Color mapped to discrete column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# bar plot, fill to discrete column, color to static value\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")"},{"path":"ggplot-tips.html","id":"ggplot_tips_scales","chapter":"31 ggplot tips","heading":"Scales","text":"map column plot aesthetic (e.g. x =, y =, fill =, color =…), plot gain scale/legend. See scale can continuous, discrete, date, etc. values depending class assigned column. multiple aesthetics mapped columns, plot multiple scales.can control scales appropriate scales_() function. scale functions ggplot() 3 parts written like : scale_AESTHETIC_METHOD().first part, scale_(), fixed.second part, AESTHETIC, aesthetic want adjust scale (_fill_, _shape_, _color_, _size_, _alpha_…) - options also include _x_ _y_.third part, METHOD, either _discrete(), continuous(), _date(), _gradient(), _manual() depending class column want control . others, -often used.sure use correct function scale! Otherwise scale command appear change anything. multiple scales, may use multiple scale functions adjust ! example:","code":""},{"path":"ggplot-tips.html","id":"scale-arguments","chapter":"31 ggplot tips","heading":"Scale arguments","text":"kind scale arguments, though overlap. Query function like ?scale_color_discrete R console see function argument documentation.continuous scales, use breaks = provide sequence values seq() (take =, =, = shown example . Set expand = c(0,0) eliminate padding space around axes (can used _x_ _y_ scale.discrete scales, can adjust order level appearance breaks =, values display labels = argument. Provide character vector (see example ). can also drop NA easily setting na.translate = FALSE.nuances date scales covered extensively Epidemic curves page.","code":""},{"path":"ggplot-tips.html","id":"manual-adjustments","chapter":"31 ggplot tips","heading":"Manual adjustments","text":"One useful tricks using “manual” scaling functions explicitly assign colors desire. functions syntax scale_xxx_manual() (e.g. scale_colour_manual() scale_fill_manual()). arguments demonstrated code example .Assign colors data values values = argumentSpecify color NA na.value =Change values written legend labels = argumentChange legend title name =, create bar plot show appears default, three scales adjusted - continuous y-axis scale, discrete x-axis scale, manual adjustment fill (interior bar color).","code":"\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n# SCALES ADJUSTED\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # simplify background\n  \n  scale_y_continuous(                # continuous scale for y-axis (counts)\n    expand = c(0,0),                 # no padding\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # discrete scale for x-axis (gender)\n    expand = c(0,0),                  # no padding\n    drop = FALSE,                     # show all factor levels (even if not in data)\n    na.translate = FALSE,             # remove NA outcomes from plot\n    labels = c(\"Died\", \"Recovered\"))+ # Change display of values\n    \n  \n  scale_fill_manual(                  # Manually specify fill (bar interior color)\n    values = c(\"m\" = \"violetred\",     # reference values in data to assign colors\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          # re-label the legend (use \"=\" assignment to avoid mistakes)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # title of legend\n    na.value = \"grey\"                 # assign a color for missing values\n  )+\n  labs(title = \"Adjustment of scales\") # Adjust the title of the fill legend"},{"path":"ggplot-tips.html","id":"continuous-axes-scales","chapter":"31 ggplot tips","heading":"Continuous axes scales","text":"data mapping plot axes, can adjusted scales commands. common example adjusting display axis (e.g. y-axis) mapped column continuous data.may want adjust breaks display values ggplot using scale_y_continuous(). noted , use argument breaks = provide sequence values serve “breaks” along scale. values numbers display. argument, can provide c() vector containing desired break values, can provide regular sequence numbers using base R function seq(). seq() function accepts =, =, =.","code":"\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")"},{"path":"ggplot-tips.html","id":"display-percents","chapter":"31 ggplot tips","heading":"Display percents","text":"original data values proportions, can easily display percents “%” providing labels = scales::percent scales command, shown .alternative convert values character add “%” character end, approach cause complications data longer continuous numeric values.","code":"\n# Original y-axis proportions\n#############################\nlinelist %>%                                   # start with linelist\n  group_by(hospital) %>%                       # group data by hospital\n  summarise(                                   # create summary columns\n    n = n(),                                     # total number of rows in group\n    deaths = sum(outcome == \"Death\", na.rm=T),   # number of deaths in group\n    prop_death = deaths/n) %>%                   # proportion deaths in group\n  ggplot(                                      # begin plotting\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Display y-axis proportions as percents\n########################################\nlinelist %>%         \n  group_by(hospital) %>% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %>% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # display proportions as percents\n  )"},{"path":"ggplot-tips.html","id":"log-scale","chapter":"31 ggplot tips","heading":"Log scale","text":"transform continuous axis log scale, add trans = \"log2\" scale command. purposes example, create data frame regions respective preparedness_index cumulative cases values.cumulative cases region “” dramatically greater regions. circumstances like , may elect display y-axis using log scale reader can see differences regions fewer cumulative cases.","code":"\nplot_data <- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data##   region preparedness_index cases_cumulative\n## 1      A                8.8               15\n## 2      B                7.5               45\n## 3      C                3.4               80\n## 4      D                3.6               20\n## 5      E                2.1               21\n## 6      F                7.9                7\n## 7      G                7.0               51\n## 8      H                5.6               30\n## 9      I                1.0             1442\n# Original y-axis\npreparedness_plot <- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # points for each region \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # add text labels\n  theme_minimal()\n\npreparedness_plot                  # print original plot\n\n\n# print with y-axis transformed\npreparedness_plot+                   # begin with plot saved above\n  scale_y_continuous(trans = \"log2\") # add transformation for y-axis"},{"path":"ggplot-tips.html","id":"gradient-scales","chapter":"31 ggplot tips","heading":"Gradient scales","text":"Fill gradient scales can involve additional nuance. defaults usually quite pleasing, may want adjust values, cutoffs, etc.demonstrate adjust continuous color scale, ’ll use data set Contact tracing page contains ages cases source cases., produce “raster” heat tile density plot. won’t elaborate (see link paragraph ) focus can adjust color scale. Read stat_density2d() ggplot2 function . Note fill scale continuous.Now show variations fill scale:Now show examples actually adjusting break points scale:scale_fill_gradient() accepts two colors (high/low)scale_fill_gradientn() accepts vector length colors values = (intermediate values interpolated)Use scales::rescale() adjust colors positioned along gradient; rescales vector positions 0 1.","code":"\ncase_source_relationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_age, target_age) \ntrans_matrix <- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\ntrans_matrix + \n  scale_fill_gradient(     # 2-sided gradient scale\n    low = \"aquamarine\",    # low value\n    high = \"purple\",       # high value\n    na.value = \"grey\",     # value for NA\n    name = \"Density\")+     # Legend title\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ colors to scale\ntrans_matrix + \n  scale_fill_gradientn(    # 3-color scale (low/mid/high)\n    colors = c(\"blue\", \"yellow\",\"red\") # provide colors in vector\n  )+\n  labs(title = \"3-color scale\")\n\n# Use of rescale() to adjust placement of colors along scale\ntrans_matrix + \n  scale_fill_gradientn(    # provide any number of colors\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # positions for colors are rescaled between 0 and 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# use of limits to cut-off values that get fill color\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")"},{"path":"ggplot-tips.html","id":"palettes","chapter":"31 ggplot tips","heading":"Palettes","text":"","code":""},{"path":"ggplot-tips.html","id":"colorbrewer-and-viridis","chapter":"31 ggplot tips","heading":"Colorbrewer and Viridis","text":"generally, want predefined palettes, can use scale_xxx_brewer scale_xxx_viridis_y functions.‘brewer’ functions can draw colorbrewer.org palettes.‘viridis’ functions draw viridis (colourblind friendly!) palettes, “provide colour maps perceptually uniform colour black--white. also designed perceived viewers common forms colour blindness.” (read ). Define palette discrete, continuous, binned specifying end function (e.g. discrete scale_xxx_viridis_d).advised test plot color blindness simulator. red/green color scheme, try “hot-cold” (red-blue) scheme instead described hereHere example ggplot basics page, using various color schemes.","code":"\nsymp_plot <- linelist %>%                                         # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  # print with default colors\n\n#################################\n# print with manually-specified colors\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # explicitly define colours\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # order the factors correctly\n    name = \"\"                           # set legend to no title\n\n  ) \n\n#################################\n# print with viridis discrete colors\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )"},{"path":"ggplot-tips.html","id":"change-order-of-discrete-variables","chapter":"31 ggplot tips","heading":"31.3 Change order of discrete variables","text":"Changing order discrete variables appear often difficult understand people new ggplot2 graphs. ’s easy understand however understand ggplot2 handles discrete variables hood. Generally speaking, discrete varaible used, automatically converted factor type - orders factors alphabetical order default. handle , simply reorder factor levels reflect order like appear chart. detailed information reorder factor objects, see factor section guide.can look common example using age groups - default 5-9 age group placed middle age groups (given alphanumeric order), can move behind 0-4 age group chart releveling factors.","code":"\nggplot(\n  data = linelist %>% drop_na(age_cat5),                         # remove rows where age_cat5 is missing\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # relevel factor\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()"},{"path":"ggplot-tips.html","id":"ggthemr","chapter":"31 ggplot tips","heading":"31.3.0.1 ggthemr","text":"Also consider using ggthemr package. can download package Github using instructions . offers palettes aesthetically pleasing, aware typically maximum number values can limiting want 7 8 colors.","code":""},{"path":"ggplot-tips.html","id":"contour-lines","chapter":"31 ggplot tips","heading":"31.4 Contour lines","text":"Contour plots helpful many points might cover (“overplotting”). case-source data used plotted, simply using stat_density2d() stat_density2d_filled() produce discrete contour levels - like topographical map. Read statistics .","code":"\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")"},{"path":"ggplot-tips.html","id":"marginal-distributions","chapter":"31 ggplot tips","heading":"31.5 Marginal distributions","text":"show distributions edges geom_point() scatterplot, can use ggExtra package function ggMarginal(). Save original ggplot object, pass ggMarginal() shown . key arguments:must specify type = either “histogram”, “density” “boxplot”, “violin”, “densigram”.default, marginal plots appear axes. can set margins = “x” “y” want one.optional arguments include fill = (bar color), color = (line color), size = (plot size relative margin size, larger number makes marginal plot smaller).can provide axis-specific arguments xparams = yparams =. example, different histogram bin sizes, shown .can marginal plots reflect groups (columns assigned color = ggplot() mapped aesthetics). case, set ggMarginal() argument groupColour = groupFill = TRUE, shown .Read vignette, R Graph Gallery function R documentation ?ggMarginal.add marginal histograms use type = \"histogram\". can optionally set groupFill = TRUE get stacked histograms.Marginal density plot grouped/colored values:Set size = arguemnt adjust relative size marginal plot. Smaller number makes larger marginal plot. also set color =. marginal boxplot, demonstration margins = argument appears one axis:","code":"\n# Install/load ggExtra\npacman::p_load(ggExtra)\n\n# Basic scatter plot of weight and age\nscatter_plot <- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n# with histograms\nggMarginal(\n  scatter_plot,                     # add marginal histograms\n  type = \"histogram\",               # specify histograms\n  fill = \"lightblue\",               # bar fill\n  xparams = list(binwidth = 10),    # other parameters for x-axis marginal\n  yparams = list(binwidth = 5))     # other parameters for y-axis marginal\n# Scatter plot, colored by outcome\n# Outcome column is assigned as color in ggplot. groupFill in ggMarginal set to TRUE\nscatter_plot_color <- ggplot(data = linelist %>% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n# with boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # only show x-axis marginal plot\n  type = \"boxplot\")   "},{"path":"ggplot-tips.html","id":"smart-labeling","chapter":"31 ggplot tips","heading":"31.6 Smart Labeling","text":"ggplot2, also possible add text plots. However, comes notable limitation text labels often clash data points plot, making look messy hard read. ideal way deal base package, ggplot2 add-, known ggrepel makes dealing simple!ggrepel package provides two new functions, geom_label_repel() geom_text_repel(), replace geom_label() geom_text(). Simply use functions instead base functions produce neat labels. Within function, map aesthetics aes() always, include argument label = provide column name containing values want display (e.g. patient id, name, etc.). can make complex labels combining columns newlines (\\n) within str_glue() shown .tips:Use min.segment.length = 0 always draw line segments, min.segment.length = Inf never draw themUse size = outside aes() set text sizeUse force = change degree repulsion labels respective points (default 1)Include fill = within aes() label colored value\nletter “” may appear legend - add guides(fill = guide_legend(override.aes = aes(color = NA)))+ remove \nletter “” may appear legend - add guides(fill = guide_legend(override.aes = aes(color = NA)))+ remove itSee -depth tutorial .can label subset data points - using standard ggplot() syntax provide different data = geom layer plot. , cases plotted, labeled.","code":"\npacman::p_load(ggrepel)\n\nlinelist %>%                                               # start with linelist\n  group_by(hospital) %>%                                   # group by hospital\n  summarise(                                               # create new dataset with summary values per hospital\n    n_cases = n(),                                           # number of cases per hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # mean delay per hospital\n  ) %>% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # send data frame to ggplot\n  geom_point(size = 2)+                                    # add points\n  geom_label_repel(                                        # add point labels\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # how label displays\n      ), \n    size = 3,                                              # text size in labels\n    min.segment.length = 0)+                               # show all line segments                \n  labs(                                                    # add axes labels\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\nggplot()+\n  # All points in grey\n  geom_point(\n    data = linelist,                                   # all data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # grey and semi-transparent\n  \n  # Few points in black\n  geom_point(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filtered data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # default black and not transparent\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filter the data for the labels\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # label color by outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # label created with str_glue()\n    min.segment.length = 0) +                                  # show line segments for all\n  \n  # remove letter \"a\" from inside legend boxes\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # axis labels\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")"},{"path":"ggplot-tips.html","id":"time-axes","chapter":"31 ggplot tips","heading":"31.7 Time axes","text":"Working time axes ggplot can seem daunting, made easy key functions. Remember working time date ensure correct variables formatted date datetime class - see Working dates page information , Epidemic curves page (ggplot section) examples.single useful set functions working dates ggplot2 scale functions (scale_x_date(), scale_x_datetime(), cognate y-axis functions). functions let define often axis labels, format axis labels. find format dates, see working dates section ! can use date_breaks date_labels arguments specify dates look:date_breaks allows specify often axis breaks occur - can pass string (e.g. \"3 months\", “2 days\")date_breaks allows specify often axis breaks occur - can pass string (e.g. \"3 months\", “2 days\")date_labels allows define format dates shown . can pass date format string arguments (e.g. \"%b-%d-%Y\"):date_labels allows define format dates shown . can pass date format string arguments (e.g. \"%b-%d-%Y\"):One easy solution efficient date labels x-axis assign labels = argument scale_x_date() function label_date_short() package scales. function automatically construct efficient date labels (read ). additional benefit function labels automatically adjust data expands time, days, weeks, months years.See complete example Epicurves page section multi-level date labels, quick example shown reference:","code":"\n# make epi curve by date of onset when available\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # 1 break every 1 month\n    date_breaks = \"1 months\",\n    # labels should show month then date\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    labels = scales::label_date_short()  # automatically efficient date labels\n  )+\n  theme_classic()"},{"path":"ggplot-tips.html","id":"highlighting","chapter":"31 ggplot tips","heading":"31.8 Highlighting","text":"Highlighting specific elements chart useful way draw attention specific instance variable also providing information dispersion full dataset. easily done base ggplot2, external package can help known gghighlight. easy use within ggplot syntax.gghighlight package uses gghighlight() function achieve effect. use function, supply logical statement function - can quite flexible outcomes, ’ll show example age distribution cases linelist, highlighting outcome.also works well faceting functions - allows user produce facet plots background data highlighted doesn’t apply facet! count cases week plot epidemic curves hospital (color = facet_wrap() set hospital column).","code":"\n# load gghighlight\nlibrary(gghighlight)\n\n# replace NA values with unknown in the outcome variable\nlinelist <- linelist %>%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produce a histogram of all cases by age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # highlight instances where the patient has died.\n# produce a histogram of all cases by age\nlinelist %>% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %>% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # highlight instances where the patient has died\n  facet_wrap(~hospital)                              # make facets by outcome"},{"path":"ggplot-tips.html","id":"plotting-multiple-datasets","chapter":"31 ggplot tips","heading":"31.9 Plotting multiple datasets","text":"Note properly aligning axes plot multiple datasets plot can difficult. Consider one following strategies:Merge data prior plotting, convert “long” format column reflecting datasetUse cowplot similar package combine two plots (see )","code":""},{"path":"ggplot-tips.html","id":"combine-plots","chapter":"31 ggplot tips","heading":"31.10 Combine plots","text":"Two packages useful combining plots cowplot patchwork. page mostly focus cowplot, occassional use patchwork.online introduction cowplot. can read extensive documentation function online . cover common use cases functions .cowplot package works tandem ggplot2 - essentially, use arrange combine ggplots legends compound figures. can also accept base R graphics.faceting (described ggplot basics page) convenient approach plotting, sometimes possible get results want relatively restrictive approach. , may choose combine plots sticking together larger plot. three well known packages great - cowplot, gridExtra, patchwork. However, packages largely things, ’ll focus cowplot section.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualisation\n  cowplot,        # combine plots\n  patchwork       # combine plots\n)"},{"path":"ggplot-tips.html","id":"plot_grid","chapter":"31 ggplot tips","heading":"plot_grid()","text":"cowplot package fairly wide range functions, easiest use can achieved use plot_grid(). effectively way arrange predefined plots grid formation. can work another example malaria dataset - can plot total cases district, also show epidemic curve time.","code":"\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# bar chart of total cases by district\np1 <- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# epidemic curve over time\np2 <- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 column and two rows - stacked on top of each other\n                   ncol = 1,\n                   nrow = 2,\n                   # top plot is 2/3 as tall as second\n                   rel_heights = c(2, 3))"},{"path":"ggplot-tips.html","id":"combine-legends","chapter":"31 ggplot tips","heading":"Combine legends","text":"plots legend, combining relatively straight-forward. Simple use cowplot approach combine plots, remove legend one (de-duplicate).plots different legends, must use alternative approach:Create save plots without legends using theme(legend.position = \"none\")Extract legends plot using get_legend() shown - extract legends plots modified actually show legendCombine legends legends panelCombine plots legends panelFor demonstration show two plots separately, arranged grid legends showing (ugly inefficient use space):two plots look combined using plot_grid() without combining legends:now show combine legends. Essentially define plot without legend (theme(legend.position = \"none\"), define plot’s legend separately, using get_legend() function cowplot. extract legend saved plot, need add + legend back , including specifying placement (“right”) smaller adjustments alignment legends titles. , combine legends together vertically, combine two plots newly-combined legends. Voila!solution learned post minor fix align legends post.TIP: Fun note - “cow” cowplot comes creator’s name - Claus O. Wilke.","code":"\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n# Define plot 1 without legend\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Define plot 2 without legend\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extract legend from p1 (from p1 + legend)\nleg_p1 <- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extract vertical legend\n                                      legend.justification = c(0,0.5))+ # so legends  align\n                                labs(fill = \"Outcome\"))                 # title of legend\n# extract legend from p2 (from p2 + legend)\nleg_p2 <- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extract vertical legend   \n                                      legend.justification = c(0,0.5))+  # so legends align\n                                labs(fill = \"Age Category\"))             # title of legend\n\n# create a blank plot for legend alignment\n#blank_p <- patchwork::plot_spacer() + theme_void()\n\n# create legends panel, can be one on top of the other (or use spacer commented above)\nlegends <- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combine two plots and the combined legends panel\ncombined <- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # print"},{"path":"ggplot-tips.html","id":"inset-plots","chapter":"31 ggplot tips","heading":"Inset plots","text":"can inset one plot another using cowplot. things aware :Define main plot theme_half_open() cowplot; may best legend either top bottomDefine inset plot. Best plot need legend. can remove plot theme elements element_blank() shown .Combine applying ggdraw() main plot, adding draw_plot() inset plot specifying coordinates (x y lower left corner), height width proportion whole main plot.technique explained two vignettes:Wilke labdraw_plot() documentation","code":"\n# Define main plot\nmain_plot <- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Define inset plot\ninset_plot <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combine main with inset\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)"},{"path":"ggplot-tips.html","id":"dual-axes","chapter":"31 ggplot tips","heading":"31.11 Dual axes","text":"secondary y-axis often requested addition ggplot2 graph. robust debate validity graphs data visualization community, often recommended, manager may still want . , present one method achieve : using cowplot package combine two separate plots.approach involves creating two separate plots - one y-axis left, y-axis right. use specific theme_cowplot() must x-axis. third command two plots aligned overlaid top . functionalities cowplot, one, described depth site.demonstrate technique overlay epidemic curve line weekly percent patients died. use example alignment dates x-axis complex say, aligning bar chart another plot. things note:epicurve line aggregated weeks prior plotting date_breaks date_labels identical - x-axes two plots overlaid.y-axis moved right-side plot 2 position = argument scale_y_continuous().plots make use theme_cowplot()Note another example technique Epidemic curves page - overlaying cumulative incidence top epicurve.Make plot 1\nessentially epicurve. use geom_area() just demonstrate use (area line, default)Make plot 2\nCreate second plot showing line weekly percent cases died.Now align plot using function align_plots(), specifying horizontal vertical alignment (“hv”, also “h”, “v”, “none”). specify alignment axes well (top, bottom, left, right) “tblr”. output class list (2 elements).draw two plots together using ggdraw() (cowplot) referencing two parts aligned_plots object.","code":"\npacman::p_load(cowplot)            # load/install cowplot\n\np1 <- linelist %>%                 # save plot as object\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # view plot \np2 <- linelist %>%         # save plot as object\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %>% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # view plot\naligned_plots <- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # align the two plots and save them as list\naligned_plotted <- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # overlay them and save the visual plot\naligned_plotted                                                                # print the overlayed plots"},{"path":"ggplot-tips.html","id":"packages-to-help-you","chapter":"31 ggplot tips","heading":"31.12 Packages to help you","text":"really neat R packages specifically designed help navigate ggplot2:","code":""},{"path":"ggplot-tips.html","id":"point-and-click-ggplot2-with-equisse","chapter":"31 ggplot tips","heading":"Point-and-click ggplot2 with equisse","text":"“addin allows interactively explore data visualizing ggplot2 package. allows draw bar plots, curves, scatter plots, histograms, boxplot sf objects, export graph retrieve code reproduce graph.”Install launch addin via RStudio menu esquisse::esquisser().See Github pageDocumentation","code":""},{"path":"ggplot-tips.html","id":"miscellaneous","chapter":"31 ggplot tips","heading":"31.13 Miscellaneous","text":"","code":""},{"path":"ggplot-tips.html","id":"numeric-display","chapter":"31 ggplot tips","heading":"Numeric display","text":"can disable scientific notation running command prior plotting.apply number_format() scales package specific value column, shown .Use functions package scales easily adjust numbers displayed. can applied columns data frame, shown individual numbers purpose example.","code":"\noptions(scipen=999)\nscales::number(6.2e5)## [1] \"620 000\"\nscales::number(1506800.62,  accuracy = 0.1,)## [1] \"1 506 800.6\"\nscales::comma(1506800.62, accuracy = 0.01)## [1] \"1,506,800.62\"\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")## [1] \"1.506.800,62\"\nscales::percent(0.1)## [1] \"10%\"\nscales::dollar(56)## [1] \"$56\"\nscales::scientific(100000)## [1] \"1e+05\""},{"path":"ggplot-tips.html","id":"resources-24","chapter":"31 ggplot tips","heading":"31.14 Resources","text":"Inspiration\nggplot graph galleryPresentation data\nEuropean Centre Disease Prevention Control Guidelines presentation surveillance dataFacets labellers\nUsing labellers facet strips\nLabellersAdjusting order factors\nfct_reorderfct_inorderHow reorder boxplotReorder variable ggplot2R Data Science - FactorsLegendsAdjust legend orderCaptions\nCaption alignmentLabelsggrepelCheatsheetsBeautiful plotting ggplot2","code":""},{"path":"epidemic-curves.html","id":"epidemic-curves","chapter":"32 Epidemic curves","heading":"32 Epidemic curves","text":"epidemic curve (also known “epi curve”) core epidemiological chart typically used visualize temporal pattern illness onset among cluster epidemic cases.Analysis epicurve can reveal temporal trends, outliers, magnitude outbreak, likely time period exposure, time intervals case generations, can even help identify mode transmission unidentified disease (e.g. point source, continuous common source, person--person propagation). One online lesson interpretation epi curves can found website US CDC.page demonstrate making epidemic curves ggplot2 package, allows advanced customizability.Also addressed specific use-cases :Plotting aggregated count dataFaceting producing small-multiplesApplying moving averagesShowing data “tentative” subject reporting delaysOverlaying cumulative case incidence using second axisThe incidence2 package offers alternative approach easier commands, writing undergoing revisions stable. re-added chapter stable.","code":""},{"path":"epidemic-curves.html","id":"preparation-24","chapter":"32 Epidemic curves","heading":"32.1 Preparation","text":"","code":""},{"path":"epidemic-curves.html","id":"packages-4","chapter":"32 Epidemic curves","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) "},{"path":"epidemic-curves.html","id":"import-data-19","chapter":"32 Epidemic curves","heading":"Import data","text":"Two example datasets used section:Linelist individual cases simulated epidemicAggregated counts hospital simulated epidemicThe datasets imported using import() function rio package. See page Import export various ways import data.Case linelistWe import dataset cases simulated Ebola epidemic. want download data follow step--step, see instruction Download handbook data page. assume file working directory sub-folders specified file path.first 50 rows displayed .Case counts aggregated hospitalFor purposes handbook, dataset weekly aggregated counts hospital created linelist following code.first 50 rows displayed :","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")\n# import the counts data into R\ncount_data <- linelist %>% \n  group_by(hospital, date_hospitalisation) %>% \n  summarize(n_cases = dplyr::n()) %>% \n  filter(date_hospitalisation > as.Date(\"2013-06-01\")) %>% \n  ungroup()"},{"path":"epidemic-curves.html","id":"set-parameters","chapter":"32 Epidemic curves","heading":"Set parameters","text":"production report, may want set editable parameters date data current (“data date”). can reference object data_date code applying filters dynamic captions.","code":"\n## set the report date for the report\n## note: can be set to Sys.Date() for the current date\ndata_date <- as.Date(\"2015-05-15\")"},{"path":"epidemic-curves.html","id":"verify-dates","chapter":"32 Epidemic curves","heading":"Verify dates","text":"Verify relevant date column class Date appropriate range values. can simply using hist() histograms, range() na.rm=TRUE, ggplot() .","code":"\n# check range of onset dates\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))"},{"path":"epidemic-curves.html","id":"epicurves-with-ggplot2","chapter":"32 Epidemic curves","heading":"32.2 Epicurves with ggplot2","text":"Using ggplot() build epicurve allows flexibility customization, requires effort understanding ggplot() works.must manually control aggregation cases time (weeks, months, etc) intervals labels date axis. must carefully managed.examples use subset linelist dataset - cases Central Hospital.produce epicurve ggplot() three main elements:histogram, linelist cases aggregated “bins” distinguished specific “break” pointsScales axes labelsThemes plot appearance, including titles, labels, captions, etc.","code":"\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")"},{"path":"epidemic-curves.html","id":"specify-case-bins","chapter":"32 Epidemic curves","heading":"Specify case bins","text":"show specify cases aggregated histogram bins (“bars”). important recognize aggregation cases histogram bins necessarily intervals dates appear x-axis.perhaps simple code produce daily weekly epicurves.-arching ggplot() command dataset provided data =. Onto foundation, geometry histogram added +. Within geom_histogram(), map aesthetics column date_onset mapped x-axis. Also within geom_histogram() within aes() set binwidth = histogram bins, days. ggplot2 syntax confusing, review page ggplot basics.CAUTION: Plotting weekly cases using binwidth = 7 starts first 7-day bin first case, day week! create specific weeks, see section .Let us note first case Central Hospital dataset symptom onset :manually specify histogram bin breaks, use binwidth = argument, instead supply vector dates breaks =.Create vector dates base R function seq.Date(). function expects arguments =, =, =. example, command returns monthly dates starting Jan 15 ending June 28.vector can provided geom_histogram() breaks =:simple weekly date sequence can returned setting = \"week\". example:alternative supplying specific start end dates write dynamic code weekly bins begin Monday first case. use date vectors throughout examples .Let’s unpack rather daunting code :“” value (earliest date sequence) created follows: minimum date value (min() na.rm=TRUE) column date_onset fed floor_date() lubridate package. floor_date() set “week” returns start date cases’s “week”, given start day week Monday (week_start = 1).Likewise, “” value (end date sequence) created using inverse function ceiling_date() return Monday last case.“” argument seq.Date() can set number days, weeks, months.Use week_start = 7 Sunday weeksAs use date vectors throughout page, also define one whole outbreak (Central Hospital ).seq.Date() outputs can used create histogram bin breaks, also breaks date labels, may independent bins. Read date labels later sections.TIP: simple ggplot() command, save bin breaks date label breaks named vectors advance, simply provide names breaks =.","code":"\n# daily \nggplot(data = central_data) +          # set data\n  geom_histogram(                      # add histogram\n    mapping = aes(x = date_onset),     # map date column to x-axis\n    binwidth = 1)+                     # cases binned by 1 day \n  labs(title = \"Central Hospital - Daily\")                # title\n\n# weekly\nggplot(data = central_data) +          # set data \n  geom_histogram(                      # add histogram\n      mapping = aes(x = date_onset),   # map date column to x-axis\n      binwidth = 7)+                   # cases binned every 7 days, starting from first case (!) \n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # title\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")## [1] \"Thursday 01 May, 2014\"\nmonthly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # print##  [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\" \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\"\n## [10] \"2014-11-01\" \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\" \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n# monthly \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # provide the pre-defined vector of breaks                    \n  labs(title = \"Monthly case bins\")   # title\nweekly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n# Sequence of weekly Monday dates for CENTRAL HOSPITAL\nweekly_breaks_central <- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")\n# Sequence for the entire outbreak\nweekly_breaks_all <- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")"},{"path":"epidemic-curves.html","id":"weekly-epicurve-example","chapter":"32 Epidemic curves","heading":"Weekly epicurve example","text":"detailed example code produce weekly epicurves Monday weeks, aligned bars, date labels, vertical gridlines. section user needs code quickly. understand aspect (themes, date labels, etc.) -depth, continue subsequent sections. note:histogram bin breaks defined seq.Date() explained begin Monday earliest case end Monday last caseThe interval date labels specified date_breaks = within scale_x_date()interval minor vertical gridlines date labels specified date_minor_breaks =use closed = \"left\" geom_histogram() ensure date counted correct binsexpand = c(0,0) x y scales removes excess space side axes, also ensures date labels begin first bar.","code":"\n# TOTAL MONDAY WEEK ALIGNMENT\n#############################\n# Define sequence of weekly breaks\nweekly_breaks_central <- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # Monday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # Monday after last case\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    \n    # mapping aesthetics\n    mapping = aes(x = date_onset),  # date column mapped to x-axis\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # histogram bin breaks defined previously\n      \n    closed = \"left\",  # count cases from start of breakpoint\n    \n    # bars\n    color = \"darkblue\",     # color of lines around bars\n    fill = \"lightblue\"      # color of fill within bars\n  )+ \n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"4 weeks\",        # date labels and major vertical gridlines appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # minor vertical lines appear every Monday week\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # remove excess y-axis space below 0 (align histogram flush with x-axis)\n  \n  # aesthetic themes\n  theme_minimal()+                # simplify plot background\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # caption on left side\n                                face = \"italic\"), # caption in italics\n    axis.title = element_text(face = \"bold\"))+    # axis titles in bold\n  \n  # labels including dynamic caption\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"sunday-weeks","chapter":"32 Epidemic curves","heading":"Sunday weeks","text":"achieve plot Sunday weeks modifications needed, date_breaks = \"weeks\" work Monday weeks.break points histogram bins must set Sundays (week_start = 7)Within scale_x_date(), similar date breaks provided breaks = minor_breaks = ensure date labels vertical gridlines align Sundays.example, scale_x_date() command Sunday weeks look like :","code":"scale_x_date(\n    expand = c(0,0),\n    \n    # specify interval of date labels and major vertical gridlines\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"4 weeks\"),\n    \n    # specify interval of minor vertical gridline \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"week\"),\n   \n    # date label format\n    #date_labels = \"%a\\n%d %b\\n%Y\")+         # day, above month abbrev., above 2-digit year\n    label = scales::label_date_short())+ # automatic label formatting"},{"path":"epidemic-curves.html","id":"groupcolor-by-value","chapter":"32 Epidemic curves","heading":"Group/color by value","text":"histogram bars can colored group “stacked”. designate grouping column, make following changes. See ggplot basics page details.Within histogram aesthetic mapping aes(), map column name group = fill = argumentsRemove fill = argument outside aes(), override one insideArguments inside aes() apply group, whereas outside apply bars (e.g. may still want color = outside, bar border)aes() command look like group color bars gender:applied:","code":"\naes(x = date_onset, group = gender, fill = gender)\nggplot(data = linelist) +     # begin with linelist (many hospitals)\n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # set data to be grouped by hospital\n      fill = hospital),       # bar fill (inside color) by hospital\n    \n    # bin breaks are Monday weeks\n    breaks = weekly_breaks_all,   # sequence of weekly Monday bin breaks for whole outbreak, defined in previous code       \n    \n    closed = \"left\",          # count cases from start of breakpoint\n\n    # Color around bars\n    color = \"black\")"},{"path":"epidemic-curves.html","id":"adjust-colors","chapter":"32 Epidemic curves","heading":"Adjust colors","text":"manually set fill group, use scale_fill_manual() (note: scale_color_manual() different!).\nUse values = argument apply vector colors.\nUse na.value = specify color NA values.\nUse labels = argument change text legend items. safe, provide named vector like c(\"old\" = \"new\", \"old\" = \"new\") adjust values data .\nUse name = give proper title legend\nUse values = argument apply vector colors.Use na.value = specify color NA values.Use labels = argument change text legend items. safe, provide named vector like c(\"old\" = \"new\", \"old\" = \"new\") adjust values data .Use name = give proper title legendFor tips color scales palettes, see page ggplot basics.","code":"\nggplot(data = linelist)+           # begin with linelist (many hospitals)\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # cases grouped by hospital\n        fill = hospital),          # bar fill by hospital\n    \n    # bin breaks\n    breaks = weekly_breaks_all,    # sequence of weekly Monday bin breaks, defined in previous code\n    \n    closed = \"left\",               # count cases from start of breakpoint\n\n    # Color around bars\n    color = \"black\")+              # border color of each bar\n  \n  # manual specification of colors\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # specify fill colors (\"values\") - attention to order!"},{"path":"epidemic-curves.html","id":"adjust-level-order","chapter":"32 Epidemic curves","heading":"Adjust level order","text":"order grouped bars stacked best adjusted classifying grouping column class Factor. can designate factor level order (display labels). See page Factors ggplot tips details.making plot, use fct_relevel() function forcats package convert grouping column class factor manually adjust level order, detailed page Factors.plot, differences previous column hospital consolidated , use guides() reverse legend order, “Missing” bottom legend.TIP: reverse order legend , add ggplot2 command: guides(fill = guide_legend(reverse = TRUE)).","code":"\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Define new dataset with hospital as factor\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convert to factor and set \"Missing\" and \"Other\" as top levels to appear on epicurve top\n\nlevels(plot_data$hospital) # print levels in order## [1] \"Missing\"                              \"Other\"                                \"Central Hospital\"                    \n## [4] \"Military Hospital\"                    \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nggplot(plot_data) +                     # Use NEW dataset with hospital as re-ordered factor\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # cases grouped by hospital\n        fill = hospital),               # bar fill (color) by hospital\n    \n    breaks = weekly_breaks_all,         # sequence of weekly Monday bin breaks for whole outbreak, defined at top of ggplot section\n    \n    closed = \"left\",                    # count cases from start of breakpoint\n\n    color = \"black\")+                   # border color around each bar\n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"3 weeks\",        # labels appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # vertical lines appear every Monday week\n    label = scales::label_date_short()) + # efficient label formatting\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+                   # remove excess y-axis space below 0\n  \n  # manual specification of colors, ! attention to order\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # aesthetic themes\n  theme_minimal()+                      # simplify plot background\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # caption on left side in italics\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # axis titles in bold\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")"},{"path":"epidemic-curves.html","id":"adjust-legend","chapter":"32 Epidemic curves","heading":"Adjust legend","text":"Read legends scales ggplot tips page. highlights:Edit legend title either scale function labs(fill = \"Legend title\") (using color = aesthetic, use labs(color = \"\"))theme(legend.title = element_blank()) legend titletheme(legend.position = \"top\") (“bottom”, “left”, “right”, “none” remove legend)theme(legend.direction = \"horizontal\") horizontal legendguides(fill = guide_legend(reverse = TRUE)) reverse order legend","code":""},{"path":"epidemic-curves.html","id":"bars-side-by-side","chapter":"32 Epidemic curves","heading":"Bars side-by-side","text":"Side--side display group bars (opposed stacked) specified within geom_histogram() position = \"dodge\" placed outside aes().two value groups, can become difficult read. Consider instead using faceted plot (small multiples). improve readability example, missing gender values removed.","code":"\nggplot(central_data %>% drop_na(gender))+   # begin with Central Hospital cases dropping missing gender\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # cases grouped by gender\n          fill = gender),         # bars filled by gender\n        \n        # histogram bin breaks\n        breaks = weekly_breaks_central,   # sequence of weekly dates for Central outbreak - defined at top of ggplot section\n        \n        closed = \"left\",          # count cases from start of breakpoint\n        \n        color = \"black\",          # bar edge color\n        \n        position = \"dodge\")+      # SIDE-BY-SIDE bars\n                      \n  \n  # The labels on the x-axis\n  scale_x_date(expand            = c(0,0),          # remove excess x-axis space below and after case bars\n               date_breaks       = \"3 weeks\",       # labels appear every 3 Monday weeks\n               date_minor_breaks = \"week\",          # vertical lines appear every Monday week\n               label = scales::label_date_short())+ # efficient date labels\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+             # removes excess y-axis space between bottom of bars and the labels\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # specify fill colors (\"values\") - attention to order!\n                    na.value = \"grey\" )+     \n\n  # aesthetic themes\n  theme_minimal()+                                               # a set of themes to simplify plot\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n        axis.title = element_text(face = \"bold\"))+               # axis titles in bold\n  \n  # labels\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")"},{"path":"epidemic-curves.html","id":"axis-limits","chapter":"32 Epidemic curves","heading":"Axis limits","text":"two ways limit extent axis values.Generally preferred way use command coord_cartesian(), accepts xlim = c(min, max) ylim = c(min, max) (provide min max values). acts “zoom” without actually removing data, important statistics summary measures.Alternatively, can set maximum minimum date values using limits = c() within scale_x_date(). example:Likewise, want x-axis extend specific date (e.g. current date), even new cases reported, can use:DANGER: cautious setting y-axis scale breaks limits (e.g. 0 30 5: seq(0, 30, 5)). static numbers can cut-plot short data changes exceed limit!.","code":"\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # sets a minimum date but leaves the maximum open.  scale_x_date(limits = c(NA, Sys.Date()) # ensures date axis will extend until current date  "},{"path":"epidemic-curves.html","id":"date-axis-labelsgridlines","chapter":"32 Epidemic curves","heading":"Date-axis labels/gridlines","text":"TIP: Remember date-axis labels independent aggregation data bars, visually can important align bins, date labels, vertical grid lines.modify date labels grid lines, use scale_x_date() one ways:histogram bins days, Monday weeks, months, years:\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)\nUse date_minor_breaks = specify interval minor vertical gridlines (date labels)\nAdd expand = c(0,0) begin labels first bar\nUse date_labels = specify format date labels - see Dates page tips (use \\n new line)\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)Use date_minor_breaks = specify interval minor vertical gridlines (date labels)Add expand = c(0,0) begin labels first barUse date_labels = specify format date labels - see Dates page tips (use \\n new line)histogram bins Sunday weeks:\nUse breaks = minor_breaks = providing sequence date breaks \ncan still use date_labels = expand = formatting described \nUse breaks = minor_breaks = providing sequence date breaks eachYou can still use date_labels = expand = formatting described aboveSome notes:See opening ggplot section instructions create sequence dates using seq.Date().See page Working dates page tips creating date labels.","code":""},{"path":"epidemic-curves.html","id":"demonstrations","chapter":"32 Epidemic curves","heading":"Demonstrations","text":"demonstration plots bins plot labels/grid lines aligned aligned:","code":"\n# 7-day bins + Monday labels\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 7-day bins with start at first case\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",             # Monday every 3 weeks\n    date_minor_breaks = \"week\",          # Monday weeks\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # remove excess space under x-axis, make flush\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7-day bins + Months\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",              # 1st of month\n    date_minor_breaks = \"week\",          # Monday weeks\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                 # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# TOTAL MONDAY ALIGNMENT: specify manual bin breaks to be mondays\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    closed = \"left\",                   # count cases from start of breakpoint\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"4 weeks\",             # Monday every 4 weeks\n    date_minor_breaks = \"week\",          # Monday weeks \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                  # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# TOTAL MONDAY ALIGNMENT WITH MONTHS LABELS:\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    closed = \"left\",                   # count cases from start of breakpoint\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",              # Monday every 4 weeks\n    date_minor_breaks = \"week\",          # Monday weeks \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                  # remove excess space under x-axis, make flush \n  \n  theme(panel.grid.major = element_blank())+  # Remove major gridlines (fall on 1st of month)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# TOTAL SUNDAY ALIGNMENT: specify manual bin breaks AND labels to be Sundays\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    closed = \"left\",                    # count cases from start of breakpoint\n\n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # date label breaks and major gridlines set to every 3 weeks beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # minor gridlines set to weekly beginning Sunday before first case\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    label = scales::label_date_short())+ # label formatting\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")"},{"path":"epidemic-curves.html","id":"aggregated-data","chapter":"32 Epidemic curves","heading":"Aggregated data","text":"Often instead linelist, begin aggregated counts facilities, districts, etc. can make epicurve ggplot() code slightly different. section utilize count_data dataset imported earlier, data preparation section. dataset linelist aggregated day-hospital counts. first 50 rows displayed .","code":""},{"path":"epidemic-curves.html","id":"plotting-daily-counts","chapter":"32 Epidemic curves","heading":"Plotting daily counts","text":"can plot daily epicurve daily counts. differences code:Within aesthetic mapping aes(), specify y = counts column (case, column name n_cases)Add argument stat = \"identity\" within geom_histogram(), specifies bar height y = value, number rows defaultAdd argument width = avoid vertical white lines bars. daily data set 1. weekly count data set 7. monthly count data, white lines issue (month different number days) - consider transforming x-axis categorical ordered factor (months) using geom_col().","code":"\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # for daily counts, set width = 1 to avoid white space between bars\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")"},{"path":"epidemic-curves.html","id":"plotting-weekly-counts","chapter":"32 Epidemic curves","heading":"Plotting weekly counts","text":"data already case counts week, might look like dataset (called count_data_weekly):first 50 rows count_data_weekly displayed . can see counts aggregated weeks. week displayed first day week (Monday default).Now plot x = epiweek column. Remember add y = counts column aesthetic mapping, add stat = \"identity\" explained .","code":"\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x-axis is epiweek (as class Date)\n      y = n_cases_weekly,    # y-axis height in the weekly case counts\n      group = hospital,      # we are grouping the bars and coloring by hospital\n      fill = hospital),\n    stat = \"identity\")+      # this is also required when plotting count data\n     \n  # labels for x-axis\n  scale_x_date(\n    date_breaks = \"2 months\",      # labels every 2 months \n    date_minor_breaks = \"1 month\", # gridlines every month\n    label = scales::label_date_short())+ # label formatting\n     \n  # Choose color palette (uses RColorBrewer package)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")"},{"path":"epidemic-curves.html","id":"moving-averages-1","chapter":"32 Epidemic curves","heading":"Moving averages","text":"See page Moving averages detailed description several options. one option calculating moving averages package slider. approach, moving average calculated dataset prior plotting:Aggregate data counts necessary (daily, weekly, etc.) (see Grouping data page)Create new column hold moving average, created slide_index() slider packagePlot moving average geom_line() top () epicurve histogramSee helpful online vignette slider package","code":"\n# load package\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# make dataset of daily counts and 7-day moving average\n#######################################################\nll_counts_7day <- linelist %>%    # begin with linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %>%   # name new column with counts as \"new_cases\"\n  drop_na(date_onset) %>%                     # remove cases with missing date_onset\n  \n  ## calculate the average number of cases in 7-day window\n  mutate(\n    avg_7day = slider::slide_index(    # create new column\n      new_cases,                       # calculate based on value in new_cases column\n      .i = date_onset,                 # index is date_onset col, so non-present dates are included in window \n      .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n      .before = 6,                     # window is the day and 6-days before\n      .complete = FALSE),              # must be FALSE for unlist() to work in next step\n    avg_7day = unlist(avg_7day))       # convert class list to class numeric\n\n\n# plot\n######\nggplot(data = ll_counts_7day) +  # begin with new dataset defined above \n    geom_histogram(              # create epicurve histogram\n      mapping = aes(\n        x = date_onset,          # date column as x-axis\n        y = new_cases),          # height is number of daily new cases\n        stat = \"identity\",       # height is y value\n        fill=\"#92a8d1\",          # cool color for bars\n        colour = \"#92a8d1\",      # same color for bar border\n        )+ \n    geom_line(                   # make line for rolling average\n      mapping = aes(\n        x = date_onset,          # date column for x-axis\n        y = avg_7day,            # y-value set to rolling average column\n        lty = \"7-day \\nrolling avg\"), # name of line in legend\n      color=\"red\",               # color of line\n      size = 1) +                # width of line\n    scale_x_date(                # date scale\n      date_breaks = \"1 month\",\n      label = scales::label_date_short(), # label formatting\n      expand = c(0,0)) +\n    scale_y_continuous(          # y-axis scale\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # removes title of legend"},{"path":"epidemic-curves.html","id":"facetingsmall-multiples","chapter":"32 Epidemic curves","heading":"Faceting/small-multiples","text":"ggplots, can create facetted plots (“small multiples”). explained ggplot tips page handbook, can use either facet_wrap() facet_grid(). demonstrate facet_wrap(). epicurves, facet_wrap() typically easier likely need facet one column.general syntax facet_wrap(rows ~ cols), left tilde (~) name column spread across “rows” facetted plot, right tilde name column spread across “columns” facetted plot. simply, just use one column name, right tilde: facet_wrap(~age_cat).Free axes\nneed decide whether scales axes facet “fixed” dimensions (default), “free” (meaning change based data within facet). scales = argument within facet_wrap() specifying “free_x” “free_y”, “free”.Number cols rows facets\ncan specified ncol = nrow = within facet_wrap().Order panels\nchange order appearance, change underlying order levels factor column used create facets.Aesthetics\nFont size face, strip color, etc. can modified theme() arguments like:strip.text = element_text() (size, colour, face, angle…)strip.background = element_rect() (e.g. element_rect(fill=“grey”))strip.position = (position strip “bottom”, “top”, “left”, “right”)Strip labels\nLabels facet plots can modified “labels” column factor, use “labeller”.Make labeller like , using function as_labeller() ggplot2. provide labeller labeller = argument facet_wrap() shown .example facetted plot - facetted column age_cat.See link information labellers.","code":"\nmy_labels <- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n# make plot\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # arguments inside aes() apply by group\n      \n    color = \"black\",      # arguments outside aes() apply to all data\n        \n    # histogram breaks\n    breaks = weekly_breaks_central, # pre-defined date vector (see earlier in this page)\n    closed = \"left\" # count cases from start of breakpoint\n    )+  \n                      \n  # The labels on the x-axis\n  scale_x_date(\n    expand            = c(0,0),          # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",      # labels appear every 2 months\n    date_minor_breaks = \"1 month\",       # vertical lines appear every 1 month \n    label = scales::label_date_short())+ # label formatting\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+                       # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"total-epidemic-in-facet-background","chapter":"32 Epidemic curves","heading":"Total epidemic in facet background","text":"show total epidemic background facet, add function gghighlight() empty parentheses ggplot. package gghighlight. Note y-axis maximum facets now based peak entire epidemic. examples package ggplot tips page.","code":"\nggplot(central_data) + \n  \n  # epicurves by group\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # arguments inside aes() apply by group\n    \n    color = \"black\",    # arguments outside aes() apply to all data\n    \n    # histogram breaks\n    breaks = weekly_breaks_central, # pre-defined date vector (see earlier in this page)\n    \n    closed = \"left\", # count cases from start of breakpoint\n    )+     # pre-defined date vector (see top of ggplot section)                \n  \n  # add grey epidemic in background to each facet\n  gghighlight::gghighlight()+\n  \n  # labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),          # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",      # labels appear every 2 months\n    date_minor_breaks = \"1 month\",       # vertical lines appear every 1 month \n    label = scales::label_date_short())+ # label formatting\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space below 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,                          # each plot is one value of age_cat\n    ncol = 4,                          # number of columns\n    strip.position = \"top\",            # position of the facet title/strip\n    labeller = my_labels)+             # labeller defines above\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"one-facet-with-data","chapter":"32 Epidemic curves","heading":"One facet with data","text":"want one facet box contains data, duplicate entire dataset treat duplicates one faceting value. “helper” function CreateAllFacet() can assist (thanks blog post). run, number rows doubles new column called facet duplicated rows value “”, original rows original value faceting colum. Now just facet facet column.helper function. Run available .Now apply helper function dataset, column age_cat:Notable changes ggplot() command :data used now central_data2 (double rows, new column “facet”)Labeller need updated, usedOptional: achieve vertically stacked facets: facet column moved rows side equation right replaced “.” (facet_wrap(facet~.)), ncol = 1. may also need adjust width height saved png plot image (see ggsave() ggplot tips).","code":"\n# Define helper function\nCreateAllFacet <- function(df, col){\n     df$facet <- df[[col]]\n     temp <- df\n     temp$facet <- \"all\"\n     merged <-rbind(temp, df)\n     \n     # ensure the facet value is a factor\n     merged[[col]] <- as.factor(merged[[col]])\n     \n     return(merged)\n}\n# Create dataset that is duplicated and with new column \"facet\" to show \"all\" age categories as another facet level\ncentral_data2 <- CreateAllFacet(central_data, col = \"age_cat\") %>%\n  \n  # set factor levels\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))## Warning: There was 1 warning in `mutate()`.\n## ℹ In argument: `facet = fct_relevel(...)`.\n## Caused by warning:\n## ! 1 unknown level in `f`: 70+\n# check levels\ntable(central_data2$facet, useNA = \"always\")## \n##   all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  <NA> \n##   454    84    84    82    58    73    57     7     9\nggplot(central_data2) + \n  \n  # actual epicurves by group\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # arguments inside aes() apply by group\n        color = \"black\",    # arguments outside aes() apply to all data\n        \n        # histogram breaks\n        breaks = weekly_breaks_central, # pre-defined date vector (see earlier in this page)\n        \n        closed = \"left\", # count cases from start of breakpoint\n        )+    # pre-defined date vector (see top of ggplot section)\n                     \n  # Labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),          # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",      # labels appear every 2 months\n    date_minor_breaks = \"1 month\",       # vertical lines appear every 1 month \n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # create facets\n  facet_wrap(facet~. ,                            # each plot is one value of facet\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"tentative-data","chapter":"32 Epidemic curves","heading":"32.3 Tentative data","text":"recent data shown epicurves often marked tentative, subject reporting delays. can done adding vertical line /rectangle specified number days. two options:Use annotate():\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.\nrectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.rectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.Group data tentative status color bars differentlyCAUTION: might try geom_rect() draw rectangle, adjusting transparency work linelist context. function overlays one rectangle observation/row!. Use either low alpha (e.g. 0.01), another approach. ","code":""},{"path":"epidemic-curves.html","id":"using-annotate","chapter":"32 Epidemic curves","heading":"Using annotate()","text":"Within annotate(geom = \"rect\"), xmin xmax arguments must given inputs class Date.Note data aggregated weekly bars, last bar extends Monday last data point, shaded region may appear cover 4 weeksHere annotate() online exampleThe black vertical line can achieved code , using geom_vline() lose ability control height:","code":"\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    \n    closed = \"left\", # count cases from start of breakpoint\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"1 month\",             # 1st of month\n    date_minor_breaks = \"1 month\",       # 1st of month\n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # labels and theme\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # add semi-transparent red rectangle to tentative data\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # note must be wrapped in as.Date()\n    xmax  = as.Date(Inf),                                          # note must be wrapped in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha easy and intuitive to adjust using annotate()\n    fill  = \"red\")+\n  \n  # add black vertical line on top of other layers\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 days before last data\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # line begins at y = 0\n    yend  = Inf,       # line to top of plot\n    size  = 2,         # line size\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\"\n\n  # add text in rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")"},{"path":"epidemic-curves.html","id":"bars-color","chapter":"32 Epidemic curves","heading":"Bars color","text":"alternative approach adjust color display tentative bars data . create new column data preparation stage use group data, aes(fill = ) tentative data can different color alpha bars.","code":"\n# add column\n############\nplot_data <- central_data %>% \n  mutate(tentative = case_when(\n    date_onset >= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative if in last 7 days\n    TRUE                                       ~ \"Reliable\")) # all else reliable\n\n# plot\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogram\n  geom_histogram(\n    breaks = weekly_breaks_central,   # pre-defined data vector, see top of ggplot page\n    closed = \"left\", # count cases from start of breakpoint\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                     # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",             # Monday every 3 weeks\n    date_minor_breaks = \"week\",          # Monday weeks \n    label = scales::label_date_short())+ # automatic label formatting\n  \n  # labels and theme\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # remove title of legend"},{"path":"epidemic-curves.html","id":"multi-level-date-labels","chapter":"32 Epidemic curves","heading":"32.4 Multi-level date labels","text":"want multi-level date labels (e.g. month year) without duplicating lower label levels, consider one approaches :Remember - can can use tools like \\n within date_labels labels arguments put parts label new line . However, codes help take years months (example) lower line .easiest method assign labels = argument scale_x_date() function label_date_short() package scales (note: don’t forget include empty parentheses (), shown ). function automatically construct efficient date labels (read ). additional benefit function labels automatically adjust data expands time: days, weeks, months years.second option use faceting. :Case counts aggregated weeks aesthetic reasons. See Epicurves page (aggregated data tab) details.geom_area() line used instead histogram, faceting approach work well histograms.Aggregate weekly countsMake plotsThe technique faceting adapted post stackoverflow.com.","code":"\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    closed = \"left\",                  # count cases from start of breakpoint\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n\n  # y-axis scale as before \n  scale_y_continuous(expand = c(0,0))+\n  \n  # x-axis scale sets efficient date labels\n  scale_x_date(\n    expand = c(0,0),                      # remove excess x-axis space below and after case bars\n    labels = scales::label_date_short())+ # auto efficient date labels\n  \n  # labels and theme\n  labs(\n    title = \"Using label_date_short()\\nTo make automatic and efficient date labels\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()\n# Create dataset of case counts by week\n#######################################\ncentral_weekly <- linelist %>%\n  filter(hospital == \"Central Hospital\") %>%   # filter linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %>%  \n  count(week) %>%                              # summarize weekly case counts\n  drop_na(week) %>%                            # remove cases with missing onset_date\n  complete(                                    # fill-in all weeks with no cases reported\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # convert new NA values to 0 counts\n# plot with no facet box border\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establish x and y for entire plot\n  geom_line(stat = \"identity\",              # make line, line height is count number\n            color = \"#69b3a2\") +            # line color\n  geom_point(size=1, color=\"#69b3a2\") +     # make points at the weekly data points\n  geom_area(fill = \"#69b3a2\",               # fill area below line\n            alpha = 0.4)+                   # fill transparency\n  scale_x_date(date_labels=\"%b\",            # date label format show month \n               date_breaks=\"month\",         # date labels on 1st of each month\n               expand=c(0,0)) +             # remove excess space\n  scale_y_continuous(\n    expand  = c(0,0))+                      # remove excess space below x-axis\n  facet_grid(~lubridate::year(week),        # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",               # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                  # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",                  # facet label placement\n          strip.background = element_blank(),         # no facet lable background\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_blank(),             # no border for facet panel\n          panel.spacing=unit(0,\"cm\"))+                # No space between facet panels\n  labs(title = \"Nested year labels - points, shaded, no label border\")"},{"path":"epidemic-curves.html","id":"dual-axis","chapter":"32 Epidemic curves","heading":"32.5 Dual-axis","text":"Although fierce discussions validity dual axes within data visualization community, many epi supervisors still want see epicurve similar chart percent overlaid second axis. discussed extensively ggplot tips page, one example using cowplot method shown :Two distinct plots made, combined cowplot package.plots must exact x-axis (set limits) else data labels alignEach uses theme_cowplot() one y-axis moved right side plotNow use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\n#######################################\nplot_cases <- linelist %>% \n  \n  # plot cases per week\n  ggplot()+\n  \n  # create histogram  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks every week beginning monday before first case, going to monday after last case\n    breaks = weekly_breaks_all)+  # pre-defined vector of weekly dates (see top of ggplot section)\n        \n  # specify beginning and end of date axis to align with other plot\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  # labels\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# make second plot of percent died per week\n###########################################\nplot_deaths <- linelist %>%                        # begin with linelist\n  group_by(week = floor_date(date_onset, \"week\")) %>%  # create week column\n  \n  # summarise to get weekly percent of cases who died\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %>% \n  \n  # begin plot\n  ggplot()+\n  \n  # line of weekly percent who died\n  geom_line(                                # create line of percent died\n    mapping = aes(x = week, y = pct_died),  # specify y-height as pct_died column\n    stat = \"identity\",                      # set line height to the value in pct_death column, not the number of rows (which is default)\n    size = 2,\n    color = \"black\")+\n  \n  # Same date-axis limits as the other plot - perfect alignment\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  \n  # y-axis adjustments\n  scale_y_continuous(                # adjust y-axis\n    breaks = seq(0,100, 10),         # set break intervals of percent axis\n    limits = c(0, 100),              # set extent of percent axis\n    position = \"right\")+             # move percent axis to the right\n  \n  # Y-axis label, no x-axis label\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # percent axis label\n  \n  theme_cowplot()                   # add this to make the two plots merge together nicely\naligned_plots <- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"cumulative-incidence","chapter":"32 Epidemic curves","heading":"32.6 Cumulative Incidence","text":"beginning case linelist, create new column containing cumulative number cases per day outbreak using cumsum() base R:first 10 rows shown :cumulative column can plotted date_onset, using geom_line():can also overlaid onto epicurve, dual-axis using cowplot method described ggplot tips page:Now use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>%                # count of rows per day (returned in column \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n)       # new column of the cumulative number of rows at each date\n    )\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\nplot_cases <- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# make second plot of cumulative cases line\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\naligned_plots <- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"resources-25","chapter":"32 Epidemic curves","heading":"32.7 Resources","text":"","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"demographic-pyramids-and-likert-scales","chapter":"33 Demographic pyramids and Likert-scales","heading":"33 Demographic pyramids and Likert-scales","text":"Demographic pyramids useful show distributions age gender. Similar code can used visualize results Likert-style survey questions (e.g. “Strongly agree”, “Agree”, “Neutral”, “Disagree”, “Strongly disagree”). page cover following:Fast & easy pyramids using apyramid packageMore customizeable pyramids using ggplot()Displaying “baseline” demographics background pyramidUsing pyramid-style plots show types data (e.g responses Likert-style survey questions)","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"preparation-25","chapter":"33 Demographic pyramids and Likert-scales","heading":"33.1 Preparation","text":"","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"load-packages-22","chapter":"33 Demographic pyramids and Likert-scales","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rio,       # to import data\n               here,      # to locate files\n               tidyverse, # to clean, handle, and plot the data (includes ggplot2 package)\n               apyramid,  # a package dedicated to creating age pyramids\n               janitor,   # tables and cleaning data\n               stringr)   # working with strings for titles, captions, etc."},{"path":"demographic-pyramids-and-likert-scales.html","id":"import-data-20","chapter":"33 Demographic pyramids and Likert-scales","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"demographic-pyramids-and-likert-scales.html","id":"cleaning","chapter":"33 Demographic pyramids and Likert-scales","heading":"Cleaning","text":"make traditional age/gender demographic pyramid, data must first cleaned following ways:gender column must cleaned.Depending method, age stored either numeric age category column.using age categories, column values corrected ordered, either default alpha-numeric intentionally set converting class factor.use tabyl() janitor inspect columns gender age_cat5.also run quick histogram age column ensure clean correctly classified:","code":"\nlinelist %>% \n  tabyl(age_cat5, gender)##  age_cat5   f   m NA_\n##       0-4 640 416  39\n##       5-9 641 412  42\n##     10-14 518 383  40\n##     15-19 359 364  20\n##     20-24 305 316  17\n##     25-29 163 259  13\n##     30-34 104 213   9\n##     35-39  42 157   3\n##     40-44  25 107   1\n##     45-49   8  80   5\n##     50-54   2  37   1\n##     55-59   0  30   0\n##     60-64   0  12   0\n##     65-69   0  12   1\n##     70-74   0   4   0\n##     75-79   0   0   1\n##     80-84   0   1   0\n##       85+   0   0   0\n##      <NA>   0   0  86\nhist(linelist$age)"},{"path":"demographic-pyramids-and-likert-scales.html","id":"apyramid-package","chapter":"33 Demographic pyramids and Likert-scales","heading":"33.2 apyramid package","text":"package apyramid product R4Epis project. can read package . allows quickly make age pyramid. nuanced situations, see section using ggplot(). can read apyramid package Help page entering ?age_pyramid R console.","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"linelist-data","chapter":"33 Demographic pyramids and Likert-scales","heading":"Linelist data","text":"Using cleaned linelist dataset, can create age pyramid one simple age_pyramid() command. command:data = argument set linelist data frameThe age_group = argument (y-axis) set name categorical age column (quotes)split_by = argument (x-axis) set gender columnThe pyramid can displayed percent cases x-axis, instead counts, including proportional = TRUE.using agepyramid package, split_by column binary (e.g. male/female, yes/), result appear pyramid. However two values split_by column (including NA), pyramid appears faceted bar plot grey bars “background” indicating range un-faceted data age group. case, values split_by = appear labels top facet panel. example, occurs split_by = assigned column hospital.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  "},{"path":"demographic-pyramids-and-likert-scales.html","id":"missing-values-2","chapter":"33 Demographic pyramids and Likert-scales","heading":"Missing values","text":"Rows NA missing values split_by = age_group = columns, coded NA, trigger faceting shown . default rows shown. However can specify appear, adjacent barplot separate age group top, specifying na.rm = FALSE.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # show patients missing age or gender"},{"path":"demographic-pyramids-and-likert-scales.html","id":"proportions-colors-aesthetics","chapter":"33 Demographic pyramids and Likert-scales","heading":"Proportions, colors, & aesthetics","text":"default, bars display counts (%), dashed mid-line group shown, colors green/purple. parameters can adjusted, shown :can also add additional ggplot() commands plot using standard ggplot() “+” syntax, aesthetic themes label adjustments:","code":"\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # show percents, not counts\n  show_midpoint = FALSE,            # remove bar mid-point line\n  #pal = c(\"orange\", \"purple\")      # can specify alt. colors here (but not labels)\n  )+                 \n  \n  # additional ggplot commands\n  theme_minimal()+                               # simplfy background\n  scale_fill_manual(                             # specify colors AND labels\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # note x and y labs are switched\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # legend to bottom\n    axis.text = element_text(size = 10, face = \"bold\"),  # fonts/sizes\n    axis.title = element_text(size = 12, face = \"bold\"))"},{"path":"demographic-pyramids-and-likert-scales.html","id":"aggregated-data-1","chapter":"33 Demographic pyramids and Likert-scales","heading":"Aggregated data","text":"examples assume data linelist format, one row per observation. data already aggregated counts age category, can still use apyramid package, shown .demonstration, aggregate linelist data counts age category gender, “wide” format. simulate data counts begin . Learn Grouping data Pivoting data respective pages.…makes dataset looks like : columns age category, male counts, female counts, missing counts.set-data age pyramid, pivot data “long” pivot_longer() function dplyr. ggplot() generally prefers “long” data, apyramid using ggplot().use split_by = count = arguments age_pyramid() specify respective columns data:Note , factor order “m” “f” different (pyramid reversed). adjust order must re-define gender aggregated data Factor order levels desired. See Factors page.","code":"\ndemo_agg <- linelist %>% \n  count(age_cat5, gender, name = \"cases\") %>% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %>% \n  rename(`missing_gender` = `NA`)\n# pivot the aggregated data into long format\ndemo_agg_long <- demo_agg %>% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # cols to elongate\n    names_to = \"gender\",                # name for new col of categories\n    values_to = \"counts\") %>%           # name for new col of counts\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # convert \"missing_gender\" to NA\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# column name for age category\n                      split_by = \"gender\",   # column name for gender\n                      count = \"counts\")      # column name for case counts"},{"path":"demographic-pyramids-and-likert-scales.html","id":"demo_pyr_gg","chapter":"33 Demographic pyramids and Likert-scales","heading":"33.3 ggplot()","text":"Using ggplot() build age pyramid allows flexibility, requires effort understanding ggplot() works. also easier accidentally make mistakes.use ggplot() make demographic pyramids, create two bar plots (one gender), convert values one plot negative, finally flip x y axes display bar plots vertically, bases meeting plot middle.","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"preparation-26","chapter":"33 Demographic pyramids and Likert-scales","heading":"Preparation","text":"approach uses numeric age column, categorical column age_cat5. check ensure class column indeed numeric.use logic build pyramid categorical data using geom_col() instead geom_histogram().","code":"\nclass(linelist$age)## [1] \"numeric\""},{"path":"demographic-pyramids-and-likert-scales.html","id":"constructing-the-plot","chapter":"33 Demographic pyramids and Likert-scales","heading":"Constructing the plot","text":"First, understand make pyramid using ggplot() approach follows:Within ggplot(), create two histograms using numeric age column. Create one two grouping values (case genders male female). , data histogram specified within respective geom_histogram() commands, respective filters applied linelist.Within ggplot(), create two histograms using numeric age column. Create one two grouping values (case genders male female). , data histogram specified within respective geom_histogram() commands, respective filters applied linelist.One graph positive count values, counts converted negative values - creates “pyramid” 0 value middle plot. negative values created using special ggplot2 term ..count.. multiplying -1.One graph positive count values, counts converted negative values - creates “pyramid” 0 value middle plot. negative values created using special ggplot2 term ..count.. multiplying -1.command coord_flip() switches X Y axes, resulting graphs turning vertical creating pyramid.command coord_flip() switches X Y axes, resulting graphs turning vertical creating pyramid.Lastly, counts-axis value labels must altered appear “positive” counts sides pyramid (despite underlying values one side negative).Lastly, counts-axis value labels must altered appear “positive” counts sides pyramid (despite underlying values one side negative).simple version , using geom_histogram(), :DANGER: limits counts axis set low, counts bar exceeds , bar disappear entirely artificially shortened! Watch analyzing data routinely updated. Prevent count-axis limits auto-adjust data, .many things can change/add simple version, including:Auto adjust counts-axis scale data (avoid errors discussed warning )Manually specify colors legend labelsConvert counts percentsTo convert counts percents (total), data prior plotting. , get age-gender counts, ungroup(), mutate() create new percent columns. want percents gender, skip ungroup step.Importantly, save max min values know limits scale . used ggplot() command .Finally make ggplot() percent data. specify scale_y_continuous() extend pre-defined lengths direction (positive “negative”). use floor() ceiling() round decimals appropriate direction () side axis.","code":"\n  # begin ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # female histogram\n  geom_histogram(data = linelist %>% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # male histogram (values converted to negative)\n  geom_histogram(data = linelist %>% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # flip the X and Y axes\n  coord_flip() +\n  \n  # adjust counts-axis scale\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n# create dataset with proportion of total\npyramid_data <- linelist %>%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %>% \n  ungroup() %>%                 # ungroup so percents are not by group\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,     # convert male to negative\n            TRUE          ~ NA_real_))    # NA val must by numeric as well\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n\nmax_per## [1] 10.9\nmin_per## [1] -7.1\n# begin ggplot\n  ggplot()+  # default x-axis is age in years;\n\n  # case data graph\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # white around each bar\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n\n  # adjust the axes scales\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # sequence of values, by 2s\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # sequence of absolute values, by 2s, with \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # label values (remember X and Y flipped now)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # display themes\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )"},{"path":"demographic-pyramids-and-likert-scales.html","id":"compare-to-baseline","chapter":"33 Demographic pyramids and Likert-scales","heading":"Compare to baseline","text":"flexibility ggplot(), can second layer bars background represent “true” “baseline” population pyramid. can provide nice visualization compare observed baseline.Import view population data (see Download handbook data page):First data management steps:record order age categories want appear. Due quirks way ggplot() implemented, specific scenario easiest store character vector use later plotting function.Combine population case data dplyr function bind_rows():First, ensure exact column names, age categories values, gender valuesMake data structure: columns age category, gender, counts, percent totalBind together, one -top (bind_rows())Review changed population datasetNow implement case linelist. Slightly different begins case-rows, counts.Review changed case datasetNow two data frames combined, one top (column names). can “name” data frame, use .id = argument create new column “data_source” indicate data frame row originated . can use column filter ggplot().Store maximum minimum percent values, used plotting function define extent plot (cut short bars!)Now plot made ggplot():One bar graph population data (wider, transparent bars)One bar graph case data (small, solid bars)","code":"\n# import the population demographics data\npop <- rio::import(\"country_demographics.csv\")\n# record correct age cat levels\nage_levels <- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n# create/transform populaton data, with percent of total\n########################################################\npop_data <- pop %>% \n  pivot_longer(      # pivot gender columns longer\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %>% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % of total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent,               # if male, convert % to negative\n     TRUE          ~ NA_real_))\n# create case data by age/gender, with percent of total\n#######################################################\ncase_data <- linelist %>%\n  count(age_cat5, gender, name = \"counts\") %>%  # counts by age-gender groups\n  ungroup() %>% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups\n    percent = case_when(                                     # convert % to negative if male\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent,\n      TRUE          ~ NA_real_))\n# combine case and population data (same column names, age_cat values, and gender values)\npyramid_data <- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n# Define extent of percent axis, used for plot limits\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n# begin ggplot\n##############\nggplot()+  # default x-axis is age in years;\n\n  # population data graph\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # black color around bars\n    alpha = 0.2,                                    # more transparent\n    width = 1)+                                     # full width\n  \n  # case data graph\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # age categories as original X axis\n      y = percent,                                # % as original Y-axis\n      fill = gender),                             # fill of bars by gender\n    colour = \"black\",                               # black color around bars\n    alpha = 1,                                      # not transparent \n    width = 0.3)+                                   # half width\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n  # manually ensure that age-axis is ordered correctly\n  scale_x_discrete(limits = age_levels)+     # defined in chunk above\n  \n  # set percent-axis \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # min and max defined above\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # from min% to max% by 2 \n    labels = paste0(                                                       # for the labels, paste together... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # assign colors to values in the data\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # change labels that appear in legend, note order\n  ) +\n\n  # plot labels, titles, caption    \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))"},{"path":"demographic-pyramids-and-likert-scales.html","id":"likert-scale","chapter":"33 Demographic pyramids and Likert-scales","heading":"33.4 Likert scale","text":"techniques used make population pyramid ggplot() can also used make plots Likert-scale survey data.Import data (see Download handbook data page desired).Start data looks like , categorical classification respondent (status) answers 8 questions 4-point Likert-type scale (“poor”, “Poor”, “Good”, “good”).First, data management steps:Pivot data longerCreate new column direction depending whether response generally “positive” “negative”Set Factor level order status column Response columnStore max count value limits plot appropriateNow make plot. age pyramids , creating two bar plots inverting values one negative.use geom_bar() data one row per observation, aggregated counts. use special ggplot2 term ..count.. one bar plots invert values negative (*-1), set position = \"stack\" values stack top .","code":"\n# import the likert survey response data\nlikert_data <- rio::import(\"likert_data.csv\")\nmelted <- likert_data %>% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %>% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # must reverse 'Very Poor' and 'Poor' for ordering to work\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# get largest value for scale limits\nmelted_max <- melted %>% \n  count(status, Question) %>% # get counts\n  pull(n) %>%                 # column 'n'\n  max(na.rm=T)                # get max\n# make plot\nggplot()+\n     \n  # bar graph of the \"negative\" responses \n     geom_bar(\n       data = melted %>% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # counts inverted to negative\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # bar graph of the \"positive responses\n     geom_bar(\n       data = melted %>% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # flip the X and Y axes\n     coord_flip()+\n  \n     # Black vertical line at 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # convert labels to all positive numbers\n    scale_y_continuous(\n      \n      # limits of the x-axis scale\n      limits = c(-ceiling(melted_max/10)*11,    # seq from neg to pos by 10, edges rounded outward to nearest 5\n                 ceiling(melted_max/10)*10),   \n      \n      # values of the x-axis scale\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # labels of the x-axis scale\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # color scales manually assigned \n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # assigns colors\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # orders the legend\n     \n    \n     \n    # facet the entire plot so each question is a sub-plot\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # labels, titles, caption\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # display adjustments \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # facet sub-titles\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # black box around each facet"},{"path":"demographic-pyramids-and-likert-scales.html","id":"resources-26","chapter":"33 Demographic pyramids and Likert-scales","heading":"33.5 Resources","text":"apyramid documentation","code":""},{"path":"heat-plots.html","id":"heat-plots","chapter":"34 Heat plots","heading":"34 Heat plots","text":"Heat plots, also known “heat maps” “heat tiles”, can useful visualizations trying display 3 variables (x-axis, y-axis, fill). demonstrate two examples:visual matrix transmission events age (“infected ”)Tracking reporting metrics across many facilities/jurisdictions time","code":""},{"path":"heat-plots.html","id":"preparation-27","chapter":"34 Heat plots","heading":"34.1 Preparation","text":"","code":""},{"path":"heat-plots.html","id":"load-packages-23","chapter":"34 Heat plots","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.DatasetsThis page utilizes case linelist simulated outbreak transmission matrix section, separate dataset daily malaria case counts facility metrics tracking section. loaded cleaned individual sections.","code":"\npacman::p_load(\n  tidyverse,       # data manipulation and visualization\n  rio,             # importing data \n  lubridate        # working with dates\n  )"},{"path":"heat-plots.html","id":"transmission-matrix","chapter":"34 Heat plots","heading":"34.2 Transmission matrix","text":"Heat tiles can useful visualize matrices. One example display “-infected-” outbreak. assumes information transmission events.Note Contact tracing page contains another example making heat tile contact matrix, using different (perhaps simple) dataset ages cases sources neatly aligned row data frame. data used make density map ggplot tips page. example begins case linelist involves considerable data manipulation prior achieving plotable data frame. many scenarios chose …begin case linelist simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see Import export page details).first 50 rows linelist shown demonstration:linelist:one row per case, identified case_idThere later column infector contains case_id infector, also case linelist","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"heat-plots.html","id":"data-preparation","chapter":"34 Heat plots","heading":"Data preparation","text":"Objective: need achieve “long”-style data frame contains one row per possible age--age transmission route, numeric column containing row’s proportion observed transmission events linelist.take several data manuipulation steps achieve:","code":""},{"path":"heat-plots.html","id":"make-cases-data-frame","chapter":"34 Heat plots","heading":"Make cases data frame","text":"begin, create data frame cases, ages, infectors - call data frame case_ages. first 50 rows displayed .","code":"\ncase_ages <- linelist %>% \n  select(case_id, infector, age_cat) %>% \n  rename(\"case_age_cat\" = \"age_cat\")"},{"path":"heat-plots.html","id":"make-infectors-data-frame","chapter":"34 Heat plots","heading":"Make infectors data frame","text":"Next, create data frame infectors - moment consists single column. infector IDs linelist. every case known infector, remove missing values. first 50 rows displayed .Next, use joins procure ages infectors. simple, linelist, infector’s ages listed . achieve result joining case linelist infectors. begin infectors, left_join() (add) case linelist infector id column left-side “baseline” data frame joins case_id column right-side linelist data frame.Thus, data infector’s case record linelist (including age) added infector row. 50 first rows displayed ., combine cases ages infectors ages. data frame column infector, used join. first rows displayed :, simple cross-tabulation counts case infector age groups. Labels added clarity.can convert table data frame data.frame() base R, also automatically converts “long” format, desired ggplot(). first rows shown .Now , apply prop.table() base R table instead counts get proportions total. first 50 rows shown .","code":"\ninfectors <- linelist %>% \n  select(infector) %>% \n  drop_na(infector)\ninfector_ages <- infectors %>%             # begin with infectors\n  left_join(                               # add the linelist data to each infector  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %>%    # match infector to their information as a case\n  select(infector, age_cat) %>%            # keep only columns of interest\n  rename(\"infector_age_cat\" = \"age_cat\")   # rename for clarity\nages_complete <- case_ages %>%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %>%        # each has the column infector\n  drop_na()                     # drop rows with any missing data## Warning in left_join(., infector_ages, by = \"infector\"): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 1 of `x` matches multiple rows in `y`.\n## ℹ Row 6 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this warning.\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)##        infectors\n## cases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n##   0-4   105 156   105   114   143   117    13   0\n##   5-9   102 132   110   102   117    96    12   5\n##   10-14 104 109    91    79   120    80    12   4\n##   15-19  85 105    82    39    75    69     7   5\n##   20-29 101 127   109    80   143   107    22   4\n##   30-49  72  97    56    54    98    61     4   5\n##   50-69   5   6    15     9     7     5     2   0\n##   70+     1   0     2     0     0     0     0   0\nlong_counts <- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\nlong_prop <- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))"},{"path":"heat-plots.html","id":"create-heat-plot","chapter":"34 Heat plots","heading":"Create heat plot","text":"Now finally can create heat plot ggplot2 package, using geom_tile() function. See ggplot tips page learn extensively color/fill scales, especially scale_fill_gradient() function.aesthetics aes() geom_tile() set x y case age infector ageAlso aes() set argument fill = Freq column - value converted tile colorSet scale color scale_fill_gradient() - can specify high/low colors\nNote scale_color_gradient() different! case want fill\nNote scale_color_gradient() different! case want fillBecause color made via “fill”, can use fill = argument labs() change legend title","code":"\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = cases,         # x-axis is case age\n      y = infectors,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # labels\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"heat-plots.html","id":"reporting-metrics-over-time","chapter":"34 Heat plots","heading":"34.3 Reporting metrics over time","text":"Often public health, one objective assess trends time many entities (facilities, jurisdictions, etc.). One way visualize trends time heat plot x-axis time y-axis many entities.","code":""},{"path":"heat-plots.html","id":"data-preparation-1","chapter":"34 Heat plots","heading":"Data preparation","text":"begin importing dataset daily malaria reports many facilities. reports contain date, province, district, malaria counts. See page Download handbook data information download data. first 30 rows:","code":"\nfacility_count_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"heat-plots.html","id":"aggregate-and-summarize","chapter":"34 Heat plots","heading":"Aggregate and summarize","text":"objective example transform daily facility total malaria case counts (seen previous tab) weekly summary statistics facility reporting performance - case proportion days per week facility reported data. example show data Spring District.achieve following data management steps:Filter data appropriate (place, date)Create week column using floor_date() package lubridate\nfunction returns start-date given date’s week, using specified start date week (e.g. “Mondays”)\nfunction returns start-date given date’s week, using specified start date week (e.g. “Mondays”)data grouped columns “location” “week” create analysis units “facility-week”function summarise() creates new columns reflecting summary statistics per facility-week group:\nNumber days per week (7 - static value)\nNumber reports received facility-week (7!)\nSum malaria cases reported facility-week (just interest)\nNumber unique days facility-week data reported\nPercent 7 days per facility-week data reported\nNumber days per week (7 - static value)Number reports received facility-week (7!)Sum malaria cases reported facility-week (just interest)Number unique days facility-week data reportedPercent 7 days per facility-week data reportedThe data frame joined right_join() comprehensive list possible facility-week combinations, make dataset complete. matrix possible combinations created applying expand() two columns data frame moment pipe chain (represented .). right_join() used, rows expand() data frame kept, added agg_weeks necessary. new rows appear NA (missing) summarized values.demonstrate step--step:Now dataset nrow(agg_weeks) rows, previously nrow(facility_count_data).Next create week column reflecting start date week record. achieved lubridate package function floor_date(), set “week” weeks begin Mondays (day 1 week - Sundays 7). top rows shown .new week column can seen far right data frameNow group data facility-weeks summarise produce statistics per facility-week. See page Descriptive tables tips. grouping doesn’t change data frame, impacts subsequent summary statistics calculated.top rows shown . Note columns completely changed reflect desired summary statistics. row reflects one facility-week.Finally, run command ensure possible facility-weeks present data, even missing .using right_join() (dataset represented “.”) expanded include possible combinations columns week location_name. See documentation expand() function page [Pivoting]. running code dataset contains nrow(agg_weeks) rows.expanded_weeks, 180 rows:running code, agg_weeks contains 107 rows.running code, agg_weeks contains nrow(agg_weeks) rows.","code":"\n# Create weekly summary dataset\nagg_weeks <- facility_count_data %>% \n  \n  # filter the data as appropriate\n  filter(\n    District == \"Spring\",\n    data_date < as.Date(\"2020-08-01\")) \nagg_weeks <- agg_weeks %>% \n  # Create week column from data_date\n  mutate(\n    week = lubridate::floor_date(                     # create new column of weeks\n      data_date,                                      # date column\n      unit = \"week\",                                  # give start of the week\n      week_start = 1))                                # weeks to start on Mondays \nagg_weeks <- agg_weeks %>%   \n\n  # Group into facility-weeks\n  group_by(location_name, week) %>%\n  \n  # Create summary statistics columns on the grouped data\n  summarize(\n    n_days          = 7,                                          # 7 days per week           \n    n_reports       = dplyr::n(),                                 # number of reports received per week (could be >7)\n    malaria_tot     = sum(malaria_tot, na.rm = T),                # total malaria cases reported\n    n_days_reported = length(unique(data_date)),                  # number of unique days reporting per week\n    p_days_reported = round(100*(n_days_reported / n_days))) %>%  # percent of days reporting\n\n  ungroup(location_name, week)                                    # ungroup so expand() works in next step\n# Create data frame of every possible facility-week\nexpanded_weeks <- agg_weeks %>% \n  tidyr::expand(location_name, week)  # expand data frame to include all possible facility-week combinations\n# Use a right-join with the expanded facility-week list to fill-in the missing gaps in the data\nagg_weeks <- agg_weeks %>%      \n  right_join(expanded_weeks) %>%                            # Ensure every possible facility-week combination appears in the data\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # convert missing values to 0                           ## Joining with `by = join_by(location_name, week)`"},{"path":"heat-plots.html","id":"create-heat-plot-1","chapter":"34 Heat plots","heading":"Create heat plot","text":"ggplot() made using geom_tile() ggplot2 package:Weeks x-axis transformed dates, allowing use scale_x_date()location_name y-axis show facility namesThe fill p_days_reported, performance facility-week (numeric)scale_fill_gradient() used numeric fill, specifying colors high, low, NAscale_x_date() used x-axis specifying labels every 2 weeks formatDisplay themes labels can adjusted necessary","code":""},{"path":"heat-plots.html","id":"basic","chapter":"34 Heat plots","heading":"Basic","text":"basic heat plot produced , using default colors, scales, etc. explained , within aes() geom_tile() must provide x-axis column, y-axis column, column fill =. fill numeric value presents tile color.","code":"\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))"},{"path":"heat-plots.html","id":"cleaned-plot","chapter":"34 Heat plots","heading":"Cleaned plot","text":"can make plot look better adding additional ggplot2 functions, shown . See page ggplot tips details.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-plots.html","id":"ordered-y-axis","chapter":"34 Heat plots","heading":"Ordered y-axis","text":"Currently, facilities ordered “alpha-numerically” bottom top. want adjust order y-axis facilities, convert class factor provide order. See page Factors tips.Since many facilities don’t want write , try another approach - ordering facilities data frame using resulting column names factor level order. , column location_name converted factor, order levels set based total number reporting days filed facility across whole time-span., create data frame represents total number reports per facility, arranged ascending order. can use vector order factor levels plot.See data frame :Now use column data frame (facility_order$location_name) order factor levels location_name data frame agg_weeks:now data re-plotted, location_name ordered factor:","code":"\nfacility_order <- agg_weeks %>% \n  group_by(location_name) %>% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %>% \n  arrange(tot_reports) # ascending order\n# load package \npacman::p_load(forcats)\n\n# create factor and define levels manually\nagg_weeks <- agg_weeks %>% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-plots.html","id":"display-values","chapter":"34 Heat plots","heading":"Display values","text":"can add geom_text() layer top tiles, display actual numbers tile. aware may look pretty many small tiles!following code added: geom_text(aes(label = p_days_reported)). adds text onto every tile. text displayed value assigned argument label =, case set numeric column p_days_reported also used create color gradient.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  # text\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+      # add text on top of tile\n  \n  # fill scale\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                    # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-plots.html","id":"resources-27","chapter":"34 Heat plots","heading":"34.4 Resources","text":"scale_fill_gradient()R graph gallery - heatmap","code":""},{"path":"diagrams-and-charts.html","id":"diagrams-and-charts","chapter":"35 Diagrams and charts","heading":"35 Diagrams and charts","text":"page covers code produce:Flow diagrams using DiagrammeR DOT languageAlluvial/Sankey diagramsEvent timelines","code":""},{"path":"diagrams-and-charts.html","id":"preparation-28","chapter":"35 Diagrams and charts","heading":"35.1 Preparation","text":"","code":""},{"path":"diagrams-and-charts.html","id":"load-packages-24","chapter":"35 Diagrams and charts","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  DiagrammeR,     # for flow diagrams\n  networkD3,      # For alluvial/Sankey diagrams\n  tidyverse)      # data management and visualization"},{"path":"diagrams-and-charts.html","id":"import-data-21","chapter":"35 Diagrams and charts","heading":"Import data","text":"content page require dataset. However, Sankey diagram section, use case linelist simulated Ebola epidemic. want follow along part, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"diagrams-and-charts.html","id":"flow-diagrams","chapter":"35 Diagrams and charts","heading":"35.2 Flow diagrams","text":"One can use R package DiagrammeR create charts/flow charts. can static, can adjust somewhat dynamically based changes dataset.ToolsThe function grViz() used create “Graphviz” diagram. function accepts character string input containing instructions making diagram. Within string, instructions written different language, called DOT - quite easy learn basics.Basic structureOpen instructions grViz(\"Specify directionality name graph, open brackets, e.g. digraph my_flow_chart {Graph statement (layout, rank direction)Nodes statements (create nodes)Edges statements (gives links nodes)Close instructions }\")","code":""},{"path":"diagrams-and-charts.html","id":"simple-examples","chapter":"35 Diagrams and charts","heading":"Simple examples","text":"two simple examplesA minimal example:example perhaps bit applied public health context:","code":"\n# A minimal plot\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -> b -> c\n}\")\ngrViz(\"                           # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodes\n  #######\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]               # width of circles\n  \n  Primary                         # names of nodes\n  Secondary\n  Tertiary\n\n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer']\n  Secondary -> Tertiary [label = ' case transfer']\n}\n\")"},{"path":"diagrams-and-charts.html","id":"syntax","chapter":"35 Diagrams and charts","heading":"Syntax","text":"Basic syntaxNode names, edge statements, can separated spaces, semicolons, newlines.Rank directionA plot can re-oriented move left--right adjusting rankdir argument within graph statement. default TB (top--bottom), can LR (left--right), RL, BT.Node namesNode names can single words, simple example . use multi-word names special characters (e.g. parentheses, dashes), put node name within single quotes (’ ’). may easier short node name, assign label, shown within brackets [ ]. want newline within node’s name, must via label - use \\n node label within single quotes, shown .Subgroups\nWithin edge statements, subgroups can created either side edge curly brackets ({ }). edge applies nodes bracket - shorthand.Layoutsdot (set rankdir either TB, LR, RL, BT, )neatotwopicircoNodes - editable attributeslabel (text, single quotes multi-word)fillcolor (many possible colors)fontcoloralpha (transparency 0-1)shape (ellipse, oval, diamond, egg, plaintext, point, square, triangle)stylesidesperipheriesfixedsize (h x w)heightwidthdistortionpenwidth (width shape border)x (displacement left/right)y (displacement /)fontnamefontsizeiconEdges - editable attributesarrowsizearrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)arrowtaildir (direction, )style (dashed, …)coloralphaheadport (text front arrowhead)tailport (text behind arrowtail)fontnamefontsizefontcolorpenwidth (width arrow)minlen (minimum length)Color names: hexadecimal values ‘X11’ color names, see X11 details","code":""},{"path":"diagrams-and-charts.html","id":"complex-examples","chapter":"35 Diagrams and charts","heading":"Complex examples","text":"example expands surveillance_diagram, adding complex node names, grouped edges, colors stylingSub-graph clustersTo group nodes boxed clusters, put within named subgraph (subgraph name {}). subgraph identified within bounding box, begin name subgraph “cluster”, shown 4 boxes .Node shapesThe example , borrowed tutorial, shows applied node shapes shorthand serial edge connections","code":"DiagrammeR::grViz(\"               # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            # layout top-to-bottom\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary   [label = 'Primary\\nFacility'] \n  Secondary [label = 'Secondary\\nFacility'] \n  Tertiary  [label = 'Tertiary\\nFacility'] \n  SC        [label = 'Surveillance\\nCoordination',\n             fontcolor = darkgreen] \n  \n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  Secondary -> Tertiary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  \n  # grouped edge\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting',\n                                      fontcolor = darkgreen,\n                                      color = darkgreen,\n                                      style = dashed]\n}\n\")DiagrammeR::grViz(\"             # All instructions are within a large character string\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # width of circles\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Primary\\nFacility'] \n    Secondary [label = 'Secondary\\nFacility'] \n    Tertiary  [label = 'Tertiary\\nFacility'] \n    SC        [label = 'Surveillance\\nCoordination',\n               fontcolor = darkgreen] \n  }\n  \n  # nodes (boxes)\n  ###############\n  node [shape = box,                     # node shape\n        fontname = Helvetica]            # text font in node\n  \n  subgraph cluster_active {\n    Active [label = 'Active\\nSurveillance'] \n    HCF_active [label = 'HCF\\nActive Search']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Event-Based\\nSurveillance (EBS)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Community-Based\\nSurveillance (CBS)']\n    RECOs\n  }\n\n  \n  # edges\n  #######\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting']\n\n  Primary   -> Secondary [label = 'case transfer',\n                          fontcolor = red]\n  Secondary -> Tertiary [label = 'case transfer',\n                          fontcolor = red]\n  \n  HCF_active -> Active\n  \n  {'Social Media' Radio} -> EBS\n  \n  RECOs -> CBS\n}\n\")\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# define the global styles of the nodes. We can override these in box if we wish\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]\nprocess [label =  'Process \\n Data']\nstatistical [label = 'Statistical \\n Analysis']\nresults [label= 'Results']\n\n# edge definitions with the node IDs\n{data1 data2}  -> process -> statistical -> results\n}\")"},{"path":"diagrams-and-charts.html","id":"outputs","chapter":"35 Diagrams and charts","heading":"Outputs","text":"handle save outputsOutputs appear RStudio’s Viewer pane, default lower-right alongside Files, Plots, Packages, Help.export can “Save image” “Copy clipboard” Viewer. graphic adjust specified size.","code":""},{"path":"diagrams-and-charts.html","id":"parameterized-figures","chapter":"35 Diagrams and charts","heading":"Parameterized figures","text":"quote tutorial: https://mikeyharper.uk/flowcharts--r-using-diagrammer/“Parameterized figures: great benefit designing figures within R able connect figures directly analysis reading R values directly flowcharts. example, suppose created filtering process removes values stage process, can figure show number values left dataset stage process. , can use @@X symbol directly within figure, refer footer plot using [X]:, X unique numeric index.”encourage review tutorial parameterization something interested .","code":""},{"path":"diagrams-and-charts.html","id":"alluvialsankey-diagrams","chapter":"35 Diagrams and charts","heading":"35.3 Alluvial/Sankey Diagrams","text":"","code":""},{"path":"diagrams-and-charts.html","id":"load-packages-25","chapter":"35 Diagrams and charts","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.load networkD3 package produce diagram, also tidyverse data preparation steps.","code":"\npacman::p_load(\n  networkD3,\n  tidyverse)"},{"path":"diagrams-and-charts.html","id":"plotting-from-dataset","chapter":"35 Diagrams and charts","heading":"Plotting from dataset","text":"Plotting connections dataset. demonstrate using package case linelist. online tutorial.begin getting case counts unique age category hospital combination. ’ve removed values missing age category clarity. also re-label hospital age_cat columns source target respectively. two sides alluvial diagram.dataset now look like :Now create data frame diagram nodes, column name. consists values hospital age_cat. Note ensure class Character combining . adjust ID columns numbers instead labels:edit links data frame, created count(). add two numeric columns IDsource IDtarget actually reflect/create links nodes. columns hold rownumbers (position) source target nodes. 1 subtracted position numbers begin 0 (1).links dataset now looks like :Now plot Sankey diagram sankeyNetwork(). can read argument running ?sankeyNetwork console. Note unless set iterations = 0 order nodes may expected.example patient Outcome included well. Note data preparation step calculate counts cases age hospital, separately hospital outcome - bind counts together bind_rows().https://www.displayr.com/sankey-diagrams-r/","code":"\n# counts by hospital and age category\nlinks <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = hospital,\n         target = age_cat)\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\nnodes  # print##                                    name\n## 1                      Central Hospital\n## 2                     Military Hospital\n## 3                               Missing\n## 4                                 Other\n## 5                         Port Hospital\n## 6  St. Mark's Maternity Hospital (SMMH)\n## 7                                   0-4\n## 8                                   5-9\n## 9                                 10-14\n## 10                                15-19\n## 11                                20-29\n## 12                                30-49\n## 13                                50-69\n## 14                                  70+\n# match to numbers, not names\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n# plot\n######\np <- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # ensure node order is as in data\np\n# counts by hospital and age category\nage_hosp_links <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = age_cat,          # re-name\n         target = hospital)\n\nhosp_out_links <- linelist %>% \n    drop_na(age_cat) %>% \n    select(hospital, outcome) %>% \n    count(hospital, outcome) %>% \n    rename(source = hospital,       # re-name\n           target = outcome)\n\n# combine links\nlinks <- bind_rows(age_hosp_links, hosp_out_links)\n\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\n# Create id numbers\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n\n# plot\n######\np <- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np"},{"path":"diagrams-and-charts.html","id":"event-timelines","chapter":"35 Diagrams and charts","heading":"35.4 Event timelines","text":"make timeline showing specific events, can use vistime package.See vignetteHere events dataset begin :","code":"\n# load package\npacman::p_load(vistime,  # make the timeline\n               plotly    # for interactive visualization\n               )\np <- vistime(data)    # apply vistime\n\nlibrary(plotly)\n\n# step 1: transform into a list\npp <- plotly_build(p)\n\n# step 2: Marker size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size <- 10\n}\n\n# step 3: text size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size <- 10\n}\n\n\n# step 4: text position\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition <- \"right\"\n}\n\n#print\npp"},{"path":"diagrams-and-charts.html","id":"dags","chapter":"35 Diagrams and charts","heading":"35.5 DAGs","text":"can build DAG manually using DiagammeR package DOT language described .Alternatively, packages like ggdag daggityIntroduction DAGs ggdag vignetteCausal inference dags R","code":""},{"path":"diagrams-and-charts.html","id":"resources-28","chapter":"35 Diagrams and charts","heading":"35.6 Resources","text":"Much regarding DOT language adapted tutorial siteAnother -depth tutorial DiagammeRThis page Sankey diagrams","code":""},{"path":"combinations-analysis.html","id":"combinations-analysis","chapter":"36 Combinations analysis","heading":"36 Combinations analysis","text":"analysis plots frequency different combinations values/responses. example, plot frequency cases exhibited various combinations symptoms.analysis also often called:“Multiple response analysis”“Sets analysis”“Combinations analysis”example plot , five symptoms shown. vertical bar line dots indicating combination symptoms reflected bar . right, horizontal bars reflect frequency individual symptom.first method show uses package ggupset, second uses package UpSetR.","code":""},{"path":"combinations-analysis.html","id":"preparation-29","chapter":"36 Combinations analysis","heading":"36.1 Preparation","text":"","code":""},{"path":"combinations-analysis.html","id":"load-packages-26","chapter":"36 Combinations analysis","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,     # data management and visualization\n  UpSetR,        # special package for combination plots\n  ggupset)       # special package for combination plots"},{"path":"combinations-analysis.html","id":"import-data-22","chapter":"36 Combinations analysis","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).linelist includes five “yes/” variables reported symptoms. need transform variables bit use ggupset package make plot. View data (scroll right see symptoms variables).","code":"\n# import case linelist \nlinelist_sym <- import(\"linelist_cleaned.rds\")"},{"path":"combinations-analysis.html","id":"re-format-values","chapter":"36 Combinations analysis","heading":"Re-format values","text":"align format expected ggupset convert “yes” “” actual symptom name, using case_when() dplyr. “”, set value blank, values either NA symptom.Now make two final columns:Concatenating (gluing together) symptoms patient (character column)Convert column class list, can accepted ggupset make plotSee page Characters strings learn unite() function stringrView new data. Note two columns towards right end - pasted combined values, list","code":"\n# create column with the symptoms named, separated by semicolons\nlinelist_sym_1 <- linelist_sym %>% \n\n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  # if old value is \"yes\", new value is \"fever\", otherwise set to missing (NA)\nmutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n       chills = ifelse(chills == \"yes\", \"chills\", NA),\n       cough = ifelse(cough == \"yes\", \"cough\", NA),\n       aches = ifelse(aches == \"yes\", \"aches\", NA),\n       vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\nlinelist_sym_1 <- linelist_sym_1 %>% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %>% \n  mutate(\n    # make a copy of all_symptoms column, but of class \"list\" (which is required to use ggupset() in next step)\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )"},{"path":"combinations-analysis.html","id":"ggupset","chapter":"36 Combinations analysis","heading":"36.2 ggupset","text":"Load packageCreate plot. begin ggplot() geom_bar(), add special function scale_x_upset() ggupset.information ggupset can found online offline package documentation RStudio Help tab ?ggupset.","code":"\npacman::p_load(ggupset)\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")"},{"path":"combinations-analysis.html","id":"upsetr","chapter":"36 Combinations analysis","heading":"36.3 UpSetR","text":"UpSetR package allows customization plot, can difficult execute:Load packageData cleaningWe must convert linelist symptoms values 1 / 0.interested efficient command, can take advantage +() function, converts 1s 0s based logical statement. command utilizes across() function change multiple columns (read Cleaning data core functions).Now make plot using custom function upset() - using symptoms columns. must designate “sets” compare (names symptom columns). Alternatively, use nsets = order.= \"freq\" show top X combinations.","code":"\npacman::p_load(UpSetR)\nlinelist_sym_2 <- linelist_sym %>% \n     # convert the \"yes\" and \"no\" values into 1s and 0s\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n# Efficiently convert \"yes\" to 1 and 0\nlinelist_sym_2 <- linelist_sym %>% \n  \n  # convert the \"yes\" and \"no\" values into 1s and 0s\n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n# Make the plot\nlinelist_sym_2 %>% \n  UpSetR::upset(\n       sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n       order.by = \"freq\",\n       sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n       empty.intersections = \"on\",\n       # nsets = 3,\n       number.angles = 0,\n       point.size = 3.5,\n       line.size = 2, \n       mainbar.y.label = \"Symptoms Combinations\",\n       sets.x.label = \"Patients with Symptom\")"},{"path":"combinations-analysis.html","id":"resources-29","chapter":"36 Combinations analysis","heading":"36.4 Resources","text":"github page UpSetRA Shiny App version - can upload data*documentation - difficult interpret","code":""},{"path":"transmission-chains.html","id":"transmission-chains","chapter":"37 Transmission chains","heading":"37 Transmission chains","text":"","code":""},{"path":"transmission-chains.html","id":"overview-7","chapter":"37 Transmission chains","heading":"37.1 Overview","text":"primary tool handle, analyse visualise transmission chains contact\ntracing data package epicontacts, developed folks \nRECON. Try interactive plot hovering nodes \ninformation, dragging move clicking highlight downstream cases.","code":""},{"path":"transmission-chains.html","id":"preparation-30","chapter":"37 Transmission chains","heading":"37.2 Preparation","text":"","code":""},{"path":"transmission-chains.html","id":"load-packages-27","chapter":"37 Transmission chains","heading":"Load packages","text":"First load standard packages required data import manipulation. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.require development version epicontacts, can \ninstalled github using p_install_github() function pacman. need run command\n, every time use package (thereafter, can use p_load() usual).","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   remotes       # Package installation from github\n)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")"},{"path":"transmission-chains.html","id":"import-data-23","chapter":"37 Transmission chains","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download handbook data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed . particular interest columns case_id, generation, infector, source.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"transmission-chains.html","id":"creating-an-epicontacts-object","chapter":"37 Transmission chains","heading":"Creating an epicontacts object","text":"need create epicontacts object, requires two types \ndata:linelist documenting cases columns variables rows correspond unique casesa list edges defining links cases basis unique IDs (can contacts,\ntransmission events, etc.)already linelist, just need create list edges \ncases, specifically IDs. can extract transmission links \nlinelist linking infector column case_id column. point can also add “edge\nproperties”, mean variable describing link two\ncases, cases . illustration, add location\nvariable describing location transmission event, duration\nvariable describing duration contact days.code , dplyr function transmute similar mutate, except keeps\ncolumns specified within function. drop_na function \nfilter rows specified columns NA value; \ncase, want keep rows infector known.can now create epicontacts object using make_epicontacts\nfunction. need specify column linelist points unique case\nidentifier, well columns contacts point unique\nidentifiers cases involved link. links directional \ninfection going infector case, need specify\narguments accordingly. therefore also set directed\nargument TRUE, affect future operations.Upon examining epicontacts objects, can see case_id column\nlinelist renamed id case_id infector\ncolumns contacts renamed . ensures\nconsistency subsequent handling, visualisation analysis operations.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %>%\n  drop_na(infector)\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n## view epicontacts object\nepic## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 5,888 cases in linelist; 3,800 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 5,888 × 30\n##    id    generation date_infection date_onset date_hospitalisation date_outcome outcome gender   age age_unit age_years age_cat\n##    <chr>      <dbl> <date>         <date>     <date>               <date>       <chr>   <chr>  <dbl> <chr>        <dbl> <fct>  \n##  1 5fe5…          4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>    m          2 years            2 0-4    \n##  2 8689…          4 NA             2014-05-13 2014-05-14           2014-05-18   Recover f          3 years            3 0-4    \n##  3 11f8…          2 NA             2014-05-16 2014-05-18           2014-05-30   Recover m         56 years           56 50-69  \n##  4 b881…          3 2014-05-04     2014-05-18 2014-05-20           NA           <NA>    f         18 years           18 15-19  \n##  5 893f…          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover m          3 years            3 0-4    \n##  6 be99…          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24   Recover f         16 years           16 15-19  \n##  7 07e3…          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01   Recover f         16 years           16 15-19  \n##  8 3694…          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07   Death   f          0 years            0 0-4    \n##  9 f393…          4 NA             2014-06-05 2014-06-06           2014-06-18   Recover m         61 years           61 50-69  \n## 10 1389…          4 NA             2014-06-05 2014-06-07           2014-06-09   Death   f         27 years           27 20-29  \n## # ℹ 5,878 more rows\n## # ℹ 18 more variables: age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>,\n## #   ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\n## \n##   // contacts\n## \n## # A tibble: 3,800 × 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 f547d6 5fe599 Community         6\n##  2 f90f5f b8812a Community         3\n##  3 11f8ea 893f25 Nosocomial        8\n##  4 aec8ec be99c8 Nosocomial        2\n##  5 893f25 07e3e8 Nosocomial        9\n##  6 133ee7 369449 Community         3\n##  7 996f3a 2978ac Community        10\n##  8 133ee7 57a565 Community        10\n##  9 37a6f6 fc15ef Nosocomial        2\n## 10 9f6884 2eaa9a Nosocomial        5\n## # ℹ 3,790 more rows"},{"path":"transmission-chains.html","id":"handling","chapter":"37 Transmission chains","heading":"37.3 Handling","text":"","code":""},{"path":"transmission-chains.html","id":"subsetting","chapter":"37 Transmission chains","heading":"Subsetting","text":"subset() method epicontacts objects allows , among things,\nfiltering networks based properties linelist (“node attributes”) contacts\ndatabase (“edge attributes”). values must passed named lists \nrespective argument. example, code keeping \nmale cases linelist infection date April \nJuly 2014 (dates specified ranges), transmission links occured\nhospital.can use thin function either filter linelist include cases\nfound contacts setting argument = \"linelist\", \nfilter contacts include cases found linelist setting\nargument = \"contacts\". code , filtering \nepicontacts object keep transmission links involving male cases\ninfected April July filtered . can see \ntwo known transmission links fit specification.addition subsetting node edge attributes, networks can pruned \ninclude components connected certain nodes. cluster_id\nargument takes vector case IDs returns linelist individuals \nlinked, directly indirectly, IDs. code , can see\ntotal 13 linelist cases involved clusters containing\n2ae019 71577a.subset() method epicontacts objects also allows filtering cluster\nsize using cs, cs_min cs_max arguments. code , \nkeeping cases linked clusters 10 cases larger, can see \n271 linelist cases involved clusters.","code":"\nsub_attributes <- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 69 cases in linelist; 1,869 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 69 × 30\n##    id    generation date_infection date_onset date_hospitalisation date_outcome outcome gender   age age_unit age_years age_cat\n##    <chr>      <dbl> <date>         <date>     <date>               <date>       <chr>   <chr>  <dbl> <chr>        <dbl> <fct>  \n##  1 5fe5…          4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>    m          2 years            2 0-4    \n##  2 893f…          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover m          3 years            3 0-4    \n##  3 2978…          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15   Death   m         12 years           12 10-14  \n##  4 57a5…          4 2014-05-28     2014-06-13 2014-06-15           NA           Death   m         42 years           42 30-49  \n##  5 fc15…          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09   Recover m         19 years           19 15-19  \n##  6 99e8…          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09   Recover m         19 years           19 15-19  \n##  7 f327…          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14   Death   m         31 years           31 30-49  \n##  8 90e5…          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16   <NA>    m         67 years           67 50-69  \n##  9 a475…          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26   Death   m         45 years           45 30-49  \n## 10 da8e…          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01   <NA>    m         12 years           12 10-14  \n## # ℹ 59 more rows\n## # ℹ 18 more variables: age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>,\n## #   ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\n## \n##   // contacts\n## \n## # A tibble: 1,869 × 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 11f8ea 893f25 Nosocomial        8\n##  2 aec8ec be99c8 Nosocomial        2\n##  3 893f25 07e3e8 Nosocomial        9\n##  4 37a6f6 fc15ef Nosocomial        2\n##  5 9f6884 2eaa9a Nosocomial        5\n##  6 a75c7f 7f5a01 Nosocomial       10\n##  7 8e104d ddddee Nosocomial        7\n##  8 ab634e 99e8fa Nosocomial        5\n##  9 b799eb bc2adf Nosocomial        1\n## 10 5d9e4d 8bd1e8 Nosocomial        1\n## # ℹ 1,859 more rows\nsub_attributes <- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)## [1] 3\nsub_id <- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)## [1] 13\nsub_cs <- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)## [1] 271"},{"path":"transmission-chains.html","id":"accessing-ids","chapter":"37 Transmission chains","heading":"Accessing IDs","text":"get_id() function retrieves information case IDs \ndataset, can parameterized follows:linelist: IDs line list datacontacts: IDs contact dataset (“” “” combined): IDs “” column contact datsetto IDs “” column contact datasetall: IDs appear anywhere either datasetcommon: IDs appear contacts dataset line listFor example, first ten IDs contacts dataset?many IDs found linelist contacts?","code":"\ncontacts_ids <- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)##  [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\" \"9f6884\" \"4802b1\"\nlength(get_id(epic, \"common\"))## [1] 4352"},{"path":"transmission-chains.html","id":"visualization","chapter":"37 Transmission chains","heading":"37.4 Visualization","text":"","code":""},{"path":"transmission-chains.html","id":"basic-plotting","chapter":"37 Transmission chains","heading":"Basic plotting","text":"visualisations epicontacts objects handled plot\nfunction. first filter epicontacts object include \ncases onset dates June 2014 using subset function, \ninclude contacts linked cases using thin function.can create basic, interactive plot simply follows:can move nodes around dragging , hover \ninformation click highlight connected cases.large number arguments modify plot. cover\nmain ones , check documentation via ?vis_epicontacts (\nfunction called using plot epicontacts object) get full\ndescription function arguments.","code":"\n## subset epicontacts object\nsub <- epic %>%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %>%\n thin(\"contacts\")\n## plot epicontacts object\nplot(\n  sub,\n  width = 700,\n  height = 700\n)"},{"path":"transmission-chains.html","id":"visualising-node-attributes","chapter":"37 Transmission chains","heading":"Visualising node attributes","text":"Node color, node shape node size can mapped given column linelist\nusing node_color, node_shape node_size arguments. similar\naes syntax may recognise ggplot2.specific colors, shapes sizes nodes can specified follows:Colors via col_pal argument, either providing name list manual\nspecification color done , providing color palette\nfunction colorRampPalette(c(\"black\", \"red\", \"orange\")), \nprovide gradient colours ones specified.Colors via col_pal argument, either providing name list manual\nspecification color done , providing color palette\nfunction colorRampPalette(c(\"black\", \"red\", \"orange\")), \nprovide gradient colours ones specified.Shapes passing named list shapes argument, specifying one shape\nunique element linelist column specified node_shape\nargument. See codeawesome available shapes.Shapes passing named list shapes argument, specifying one shape\nunique element linelist column specified node_shape\nargument. See codeawesome available shapes.Size passing size range nodes size_range argument.Size passing size range nodes size_range argument.example, color represents outcome, shape gender size\nage:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"visualising-edge-attributes","chapter":"37 Transmission chains","heading":"Visualising edge attributes","text":"Edge color, width linetype can mapped given column contacts\ndataframe using edge_color, edge_width edge_linetype\narguments. specific colors widths edges can specified follows:Colors via edge_col_pal argument, manner used col_pal.Colors via edge_col_pal argument, manner used col_pal.Widths passing size range nodes width_range argument.Widths passing size range nodes width_range argument.example:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"temporal-axis","chapter":"37 Transmission chains","heading":"Temporal axis","text":"can also visualise network along temporal axis mapping x_axis\nargument column linelist. example , x-axis\nrepresents date symptom onset. also specified arrow_size\nargument ensure arrows large, set label = FALSE make\nfigure less cluttered.large number additional arguments futher specify \nnetwork visualised along temporal axis, can check \nvia ?vis_temporal_interactive (function called using plot \nepicontacts object x_axis specified). ’ll go \n.","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"specifying-transmission-tree-shape","chapter":"37 Transmission chains","heading":"Specifying transmission tree shape","text":"two main shapes transmission tree can assume, specified using\nnetwork_shape argument. first branching shape shown ,\nstraight edge connects two nodes. intuitive\nrepresentation, however can result overlapping edges densely connected\nnetwork. second shape rectangle, produces tree resembling \nphylogeny. example:case node can assigned unique vertical position toggling \nposition_dodge argument. position unconnected cases (.e. \nreported contacts) specified using unlinked_pos argument.position parent node relative children nodes can \nspecified using parent_pos argument. default option place \nparent node middle, however can placed bottom (parent_pos = 'bottom') top (parent_pos = 'top').","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"saving-plots-and-figures","chapter":"37 Transmission chains","heading":"Saving plots and figures","text":"can save plot interactive, self-contained html file \nvisSave function VisNetwork package:Saving network outputs image unfortunately less easy requires\nsave file html take screenshot file using\nwebshot package. code , converting html file saved\nPNG:","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %>%\n  visNetwork::visSave(\"network.html\")\nwebshot(url = \"network.html\", file = \"network.png\")"},{"path":"transmission-chains.html","id":"timelines","chapter":"37 Transmission chains","heading":"Timelines","text":"can also case timelines network, represented x-axis\ncase. can used visualise case locations, example, time\noutcome. generate timeline, need create data.frame least\nthree columns indicating case ID, start date “event” end\ndate “event”. can also add number columns can\nmapped node edge properties timeline. code ,\ngenerate timeline going date symptom onset date \noutcome, keep outcome hospital variables use define \nnode shape colour. Note can one timeline row/event\nper case, example case transferred multiple hospitals.pass timeline element timeline argument. can map\ntimeline attributes timeline node colours, shapes sizes way\ndefined previous sections, except two nodes: start end\nnode timeline, seperate arguments. example,\ntl_start_node_color defines timeline column mapped colour \nstart node, tl_end_node_shape defines timeline column \nmapped shape end node. can also map colour, width, linetype \nlabels timeline edge via tl_edge_* arguments.See ?vis_temporal_interactive (function called plotting \nepicontacts object) detailed documentation arguments. argument\nannotated code :","code":"\n## generate timeline\ntimeline <- linelist %>%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n## define shapes\nshapes <- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define colours\ncolours <- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## make plot\nplot(\n  sub,\n  ## max x coordinate to date of onset\n  x_axis = \"date_onset\",\n  ## use rectangular network shape\n  network_shape = \"rectangle\",\n  ## mape case node shapes to gender column\n  node_shape = \"gender\",\n  ## we don't want to map node colour to any columns - this is important as the\n  ## default value is to map to node id, which will mess up the colour scheme\n  node_color = NULL,\n  ## set case node size to 30 (as this is not a character, node_size is not\n  ## mapped to a column but instead interpreted as the actual node size)\n  node_size = 30,\n  ## set transmission link width to 4 (as this is not a character, edge_width is\n  ## not mapped to a column but instead interpreted as the actual edge width)\n  edge_width = 4,\n  ## provide the timeline object\n  timeline = timeline,\n  ## map the shape of the end node to the outcome column in the timeline object\n  tl_end_node_shape = \"outcome\",\n  ## set the size of the end node to 15 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## node size)\n  tl_end_node_size = 15,\n  ## map the colour of the timeline edge to the hospital column\n  tl_edge_color = \"hospital\",\n  ## set the width of the timeline edge to 2 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## edge width)\n  tl_edge_width = 2,\n  ## map edge labels to the hospital variable\n  tl_edge_label = \"hospital\",\n  ## specify the shape for everyone node attribute (defined above)\n  shapes = shapes,\n  ## specify the colour palette (defined above)\n  col_pal = colours,\n  ## set the size of the arrow to 0.5\n  arrow_size = 0.5,\n  ## use two columns in the legend\n  legend_ncol = 2,\n  ## set font size\n  font_size = 15,\n  ## define formatting for dates\n  date_labels = c(\"%d %b %Y\"),\n  ## don't plot the ID labels below nodes\n  label = FALSE,\n  ## specify height\n  height = 1000,\n  ## specify width\n  width = 1200,\n  ## ensure each case node has a unique y-coordinate - this is very important\n  ## when using timelines, otherwise you will have overlapping timelines from\n  ## different cases\n  position_dodge = TRUE\n)## Warning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed as ID not found in linelist or start/end date is\n## NA"},{"path":"transmission-chains.html","id":"analysis","chapter":"37 Transmission chains","heading":"37.5 Analysis","text":"","code":""},{"path":"transmission-chains.html","id":"summarising","chapter":"37 Transmission chains","heading":"Summarising","text":"can get overview network properties using \nsummary function.example, can see 57% contacts cases \nlinelist; means linelist data significant\nnumber cases involved transmission chains.","code":"\n## summarise epicontacts object\nsummary(epic)## \n## /// Overview //\n##   // number of unique IDs in linelist: 5888\n##   // number of unique IDs in contacts: 5511\n##   // number of unique IDs in both: 4352\n##   // number of contacts: 3800\n##   // contacts with both cases in linelist: 56.868 %\n## \n## /// Degrees of the network //\n##   // in-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n## \n##   // out-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n## \n##   // in and out degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   1.000   1.000   1.078   1.000   7.000 \n## \n## /// Attributes //\n##   // attributes in linelist:\n##  generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n## \n##   // attributes in contacts:\n##  location duration"},{"path":"transmission-chains.html","id":"pairwise-characteristics","chapter":"37 Transmission chains","heading":"Pairwise characteristics","text":"get_pairwise() function allows processing variable(s) line list\naccording pair contact dataset. following example, date\nonset disease extracted line list order compute \ndifference disease date onset pair. value \nproduced comparison represents serial interval (si).get_pairwise() interpret class column used \ncomparison, adjust method comparing values accordingly. \nnumbers dates (like si example ), function subtract\nvalues. applied columns characters categorical,\nget_pairwise() paste values together. function also allows\narbitrary processing (see “f” argument), discrete combinations can \neasily tabulated analyzed., see significant association transmission links gender.","code":"\nsi <- get_pairwise(epic, \"date_onset\")   \nsummary(si)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    5.00    9.00   11.01   15.00   99.00    1820\ntibble(si = si) %>%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1820 rows containing non-finite values (`stat_bin()`).\nhead(get_pairwise(epic, \"gender\"), n = 10)##  [1] \"f -> m\" NA       \"m -> m\" NA       \"m -> f\" \"f -> f\" NA       \"f -> m\" NA       \"m -> f\"\nget_pairwise(epic, \"gender\", f = table)##            values.to\n## values.from   f   m\n##           f 464 516\n##           m 510 468\nfisher.test(get_pairwise(epic, \"gender\", f = table))## \n##  Fisher's Exact Test for Count Data\n## \n## data:  get_pairwise(epic, \"gender\", f = table)\n## p-value = 0.03758\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  0.6882761 0.9892811\n## sample estimates:\n## odds ratio \n##  0.8252575"},{"path":"transmission-chains.html","id":"identifying-clusters","chapter":"37 Transmission chains","heading":"Identifying clusters","text":"get_clusters() function can used identify connected components\nepicontacts object. First, use retrieve data.frame\ncontaining cluster information:Let us look largest clusters. , add cluster information \nepicontacts object subset keep largest clusters:","code":"\nclust <- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)## \n##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n## 1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\nepic <- get_clusters(epic)\nmax_size <- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))"},{"path":"transmission-chains.html","id":"calculating-degrees","chapter":"37 Transmission chains","heading":"Calculating degrees","text":"degree node corresponds number edges connections \nnodes. get_degree() provides easy method calculating value \nepicontacts networks. high degree context indicates individual\ncontact many others. type argument indicates want\ncount -degree -degree, only_linelist argument\nindicates want calculate degree cases linelist.individuals ten contacts?mean number contacts?","code":"\ndeg_both <- get_degree(epic, type = \"both\", only_linelist = TRUE)\nhead(sort(deg_both, decreasing = TRUE), 10)## 916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n##      7      6      6      6      5      5      5      5      5      5\nmean(deg_both)## [1] 1.078473"},{"path":"transmission-chains.html","id":"resources-30","chapter":"37 Transmission chains","heading":"37.6 Resources","text":"\nepicontacts page\nprovides overview package functions includes -depth\nvignettes.github page can used raise\nissues request features.","code":""},{"path":"phylogenetic-trees-1.html","id":"phylogenetic-trees-1","chapter":"38 Phylogenetic trees","heading":"38 Phylogenetic trees","text":"","code":""},{"path":"phylogenetic-trees-1.html","id":"overview-8","chapter":"38 Phylogenetic trees","heading":"38.1 Overview","text":"Phylogenetic trees used visualize describe relatedness evolution organisms based sequence genetic code.can constructed genetic sequences using distance-based methods (neighbor-joining method) character-based methods (maximum likelihood Bayesian Markov Chain Monte Carlo method). Next-generation sequencing (NGS) become affordable becoming widely used public health describe pathogens causing infectious diseases. Portable sequencing devices decrease turn around time hold promises make data available support outbreak investigation real-time. NGS data can used identify origin source outbreak strain propagation, well determine presence antimicrobial resistance genes. visualize genetic relatedness samples phylogenetic tree constructed.page learn use ggtree package, allows combined visualization phylogenetic trees additional sample data form dataframe. enable us observe patterns improve understanding outbreak dynamic.","code":""},{"path":"phylogenetic-trees-1.html","id":"preparation-31","chapter":"38 Phylogenetic trees","heading":"38.2 Preparation","text":"","code":""},{"path":"phylogenetic-trees-1.html","id":"load-packages-28","chapter":"38 Phylogenetic trees","heading":"Load packages","text":"code chunk shows loading required packages. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,             # import/export\n  here,            # relative file paths\n  tidyverse,       # general data management and visualization\n  ape,             # to import and export phylogenetic files\n  ggtree,          # to visualize phylogenetic files\n  treeio,          # to visualize phylogenetic files\n  ggnewscale)      # to add additional layers of color schemes"},{"path":"phylogenetic-trees-1.html","id":"import-data-24","chapter":"38 Phylogenetic trees","heading":"Import data","text":"data page can downloaded instructions Download handbook data page.several different formats phylogenetic tree can stored (eg. Newick, NEXUS, Phylip). common one Newick file format (.nwk), standard representing trees computer-readable form. means entire tree can expressed string format “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59);”, listing nodes tips relationship (branch length) .Note: important understand phylogenetic tree file contain sequencing data, merely result genetic distances sequences. therefore extract sequencing data tree file.First, use read.tree() function ape package import Newick phylogenetic tree file .txt format, store list object class “phylo”. necessary, use () function package specify relative file path.Note: case newick tree saved .txt file easier handling downloading Github.inspect tree object see contains 299 tips (samples) 236 nodes.Second, import table stored .csv file additional information sequenced sample, gender, country origin attributes antimicrobial resistance, using import() function rio package:first 50 rows data:","code":"\ntree <- ape::read.tree(\"Shigella_tree.txt\")\ntree## \n## Phylogenetic tree with 299 tips and 236 internal nodes.\n## \n## Tip labels:\n##   SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\n## Node labels:\n##   17, 29, 100, 67, 100, 100, ...\n## \n## Rooted; includes branch lengths.\nsample_data <- import(\"sample_data_Shigella_tree.csv\")"},{"path":"phylogenetic-trees-1.html","id":"clean-and-inspect","chapter":"38 Phylogenetic trees","heading":"Clean and inspect","text":"clean inspect data: order assign correct sample data phylogenetic tree, values column Sample_ID sample_data data frame need match tip.labels values tree file:check formatting tip.labels tree file looking first 6 entries using head() base R.also make sure first column sample_data data frame Sample_ID. look column names dataframe using colnames() base R.look Sample_IDs data frame make sure formatting tip.label (eg. letters capitals, extra underscores _ letters numbers, etc.)can also compare samples present tree file vice versa generating logical vector TRUE FALSE match. printed , simplicity.can use vectors show sample IDs tree (none).Upon inspection can see format Sample_ID dataframe corresponds format sample names tip.labels. sorted order matched.ready go!","code":"\nhead(tree$tip.label) ## [1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\" \"S17BD05939\"\ncolnames(sample_data)   ##  [1] \"Sample_ID\"                  \"serotype\"                   \"Country\"                    \"Continent\"                 \n##  [5] \"Travel_history\"             \"Year\"                       \"Belgium\"                    \"Source\"                    \n##  [9] \"Gender\"                     \"gyrA_mutations\"             \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n## [13] \"MIC_CIP\"\nhead(sample_data$Sample_ID) # we again inspect only the first 6 using head()## [1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\" \"S18BD02657\"\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]## character(0)"},{"path":"phylogenetic-trees-1.html","id":"simple-tree-visualization","chapter":"38 Phylogenetic trees","heading":"38.3 Simple tree visualization","text":"","code":""},{"path":"phylogenetic-trees-1.html","id":"different-tree-layouts","chapter":"38 Phylogenetic trees","heading":"Different tree layouts","text":"ggtree offers many different layout formats may suitable specific purpose others. demonstrations. options see online book.example tree layouts:","code":"\nggtree(tree)                                            # simple linear tree\nggtree(tree,  branch.length = \"none\")                   # simple linear tree with all tips aligned\nggtree(tree, layout=\"circular\")                         # simple circular tree\nggtree(tree, layout=\"circular\", branch.length = \"none\") # simple circular tree with all tips aligned"},{"path":"phylogenetic-trees-1.html","id":"simple-tree-plus-sample-data","chapter":"38 Phylogenetic trees","heading":"Simple tree plus sample data","text":"%<+% operator used connect sample_data data frame tree file.\neasy annotation tree addition sample names tips, well coloring tip points desired branches:example circular tree:can export tree plot ggsave() ggplot object. Written way, ggsave() saves last image produced file path specify. Remember can use () relative file paths easily save subfolders, etc.","code":"\nggtree(tree, layout = \"circular\", branch.length = 'none') %<+% sample_data + # %<+% adds dataframe with sample data to tree\n  aes(color = I(Belgium))+                       # color the branches according to a variable in your dataframe\n  scale_color_manual(\n    name = \"Sample Origin\",                      # name of your color scheme (will show up in the legend like this)\n    breaks = c(\"Yes\", \"No\"),                     # the different options in your variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # how you want the different options named in your legend, allows for formatting\n    values = c(\"blue\", \"black\"),                  # the color you want to assign to the variable \n    na.value = \"black\") +                        # color NA values in black as well\n  new_scale_color()+                             # allows to add an additional color scheme for another variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # tip color by continent. You may change shape adding \"shape = \"\n      size = 1.5)+                               # define the size of the point at the tip\n  scale_color_brewer(\n    name = \"Continent\",                    # name of your color scheme (will show up in the legend like this)\n    palette = \"Set1\",                      # we choose a set of colors coming with the brewer package\n    na.value = \"grey\") +                    # for the NA values we choose the color grey\n  geom_tiplab(                             # adds name of sample to tip of its branch \n    color = 'black',                       # (add as many text lines as you wish with + , but you may need to adjust offset value to place them next to each other)\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align = TRUE)+    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # title of your graph\n  theme(\n    axis.title.x = element_blank(), # removes x-axis title\n    axis.title.y = element_blank(), # removes y-axis title\n    legend.title = element_text(    # defines font size and format of the legend title\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # defines font size and format of the legend text\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # defines font size and format of the plot title\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # defines placement of the legend\n    legend.box = \"vertical\",        # defines placement of the legend\n    legend.margin = margin())   \nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)"},{"path":"phylogenetic-trees-1.html","id":"tree-manipulation","chapter":"38 Phylogenetic trees","heading":"38.4 Tree manipulation","text":"Sometimes may large phylogenetic tree interested one part tree. example, produced tree including historical international samples get large overview dataset might fit bigger picture. look closer data want inspect portion bigger tree.Since phylogenetic tree file just output sequencing data analysis, can manipulate order nodes branches file . already determined previous analysis raw NGS data. able though zoom parts, hide parts even subset part tree.","code":""},{"path":"phylogenetic-trees-1.html","id":"zoom-in","chapter":"38 Phylogenetic trees","heading":"Zoom in","text":"don’t want “cut” tree, inspect part closely can zoom view specific part.First, plot entire tree linear format add numeric labels node tree.zoom one particular branch (sticking right), use viewClade() ggtree object p provide node number get closer look:","code":"\np <- ggtree(tree,) %<+% sample_data +\n  geom_tiplab(size = 1.5) +                # labels the tips of all branches with the sample name in the tree file\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # labels all the nodes in the tree\n\np  # print\nviewClade(p, node = 452)"},{"path":"phylogenetic-trees-1.html","id":"collapsing-branches","chapter":"38 Phylogenetic trees","heading":"Collapsing branches","text":"However, may want ignore branch can collapse node (node nr. 452) using collapse(). tree defined p_collapsed.clarity, print p_collapsed, add geom_point2() (blue diamond) node collapsed branch.","code":"\np_collapsed <- collapse(p, node = 452)\np_collapsed\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # we assign a symbol to the collapsed node\n            size = 5,                     # define the size of the symbol\n            shape = 23,                   # define the shape of the symbol\n            fill = \"steelblue\")           # define the color of the symbol"},{"path":"phylogenetic-trees-1.html","id":"subsetting-a-tree","chapter":"38 Phylogenetic trees","heading":"Subsetting a tree","text":"want make permanent change create new, reduced tree work can subset part tree_subset(). can save new newick tree file .txt file.First, inspect tree nodes tip labels order decide subset.Now, say decided subset tree node 528 (keep tips within branch node 528) save new sub_tree1 object:Lets look subset tree 1:can also subset based one particular sample, specifying many nodes “backwards” want include. Let’s subset part tree based sample, case S17BD07692, going back 9 nodes save new sub_tree2 object:Lets look subset tree 2:can also save new tree either Newick type even text file using write.tree() function ape package:","code":"\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %<+% sample_data +               # we add the asmple data using the %<+% operator\n  geom_tiplab(size = 1)+                                # label tips of all branches with sample name in tree file\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # labels all the nodes in the tree\n theme(\n   legend.position = \"none\",                            # removes the legend all together\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\nsub_tree1 <- tree_subset(\n  tree,\n  node = 528)                                            # we subset the tree at node 528\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\nsub_tree2 <- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back defines how many nodes backwards from the sample tip you want to go\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n# to save in .nwk format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# to save in .txt format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')"},{"path":"phylogenetic-trees-1.html","id":"rotating-nodes-in-a-tree","chapter":"38 Phylogenetic trees","heading":"Rotating nodes in a tree","text":"mentioned change order tips nodes tree, based genetic relatedness subject visual manipulation. can rote branches around nodes eases visualization.First, plot new subset tree 2 node labels choose node want manipulate store ggtree plot object p.can manipulate nodes applying ggtree::rotate() ggtree::flip():\nNote: illustrate nodes manipulating first apply geom_hilight() function ggtree highlight samples nodes interested store ggtree plot object new object p1.Now can rotate node 37 object p1 samples node 38 move top. store rotated tree new object p2.can use flip command rotate node 36 object p1 switch node 37 top node 39 bottom. store flipped tree new object p3.","code":"\np <- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # labels all the nodes in the tree\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\np1 <- p + geom_hilight(  # highlights node 39 in blue, \"extend =\" allows us to define the length of the color block\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # highlights the node 37 in yellow\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # print\np2 <- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # print\np3 <-  flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # print"},{"path":"phylogenetic-trees-1.html","id":"example-subtree-with-sample-data-annotation","chapter":"38 Phylogenetic trees","heading":"Example subtree with sample data annotation","text":"Lets say investigating cluster cases clonal expansion occurred 2017 2018 node 39 sub-tree. add year strain isolation well travel history color country see origin closely related strains:observation points towards import event strains Asia, circulated Belgium years seem caused latest outbreak.","code":"\nggtree(sub_tree2) %<+% sample_data +     # we use th %<+% operator to link to the sample_data\n  geom_tiplab(                          # labels the tips of all branches with the sample name in the tree file\n    size = 2.5,\n    offset = 0.001,\n    align = TRUE) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # set the x-axis limits of our tree\n  geom_tippoint(aes(color=Country),     # color the tip point by continent\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                          # add isolation year as a text label at the tips\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    align = TRUE)+ \n  geom_tiplab(                          # add travel history as a text label at the tips, in red color\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align = TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # add plot title\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                    # add a label to the x-axis \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))"},{"path":"phylogenetic-trees-1.html","id":"more-complex-trees-adding-heatmaps-of-sample-data","chapter":"38 Phylogenetic trees","heading":"More complex trees: adding heatmaps of sample data","text":"can add complex information, categorical presence antimicrobial resistance genes numeric values actually measured resistance antimicrobials form heatmap using ggtree::gheatmap() function.First need plot tree (can either linear circular) store new ggtree plot object p: use sub_tree part 3.)Second, prepare data. visualize different variables new color schemes, subset dataframe desired variable. important add Sample_ID rownames otherwise match data tree tip.labels:example want look gender mutations confer resistance Ciprofloxacin, important first line antibiotic used treat Shigella infections.create dataframe gender:create dataframe mutations gyrA gene, confer Ciprofloxacin resistance:create dataframe measured minimum inhibitory concentration (MIC) Ciprofloxacin laboratory:create first plot adding binary heatmap gender phylogenetic tree storing new ggtree plot object h1:add information mutations gyrA gene, confer resistance Ciprofloxacin:Note: presence chromosomal point mutations WGS data prior determined using PointFinder tool developed Zankari et al. (see reference additional references section)First, assign new color scheme existing plot object h1 store now object h2. enables us define change colors second variable heatmap.add second heatmap layer h2 store combined plots new object h3:repeat process, first adding new color scale layer existing object h3, adding continuous data minimum inhibitory concentration (MIC) Ciprofloxacin strain resulting object h4 produce final object h5:can exercise linear tree:First add gender:add Ciprofloxacin resistance mutations adding another color scheme layer:add minimum inhibitory concentration determined laboratory (MIC):","code":"\np <- ggtree(sub_tree2, branch.length='none', layout='circular') %<+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\ngender <- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) <- sample_data$Sample_ID\ncipR <- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) <- sample_data$Sample_ID\nMIC_Cip <- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) <- sample_data$Sample_ID\nh1 <-  gheatmap(p, gender,                                 # we add a heatmap layer of the gender dataframe to our tree plot\n                offset = 10,                               # offset shifts the heatmap to the right,\n                width = 0.10,                              # width defines the width of the heatmap column,\n                color = NULL,                              # color defines the boarder of the heatmap columns\n         colnames = FALSE) +                               # hides column names for the heatmap\n  scale_fill_manual(name = \"Gender\",                       # define the coloring scheme and legend for gender\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill() \nh3 <- gheatmap(h2, cipR,         # adds the second row of heatmap describing Ciprofloxacin resistance mutations\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh3\n# First we add the new coloring scheme:\nh4 <- h3 + new_scale_fill()\n\n# then we combine the two into a new plot:\nh5 <- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # here we define a gradient color scheme for the continuous variable of MIC\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh5\np <- ggtree(sub_tree2) %<+% sample_data +\n  geom_tiplab(size = 3) + # labels the tips\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\nh1 <-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill()\nh3 <- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\n h3\nh4 <- h3 + new_scale_fill()\nh5 <- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh5"},{"path":"phylogenetic-trees-1.html","id":"resources-31","chapter":"38 Phylogenetic trees","heading":"38.5 Resources","text":"http://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors\nhttps://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html\nhttps://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.htmlEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: novel web tool WGS-based detection antimicrobial resistance associated chromosomal point mutations bacterial pathogens, Journal Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764–2768, https://doi.org/10.1093/jac/dkx217","code":""},{"path":"interactive-plots.html","id":"interactive-plots","chapter":"39 Interactive plots","heading":"39 Interactive plots","text":"Data visualisation increasingly required interrogable audience. Consequently, becoming common create interactive plots. several ways include two common plotly shiny.page focus converting existing ggplot() plot interactive plot plotly. can read shiny Dashboards Shiny page. worth mentioning interactive plots useable HTML format R markdown documents, PDF Word documents.basic epicurve transformed interactive using integration ggplot2 plotly (hover mouse plot, zoom , click items legend).","code":""},{"path":"interactive-plots.html","id":"preparation-32","chapter":"39 Interactive plots","heading":"39.1 Preparation","text":"","code":""},{"path":"interactive-plots.html","id":"load-packages-29","chapter":"39 Interactive plots","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,       # import/export\n  here,      # filepaths\n  lubridate, # working with dates\n  plotly,    # interactive plots\n  scales,    # quick percents\n  tidyverse  # data management and visualization\n  ) "},{"path":"interactive-plots.html","id":"start-with-a-ggplot","chapter":"39 Interactive plots","heading":"Start with a ggplot()","text":"page assume beginning ggplot() plot want convert interactive. build several plots page, using case linelist used many pages handbook.","code":""},{"path":"interactive-plots.html","id":"import-data-25","chapter":"39 Interactive plots","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"interactive-plots.html","id":"plot-with-ggplotly","chapter":"39 Interactive plots","heading":"39.2 Plot with ggplotly()","text":"function ggplotly() plotly package makes easy convert ggplot() interactive. Simply save ggplot() pipe ggplotly() function., plot simple line representing proportion cases died given week:begin creating summary dataset epidemiological week, percent cases known outcome died.first 50 rows weekly_deaths dataset.create plot ggplot2, using geom_line().can make interactive simply passing plot ggplotly(), . Hover mouse line show x y values. can zoom plot, drag around. can also see icons upper-right plot. order, allow :Download current view PNG imageZoom select box“Pan”, move across plot clicking dragging plotZoom , zoom , return default zoomReset axes defaultsToggle /“spike lines” dotted lines interactive point extending x y axesAdjustments whether data show hovering lineGrouped data work ggplotly() well. , weekly epicurve made, grouped outcome. stacked bars interactive. Try clicking different items legend (appear/disappear).","code":"\nweekly_deaths <- linelist %>%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %>%  # create and group data by epiweek column\n  summarise(                                              # create new summary data frame:\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # number of cases per group with known outcome\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # number of cases per group who died\n    pct_death = 100*(n_death / n_known_outcome)           # percent of cases with known outcome who died\n  )\ndeaths_plot <- ggplot(data = weekly_deaths)+            # begin with weekly deaths data\n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # make line \n\ndeaths_plot   # print\ndeaths_plot %>% plotly::ggplotly()\n# Make epidemic curve with incidence2 pacakge\np <- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %>% plot(fill = outcome)\n# Plot interactively  \np %>% plotly::ggplotly()"},{"path":"interactive-plots.html","id":"modifications","chapter":"39 Interactive plots","heading":"39.3 Modifications","text":"","code":""},{"path":"interactive-plots.html","id":"file-size","chapter":"39 Interactive plots","heading":"File size","text":"exporting R Markdown generated HTML (like book!) want make plot small data size possible (negative side effects cases). , just pipe interactive plot partial_bundle(), also plotly.","code":"\np <- p %>% \n  plotly::ggplotly() %>%\n  plotly::partial_bundle()"},{"path":"interactive-plots.html","id":"buttons","chapter":"39 Interactive plots","heading":"Buttons","text":"buttons standard plotly superfluous can distracting, can remove . can simply piping output config() plotly specifying buttons remove. example specify advance names buttons remove, provide argument modeBarButtonsToRemove =. also set displaylogo = FALSE remove plotly logo.","code":"\n## these buttons are distracting and we want to remove them\nplotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np <- p %>%          # re-define interactive plot without these buttons\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"heat-tiles","chapter":"39 Interactive plots","heading":"39.4 Heat tiles","text":"can make almost ggplot() plot interactive, including heat tiles. page Heat plots can read make plot, displays proportion days per week certain facilities reported data province.code, although describe depth ., make interactive modify simple buttons file size.–>\n","code":"\n# import data\nfacility_count_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# aggregate data into Weeks for Spring district\nagg_weeks <- facility_count_data %>% \n  filter(District == \"Spring\",\n         data_date < as.Date(\"2020-08-01\")) %>% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %>% \n  group_by(location_name, week, .drop = F) %>%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %>% \n  ungroup(location_name, week) %>% \n  right_join(tidyr::expand(., week, location_name)) %>% \n  mutate(week = aweek::week2date(week))\n\n# create plot\nmetrics_plot <- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # print\nmetrics_plot %>% \n  plotly::ggplotly() %>% \n  plotly::partial_bundle() %>% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"resources-32","chapter":"39 Interactive plots","heading":"39.5 Resources","text":"Plotly just R, also works well Python (really data science language ’s built JavaScript). can read plotly website","code":""},{"path":"reports-with-r-markdown.html","id":"reports-with-r-markdown","chapter":"40 Reports with R Markdown","heading":"40 Reports with R Markdown","text":"R Markdown widely-used tool creating automated, reproducible, share-worthy outputs, reports. can generate static interactive outputs, Word, pdf, html, powerpoint, formats.R Markdown script intersperces R code text script actually becomes output document. can create entire formatted document, including narrative text (can dynamic change based data), tables, figures, bullets/numbers, bibliographies, etc.documents can produced update routine basis (e.g. daily surveillance reports) /run subsets data (e.g. reports jurisdiction).pages handbook expand topic:page Organizing routine reports demonstrates routinize report production auto-generated time-stamped folders.page Dashboards R Markdown explains format R Markdown report dashboard.note, R4Epis project developed template R Markdown scripts common outbreaks surveys scenarios encountered MSF project locations.","code":""},{"path":"reports-with-r-markdown.html","id":"preparation-33","chapter":"40 Reports with R Markdown","heading":"40.1 Preparation","text":"Background R MarkdownTo explain concepts packages involved:Markdown “language” allows write document using plain text, can converted html formats. specific R. Files written Markdown ‘.md’ extension.R Markdown: variation markdown specific R - allows write document using markdown produce text embed R code display outputs. R Markdown files ‘.Rmd’ extension.rmarkdown - package: used R render .Rmd file desired output. ’s focus converting markdown (text) syntax, also need…knitr: R package read code chunks, execute , ‘knit’ back document. tables graphs included alongside text.Pandoc: Finally, pandoc actually convert output word/pdf/powerpoint etc. software separate R installed automatically RStudio.sum, process happens background (need know steps!) involves feeding .Rmd file knitr, executes R code chunks creates new .md (markdown) file includes R code rendered output. .md file processed pandoc create finished product: Microsoft Word document, HTML file, powerpoint document, pdf, etc.(source: https://rmarkdown.rstudio.com/authoring_quick_tour.html):InstallationTo create R Markdown output, need following installed:rmarkdown package (knitr also installed automatically)Pandoc, come installed RStudio. using RStudio, can download Pandoc : http://pandoc.org.want generate PDF output (bit trickier), need install LaTeX. R Markdown users installed LaTeX , recommend install TinyTeX (https://yihui.name/tinytex/). can use following commands:","code":"\npacman::p_load(tinytex)     # install tinytex package\ntinytex::install_tinytex()  # R command to install TinyTeX software"},{"path":"reports-with-r-markdown.html","id":"getting-started","chapter":"40 Reports with R Markdown","heading":"40.2 Getting started","text":"","code":""},{"path":"reports-with-r-markdown.html","id":"install-rmarkdown-r-package","chapter":"40 Reports with R Markdown","heading":"Install rmarkdown R package","text":"Install rmarkdown R package. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rmarkdown)"},{"path":"reports-with-r-markdown.html","id":"starting-a-new-rmd-file","chapter":"40 Reports with R Markdown","heading":"Starting a new Rmd file","text":"RStudio, open new R markdown file, starting ‘File’, ‘New file’ ‘R markdown…’.R Studio give output options pick . example select “HTML” want create html document. title author names important. output document type want one , don’t worry - can just pick one change script later.open new .Rmd script.","code":""},{"path":"reports-with-r-markdown.html","id":"important-to-know","chapter":"40 Reports with R Markdown","heading":"Important to know","text":"working directoryThe working directory markdown file wherever Rmd file saved. instance, R project within ~/Documents/projectX Rmd file subfolder ~/Documents/projectX/markdownfiles/markdown.Rmd, code read.csv(“data.csv”) within markdown look csv file markdownfiles folder, root project folder scripts within projects normally automatically look.refer files elsewhere, either need use full file path use package. package sets working directory root folder R project explained detail R projects Import export pages handbook. instance, import file called “data.csv” within projectX folder, code import((“data.csv”)).Note use setwd() R Markdown scripts recommended – applies code chunk written .Working drive vs computerBecause R Markdown can run pandoc issues running shared network drive, recommended folder local machine, e.g. project within ‘Documents’. use Git (much recommended!), familiar. details, see handbook pages R network drives [Errors help].","code":""},{"path":"reports-with-r-markdown.html","id":"r-markdown-components","chapter":"40 Reports with R Markdown","heading":"40.3 R Markdown components","text":"R Markdown document can edited RStudio just like standard R script. start new R Markdown script, RStudio tries helpful showing template explains different section R Markdown script.appears starting new Rmd script intended produce html output (per previous section).can see, three basic components Rmd file: YAML, Markdown text, R code chunks.create become document output. See diagram :","code":""},{"path":"reports-with-r-markdown.html","id":"yaml-metadata","chapter":"40 Reports with R Markdown","heading":"YAML metadata","text":"Referred ‘YAML metadata’ just ‘YAML’, top R Markdown document. section script tell Rmd file type output produce, formatting preferences, metadata document title, author, date. uses mentioned (referred ‘Producing output’). Note indentation matters; tabs accepted spaces .section must begin line containing just three dashes --- must close line containing just three dashes ---. YAML parameters comes key:value pairs. placement colons YAML important - key:value pairs separated colons (equals signs!).YAML begin metadata document. order primary YAML parameters (indented) matter. example:can use R code YAML values writing -line code (preceded r within back-ticks) also within quotes (see example date:).image , clicked default output html file, can see YAML says output: html_document. However can also change say powerpoint_presentation word_document even pdf_document.","code":"title: \"My document\"\nauthor: \"Me\"\ndate: \"2023-07-18\""},{"path":"reports-with-r-markdown.html","id":"text","chapter":"40 Reports with R Markdown","heading":"Text","text":"narrative document, including titles headings. written “markdown” language, used across many different software.core ways write text. See extensive documentation available R Markdown “cheatsheet” RStudio website.","code":""},{"path":"reports-with-r-markdown.html","id":"new-lines","chapter":"40 Reports with R Markdown","heading":"New lines","text":"Uniquely R Markdown, initiate new line, enter *two spaces** end previous line Enter/Return.","code":""},{"path":"reports-with-r-markdown.html","id":"case","chapter":"40 Reports with R Markdown","heading":"Case","text":"Surround normal text character change appears output.Underscores (_text_) single asterisk (*text*) italiciseDouble asterisks (**text**) bold textBack-ticks (text) display text codeThe actual appearance font can set using specific templates (specified YAML metadata; see example tabs).","code":""},{"path":"reports-with-r-markdown.html","id":"color","chapter":"40 Reports with R Markdown","heading":"Color","text":"simple mechanism change color text R Markdown. One work-around, output HTML file, add HTML line markdown text. HTML code print line text bold red.DANGER: warning.","code":"<span style=\"color: red;\">**_DANGER:_** This is a warning.<\/span>  "},{"path":"reports-with-r-markdown.html","id":"titles-and-headings","chapter":"40 Reports with R Markdown","heading":"Titles and headings","text":"hash symbol text portion R Markdown script creates heading. different chunk R code script, hash symbol mechanism comment/annotate/de-activate, normal R script.Different heading levels established different numbers hash symbols start new line. One hash symbol title primary heading. Two hash symbols second-level heading. Third- fourth-level headings can made successively hash symbols.","code":"# First-level heading / title\n\n## Second level heading  \n\n### Third-level heading"},{"path":"reports-with-r-markdown.html","id":"bullets-and-numbering","chapter":"40 Reports with R Markdown","heading":"Bullets and numbering","text":"Use asterisks (*) created bullets list. Finish previous sentence, enter two spaces, Enter/Return twice, start bullets. Include space asterisk bullet text. bullet enter two spaces Enter/Return. Sub-bullets work way indented. Numbers work way instead asterisk, write 1), 2), etc. R Markdown script text might look.","code":"Here are my bullets (there are two spaces after this colon):  \n\n* Bullet 1 (followed by two spaces and Enter/Return)  \n* Bullet 2 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 1 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 2 (followed by two spaces and Enter/Return)  \n  "},{"path":"reports-with-r-markdown.html","id":"comment-out-text","chapter":"40 Reports with R Markdown","heading":"Comment out text","text":"can “comment ” R Markdown text just can use “#” comment line R code R chunk. Simply highlight text press Ctrl+Shift+c (Cmd+Shift+c Mac). text surrounded arrows turn green. appear output.","code":""},{"path":"reports-with-r-markdown.html","id":"code-chunks","chapter":"40 Reports with R Markdown","heading":"Code chunks","text":"Sections script dedicated running R code called “chunks”. may load packages, import data, perform actual data management visualisation. may many code chunks, can help organize R code parts, perhaps interspersed text. note:\n‘chunks’ appear slightly different background colour narrative part document.chunk opened line starts three back-ticks, curly brackets contain parameters chunk ({ }). chunk ends three back-ticks.can create new chunk typing , using keyboard shortcut “Ctrl + Alt + ” (Cmd + Shift + r Mac), clicking green ‘insert new code chunk’ icon top script editor.notes contents curly brackets { }:start ‘r’ indicate language name within chunk RAfter r can optionally write chunk “name” – necessary can help organise work. Note name chunks, ALWAYS use unique names else R complain try render.curly brackets can include options , written tag=value, :eval = FALSE run R codeecho = FALSE print chunk’s R source code output documentwarning = FALSE print warnings produced R codemessage = FALSE print messages produced R codeinclude = either TRUE/FALSE whether include chunk outputs (e.g. plots) documentout.width = .height = - provide style .width = \"75%\"fig.align = \"center\" adjust figure aligned across pagefig.show='hold' chunk prints multiple figures want printed next (pair .width = c(\"33%\", \"67%\"). Can also set fig.show='asis' show code generates , 'hide' hide, 'animate' concatenate multiple animation.chunk header must written one lineTry avoid periods, underscores, spaces. Use hyphens ( - ) instead need separator.Read extensively knitr options .options can configured point--click using setting buttons top right chunk. , can specify parts chunk want rendered document include, namely code, outputs, warnings. come written preferences within curly brackets, e.g. echo=FALSE specify want ‘Show output ’.also two arrows top right chunk, useful run code within chunk, code prior chunks. Hover see .global options applied chunks script, can set within first R code chunk script. instance, outputs shown code chunk code , can include command R code chunk:","code":"\nknitr::opts_chunk$set(echo = FALSE) "},{"path":"reports-with-r-markdown.html","id":"in-text-r-code","chapter":"40 Reports with R Markdown","heading":"In-text R code","text":"can also include minimal R code within back-ticks. Within back-ticks, begin code “r” space, RStudio knows evaluate code R code. See example .example shows multiple heading levels, bullets, uses R code current date (Sys.Date()) evaluate printed date.example simple (showing current date), using syntax can display values produced complex R code (e.g. calculate min, median, max column). can also integrate R objects values created R code chunks earlier script.example, script calculates proportion cases aged less 18 years old, using tidyverse functions, creates objects less18, total, less18prop. dynamic value inserted subsequent text. see looks knitted word document.","code":""},{"path":"reports-with-r-markdown.html","id":"images","chapter":"40 Reports with R Markdown","heading":"Images","text":"can include images R Markdown one two ways:work, try using knitr::include_graphics()(remember, file path written using package)","code":"![](\"path/to/image.png\")  \nknitr::include_graphics(\"path/to/image.png\")\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))"},{"path":"reports-with-r-markdown.html","id":"tables","chapter":"40 Reports with R Markdown","heading":"Tables","text":"Create table using hyphens ( - ) bars ( | ). number hyphens /bars allow number spaces cell text begins wrap.code produces table :","code":"Column 1 |Column  2 |Column 3\n---------|----------|--------\nCell A   |Cell B    |Cell C\nCell D   |Cell E    |Cell F"},{"path":"reports-with-r-markdown.html","id":"tabbed-sections","chapter":"40 Reports with R Markdown","heading":"Tabbed sections","text":"HTML outputs, can arrange sections “tabs”. Simply add .tabset curly brackets { } placed heading. sub-headings beneath heading (another heading level) appear tabs user can click . Read hereYou can add additional option .tabset-pills .tabset give tabs “pilled” appearance. aware viewing tabbed HTML output, Ctrl+f search functionality search “active” tabs, hidden tabs.","code":""},{"path":"reports-with-r-markdown.html","id":"file-structure","chapter":"40 Reports with R Markdown","heading":"40.4 File structure","text":"several ways structure R Markdown associated R scripts. advantages disadvantages:Self-contained R Markdown - everything needed report imported created within R Markdown\nSource files - can run external R scripts source() command use outputs Rmd\nChild scripts - alternate mechanism source()\nSource files - can run external R scripts source() command use outputs RmdChild scripts - alternate mechanism source()Utilize “runfile” - Run commands R script prior rendering R Markdown","code":""},{"path":"reports-with-r-markdown.html","id":"self-contained-rmd","chapter":"40 Reports with R Markdown","heading":"Self-contained Rmd","text":"relatively simple report, may elect organize R Markdown script “self-contained” involve external scripts.Everything need run R markdown imported created within Rmd file, including code chunks package loading. “self-contained” approach appropriate need much data processing (e.g. brings clean semi-clean data file) rendering R Markdown take long.scenario, one logical organization R Markdown script might :Set global knitr optionsLoad packagesImport dataProcess dataProduce outputs (tables, plots, etc.)Save outputs, applicable (.csv, .png, etc.)","code":""},{"path":"reports-with-r-markdown.html","id":"source-other-files","chapter":"40 Reports with R Markdown","heading":"Source other files","text":"One variation “self-contained” approach R Markdown code chunks “source” (run) R scripts. can make R Markdown script less cluttered, simple, easier organize. can also help want display final figures beginning report. approach, final R Markdown script simply combines pre-processed outputs document.One way providing R scripts (file path name extension) base R command source().Note using source() within R Markdown, external files still run course rendering Rmd file. Therefore, script run every time render report. Thus, source() commands within R Markdown speed run time, greatly assist de-bugging, error produced still printed producing R Markdown.alternative utilize child = knitr option. EXPLAIN DOYou must aware various R environments. Objects created within environment necessarily available environment used R Markdown.","code":"\nsource(\"your-script.R\", local = knitr::knit_global())\n# or sys.source(\"your-script.R\", envir = knitr::knit_global())"},{"path":"reports-with-r-markdown.html","id":"runfile","chapter":"40 Reports with R Markdown","heading":"Runfile","text":"approach involves utilizing R script contains render() command(s) pre-process objects feed R markdown.instance, can load packages, load clean data, even create graphs interest prior render(). steps can occur R script, scripts sourced. long commands occur RStudio session objects saved environment, objects can called within Rmd content. R markdown used final step - produce output pre-processed objects. much easier de-bug something goes wrong.approach helpful following reasons:informative error messages - messages generated R script, R Markdown. R Markdown errors tend tell chunk problem, tell line.applicable, can run long processing steps advance render() command - run .example , separate R script pre-process data object R Environment render “create_output.Rmd” using render().","code":"\ndata <- import(\"datafile.csv\") %>%       # Load data and save to environment\n  select(age, hospital, weight)          # Select limited columns\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Create Rmd file"},{"path":"reports-with-r-markdown.html","id":"folder-strucutre","chapter":"40 Reports with R Markdown","heading":"Folder strucutre","text":"Workflow also concerns overall folder structure, ‘output’ folder created documents figures, ‘data’ ‘inputs’ folders cleaned data. go detail , check Organizing routine reports page.","code":""},{"path":"reports-with-r-markdown.html","id":"producing-the-document","chapter":"40 Reports with R Markdown","heading":"40.5 Producing the document","text":"can produce document following ways:Manually pressing “Knit” button top RStudio script editor (fast easy)Run render() command (executed outside R Markdown script)","code":""},{"path":"reports-with-r-markdown.html","id":"option-1-knit-button","chapter":"40 Reports with R Markdown","heading":"Option 1: “Knit” button","text":"Rmd file open, press ‘Knit’ icon/button top file.R Studio show progress within ‘R Markdown’ tab near R console. document automatically open complete.document saved folder R markdown script, file name (aside extension). obviously ideal version control (-written tim knit, unless moved manually), may need rename file (e.g. add date).RStudio’s shortcut button render() function rmarkdown. approach compatible self-contained R markdown, needed components exist sourced within file.","code":""},{"path":"reports-with-r-markdown.html","id":"option-2-render-command","chapter":"40 Reports with R Markdown","heading":"Option 2: render() command","text":"Another way produce R Markdown output run render() function (rmarkdown package). must execute command outside R Markdown script - either separate R script (often called “run file”), stand-alone command R Console.“knit”, default settings save Rmd output folder Rmd script, file name (aside file extension). instance “my_report.Rmd” knitted create “my_report.docx” knitting word document. However, using render() option use different settings. render() can accept arguments including:output_format = output format convert (e.g. \"html_document\", \"pdf_document\", \"word_document\", \"\"). can also specify YAML inside R Markdown script.output_file = name output file (file path). can created via R functions like () str_glue() demonstrated .output_dir = output directory (folder) save file. allows chose alternative directory Rmd file saved .output_options = can provide list options override script YAML (e.g. )output_yaml = can provide path .yml file contains YAML specificationsparams = See section parameters belowSee complete list hereAs one example, improve version control, following command save output file within ‘outputs’ sub-folder, current date file name. create file name, function str_glue() stringr package use ‘glue’ together static strings (written plainly) dynamic R code (written curly brackets). instance April 10th 2021, file name “Report_2021-04-10.docx”. See page Characters strings details str_glue().file renders, RStudio Console show rendering progress 100%, final message indicate rendering complete.","code":"\nrmarkdown::render(input = \"my_report.Rmd\")\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) "},{"path":"reports-with-r-markdown.html","id":"options-3-reportfactory-package","chapter":"40 Reports with R Markdown","heading":"Options 3: reportfactory package","text":"R package reportfactory offers alternative method organising compiling R Markdown reports catered scenarios run reports routinely (e.g. daily, weekly…). eases compilation multiple R Markdown files organization outputs. essence, provides “factory” can run R Markdown reports, get automatically date- time-stamped folders outputs, “light” version control.Read work flow page Organizing routine reports.","code":""},{"path":"reports-with-r-markdown.html","id":"parameterised-reports","chapter":"40 Reports with R Markdown","heading":"40.6 Parameterised reports","text":"can use parameterisation make report dynamic, can run specific setting (e.g. specific date place certain knitting options). , focus basics, detail online parameterized reports.Using Ebola linelist example, let’s say want run standard surveillance report hospital day. show one can using parameters.Important: dynamic reports also possible without formal parameter structure (without params:), using simple R objects adjacent R script. explained end section.","code":""},{"path":"reports-with-r-markdown.html","id":"setting-parameters","chapter":"40 Reports with R Markdown","heading":"Setting parameters","text":"several options specifying parameter values R Markdown output.","code":""},{"path":"reports-with-r-markdown.html","id":"option-1-set-parameters-within-yaml","chapter":"40 Reports with R Markdown","heading":"Option 1: Set parameters within YAML","text":"Edit YAML include params: option, indented statements parameter want define. example create parameters date hospital, specify values. values subject change time report run. use “Knit” button produce output, parameters default values. Likewise, use render() parameters default values unless otherwise specified render() command.background, parameter values contained within read-list called params. Thus, can insert parameter values R code another R object/value environment. Simply type params$ followed parameter name. example params$hospital represent hospital name (“Central Hospital” default).Note parameters can also hold values true false, can included knitr options R chunk. example, can set {r, eval=params$run} instead {r, eval=FALSE}, now whether chunk runs depends value parameter run:.Note parameters dates, input string. params$date interpreted R code likely need wrapped .Date() similar function convert class Date.","code":"---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Central Hospital\n---"},{"path":"reports-with-r-markdown.html","id":"option-2-set-parameters-within-render","chapter":"40 Reports with R Markdown","heading":"Option 2: Set parameters within render()","text":"mentioned , alternative pressing “Knit” button produce output execute render() function separate script. later case, can specify parameters used rendering params = argument render().Note parameter values provided overwrite default values written within YAML. write values quotation marks case defined character/string values.command renders “surveillance_report.Rmd”, specifies dynamic output file name folder, provides list() two parameters values argument params =.","code":"\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))"},{"path":"reports-with-r-markdown.html","id":"option-3-set-parameters-using-a-graphical-user-interface","chapter":"40 Reports with R Markdown","heading":"Option 3: Set parameters using a Graphical User Interface","text":"interactive feel, can also use Graphical User Interface (GUI) manually select values parameters. can click drop-menu next ‘Knit’ button choose ‘Knit parameters’.pop-appear allowing type values parameters established document’s YAML.can achieve render() command specifying params = \"ask\", demonstrated .However, typing values pop-window subject error spelling mistakes. may prefer add restrictions values can entered drop-menus. can adding YAML several specifications params: entry.label: title particular drop-menuvalue: default (starting) valueinput: set select drop-menuchoices: Give eligible values drop-menuBelow, specifications written hospital parameter.knitting (either via ‘knit parameters’ button render()), pop-window drop-options select .","code":"rmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---"},{"path":"reports-with-r-markdown.html","id":"parameterized-example","chapter":"40 Reports with R Markdown","heading":"Parameterized example","text":"following code creates parameters date hospital, used R Markdown params$date params$hospital, respectively.resulting report output, see data filtered specific hospital, plot title refers correct hospital date. use “linelist_cleaned.rds” file , particularly appropriate linelist also datestamp within align parameterised date.Knitting produces final output default font layout.","code":""},{"path":"reports-with-r-markdown.html","id":"parameterisation-without-params","chapter":"40 Reports with R Markdown","heading":"Parameterisation without params","text":"rendering R Markdown file render() separate script, can actually create impact parameterization without using params: functionality.instance, R script contains render() command, can simply define hospital date two R objects (values) render() command. R Markdown, need params: section YAML, refer date object rather params$date hospital rather params$hospital.Following approach means means can “knit parameters”, use GUI, include knitting options within parameters. However allows simpler code, may advantageous.","code":"\n# This is a R script that is separate from the R Markdown\n\n# define R objects\nhospital <- \"Central Hospital\"\ndate <- \"2021-04-10\"\n\n# Render the R markdown\nrmarkdown::render(input = \"create_output.Rmd\") "},{"path":"reports-with-r-markdown.html","id":"looping-reports","chapter":"40 Reports with R Markdown","heading":"40.7 Looping reports","text":"may want run report multiple times, varying input parameters, produce report jurisdictions/unit. can done using tools iteration, explained detail page Iteration, loops, lists. Options include purrr package, use loop explained ., use simple loop generate surveillance report hospitals interest. done one command (instead manually changing hospital parameter one---time). command render reports must exist separate script outside report Rmd. script also contain defined objects “loop ” - today’s date, vector hospital names loop .feed values one---time render() command using loop, runs command value hospitals vector. letter represents index position (1 4) hospital currently used iteration, hospital_list[1] “Central Hospital”. information supplied two places render() command:file name, file name first iteration produced 10th April 2021 “Report_Central Hospital_2021-04-10.docx”, saved ‘output’ subfolder working directory.params = Rmd uses hospital name internally whenever params$hospital value called (e.g. filter dataset particular hospital ). example, four files created - one hospital.","code":"\nhospitals <- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}       "},{"path":"reports-with-r-markdown.html","id":"templates","chapter":"40 Reports with R Markdown","heading":"40.8 Templates","text":"using template document contains desired formatting, can adjust aesthetics Rmd output look. can create instance MS Word Powerpoint file contains pages/slides desired dimensions, watermarks, backgrounds, fonts.","code":""},{"path":"reports-with-r-markdown.html","id":"word-documents","chapter":"40 Reports with R Markdown","heading":"Word documents","text":"create template, start new word document (use existing output formatting suits ), edit fonts defining Styles. Style,Headings 1, 2, 3 refer various markdown header levels (# Header 1, ## Header 2 ### Header 3 respectively). Right click style click ‘modify’ change font formatting well paragraph (e.g. can introduce page breaks certain styles can help spacing). aspects word document margins, page size, headers etc, can changed like usual word document working directly within.","code":""},{"path":"reports-with-r-markdown.html","id":"powerpoint-documents","chapter":"40 Reports with R Markdown","heading":"Powerpoint documents","text":", create new slideset use existing powerpoint file desired formatting. editing, click ‘View’ ‘Slide Master’. can change ‘master’ slide appearance editing text formatting text boxes, well background/page dimensions overall page.Unfortunately, editing powerpoint files slightly less flexible:first level header (# Header 1) automatically become title new slide,## Header 2 text come subtitle text within slide’s main textbox (unless find way maniuplate Master view).Outputted plots tables automatically go new slides. need combine , instance patchwork function combine ggplots, show page. See blog post using patchwork package put multiple images one slide.See officer package tool work -depth powerpoint presentations.","code":""},{"path":"reports-with-r-markdown.html","id":"integrating-templates-into-the-yaml","chapter":"40 Reports with R Markdown","heading":"Integrating templates into the YAML","text":"template prepared, detail can added YAML Rmd underneath ‘output’ line underneath document type specified (goes separate line ). Note reference_doc can used powerpoint slide templates.easiest save template folder Rmd file (example ), subfolder within.","code":"---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---"},{"path":"reports-with-r-markdown.html","id":"formatting-html-files","chapter":"40 Reports with R Markdown","heading":"Formatting HTML files","text":"HTML files use templates, can styles configured within YAML. HTMLs interactive documents, particularly flexible. cover basic options .Table contents: can add table contents toc: true , also specify remains viewable (“floats”) scroll, toc_float: true.Table contents: can add table contents toc: true , also specify remains viewable (“floats”) scroll, toc_float: true.Themes: can refer pre-made themes, come Bootswatch theme library. example use cerulean. options include: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, yeti.Themes: can refer pre-made themes, come Bootswatch theme library. example use cerulean. options include: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, yeti.Highlight: Configuring changes look highlighted text (e.g. code within chunks shown). Supported styles include default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, textmate.Highlight: Configuring changes look highlighted text (e.g. code within chunks shown). Supported styles include default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, textmate.example integrate options YAML.two examples HTML outputs floating tables contents, different theme highlight styles selected:","code":"---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---"},{"path":"reports-with-r-markdown.html","id":"dynamic-content","chapter":"40 Reports with R Markdown","heading":"40.9 Dynamic content","text":"HTML output, report content can dynamic. examples:","code":""},{"path":"reports-with-r-markdown.html","id":"tables-1","chapter":"40 Reports with R Markdown","heading":"Tables","text":"HTML report, can print data frame / tibbles content dynamic, filters scroll bars. several packages offer capability.DT package, used throughout handbook, can insert code chunk like :function datatable() print provided data frame dynamic table reader. can set rownames = FALSE simplify far left-side table. filter = \"top\" provides filter column. option() argument provide list specifications. include two: pageLength = 5 set number rows appear 5 (remaining rows can viewed paging arrows), scrollX=TRUE enables scrollbar bottom table (columns extend far right).dataset large, consider showing top X rows wrapping data frame head().","code":""},{"path":"reports-with-r-markdown.html","id":"html-widgets","chapter":"40 Reports with R Markdown","heading":"HTML widgets","text":"HTML widgets R special class R packages enable increased interactivity utilizing JavaScript libraries. can embed HTML R Markdown outputs.common examples widgets include:Plotly (used handbook page [Interative plots] page)visNetwork (used Transmission Chains page handbook)Leaflet (used GIS Basics page handbook)dygraphs (useful interactively showing time series data)DT (datatable()) (used show dynamic tables filter, sort, etc.)ggplotly() function plotly particularly easy use. See Interactive plots page.","code":""},{"path":"reports-with-r-markdown.html","id":"resources-33","chapter":"40 Reports with R Markdown","heading":"40.10 Resources","text":"information can found via:https://bookdown.org/yihui/rmarkdown/https://rmarkdown.rstudio.com/articles_intro.htmlA good explainer markdown vs knitr vs Rmarkdown : https://stackoverflow.com/questions/40563479/relationship--r-markdown-knitr-pandoc--bookdown","code":""},{"path":"organizing-routine-reports.html","id":"organizing-routine-reports","chapter":"41 Organizing routine reports","heading":"41 Organizing routine reports","text":"page covers reportfactory package, accompaniment using R Markdown reports.scenarios run reports routinely (daily, weekly, etc.), eases compilation multiple R Markdown files organization outputs. essence, provides “factory” can run R Markdown reports, get automatically date- time-stamped folders outputs, “light” version control.reportfactory one packages developed RECON (R Epidemics Consortium). website Github.","code":""},{"path":"organizing-routine-reports.html","id":"preparation-34","chapter":"41 Organizing routine reports","heading":"41.1 Preparation","text":"","code":""},{"path":"organizing-routine-reports.html","id":"load-packages-30","chapter":"41 Organizing routine reports","heading":"Load packages","text":"within RStudio, install latest version reportfactory package Github.can via pacman package p_load_current_gh() force intall latest version Github. Provide character string “reconverse/reportfactory”, specifies Github organization (reconverse) repository (reportfactory). can also use install_github() remotes package, alternative.","code":"\n# Install and load the latest version of the package from Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternative"},{"path":"organizing-routine-reports.html","id":"new-factory","chapter":"41 Organizing routine reports","heading":"41.2 New factory","text":"create new factory, run function new_factory(). create new self-contained R project folder. default:factory added working directoryThe name factory R project called “new_factory.Rproj”RStudio session “move ” R projectLooking inside factory, can see sub-folders files created automatically.report_sources folder hold R Markdown scripts, generate reportsThe outputs folder hold report outputs (e.g. HTML, Word, PDF, etc.)scripts folder can used store R scripts (e.g. sourced Rmd scripts)data folder can used hold data (“raw” “clean” subfolders included).file, can use package call files sub-folders relation root folder (see R projects page details)gitignore file created case link R project Github repository (see [Version control collaboration Github])empty README file, use Github repositoryCAUTION: depending computer’s setting, files “.” may exist invisible.default settings, several might want adjust within new_factory() command:factory = - Provide name factory folder (default “new_factory”)path = - Designate file path new factory (default working directory)report_sources = Provide alternate name subfolder holds R Markdown scripts (default “report_sources”)outputs = Provide alternate name folder holds report outputs (default “outputs”)See ?new_factory complete list arguments.create new factory, R session transferred new R project, load reportfactory package.Now can run factory_overview() command see internal structure (folders files) factory.following “tree” factory’s folders files printed R console. Note “data” folder sub-folders “raw” “clean” data, example CSV data. also “example_report.Rmd” “report_sources” folder.","code":"\n# This will create the factory in the working directory\nnew_factory()\npacman::p_load(reportfactory)\nfactory_overview()            # print overview of the factory to console"},{"path":"organizing-routine-reports.html","id":"create-a-report","chapter":"41 Organizing routine reports","heading":"41.3 Create a report","text":"within factory R project, create R Markdown report just normally, save “report_sources” folder. See R Markdown page instructions. purposes example, added following factory:new R markdown script entitled “daily_sitrep.Rmd”, saved within “report_sources” folderData report (“linelist_cleaned.rds”), saved “clean” sub-folder within “data” folderWe can see using factory_overview() R Markdown “report_sources” folder data file “clean” data folder (highlighted):screenshot beginning R Markdown “daily_sitrep.Rmd”. can see output format set HTML, via YAML header output: html_document.simple script, commands :Load necessary packagesImport linelist data using filepath package (read page Import export)Print summary table cases, export export() .csv filePrint epicurve, export ggsave() .png fileYou can review just list R Markdown reports “report_sources” folder command:","code":"\nlinelist <- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\nlist_reports()"},{"path":"organizing-routine-reports.html","id":"compile","chapter":"41 Organizing routine reports","heading":"41.4 Compile","text":"report factory, “compile” R Markdown report means .Rmd script run output produced (specified script YAML e.g. HTML, Word, PDF, etc).factory automatically create date- time-stamped folder outputs “outputs” folder.report exported files produced script (e.g. csv, png, xlsx) saved folder. addition, Rmd script saved folder, record version script.contrasts normal behavior “knitted” R Markdown, saves outputs location Rmd script. default behavior can result crowded, messy folders. factory aims improve organization one needs run reports frequently.","code":""},{"path":"organizing-routine-reports.html","id":"compile-by-name","chapter":"41 Organizing routine reports","heading":"Compile by name","text":"can compile specific report running compile_reports() providing Rmd script name (without .Rmd extension) reports =. simplicity, can skip reports = just write R Markdown name quotes, .command compile “daily_sitrep.Rmd” report, saving HTML report, .csv table .png epicurve exports date- time-stamped sub-folder specific report, within “outputs” folder.Note choose provide .Rmd extension, must correctly type extension saved file name (.rmd vs. .Rmd).Also note compile, may see several files temporarily appear “report_sources” folder - soon disappear transferred correct “outputs” folder.","code":""},{"path":"organizing-routine-reports.html","id":"compile-by-number","chapter":"41 Organizing routine reports","heading":"Compile by number","text":"can also specify Rmd script compile providing number vector numbers reports =. numbers must align order reports appear run list_reports().","code":"\n# Compile the second and fourth Rmds in the \"report_sources\" folder\ncompile_reports(reports = c(2, 4))"},{"path":"organizing-routine-reports.html","id":"compile-all","chapter":"41 Organizing routine reports","heading":"Compile all","text":"can compile R Markdown reports “report_sources” folder setting reports = argument TRUE.","code":""},{"path":"organizing-routine-reports.html","id":"compile-from-sub-folder","chapter":"41 Organizing routine reports","heading":"Compile from sub-folder","text":"can add sub-folders “report_sources” folder. run R Markdown report subfolder, simply provide name folder subfolder =. example code compile Rmd report lives sub_folder “report_sources”.can compile Rmd reports within subfolder providing subfolder name reports =, slash end, .","code":"\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\ncompile_reports(reports = \"for_partners/\")"},{"path":"organizing-routine-reports.html","id":"parameterization","chapter":"41 Organizing routine reports","heading":"Parameterization","text":"noted page Reports R Markdown, can run reports specified parameters. can pass parameters list compile_reports() via params = argument. example, fictional report three parameters provided R Markdown reports.","code":"\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)"},{"path":"organizing-routine-reports.html","id":"using-a-run-file","chapter":"41 Organizing routine reports","heading":"Using a “run-file”","text":"multiple reports run, consider creating R script contains compile_reports() commands. user can simply run commands R script reports compile. can save “run-file” “scripts” folder.","code":""},{"path":"organizing-routine-reports.html","id":"outputs-1","chapter":"41 Organizing routine reports","heading":"41.5 Outputs","text":"compiled reports times, “outputs” folder might look like (highlights added clarity):Within “outputs”, sub-folders created Rmd reportWithin , sub-folders created unique compiling\ndate- time-stamped (“2021-04-23_T11-07-36” means 23rd April 2021 11:07:36)\ncan edit date/time-stamp format. See ?compile_reports\ndate- time-stamped (“2021-04-23_T11-07-36” means 23rd April 2021 11:07:36)can edit date/time-stamp format. See ?compile_reportsWithin date/time compiled folder, report output stored (e.g. HTML, PDF, Word) along Rmd script (version control!) exported files (e.g. table.csv, epidemic_curve.png)view inside one date/time-stamped folders, “daily_sitrep” report. file path highlighted yellow emphasis.Finally, screenshot HTML report output.can use list_outputs() review list outputs.","code":""},{"path":"organizing-routine-reports.html","id":"miscellaneous-1","chapter":"41 Organizing routine reports","heading":"41.6 Miscellaneous","text":"","code":""},{"path":"organizing-routine-reports.html","id":"knit","chapter":"41 Organizing routine reports","heading":"Knit","text":"can still “knit” one R Markdown reports pressing “Knit” button, want. , default, outputs appear folder Rmd saved - “report_sources” folder. prior versions reportfactory, non-Rmd files “report_sources” prevent compiling, longer case. can run compile_reports() error occur.","code":""},{"path":"organizing-routine-reports.html","id":"scripts-2","chapter":"41 Organizing routine reports","heading":"Scripts","text":"encourage utilize “scripts” folder store “runfiles” .R scripts sourced .Rmd scripts. See page R Markdown tips structure code across several files.","code":""},{"path":"organizing-routine-reports.html","id":"extras","chapter":"41 Organizing routine reports","heading":"Extras","text":"reportfactory, can use function list_deps() list packages required across reports entire factory.reportfactory, can use function list_deps() list packages required across reports entire factory.accompanying package development called rfextras offers helper functions assist building reports, :\nload_scripts() - sources/loads .R scripts given folder (“scripts” folder default)\nfind_latest() - finds latest version file (e.g. latest dataset)\naccompanying package development called rfextras offers helper functions assist building reports, :load_scripts() - sources/loads .R scripts given folder (“scripts” folder default)find_latest() - finds latest version file (e.g. latest dataset)","code":""},{"path":"organizing-routine-reports.html","id":"resources-34","chapter":"41 Organizing routine reports","heading":"41.7 Resources","text":"See reportfactory package’s Github pageSee rfextras package’s Github page","code":""},{"path":"dashboards-with-r-markdown.html","id":"dashboards-with-r-markdown","chapter":"42 Dashboards with R Markdown","heading":"42 Dashboards with R Markdown","text":"page cover basic use flexdashboard package. package allows easily format R Markdown output dashboard panels pages. dashboard content can text, static figures/tables interactive graphics.Advantages flexdashboard:requires minimal non-standard R coding - little practice can quickly create dashboardThe dashboard can usually emailed colleagues self-contained HTML file - server requiredYou can combine flexdashboard shiny, ggplotly, “html widgets” add interactivityDisadvantages flexdashboard:Less customization compared using shiny alone create dashboardVery comprehensive tutorials using flexdashboard informed page can found Resources section. describe core features give example building dashboard explore outbreak, using case linelist data.","code":""},{"path":"dashboards-with-r-markdown.html","id":"preparation-35","chapter":"42 Dashboards with R Markdown","heading":"42.1 Preparation","text":"","code":""},{"path":"dashboards-with-r-markdown.html","id":"load-packages-31","chapter":"42 Dashboards with R Markdown","heading":"Load packages","text":"handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,             # data import/export     \n  here,            # locate files\n  tidyverse,       # data management and visualization\n  flexdashboard,   # dashboard versions of R Markdown reports\n  shiny,           # interactive figures\n  plotly           # interactive figures\n)"},{"path":"dashboards-with-r-markdown.html","id":"import-data-26","chapter":"42 Dashboards with R Markdown","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see Import export page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"dashboards-with-r-markdown.html","id":"create-new-r-markdown","chapter":"42 Dashboards with R Markdown","heading":"42.2 Create new R Markdown","text":"installed package, create new R Markdown file clicking File > New file > R Markdown.window opens, select “Template” select “Flex Dashboard” template. prompted name document. page’s example, name R Markdown “outbreak_dashboard.Rmd”.","code":""},{"path":"dashboards-with-r-markdown.html","id":"the-script","chapter":"42 Dashboards with R Markdown","heading":"42.3 The script","text":"script R Markdown script, components organization described page Reports R Markdown. briefly re-visit highlight differences R Markdown output formats.","code":""},{"path":"dashboards-with-r-markdown.html","id":"yaml","chapter":"42 Dashboards with R Markdown","heading":"YAML","text":"top script “YAML” header. must begin three dashes --- must close three dashes ---. YAML parameters comes key:value pairs. indentation placement colons YAML important - key:value pairs separated colons (equals signs!).YAML begin metadata document. order primary YAML parameters (indented) matter. example:can use R code YAML values putting like -line code (preceeded r within backticks) also within quotes (see Date).required YAML parameter output:, specifies type file produced (e.g. html_document, pdf_document, word_document, powerpoint_presentation). flexdashboard parameter value bit confusing - must set output:flexdashboard::flex_dashboard. Note single double colons, underscore. YAML output parameter often followed additional colon indented sub-parameters (see orientation: vertical_layout: parameters ).shown , indentations (2 spaces) used sub-parameters. case, forget put additional colon primary, like key:value:.appropriate, logical values given YAML lowercase (true, false, null). colon part value (e.g. title) put value quotes. See examples sections .","code":"\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\ntitle: \"My dashboard\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll"},{"path":"dashboards-with-r-markdown.html","id":"code-chunks-1","chapter":"42 Dashboards with R Markdown","heading":"Code chunks","text":"R Markdown script can contain multiple code “chunks” - areas script can write multiple-line R code function just like mini R scripts.Code chunks created three back-ticks curly brackets lowercase “r” within. chunk closed three backticks. can create new chunk typing , using keyboard shortcut “Ctrl + Alt + ” (Cmd + Shift + r Mac), clicking green ‘insert new code chunk’ icon top script editor. Many examples given .","code":""},{"path":"dashboards-with-r-markdown.html","id":"narrative-text","chapter":"42 Dashboards with R Markdown","heading":"Narrative text","text":"Outside R code “chunk”, can write narrative text. described page Reports R Markdown, can italicize text surrounding one asterisk (*), bold surrounding two asterisks (**). Recall bullets numbering schemes sensitive newlines, indentation, finishing line two spaces.can also insert -line R code text described Reports R Markdown page, surrounding code backticks starting command “r”: ` 1+1`(see example date ).","code":""},{"path":"dashboards-with-r-markdown.html","id":"headings","chapter":"42 Dashboards with R Markdown","heading":"Headings","text":"Different heading levels established different numbers hash symbols, described Reports R Markdown page.flexdashboard, primary heading (#) creates “page” dashboard. Second-level headings (##) create column row depending orientation: parameter (see details ). Third-level headings (###) create panels plots, charts, tables, text, etc.","code":"# First-level heading (page)\n\n## Second level heading (row or column)  \n\n### Third-level heading (pane for plot, chart, etc.)"},{"path":"dashboards-with-r-markdown.html","id":"section-attributes","chapter":"42 Dashboards with R Markdown","heading":"42.4 Section attributes","text":"normal R markdown, can specify attributes apply parts dashboard including key=value options heading, within curly brackets { }. example, typical HTML R Markdown report might organize sub-headings tabs ## heading {.tabset}.Note attributes written heading text portion script. different knitr options inserted within top R code chunks, .height =.Section attributes specific flexdashboard include:{data-orientation=} Set either rows columns. dashboard multiple pages, add attribute page indicate orientation (explained layout section).{data-width=} {data-height=} set relative size charts, columns, rows laid dimension (horizontal vertical). Absolute sizes adjusted best fill space display device thanks flexbox engine.\nHeight charts also depends whether set YAML parameter vertical_layout: fill vertical_layout: scroll. set scroll, figure height reflect traditional fig.height = option R code chunk.\nSee complete size documentation flexdashboard website\nHeight charts also depends whether set YAML parameter vertical_layout: fill vertical_layout: scroll. set scroll, figure height reflect traditional fig.height = option R code chunk.See complete size documentation flexdashboard website{.hidden} Use exclude specific page navigation bar{data-navbar=} Use page-level heading nest within navigation bar drop-menu. Provide name (quotes) drop-menu. See example .","code":""},{"path":"dashboards-with-r-markdown.html","id":"layout","chapter":"42 Dashboards with R Markdown","heading":"42.5 Layout","text":"Adjust layout dashboard following ways:Add pages, columns/rows, charts R Markdown headings (e.g. #, ##, ###)Adjust YAML parameter orientation: either rows columnsSpecify whether layout fills browser allows scrollingAdd tabs particular section heading","code":""},{"path":"dashboards-with-r-markdown.html","id":"pages","chapter":"42 Dashboards with R Markdown","heading":"Pages","text":"First-level headings (#) R Markdown represent “pages” dashboard. default, pages appear navigation bar along top dashboard.can group pages “menu” within top navigation bar adding attribute {data-navmenu=} page heading. careful - include spaces around equals sign otherwise work!script produces:can also convert page column “sidebar” left side dashboard adding {.sidebar} attribute. can hold text (viewable page), integrated shiny interactivity can useful hold user-input controls sliders drop-menus.script produces:","code":""},{"path":"dashboards-with-r-markdown.html","id":"orientation","chapter":"42 Dashboards with R Markdown","heading":"Orientation","text":"Set orientation: yaml parameter indicate second-level (##) R Markdown headings interpreted - either orientation: columns orientation: rows.Second-level headings (##) interpreted new columns rows based orientation setting.set orientation: columns, second-level headers create new columns dashboard. dashboard one page, containing two columns, total three panels. can adjust relative width columns {data-width=} shown .script produces:set orientation: rows, second-level headers create new rows instead columns. script , orientation: rows second-level headings produce rows instead columns. can adjust relative height rows {data-height=} shown .script produces:dashboard multiple pages, can designate orientation specific page adding {data-orientation=} attribute header page (specify either rows columns without quotes).","code":""},{"path":"dashboards-with-r-markdown.html","id":"tabs","chapter":"42 Dashboards with R Markdown","heading":"Tabs","text":"can divide content tabs {.tabset} attribute, HTML R Markdown outputs.Simply add attribute desired heading. Sub-headings heading displayed tabs. example, example script column 2 right (##) modified epidemic curve table panes (###) displayed tabs.can rows orientation rows.script produces:","code":""},{"path":"dashboards-with-r-markdown.html","id":"adding-content","chapter":"42 Dashboards with R Markdown","heading":"42.6 Adding content","text":"Let’s begin build dashboard. simple dashboard 1 page, 2 columns, 4 panels. build panels piece--piece demonstration.can easily include standard R outputs text, ggplots, tables (see Tables presentation page). Simply code within R code chunk R Markdown script.Note: can download finished Rmd script HTML dashboard output - see Download handbook data page.","code":""},{"path":"dashboards-with-r-markdown.html","id":"text-1","chapter":"42 Dashboards with R Markdown","heading":"Text","text":"can type Markdown text include -line code R Markdown output. See Reports R Markdown page details.dashboard include summary text panel includes dynamic text showing latest hospitalisation date number cases reported outbreak.","code":""},{"path":"dashboards-with-r-markdown.html","id":"tables-2","chapter":"42 Dashboards with R Markdown","heading":"Tables","text":"can include R code chunks print outputs tables. output look best respond window size use kable() function knitr display tables. flextable functions may produce tables shortened / cut-.example, feed linelist() count() command produce summary table cases hospital. Ultimately, table piped knitr::kable() result scroll bar right. can read customizing table kable() kableExtra .script produces:want show dynamic table allows user filter, sort, /click “pages” data frame, use package DT ’s function datatable(), code .example code , data frame linelist printed. can set rownames = FALSE conserve horizontal space, filter = \"top\" filters top every column. list specifications can provided options =. , set pageLength = 5 rows appear scrollX = user can use scroll bar bottom scroll horizontally. argument class = 'white-space: nowrap' ensures row one line (multiple lines). can read possible arguments values entering ?datatable","code":"\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = list(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )"},{"path":"dashboards-with-r-markdown.html","id":"plots","chapter":"42 Dashboards with R Markdown","heading":"Plots","text":"can print plots dashboard pane R script. example, use incidence2 package create “epicurve” age group two simple commands (see Epidemic curves page). However, use ggplot() print plot manner.script produces:","code":""},{"path":"dashboards-with-r-markdown.html","id":"interactive-plots-1","chapter":"42 Dashboards with R Markdown","heading":"Interactive plots","text":"can also pass standard ggplot plot object ggplotly() plotly package (see Interactive plots page). make plot interactive, allow reader “zoom ”, show--hover value every data point (scenario number cases per week age group curve).looks like dashboard (gif). interactive functionality still work even email dashboard static file (online server).","code":"\nage_outbreak <- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %>% \n  plotly::ggplotly()"},{"path":"dashboards-with-r-markdown.html","id":"html-widgets-1","chapter":"42 Dashboards with R Markdown","heading":"HTML widgets","text":"HTML widgets R special class R packages increases interactivity utilizing JavaScript libraries. can embed R Markdown outputs (flexdashboard) Shiny dashboards.common examples widgets include:Plotly (used handbook page [Interative plots] page)visNetwork (used Transmission Chains page handbook)Leaflet (used GIS Basics page handbook)dygraphs (useful interactively showing time series data)DT (datatable()) (used show dynamic tables filter, sort, etc.)demonstrate adding epidemic transmission chain uses visNetwork dashboard. script shows new code added “Column 2” section R Markdown script. can find code Transmission chains page handbook.script produces:","code":""},{"path":"dashboards-with-r-markdown.html","id":"code-organization","chapter":"42 Dashboards with R Markdown","heading":"42.7 Code organization","text":"may elect code within R Markdown flexdashboard script. Alternatively, clean concise dashboard script may choose call upon code/figures hosted created external R scripts. described greater detail Reports R Markdown page.","code":""},{"path":"dashboards-with-r-markdown.html","id":"shiny-1","chapter":"42 Dashboards with R Markdown","heading":"42.8 Shiny","text":"Integrating R package shiny can make dashboards even reactive user input. example, user select jurisdiction, date range, panels react choice (e.g. filter data displayed). embed shiny reactivity flexdashboard, need make changes flexdashboard R Markdown script.can use shiny produce apps/dashboards without flexdashboard . handbook page Dashboards Shiny gives overview approach, including primers shiny syntax, app file structure, options sharing/publishing (including free server options). syntax general tips translate flexdashboard context well.Embedding shiny flexdashboard however, fundamental change flexdashboard. longer produce HTML output can send email anyone open view. Instead, “app”. “Knit” button top script replaced “Run document” icon, open instance interactive dashboard locally computer.Sharing dashboard now require either:Send Rmd script viewer, open R computer, run app, orThe app/dashboard hosted server accessible viewerThus, benefits integrating shiny, also complications. easy sharing email priority don’t need shiny reactive capabilities, consider reduced interactivity offered ggplotly() demonstrated .give simple example using “outbreak_dashboard.Rmd” . Extensive documentation integrating Shiny flexdashboard available online .","code":""},{"path":"dashboards-with-r-markdown.html","id":"settings-1","chapter":"42 Dashboards with R Markdown","heading":"Settings","text":"Enable shiny flexdashboard adding YAML parameter runtime: shiny indentation level output:, :also convenient enable “side bar” hold shiny input widgets collect information user. explained , create column indicate {.sidebar} option create side bar left side. can add text R chunks containing shiny input commands within column.app/dashboard hosted server may multiple simultaneous users, name first R code chunk global. Include commands import/load data chunk. special named chunk treated differently, data imported within imported (continuously) available users. improves start-speed app.","code":"---\ntitle: \"Outbreak dashboard (Shiny demo)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---"},{"path":"dashboards-with-r-markdown.html","id":"worked-example","chapter":"42 Dashboards with R Markdown","heading":"Worked example","text":"adapt flexdashboard script “outbreak_dashboard.Rmd” include shiny. add capability user select hospital drop-menu, epidemic curve reflect cases hospital, dynamic plot title. following:Add runtime: shiny YAMLRe-name setup chunk globalCreate sidebar containing:\nCode create vector unique hospital names\nselectInput() command (shiny drop-menu) choice hospital names. selection saved hospital_choice, can referenced later code input$hospital_choice\nCode create vector unique hospital namesA selectInput() command (shiny drop-menu) choice hospital names. selection saved hospital_choice, can referenced later code input$hospital_choiceThe epidemic curve code (column 2) wrapped within renderPlot({ }), including:\nfilter dataset restricting column hospital current value input$hospital_choice\ndynamic plot title incorporates input$hospital_choice\nfilter dataset restricting column hospital current value input$hospital_choiceA dynamic plot title incorporates input$hospital_choiceNote code referencing input$ value must within render({}) function (reactive).top script, including YAML, global chunk, sidebar:Column 2, reactive epicurve plot:dashboard:","code":""},{"path":"dashboards-with-r-markdown.html","id":"other-examples","chapter":"42 Dashboards with R Markdown","heading":"Other examples","text":"read health-related example Shiny-flexdashboard using shiny interactivity leaflet mapping widget, see chapter online book Geospatial Health Data: Modeling Visualization R-INLA Shiny.","code":""},{"path":"dashboards-with-r-markdown.html","id":"sharing","chapter":"42 Dashboards with R Markdown","heading":"42.9 Sharing","text":"Dashboards contain Shiny elements output HTML file (.html), can emailed (size permits). useful, can send “dashboard” report set server host website.embedded shiny, able send output email, can send script R user, host dashboard server explained .","code":""},{"path":"dashboards-with-r-markdown.html","id":"resources-35","chapter":"42 Dashboards with R Markdown","heading":"42.10 Resources","text":"Excellent tutorials informed page can found . review , likely within hour can dashboard.https://bookdown.org/yihui/rmarkdown/dashboards.htmlhttps://rmarkdown.rstudio.com/flexdashboard/https://rmarkdown.rstudio.com/flexdashboard/using.htmlhttps://rmarkdown.rstudio.com/flexdashboard/examples.html","code":""},{"path":"dashboards-with-shiny.html","id":"dashboards-with-shiny","chapter":"43 Dashboards with Shiny","heading":"43 Dashboards with Shiny","text":"Dashboards often great way share results analyses others. Producing dashboard shiny requires relatively advanced knowledge R language, offers incredible customization possibilities.recommended someone learning dashboards shiny good knowledge data transformation visualisation, comfortable debugging code, writing functions. Working dashboards intuitive ’re starting, difficult understand times, great skill learn gets much easier practice!page give short overview make dashboards shiny extensions.\nalternative method making dashboards faster, easier, perhaps less customizeable, see page flextable (Dashboards R Markdown).","code":""},{"path":"dashboards-with-shiny.html","id":"preparation-36","chapter":"43 Dashboards with Shiny","heading":"43.1 Preparation","text":"","code":""},{"path":"dashboards-with-shiny.html","id":"load-packages-32","chapter":"43 Dashboards with Shiny","heading":"Load packages","text":"handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.begin installing shiny R package:","code":"\npacman::p_load(shiny)"},{"path":"dashboards-with-shiny.html","id":"import-data-27","chapter":"43 Dashboards with Shiny","heading":"Import data","text":"like follow-along page, see section Download handbook data. links download R scripts data files produce final Shiny app.try re-construct app using files, please aware R project folder structure created course demonstration (e.g. folders “data” “funcs”).","code":""},{"path":"dashboards-with-shiny.html","id":"the-structure-of-a-shiny-app","chapter":"43 Dashboards with Shiny","heading":"43.2 The structure of a shiny app","text":"","code":""},{"path":"dashboards-with-shiny.html","id":"basic-file-structures","chapter":"43 Dashboards with Shiny","heading":"Basic file structures","text":"understand shiny, first need understand file structure app works! make brand new directory start. can actually made easier choosing New project Rstudio, choosing Shiny Web Application. create basic structure shiny app .opening project, ’ll notice .R file already present called app.R. essential one two basic file structures:One file called app.R, orTwo files, one called ui.R server.RIn page, use first approach one file called app.R. example script:open file, ’ll notice two objects defined - one called ui another called server. objects must defined every shiny app central structure app ! fact, difference two file structures described structure 1, ui server defined one file, whereas structure 2 defined separate files. Note: can also (larger app) .R files structure can source() app.","code":"\n# an example of app.R\n\nlibrary(shiny)\n\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"My app\"),\n\n    # Sidebar with a slider input widget\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # Show a plot \n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver <- function(input, output) {\n     \n     plot_1 <- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot <- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Run the application \nshinyApp(ui = ui, server = server)"},{"path":"dashboards-with-shiny.html","id":"the-server-and-the-ui","chapter":"43 Dashboards with Shiny","heading":"The server and the ui","text":"next need understand server ui objects actually . Put simply, two objects interacting whenever user interacts shiny app.UI element shiny app , basic level, R code creates HTML interface. means everything displayed UI app. generally includes:“Widgets” - dropdown menus, check boxes, sliders, etc can interacted userPlots, tables, etc - outputs generated R codeNavigation aspects app - tabs, panes, etc.Generic text, hyperlinks, etcHTML CSS elements (addressed later)important thing understand UI receives inputs user displays outputs server. active code running ui time - changes seen UI passed server (less). make plots, downloads, etc serverThe server shiny app code run app starts . way works little confusing. server function effectively react user interfacing UI, run chunks code response. things change server, passed back ui, changes can seen. Importantly, code server executed non-consecutively (’s best think way). Basically, whenever ui input affects chunk code server, run automatically, output produced displayed.probably sounds abstract now, ’ll dive examples get clear idea actually works.","code":""},{"path":"dashboards-with-shiny.html","id":"before-you-start-to-build-an-app","chapter":"43 Dashboards with Shiny","heading":"Before you start to build an app","text":"begin build app, immensely helpful know want build. Since UI written code, can’t really visualise ’re building unless aiming something specific. reason, immensely helpful look lots examples shiny apps get idea can make - even better can look source code behind apps! great resources :Rstudio app galleryOnce get idea possible, ’s also helpful map want look like - can paper drawing software (PowerPoint, MS paint, etc.). ’s helpful start simple first app! ’s also shame using code find online nice app template work - much easier building something scratch!","code":""},{"path":"dashboards-with-shiny.html","id":"building-a-ui","chapter":"43 Dashboards with Shiny","heading":"43.3 Building a UI","text":"building app, easier work UI first can see ’re making, risk app failing server errors. mentioned previously, often good use template working UI. number standard layouts can used shiny available base shiny package, ’s worth noting also number package extensions shinydashboard. ’ll use example base shiny start .shiny UI generally defined series nested functions, following orderA function defining general layout (basic fluidPage(), available)Panels within layout :\nsidebar (sidebarPanel())\n“main” panel (mainPanel())\ntab (tabPanel())\ngeneric “column” (column())\nsidebar (sidebarPanel())“main” panel (mainPanel())tab (tabPanel())generic “column” (column())Widgets outputs - can confer inputs server (widgets) outputs server (outputs)\nWidgets generally styled xxxInput() e.g. selectInput()\nOutputs generally styled xxxOutput() e.g. plotOutput()\nWidgets generally styled xxxInput() e.g. selectInput()Outputs generally styled xxxOutput() e.g. plotOutput()’s worth stating can’t visualised easily abstract way, ’s best look example! Lets consider making basic app visualises malaria facility count data district. data lot differnet parameters, great end user apply filters see data age group/district see fit! can use simple shiny layout start - sidebar layout. layout widgets placed sidebar left, plot placed right.Lets plan app - can start selector lets us choose district want visualise data, another let us visualise age group interested . ’ll aim use filters show epicurve reflects parameters. need:Two dropdown menus let us choose district want, age group ’re interested .area can show resulting epicurve.might look something like :app.R run UI code (active code server portion app.R) layout appears looking like - note plot server render , inputs working!good opportunity discuss widgets work - note widget accepting inputId, label, series options specific widget type. inputId extremely important - IDs used pass information UI server. reason, must unique. make effort name something sensible, specific interacting cases larger apps.read documentation carefully full details widgets . Widgets pass specific types data server depending widget type, needs fully understood. example, selectInput() pass character type server:select Spring first widget , pass character object \"Spring\" server.select two items dropdown menu, come character vector (e.g. c(\"Spring\", \"Bolo\")).widgets pass different types object server! example:numericInput() pass numeric type object servercheckboxInput() pass logical type object server (TRUE FALSE)’s also worth noting named vector used age data . many widgets, using named vector choices display names vector display choices, pass selected value vector server. .e. someone can select “15+” drop-menu, UI pass \"malaria_rdt_15\" server - happens name column ’re interested !loads widgets can use lots things app. Widgets also allow upload files app, download outputs. also excellent shiny extensions give access widgets base shiny - shinyWidgets package great example . look examples can look following links:base shiny widget galleryshinyWidgets gallery","code":"\nlibrary(shiny)\n\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)"},{"path":"dashboards-with-shiny.html","id":"loading-data-into-our-app","chapter":"43 Dashboards with Shiny","heading":"43.4 Loading data into our app","text":"next step app development getting server running. however, need get data app, figure calculations ’re going . shiny app straightforward debug, ’s often clear errors coming , ’s ideal get data processing visualisation code working start making server .given want make app shows epi curves change based user input, think code need run normal R script. ’ll need :Load packagesLoad dataTransform dataDevelop function visualise data based user inputsThis list pretty straightforward, shouldn’t hard . ’s now important think parts process need done parts need run response user inputs. shiny apps generally run code running, performed . help app’s performance much code can moved section. example, need load data/packages basic transformations , can put code outside server. means thing ’ll need server code visualise data. Lets develop componenets script first. However, since ’re visualising data function, can also put code function outside server function environment app runs!First lets load data. Since ’re working new project, want make clean, can create new directory called data, add malaria data . can run code testing script eventually delete clean structure app.easier work data use tidy data standards, also transform longer data format, age group column, cases another column. can easily using ’ve learned Pivoting data page.’ve finished preparing data! crosses items 1, 2, 3 list things develop “testing R script”. last, difficult task building function produce epicurve based user defined parameters. mentioned previously, ’s highly recommended anyone learning shiny first look section functional programming (Writing functions) understand works!defining function, might hard think parameters want include. functional programming shiny, every relevent parameter generally widget associated , thinking usually quite easy! example current app, want able filter district, widget , can add district parameter reflect . don’t app functionality filter facility (now), don’t need add parameter. Lets start making function three parameters:core datasetThe district choiceThe age group choiceWe won’t go great detail function, ’s relatively simple works. One thing note however, handle errors returning NULL otherwise give error. shiny server produces NULL object instead plot object, nothing shown ui! important, otherwise errors often cause app stop working.Another thing note use %% operator evaluating district input. mentioned , arrive character vector multiple values, using %% flexible say, ==.Let’s test function!function working, now understand going fit shiny app. mentioned concept startup code , lets look can actually incorporate structure app. two ways can !Put code app.R file start script (UI), orCreate new file app’s directory called global.R, put startup code file.’s worth noting point ’s generally easier, especially bigger apps, use second file structure, lets separate file structure simple way. Lets fully develop global.R script now. look like:Easy! One great feature shiny understand files named app.R, server.R, ui.R, global.R , need connect via code. just code global.R directory run start app!.also note improve app’s organisation moved plotting function file - especially helpful apps become larger. , make another directory called funcs, put function file called plot_epicurve.R. read function via following command global.RNote always specify local = TRUE shiny apps, since affect sourcing /app published server.","code":"\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\nprint(malaria_data)## # A tibble: 3,038 × 10\n##    location_name data_date  submitted_date Province District `malaria_rdt_0-4` `malaria_rdt_5-14` malaria_rdt_15 malaria_tot\n##    <chr>         <date>     <date>         <chr>    <chr>                <int>              <int>          <int>       <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11                 12             23          46\n##  2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11                 10              5          26\n##  3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8                  5              5          18\n##  4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16                 16             17          49\n##  5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9                  2              6          17\n##  6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3                  1              4           8\n##  7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4                  0              3           7\n##  8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15                 14             13          42\n##  9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11                 11             13          35\n## 10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19                 15             15          49\n## # ℹ 3,028 more rows\n## # ℹ 1 more variable: newid <int>\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)## # A tibble: 12,152 × 7\n##    location_name data_date  submitted_date Province District age_group        cases_reported\n##    <chr>         <date>     <date>         <chr>    <chr>    <chr>                     <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0-4              11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5-14             12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15               23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot                  46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0-4              11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5-14             10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15                5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot                  26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0-4               8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5-14              5\n## # ℹ 12,142 more rows\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n# global.R script\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\n# clean data and pivot longer\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# define plotting function\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # create plot title\n  if (!(\"All\" %in% district)) {            \n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filter to age group\n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)"},{"path":"dashboards-with-shiny.html","id":"developing-an-app-server","chapter":"43 Dashboards with Shiny","heading":"43.5 Developing an app server","text":"Now code, just develop server. final piece app, probably hardest understand. server large R function, helpful think series smaller functions, tasks app can perform. ’s important understand functions executed linear order. order , ’s fully necessary understand starting shiny. basic level, tasks functions activate change user inputs affects , unless developer set behave differently. , quite abstract, lets first go three basic types shiny objectsReactive sources - another term user inputs. shiny server access outputs UI widgets ’ve programmed. Every time values changed, passed server.Reactive sources - another term user inputs. shiny server access outputs UI widgets ’ve programmed. Every time values changed, passed server.Reactive conductors - objects exist inside shiny server. don’t actually need simple apps, produce objects can seen inside server, used operations. generally depend reactive sources.Reactive conductors - objects exist inside shiny server. don’t actually need simple apps, produce objects can seen inside server, used operations. generally depend reactive sources.Endpoints - outputs passed server UI. example, epi curve producing.Endpoints - outputs passed server UI. example, epi curve producing.mind lets construct server step--step. ’ll show UI code just reference:code UI :Two inputs:\nDistrict selector (inputId select_district)\nAge group selector (inputId select_agegroup)\nDistrict selector (inputId select_district)Age group selector (inputId select_agegroup)One output:\nepicurve (outputId malaria_epicurve)\nepicurve (outputId malaria_epicurve)stated previously, unique names assigned inputs outputs crucial. must unique used pass information ui server. server, access inputs via syntax input$inputID outputs passed ui syntax output$output_name Lets look example, hard understand otherwise!server simple app like actually quite straightforward! ’ll notice server function three parameters - input, output, session - isn’t important understand now, important stick setup! server one task - renders plot based function made earlier, inputs server. Notice names input output objects correspond exactly ui.understand basics server reacts user inputs, note output know (underlying package) inputs change, rerun function create plot every time change. Note also use renderPlot() function - one family class-specific functions pass objects ui output. number functions behave similarly, need ensure function used matches class object ’re passing ui! example:renderText() - send text uirenderDataTable - send interactive table ui.Remember also need match output function used ui - renderPlot() paired plotOutput(), renderText() matched textOutput().’ve finally made functioning app! can run pressing Run App button top right script window Rstudio. note can choose run app default browser (rather Rstudio) accurately reflect app look like users.fun note R console, app “listening”! Talk reactivity!","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}"},{"path":"dashboards-with-shiny.html","id":"adding-more-functionality","chapter":"43 Dashboards with Shiny","heading":"43.6 Adding more functionality","text":"point ’ve finally got running app, little functionality. also haven’t really scratched surface shiny can , ’s lot learn ! Lets continue build existing app adding extra features. things nice add :explanatory textA download button plot - provide user high quality version image ’re generating appA selector specific facilitiesAnother dashboard page - show table data.lot add, can use learn bunch different shiny featues way. much learn shiny (can get advanced, hopefully case users better idea use can become comfortable using external learning sources well).","code":""},{"path":"dashboards-with-shiny.html","id":"adding-static-text","chapter":"43 Dashboards with Shiny","heading":"Adding static text","text":"Lets first discuss adding static text shiny app. Adding text app extremely easy, basic grasp . Since static text doesn’t change shiny app (’d like change, can use text rendering functions server!), shiny’s static text generally added ui app. wont go great detail, can add number different elements ui (even custom ones) interfacing R HTML css.HTML css languages explicitly involved user interface design. don’t need understand well, HTML creates objects UI (like text box, table), css generally used change style aesthetics objects. Shiny access large array HTML tags - present objects behave specific way, headers, paragraphs text, line breaks, tables, etc. can use examples like :h1() - header tag, make enclosed text automatically larger, change defaults pertain font face, colour etc (depending overall theme app). can access smaller smaller sub-heading h2() h6() well. Usage looks like:\nh1(\"header - section 1\")\nh1() - header tag, make enclosed text automatically larger, change defaults pertain font face, colour etc (depending overall theme app). can access smaller smaller sub-heading h2() h6() well. Usage looks like:h1(\"header - section 1\")p() - paragraph tag, make enclosed text similar text body text. text automatically wrap, relatively small size (footers smaller example.) Think text body word document. Usage looks like:\np(\"larger body text explaining function app\")\np() - paragraph tag, make enclosed text similar text body text. text automatically wrap, relatively small size (footers smaller example.) Think text body word document. Usage looks like:p(\"larger body text explaining function app\")tags$b() tags$() - used create bold tags$b() italicised tags$() whichever text enclosed!tags$b() tags$() - used create bold tags$b() italicised tags$() whichever text enclosed!tags$ul(), tags$ol() tags$li() - tags used creating lists. used within syntax , allow user create either ordered list (tags$ol(); .e. numbered) unordered list (tags$ul(), .e. bullet points). tags$li() used denote items list, regardless type list used. e.g.:tags$ul(), tags$ol() tags$li() - tags used creating lists. used within syntax , allow user create either ordered list (tags$ol(); .e. numbered) unordered list (tags$ul(), .e. bullet points). tags$li() used denote items list, regardless type list used. e.g.:br() hr() - tags create linebreaks horizontal lines (linebreak) respectively. Use separate sections app text! need pass items tags (parentheses can remain empty).br() hr() - tags create linebreaks horizontal lines (linebreak) respectively. Use separate sections app text! need pass items tags (parentheses can remain empty).div() - generic tag can contain anything, can named anything. progress ui design, can use compartmentalize ui, give specific sections specific styles, create interactions server UI elements. won’t go detail, ’re worth aware !div() - generic tag can contain anything, can named anything. progress ui design, can use compartmentalize ui, give specific sections specific styles, create interactions server UI elements. won’t go detail, ’re worth aware !Note every one objects can accessed tags$... , just function. effectively synonymous, may help use tags$... style ’d rather explicit overwrite functions accidentally. also means exhaustive list tags available. full list tags available shiny even can used inserting HTML directly ui!’re feeling confident, can also add css styling elements HTML tags style argument . won’t go works detail, one tip testing aesthetic changes UI using HTML inspector mode chrome (shiny app running browser), editing style objects !Lets add text app","code":"\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)"},{"path":"dashboards-with-shiny.html","id":"adding-a-link","chapter":"43 Dashboards with Shiny","heading":"Adding a link","text":"add link website, use tags$() link display text shown . standalone paragraph, put within p(). words sentence linked, break sentence parts use tags$() hyperlinked part. ensure link opens new browser window, add target = \"_blank\" argument.","code":"\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")"},{"path":"dashboards-with-shiny.html","id":"adding-a-download-button","chapter":"43 Dashboards with Shiny","heading":"Adding a download button","text":"Lets move second three features. download button fairly common thing add app fairly easy make. need add another Widget ui, need add another output server attach . can also introduce reactive conductors example!Lets update ui first - easy shiny comes widget called downloadButton() - lets give inputId label.Note ’ve also added hr() tag - adds horizontal line separating control widgets download widgets. another one HTML tags discussed previously.Now ui ready, need add server component. Downloads done server downloadHandler() function. Similar plot, need attach output inputId download button. function takes two arguments - filename content - functions. might able guess, filename used specify name downloaded file, content used specify downloaded. content contain function use save data locally - downloading csv file use rio::export(). Since ’re downloading plot, ’ll use ggplot2::ggsave(). Lets look program (won’t add server yet).Note content function always takes file argument, put output file name specified. might also notice ’re repeating code - using plot_epicurve() function twice server, download image displayed app. wont massively affect performance, means code generate plot run user changes widgets specifying district age group, want download plot. larger apps, suboptimal decisions like one slow things , ’s good learn make app efficient sense. make sense way run epicurve code districts/age groups changes, let used renderPlot() downloadHandler() functions. reactive conductors come !Reactive conductors objects created shiny server reactive way, outputted - can just used parts server. number different kinds reactive conductors, ’ll go basic two.1.reactive() - basic reactive conductor - react whenever inputs used inside change (district/age group widgets)\n2. eventReactive()- rective conductor works reactive(), except user can specify inputs cause rerun. useful reactive conductor takes long time process, explained later.Lets look two examples:use eventReactive() setup, can specify inputs cause chunk code run - isn’t useful us moment, can leave now. Note can include multiple inputs c()Lets look can integrate server code:can see ’re just calling output reactive ’ve defined download plot rendering functions. One thing note often trips people use outputs reactives functions - must add empty brackets end (.e. malaria_plot() correct, malaria_plot ). Now ’ve added solution app little tidyer, faster, easier change since code runs epicurve function one place.","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\nmalaria_plot_r <- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# only runs when the district selector changes!\nmalaria_plot_er <- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}"},{"path":"dashboards-with-shiny.html","id":"adding-a-facility-selector","chapter":"43 Dashboards with Shiny","heading":"Adding a facility selector","text":"Lets move next feature - selector specific facilities. ’ll implement another parameter function can pass argument code. Lets look first - just operates principles parameters ’ve set . Lets update test function.Let’s test :facilites data, isn’t clear facilities correspond districts - end user won’t know either. might make using app quite unintuitive. reason, make facility options UI change dynamically user changes district - one filters ! Since many variables ’re using options, might also want generate options ui global.R file data. example, can add code chunk global.R ’ve read data :Let’s look :can pass new variables ui without issue, since globally visible server ui! Lets update UI:Notice ’re now passing variables choices instead hard coding ui! might make code compact well! Lastly, ’ll update server. easy update function incorporate new input (just pass argument new parameter), remember also want ui update dynamically user changes selected district. important understand can change parameters behaviour widgets app running, needs done server. need understand new way output server learn .functions need understand known observer functions, similar reactive functions behave. one key difference though:Reactive functions directly affect outputs, produce objects can seen locations serverObserver functions can affect server outputs, via side effects functions. (can also things, main function practice)Similar reactive functions, two flavours observer functions, divided logic divides reactive functions:observe() - function runs whenever inputs used inside changeobserveEvent() - function runs user-specified input changesWe also need understand shiny-provided functions update widgets. fairly straightforward run - first take session object server function (doesn’t need understood now), inputId function changed. pass new versions parameters already taken selectInput() - automatically updated widget.Lets look isolated example use server. user changes district, want filter tibble facilities district, update choices reflect available district (option facilities)’s ! can add server, behaviour now work. ’s new server look like:","code":"\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data <- data %>%\n      filter(location_name == facility)\n    \n    plot_title_facility <- facility\n    \n  } else {\n    \n    plot_title_facility <- \"all facilities\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\nall_districts <- c(\"All\", unique(malaria_data$District))\n\n# data frame of location names by district\nfacility_list <- malaria_data %>%\n  group_by(location_name, District) %>%\n  summarise() %>% \n  ungroup()\nall_districts## [1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\nfacility_list## # A tibble: 65 × 2\n##    location_name District\n##    <chr>         <chr>   \n##  1 Facility 1    Spring  \n##  2 Facility 10   Bolo    \n##  3 Facility 11   Spring  \n##  4 Facility 12   Dingo   \n##  5 Facility 13   Bolo    \n##  6 Facility 14   Dingo   \n##  7 Facility 15   Barnard \n##  8 Facility 16   Barnard \n##  9 Facility 17   Barnard \n## 10 Facility 18   Bolo    \n## # ℹ 55 more rows\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for facility\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices <- facility_list$location_name\n  } else {\n    new_choices <- facility_list %>%\n      filter(District == input$select_district) %>%\n      pull(location_name)\n  }\n  \n  new_choices <- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}"},{"path":"dashboards-with-shiny.html","id":"adding-another-tab-with-a-table","chapter":"43 Dashboards with Shiny","heading":"Adding another tab with a table","text":"Now ’ll move last component want add app. ’ll want separate ui two tabs, one interactive table user can see data making epidemic curve . , can use packaged ui elements come shiny relevant tabs. basic level, can enclose main panel general structure:Lets apply ui. also want use DT package - great package making interactive tables pre-existing data. can see used DT::datatableOutput() example.Now app arranged tabs! Lets make necessary edits server well. Since dont need manipulate dataset render actually simple - just render malaria_data dataset via DT::renderDT() ui!","code":"\n# ... the rest of ui\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\nui <- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # selector for district\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for age group\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for facility\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # horizontal line\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # render data table to ui\n  output$raw_data <- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}"},{"path":"dashboards-with-shiny.html","id":"sharing-shiny-apps","chapter":"43 Dashboards with Shiny","heading":"43.7 Sharing shiny apps","text":"Now ’ve developed app, probably want share others - main advantage shiny ! can sharing code directly, publish server. share code, others able see ’ve done build , negate one main advantages shiny - can eliminate need end-users maintain R installation. reason, ’re sharing app users comfortable R, much easier share app published server.’d rather share code, make .zip file app, better yet, publish app github add collaborators. can refer section github information .However, ’re publishing app online, need little work. Ultimately, want app able accessed via web URL others can get quick easy access . Unfortunately, publish app server, need access server publish ! number hosting options comes :shinyapps.io: easiest place publish shiny apps, smallest amount configuration work needed, free, limited licenses.shinyapps.io: easiest place publish shiny apps, smallest amount configuration work needed, free, limited licenses.RStudio Connect: far powerful version R server, can perform many operations, including publishing shiny apps. however, harder use, less recommended first-time users.RStudio Connect: far powerful version R server, can perform many operations, including publishing shiny apps. however, harder use, less recommended first-time users.purposes document, use shinyapps.io, since easier first time users. can make free account start - also different price plans server licesnses needed. users expect , expensive price plan may , keep consideration. ’re looking create something small set individuals use, free license may perfectly suitable, public facing app may need licenses.First make sure app suitable publishing server. app, restart R session, ensure runs without running extra code. important, app requires package loading, data reading defined app code won’t run server. Also note can’t explicit file paths app - invalid server setting - using package solves issue well. Finally, ’re reading data source requires user-authentication, organisation’s servers, generally work server. need liase department figure whitelist shiny server .signing accountOnce account, can navigate tokens page Accounts. want add new token - used deploy app., note url account reflect name app - app called my_app, url appended xxx.io/my_app/. Choose app name wisely! Now ready, click deploy - successful run app web url chose!something making apps documents?","code":""},{"path":"dashboards-with-shiny.html","id":"further-reading","chapter":"43 Dashboards with Shiny","heading":"43.8 Further reading","text":"far, ’ve covered lot aspects shiny, barely scratched surface offer shiny. guide serves introduction, loads learn fully understand shiny. start making apps gradually add functionality","code":""},{"path":"dashboards-with-shiny.html","id":"recommended-extension-packages","chapter":"43 Dashboards with Shiny","heading":"43.9 Recommended extension packages","text":"following represents selection high quality shiny extensions can help get lot shiny. particular order:shinyWidgets - package gives many many widgets can used app. Run shinyWidgets::shinyWidgetsGallery() see selection available widgets package. See examples hereshinyWidgets - package gives many many widgets can used app. Run shinyWidgets::shinyWidgetsGallery() see selection available widgets package. See examples hereshinyjs - excellent package gives user ability greatly extend shiny’s utility via series javascript. applications package range simple highly advanced, might want first use manipulate ui simple ways, like hiding/showing elements, enabling/disabling buttons. Find hereshinyjs - excellent package gives user ability greatly extend shiny’s utility via series javascript. applications package range simple highly advanced, might want first use manipulate ui simple ways, like hiding/showing elements, enabling/disabling buttons. Find hereshinydashboard - package massively expands available ui can used shiny, specifically letting user create complex dashboard variety complex layouts. See hereshinydashboard - package massively expands available ui can used shiny, specifically letting user create complex dashboard variety complex layouts. See hereshinydashboardPlus - get even features shinydashboard framework! See hereshinydashboardPlus - get even features shinydashboard framework! See hereshinythemes - change default css theme shiny app wide range preset templates! See hereshinythemes - change default css theme shiny app wide range preset templates! See hereThere also number packages can used create interactive outputs shiny compatible.DT semi-incorporated base-shiny, provides great set functions create interactive tables.DT semi-incorporated base-shiny, provides great set functions create interactive tables.plotly package creating interactive plots user can manipulate app. can also convert plot interactive versions via plotly::ggplotly()! alternatives, dygraphs highcharter also excellent.plotly package creating interactive plots user can manipulate app. can also convert plot interactive versions via plotly::ggplotly()! alternatives, dygraphs highcharter also excellent.","code":""},{"path":"dashboards-with-shiny.html","id":"recommended-resources","chapter":"43 Dashboards with Shiny","heading":"43.10 Recommended resources","text":"","code":""},{"path":"writing-functions-1.html","id":"writing-functions-1","chapter":"44 Writing functions","heading":"44 Writing functions","text":"","code":""},{"path":"writing-functions-1.html","id":"preparation-37","chapter":"44 Writing functions","heading":"44.1 Preparation","text":"","code":""},{"path":"writing-functions-1.html","id":"load-packages-33","chapter":"44 Writing functions","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page R basics information R packages.","code":""},{"path":"writing-functions-1.html","id":"import-data-28","chapter":"44 Writing functions","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions [Download book data] page. dataset imported using import() function rio package. See page Import export various ways import data.also use last part page data H7N9 flu 2013.","code":""},{"path":"writing-functions-1.html","id":"functions-2","chapter":"44 Writing functions","heading":"44.2 Functions","text":"Functions helpful programming since allow make codes easier understand, somehow shorter less prone errors (given errors function ).come far handbook, means came across endless functions since R, every operation function call\n+, , , [, $, { …. example x + y '+'(x, y)R one languages offers possibility work functions give enough tools user easily write . think functions fixed top end programming chain, R offers possibility use vectors even use inside functions, lists…Lot advanced resources functional programming exist give insight help start functional programming short practical examples. encouraged visit links references read .","code":""},{"path":"writing-functions-1.html","id":"why-would-you-use-a-function","chapter":"44 Writing functions","heading":"44.3 Why would you use a function?","text":"answering question, important note already tips get write first R functions page Iteration, loops, lists handbook. fact, use “/else” loops often core part many functions since easily help either broaden application code allowing multiple conditions iterate codes repeating tasks.repeating multiple times block code apply different variable data?repeating multiple times block code apply different variable data?Getting rid substantially shorten overall code make run quicker?Getting rid substantially shorten overall code make run quicker?possible code written used different value many places code?possible code written used different value many places code?answer one previous questions “YES”, probably need write function","code":""},{"path":"writing-functions-1.html","id":"how-does-r-build-functions","chapter":"44 Writing functions","heading":"44.4 How does R build functions?","text":"Functions R three main components:formals() list arguments controls can call functionthe formals() list arguments controls can call functionthe body() code inside function .e. within brackets following parenthesis depending write itthe body() code inside function .e. within brackets following parenthesis depending write itand,environment() help locate function’s variables determines function finds value.created function, can verify components calling function associated.","code":""},{"path":"writing-functions-1.html","id":"basic-syntax-and-structure","chapter":"44 Writing functions","heading":"44.5 Basic syntax and structure","text":"function need named properly job easily understandable soon read name. Actually already case majority base R architecture. Functions like mean(), print(), summary() names straightforwardA function need named properly job easily understandable soon read name. Actually already case majority base R architecture. Functions like mean(), print(), summary() names straightforwardA function need arguments, data work objects can static values among optionsA function need arguments, data work objects can static values among optionsAnd finally function give output based core task arguments given. Usually use built-functions print(), return()… produce output. output can logical value, number, character, data frame…short kind R object.finally function give output based core task arguments given. Usually use built-functions print(), return()… produce output. output can logical value, number, character, data frame…short kind R object.Basically composition function:can create first function called contain_covid19().can verify components newly created function.Now test function. call written function, use use R functions .e writing function name adding required arguments.can write name argument precautionary reasons. without specifying , code work since R memory positioning argument. long put values arguments correct order, can skip writing arguments names calling functions.let’s look happens one values \"\" \"yes\".provide argument recognized, get error:Error contain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\",  :    find function \"contain_covid19\"NOTE: functions (time short straightforward) may need name can used directly line code inside another function quick task. called anonymous functions .instance first anonymous function keeps character variables dataset.another function selects every second observation dataset (may relevant longitudinal data many records per patient instance ordered date visit).\ncase, proper function writing outside dplyr function (x) (x%%2 == 0) apply vector containing row numbers.possible base R code task :CAUTION: Though true using functions can help us code, can nevertheless time consuming write functions fix one thought thoroughly, written adequately returning errors result. reason often recommended first write R code, make sure intend , transform function three main components listed . ","code":"\nfunction_name <- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\ncontain_covid19 <- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\nformals(contain_covid19)## $barrier_gest\n## \n## \n## $wear_mask\n## \n## \n## $get_vaccine\nbody(contain_covid19)## {\n##     if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n##         \"yes\") \n##         return(\"success\")\n##     else (\"please make sure all are yes, this pandemic has to end!\")\n## }\nenvironment(contain_covid19)## <environment: R_GlobalEnv>\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")## [1] \"success\"\ncontain_covid19(\"yes\", \"yes\", \"yes\")## [1] \"success\"\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")## [1] \"please make sure all are yes, this pandemic has to end!\"\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\nlinelist %>% \n  dplyr::slice_head(n=10) %>%  #equivalent to R base \"head\" function and that return first n observation of the  dataset\n  select(function(x) is.character(x)) \nlinelist %>%   \n   slice_head(n=20) %>% \n   tibble::rownames_to_column() %>% # add indices of each obs as rownames to clearly see the final selection\n   filter(row_number() %%2 == 0)\nlinelist_firstobs <- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]"},{"path":"writing-functions-1.html","id":"examples-2","chapter":"44 Writing functions","heading":"44.6 Examples","text":"","code":""},{"path":"writing-functions-1.html","id":"return-proportion-tables-for-several-columns","chapter":"44 Writing functions","heading":"Return proportion tables for several columns","text":"Yes, already nice functions many packages allowing summarize information easy nice way. still try make , first steps getting used writing functions.example want show writing simple function avoid copy-pasting code multiple times.TIP: shown , important comment functions general programming. Bear mind function’s aim make code ready read, shorter efficient. one able understand function just reading name details reading comments.second option use function another one via loop make process :simpler way using base R “apply” instead “loop” expressed :TIP: R often defined functional programming language almost anytime run line code using built-functions. good habit comfortable writing functions often internal look basic functions using daily built. shortcut selecting function name clicking onCtrl+F2 fn+F2 Cmd+F2 (depending computer) .","code":"\nproptab_multiple <- function(my_data, var_to_tab){\n  \n  #print the name of each variable of interest before doing the tabulation\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #bind the results of the two following function by row\n        #tabulate the variable of interest: gives only numbers\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calculate the proportions for each variable of interest and round the value to 2 decimals\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")## [1] \"gender\"##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\nproptab_multiple(linelist, \"age_cat\")## [1] \"age_cat\"##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\nproptab_multiple(linelist, \"outcome\")## [1] \"outcome\"##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44\nfor(var_to_tab in c(\"gender\",\"age_cat\",  \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}## [1] \"gender\"\n##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\n## [1] \"age_cat\"\n##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n## [1] \"outcome\"\n##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44"},{"path":"writing-functions-1.html","id":"using-purrr-writing-functions-that-can-be-iteratively-applied","chapter":"44 Writing functions","heading":"44.7 Using purrr: writing functions that can be iteratively applied","text":"","code":""},{"path":"writing-functions-1.html","id":"modify-class-of-multiple-columns-in-a-dataset","chapter":"44 Writing functions","heading":"Modify class of multiple columns in a dataset","text":"Let’s say many character variables original linelist data need changes “factor” analysis plotting purposes. Instead repeating step several times, can just use lapply() transformation variables concerned single line code.CAUTION: lapply() returns list, thus use may require additional modification last step.step can done using map_if() function purrr package","code":"\nlinelist_factor2 <- linelist %>%\n  purrr::map_if(is.character, as.factor)\n\n\nlinelist_factor2 %>%\n        glimpse()## List of 30\n##  $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n##  $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n##  $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA NA \"2014-05-04\" ...\n##  $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" \"2014-05-16\" \"2014-05-18\" ...\n##  $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" \"2014-05-18\" \"2014-05-20\" ...\n##  $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" \"2014-05-30\" NA ...\n##  $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n##  $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n##  $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n##  $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n##  $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n##  $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n##  $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n##  $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n##  $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n##  $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n##  $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n##  $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n##  $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n##  $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n##  $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n##  $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n##  $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n##  $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n##  $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ..."},{"path":"writing-functions-1.html","id":"iteratively-produce-graphs-for-different-levels-of-a-variable","chapter":"44 Writing functions","heading":"Iteratively produce graphs for different levels of a variable","text":"produce pie chart look distribution patient’s outcome China H7N9 outbreak province. Instead repeating code , just apply function create.","code":"\n#precising options for the use of highchart\noptions(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#create a function called \"chart_outcome_province\" that takes as argument the dataset and the name of the province for which to plot the distribution of the outcome.\n\nchart_outcome_province <- function(data_used, prov){\n  \n  tab_prov <- data_used %>% \n    filter(province == prov,\n           !is.na(outcome))%>% \n    group_by(outcome) %>% \n    count() %>%\n    adorn_totals(where = \"row\") %>% \n    adorn_percentages(denominator = \"col\", )%>%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %>%\n    filter(outcome != \"Total\") %>% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distibution of the outcome in:\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\nchart_outcome_province(flu_china,\"Zhejiang\")\nchart_outcome_province(flu_china,\"Jiangsu\")"},{"path":"writing-functions-1.html","id":"iteratively-produce-tables-for-different-levels-of-a-variable","chapter":"44 Writing functions","heading":"Iteratively produce tables for different levels of a variable","text":"create three indicators summarize table like produce table provinces. indicators delay onset hospitalization, percentage recovery median age cases.Indicateurs pour la province de: ShanghaiIndicateursEstimationMean delay onset-hosp4.0Percentage recovery46.7Median age cases67.0Indicateurs pour la province de: JiangsuIndicateursEstimationMean delay onset-hosp6.0Percentage recovery71.4Median age cases55.0","code":"\nindic_1 <- flu_china %>% \n  group_by(province) %>% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %>%\n  select(province, mean_delay_onset_hosp)  %>% \n  distinct()\n     \n\nindic_2 <-  flu_china %>% \n            filter(!is.na(outcome)) %>% \n            group_by(province, outcome) %>% \n            count() %>%\n            pivot_wider(names_from = outcome, values_from = n) %>% \n    adorn_totals(where = \"col\") %>% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%>% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 <-  flu_china %>% \n            group_by(province) %>% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %>% \n  select(province, median_age_cases)  %>% \n  distinct()## Warning: There was 1 warning in `mutate()`.\n## ℹ In argument: `median_age_cases = median(as.numeric(age), na.rm = TRUE)`.\n## ℹ In group 11: `province = \"Shanghai\"`.\n## Caused by warning in `median()`:\n## ! NAs introduced by coercion\n#join the three indicator datasets\n\ntable_indic_all <- indic_1 %>% \n  dplyr::left_join(indic_2, by = \"province\") %>% \n        left_join(indic_3, by = \"province\")\n\n\n#print the indicators in a flextable\n\n\nprint_indic_prov <-  function(table_used, prov){\n  \n  #first transform a bit the dataframe for printing ease\n  indic_prov <- table_used %>%\n    filter(province==prov) %>%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %>% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\",\"perc_recovery\",\"median_age_cases\"),\n   labels=c(\"Mean delay onset-hosp\",\"Percentage of recovery\", \"Median age of the cases\"))\n   ) %>% \n    ungroup(province) %>% \n    select(indic_label, value)\n  \n\n    tab_print <- flextable(indic_prov)  %>%\n    theme_vanilla() %>% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print <- tab_print %>% \n                  autofit()   %>%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %>%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %>%\n    flextable::bold(part = \"header\") %>%\n    flextable::color(color = \"white\", part = \"header\") %>% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de: \", prov)) %>% \nbold(part = \"header\")\n \n tab_print <- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\nprint_indic_prov(table_indic_all, \"Jiangsu\")"},{"path":"writing-functions-1.html","id":"tips-and-best-practices-for-well-functioning-functions","chapter":"44 Writing functions","heading":"44.8 Tips and best Practices for well functioning functions","text":"Functional programming meant ease code facilitates reading. produce contrary. tips help clean code easy read code.","code":""},{"path":"writing-functions-1.html","id":"naming-and-syntax","chapter":"44 Writing functions","heading":"Naming and syntax","text":"Avoid using character easily already taken functions already existing environmentAvoid using character easily already taken functions already existing environmentIt recommended function name short straightforward understand another readerIt recommended function name short straightforward understand another readerIt preferred use verbs function name nouns argument names.preferred use verbs function name nouns argument names.","code":""},{"path":"writing-functions-1.html","id":"column-names-and-tidy-evaluation","chapter":"44 Writing functions","heading":"Column names and tidy evaluation","text":"want know reference column names provided code arguments, read tidyverse programming guidance. Among topics covered tidy evaluation use embrace {{ }} “double braces”example, quick skeleton template code page tutorial mentioned just :","code":"\nvar_summary <- function(data, var) {\n  data %>%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))\n}\nmtcars %>% \n  group_by(cyl) %>% \n  var_summary(mpg)"},{"path":"writing-functions-1.html","id":"testing-and-error-handling","chapter":"44 Writing functions","heading":"Testing and Error handling","text":"complicated function’s task higher possibility errors. Thus sometimes necessary add verification within funtion help quickly understand error find way t fix .can recommended introduce check missingness one argument using missing(argument). simple check can return “TRUE” “FALSE” value.Use stop() detectable errors.see run built-functions, messages warnings can pop-certain conditions. can integrate written functions using functions message() warning().see run built-functions, messages warnings can pop-certain conditions. can integrate written functions using functions message() warning().can handle errors also using safely() takes one function argument executes safe way. fact function execute without stopping encounters error. safely() returns output list two objects results error “skipped”.can handle errors also using safely() takes one function argument executes safe way. fact function execute without stopping encounters error. safely() returns output list two objects results error “skipped”.can verify first running mean() function, run safely().said previously, well commenting codes already good way documentation work.","code":"\ncontain_covid19_missing <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask ==\"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")## [1] \"please provide arg1\"\n## [1] \"please provide arg2\"## Error in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\ncontain_covid19_stop <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\"))\n  \n  if (barrier_gest == \"yes\" & wear_mask ==\"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")## Error in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\nmap(linelist, mean)## $case_id\n## [1] NA\n## \n## $generation\n## [1] 16.56165\n## \n## $date_infection\n## [1] NA\n## \n## $date_onset\n## [1] NA\n## \n## $date_hospitalisation\n## [1] \"2014-11-03\"\n## \n## $date_outcome\n## [1] NA\n## \n## $outcome\n## [1] NA\n## \n## $gender\n## [1] NA\n## \n## $age\n## [1] NA\n## \n## $age_unit\n## [1] NA\n## \n## $age_years\n## [1] NA\n## \n## $age_cat\n## [1] NA\n## \n## $age_cat5\n## [1] NA\n## \n## $hospital\n## [1] NA\n## \n## $lon\n## [1] -13.23381\n## \n## $lat\n## [1] 8.469638\n## \n## $infector\n## [1] NA\n## \n## $source\n## [1] NA\n## \n## $wt_kg\n## [1] 52.64487\n## \n## $ht_cm\n## [1] 124.9633\n## \n## $ct_blood\n## [1] 21.20686\n## \n## $fever\n## [1] NA\n## \n## $chills\n## [1] NA\n## \n## $cough\n## [1] NA\n## \n## $aches\n## [1] NA\n## \n## $vomit\n## [1] NA\n## \n## $temp\n## [1] NA\n## \n## $time_admission\n## [1] NA\n## \n## $bmi\n## [1] 46.89023\n## \n## $days_onset_hosp\n## [1] NA\nsafe_mean <- safely(mean)\nlinelist %>% \n  map(safe_mean)## $case_id\n## $case_id$result\n## [1] NA\n## \n## $case_id$error\n## NULL\n## \n## \n## $generation\n## $generation$result\n## [1] 16.56165\n## \n## $generation$error\n## NULL\n## \n## \n## $date_infection\n## $date_infection$result\n## [1] NA\n## \n## $date_infection$error\n## NULL\n## \n## \n## $date_onset\n## $date_onset$result\n## [1] NA\n## \n## $date_onset$error\n## NULL\n## \n## \n## $date_hospitalisation\n## $date_hospitalisation$result\n## [1] \"2014-11-03\"\n## \n## $date_hospitalisation$error\n## NULL\n## \n## \n## $date_outcome\n## $date_outcome$result\n## [1] NA\n## \n## $date_outcome$error\n## NULL\n## \n## \n## $outcome\n## $outcome$result\n## [1] NA\n## \n## $outcome$error\n## NULL\n## \n## \n## $gender\n## $gender$result\n## [1] NA\n## \n## $gender$error\n## NULL\n## \n## \n## $age\n## $age$result\n## [1] NA\n## \n## $age$error\n## NULL\n## \n## \n## $age_unit\n## $age_unit$result\n## [1] NA\n## \n## $age_unit$error\n## NULL\n## \n## \n## $age_years\n## $age_years$result\n## [1] NA\n## \n## $age_years$error\n## NULL\n## \n## \n## $age_cat\n## $age_cat$result\n## [1] NA\n## \n## $age_cat$error\n## NULL\n## \n## \n## $age_cat5\n## $age_cat5$result\n## [1] NA\n## \n## $age_cat5$error\n## NULL\n## \n## \n## $hospital\n## $hospital$result\n## [1] NA\n## \n## $hospital$error\n## NULL\n## \n## \n## $lon\n## $lon$result\n## [1] -13.23381\n## \n## $lon$error\n## NULL\n## \n## \n## $lat\n## $lat$result\n## [1] 8.469638\n## \n## $lat$error\n## NULL\n## \n## \n## $infector\n## $infector$result\n## [1] NA\n## \n## $infector$error\n## NULL\n## \n## \n## $source\n## $source$result\n## [1] NA\n## \n## $source$error\n## NULL\n## \n## \n## $wt_kg\n## $wt_kg$result\n## [1] 52.64487\n## \n## $wt_kg$error\n## NULL\n## \n## \n## $ht_cm\n## $ht_cm$result\n## [1] 124.9633\n## \n## $ht_cm$error\n## NULL\n## \n## \n## $ct_blood\n## $ct_blood$result\n## [1] 21.20686\n## \n## $ct_blood$error\n## NULL\n## \n## \n## $fever\n## $fever$result\n## [1] NA\n## \n## $fever$error\n## NULL\n## \n## \n## $chills\n## $chills$result\n## [1] NA\n## \n## $chills$error\n## NULL\n## \n## \n## $cough\n## $cough$result\n## [1] NA\n## \n## $cough$error\n## NULL\n## \n## \n## $aches\n## $aches$result\n## [1] NA\n## \n## $aches$error\n## NULL\n## \n## \n## $vomit\n## $vomit$result\n## [1] NA\n## \n## $vomit$error\n## NULL\n## \n## \n## $temp\n## $temp$result\n## [1] NA\n## \n## $temp$error\n## NULL\n## \n## \n## $time_admission\n## $time_admission$result\n## [1] NA\n## \n## $time_admission$error\n## NULL\n## \n## \n## $bmi\n## $bmi$result\n## [1] 46.89023\n## \n## $bmi$error\n## NULL\n## \n## \n## $days_onset_hosp\n## $days_onset_hosp$result\n## [1] NA\n## \n## $days_onset_hosp$error\n## NULL"},{"path":"writing-functions-1.html","id":"resources-36","chapter":"44 Writing functions","heading":"44.9 Resources","text":"R Data Science linkCheatsheet advance R programmingCheatsheet purr PackageVideo-ACM talk Hadley Wickham: joy functional programming (map_dbl work)","code":""},{"path":"directory-interactions.html","id":"directory-interactions","chapter":"45 Directory interactions","heading":"45 Directory interactions","text":"page cover common scenarios create, interact , save, import directories (folders).","code":""},{"path":"directory-interactions.html","id":"preparation-38","chapter":"45 Directory interactions","heading":"45.1 Preparation","text":"","code":""},{"path":"directory-interactions.html","id":"fs-package","chapter":"45 Directory interactions","heading":"fs package","text":"fs package tidyverse package facilitate directory interactions, improving base R functions. sections often use functions fs.","code":"\npacman::p_load(\n  fs,             # file/directory interactions\n  rio,            # import/export\n  here,           # relative file pathways\n  tidyverse)      # data management and visualization"},{"path":"directory-interactions.html","id":"print-directory-as-a-dendrogram-tree","chapter":"45 Directory interactions","heading":"Print directory as a dendrogram tree","text":"Use function dir_tree() fs.Provide folder filepath path = decide whether want show one level (recurse = FALSE) files sub-levels (recurse = TRUE). use () shorthand R project specify sub-folder “data”, contains data used R handbook. set display files within “data” sub-folders (e.g. “cache”, “epidemic models”, “population”, “shp”, “weather”).","code":"\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_eng/data\n## ├── africa_countries.geo.json\n## ├── cache\n## │   └── epidemic_models\n## │       ├── 2015-04-30\n## │       │   ├── estimated_reported_cases_samples.rds\n## │       │   ├── estimate_samples.rds\n## │       │   ├── latest_date.rds\n## │       │   ├── reported_cases.rds\n## │       │   ├── summarised_estimated_reported_cases.rds\n## │       │   ├── summarised_estimates.rds\n## │       │   └── summary.rds\n## │       ├── epinow_res.rds\n## │       ├── epinow_res_small.rds\n## │       ├── generation_time.rds\n## │       └── incubation_period.rds\n## ├── case_linelists\n## │   ├── cleaning_dict.csv\n## │   ├── fluH7N9_China_2013.csv\n## │   ├── linelist_cleaned.rds\n## │   ├── linelist_cleaned.xlsx\n## │   └── linelist_raw.xlsx\n## ├── country_demographics.csv\n## ├── covid_example_data\n## │   ├── covid_example_data.xlsx\n## │   └── covid_shapefile\n## │       ├── FultonCountyZipCodes.cpg\n## │       ├── FultonCountyZipCodes.dbf\n## │       ├── FultonCountyZipCodes.prj\n## │       ├── FultonCountyZipCodes.sbn\n## │       ├── FultonCountyZipCodes.sbx\n## │       ├── FultonCountyZipCodes.shp\n## │       ├── FultonCountyZipCodes.shp.xml\n## │       └── FultonCountyZipCodes.shx\n## ├── covid_incidence.csv\n## ├── covid_incidence_map.R\n## ├── district_count_data.xlsx\n## ├── example\n## │   ├── Central Hospital.csv\n## │   ├── district_weekly_count_data.xlsx\n## │   ├── fluH7N9_China_2013.csv\n## │   ├── hospital_linelists.xlsx\n## │   ├── linelists\n## │   │   ├── 20201007linelist.csv\n## │   │   ├── case_linelist20201006.csv\n## │   │   ├── case_linelist_2020-10-02.csv\n## │   │   ├── case_linelist_2020-10-03.csv\n## │   │   ├── case_linelist_2020-10-04.csv\n## │   │   ├── case_linelist_2020-10-05.csv\n## │   │   └── case_linelist_2020-10-08.xlsx\n## │   ├── Military Hospital.csv\n## │   ├── Missing.csv\n## │   ├── Other.csv\n## │   ├── Port Hospital.csv\n## │   └── St. Mark's Maternity Hospital (SMMH).csv\n## ├── facility_count_data.rds\n## ├── flexdashboard\n## │   ├── outbreak_dashboard.html\n## │   ├── outbreak_dashboard.Rmd\n## │   ├── outbreak_dashboard_shiny.Rmd\n## │   ├── outbreak_dashboard_test.html\n## │   └── outbreak_dashboard_test.Rmd\n## ├── fluH7N9_China_2013.csv\n## ├── gis\n## │   ├── africa_countries.geo.json\n## │   ├── covid_incidence.csv\n## │   ├── covid_incidence_map.R\n## │   ├── linelist_cleaned_with_adm3.rds\n## │   ├── population\n## │   │   ├── sle_admpop_adm3_2020.csv\n## │   │   └── sle_population_statistics_sierraleone_2020.xlsx\n## │   └── shp\n## │       ├── README.txt\n## │       ├── sle_adm3.CPG\n## │       ├── sle_adm3.dbf\n## │       ├── sle_adm3.prj\n## │       ├── sle_adm3.sbn\n## │       ├── sle_adm3.sbx\n## │       ├── sle_adm3.shp\n## │       ├── sle_adm3.shp.xml\n## │       ├── sle_adm3.shx\n## │       ├── sle_hf.CPG\n## │       ├── sle_hf.dbf\n## │       ├── sle_hf.prj\n## │       ├── sle_hf.sbn\n## │       ├── sle_hf.sbx\n## │       ├── sle_hf.shp\n## │       └── sle_hf.shx\n## ├── godata\n## │   ├── cases_clean.rds\n## │   ├── contacts_clean.rds\n## │   ├── followups_clean.rds\n## │   └── relationships_clean.rds\n## ├── likert_data.csv\n## ├── linelist_cleaned.rds\n## ├── linelist_cleaned.xlsx\n## ├── linelist_raw.xlsx\n## ├── make_evd_dataset-DESKTOP-JIEUMMI.R\n## ├── make_evd_dataset.R\n## ├── malaria_app\n## │   ├── app.R\n## │   ├── data\n## │   │   └── facility_count_data.rds\n## │   ├── funcs\n## │   │   └── plot_epicurve.R\n## │   ├── global.R\n## │   ├── malaria_app.Rproj\n## │   ├── server.R\n## │   └── ui.R\n## ├── malaria_facility_count_data.rds\n## ├── phylo\n## │   ├── sample_data_Shigella_tree.csv\n## │   ├── Shigella_subtree_2.nwk\n## │   ├── Shigella_subtree_2.txt\n## │   └── Shigella_tree.txt\n## ├── rmarkdown\n## │   ├── outbreak_report.docx\n## │   ├── outbreak_report.html\n## │   ├── outbreak_report.pdf\n## │   ├── outbreak_report.pptx\n## │   ├── outbreak_report.Rmd\n## │   ├── report_tabbed_example.html\n## │   └── report_tabbed_example.Rmd\n## ├── standardization\n## │   ├── country_demographics.csv\n## │   ├── country_demographics_2.csv\n## │   ├── deaths_countryA.csv\n## │   ├── deaths_countryB.csv\n## │   └── world_standard_population_by_sex.csv\n## ├── surveys\n## │   ├── population.xlsx\n## │   ├── survey_data.xlsx\n## │   └── survey_dict.xlsx\n## └── time_series\n##     ├── campylobacter_germany.xlsx\n##     └── weather\n##         ├── germany_weather2002.nc\n##         ├── germany_weather2003.nc\n##         ├── germany_weather2004.nc\n##         ├── germany_weather2005.nc\n##         ├── germany_weather2006.nc\n##         ├── germany_weather2007.nc\n##         ├── germany_weather2008.nc\n##         ├── germany_weather2009.nc\n##         ├── germany_weather2010.nc\n##         └── germany_weather2011.nc"},{"path":"directory-interactions.html","id":"list-files-in-a-directory","chapter":"45 Directory interactions","heading":"45.2 List files in a directory","text":"list just file names directory can use dir() base R. example, command lists file names files “population” subfolder “data” folder R project. relative filepath provided using () (can read Import export page).list full file paths directory’s files, can use can use dir_ls() fs. base R alternative list.files().get metadata information file directory, (e.g. path, modification date, etc.) can use dir_info() fs.can particularly useful want extract last modification time file, example want import recent version file. example , see Import export page.data frame returned. Scroll right see columns.","code":"\n# file names\ndir(here(\"data\", \"gis\", \"population\"))## [1] \"sle_admpop_adm3_2020.csv\"                        \"sle_population_statistics_sierraleone_2020.xlsx\"\n# file paths\ndir_ls(here(\"data\", \"gis\", \"population\"))## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_eng/data/gis/population/sle_admpop_adm3_2020.csv\n## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_eng/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n# file info\ndir_info(here(\"data\", \"gis\", \"population\"))"},{"path":"directory-interactions.html","id":"file-information","chapter":"45 Directory interactions","heading":"45.3 File information","text":"extract metadata information specific file, can use file_info() fs (file.info() base R).use $ index result return modification_time value.","code":"\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time## [1] \"2022-03-03 16:18:33 CET\""},{"path":"directory-interactions.html","id":"check-if-exists","chapter":"45 Directory interactions","heading":"45.4 Check if exists","text":"","code":""},{"path":"directory-interactions.html","id":"r-objects","chapter":"45 Directory interactions","heading":"R objects","text":"can use exists() base R check whether R object exists within R (supply object name quotes).Note base R packages use generic object names like “data” behind scenes, appear TRUE unless inherit = FALSE specified. one reason name dataset “data”.writing function, use missing() base R check argument present , instead exists().","code":"\nexists(\"linelist\")## [1] TRUE\nexists(\"data\")## [1] TRUE\nexists(\"data\", inherit = FALSE)## [1] FALSE"},{"path":"directory-interactions.html","id":"directories","chapter":"45 Directory interactions","heading":"Directories","text":"check whether directory exists, provide file path (file name) is_dir() fs. Scroll right see TRUE printed.alternative file.exists() base R.","code":"\nis_dir(here(\"data\"))## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_eng/data \n##                                                             TRUE"},{"path":"directory-interactions.html","id":"files","chapter":"45 Directory interactions","heading":"Files","text":"check specific file exists, use is_file() fs. Scroll right see TRUE printed.base R alternative file.exists().","code":"\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_eng/data/case_linelists/linelist_cleaned.rds \n##                                                                                                 TRUE"},{"path":"directory-interactions.html","id":"create","chapter":"45 Directory interactions","heading":"45.5 Create","text":"","code":""},{"path":"directory-interactions.html","id":"directories-1","chapter":"45 Directory interactions","heading":"Directories","text":"create new directory (folder) can use dir_create() fs. directory already exists, overwritten error returned.alternative dir.create() base R, show error directory already exists. contrast, dir_create() scenario silent.","code":"\ndir_create(here(\"data\", \"test\"))"},{"path":"directory-interactions.html","id":"files-1","chapter":"45 Directory interactions","heading":"Files","text":"can create (empty) file file_create() fs. file already exists, -written changed.base R alternative file.create(). file already exists, option truncate . use file_create() file left unchanged.","code":"\nfile_create(here(\"data\", \"test.rds\"))"},{"path":"directory-interactions.html","id":"create-if-does-not-exists","chapter":"45 Directory interactions","heading":"Create if does not exists","text":"CONSTRUCTION","code":""},{"path":"directory-interactions.html","id":"delete","chapter":"45 Directory interactions","heading":"45.6 Delete","text":"","code":""},{"path":"directory-interactions.html","id":"r-objects-1","chapter":"45 Directory interactions","heading":"R objects","text":"Use rm() base R remove R object.","code":""},{"path":"directory-interactions.html","id":"directories-2","chapter":"45 Directory interactions","heading":"Directories","text":"Use dir_delete() fs.","code":""},{"path":"directory-interactions.html","id":"files-2","chapter":"45 Directory interactions","heading":"Files","text":"can delete files file_delete() fs.","code":""},{"path":"directory-interactions.html","id":"running-other-files","chapter":"45 Directory interactions","heading":"45.7 Running other files","text":"","code":""},{"path":"directory-interactions.html","id":"source","chapter":"45 Directory interactions","heading":"source()","text":"run one R script another R script, can use source() command (base R).equivalent viewing R script clicking “Source” button upper-right script. execute script silently (output R console) unless specifically intended. See page [Interactive console] examples using source() interact user via R console question--answer mode.","code":"\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))"},{"path":"directory-interactions.html","id":"render","chapter":"45 Directory interactions","heading":"render()","text":"render() variation source() often used R markdown scripts. provide input = R markdown file, also output_format = (typically either “html_document”, “pdf_document”, “word_document”, ““)See page Reports R Markdown details. Also see documentation render() entering ?render.","code":""},{"path":"directory-interactions.html","id":"run-files-in-a-directory","chapter":"45 Directory interactions","heading":"Run files in a directory","text":"can create loop use source() every file directory, identified dir().want run certain scripts, can identify name like :comparison fs base R functions.","code":"\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # for each script name in the R Project's \"scripts\" folder (with .R extension)\n  source(here(\"scripts\", script))                        # source the file with the matching name that exists in the scripts folder\n}\nscripts_to_run <- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}"},{"path":"directory-interactions.html","id":"import-files-in-a-directory","chapter":"45 Directory interactions","heading":"Import files in a directory","text":"See page Import export importing exporting individual files.Also see Import export page methods automatically import recent file, based date file name looking file meta-data.See page Iteration, loops, lists example package purrr demonstrating:Splitting data frame saving multiple CSV filesSplitting data frame saving part separate sheet within one Excel workbookImporting multiple CSV files combining one dataframeImporting Excel workbook multiple sheets combining one dataframe","code":""},{"path":"directory-interactions.html","id":"base-r-4","chapter":"45 Directory interactions","heading":"45.8 base R","text":"See functions list.files() dir(), perform operation listing files within specified directory. can specify ignore.case = specific pattern look .file currently “open”, display folder tilde front, like “~$hospital_linelists.xlsx”.","code":"\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)"},{"path":"directory-interactions.html","id":"resources-37","chapter":"45 Directory interactions","heading":"45.9 Resources","text":"https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"version-control-and-collaboration-with-git-and-github","chapter":"46 Version control and collaboration with Git and Github","heading":"46 Version control and collaboration with Git and Github","text":"chapter presents overview using Git collaborate others.\nextensive tutorials can \nfound bottom Resources section.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"what-is-git","chapter":"46 Version control and collaboration with Git and Github","heading":"46.1 What is Git?","text":"Git version control software allows tracking changes \nfolder. can used like “track change” option Word, LibreOffice \nGoogle docs, types files. one powerful\nused options version control.never heard ? - people developer\nbackground routinely learn use version control software (Git,\nMercurial, Subversion others), us \nquantitative disciplines taught skills. Consequently, epidemiologists never\nhear studies, learn fly.Wait, heard Github, ? - exactly, \noften use together, show . short:Git version control system, piece software. can use \nlocally computer synchronize folder \nhost website. default, one uses terminal give Git\ninstructions command-line.Git version control system, piece software. can use \nlocally computer synchronize folder \nhost website. default, one uses terminal give Git\ninstructions command-line.can use Git client/interface avoid command-line \nperform actions (least simple, super common\nones).can use Git client/interface avoid command-line \nperform actions (least simple, super common\nones).want store folder host website \ncollaborate others, may create account Github,\nGitlab, Bitbucket others.want store folder host website \ncollaborate others, may create account Github,\nGitlab, Bitbucket others.use client/interface Github Desktop, uses\nGit background manage files, locally \ncomputer, remotely Github server.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"why-use-the-combo-git-and-github","chapter":"46 Version control and collaboration with Git and Github","heading":"46.2 Why use the combo Git and Github?","text":"Using Git facilitates:Archiving documented versions incremental changes \ncan easily revert backwards previous stateHaving parallel branches, .e. developing/“working” versions \nstructured ways integrate changes reviewThis can done locally computer, even don’t collaborate\npeople. ever:regretted deleted section code, realize two\nmonths later actually needed ?regretted deleted section code, realize two\nmonths later actually needed ?come back project pause attempted \nremember whether made tricky modification one \nmodels?come back project pause attempted \nremember whether made tricky modification one \nmodels?file model_1.R another file model_1_test.R file\nmodel_1_not_working.R try things ?file model_1.R another file model_1_test.R file\nmodel_1_not_working.R try things ?file report.Rmd, file report_full.Rmd, file\nreport_true_final.Rmd, file report_final_20210304.Rmd, file\nreport_final_20210402.Rmd cursed archiving skills?file report.Rmd, file report_full.Rmd, file\nreport_true_final.Rmd, file report_final_20210304.Rmd, file\nreport_final_20210402.Rmd cursed archiving skills?Git help , worth learn alone.However, becomes even powerful used online repository\nGithub support collaborative projects. facilitates:Collaboration: others can review, comment , \naccept/decline changesCollaboration: others can review, comment , \naccept/decline changesSharing code, data, outputs, invite feedback\npublic (privately, team)Sharing code, data, outputs, invite feedback\npublic (privately, team)avoids:“Oops, forgot send last version now need \nredo two days worth work new file”“Oops, forgot send last version now need \nredo two days worth work new file”Mina, Henry Oumar worked time one script \nneed manually merge changesMina, Henry Oumar worked time one script \nneed manually merge changesTwo people try modify file Dropbox Sharepoint\ncreates synchronization error.Two people try modify file Dropbox Sharepoint\ncreates synchronization error.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"this-sounds-complicated-i-am-not-a-programmer","chapter":"46 Version control and collaboration with Git and Github","heading":"This sounds complicated, I am not a programmer","text":"can . Examples advanced uses can quite scary. However, much\nlike R, even Excel, don’t need become expert reap \nbenefits tool. Learning small number functions notions\nlets track changes, synchronize files online\nrepository collaborate colleagues short amount\ntime.Due learning curve, emergency context may best time\nlearn tools. learning can achieved steps. acquire\ncouple notions, workflow can quite efficient fast.\nworking project collaborating people\nGit necessity, actually good time get\nconfident using solo diving collaboration.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"setup","chapter":"46 Version control and collaboration with Git and Github","heading":"46.3 Setup","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"install-git","chapter":"46 Version control and collaboration with Git and Github","heading":"Install Git","text":"Git engine behind scenes computer, tracks\nchanges, branches (versions), merges, reverting. must first\ninstall Git https://git-scm.com/downloads.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"install-an-interface-optional-but-recommended","chapter":"46 Version control and collaboration with Git and Github","heading":"Install an interface (optional but recommended)","text":"Git language commands, can typed command\nline terminal. However, many clients/interfaces non-developpers, \nday--day use, rarely need interact Git directly \ninterface usually provide nice visualisation tools file modifications branches.Many options exist, OS, beginner friendly complex ones.\nGood options beginners include RStudio Git pane \nGithub Desktop, showcase \nchapter.\nIntermediate (powerfull, complex) options include Source Tree,\nGitkracken, Smart Git others.Quick explanation Git clients.Note: since interfaces actually use Git internally, can try several \n, switch one another given project, use console punctually\naction interface support, even perform number \nactions online Github.noted , may occasionally write Git commands \nterminal RStudio terminal pane (tab adjacent R\nConsole) Git Bash terminal.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"github-account","chapter":"46 Version control and collaboration with Git and Github","heading":"Github account","text":"Sign-free account github.com.may offered set-two-factor authentication app \nphone. Read Github help\ndocuments.use Github Desktop, can enter Gitub credentials \ninstallation following \nsteps.\ndon’t know, credentials asked later try \nclone project Github.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"vocabulary-concepts-and-basic-functions","chapter":"46 Version control and collaboration with Git and Github","heading":"46.4 Vocabulary, concepts and basic functions","text":"learning R, bit vocabulary remember \nunderstand Git. basics get \ngoing\n/ interactive tutorial. next\nsections, show use interfaces, good\nvocabulary concepts mind, build mental model,\n’ll need using interfaces anyway.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"repository","chapter":"46 Version control and collaboration with Git and Github","heading":"Repository","text":"Git repository (“repo”) folder contains \nsub-folders files project (data, code, images, etc.) \nrevision histories. begin tracking changes \nrepository , Git create hidden folder contains\ntracking information. typical Git repository \nR Project folder (see handbook page R projects).show create (initialize) Git repository\nGithub, Github Desktop Rstudio next\nsections.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"commits","chapter":"46 Version control and collaboration with Git and Github","heading":"Commits","text":"commit snapshot project given time.\nmake change project, make new commit\ntrack changes (delta) made \nfiles. example, perhaps edited lines code updated \nrelated dataset. changes saved, can bundle \nchanges together one “commit”.commit unique ID (hash). version control purposes,\ncan revert project back time based commits, best\nkeep relatively small coherent. also attach brief\ndescription changes called “commit message”.Staged changes? stage changes add staging area\npreparation next commit. idea can finely\ndecide changes include given commit. example, \nworked model specification one script, later figure \nanother script, make sense two different commits (easier\ncase wanted revert changes figure model).","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"branches","chapter":"46 Version control and collaboration with Git and Github","heading":"Branches","text":"branch represents independent line changes repo, \nparallel, alternate version project files.Branches useful test changes incorporated \nmain branch, usually primary/final/“live” version \nproject. done experimenting branch, can bring\nchanges main branch, merging , delete , \nchanges successful.Note: collaborate people use branches,\nneed remote online repository.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"local-and-remote-repositories","chapter":"46 Version control and collaboration with Git and Github","heading":"Local and remote repositories","text":"clone create copy Git repository another place.example, can clone online repository Github locally \ncomputer, begin local repository clone\nonline Github.cloned repository, project files exist \ntwo places:LOCAL repository physical computer. \nmake actual changes files/code.LOCAL repository physical computer. \nmake actual changes files/code.REMOTE, online repository: versions project files\nGithub repository (web\nhost).REMOTE, online repository: versions project files\nGithub repository (web\nhost).synchronize repositories, use functions. Indeed,\nunlike Sharepoint, Dropbox synchronizing software, Git \nautomatically update local repository based ’s online,\nvice-versa. get choose synchronize.git fetch downloads new changes remote repository \nchange local repository. Think checking state remote repository.git fetch downloads new changes remote repository \nchange local repository. Think checking state remote repository.git pull downloads new changes remote repositories\nupdate local repository.git pull downloads new changes remote repositories\nupdate local repository.made one several commits locally, can\ngit push commits remote repository. sends \nchanges Github people can see pull \nwant .made one several commits locally, can\ngit push commits remote repository. sends \nchanges Github people can see pull \nwant .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"get-started-create-a-new-repository","chapter":"46 Version control and collaboration with Git and Github","heading":"46.5 Get started: create a new repository","text":"many ways create new repositories. can \nconsole, Github, interface.Two general approaches set-:Create new R Project existing new Github repository\n(preferred beginners), orCreate Github repository existing R project","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"start-up-files","chapter":"46 Version control and collaboration with Git and Github","heading":"Start-up files","text":"create new repository, can optionally create\nfiles, can add repository later stage.\ntypically live “root” folder repository.README file file someone can read understand \nproject exists else know use . \nempty first, complete later.README file file someone can read understand \nproject exists else know use . \nempty first, complete later..gitignore file text file line contain\nfolders files Git ignore (track changes). Read\nsee examples\n..gitignore file text file line contain\nfolders files Git ignore (track changes). Read\nsee examples\n.can choose license work, people\nknow conditions can use reproduce work. \ninformation, see Creative Commons\nlicenses.can choose license work, people\nknow conditions can use reproduce work. \ninformation, see Creative Commons\nlicenses.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"create-a-new-repository-in-github","chapter":"46 Version control and collaboration with Git and Github","heading":"Create a new repository in Github","text":"create new repository, log Github look green\nbutton create new repository. now empty repository can \ncloned locally computer (see next section).must choose want repository public (visible \neveryone internet) private (visible \npermission). important implications data sensitive.\nrepository private encounter quotas advanced\nspecial circumstances, using Github actions \nautomatically run code cloud.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"clone-from-a-github-repository","chapter":"46 Version control and collaboration with Git and Github","heading":"Clone from a Github repository","text":"can clone existing Github repository create\nnew local R project computer.Github repository one already exists contains\ncontent, empty repository just created. \nlatter case essentially creating Github repo local R\nproject time (see instructions ).Note: contributing rights Github repository,\npossible first fork repository profile, \nproceed actions. Forking explained end \nchapter, recommend read sections first.Step 1: Navigate Github repository, click green “Code”\nbutton copy HTTPS clone URL (see image )next step can performed interface. illustrate \nRstudio Github desktop.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-rstudio","chapter":"46 Version control and collaboration with Git and Github","heading":"In Rstudio","text":"RStudio, start new R project clicking File > New Project >\nVersion Control > GitWhen prompted “Repository URL”, paste HTTPS URL \nGithubAssign R project short, informative nameChoose new R Project saved locallyCheck “Open new session” click “Create project”now new, local, RStudio project clone \nGithub repository. local project Github repository now\nlinked.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-desktop","chapter":"46 Version control and collaboration with Git and Github","heading":"In Github Desktop","text":"Click File > Clone repositoryClick File > Clone repositorySelect URL tabSelect URL tabPaste HTTPS URL Github first boxPaste HTTPS URL Github first boxSelect folder want local repositorySelect folder want local repositoryClick “CLONE”Click “CLONE”","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"new-github-repo-from-existing-r-project","chapter":"46 Version control and collaboration with Git and Github","heading":"New Github repo from existing R project","text":"alternative setup scenario existing R project\ncontent, want create Github repository .Create new, empty Github repository project (see\ninstructions )Clone repository locally (see HTTPS instructions )Copy content pre-existing R\nproject (codes, data, etc.) new empty, local, repository (e.g. use copy paste).Open new project RStudio, go Git pane. new files \nregister file changes, now tracked Git. Therefore, can\nbundle changes commit push Github.\npushed, repository Github reflect files.See Github workflow section details process.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"what-does-it-look-like-now","chapter":"46 Version control and collaboration with Git and Github","heading":"What does it look like now?","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-rstudio-1","chapter":"46 Version control and collaboration with Git and Github","heading":"In RStudio","text":"cloned Github repository new R project,\nnow see RStudio “Git” tab. tab appears RStudio pane\nR Environment:Please note buttons circled image , \nreferenced later (left right):Button commit saved file changes local\nbranch (open new window)Blue arrow pull (update local version branch \nchanges made remote/Github version branch)Green arrow push (send commits/changes local\nversion branch remote/Github version branch)Git tab RStudioButton create NEW branch using whichever local branch shown\nright base. almost always want branch \nmain branch (first pull update main branch)branch currently working inChanges made code files appear ","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-desktop-1","chapter":"46 Version control and collaboration with Git and Github","heading":"In Github Desktop","text":"Github Desktop independent application allows manage\nrepositories. open , interface allows \nchoose repository want work , perform basic Git\nactions .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"git-github-workflow","chapter":"46 Version control and collaboration with Git and Github","heading":"46.6 Git + Github workflow","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"process-overview","chapter":"46 Version control and collaboration with Git and Github","heading":"Process overview","text":"completed setup (described ), \nGithub repo connected (cloned) local R project. \nmain branch (created default) -called “live” version \nfiles. want make modifications, good\npractice create new branch main branch (like “Make \nCopy”). typical workflow Git creating branch \neasy fast.typical workflow follow:Make sure local repository --date, update \nnotMake sure local repository --date, update \nnotGo branch working previously, create new\nbranch try thingsGo branch working previously, create new\nbranch try thingsWork files locally computer, make one several\ncommits branchWork files locally computer, make one several\ncommits branchUpdate remote version branch changes (push)Update remote version branch changes (push)satisfied branch, can merge online\nversion working branch online “main” branch \ntransfer changesWhen satisfied branch, can merge online\nversion working branch online “main” branch \ntransfer changesOther team members may thing branches,\nperhaps contributing commits working branch well.go process step--step detail .\nschematic ’ve developed - ’s format two-way\ntable help epidemiologists understand.’s another diagram.Note: recently, term “master” branch used, now\nreferred “main” branch.Image\nsource","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"create-a-new-branch","chapter":"46 Version control and collaboration with Git and Github","heading":"46.7 Create a new branch","text":"select branch work , Git resets working directory\nway last time branch.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-rstudio-git-pane","chapter":"46 Version control and collaboration with Git and Github","heading":"In Rstudio Git pane","text":"Ensure “main” branch, click purple icon \ncreate new branch (see image ).prompted name branch one-word descriptive\nname (can use underscores needed).see locally, still R project, \nlonger working “main” branch.created, new branch also appear Github website\nbranch.can visualize branches Git Pane Rstudio clicking “History”","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-desktop-2","chapter":"46 Version control and collaboration with Git and Github","heading":"In Github Desktop","text":"process much similar, prompted give branch\nname. , prompted “Publish branch Github” \nmake new branch appear remote repo well.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-console","chapter":"46 Version control and collaboration with Git and Github","heading":"In console","text":"actually happening behind scenes create new\nbranch git branch, go branch \ngit checkout (.e. tell Git next commits occur ).\ngit repository:information using console, see section \nGit commands end.","code":"git branch my-new-branch  # Create the new branch branch\ngit checkout my-new-branch # Go to the branch\ngit checkout -b my-new-branch # Both at once (shortcut)"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"commit-changes","chapter":"46 Version control and collaboration with Git and Github","heading":"46.8 Commit changes","text":"Now can edit code, add new files, update datasets, etc.Every one changes tracked, respective file \nsaved. Changed files appear RStudio Git tab, Github\nDesktop, using command git status terminal (see ).Whenever make substantial changes (e.g. adding updating section \ncode), pause commit changes. Think commit “batch”\nchanges related common purpose. can always continue \nrevise file committed changes .Advice commits: generally, better make small commits, \ncan easily reverted problem arises, commit together\nmodifications related common purpose. achieve , \nfind commit often. beginning, ’ll probably\nforget commit often, habit kicks .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-rstudio-2","chapter":"46 Version control and collaboration with Git and Github","heading":"In Rstudio","text":"example shows , since last commit, R Markdown script “collaboration.Rmd” changed,\nseveral PNG images added.might wondering yellow, blue, green, red squares next \nfile names represent. snapshot RStudio\ncheatsheet\nexplains meaning. Note changes yellow “?” can still\nstaged, committed, pushed.Press “Commit” button Git tab, open new\nwindow (shown )Press “Commit” button Git tab, open new\nwindow (shown )Click file name upper-left boxClick file name upper-left boxReview changes made file (highlighted green\nred)Review changes made file (highlighted green\nred)“Stage” file, include changes commit. \nchecking box next file name. Alternatively, \ncan highlight multiple file names click “Stage”“Stage” file, include changes commit. \nchecking box next file name. Alternatively, \ncan highlight multiple file names click “Stage”Write commit message short descriptive (required)Write commit message short descriptive (required)Press “Commit” button. pop-box appear showing success\nerror message.Press “Commit” button. pop-box appear showing success\nerror message.Now can make changes commits, many times like","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-desktop-3","chapter":"46 Version control and collaboration with Git and Github","heading":"In Github Desktop","text":"can see list files changed left. \nselect text file, see summary modifications made\nright pane (view work complex files like .docs .xlsx).stage changes, just tick little box near file names. \nselected files want add commit, give commit\nname, optionally description click commit\nbutton.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-console-1","chapter":"46 Version control and collaboration with Git and Github","heading":"In console","text":"two functions used behind scenes git add select/stage\nfiles git commit actually commit.","code":"git status # see the changes \n\ngit add new_pages/collaboration.Rmd  # select files to commit (= stage the changes)\n\ngit commit -m \"Describe commit from Github Desktop\" # commit the changes with a message\n\ngit log  # view information on past commits"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"amend-a-previous-commit","chapter":"46 Version control and collaboration with Git and Github","heading":"Amend a previous commit","text":"happens commit changes, carry working, realize\nmade changes “belong” past commit (opinion).\nFear ! can append changes previous commit.Rstudio, pretty obvious “Amend previous commit”\nbox line COMMIT button.unclear reason, functionality implemented\nGithub Desktop, (conceptually awkward easy)\nway around. committed pushed changes yet,\n“UNDO” button appears just COMMIT button. Click \nrevert commit (keep staged files commit message).\nSave changes, add new files commit necessary commit .console:Note: think modifying commits already public shared collaborators.","code":"git add [YOUR FILES] # Stage your new changes\n\ngit commit --amend  # Amend the previous commit\n\ngit commit --amend -m \"An updated commit message\"  # Amend the previous commit AND update the commit message"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"pull-and-push-changes-up-to-github","chapter":"46 Version control and collaboration with Git and Github","heading":"46.9 Pull and push changes up to Github","text":"“First PULL, PUSH”good practice fetch pull begin working \nproject, update branch version local computer \nchanges made remote/Github version.PULL often. Don’t hesitate. Always pull pushing.changes made committed happy \nstate project, can push commits \nremote/Github version branch.Rince repeat working repository.Note: much easier revert changes committed \npushed (.e. still local) revert changes pushed \nremote repository (perhaps already pulled someone else), better\npush done introducing changes task \nworking .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-rstudio-3","chapter":"46 Version control and collaboration with Git and Github","heading":"In Rstudio","text":"PULL - First, click “Pull” icon (downward arrow) fetches \npulls time.PUSH - Clicking green “Pull” icon (upward arrow). may asked\nenter Github username password. first time \nasked, may need enter two Git command lines Terminal:git config –global user.email\n“@example.com” (Github\nemail address), andgit config –global user.name “Github username”learn enter commands, see section \nGit commands.TIP: Asked provide password often? See chapters\n10 & 11 \ntutorial\nconnect repository using SSH key (\ncomplicated)","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-desktop-4","chapter":"46 Version control and collaboration with Git and Github","heading":"In Github Desktop","text":"Click “Fetch origin” button check new commits \nremote repository.Git finds new commits remote repository, button \nchange “Pull” button. button used push \npull, push changes don’t pull .can go “History” tab (near “Changes” tab) see \ncommits (others). nice way acquainting \ncollaborators . can read commit message, \ndescription one, compare code two files using\ndiff pane.remote changes pulled, least one local change\ncommitted, can push clicking button.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"console","chapter":"46 Version control and collaboration with Git and Github","heading":"Console","text":"Without surprise, commands fetch, pull push.","code":"git fetch  # are there new commits in the remote directory?\ngit pull   # Bring remote commits into your local branch\ngit push   # Puch local commits of this branch to the remote branch"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"i-want-to-pull-but-i-have-local-work","chapter":"46 Version control and collaboration with Git and Github","heading":"I want to pull but I have local work","text":"can happen sometimes:\nmade changes local repository, remote\nrepository commits didn’t pull.Git refuse pull might overwrite changes.\nseveral strategies keep changes,\nwell described Happy Git R,\namong two main ones :\n- commit changes, fetch remote changes, pull , resolve conflicts\nneeded (see section ), push everything online\n- stash changes, sort stores aside, pull, unstash\n(restore), commit, solve conflicts, push.files concerned remote changes files concerned\nlocal changes overlap, Git may solve conflicts automatically.Github Desktop, can done buttons. stash, go Branch > Stash changes.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"merge-branch-into-main","chapter":"46 Version control and collaboration with Git and Github","heading":"46.10 Merge branch into Main","text":"finished making changes, can begin process \nmerging changes main branch. Depending situation,\nmay fast, may deliberate review approval\nsteps involving teammates.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"locally-in-github-desktop","chapter":"46 Version control and collaboration with Git and Github","heading":"Locally in Github Desktop","text":"One can merge branches locally using Github Desktop. First, go \n(checkout) branch recipient commits, words, \nbranch want update. go menu Branch > Merge \ncurrent branch click. box allow select branch \nwant import .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-console-2","chapter":"46 Version control and collaboration with Git and Github","heading":"In console","text":"First move back branch recipient changes.\nusually master, another branch. merge \nworking branch master.\npage\nshows advanced example branching explains bit \nhappening behind scenes.","code":"git checkout master  # Go back to master (or to the branch you want to move your )\ngit merge this_fancy_new_branch"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-submitting-pull-requests","chapter":"46 Version control and collaboration with Git and Github","heading":"In Github: submitting pull requests","text":"totally possible merge two branches locally, without\ninforming anybody, merge may discussed investigated several\npeople integrated master branch. help \nprocess, Github offers discussion features around merge: \npull request.pull request (“PR”) request merge one branch another\n(words, request working branch pulled “main” branch).\npull request typically involves multiple commits. pull request usually begins conversation review\nprocess accepted branch merged. example,\ncan read pull request discussions dplyr’s\ngithub.can submit pull request (PR) directly form website (\nillustrated bellow) Github Desktop.Go Github repository (online)View tab “Pull Requests” click “New pull request” buttonSelect drop-menu merge branch mainWrite detailed Pull Request comment click “Create Pull\nRequest”.image , branch “forests” selected merged\n“main”:Now able see pull request (example image ):Review tab “Files changed” see “main” branch \nchange branch merged.right, can request review members team \ntagging Github ID. like, can set repository\nsettings require one approving review order merge \nmain.pull request approved, button \n“Merge pull request” become active. Click .completed, delete branch explained .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"resolving-conflicts","chapter":"46 Version control and collaboration with Git and Github","heading":"Resolving conflicts","text":"two people modified line(s) time, \nmerge conflict arises. Indeed, Git refuses make decision \nversion keep, helps find \nconflict . PANIC. time, pretty straightforward\nresolve.example, Github:merge raised conflict, open file favorite editor.\nconflict indicated series characters:text <<<<<<< HEAD ======= comes \nlocal repository, one ======= >>>>>>> \nbranch (may origin, master branch \nchoice).need decide version code prefer (even write \nthird, including changes sides pertinent), delete rest\nremove marks Git added (<<<<<<< HEAD, =======,\n>>>>>>> origin/master/your_branch_name)., save file, stage commit : commit\nmakes merged version “official”. forget push afterwards.often collaborators pull push, smaller \nconflicts .Note: feel ease console, advanced\nmerging\noptions\n(e.g. ignoring whitespace, giving collaborator priority etc.).","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"delete-your-branch","chapter":"46 Version control and collaboration with Git and Github","heading":"Delete your branch","text":"branch merged master longer needed, can\ndelete .","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"github-rstudio","chapter":"46 Version control and collaboration with Git and Github","heading":"46.10.0.1 Github + Rstudio","text":"Go repository Github click button view \nbranches (next drop-select branches). Now find \nbranch click trash icon next . Read detail deleting\nbranch\n.sure also delete branch locally computer. \nhappen automatically.RStudio, make sure Main branchSwitch typing Git commands RStudio “Terminal” (tab\nadjacent R console), type: git branch -d\nbranch_name, “branch_name” name branch \ndeletedRefresh Git tab branch gone","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"in-github-desktop-5","chapter":"46 Version control and collaboration with Git and Github","heading":"46.10.0.2 In Github Desktop","text":"Just checkout branch want delete, go menu\nBranch > Delete.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"forking","chapter":"46 Version control and collaboration with Git and Github","heading":"Forking","text":"can fork project like contribute \nrights , just\nwant modify personal use. \nshort description forking can found .Github, click “Fork” button:clone original repository, profile. now,\ntwo versions repository Github: original one,\nmodify, cloned version profile., can proceed clone version online repository locally\ncomputer, using methods described previous sections.\n, can create new branch, make changes, commit push \nremote repository.happy result can create Pull Request\nGithub Github Desktop begin conversation \nowners/maintainers original repository.need newer commits official repository?Imagine someone makes critical modification official repository,\nwant include cloned version.\npossible synchronize fork official repository.\ninvolves using terminal, complicated.\nmostly need remember :\n- upstream = official repository, one modify\n- origin = version repository Github profileYou can read tutorial follow along :First, type Git terminal (inside repo):yet configured upstream repository \nsee two lines, beginning origin. show remote repo\nfetch push point . Remember, origin conventional\nnickname version repository Github. example:Now, add new remote repository:address address Github generates clone\nrepository (see section cloning). Now four remote pointers:Now setup done, whenever want get changes \noriginal (upstream) repository, just go (checkout) \nbranch want update type:conflicts, solve , explained\nResolving conflicts section.Summary: forking cloning, Github server side.\nrest actions typical collaboration workflow actions\n(clone, push, pull, commit, merge, submit pull requests…).Note: forking concept, Git command, also exist Web hosts, like Bitbucket.","code":"git remote -vgit remote add upstream https://github.com/appliedepi/epirhandbook_eng.gitgit fetch upstream # Get the new commits from the remote repository\ngit checkout the_branch_you_want_to_update\ngit merge upstream/the_branch_you_want_to_update  # Merge the upstream branch into your branch.\ngit push # Update your own version of the remote repo"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"what-we-learned","chapter":"46 Version control and collaboration with Git and Github","heading":"46.11 What we learned","text":"learned :setup Git track modifications folders,connect local repository remote online repository,commit changes,synchronize local remote repositories.get going enough needs \nepidemiologists. usually advanced usage developers.However, know want (need) go , Git offers power simplify\ncommit histories, revert one several commits, cherry-pick commits, etc.\nmay sound like pure wizardry, now basics,\neasier build .Note Git pane Rstudio Github Desktop good \nbeginners / day--day usage line work, offer \ninterface intermediate / advanced Git functions.\ncomplete interfaces allows point--click\n(usually cost complex layout).Remember since can use tool point track repository,\ncan easily install interface try sometimes,\nperform less common complex task occasionally,\npreferring simplified interface rest time (e.g. using\nGithub Desktop time, switching SourceTree Gitbash specific tasks).","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"git","chapter":"46 Version control and collaboration with Git and Github","heading":"46.12 Git commands","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"recommended-learning","chapter":"46 Version control and collaboration with Git and Github","heading":"Recommended learning","text":"learn Git commands interactive tutorial, see \nwebsite.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"where-to-enter-commands","chapter":"46 Version control and collaboration with Git and Github","heading":"Where to enter commands","text":"enter commands Git shell.Option 1 can open new Terminal RStudio. tab next \nR Console. type text , click \ndrop-menu “Terminal” select “New terminal”. Type \ncommands blinking space front dollar sign “$”.Option 2 can also open shell (terminal enter commands) \nclicking blue “gears” icon Git tab (near RStudio\nEnvironment). Select “Shell” drop-menu. new window \nopen can type commands dollar sign “$”.Option 3 Right click open “Git Bash ” open \nsort terminal, open Git Bash form application list.\nbeginner-friendly informations Git Bash,\nfind bash commands need.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"sample-commands","chapter":"46 Version control and collaboration with Git and Github","heading":"Sample commands","text":"present common git commands. use , keep mind\nbranch active (checked-), change action!commands ,  represents branch name.\n represents hash ID specific\ncommit.  represents number. type \n< > symbols.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"resources-38","chapter":"46 Version control and collaboration with Git and Github","heading":"46.13 Resources","text":"Much page informed “Happy Git R”\nwebsite Jenny Bryan. helpful\nsection website helps troubleshoot common Git \nR-related errors.Github.com documentation start\nguide.RStudio “IDE”\ncheatsheet\nincludes tips Git RStudio.https://ohi-science.org/news/github-going-back--timeGit commands beginnersAn interactive\ntutorial learn\nGit commands.https://www.freecodecamp.org/news/-introduction--git--absolute-beginners-86fa1d32ff71/:\ngood learning absolute basics track changes one folder \ncomputer.Nice schematics understand branches:\nhttps://speakerdeck.com/alicebartlett/git--humansTutorials covering basic advanced subjectshttps://tutorialzine.com/2016/06/learn-git--30-minuteshttps://dzone.com/articles/git-tutorial-commands--operations--git\nhttps://swcarpentry.github.io/git-novice/ (short course)\nhttps://rsjakob.gitbooks.io/git/content/chapter1.htmlThe Pro Git book considered official reference.\nchapters ok, usually bit technical. probably good resource\nused Git bit want learn bit precisely\nhappens go .","code":""},{"path":"common-errors.html","id":"common-errors","chapter":"47 Common errors","heading":"47 Common errors","text":"page includes running list common errors suggests solutions troubleshooting .","code":""},{"path":"common-errors.html","id":"interpreting-error-messages","chapter":"47 Common errors","heading":"47.1 Interpreting error messages","text":"R errors can cryptic times, Google friend. Search error message “R” look recent posts StackExchange.com, stackoverflow.com, community.rstudio.com, twitter (#rstats), forums used programmers filed questions answers. Try find recent posts solved similar problems.much searching find answer problem, consider creating reproducible example (“reprex”) posting question . See page Getting help tips create post reproducible example forums.","code":""},{"path":"common-errors.html","id":"common-errors-1","chapter":"47 Common errors","heading":"47.2 Common errors","text":", list common errors potential explanations/solutions. borrowed Noam Ross analyzed common forum posts Stack Overflow R error messages (see analysis )","code":""},{"path":"common-errors.html","id":"typo-errors","chapter":"47 Common errors","heading":"Typo errors","text":"see “unexpected symbol”, check missing commas","code":"Error: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\""},{"path":"common-errors.html","id":"package-errors","chapter":"47 Common errors","heading":"Package errors","text":"likely means typed function name incorrectly, forgot install load package.think using dplyr::select() select() function masked MASS::select() - specify dplyr:: re-order package loading dplyr others.common masking errors stem : plyr::summarise() stats::filter(). Consider using conflicted package.get error saying need remove “00LOCK” file, go “R” library computer directory (e.g. R/win-library/) look folder called “00LOCK”. Delete manually, try installing package . previous install process probably interrupted, led .","code":"could not find function \"x\"...Error in select(data, var) : unused argument (var)Error in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’"},{"path":"common-errors.html","id":"object-errors","chapter":"47 Common errors","heading":"Object errors","text":"see error like try export import: Check spelling file filepath, path contains slashes make sure forward / backward \\. Also make sure used correct file extension (e.g. .csv, .xlsx).means object referencing exist. Perhaps code run properly?means tried access something (element vector list) .","code":"No such file or directory:object 'x' not found Error in 'x': subscript out of bounds"},{"path":"common-errors.html","id":"function-syntax-errors","chapter":"47 Common errors","heading":"Function syntax errors","text":"error (argument .x missing, default) common mutate() supplying function like recode() replace_na() expects provide column name first argument. easy forget.","code":"# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`."},{"path":"common-errors.html","id":"logic-errors","chapter":"47 Common errors","heading":"Logic errors","text":"likely means statement applied something TRUE FALSE.","code":"Error in if"},{"path":"common-errors.html","id":"factor-errors","chapter":"47 Common errors","heading":"Factor errors","text":"see error invalid factor levels, likely column class Factor (contains pre-defined levels) tried add new value . Convert class Character adding new value.","code":"#Tried to add a value (\"Missing\") to a factor (with replace_na operating on a factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated"},{"path":"common-errors.html","id":"plotting-errors","chapter":"47 Common errors","heading":"Plotting errors","text":"Error: Insufficient values manual scale. 3 needed 2 provided.\nggplot() scale_fill_manual() values = c(“orange”, “purple”) … insufficient number factor levels … consider whether NA now factor level…probably extra + end ggplot command need delete.","code":"Can't add x object"},{"path":"common-errors.html","id":"r-markdown-errors","chapter":"47 Common errors","heading":"R Markdown errors","text":"error message contains something like Error options[[sprintf(\"fig.%s\", )]], check knitr options top chunk correctly use .width = .height = fig.width= fig.height=.","code":""},{"path":"common-errors.html","id":"miscellaneous-2","chapter":"47 Common errors","heading":"Miscellaneous","text":"Consider whether re-arranged piped dplyr verbs didn’t replace pipe middle, didn’t remove pipe end re-arranging.","code":""},{"path":"common-errors.html","id":"resources-39","chapter":"47 Common errors","heading":"47.3 Resources","text":"another blog post lists common R programming errors faced beginners","code":""},{"path":"getting-help.html","id":"getting-help","chapter":"48 Getting help","heading":"48 Getting help","text":"page covers get help posting Github issue posting reproducible example (“reprex”) online forum.","code":""},{"path":"getting-help.html","id":"github-issues","chapter":"48 Getting help","heading":"48.1 Github issues","text":"Many R packages projects code hosted website Github.com. can communicate directly authors via website posting “Issue”.Read store work Github page [Collaboration Github].Github, project contained within repository. repository contains code, data, outputs, help documentation, etc. also vehicle communicate authors called “Issues”.See Github page incidence2 package (used make epidemic curves). can see “Issues” tab highlighted yellow. can see 5 open issues.Issues tab, can see open issues. Review ensure problem already addressed. can open new issue clicking green button right. need Github account .issue, follow instructions provide minimal, reproducible example. please courteous! people developing R packages projects spare time (like handbook!).read advanced materials handling issues Github repository, check Github documentation Issues.","code":""},{"path":"getting-help.html","id":"reproducible-example","chapter":"48 Getting help","heading":"48.2 Reproducible example","text":"Providing reproducible example (“reprex”) key getting help posting forum Github issue. People want help , give example can work computer. example :Demonstrate problem encounteredBe minimal, includes data code required reproduce problemBe reproducible, objects (e.g. data), package calls (e.g. library() p_load()) includedAlso, sure post sensitive data reprex! can create example data frames, use one data frames built R (enter data() open list datasets).","code":""},{"path":"getting-help.html","id":"the-reprex-package","chapter":"48 Getting help","heading":"The reprex package","text":"reprex package can assist making reproducible example:reprex installed tidyverse, load either packageBegin R script creates problem, step--step, starting loading packages data.Copy code clipboard, run following command:see HTML output appear RStudio Viewer pane. contain code warnings, errors, plot outputs. output also copied clipboard, can post directly Github issue forum post.set session_info = TRUE output sessioninfo::session_info() R R package versions includedYou can provide working directory wd =can read arguments possible variations documentation entering ?reprexIn example , ggplot() command run arguemnt date_format = correct - date_labels =.","code":"\n# install/load tidyverse (which includes reprex)\npacman::p_load(tidyverse)\n# load packages\npacman::p_load(\n     tidyverse,  # data mgmt and vizualization\n     outbreaks)  # example outbreak datasets\n\n# flu epidemic case linelist\noutbreak_raw <- outbreaks::fluH7N9_china_2013  # retrieve dataset from outbreaks package\n\n# Clean dataset\noutbreak <- outbreak_raw %>% \n     mutate(across(contains(\"date\"), as.Date))\n\n# Plot epidemic\n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\nreprex::reprex()"},{"path":"getting-help.html","id":"minimal-data","chapter":"48 Getting help","heading":"Minimal data","text":"helpers need able use data - ideally need able create code.create minumal dataset, consider anonymising using subset observations.CONSTRUCTION - can also use function dput() create minimal dataset.","code":""},{"path":"getting-help.html","id":"posting-to-a-forum","chapter":"48 Getting help","heading":"48.3 Posting to a forum","text":"Read lots forum posts. Get understanding posts well-written, ones .First, decide whether ask question . thoroughly reviewed forum website, trying various search terms, see question already asked?First, decide whether ask question . thoroughly reviewed forum website, trying various search terms, see question already asked?Give question informative title (“Help! isn’t working”).Give question informative title (“Help! isn’t working”).Write question:Write question:Introduce situation problemLink posts similar issues explain answer questionInclude relevant information help someone know context workGive minimal reproducible example R session informationUse proper spelling, grammar, punctuation, break question paragraphs easier readMonitor question posted respond requests clarification. courteous gracious - often people answering volunteering time help . follow-question consider whether separate posted question.Monitor question posted respond requests clarification. courteous gracious - often people answering volunteering time help . follow-question consider whether separate posted question.Mark question answered, get answer meets original request. helps others later quickly recognize solution.Mark question answered, get answer meets original request. helps others later quickly recognize solution.Read posts ask good question Stack overflow code conduct.","code":""},{"path":"getting-help.html","id":"resources-40","chapter":"48 Getting help","heading":"48.4 Resources","text":"Tidyverse page get help!Tips producing minimal datasetDocumentation dput function","code":""},{"path":"r-on-network-drives.html","id":"r-on-network-drives","chapter":"49 R on network drives","heading":"49 R on network drives","text":"","code":""},{"path":"r-on-network-drives.html","id":"overview-9","chapter":"49 R on network drives","heading":"49.1 Overview","text":"Using R network “company” shared drives can present additional challenges. page contains approaches, common errors, suggestions troubleshooting gained experience working issues. include tips particularly delicate situations involving R Markdown.Using R Network Drives: Overarching principlesYou must get administrator access computer. Setup RStudio specifically run administrator.Save packages library lettered drive (e.g. “C:”) possible. Use package library whose path begins “\\\" little possible.rmarkdown package must “\\\" package library, can’t connect TinyTex Pandoc.","code":""},{"path":"r-on-network-drives.html","id":"rstudio-as-administrator","chapter":"49 R on network drives","heading":"49.2 RStudio as administrator","text":"click RStudio icon open RStudio, right-click. Depending machine, may see option “Run Administrator”. Otherwise, may see option select Properties (appear window option “Compatibility”, can select checkbox “Run Administrator”).","code":""},{"path":"r-on-network-drives.html","id":"useful-commands","chapter":"49 R on network drives","heading":"49.3 Useful commands","text":"useful commands trying troubleshoot issues using R network drives.can return path(s) package libraries R using. listed order R using install/load/search packages. Thus, want R use different default library, can switch order paths (see ).may want switch order package libraries used R. example R picking library location begins “\\\" one begins letter e.g. ”D:“. can adjust order .libPaths() following code.difficulties R Markdown connecting Pandoc, begin code find RStudio thinks Pandoc installation .want see library package loading , try code:","code":"\n# Find libraries\n.libPaths()                   # Your library paths, listed in order that R installs/searches. \n                              # Note: all libraries will be listed, but to install to some (e.g. C:) you \n                              # may need to be running RStudio as an administrator (it won't appear in the \n                              # install packages library drop-down menu) \n# Switch order of libraries\n# this can effect the priority of R finding a package. E.g. you may want your C: library to be listed first\nmyPaths <- .libPaths() # get the paths\nmyPaths <- c(myPaths[2], myPaths[1]) # switch them\n.libPaths(myPaths) # reassign them\n# Find Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\")  # Find where RStudio thinks your Pandoc installation is\n# Find a package\n# gives first location of package (note order of your libraries)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\")) "},{"path":"r-on-network-drives.html","id":"troubleshooting-common-errors","chapter":"49 R on network drives","heading":"49.4 Troubleshooting common errors","text":"“Failed compile…tex rmarkdown”Check installation TinyTex, install TinyTex C: location. See R basics page install TinyTex.Internet routines loadedFor example, Error tools::startDynamicHelp() : internet routines loadedTry selecting 32-bit version RStudio via Tools/Global Options.\nnote: 32-bit version appear menu, make sure using RStudio v1.2.\nnote: 32-bit version appear menu, make sure using RStudio v1.2.Alternatively, try uninstalling R re-installing different bit version (32 instead 64)C: library appear option try install packages manuallyRun RStudio administrator, option appear.set-RStudio always run administrator (advantageous using Rproject don’t click RStudio icon open)… right-click Rstudio iconThe image shows can manually select library install package . window appears open Packages RStudio pane click “Install”.Pandoc 1 errorIf getting “pandoc error 1” knitting R Markdowns scripts network drives:multiple library locations, one lettered drive listed first (see codes )solution worked knitting local drive networked internet connectionSee tips : https://ciser.cornell.edu/rmarkdown-knit--html-word-pdf/Pandoc Error 83The error look something like : find file...rmarkdown...lua.... means unable find file.See https://stackoverflow.com/questions/58830927/rmarkdown-unable--locate-lua-filter--knitting--wordPossibilities:Rmarkdown package installedRmarkdown package findableAn admin rights issue.possible R able find rmarkdown package file, check library rmarkdown package lives (see code ). package installed library inaccessible (e.g. starts “\\\") consider manually moving C: named drive library. aware rmarkdown package able connect TinyTex installation, can live library network drive.Pandoc Error 61For example: Error: pandoc document conversion failed error 61 fetch...Try running RStudio administrator (right click icon, select run admin, see instructions)Also see specific package unable reached can moved C: library.LaTex error (see )error like: ! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' found: using draft setting. Error: LaTeX failed compile file_name.tex.See https://yihui.org/tinytex/r/#debugging debugging tips.See file_name.log info.Pandoc Error 127This RAM (space) issue. Re-start R session try .Mapping network drivesMapping network drive can risky. Consult department attempting .tip borrowed forum discussion:one open file “mapped network drive”?First, ’ll need know network location ’re trying access.Next, Windows file manager, need right click “PC” right hand pane, select “Map network drive”.Go dialogue define network location earlier lettered drive.Now two ways get file ’re opening. Using drive-letter path work.Error install.packages()get error includes mention “lock” directory, example: Error install.packages : ERROR: failed lock directory...Look package library see folder whose name begins “00LOCK”. Try following tips:Manually delete “00LOCK” folder directory package library. Try installing package .can also try command pacman::p_unlock() (can also put command Rprofile runs every time project opens.). try installing package . may take several tries.Try running RStudio Administrator mode, try installing packages one--one.else fails, install package another library folder (e.g. Temp) manually copy package’s folder desired library.","code":"\n# check/install tinytex, to C: location\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # should return TRUE (note three colons)"},{"path":"data-table.html","id":"data-table","chapter":"50 Data Table","heading":"50 Data Table","text":"handbook focusses dplyr “verb” functions magrittr pipe operator %>% method clean group data, data.table package offers alternative method may encounter R career.","code":""},{"path":"data-table.html","id":"intro-to-data-tables","chapter":"50 Data Table","heading":"50.1 Intro to data tables","text":"data table 2-dimensional data structure like data frame allows complex grouping operations performed. data.table syntax structured operations can performed rows, columns groups.structure DT[, j, ], separated 3 parts; , j arguments. argument allows subsetting required rows, j argument allows operate columns argument allows operate columns groups.page address following topics:Importing data use fread() fwrite()Selecting filtering rows using argumentUsing helper functions %like%, %chin%, %%Selecting computing columns using j argumentComputing groups using argumentAdding updating data data tables using :=","code":""},{"path":"data-table.html","id":"load-packages-and-import-data","chapter":"50 Data Table","heading":"50.2 Load packages and import data","text":"","code":""},{"path":"data-table.html","id":"load-packages-34","chapter":"50 Data Table","heading":"Load packages","text":"Using p_load() function pacman, load (install necessary) packages required analysis.","code":"\npacman::p_load(\n  rio,        # to import data\n  data.table, # to group and clean data\n  tidyverse,  # allows use of pipe (%>%) function in this chapter\n  here \n  ) "},{"path":"data-table.html","id":"import-data-29","chapter":"50 Data Table","heading":"Import data","text":"page explore core functions data.table using case linelist referenced throughout handbook.import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions [Download book data] page. dataset imported using import() function rio package. See page Import export various ways import data. use data.table() convert data frame data table.fread() function used directly import regular delimited files, .csv files, directly data table format. function, counterpart, fwrite(), used writing data.tables regular delimited files fast computationally efficient options large databases.first 20 rows linelist:Base R commands dim() used data frames can also used data tables","code":"\nlinelist <- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %>% data.table()\ndim(linelist) #gives the number of rows and columns in the data table## [1] 5888   30"},{"path":"data-table.html","id":"the-i-argument-selecting-and-filtering-rows","chapter":"50 Data Table","heading":"50.3 The i argument: selecting and filtering rows","text":"Recalling DT[, j, ] structure, can filter rows using either row numbers logical expressions. argument first; therefore, syntax DT[] DT[,] can used.first example retrieves first 5 rows data table, second example subsets cases 18 years , third example subsets cases 18 years old diagnosed Central Hospital:Using .N argument represents total number rows data table. can used subset row numbers:","code":"\nlinelist[1:5] #returns the 1st to 5th row\nlinelist[age >= 18] #subsets cases are equal to or over 18 years\nlinelist[age >= 18 & hospital != \"Central Hospital\"] #subsets cases equal to or over 18 years old but not diagnosed at the Central Hospital\nlinelist[.N] #returns the last row\nlinelist[15:.N] #returns the 15th to the last row"},{"path":"data-table.html","id":"using-helper-functions-for-filtering","chapter":"50 Data Table","heading":"Using helper functions for filtering","text":"Data table uses helper functions make subsetting rows easy. %like% function used match pattern column, %chin% used match specific character, %% helper function used match numeric columns within prespecified range.following examples :\n* filter rows hospital variable contains “Hospital”\n* filter rows outcome “Recover” “Death”\n* filter rows age range 40-60","code":"\nlinelist[hospital %like% \"Hospital\"] #filter rows where the hospital variable contains “Hospital”\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #filter rows where the outcome is “Recover” or “Death”\nlinelist[age %between% c(40, 60)] #filter rows in the age range 40-60\n\n#%between% must take a vector of length 2, whereas %chin% can take vectors of length >= 1"},{"path":"data-table.html","id":"the-j-argument-selecting-and-computing-on-columns","chapter":"50 Data Table","heading":"50.4 The j argument: selecting and computing on columns","text":"Using DT[, j, ] structure, can select columns using numbers names. j argument second; therefore, syntax DT[, j] used. facilitate computations j argument, column wrapped using either list() .().","code":""},{"path":"data-table.html","id":"selecting-columns","chapter":"50 Data Table","heading":"Selecting columns","text":"first example retrieves first, third fifth columns data table, second example selects columns except height, weight gender columns. third example uses .() wrap select case_id outcome columns.","code":"\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] works just as well"},{"path":"data-table.html","id":"computing-on-columns","chapter":"50 Data Table","heading":"Computing on columns","text":"combining j arguments possible filter rows compute columns. Using .N j argument also represents total number rows data table can useful return number rows row filtering.following examples :\n* Count number cases stayed 7 days hospital\n* Calculate mean age cases died military hospital\n* Calculate standard deviation, median, mean age cases recovered central hospitalRemember using .() wrap j argument facilitates computation, returns data table allows column naming.","code":"\nlinelist[days_onset_hosp > 7 , .N]## [1] 189\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T removes N/A values##         V1\n## 1: 15.9084\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #this syntax does not use the helper functions but works just as well##    mean_age median_age   sd_age\n## 1: 16.85185         14 12.93857"},{"path":"data-table.html","id":"the-by-argument-computing-by-groups","chapter":"50 Data Table","heading":"50.5 The by argument: computing by groups","text":"argument third argument DT[, j, ] structure. argument accepts character vector list() .() syntax. Using .() syntax argument allows column renaming fly.following examples :\n* group number cases hospital\n* cases 18 years old , calculate mean height weight cases according gender whether recovered died\n* admissions lasted 7 days, count number cases according month admitted hospital admitted toData.table also allows chaining expressions follows:examples following assumption row data table equal new case, can use .N represent number rows data table. Another useful function represent number unique cases uniqueN(), returns number unique values given input. illustrated :answer 3, unique values gender column m, f N/. Compare base R function unique(), returns unique values given input:find number unique cases given month write following:","code":"\nlinelist[, .N, .(hospital)] #the number of cases by hospital##                                hospital    N\n## 1:                                Other  885\n## 2:                              Missing 1469\n## 3: St. Mark's Maternity Hospital (SMMH)  422\n## 4:                        Port Hospital 1762\n## 5:                    Military Hospital  896\n## 6:                     Central Hospital  454\nlinelist[age > 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs represent the categories where the data is missing##    gender outcome  mean_wt  mean_ht\n## 1:      m Recover 71.90227 178.1977\n## 2:      f   Death 63.27273 159.9448\n## 3:      m   Death 71.61770 175.4726\n## 4:      f    <NA> 64.49375 162.7875\n## 5:      m    <NA> 72.65505 176.9686\n## 6:      f Recover 62.86498 159.2996\n## 7:   <NA> Recover 67.21429 175.2143\n## 8:   <NA>   Death 69.16667 170.7917\n## 9:   <NA>    <NA> 70.25000 175.5000\nlinelist[days_onset_hosp > 7, .N, .(month = month(date_hospitalisation), hospital)]##     month                             hospital  N\n##  1:     5                    Military Hospital  3\n##  2:     6                        Port Hospital  4\n##  3:     7                        Port Hospital  8\n##  4:     8 St. Mark's Maternity Hospital (SMMH)  5\n##  5:     8                    Military Hospital  9\n##  6:     8                                Other 10\n##  7:     8                        Port Hospital 10\n##  8:     9                        Port Hospital 28\n##  9:     9                              Missing 27\n## 10:     9                     Central Hospital 10\n## 11:     9 St. Mark's Maternity Hospital (SMMH)  6\n## 12:    10                              Missing  2\n## 13:    10                    Military Hospital  3\n## 14:     3                        Port Hospital  1\n## 15:     4                    Military Hospital  1\n## 16:     5                                Other  2\n## 17:     5                     Central Hospital  1\n## 18:     5                              Missing  1\n## 19:     6                              Missing  7\n## 20:     6 St. Mark's Maternity Hospital (SMMH)  2\n## 21:     6                    Military Hospital  1\n## 22:     7                    Military Hospital  3\n## 23:     7                                Other  1\n## 24:     7                              Missing  2\n## 25:     7 St. Mark's Maternity Hospital (SMMH)  1\n## 26:     8                     Central Hospital  2\n## 27:     8                              Missing  6\n## 28:     9                                Other  9\n## 29:     9                    Military Hospital 11\n## 30:    10                        Port Hospital  3\n## 31:    10                                Other  4\n## 32:    10 St. Mark's Maternity Hospital (SMMH)  1\n## 33:    10                     Central Hospital  1\n## 34:    11                              Missing  2\n## 35:    11                        Port Hospital  1\n## 36:    12                        Port Hospital  1\n##     month                             hospital  N\nlinelist[, .N, .(hospital)][order(-N)][1:3] #1st selects all cases by hospital, 2nd orders the cases in descending order, 3rd subsets the 3 hospitals with the largest caseload##             hospital    N\n## 1:     Port Hospital 1762\n## 2:           Missing 1469\n## 3: Military Hospital  896\nlinelist[, .(uniqueN(gender))] #remember .() in the j argument returns a data table##    V1\n## 1:  3\nlinelist[, .(unique(gender))]##      V1\n## 1:    m\n## 2:    f\n## 3: <NA>\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]##     month   V1\n##  1:     5   62\n##  2:     6  100\n##  3:     7  198\n##  4:     8  509\n##  5:     9 1170\n##  6:    10 1228\n##  7:    11  813\n##  8:    12  576\n##  9:     1  434\n## 10:     2  310\n## 11:     3  290\n## 12:     4  198"},{"path":"data-table.html","id":"adding-and-updating-to-data-tables","chapter":"50 Data Table","heading":"50.6 Adding and updating to data tables","text":":= operator used add update data data table. Adding columns data table can done following ways:complex aggregations beyond scope introductory chapter, idea provide popular viable alternative dplyr grouping cleaning data. data.table package great package allows neat readable code.","code":"\nlinelist[, adult := age >= 18] #adds one column\nlinelist[, c(\"child\", \"wt_lbs\") := .(age < 18, wt_kg*2.204)] #to add multiple columns requires c(\"\") and list() or .() syntax\nlinelist[, `:=` (bmi_in_range = (bmi > 16 & bmi < 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #this method uses := as a functional operator `:=`\nlinelist[, adult := NULL] #deletes the column"},{"path":"data-table.html","id":"resources-41","chapter":"50 Data Table","heading":"50.7 Resources","text":"useful resources information:\n* https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\n* https://github.com/Rdatatable/data.table\n* https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf\n* https://www.machinelearningplus.com/data-manipulation/datatable--r-complete-guide/\n* https://www.datacamp.com/community/tutorials/data-table-r-tutorialYou can perform summary function grouped data; see Cheat Sheet info:\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf","code":""}]
