{"title":"De-duplication","markdown":{"headingText":"De-duplication","headingAttr":{"id":"","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n```{r, out.width=c(\"50%\"), echo=F}\nknitr::include_graphics(here::here(\"images\", \"deduplication.png\"))\n```\n\nThis page covers the following de-duplication techniques:  \n\n1. Identifying and removing duplicate rows  \n2. \"Slicing\" rows to keep only certain rows (e.g. min or max) from each group of rows  \n3. \"Rolling-up\", or combining values from multiple rows into one row  \n\n\n<!-- ======================================================= -->\n## Preparation { }\n\n\n### Load packages {.unnumbered}\n\nThis code chunk shows the loading of packages required for the analyses. In this handbook we emphasize `p_load()` from **pacman**, which installs the package if necessary *and* loads it for use. You can also load installed packages with  `library()` from **base** R. See the page on [R basics] for more information on R packages.  \n\n```{r}\npacman::p_load(\n  tidyverse,   # deduplication, grouping, and slicing functions\n  janitor,     # function for reviewing duplicates\n  stringr)      # for string searches, can be used in \"rolling-up\" values\n```\n\n### Import data {.unnumbered}\n\nFor demonstration, we will use an example dataset that is created with the R code below.  \n\nThe data are records of COVID-19 phone encounters, including encounters with contacts and with cases. The columns include `recordID` (computer-generated), `personID`, `name`, `date` of encounter, `time` of encounter, the `purpose` of the encounter (either to interview as a case or as a contact), and `symptoms_ever` (whether the person in that encounter reported *ever* having symptoms).  \n\nHere is the code to create the `obs` dataset:  \n\n```{r}\nobs <- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %>% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))\n```\n\n\n#### Here is the data frame {#dedup_data .unnumbered}  \n\nUse the filter boxes along the top to review the encounters for each person.  \n\n```{r message=FALSE, echo=F}\nDT::datatable(obs, rownames = FALSE, filter = \"top\", options = list(pageLength = nrow(obs), scrollX=T), class = 'white-space: nowrap' )\n```\n\n\nA few things to note as you review the data:  \n\n* The first two records are 100% complete duplicates including duplicate `recordID` (must be a computer glitch!)  \n* The second two rows are duplicates, in all columns *except for `recordID`*  \n* Several people had multiple phone encounters, at various dates and times, and as contacts and/or cases  \n* At each encounter, the person was asked if they had **ever** had symptoms, and some of this information is missing.  \n\n\nAnd here is a quick summary of the people and the purposes of their encounters, using `tabyl()` from **janitor**:  \n\n```{r}\nobs %>% \n  tabyl(name, purpose)\n```\n<!-- ======================================================= -->\n## Deduplication { }\n\n\nThis section describes how to review and remove duplicate rows in a data frame. It also show how to handle duplicate elements in a vector.  \n\n\n<!-- ======================================================= -->\n### Examine duplicate rows {.unnumbered}  \n\n\nTo quickly review rows that have duplicates, you can use `get_dupes()` from the **janitor** package. *By default*, all columns are considered when duplicates are evaluated - rows returned by the function are 100% duplicates considering the values in *all* columns.  \n\nIn the `obs` data frame, the first two rows are *100% duplicates* - they have the same value in every column (including the `recordID` column, which is *supposed* to be unique - it must be some computer glitch). The returned data frame automatically includes a new column `dupe_count` on the right side, showing the number of rows with that combination of duplicate values. \n\n```{r, eval=F}\n# 100% duplicates across all columns\nobs %>% \n  janitor::get_dupes()\n```\n\n```{r message=FALSE, echo=F}\nobs %>% \n  janitor::get_dupes() %>% \n  DT::datatable(rownames = FALSE, options = list(pageLength = nrow(obs), scrollX=T), class = 'white-space: nowrap' )\n```\n\nSee the [original data](#dedup_data)  \n\nHowever, if we choose to ignore `recordID`, the 3rd and 4th rows rows are also duplicates of each other. That is, they have the same values in all columns *except* for `recordID`. You can specify specific columns to be ignored in the function using a `-` minus symbol.  \n\n```{r, eval=F}\n# Duplicates when column recordID is not considered\nobs %>% \n  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()\n```\n\n```{r message=FALSE, echo=F}\nobs %>% \n  janitor::get_dupes(-recordID) %>% \n  DT::datatable(rownames = FALSE, options = list(pageLength = nrow(obs), scrollX=T), class = 'white-space: nowrap' )\n```\n\nYou can also positively specify the columns to consider. Below, only rows that have the same values in the `name` and `purpose` columns are returned. Notice how \"amrish\" now has `dupe_count` equal to 3 to reflect his three \"contact\" encounters.  \n\n*Scroll left for more rows**  \n\n```{r, eval=F}\n# duplicates based on name and purpose columns ONLY\nobs %>% \n  janitor::get_dupes(name, purpose)\n```\n\n```{r message=FALSE, echo=F}\nobs %>% \n  janitor::get_dupes(name, purpose) %>% \n  DT::datatable(rownames = FALSE, options = list(pageLength = 7, scrollX=T), class = 'white-space: nowrap' )\n```\n\nSee the [original data](#dedup_data).  \n\nSee `?get_dupes` for more details, or see this [online reference](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables-with-get_dupes)  \n\n\n\n\n\n\n<!-- ======================================================= -->\n### Keep only unique rows  {.unnumbered}\n\n\nTo keep only unique rows of a data frame, use `distinct()` from **dplyr** (as demonstrated in the [Cleaning data and core functions] page). Rows that are duplicates are removed such that only the first of such rows is kept. By default, \"first\" means the highest `rownumber` (order of rows top-to-bottom). Only unique rows remain.  \n\nIn the example below, we run `distinct()` such that the column `recordID` is excluded from consideration - thus **two duplicate rows are removed**. The first row (for \"adam\") was 100% duplicated and has been removed. Also row 3 (for \"amrish\") was a duplicate in every column *except* `recordID` (which is not being considered) and so is also removed. The `obs` dataset n is now ` nrow(obs)-2`, not ` nrow(obs)` rows).  \n\n*Scroll to the left to see the entire data frame*  \n\n\n```{r, eval=F}\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(across(-recordID), # reduces data frame to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) \n\n# if outside pipes, include the data as first argument \n# distinct(obs)\n```\n\n```{r message=FALSE, echo=F}\nobs %>% \n  distinct(across(-recordID), # reduces data frame to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) %>% \n  DT::datatable(rownames = FALSE, options = list(pageLength = 6, scrollX=T), class = 'white-space: nowrap' )\n```\n\n<span style=\"color: orange;\">**_CAUTION:_** If using `distinct()` on grouped data, the function will apply to each group.</span>\n\n\n**Deduplicate based on specific columns**  \n\nYou can also specify columns to be the basis for de-duplication. In this way, the de-duplication only applies to rows that are duplicates within the specified columns. Unless you set `.keep_all = TRUE`, all columns not mentioned will be dropped.  \n\nIn the example below, the de-duplication only applies to rows that have identical values for `name` and `purpose` columns. Thus, \"brian\" has only 2 rows instead of 3 - his *first* \"contact\" encounter and his only \"case\" encounter. To adjust so that brian's *latest* encounter of each purpose is kept, see the tab on Slicing within groups.  \n\n*Scroll to the left to see the entire data frame*  \n\n```{r, eval=F}\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns\n  arrange(name)                                  # arrange for easier viewing\n```\n\n```{r message=FALSE, echo=F}\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns\n  arrange(name) %>% \n  DT::datatable(rownames = FALSE, options = list(pageLength = 6, scrollX=T), class = 'white-space: nowrap' )\n```\n\nSee the [original data](#dedup_data).  \n\n<!-- ======================================================= -->\n### Deduplicate elements in a vector {.unnumbered}  \n\n\nThe function `duplicated()` from **base** R will evaluate a vector (column) and return a logical vector of the same length (TRUE/FALSE). The first time a value appears, it will return FALSE (not a duplicate), and subsequent times that value appears it will return TRUE. Note how `NA` is treated the same as any other value.    \n\n```{r}\nx <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)\n```\n\nTo return only the duplicated elements, you can use brackets to subset the original vector: \n\n```{r}\nx[duplicated(x)]\n```\n\nTo return only the unique elements, use `unique()` from **base** R. To remove `NA`s from the output, nest `na.omit()` within `unique()`.  \n\n```{r}\nunique(x)           # alternatively, use x[!duplicated(x)]\nunique(na.omit(x))  # remove NAs \n```\n\n\n<!-- ======================================================= -->\n### Using **base** R {.unnumbered}\n\n**To return duplicate rows**  \n\nIn **base** R, you can also see which rows are 100% duplicates in a data frame `df` with the command `duplicated(df)` (returns a logical vector of the rows).  \n\nThus, you can also use the base subset `[ ]` on the data frame to see the *duplicated* rows with `df[duplicated(df),]` (don't forget the comma, meaning that you want to see all columns!). \n\n**To return unique rows**  \n\nSee the notes above. To see the *unique* rows you add the logical negator `!` in front of the `duplicated()` function:  \n`df[!duplicated(df),]`  \n\n\n**To return rows that are duplicates of only certain columns**  \n\nSubset the `df` that is *within the `duplicated()` parentheses*, so this function will operate on only certain columns of the `df`.  \n\nTo specify the columns, provide column numbers or names after a comma (remember, all this is *within* the `duplicated()` function).  \n\nBe sure to keep the comma `,` *outside* after the `duplicated()` function as well! \n\nFor example, to evaluate only columns 2 through 5 for duplicates:  `df[!duplicated(df[, 2:5]),]`  \nTo evaluate only columns `name` and `purpose` for duplicates: `df[!duplicated(df[, c(\"name\", \"purpose)]),]`  \n\n\n\n\n\n<!-- ======================================================= -->\n## Slicing { }\n\n\nTo \"slice\" a data frame to apply a filter on the rows by row number/position. This becomes particularly useful if you have multiple rows per functional group (e.g. per \"person\") and you only want to keep one or some of them. \n\nThe basic `slice()` function accepts numbers and returns rows in those positions. If the numbers provided are positive, only they are returned. If negative, those rows are *not* returned. Numbers must be either all positive or all negative.     \n\n```{r}\nobs %>% slice(4)  # return the 4th row\n```\n\n```{r}\nobs %>% slice(c(2,4))  # return rows 2 and 4\n#obs %>% slice(c(2:4))  # return rows 2 through 4\n```\n\n\nSee the [original data](#dedup_data). \n\nThere are several variations:  These should be provided with a column and a number of rows to return (to `n = `).  \n\n* `slice_min()` and `slice_max()`  keep only the row(s) with the minimium or maximum value(s) of the specified column. This also works to return the \"min\" and \"max\" of ordered factors.    \n* `slice_head()` and `slice_tail()` - keep only the *first* or *last* row(s).  \n* `slice_sample()`  - keep only a random sample of the rows.  \n\n\n```{r}\nobs %>% slice_max(encounter, n = 1)  # return rows with the largest encounter number\n```\n\nUse arguments `n = ` or `prop = ` to specify the number or proportion of rows to keep. If not using the function in a pipe chain, provide the data argument first (e.g. `slice(data, n = 2)`). See `?slice` for more information. \n\nOther arguments:  \n\n`.order_by = ` used in `slice_min()` and `slice_max()` this is a column to order by before slicing.  \n`with_ties = ` TRUE by default, meaning ties are kept.  \n`.preserve = ` FALSE by default. If TRUE then the grouping structure is re-calculated after slicing.  \n`weight_by = ` Optional, numeric column to weight by (bigger number more likely to get sampled).  Also `replace = ` for whether sampling is done with/without replacement.  \n\n<span style=\"color: darkgreen;\">**_TIP:_** When using `slice_max()` and `slice_min()`, be sure to specify/write the `n = `  (e.g. `n = 2`, not just `2`). Otherwise you may get an error `Error: `...` is not empty.` </span>\n\n<span style=\"color: black;\">**_NOTE:_** You may encounter the function [`top_n()`](https://dplyr.tidyverse.org/reference/top_n.html), which has been superseded by the `slice` functions.</span>\n\n \n\n\n<!-- ======================================================= -->\n### Slice with groups  {.unnumbered}\n\nThe `slice_*()` functions can be very useful if applied to a grouped data frame because the slice operation is performed on each group separately. Use the **function** `group_by()` in conjunction with `slice()` to group the data to take a slice from each group.  \n\nThis is helpful for de-duplication if you have multiple rows per person but only want to keep one of them. You first use `group_by()` with key columns that are the same per person, and then use a slice function on a column that will differ among the grouped rows.  \n\nIn the example below, to keep only the *latest* encounter *per person*, we group the rows by `name` and then use `slice_max()` with `n = 1` on the `date` column. Be aware! To apply a function like `slice_max()` on dates, the date column must be class Date.   \n\nBy default, \"ties\" (e.g. same date in this scenario) are kept, and we would still get multiple rows for some people (e.g. adam). To avoid this we set `with_ties = FALSE`. We get back only one row per person.  \n\n<span style=\"color: orange;\">**_CAUTION:_** If using `arrange()`, specify `.by_group = TRUE` to have the data arranged within each group.</span>\n\n<span style=\"color: red;\">**_DANGER:_** If `with_ties = FALSE`, the first row of a tie is kept. This may be deceptive. See how for Mariah, she has two encounters on her latest date (6 Jan) and the first (earliest) one was kept. Likely, we want to keep her later encounter on that day. See how to \"break\" these ties in the next example. </span>  \n\n\n\n\n```{r, eval=F}\nobs %>% \n  group_by(name) %>%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) # if there's a tie (of date), take the first row\n```\n\n```{r message=FALSE, echo=F}\nobs %>% \n  group_by(name) %>%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) %>%  # if there's a tie (of date), take the first row\n  DT::datatable(rownames = FALSE, options = list(pageLength = 8, scrollX=T), class = 'white-space: nowrap' )\n```\n\nAbove, for example we can see that only Amrish's row on 5 Jan was kept, and only Brian's row on 7 Jan was kept. See the [original data](#dedup_data).  \n\n\n**Breaking \"ties\"**  \n\nMultiple slice statements can be run to \"break ties\". In this case, if a person has multiple encounters on their latest *date*, the encounter with the latest *time* is kept (`lubridate::hm()` is used to convert the character times to a sortable time class).  \nNote how now, the one row kept for \"Mariah\" on 6 Jan is encounter 3 from 08:32, not encounter 2 at 07:25.  \n\n```{r, eval=F}\n# Example of multiple slice statements to \"break ties\"\nobs %>%\n  group_by(name) %>%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)\n```\n\n```{r message=FALSE, echo=F}\n# Example of multiple slice statements to \"break ties\"\nobs %>%\n  group_by(name) %>%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE) %>% \n  \n  DT::datatable(rownames = FALSE, options = list(pageLength = 8, scrollX=T), class = 'white-space: nowrap' )\n```\n\n*In the example above, it would also have been possible to slice by `encounter` number, but we showed the slice on `date` and `time` for example purposes.*  \n\n<span style=\"color: darkgreen;\">**_TIP:_** To use `slice_max()` or `slice_min()` on a \"character\" column, mutate it to an *ordered* factor class!</span>\n\nSee the [original data](#dedup_data).  \n\n\n<!-- ======================================================= -->\n### Keep all but mark them  {.unnumbered}\n\nIf you want to keep all records but mark only some for analysis, consider a two-step approach utilizing a unique recordID/encounter number:  \n\n1) Reduce/slice the orginal data frame to only the rows for analysis. Save/retain this reduced data frame.  \n2) In the original data frame, mark rows as appropriate with `case_when()`, based on whether their record unique identifier (recordID in this example) is present in the reduced data frame.  \n\n\n```{r}\n# 1. Define data frame of rows to keep for analysis\nobs_keep <- obs %>%\n  group_by(name) %>%\n  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person\n\n\n# 2. Mark original data frame\nobs_marked <- obs %>%\n\n  # make new dup_record column\n  mutate(dup_record = case_when(\n    \n    # if record is in obs_keep data frame\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # all else marked as \"Ignore\" for analysis purposes\n    TRUE                            ~ \"Ignore\"))\n\n# print\nobs_marked\n```\n\n\n```{r, echo=F}\nDT::datatable(obs_marked, rownames = FALSE, options = list(pageLength = 8, scrollX=T), class = 'white-space: nowrap' )\n```\n\nSee the [original data](#dedup_data).  \n\n<!-- ======================================================= -->\n### Calculate row completeness {.unnumbered} \n\nCreate a column that contains a metric for the row's completeness (non-missingness). This could be helpful when deciding which rows to prioritize over others when de-duplicating/slicing.  \n\nIn this example, \"key\" columns over which you want to measure completeness are saved in a vector of column names.  \n\nThen the new column `key_completeness` is created with `mutate()`. The new value in each row is defined as a calculated fraction: the number of non-missing values in that row among the key columns, divided by the number of key columns.  \n\nThis involves the function `rowSums()` from **base** R. Also used is `.`, which within piping refers to the data frame at that point in the pipe (in this case, it is being subset with brackets `[]`).  \n\n*Scroll to the right to see more rows**  \n\n```{r, eval=F}\n# create a \"key variable completeness\" column\n# this is a *proportion* of the columns designated as \"key_cols\" that have non-missing values\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) \n```\n\n```{r message=FALSE, echo=F}\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) %>% \n  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n```\n\nSee the [original data](#dedup_data).  \n\n\n\n\n<!-- ======================================================= -->\n## Roll-up values {#str_rollup}\n\n\nThis section describes:  \n\n1) How to \"roll-up\" values from multiple rows into just one row, with some variations  \n2) Once you have \"rolled-up\" values, how to overwrite/prioritize the values in each cell  \n\nThis tab uses the example dataset from the Preparation tab.  \n\n\n\n<!-- ======================================================= -->\n### Roll-up values into one row {.unnumbered}  \n\nThe code example below uses `group_by()` and `summarise()` to group rows by person, and then paste together all unique values within the grouped rows. Thus, you get one summary row per person. A few notes:  \n\n* A suffix is appended to all new columns (\"_roll\" in this example)  \n* If you want to show only unique values per cell, then wrap the `na.omit()` with `unique()`  \n* `na.omit()` removes `NA` values, but if this is not desired it can be removed `paste0(.x)`...  \n\n\n\n```{r, eval=F}\n# \"Roll-up\" values into one row per group (per \"personID\") \ncases_rolled <- obs %>% \n  \n  # create groups by name\n  group_by(personID) %>% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                           # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) # function is defined which combines non-NA values\n```\n\nThe result is one row per group (`ID`), with entries arranged by date and pasted together. *Scroll to the left to see more rows*    \n\n```{r message=FALSE, echo=F}\n# \"Roll-up\" values into one row per group (per \"personID\") \nobs %>% \n  \n  # create groups by name\n  group_by(personID) %>% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                                # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) %>%  # function is defined which combines non-NA values\n\n  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap')\n```\n\nSee the [original data](#dedup_data).  \n\n\n**This variation shows unique values only:**  \n\n```{r}\n# Variation - show unique values only \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # function is defined which combines unique non-NA values\n```\n\n```{r message=FALSE, echo=F}\n# Variation - show unique values only \nobs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) %>%  # function is defined which combines unique non-NA values\n\n  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n```\n\n\n**This variation appends a suffix to each column.**  \nIn this case \"_roll\" to signify that it has been rolled:  \n\n```{r, eval=F}\n# Variation - suffix added to column names \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll is appended to column names\n```\n\n```{r message=FALSE, echo=F}\n# display the linelist data as a table\n# Variation - suffix added to column names \nobs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) %>%  # _roll is appended to column names\n  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )\n```\n\n\n<!-- ======================================================= -->\n### Overwrite values/hierarchy {.unnumbered} \n\n\nIf you then want to evaluate all of the rolled values, and keep only a specific value (e.g. \"best\" or \"maximum\" value), you can use `mutate()` across the desired columns, to implement `case_when()`, which uses `str_detect()` from the **stringr** package to sequentially look for string patterns and overwrite the cell content.  \n\n```{r}\n# CLEAN CASES\n#############\ncases_clean <- cases_rolled %>% \n    \n    # clean Yes-No-Unknown vars: replace text with \"highest\" value present in the string\n    mutate(across(c(contains(\"symptoms_ever\")),                     # operates on specified columns (Y/N/U)\n             list(mod = ~case_when(                                 # adds suffix \"_mod\" to new cols; implements case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # if \"Yes\" is detected, then cell value converts to yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # then, if \"No\" is detected, then cell value converts to no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # then, if \"Unknown\" is detected, then cell value converts to Unknown\n               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is\n      .keep = \"unused\")                                             # old columns removed, leaving only _mod columns\n```\n\n\nNow you can see in the column `symptoms_ever` that if the person EVER said \"Yes\" to symptoms, then only \"Yes\" is displayed.  \n\n```{r message=FALSE, echo=F}\n# display the linelist data as a table\nDT::datatable(cases_clean, rownames = FALSE, options = list(pageLength = 10, scrollX=T), class = 'white-space: nowrap')\n```\n\n\nSee the [original data](#dedup_data).  \n\n\n## Probabilistic de-duplication  \n\nSometimes, you may want to identify \"likely\" duplicates based on similarity (e.g. string \"distance\") across several columns such as name, age, sex, date of birth, etc. You can apply a probabilistic matching algorithm to identify likely duplicates.  \n\nSee the page on [Joining data] for an explanation on this method. The section on Probabilistic Matching contains an example of applying these algorithms to compare a data frame to *itself*, thus performing probabilistic de-duplication.  \n\n\n\n<!-- ======================================================= -->\n## Resources { }\n\nMuch of the information in this page is adapted from these resources and vignettes online:  \n\n[datanovia](https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/)\n\n[dplyr tidyverse reference](https://dplyr.tidyverse.org/reference/slice.html)  \n\n[cran janitor vignette](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables-with-get_dupes)  \n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"deduplication.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.340","lightbox":true,"theme":{"light":"cosmo","dark":["cosmo","theme-dark.scss"]}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}